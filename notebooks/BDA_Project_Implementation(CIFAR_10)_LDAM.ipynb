{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMnf3Xqn6EgA",
        "outputId": "a67a700b-4944-4e9a-cd5c-9d73015665d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorBoardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1TX5LK2HYgx",
        "outputId": "050e9e70-6bfc-4627-9aad-41b011f4e4e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TensorBoardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (3.19.6)\n",
            "Installing collected packages: TensorBoardX\n",
            "Successfully installed TensorBoardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wlAfnk6HszO",
        "outputId": "d237c1f7-05fb-4134-aba9-9683455d9e91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import yaml\n",
        "import sklearn\n",
        "import tensorboardX"
      ],
      "metadata": {
        "id": "0ycPQC9iHxzo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/BDAProject/imbalanced-semi-self-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtceccWX_ool",
        "outputId": "662a0125-4040-40f4-b28f-bf1df29e8f02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CslK100MIylmBJU9zN4Vmh1BZXMZZloK/BDAProject/imbalanced-semi-self-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gen_pseudolabels.py --resume \"./checkpoint\" --data_dir \"./data\" --output_dir \"./data\" --output_filename \"./gen_pseudolabels_ouptut\""
      ],
      "metadata": {
        "id": "iHxhl8An7QUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbEuIaOG8GqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Semi-Supervised Imbalance Learning**"
      ],
      "metadata": {
        "id": "34MRc1R2m7-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function: Cross Entropy Loss**"
      ],
      "metadata": {
        "id": "ODjmTLdxfZN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train with unlabeled data"
      ],
      "metadata": {
        "id": "FvqYE5wzm_4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset cifar10 --imb_factor 0.02 --imb_factor_unlabel 0.02"
      ],
      "metadata": {
        "id": "DUhB43gJArTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d118f5d6-e10f-4722-a9cf-aac50e8e1cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/329], lr: 0.01000\tTime 0.652 (0.652)\tData 0.569 (0.569)\tLoss 0.3974 (0.3974)\tPrec@1 85.547 (85.547)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [98][10/329], lr: 0.01000\tTime 0.096 (0.145)\tData 0.000 (0.058)\tLoss 0.5027 (0.5349)\tPrec@1 85.547 (82.493)\tPrec@5 98.828 (99.006)\n",
            "Epoch: [98][20/329], lr: 0.01000\tTime 0.105 (0.122)\tData 0.000 (0.035)\tLoss 0.3820 (0.5011)\tPrec@1 87.500 (83.352)\tPrec@5 99.219 (98.996)\n",
            "Epoch: [98][30/329], lr: 0.01000\tTime 0.100 (0.113)\tData 0.000 (0.025)\tLoss 0.3447 (0.4606)\tPrec@1 90.234 (84.829)\tPrec@5 98.828 (99.143)\n",
            "Epoch: [98][40/329], lr: 0.01000\tTime 0.077 (0.108)\tData 0.006 (0.021)\tLoss 0.3408 (0.4310)\tPrec@1 89.453 (85.880)\tPrec@5 99.609 (99.209)\n",
            "Epoch: [98][50/329], lr: 0.01000\tTime 0.100 (0.105)\tData 0.006 (0.018)\tLoss 0.2142 (0.4044)\tPrec@1 94.141 (86.757)\tPrec@5 100.000 (99.257)\n",
            "Epoch: [98][60/329], lr: 0.01000\tTime 0.094 (0.102)\tData 0.005 (0.016)\tLoss 0.2558 (0.3885)\tPrec@1 91.016 (87.218)\tPrec@5 100.000 (99.321)\n",
            "Epoch: [98][70/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.000 (0.015)\tLoss 0.3852 (0.3764)\tPrec@1 88.281 (87.610)\tPrec@5 98.828 (99.362)\n",
            "Epoch: [98][80/329], lr: 0.01000\tTime 0.118 (0.099)\tData 0.004 (0.014)\tLoss 0.2098 (0.3656)\tPrec@1 93.750 (87.910)\tPrec@5 100.000 (99.373)\n",
            "Epoch: [98][90/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.005 (0.013)\tLoss 0.3162 (0.3582)\tPrec@1 87.109 (88.127)\tPrec@5 98.828 (99.360)\n",
            "Epoch: [98][100/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.000 (0.012)\tLoss 0.2832 (0.3500)\tPrec@1 89.453 (88.355)\tPrec@5 99.609 (99.350)\n",
            "Epoch: [98][110/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.007 (0.012)\tLoss 0.2889 (0.3479)\tPrec@1 89.844 (88.503)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [98][120/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.007 (0.011)\tLoss 0.2377 (0.3408)\tPrec@1 91.406 (88.727)\tPrec@5 99.219 (99.367)\n",
            "Epoch: [98][130/329], lr: 0.01000\tTime 0.112 (0.096)\tData 0.007 (0.011)\tLoss 0.2682 (0.3363)\tPrec@1 90.625 (88.860)\tPrec@5 100.000 (99.398)\n",
            "Epoch: [98][140/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.011)\tLoss 0.2984 (0.3335)\tPrec@1 91.016 (88.943)\tPrec@5 100.000 (99.421)\n",
            "Epoch: [98][150/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.006 (0.010)\tLoss 0.3042 (0.3296)\tPrec@1 88.281 (89.052)\tPrec@5 99.609 (99.433)\n",
            "Epoch: [98][160/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.004 (0.010)\tLoss 0.2716 (0.3266)\tPrec@1 90.625 (89.143)\tPrec@5 98.828 (99.452)\n",
            "Epoch: [98][170/329], lr: 0.01000\tTime 0.110 (0.094)\tData 0.005 (0.010)\tLoss 0.3224 (0.3220)\tPrec@1 90.234 (89.298)\tPrec@5 99.609 (99.479)\n",
            "Epoch: [98][180/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.013 (0.010)\tLoss 0.2574 (0.3187)\tPrec@1 89.062 (89.378)\tPrec@5 100.000 (99.486)\n",
            "Epoch: [98][190/329], lr: 0.01000\tTime 0.110 (0.093)\tData 0.000 (0.010)\tLoss 0.2661 (0.3159)\tPrec@1 92.188 (89.490)\tPrec@5 99.219 (99.495)\n",
            "Epoch: [98][200/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.000 (0.010)\tLoss 0.2817 (0.3127)\tPrec@1 91.016 (89.612)\tPrec@5 100.000 (99.502)\n",
            "Epoch: [98][210/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.004 (0.010)\tLoss 0.2543 (0.3100)\tPrec@1 91.016 (89.688)\tPrec@5 100.000 (99.519)\n",
            "Epoch: [98][220/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.008 (0.010)\tLoss 0.3503 (0.3081)\tPrec@1 89.453 (89.754)\tPrec@5 99.609 (99.519)\n",
            "Epoch: [98][230/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.005 (0.009)\tLoss 0.3004 (0.3073)\tPrec@1 89.062 (89.788)\tPrec@5 99.219 (99.520)\n",
            "Epoch: [98][240/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.005 (0.009)\tLoss 0.2316 (0.3044)\tPrec@1 93.359 (89.888)\tPrec@5 98.828 (99.527)\n",
            "Epoch: [98][250/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.006 (0.009)\tLoss 0.3135 (0.3030)\tPrec@1 91.016 (89.912)\tPrec@5 98.828 (99.535)\n",
            "Epoch: [98][260/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.007 (0.009)\tLoss 0.2368 (0.3010)\tPrec@1 91.797 (89.986)\tPrec@5 100.000 (99.544)\n",
            "Epoch: [98][270/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.006 (0.009)\tLoss 0.2541 (0.2997)\tPrec@1 93.359 (90.030)\tPrec@5 99.609 (99.553)\n",
            "Epoch: [98][280/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.004 (0.009)\tLoss 0.2665 (0.2985)\tPrec@1 92.188 (90.079)\tPrec@5 99.609 (99.559)\n",
            "Epoch: [98][290/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.011 (0.009)\tLoss 0.2353 (0.2971)\tPrec@1 92.188 (90.115)\tPrec@5 99.609 (99.565)\n",
            "Epoch: [98][300/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.007 (0.009)\tLoss 0.3924 (0.2963)\tPrec@1 86.328 (90.149)\tPrec@5 98.828 (99.567)\n",
            "Epoch: [98][310/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.007 (0.009)\tLoss 0.2399 (0.2951)\tPrec@1 92.969 (90.182)\tPrec@5 98.828 (99.569)\n",
            "Epoch: [98][320/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.056 (0.009)\tLoss 0.3112 (0.2943)\tPrec@1 89.844 (90.216)\tPrec@5 99.219 (99.567)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.6936 (0.6936)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.033 (0.060)\tLoss 0.8081 (0.8910)\tPrec@1 73.000 (72.818)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/100]\tTime 0.024 (0.045)\tLoss 0.8825 (0.9113)\tPrec@1 75.000 (73.095)\tPrec@5 100.000 (98.048)\n",
            "Test: [30/100]\tTime 0.014 (0.037)\tLoss 0.9669 (0.9230)\tPrec@1 73.000 (72.968)\tPrec@5 99.000 (98.065)\n",
            "Test: [40/100]\tTime 0.028 (0.035)\tLoss 1.0328 (0.9335)\tPrec@1 72.000 (72.756)\tPrec@5 99.000 (98.049)\n",
            "Test: [50/100]\tTime 0.030 (0.032)\tLoss 0.8867 (0.9338)\tPrec@1 75.000 (72.627)\tPrec@5 97.000 (98.196)\n",
            "Test: [60/100]\tTime 0.015 (0.031)\tLoss 0.9658 (0.9379)\tPrec@1 71.000 (72.738)\tPrec@5 99.000 (98.246)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 0.9505 (0.9360)\tPrec@1 75.000 (72.789)\tPrec@5 99.000 (98.239)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 0.9190 (0.9283)\tPrec@1 77.000 (72.827)\tPrec@5 97.000 (98.284)\n",
            "Test: [90/100]\tTime 0.016 (0.029)\tLoss 0.8998 (0.9418)\tPrec@1 77.000 (72.527)\tPrec@5 99.000 (98.253)\n",
            "val Results: Prec@1 72.540 Prec@5 98.260 Loss 0.94368\n",
            "val Class Accuracy: [0.945,0.976,0.890,0.398,0.662,0.801,0.835,0.627,0.463,0.657]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/329], lr: 0.01000\tTime 1.010 (1.010)\tData 0.902 (0.902)\tLoss 0.2489 (0.2489)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][10/329], lr: 0.01000\tTime 0.121 (0.204)\tData 0.000 (0.096)\tLoss 0.2457 (0.2409)\tPrec@1 92.578 (91.903)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [99][20/329], lr: 0.01000\tTime 0.104 (0.166)\tData 0.002 (0.068)\tLoss 0.2249 (0.2517)\tPrec@1 92.969 (91.592)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [99][30/329], lr: 0.01000\tTime 0.107 (0.143)\tData 0.000 (0.047)\tLoss 0.2780 (0.2580)\tPrec@1 90.625 (91.318)\tPrec@5 99.219 (99.660)\n",
            "Epoch: [99][40/329], lr: 0.01000\tTime 0.102 (0.131)\tData 0.009 (0.037)\tLoss 0.2434 (0.2553)\tPrec@1 91.406 (91.425)\tPrec@5 99.609 (99.667)\n",
            "Epoch: [99][50/329], lr: 0.01000\tTime 0.078 (0.123)\tData 0.000 (0.032)\tLoss 0.2387 (0.2550)\tPrec@1 91.797 (91.483)\tPrec@5 99.609 (99.655)\n",
            "Epoch: [99][60/329], lr: 0.01000\tTime 0.078 (0.118)\tData 0.006 (0.028)\tLoss 0.3627 (0.2553)\tPrec@1 86.719 (91.470)\tPrec@5 99.609 (99.667)\n",
            "Epoch: [99][70/329], lr: 0.01000\tTime 0.106 (0.114)\tData 0.012 (0.025)\tLoss 0.2279 (0.2535)\tPrec@1 91.797 (91.555)\tPrec@5 100.000 (99.659)\n",
            "Epoch: [99][80/329], lr: 0.01000\tTime 0.093 (0.111)\tData 0.000 (0.023)\tLoss 0.2731 (0.2519)\tPrec@1 91.797 (91.609)\tPrec@5 99.219 (99.648)\n",
            "Epoch: [99][90/329], lr: 0.01000\tTime 0.083 (0.109)\tData 0.006 (0.021)\tLoss 0.3233 (0.2527)\tPrec@1 90.234 (91.612)\tPrec@5 99.609 (99.657)\n",
            "Epoch: [99][100/329], lr: 0.01000\tTime 0.104 (0.107)\tData 0.007 (0.020)\tLoss 0.1912 (0.2530)\tPrec@1 93.750 (91.603)\tPrec@5 100.000 (99.664)\n",
            "Epoch: [99][110/329], lr: 0.01000\tTime 0.077 (0.105)\tData 0.007 (0.018)\tLoss 0.1931 (0.2543)\tPrec@1 94.531 (91.600)\tPrec@5 100.000 (99.669)\n",
            "Epoch: [99][120/329], lr: 0.01000\tTime 0.086 (0.103)\tData 0.007 (0.018)\tLoss 0.3109 (0.2539)\tPrec@1 91.016 (91.600)\tPrec@5 99.219 (99.671)\n",
            "Epoch: [99][130/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.007 (0.017)\tLoss 0.1853 (0.2526)\tPrec@1 94.141 (91.627)\tPrec@5 99.609 (99.681)\n",
            "Epoch: [99][140/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.005 (0.016)\tLoss 0.2909 (0.2519)\tPrec@1 91.016 (91.642)\tPrec@5 99.609 (99.690)\n",
            "Epoch: [99][150/329], lr: 0.01000\tTime 0.066 (0.100)\tData 0.000 (0.016)\tLoss 0.2245 (0.2515)\tPrec@1 93.750 (91.662)\tPrec@5 100.000 (99.684)\n",
            "Epoch: [99][160/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.012 (0.015)\tLoss 0.2496 (0.2502)\tPrec@1 92.969 (91.722)\tPrec@5 99.609 (99.689)\n",
            "Epoch: [99][170/329], lr: 0.01000\tTime 0.102 (0.100)\tData 0.007 (0.015)\tLoss 0.2376 (0.2511)\tPrec@1 91.016 (91.667)\tPrec@5 100.000 (99.696)\n",
            "Epoch: [99][180/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.005 (0.015)\tLoss 0.1769 (0.2502)\tPrec@1 94.531 (91.695)\tPrec@5 100.000 (99.706)\n",
            "Epoch: [99][190/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.000 (0.014)\tLoss 0.2685 (0.2505)\tPrec@1 90.234 (91.648)\tPrec@5 99.609 (99.712)\n",
            "Epoch: [99][200/329], lr: 0.01000\tTime 0.079 (0.098)\tData 0.010 (0.014)\tLoss 0.2069 (0.2497)\tPrec@1 92.188 (91.655)\tPrec@5 99.609 (99.712)\n",
            "Epoch: [99][210/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.002 (0.014)\tLoss 0.2382 (0.2495)\tPrec@1 93.359 (91.678)\tPrec@5 99.219 (99.709)\n",
            "Epoch: [99][220/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.000 (0.013)\tLoss 0.2120 (0.2490)\tPrec@1 92.578 (91.693)\tPrec@5 100.000 (99.712)\n",
            "Epoch: [99][230/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.004 (0.013)\tLoss 0.1961 (0.2485)\tPrec@1 93.359 (91.704)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [99][240/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.013)\tLoss 0.2860 (0.2490)\tPrec@1 90.234 (91.683)\tPrec@5 99.609 (99.715)\n",
            "Epoch: [99][250/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.013)\tLoss 0.2399 (0.2493)\tPrec@1 92.188 (91.677)\tPrec@5 100.000 (99.715)\n",
            "Epoch: [99][260/329], lr: 0.01000\tTime 0.069 (0.095)\tData 0.005 (0.012)\tLoss 0.3187 (0.2490)\tPrec@1 89.453 (91.691)\tPrec@5 99.609 (99.714)\n",
            "Epoch: [99][270/329], lr: 0.01000\tTime 0.070 (0.095)\tData 0.000 (0.012)\tLoss 0.2546 (0.2484)\tPrec@1 91.797 (91.728)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [99][280/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.011 (0.012)\tLoss 0.2748 (0.2487)\tPrec@1 90.625 (91.709)\tPrec@5 100.000 (99.719)\n",
            "Epoch: [99][290/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.007 (0.012)\tLoss 0.2203 (0.2482)\tPrec@1 92.578 (91.720)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [99][300/329], lr: 0.01000\tTime 0.064 (0.095)\tData 0.007 (0.012)\tLoss 0.2291 (0.2484)\tPrec@1 91.406 (91.701)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [99][310/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.001 (0.012)\tLoss 0.2277 (0.2481)\tPrec@1 92.578 (91.715)\tPrec@5 99.609 (99.721)\n",
            "Epoch: [99][320/329], lr: 0.01000\tTime 0.109 (0.094)\tData 0.072 (0.012)\tLoss 0.3542 (0.2488)\tPrec@1 88.281 (91.696)\tPrec@5 99.219 (99.720)\n",
            "Test: [0/100]\tTime 0.404 (0.404)\tLoss 0.8241 (0.8241)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.019 (0.058)\tLoss 0.6930 (0.9192)\tPrec@1 80.000 (72.455)\tPrec@5 100.000 (98.545)\n",
            "Test: [20/100]\tTime 0.026 (0.042)\tLoss 0.6233 (0.8789)\tPrec@1 77.000 (73.429)\tPrec@5 100.000 (98.429)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 0.8867 (0.8892)\tPrec@1 72.000 (73.290)\tPrec@5 99.000 (98.323)\n",
            "Test: [40/100]\tTime 0.030 (0.034)\tLoss 1.1750 (0.8964)\tPrec@1 69.000 (73.049)\tPrec@5 98.000 (98.390)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 0.8971 (0.8825)\tPrec@1 77.000 (73.255)\tPrec@5 98.000 (98.451)\n",
            "Test: [60/100]\tTime 0.010 (0.031)\tLoss 0.7667 (0.8897)\tPrec@1 77.000 (73.000)\tPrec@5 99.000 (98.525)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 1.1418 (0.8894)\tPrec@1 65.000 (72.944)\tPrec@5 98.000 (98.535)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 0.8227 (0.8831)\tPrec@1 74.000 (73.111)\tPrec@5 99.000 (98.593)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 0.9170 (0.8942)\tPrec@1 72.000 (72.945)\tPrec@5 99.000 (98.571)\n",
            "val Results: Prec@1 73.120 Prec@5 98.530 Loss 0.89563\n",
            "val Class Accuracy: [0.961,0.960,0.690,0.656,0.706,0.846,0.755,0.446,0.631,0.661]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [100][0/329], lr: 0.01000\tTime 0.654 (0.654)\tData 0.566 (0.566)\tLoss 0.3010 (0.3010)\tPrec@1 91.016 (91.016)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [100][10/329], lr: 0.01000\tTime 0.071 (0.148)\tData 0.000 (0.057)\tLoss 0.5419 (0.5838)\tPrec@1 80.469 (81.499)\tPrec@5 98.828 (98.473)\n",
            "Epoch: [100][20/329], lr: 0.01000\tTime 0.080 (0.121)\tData 0.006 (0.034)\tLoss 0.4687 (0.5355)\tPrec@1 83.984 (82.664)\tPrec@5 98.828 (98.661)\n",
            "Epoch: [100][30/329], lr: 0.01000\tTime 0.106 (0.111)\tData 0.000 (0.024)\tLoss 0.3940 (0.4938)\tPrec@1 87.891 (84.085)\tPrec@5 98.828 (98.841)\n",
            "Epoch: [100][40/329], lr: 0.01000\tTime 0.101 (0.105)\tData 0.003 (0.020)\tLoss 0.2952 (0.4532)\tPrec@1 89.844 (85.299)\tPrec@5 98.828 (99.028)\n",
            "Epoch: [100][50/329], lr: 0.01000\tTime 0.093 (0.102)\tData 0.007 (0.018)\tLoss 0.2933 (0.4269)\tPrec@1 89.062 (86.037)\tPrec@5 100.000 (99.157)\n",
            "Epoch: [100][60/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.006 (0.016)\tLoss 0.2458 (0.4072)\tPrec@1 91.406 (86.776)\tPrec@5 100.000 (99.238)\n",
            "Epoch: [100][70/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.000 (0.015)\tLoss 0.3023 (0.3905)\tPrec@1 90.234 (87.302)\tPrec@5 100.000 (99.301)\n",
            "Epoch: [100][80/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.014)\tLoss 0.2833 (0.3791)\tPrec@1 92.578 (87.635)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [100][90/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.004 (0.013)\tLoss 0.2978 (0.3692)\tPrec@1 90.625 (88.019)\tPrec@5 99.219 (99.369)\n",
            "Epoch: [100][100/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.000 (0.013)\tLoss 0.2513 (0.3591)\tPrec@1 94.141 (88.328)\tPrec@5 99.609 (99.420)\n",
            "Epoch: [100][110/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.000 (0.012)\tLoss 0.2069 (0.3508)\tPrec@1 92.578 (88.573)\tPrec@5 100.000 (99.458)\n",
            "Epoch: [100][120/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.009 (0.012)\tLoss 0.2703 (0.3457)\tPrec@1 91.016 (88.659)\tPrec@5 100.000 (99.480)\n",
            "Epoch: [100][130/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.004 (0.011)\tLoss 0.2477 (0.3400)\tPrec@1 92.188 (88.827)\tPrec@5 99.609 (99.505)\n",
            "Epoch: [100][140/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.011)\tLoss 0.3131 (0.3338)\tPrec@1 89.062 (89.024)\tPrec@5 99.219 (99.526)\n",
            "Epoch: [100][150/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.005 (0.011)\tLoss 0.2339 (0.3279)\tPrec@1 93.359 (89.220)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [100][160/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.005 (0.010)\tLoss 0.3102 (0.3239)\tPrec@1 88.672 (89.363)\tPrec@5 99.609 (99.546)\n",
            "Epoch: [100][170/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.000 (0.010)\tLoss 0.2138 (0.3209)\tPrec@1 93.750 (89.467)\tPrec@5 99.609 (99.552)\n",
            "Epoch: [100][180/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.000 (0.010)\tLoss 0.3284 (0.3194)\tPrec@1 89.453 (89.524)\tPrec@5 99.609 (99.562)\n",
            "Epoch: [100][190/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 0.2949 (0.3168)\tPrec@1 91.016 (89.611)\tPrec@5 99.609 (99.573)\n",
            "Epoch: [100][200/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.006 (0.010)\tLoss 0.3091 (0.3146)\tPrec@1 88.672 (89.679)\tPrec@5 99.219 (99.576)\n",
            "Epoch: [100][210/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.000 (0.010)\tLoss 0.2552 (0.3118)\tPrec@1 90.625 (89.768)\tPrec@5 100.000 (99.583)\n",
            "Epoch: [100][220/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.000 (0.010)\tLoss 0.1962 (0.3099)\tPrec@1 93.359 (89.803)\tPrec@5 100.000 (99.586)\n",
            "Epoch: [100][230/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.000 (0.009)\tLoss 0.2921 (0.3094)\tPrec@1 89.453 (89.805)\tPrec@5 99.609 (99.587)\n",
            "Epoch: [100][240/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.000 (0.009)\tLoss 0.2427 (0.3074)\tPrec@1 93.359 (89.865)\tPrec@5 99.609 (99.592)\n",
            "Epoch: [100][250/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.000 (0.009)\tLoss 0.2530 (0.3065)\tPrec@1 91.797 (89.890)\tPrec@5 99.609 (99.595)\n",
            "Epoch: [100][260/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.006 (0.009)\tLoss 0.2384 (0.3051)\tPrec@1 92.969 (89.944)\tPrec@5 99.609 (99.600)\n",
            "Epoch: [100][270/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.007 (0.009)\tLoss 0.1797 (0.3032)\tPrec@1 93.359 (90.018)\tPrec@5 99.609 (99.604)\n",
            "Epoch: [100][280/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.012 (0.009)\tLoss 0.2291 (0.3020)\tPrec@1 92.188 (90.052)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [100][290/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.005 (0.009)\tLoss 0.2004 (0.3003)\tPrec@1 93.359 (90.110)\tPrec@5 99.219 (99.609)\n",
            "Epoch: [100][300/329], lr: 0.01000\tTime 0.111 (0.091)\tData 0.000 (0.009)\tLoss 0.2238 (0.2988)\tPrec@1 92.969 (90.167)\tPrec@5 100.000 (99.615)\n",
            "Epoch: [100][310/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.2639 (0.2972)\tPrec@1 91.016 (90.204)\tPrec@5 99.609 (99.617)\n",
            "Epoch: [100][320/329], lr: 0.01000\tTime 0.118 (0.091)\tData 0.086 (0.009)\tLoss 0.2807 (0.2967)\tPrec@1 88.672 (90.214)\tPrec@5 100.000 (99.619)\n",
            "Test: [0/100]\tTime 0.396 (0.396)\tLoss 1.1982 (1.1982)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.044 (0.057)\tLoss 1.1221 (1.3734)\tPrec@1 68.000 (61.636)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.010 (0.041)\tLoss 1.2421 (1.3728)\tPrec@1 64.000 (62.381)\tPrec@5 99.000 (97.048)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 1.2998 (1.3737)\tPrec@1 62.000 (62.710)\tPrec@5 97.000 (96.677)\n",
            "Test: [40/100]\tTime 0.024 (0.032)\tLoss 1.5298 (1.3695)\tPrec@1 63.000 (63.195)\tPrec@5 95.000 (96.512)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 1.4239 (1.3680)\tPrec@1 62.000 (63.275)\tPrec@5 97.000 (96.647)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 1.0952 (1.3653)\tPrec@1 67.000 (63.230)\tPrec@5 100.000 (96.705)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 1.3781 (1.3653)\tPrec@1 66.000 (63.310)\tPrec@5 98.000 (96.634)\n",
            "Test: [80/100]\tTime 0.044 (0.028)\tLoss 1.2466 (1.3582)\tPrec@1 68.000 (63.506)\tPrec@5 96.000 (96.617)\n",
            "Test: [90/100]\tTime 0.009 (0.028)\tLoss 1.2975 (1.3781)\tPrec@1 66.000 (63.066)\tPrec@5 97.000 (96.626)\n",
            "val Results: Prec@1 63.120 Prec@5 96.600 Loss 1.37799\n",
            "val Class Accuracy: [0.962,0.884,0.835,0.427,0.382,0.694,0.882,0.584,0.202,0.460]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [101][0/329], lr: 0.01000\tTime 0.710 (0.710)\tData 0.632 (0.632)\tLoss 0.2947 (0.2947)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][10/329], lr: 0.01000\tTime 0.094 (0.147)\tData 0.005 (0.065)\tLoss 0.5317 (0.6285)\tPrec@1 81.250 (79.865)\tPrec@5 99.219 (99.148)\n",
            "Epoch: [101][20/329], lr: 0.01000\tTime 0.120 (0.121)\tData 0.007 (0.037)\tLoss 0.5218 (0.5628)\tPrec@1 82.812 (81.399)\tPrec@5 99.219 (99.126)\n",
            "Epoch: [101][30/329], lr: 0.01000\tTime 0.098 (0.110)\tData 0.006 (0.028)\tLoss 0.4090 (0.5174)\tPrec@1 87.109 (82.863)\tPrec@5 99.219 (99.231)\n",
            "Epoch: [101][40/329], lr: 0.01000\tTime 0.071 (0.104)\tData 0.000 (0.022)\tLoss 0.3976 (0.4882)\tPrec@1 89.062 (84.022)\tPrec@5 99.219 (99.266)\n",
            "Epoch: [101][50/329], lr: 0.01000\tTime 0.095 (0.102)\tData 0.006 (0.020)\tLoss 0.2902 (0.4591)\tPrec@1 90.234 (85.026)\tPrec@5 99.609 (99.349)\n",
            "Epoch: [101][60/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.000 (0.017)\tLoss 0.4140 (0.4423)\tPrec@1 87.891 (85.681)\tPrec@5 99.219 (99.366)\n",
            "Epoch: [101][70/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.006 (0.016)\tLoss 0.2982 (0.4242)\tPrec@1 89.844 (86.229)\tPrec@5 99.219 (99.422)\n",
            "Epoch: [101][80/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.007 (0.015)\tLoss 0.3320 (0.4121)\tPrec@1 90.625 (86.589)\tPrec@5 98.438 (99.455)\n",
            "Epoch: [101][90/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.006 (0.014)\tLoss 0.2724 (0.3998)\tPrec@1 91.406 (86.985)\tPrec@5 99.609 (99.472)\n",
            "Epoch: [101][100/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.011 (0.013)\tLoss 0.3106 (0.3895)\tPrec@1 88.281 (87.272)\tPrec@5 99.609 (99.497)\n",
            "Epoch: [101][110/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.005 (0.013)\tLoss 0.2803 (0.3826)\tPrec@1 90.625 (87.507)\tPrec@5 100.000 (99.500)\n",
            "Epoch: [101][120/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.007 (0.012)\tLoss 0.3247 (0.3734)\tPrec@1 87.500 (87.823)\tPrec@5 100.000 (99.525)\n",
            "Epoch: [101][130/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.012)\tLoss 0.2732 (0.3667)\tPrec@1 91.797 (88.007)\tPrec@5 100.000 (99.553)\n",
            "Epoch: [101][140/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.003 (0.012)\tLoss 0.3443 (0.3606)\tPrec@1 90.234 (88.165)\tPrec@5 98.438 (99.537)\n",
            "Epoch: [101][150/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.011)\tLoss 0.2528 (0.3548)\tPrec@1 91.797 (88.330)\tPrec@5 99.609 (99.545)\n",
            "Epoch: [101][160/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.000 (0.011)\tLoss 0.2636 (0.3497)\tPrec@1 91.406 (88.524)\tPrec@5 99.609 (99.544)\n",
            "Epoch: [101][170/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.007 (0.011)\tLoss 0.2964 (0.3457)\tPrec@1 90.625 (88.640)\tPrec@5 99.609 (99.552)\n",
            "Epoch: [101][180/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.005 (0.011)\tLoss 0.2974 (0.3420)\tPrec@1 88.672 (88.737)\tPrec@5 99.609 (99.564)\n",
            "Epoch: [101][190/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.005 (0.010)\tLoss 0.2647 (0.3372)\tPrec@1 90.625 (88.885)\tPrec@5 98.828 (99.562)\n",
            "Epoch: [101][200/329], lr: 0.01000\tTime 0.069 (0.092)\tData 0.000 (0.010)\tLoss 0.2323 (0.3340)\tPrec@1 92.188 (88.975)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [101][210/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.007 (0.010)\tLoss 0.2712 (0.3315)\tPrec@1 90.234 (89.057)\tPrec@5 99.609 (99.569)\n",
            "Epoch: [101][220/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.000 (0.010)\tLoss 0.3203 (0.3277)\tPrec@1 90.234 (89.177)\tPrec@5 99.219 (99.578)\n",
            "Epoch: [101][230/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.007 (0.010)\tLoss 0.3630 (0.3254)\tPrec@1 88.672 (89.242)\tPrec@5 99.609 (99.584)\n",
            "Epoch: [101][240/329], lr: 0.01000\tTime 0.115 (0.091)\tData 0.007 (0.010)\tLoss 0.3590 (0.3234)\tPrec@1 90.234 (89.310)\tPrec@5 99.219 (99.592)\n",
            "Epoch: [101][250/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.000 (0.010)\tLoss 0.2624 (0.3213)\tPrec@1 89.844 (89.344)\tPrec@5 100.000 (99.592)\n",
            "Epoch: [101][260/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.000 (0.009)\tLoss 0.2657 (0.3185)\tPrec@1 91.016 (89.440)\tPrec@5 99.609 (99.602)\n",
            "Epoch: [101][270/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.000 (0.009)\tLoss 0.2835 (0.3166)\tPrec@1 88.672 (89.472)\tPrec@5 100.000 (99.606)\n",
            "Epoch: [101][280/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.006 (0.009)\tLoss 0.2081 (0.3137)\tPrec@1 93.750 (89.567)\tPrec@5 100.000 (99.616)\n",
            "Epoch: [101][290/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.011 (0.009)\tLoss 0.2461 (0.3120)\tPrec@1 91.406 (89.612)\tPrec@5 100.000 (99.620)\n",
            "Epoch: [101][300/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.005 (0.009)\tLoss 0.2696 (0.3100)\tPrec@1 92.969 (89.692)\tPrec@5 99.609 (99.618)\n",
            "Epoch: [101][310/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.007 (0.009)\tLoss 0.2377 (0.3083)\tPrec@1 92.969 (89.760)\tPrec@5 100.000 (99.622)\n",
            "Epoch: [101][320/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.050 (0.009)\tLoss 0.2826 (0.3072)\tPrec@1 90.234 (89.790)\tPrec@5 100.000 (99.620)\n",
            "Test: [0/100]\tTime 0.398 (0.398)\tLoss 0.6417 (0.6417)\tPrec@1 80.000 (80.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.025 (0.061)\tLoss 0.6538 (0.7579)\tPrec@1 79.000 (77.091)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.025 (0.043)\tLoss 0.7005 (0.7466)\tPrec@1 80.000 (77.429)\tPrec@5 100.000 (98.429)\n",
            "Test: [30/100]\tTime 0.018 (0.037)\tLoss 0.8491 (0.7733)\tPrec@1 72.000 (77.258)\tPrec@5 97.000 (98.161)\n",
            "Test: [40/100]\tTime 0.015 (0.034)\tLoss 0.8814 (0.7869)\tPrec@1 74.000 (77.000)\tPrec@5 99.000 (98.195)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 0.8782 (0.7821)\tPrec@1 78.000 (76.882)\tPrec@5 97.000 (98.176)\n",
            "Test: [60/100]\tTime 0.020 (0.031)\tLoss 0.7500 (0.7899)\tPrec@1 78.000 (76.492)\tPrec@5 99.000 (98.230)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 0.7525 (0.7862)\tPrec@1 82.000 (76.563)\tPrec@5 99.000 (98.197)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 0.7189 (0.7776)\tPrec@1 80.000 (76.753)\tPrec@5 99.000 (98.272)\n",
            "Test: [90/100]\tTime 0.031 (0.029)\tLoss 0.8522 (0.7905)\tPrec@1 78.000 (76.429)\tPrec@5 99.000 (98.308)\n",
            "val Results: Prec@1 76.330 Prec@5 98.300 Loss 0.79236\n",
            "val Class Accuracy: [0.927,0.944,0.889,0.556,0.818,0.793,0.801,0.644,0.670,0.591]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [102][0/329], lr: 0.01000\tTime 0.634 (0.634)\tData 0.553 (0.553)\tLoss 0.2664 (0.2664)\tPrec@1 91.406 (91.406)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [102][10/329], lr: 0.01000\tTime 0.102 (0.145)\tData 0.008 (0.058)\tLoss 0.2287 (0.2427)\tPrec@1 91.797 (92.010)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [102][20/329], lr: 0.01000\tTime 0.106 (0.122)\tData 0.000 (0.033)\tLoss 0.2668 (0.2344)\tPrec@1 91.406 (92.299)\tPrec@5 99.609 (99.758)\n",
            "Epoch: [102][30/329], lr: 0.01000\tTime 0.082 (0.112)\tData 0.005 (0.024)\tLoss 0.2622 (0.2399)\tPrec@1 90.234 (92.061)\tPrec@5 100.000 (99.735)\n",
            "Epoch: [102][40/329], lr: 0.01000\tTime 0.096 (0.108)\tData 0.007 (0.020)\tLoss 0.2369 (0.2367)\tPrec@1 91.797 (92.073)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [102][50/329], lr: 0.01000\tTime 0.080 (0.104)\tData 0.005 (0.017)\tLoss 0.2769 (0.2392)\tPrec@1 91.406 (92.065)\tPrec@5 99.219 (99.763)\n",
            "Epoch: [102][60/329], lr: 0.01000\tTime 0.090 (0.102)\tData 0.000 (0.015)\tLoss 0.2249 (0.2402)\tPrec@1 93.359 (92.111)\tPrec@5 100.000 (99.750)\n",
            "Epoch: [102][70/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.004 (0.014)\tLoss 0.2866 (0.2440)\tPrec@1 90.234 (91.984)\tPrec@5 100.000 (99.747)\n",
            "Epoch: [102][80/329], lr: 0.01000\tTime 0.068 (0.099)\tData 0.006 (0.014)\tLoss 0.2283 (0.2446)\tPrec@1 91.797 (91.913)\tPrec@5 99.609 (99.759)\n",
            "Epoch: [102][90/329], lr: 0.01000\tTime 0.103 (0.097)\tData 0.005 (0.013)\tLoss 0.3040 (0.2437)\tPrec@1 91.797 (91.939)\tPrec@5 99.609 (99.760)\n",
            "Epoch: [102][100/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.012)\tLoss 0.2239 (0.2450)\tPrec@1 91.406 (91.913)\tPrec@5 99.609 (99.756)\n",
            "Epoch: [102][110/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.007 (0.012)\tLoss 0.2167 (0.2451)\tPrec@1 91.797 (91.902)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [102][120/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.000 (0.012)\tLoss 0.2308 (0.2457)\tPrec@1 91.797 (91.874)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [102][130/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.011 (0.011)\tLoss 0.2889 (0.2467)\tPrec@1 90.625 (91.854)\tPrec@5 99.219 (99.732)\n",
            "Epoch: [102][140/329], lr: 0.01000\tTime 0.106 (0.094)\tData 0.003 (0.011)\tLoss 0.2627 (0.2468)\tPrec@1 90.234 (91.852)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [102][150/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.011)\tLoss 0.2592 (0.2469)\tPrec@1 94.141 (91.823)\tPrec@5 99.219 (99.739)\n",
            "Epoch: [102][160/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.000 (0.010)\tLoss 0.2385 (0.2478)\tPrec@1 91.016 (91.811)\tPrec@5 100.000 (99.738)\n",
            "Epoch: [102][170/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.007 (0.010)\tLoss 0.2295 (0.2483)\tPrec@1 91.406 (91.776)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [102][180/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.000 (0.010)\tLoss 0.2547 (0.2480)\tPrec@1 89.062 (91.788)\tPrec@5 99.609 (99.735)\n",
            "Epoch: [102][190/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.007 (0.010)\tLoss 0.2825 (0.2488)\tPrec@1 90.625 (91.758)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [102][200/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.000 (0.010)\tLoss 0.2368 (0.2484)\tPrec@1 92.969 (91.772)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [102][210/329], lr: 0.01000\tTime 0.113 (0.092)\tData 0.012 (0.010)\tLoss 0.2669 (0.2497)\tPrec@1 89.844 (91.725)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [102][220/329], lr: 0.01000\tTime 0.101 (0.092)\tData 0.000 (0.009)\tLoss 0.2517 (0.2495)\tPrec@1 91.797 (91.733)\tPrec@5 99.609 (99.745)\n",
            "Epoch: [102][230/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.007 (0.009)\tLoss 0.2099 (0.2494)\tPrec@1 93.750 (91.736)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [102][240/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.005 (0.009)\tLoss 0.2391 (0.2499)\tPrec@1 92.969 (91.747)\tPrec@5 100.000 (99.739)\n",
            "Epoch: [102][250/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.003 (0.009)\tLoss 0.1748 (0.2493)\tPrec@1 93.750 (91.758)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [102][260/329], lr: 0.01000\tTime 0.066 (0.091)\tData 0.000 (0.009)\tLoss 0.3186 (0.2493)\tPrec@1 88.672 (91.737)\tPrec@5 99.219 (99.743)\n",
            "Epoch: [102][270/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.005 (0.009)\tLoss 0.1776 (0.2487)\tPrec@1 94.531 (91.739)\tPrec@5 100.000 (99.746)\n",
            "Epoch: [102][280/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.006 (0.009)\tLoss 0.2108 (0.2491)\tPrec@1 92.969 (91.715)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [102][290/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.000 (0.009)\tLoss 0.3287 (0.2492)\tPrec@1 88.281 (91.704)\tPrec@5 99.609 (99.746)\n",
            "Epoch: [102][300/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.3337 (0.2500)\tPrec@1 89.062 (91.689)\tPrec@5 99.219 (99.743)\n",
            "Epoch: [102][310/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.000 (0.009)\tLoss 0.3033 (0.2500)\tPrec@1 89.062 (91.689)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [102][320/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.062 (0.009)\tLoss 0.1866 (0.2505)\tPrec@1 92.578 (91.669)\tPrec@5 100.000 (99.740)\n",
            "Test: [0/100]\tTime 0.322 (0.322)\tLoss 1.7448 (1.7448)\tPrec@1 60.000 (60.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.020 (0.058)\tLoss 1.5824 (1.8596)\tPrec@1 66.000 (56.636)\tPrec@5 97.000 (96.364)\n",
            "Test: [20/100]\tTime 0.036 (0.042)\tLoss 1.6544 (1.8555)\tPrec@1 58.000 (56.524)\tPrec@5 97.000 (96.000)\n",
            "Test: [30/100]\tTime 0.015 (0.033)\tLoss 1.7447 (1.8394)\tPrec@1 59.000 (57.032)\tPrec@5 95.000 (96.032)\n",
            "Test: [40/100]\tTime 0.028 (0.032)\tLoss 1.9858 (1.8428)\tPrec@1 56.000 (56.829)\tPrec@5 96.000 (96.195)\n",
            "Test: [50/100]\tTime 0.019 (0.031)\tLoss 1.8954 (1.8239)\tPrec@1 59.000 (57.118)\tPrec@5 96.000 (96.333)\n",
            "Test: [60/100]\tTime 0.024 (0.029)\tLoss 1.8434 (1.8344)\tPrec@1 61.000 (56.574)\tPrec@5 92.000 (96.246)\n",
            "Test: [70/100]\tTime 0.040 (0.029)\tLoss 2.0131 (1.8410)\tPrec@1 57.000 (56.465)\tPrec@5 97.000 (96.282)\n",
            "Test: [80/100]\tTime 0.034 (0.028)\tLoss 1.8745 (1.8443)\tPrec@1 55.000 (56.469)\tPrec@5 99.000 (96.383)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 2.1379 (1.8591)\tPrec@1 49.000 (56.022)\tPrec@5 99.000 (96.462)\n",
            "val Results: Prec@1 55.820 Prec@5 96.400 Loss 1.88086\n",
            "val Class Accuracy: [0.990,0.837,0.476,0.640,0.564,0.316,0.617,0.407,0.513,0.222]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [103][0/329], lr: 0.01000\tTime 0.670 (0.670)\tData 0.580 (0.580)\tLoss 0.4536 (0.4536)\tPrec@1 85.547 (85.547)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [103][10/329], lr: 0.01000\tTime 0.097 (0.148)\tData 0.000 (0.058)\tLoss 1.0850 (1.0477)\tPrec@1 61.328 (70.739)\tPrec@5 95.703 (96.378)\n",
            "Epoch: [103][20/329], lr: 0.01000\tTime 0.098 (0.120)\tData 0.005 (0.033)\tLoss 0.7404 (0.9225)\tPrec@1 75.000 (71.949)\tPrec@5 97.656 (97.135)\n",
            "Epoch: [103][30/329], lr: 0.01000\tTime 0.078 (0.111)\tData 0.005 (0.025)\tLoss 0.6056 (0.8272)\tPrec@1 79.688 (74.257)\tPrec@5 98.828 (97.631)\n",
            "Epoch: [103][40/329], lr: 0.01000\tTime 0.101 (0.106)\tData 0.005 (0.021)\tLoss 0.5266 (0.7630)\tPrec@1 80.469 (75.857)\tPrec@5 98.828 (97.866)\n",
            "Epoch: [103][50/329], lr: 0.01000\tTime 0.143 (0.104)\tData 0.000 (0.018)\tLoss 0.5170 (0.7104)\tPrec@1 82.031 (77.252)\tPrec@5 98.828 (98.162)\n",
            "Epoch: [103][60/329], lr: 0.01000\tTime 0.099 (0.105)\tData 0.001 (0.015)\tLoss 0.4710 (0.6696)\tPrec@1 83.594 (78.426)\tPrec@5 97.656 (98.322)\n",
            "Epoch: [103][70/329], lr: 0.01000\tTime 0.125 (0.107)\tData 0.000 (0.014)\tLoss 0.5151 (0.6322)\tPrec@1 80.078 (79.456)\tPrec@5 99.609 (98.493)\n",
            "Epoch: [103][80/329], lr: 0.01000\tTime 0.108 (0.108)\tData 0.009 (0.017)\tLoss 0.2663 (0.6003)\tPrec@1 92.969 (80.541)\tPrec@5 99.609 (98.621)\n",
            "Epoch: [103][90/329], lr: 0.01000\tTime 0.091 (0.107)\tData 0.000 (0.015)\tLoss 0.3730 (0.5745)\tPrec@1 84.766 (81.297)\tPrec@5 100.000 (98.738)\n",
            "Epoch: [103][100/329], lr: 0.01000\tTime 0.097 (0.106)\tData 0.003 (0.014)\tLoss 0.4319 (0.5561)\tPrec@1 84.375 (81.857)\tPrec@5 100.000 (98.805)\n",
            "Epoch: [103][110/329], lr: 0.01000\tTime 0.100 (0.105)\tData 0.010 (0.014)\tLoss 0.4240 (0.5383)\tPrec@1 85.547 (82.369)\tPrec@5 98.438 (98.860)\n",
            "Epoch: [103][120/329], lr: 0.01000\tTime 0.091 (0.103)\tData 0.008 (0.013)\tLoss 0.3965 (0.5234)\tPrec@1 86.719 (82.806)\tPrec@5 99.219 (98.902)\n",
            "Epoch: [103][130/329], lr: 0.01000\tTime 0.080 (0.102)\tData 0.002 (0.013)\tLoss 0.3793 (0.5105)\tPrec@1 88.672 (83.194)\tPrec@5 99.219 (98.947)\n",
            "Epoch: [103][140/329], lr: 0.01000\tTime 0.096 (0.101)\tData 0.001 (0.012)\tLoss 0.3761 (0.5012)\tPrec@1 86.328 (83.475)\tPrec@5 99.609 (98.989)\n",
            "Epoch: [103][150/329], lr: 0.01000\tTime 0.067 (0.100)\tData 0.000 (0.012)\tLoss 0.3437 (0.4897)\tPrec@1 87.500 (83.824)\tPrec@5 100.000 (99.035)\n",
            "Epoch: [103][160/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.007 (0.011)\tLoss 0.3595 (0.4817)\tPrec@1 89.453 (84.094)\tPrec@5 100.000 (99.056)\n",
            "Epoch: [103][170/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.012 (0.011)\tLoss 0.3596 (0.4729)\tPrec@1 86.328 (84.375)\tPrec@5 100.000 (99.091)\n",
            "Epoch: [103][180/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.000 (0.011)\tLoss 0.3735 (0.4653)\tPrec@1 90.234 (84.638)\tPrec@5 99.219 (99.115)\n",
            "Epoch: [103][190/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.005 (0.011)\tLoss 0.3199 (0.4581)\tPrec@1 89.062 (84.882)\tPrec@5 99.609 (99.145)\n",
            "Epoch: [103][200/329], lr: 0.01000\tTime 0.075 (0.098)\tData 0.000 (0.010)\tLoss 0.4203 (0.4512)\tPrec@1 86.328 (85.100)\tPrec@5 98.438 (99.149)\n",
            "Epoch: [103][210/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.009 (0.010)\tLoss 0.3197 (0.4456)\tPrec@1 89.844 (85.293)\tPrec@5 100.000 (99.171)\n",
            "Epoch: [103][220/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.010)\tLoss 0.2942 (0.4395)\tPrec@1 88.281 (85.508)\tPrec@5 100.000 (99.189)\n",
            "Epoch: [103][230/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.003 (0.010)\tLoss 0.3284 (0.4342)\tPrec@1 89.844 (85.679)\tPrec@5 99.609 (99.210)\n",
            "Epoch: [103][240/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.000 (0.010)\tLoss 0.3404 (0.4290)\tPrec@1 88.672 (85.850)\tPrec@5 98.828 (99.224)\n",
            "Epoch: [103][250/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.007 (0.010)\tLoss 0.3255 (0.4255)\tPrec@1 87.891 (85.972)\tPrec@5 99.609 (99.239)\n",
            "Epoch: [103][260/329], lr: 0.01000\tTime 0.066 (0.096)\tData 0.000 (0.010)\tLoss 0.2971 (0.4219)\tPrec@1 88.281 (86.063)\tPrec@5 100.000 (99.253)\n",
            "Epoch: [103][270/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.005 (0.010)\tLoss 0.3002 (0.4175)\tPrec@1 90.234 (86.210)\tPrec@5 99.609 (99.274)\n",
            "Epoch: [103][280/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.005 (0.010)\tLoss 0.3387 (0.4139)\tPrec@1 87.500 (86.295)\tPrec@5 100.000 (99.288)\n",
            "Epoch: [103][290/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.005 (0.010)\tLoss 0.3548 (0.4103)\tPrec@1 89.062 (86.390)\tPrec@5 99.609 (99.298)\n",
            "Epoch: [103][300/329], lr: 0.01000\tTime 0.076 (0.095)\tData 0.016 (0.010)\tLoss 0.2790 (0.4067)\tPrec@1 91.016 (86.509)\tPrec@5 99.219 (99.310)\n",
            "Epoch: [103][310/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.010)\tLoss 0.2817 (0.4025)\tPrec@1 88.672 (86.635)\tPrec@5 100.000 (99.320)\n",
            "Epoch: [103][320/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.058 (0.010)\tLoss 0.2953 (0.3990)\tPrec@1 88.281 (86.752)\tPrec@5 100.000 (99.337)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 1.4748 (1.4748)\tPrec@1 62.000 (62.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.031 (0.060)\tLoss 1.3473 (1.2330)\tPrec@1 72.000 (67.818)\tPrec@5 92.000 (96.000)\n",
            "Test: [20/100]\tTime 0.037 (0.044)\tLoss 1.0020 (1.2968)\tPrec@1 76.000 (66.238)\tPrec@5 97.000 (96.000)\n",
            "Test: [30/100]\tTime 0.026 (0.038)\tLoss 1.4044 (1.3048)\tPrec@1 64.000 (65.903)\tPrec@5 95.000 (96.129)\n",
            "Test: [40/100]\tTime 0.037 (0.034)\tLoss 1.3909 (1.3014)\tPrec@1 65.000 (65.927)\tPrec@5 98.000 (96.146)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 1.2522 (1.2935)\tPrec@1 65.000 (65.902)\tPrec@5 97.000 (96.216)\n",
            "Test: [60/100]\tTime 0.045 (0.031)\tLoss 1.4998 (1.3216)\tPrec@1 64.000 (65.311)\tPrec@5 98.000 (96.164)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 1.4759 (1.3156)\tPrec@1 63.000 (65.282)\tPrec@5 99.000 (96.225)\n",
            "Test: [80/100]\tTime 0.009 (0.030)\tLoss 1.1034 (1.3079)\tPrec@1 68.000 (65.370)\tPrec@5 97.000 (96.296)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 0.9980 (1.3201)\tPrec@1 68.000 (64.978)\tPrec@5 96.000 (96.187)\n",
            "val Results: Prec@1 64.890 Prec@5 96.100 Loss 1.32231\n",
            "val Class Accuracy: [0.977,0.859,0.536,0.551,0.465,0.680,0.354,0.665,0.638,0.764]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [104][0/329], lr: 0.01000\tTime 0.666 (0.666)\tData 0.593 (0.593)\tLoss 0.3604 (0.3604)\tPrec@1 87.109 (87.109)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [104][10/329], lr: 0.01000\tTime 0.099 (0.147)\tData 0.000 (0.060)\tLoss 0.7673 (0.6162)\tPrec@1 74.219 (80.114)\tPrec@5 98.047 (98.686)\n",
            "Epoch: [104][20/329], lr: 0.01000\tTime 0.082 (0.123)\tData 0.000 (0.035)\tLoss 0.5102 (0.5665)\tPrec@1 82.422 (81.231)\tPrec@5 99.219 (98.865)\n",
            "Epoch: [104][30/329], lr: 0.01000\tTime 0.088 (0.111)\tData 0.007 (0.026)\tLoss 0.4196 (0.5255)\tPrec@1 85.938 (82.472)\tPrec@5 100.000 (98.992)\n",
            "Epoch: [104][40/329], lr: 0.01000\tTime 0.091 (0.105)\tData 0.001 (0.022)\tLoss 0.3874 (0.4919)\tPrec@1 86.328 (83.632)\tPrec@5 99.609 (99.076)\n",
            "Epoch: [104][50/329], lr: 0.01000\tTime 0.099 (0.102)\tData 0.000 (0.019)\tLoss 0.3253 (0.4661)\tPrec@1 89.844 (84.513)\tPrec@5 98.828 (99.150)\n",
            "Epoch: [104][60/329], lr: 0.01000\tTime 0.099 (0.100)\tData 0.000 (0.017)\tLoss 0.3188 (0.4388)\tPrec@1 89.844 (85.355)\tPrec@5 100.000 (99.244)\n",
            "Epoch: [104][70/329], lr: 0.01000\tTime 0.107 (0.098)\tData 0.005 (0.016)\tLoss 0.3428 (0.4207)\tPrec@1 89.844 (85.976)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [104][80/329], lr: 0.01000\tTime 0.123 (0.097)\tData 0.006 (0.014)\tLoss 0.3386 (0.4067)\tPrec@1 89.844 (86.526)\tPrec@5 99.219 (99.320)\n",
            "Epoch: [104][90/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.007 (0.014)\tLoss 0.2995 (0.3974)\tPrec@1 90.234 (86.762)\tPrec@5 99.609 (99.330)\n",
            "Epoch: [104][100/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.000 (0.013)\tLoss 0.2607 (0.3874)\tPrec@1 92.578 (87.136)\tPrec@5 100.000 (99.373)\n",
            "Epoch: [104][110/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.001 (0.012)\tLoss 0.3119 (0.3797)\tPrec@1 88.281 (87.380)\tPrec@5 99.609 (99.402)\n",
            "Epoch: [104][120/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.003 (0.012)\tLoss 0.2952 (0.3720)\tPrec@1 91.016 (87.626)\tPrec@5 99.609 (99.416)\n",
            "Epoch: [104][130/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.005 (0.012)\tLoss 0.2030 (0.3673)\tPrec@1 93.359 (87.759)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [104][140/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.004 (0.011)\tLoss 0.2965 (0.3653)\tPrec@1 89.453 (87.863)\tPrec@5 99.609 (99.449)\n",
            "Epoch: [104][150/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.003 (0.011)\tLoss 0.2172 (0.3595)\tPrec@1 91.406 (88.054)\tPrec@5 100.000 (99.467)\n",
            "Epoch: [104][160/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.000 (0.011)\tLoss 0.2767 (0.3552)\tPrec@1 91.797 (88.201)\tPrec@5 99.609 (99.486)\n",
            "Epoch: [104][170/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.011)\tLoss 0.3311 (0.3513)\tPrec@1 87.500 (88.322)\tPrec@5 98.828 (99.484)\n",
            "Epoch: [104][180/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.011)\tLoss 0.2418 (0.3483)\tPrec@1 91.406 (88.422)\tPrec@5 100.000 (99.493)\n",
            "Epoch: [104][190/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.000 (0.010)\tLoss 0.3087 (0.3452)\tPrec@1 89.062 (88.527)\tPrec@5 99.609 (99.507)\n",
            "Epoch: [104][200/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.006 (0.010)\tLoss 0.2584 (0.3421)\tPrec@1 91.016 (88.635)\tPrec@5 100.000 (99.522)\n",
            "Epoch: [104][210/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.000 (0.010)\tLoss 0.3848 (0.3393)\tPrec@1 87.500 (88.739)\tPrec@5 99.609 (99.526)\n",
            "Epoch: [104][220/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.010)\tLoss 0.2650 (0.3369)\tPrec@1 89.844 (88.790)\tPrec@5 100.000 (99.533)\n",
            "Epoch: [104][230/329], lr: 0.01000\tTime 0.112 (0.092)\tData 0.000 (0.010)\tLoss 0.3457 (0.3361)\tPrec@1 90.234 (88.799)\tPrec@5 100.000 (99.542)\n",
            "Epoch: [104][240/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.000 (0.010)\tLoss 0.3051 (0.3339)\tPrec@1 89.844 (88.863)\tPrec@5 98.828 (99.545)\n",
            "Epoch: [104][250/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.009)\tLoss 0.3335 (0.3319)\tPrec@1 87.891 (88.950)\tPrec@5 99.609 (99.538)\n",
            "Epoch: [104][260/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.009)\tLoss 0.3318 (0.3288)\tPrec@1 89.844 (89.036)\tPrec@5 99.609 (99.550)\n",
            "Epoch: [104][270/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.012 (0.009)\tLoss 0.3027 (0.3259)\tPrec@1 89.844 (89.142)\tPrec@5 100.000 (99.556)\n",
            "Epoch: [104][280/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.000 (0.009)\tLoss 0.3088 (0.3240)\tPrec@1 91.797 (89.213)\tPrec@5 99.219 (99.557)\n",
            "Epoch: [104][290/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.006 (0.009)\tLoss 0.3394 (0.3229)\tPrec@1 88.672 (89.269)\tPrec@5 99.609 (99.561)\n",
            "Epoch: [104][300/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.008 (0.009)\tLoss 0.3078 (0.3219)\tPrec@1 90.625 (89.305)\tPrec@5 99.219 (99.557)\n",
            "Epoch: [104][310/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.005 (0.009)\tLoss 0.3240 (0.3210)\tPrec@1 87.891 (89.319)\tPrec@5 99.219 (99.564)\n",
            "Epoch: [104][320/329], lr: 0.01000\tTime 0.127 (0.091)\tData 0.085 (0.009)\tLoss 0.2030 (0.3199)\tPrec@1 94.141 (89.355)\tPrec@5 100.000 (99.570)\n",
            "Test: [0/100]\tTime 0.418 (0.418)\tLoss 2.2204 (2.2204)\tPrec@1 45.000 (45.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.030 (0.058)\tLoss 1.9519 (2.2620)\tPrec@1 55.000 (49.636)\tPrec@5 92.000 (86.545)\n",
            "Test: [20/100]\tTime 0.019 (0.042)\tLoss 1.8057 (2.2509)\tPrec@1 49.000 (49.190)\tPrec@5 94.000 (86.952)\n",
            "Test: [30/100]\tTime 0.022 (0.037)\tLoss 1.9764 (2.2276)\tPrec@1 51.000 (49.774)\tPrec@5 85.000 (86.677)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 2.0596 (2.2258)\tPrec@1 53.000 (49.902)\tPrec@5 84.000 (86.488)\n",
            "Test: [50/100]\tTime 0.034 (0.032)\tLoss 1.9642 (2.2281)\tPrec@1 54.000 (50.176)\tPrec@5 88.000 (86.510)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 1.8114 (2.2169)\tPrec@1 59.000 (49.984)\tPrec@5 90.000 (86.672)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 2.1327 (2.2233)\tPrec@1 52.000 (49.944)\tPrec@5 87.000 (86.704)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 2.0295 (2.2146)\tPrec@1 57.000 (50.136)\tPrec@5 87.000 (86.889)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 2.0775 (2.2324)\tPrec@1 56.000 (49.813)\tPrec@5 88.000 (86.769)\n",
            "val Results: Prec@1 49.670 Prec@5 86.700 Loss 2.24586\n",
            "val Class Accuracy: [0.873,0.484,0.881,0.342,0.643,0.295,0.615,0.746,0.058,0.030]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [105][0/329], lr: 0.01000\tTime 0.686 (0.686)\tData 0.598 (0.598)\tLoss 0.5518 (0.5518)\tPrec@1 79.297 (79.297)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][10/329], lr: 0.01000\tTime 0.112 (0.152)\tData 0.010 (0.061)\tLoss 0.8882 (1.1251)\tPrec@1 71.094 (64.418)\tPrec@5 98.047 (95.455)\n",
            "Epoch: [105][20/329], lr: 0.01000\tTime 0.079 (0.124)\tData 0.001 (0.035)\tLoss 0.8977 (1.0419)\tPrec@1 71.484 (66.518)\tPrec@5 94.922 (95.945)\n",
            "Epoch: [105][30/329], lr: 0.01000\tTime 0.091 (0.114)\tData 0.007 (0.026)\tLoss 0.6867 (0.9516)\tPrec@1 73.828 (69.027)\tPrec@5 98.828 (96.560)\n",
            "Epoch: [105][40/329], lr: 0.01000\tTime 0.102 (0.108)\tData 0.012 (0.022)\tLoss 0.6590 (0.8886)\tPrec@1 78.906 (70.884)\tPrec@5 98.828 (97.008)\n",
            "Epoch: [105][50/329], lr: 0.01000\tTime 0.103 (0.104)\tData 0.006 (0.020)\tLoss 0.6010 (0.8356)\tPrec@1 81.250 (72.549)\tPrec@5 98.828 (97.327)\n",
            "Epoch: [105][60/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.004 (0.017)\tLoss 0.4835 (0.7946)\tPrec@1 85.547 (73.860)\tPrec@5 99.219 (97.535)\n",
            "Epoch: [105][70/329], lr: 0.01000\tTime 0.077 (0.100)\tData 0.005 (0.016)\tLoss 0.5345 (0.7596)\tPrec@1 81.641 (74.983)\tPrec@5 99.219 (97.777)\n",
            "Epoch: [105][80/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.008 (0.015)\tLoss 0.4264 (0.7300)\tPrec@1 85.156 (75.916)\tPrec@5 99.609 (97.907)\n",
            "Epoch: [105][90/329], lr: 0.01000\tTime 0.108 (0.097)\tData 0.011 (0.014)\tLoss 0.5121 (0.7015)\tPrec@1 82.812 (76.820)\tPrec@5 99.609 (98.055)\n",
            "Epoch: [105][100/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.000 (0.013)\tLoss 0.4531 (0.6772)\tPrec@1 84.375 (77.642)\tPrec@5 99.219 (98.190)\n",
            "Epoch: [105][110/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.000 (0.013)\tLoss 0.4056 (0.6588)\tPrec@1 86.719 (78.188)\tPrec@5 99.609 (98.262)\n",
            "Epoch: [105][120/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.012)\tLoss 0.4166 (0.6408)\tPrec@1 86.719 (78.771)\tPrec@5 99.219 (98.344)\n",
            "Epoch: [105][130/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.006 (0.012)\tLoss 0.4756 (0.6247)\tPrec@1 83.984 (79.321)\tPrec@5 99.219 (98.423)\n",
            "Epoch: [105][140/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.012)\tLoss 0.5805 (0.6119)\tPrec@1 80.078 (79.732)\tPrec@5 99.219 (98.479)\n",
            "Epoch: [105][150/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.000 (0.011)\tLoss 0.4234 (0.6019)\tPrec@1 87.500 (80.104)\tPrec@5 98.438 (98.518)\n",
            "Epoch: [105][160/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.000 (0.011)\tLoss 0.4544 (0.5926)\tPrec@1 84.375 (80.398)\tPrec@5 99.609 (98.556)\n",
            "Epoch: [105][170/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.000 (0.011)\tLoss 0.3701 (0.5806)\tPrec@1 87.109 (80.793)\tPrec@5 100.000 (98.623)\n",
            "Epoch: [105][180/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.006 (0.011)\tLoss 0.3908 (0.5708)\tPrec@1 86.719 (81.080)\tPrec@5 99.609 (98.651)\n",
            "Epoch: [105][190/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.006 (0.010)\tLoss 0.3506 (0.5617)\tPrec@1 87.109 (81.344)\tPrec@5 99.609 (98.683)\n",
            "Epoch: [105][200/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.006 (0.010)\tLoss 0.4353 (0.5537)\tPrec@1 87.109 (81.608)\tPrec@5 99.609 (98.715)\n",
            "Epoch: [105][210/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.005 (0.010)\tLoss 0.4074 (0.5432)\tPrec@1 87.500 (81.963)\tPrec@5 99.609 (98.754)\n",
            "Epoch: [105][220/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.010)\tLoss 0.3653 (0.5361)\tPrec@1 89.453 (82.201)\tPrec@5 100.000 (98.793)\n",
            "Epoch: [105][230/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.005 (0.010)\tLoss 0.3257 (0.5278)\tPrec@1 90.234 (82.462)\tPrec@5 99.609 (98.820)\n",
            "Epoch: [105][240/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.010)\tLoss 0.3910 (0.5210)\tPrec@1 86.719 (82.722)\tPrec@5 99.219 (98.843)\n",
            "Epoch: [105][250/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.010)\tLoss 0.3180 (0.5141)\tPrec@1 88.281 (82.911)\tPrec@5 100.000 (98.876)\n",
            "Epoch: [105][260/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.006 (0.010)\tLoss 0.3529 (0.5086)\tPrec@1 89.453 (83.122)\tPrec@5 99.219 (98.901)\n",
            "Epoch: [105][270/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.005 (0.010)\tLoss 0.3676 (0.5027)\tPrec@1 86.719 (83.304)\tPrec@5 100.000 (98.929)\n",
            "Epoch: [105][280/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.002 (0.009)\tLoss 0.3368 (0.4969)\tPrec@1 87.891 (83.485)\tPrec@5 100.000 (98.956)\n",
            "Epoch: [105][290/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.4088 (0.4928)\tPrec@1 85.938 (83.599)\tPrec@5 99.219 (98.970)\n",
            "Epoch: [105][300/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.4053 (0.4880)\tPrec@1 86.328 (83.773)\tPrec@5 98.828 (98.988)\n",
            "Epoch: [105][310/329], lr: 0.01000\tTime 0.065 (0.092)\tData 0.006 (0.009)\tLoss 0.3730 (0.4840)\tPrec@1 88.281 (83.917)\tPrec@5 100.000 (99.004)\n",
            "Epoch: [105][320/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.036 (0.009)\tLoss 0.4218 (0.4793)\tPrec@1 87.109 (84.084)\tPrec@5 98.438 (99.018)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 0.9427 (0.9427)\tPrec@1 71.000 (71.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.8770 (0.9716)\tPrec@1 74.000 (69.818)\tPrec@5 100.000 (98.000)\n",
            "Test: [20/100]\tTime 0.029 (0.042)\tLoss 0.9858 (0.9605)\tPrec@1 67.000 (70.667)\tPrec@5 100.000 (97.667)\n",
            "Test: [30/100]\tTime 0.031 (0.037)\tLoss 1.0707 (0.9744)\tPrec@1 71.000 (70.774)\tPrec@5 99.000 (97.806)\n",
            "Test: [40/100]\tTime 0.020 (0.033)\tLoss 1.0417 (0.9915)\tPrec@1 69.000 (70.146)\tPrec@5 97.000 (97.732)\n",
            "Test: [50/100]\tTime 0.019 (0.031)\tLoss 1.1184 (0.9859)\tPrec@1 67.000 (69.980)\tPrec@5 97.000 (97.745)\n",
            "Test: [60/100]\tTime 0.041 (0.030)\tLoss 0.9396 (0.9947)\tPrec@1 72.000 (69.803)\tPrec@5 97.000 (97.803)\n",
            "Test: [70/100]\tTime 0.037 (0.029)\tLoss 0.9559 (0.9818)\tPrec@1 71.000 (69.930)\tPrec@5 99.000 (97.887)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.0163 (0.9778)\tPrec@1 70.000 (69.951)\tPrec@5 97.000 (97.963)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 0.9175 (0.9826)\tPrec@1 67.000 (69.791)\tPrec@5 99.000 (97.989)\n",
            "val Results: Prec@1 69.850 Prec@5 97.960 Loss 0.97971\n",
            "val Class Accuracy: [0.887,0.933,0.675,0.857,0.890,0.447,0.578,0.397,0.630,0.691]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [106][0/329], lr: 0.01000\tTime 0.691 (0.691)\tData 0.609 (0.609)\tLoss 0.3380 (0.3380)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [106][10/329], lr: 0.01000\tTime 0.070 (0.148)\tData 0.003 (0.062)\tLoss 0.3534 (0.3131)\tPrec@1 90.234 (90.376)\tPrec@5 99.219 (99.538)\n",
            "Epoch: [106][20/329], lr: 0.01000\tTime 0.115 (0.122)\tData 0.005 (0.035)\tLoss 0.3289 (0.3096)\tPrec@1 89.844 (90.420)\tPrec@5 100.000 (99.572)\n",
            "Epoch: [106][30/329], lr: 0.01000\tTime 0.093 (0.111)\tData 0.000 (0.026)\tLoss 0.3866 (0.3110)\tPrec@1 87.109 (89.995)\tPrec@5 99.609 (99.559)\n",
            "Epoch: [106][40/329], lr: 0.01000\tTime 0.088 (0.106)\tData 0.007 (0.021)\tLoss 0.4425 (0.3129)\tPrec@1 85.547 (89.768)\tPrec@5 99.219 (99.581)\n",
            "Epoch: [106][50/329], lr: 0.01000\tTime 0.075 (0.103)\tData 0.000 (0.018)\tLoss 0.3622 (0.3136)\tPrec@1 89.453 (89.737)\tPrec@5 99.219 (99.609)\n",
            "Epoch: [106][60/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.008 (0.017)\tLoss 0.2917 (0.3134)\tPrec@1 91.016 (89.703)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [106][70/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.005 (0.015)\tLoss 0.2650 (0.3164)\tPrec@1 89.844 (89.574)\tPrec@5 99.609 (99.549)\n",
            "Epoch: [106][80/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.010 (0.014)\tLoss 0.3409 (0.3200)\tPrec@1 88.281 (89.434)\tPrec@5 98.828 (99.552)\n",
            "Epoch: [106][90/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.000 (0.014)\tLoss 0.3141 (0.3185)\tPrec@1 89.844 (89.436)\tPrec@5 100.000 (99.549)\n",
            "Epoch: [106][100/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.013)\tLoss 0.2833 (0.3162)\tPrec@1 91.797 (89.488)\tPrec@5 99.609 (99.575)\n",
            "Epoch: [106][110/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.000 (0.012)\tLoss 0.3687 (0.3156)\tPrec@1 85.938 (89.527)\tPrec@5 98.828 (99.578)\n",
            "Epoch: [106][120/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.004 (0.012)\tLoss 0.2672 (0.3146)\tPrec@1 90.625 (89.553)\tPrec@5 100.000 (99.587)\n",
            "Epoch: [106][130/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.005 (0.011)\tLoss 0.2290 (0.3140)\tPrec@1 91.797 (89.519)\tPrec@5 100.000 (99.580)\n",
            "Epoch: [106][140/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.011)\tLoss 0.3204 (0.3124)\tPrec@1 90.625 (89.575)\tPrec@5 99.609 (99.596)\n",
            "Epoch: [106][150/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.011)\tLoss 0.3304 (0.3120)\tPrec@1 87.891 (89.577)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [106][160/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.016 (0.011)\tLoss 0.4190 (0.3115)\tPrec@1 87.891 (89.613)\tPrec@5 99.219 (99.588)\n",
            "Epoch: [106][170/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.010 (0.011)\tLoss 0.3259 (0.3113)\tPrec@1 90.234 (89.606)\tPrec@5 99.609 (99.582)\n",
            "Epoch: [106][180/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.010)\tLoss 0.3676 (0.3098)\tPrec@1 87.109 (89.639)\tPrec@5 99.609 (99.594)\n",
            "Epoch: [106][190/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.001 (0.010)\tLoss 0.3460 (0.3106)\tPrec@1 87.891 (89.647)\tPrec@5 99.609 (99.589)\n",
            "Epoch: [106][200/329], lr: 0.01000\tTime 0.073 (0.092)\tData 0.000 (0.010)\tLoss 0.3030 (0.3096)\tPrec@1 88.672 (89.696)\tPrec@5 99.609 (99.592)\n",
            "Epoch: [106][210/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.004 (0.010)\tLoss 0.2578 (0.3098)\tPrec@1 91.406 (89.696)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [106][220/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.000 (0.010)\tLoss 0.2658 (0.3093)\tPrec@1 90.625 (89.715)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [106][230/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.000 (0.010)\tLoss 0.2550 (0.3095)\tPrec@1 90.625 (89.717)\tPrec@5 100.000 (99.584)\n",
            "Epoch: [106][240/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.000 (0.010)\tLoss 0.3309 (0.3098)\tPrec@1 87.109 (89.690)\tPrec@5 98.828 (99.585)\n",
            "Epoch: [106][250/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.006 (0.010)\tLoss 0.2843 (0.3091)\tPrec@1 92.188 (89.710)\tPrec@5 100.000 (99.588)\n",
            "Epoch: [106][260/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 0.2414 (0.3095)\tPrec@1 92.578 (89.678)\tPrec@5 98.828 (99.579)\n",
            "Epoch: [106][270/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.000 (0.009)\tLoss 0.2366 (0.3089)\tPrec@1 91.406 (89.691)\tPrec@5 100.000 (99.582)\n",
            "Epoch: [106][280/329], lr: 0.01000\tTime 0.061 (0.091)\tData 0.006 (0.009)\tLoss 0.2623 (0.3085)\tPrec@1 91.406 (89.708)\tPrec@5 99.609 (99.587)\n",
            "Epoch: [106][290/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.007 (0.009)\tLoss 0.2512 (0.3081)\tPrec@1 92.188 (89.734)\tPrec@5 100.000 (99.587)\n",
            "Epoch: [106][300/329], lr: 0.01000\tTime 0.097 (0.091)\tData 0.005 (0.009)\tLoss 0.3095 (0.3071)\tPrec@1 87.500 (89.754)\tPrec@5 100.000 (99.592)\n",
            "Epoch: [106][310/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.000 (0.009)\tLoss 0.2540 (0.3067)\tPrec@1 92.578 (89.786)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [106][320/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.054 (0.009)\tLoss 0.3254 (0.3064)\tPrec@1 89.062 (89.788)\tPrec@5 100.000 (99.598)\n",
            "Test: [0/100]\tTime 0.403 (0.403)\tLoss 0.7717 (0.7717)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.034 (0.060)\tLoss 0.8584 (0.9192)\tPrec@1 76.000 (72.091)\tPrec@5 98.000 (97.818)\n",
            "Test: [20/100]\tTime 0.020 (0.043)\tLoss 0.7038 (0.8938)\tPrec@1 75.000 (72.143)\tPrec@5 100.000 (97.619)\n",
            "Test: [30/100]\tTime 0.010 (0.037)\tLoss 1.0706 (0.8979)\tPrec@1 66.000 (71.903)\tPrec@5 96.000 (97.613)\n",
            "Test: [40/100]\tTime 0.028 (0.034)\tLoss 0.9764 (0.9089)\tPrec@1 74.000 (71.829)\tPrec@5 96.000 (97.561)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 0.8186 (0.9021)\tPrec@1 71.000 (71.804)\tPrec@5 98.000 (97.608)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 0.7945 (0.9050)\tPrec@1 79.000 (71.885)\tPrec@5 100.000 (97.672)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 1.0532 (0.9003)\tPrec@1 70.000 (71.901)\tPrec@5 96.000 (97.746)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 0.8270 (0.8939)\tPrec@1 75.000 (72.099)\tPrec@5 96.000 (97.778)\n",
            "Test: [90/100]\tTime 0.016 (0.029)\tLoss 0.8597 (0.9056)\tPrec@1 76.000 (71.769)\tPrec@5 98.000 (97.725)\n",
            "val Results: Prec@1 71.620 Prec@5 97.720 Loss 0.90678\n",
            "val Class Accuracy: [0.928,0.946,0.677,0.478,0.754,0.876,0.629,0.659,0.439,0.776]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [107][0/329], lr: 0.01000\tTime 0.652 (0.652)\tData 0.563 (0.563)\tLoss 0.3904 (0.3904)\tPrec@1 89.453 (89.453)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [107][10/329], lr: 0.01000\tTime 0.075 (0.150)\tData 0.006 (0.058)\tLoss 0.6191 (0.6797)\tPrec@1 76.562 (77.734)\tPrec@5 98.438 (97.727)\n",
            "Epoch: [107][20/329], lr: 0.01000\tTime 0.129 (0.124)\tData 0.008 (0.033)\tLoss 0.5808 (0.6246)\tPrec@1 82.031 (79.315)\tPrec@5 98.438 (98.344)\n",
            "Epoch: [107][30/329], lr: 0.01000\tTime 0.089 (0.112)\tData 0.000 (0.024)\tLoss 0.4796 (0.5771)\tPrec@1 83.203 (81.036)\tPrec@5 98.828 (98.677)\n",
            "Epoch: [107][40/329], lr: 0.01000\tTime 0.104 (0.108)\tData 0.000 (0.020)\tLoss 0.3230 (0.5319)\tPrec@1 87.500 (82.460)\tPrec@5 99.609 (98.885)\n",
            "Epoch: [107][50/329], lr: 0.01000\tTime 0.096 (0.104)\tData 0.010 (0.018)\tLoss 0.3286 (0.5021)\tPrec@1 89.453 (83.364)\tPrec@5 100.000 (99.035)\n",
            "Epoch: [107][60/329], lr: 0.01000\tTime 0.087 (0.101)\tData 0.009 (0.016)\tLoss 0.3709 (0.4781)\tPrec@1 87.500 (84.208)\tPrec@5 99.609 (99.135)\n",
            "Epoch: [107][70/329], lr: 0.01000\tTime 0.099 (0.100)\tData 0.006 (0.015)\tLoss 0.2873 (0.4569)\tPrec@1 89.844 (84.887)\tPrec@5 99.609 (99.219)\n",
            "Epoch: [107][80/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.016 (0.014)\tLoss 0.3705 (0.4399)\tPrec@1 88.672 (85.532)\tPrec@5 99.219 (99.238)\n",
            "Epoch: [107][90/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.006 (0.014)\tLoss 0.3498 (0.4250)\tPrec@1 89.062 (86.010)\tPrec@5 100.000 (99.292)\n",
            "Epoch: [107][100/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.007 (0.013)\tLoss 0.3186 (0.4122)\tPrec@1 88.672 (86.398)\tPrec@5 99.609 (99.312)\n",
            "Epoch: [107][110/329], lr: 0.01000\tTime 0.097 (0.096)\tData 0.000 (0.012)\tLoss 0.2783 (0.4013)\tPrec@1 89.453 (86.747)\tPrec@5 99.609 (99.338)\n",
            "Epoch: [107][120/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.008 (0.012)\tLoss 0.2743 (0.3910)\tPrec@1 91.016 (87.077)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [107][130/329], lr: 0.01000\tTime 0.113 (0.099)\tData 0.000 (0.011)\tLoss 0.4742 (0.3844)\tPrec@1 85.547 (87.300)\tPrec@5 99.219 (99.389)\n",
            "Epoch: [107][140/329], lr: 0.01000\tTime 0.146 (0.100)\tData 0.072 (0.012)\tLoss 0.2510 (0.3769)\tPrec@1 93.359 (87.533)\tPrec@5 99.609 (99.418)\n",
            "Epoch: [107][150/329], lr: 0.01000\tTime 0.093 (0.100)\tData 0.004 (0.012)\tLoss 0.3205 (0.3729)\tPrec@1 90.625 (87.645)\tPrec@5 99.609 (99.439)\n",
            "Epoch: [107][160/329], lr: 0.01000\tTime 0.075 (0.100)\tData 0.001 (0.011)\tLoss 0.2932 (0.3685)\tPrec@1 92.188 (87.767)\tPrec@5 99.219 (99.440)\n",
            "Epoch: [107][170/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.006 (0.011)\tLoss 0.2303 (0.3638)\tPrec@1 91.016 (87.920)\tPrec@5 100.000 (99.445)\n",
            "Epoch: [107][180/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.000 (0.011)\tLoss 0.2190 (0.3605)\tPrec@1 93.750 (88.031)\tPrec@5 99.609 (99.445)\n",
            "Epoch: [107][190/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.000 (0.011)\tLoss 0.2641 (0.3567)\tPrec@1 92.578 (88.138)\tPrec@5 99.609 (99.448)\n",
            "Epoch: [107][200/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.010)\tLoss 0.3071 (0.3542)\tPrec@1 88.281 (88.262)\tPrec@5 100.000 (99.458)\n",
            "Epoch: [107][210/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.008 (0.010)\tLoss 0.2225 (0.3497)\tPrec@1 93.359 (88.403)\tPrec@5 100.000 (99.472)\n",
            "Epoch: [107][220/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.000 (0.010)\tLoss 0.2411 (0.3462)\tPrec@1 92.188 (88.523)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [107][230/329], lr: 0.01000\tTime 0.103 (0.097)\tData 0.005 (0.010)\tLoss 0.2232 (0.3424)\tPrec@1 92.578 (88.662)\tPrec@5 100.000 (99.491)\n",
            "Epoch: [107][240/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.006 (0.010)\tLoss 0.1996 (0.3399)\tPrec@1 92.578 (88.729)\tPrec@5 100.000 (99.501)\n",
            "Epoch: [107][250/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.000 (0.010)\tLoss 0.2661 (0.3373)\tPrec@1 91.797 (88.813)\tPrec@5 99.219 (99.505)\n",
            "Epoch: [107][260/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.000 (0.010)\tLoss 0.3169 (0.3358)\tPrec@1 87.891 (88.835)\tPrec@5 99.609 (99.506)\n",
            "Epoch: [107][270/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.000 (0.010)\tLoss 0.3131 (0.3339)\tPrec@1 88.672 (88.907)\tPrec@5 100.000 (99.510)\n",
            "Epoch: [107][280/329], lr: 0.01000\tTime 0.121 (0.095)\tData 0.007 (0.009)\tLoss 0.2517 (0.3315)\tPrec@1 91.406 (89.000)\tPrec@5 100.000 (99.519)\n",
            "Epoch: [107][290/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.006 (0.009)\tLoss 0.3636 (0.3299)\tPrec@1 87.891 (89.058)\tPrec@5 100.000 (99.523)\n",
            "Epoch: [107][300/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.006 (0.009)\tLoss 0.2703 (0.3277)\tPrec@1 91.406 (89.121)\tPrec@5 99.609 (99.532)\n",
            "Epoch: [107][310/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.007 (0.009)\tLoss 0.3002 (0.3265)\tPrec@1 91.797 (89.172)\tPrec@5 99.609 (99.537)\n",
            "Epoch: [107][320/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.057 (0.009)\tLoss 0.2176 (0.3249)\tPrec@1 91.016 (89.204)\tPrec@5 100.000 (99.542)\n",
            "Test: [0/100]\tTime 0.411 (0.411)\tLoss 0.7034 (0.7034)\tPrec@1 77.000 (77.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.013 (0.058)\tLoss 0.8364 (0.9323)\tPrec@1 79.000 (70.636)\tPrec@5 99.000 (98.727)\n",
            "Test: [20/100]\tTime 0.030 (0.042)\tLoss 0.7932 (0.9064)\tPrec@1 76.000 (72.762)\tPrec@5 100.000 (98.429)\n",
            "Test: [30/100]\tTime 0.049 (0.037)\tLoss 1.0223 (0.9204)\tPrec@1 70.000 (72.387)\tPrec@5 97.000 (98.226)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 0.9355 (0.9350)\tPrec@1 72.000 (71.659)\tPrec@5 98.000 (98.195)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 0.9860 (0.9186)\tPrec@1 75.000 (72.176)\tPrec@5 97.000 (98.137)\n",
            "Test: [60/100]\tTime 0.036 (0.031)\tLoss 0.8375 (0.9183)\tPrec@1 79.000 (72.197)\tPrec@5 100.000 (98.246)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 0.9646 (0.9096)\tPrec@1 73.000 (72.394)\tPrec@5 99.000 (98.282)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 0.9362 (0.9083)\tPrec@1 73.000 (72.556)\tPrec@5 99.000 (98.333)\n",
            "Test: [90/100]\tTime 0.013 (0.028)\tLoss 1.0481 (0.9196)\tPrec@1 68.000 (72.275)\tPrec@5 99.000 (98.319)\n",
            "val Results: Prec@1 72.160 Prec@5 98.290 Loss 0.92150\n",
            "val Class Accuracy: [0.880,0.986,0.659,0.700,0.810,0.860,0.582,0.525,0.659,0.555]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [108][0/329], lr: 0.01000\tTime 0.636 (0.636)\tData 0.565 (0.565)\tLoss 0.2889 (0.2889)\tPrec@1 91.016 (91.016)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [108][10/329], lr: 0.01000\tTime 0.110 (0.143)\tData 0.000 (0.056)\tLoss 0.2348 (0.2612)\tPrec@1 92.578 (91.513)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [108][20/329], lr: 0.01000\tTime 0.088 (0.121)\tData 0.004 (0.032)\tLoss 0.2543 (0.2706)\tPrec@1 90.625 (91.443)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [108][30/329], lr: 0.01000\tTime 0.080 (0.111)\tData 0.000 (0.025)\tLoss 0.3051 (0.2641)\tPrec@1 91.406 (91.507)\tPrec@5 98.828 (99.761)\n",
            "Epoch: [108][40/329], lr: 0.01000\tTime 0.084 (0.106)\tData 0.005 (0.021)\tLoss 0.1842 (0.2601)\tPrec@1 94.141 (91.683)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [108][50/329], lr: 0.01000\tTime 0.092 (0.103)\tData 0.012 (0.018)\tLoss 0.3221 (0.2626)\tPrec@1 89.062 (91.460)\tPrec@5 99.219 (99.709)\n",
            "Epoch: [108][60/329], lr: 0.01000\tTime 0.092 (0.102)\tData 0.000 (0.016)\tLoss 0.2390 (0.2633)\tPrec@1 93.359 (91.509)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [108][70/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.007 (0.015)\tLoss 0.1794 (0.2648)\tPrec@1 93.359 (91.439)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [108][80/329], lr: 0.01000\tTime 0.059 (0.098)\tData 0.000 (0.014)\tLoss 0.2831 (0.2644)\tPrec@1 89.453 (91.348)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [108][90/329], lr: 0.01000\tTime 0.071 (0.097)\tData 0.000 (0.013)\tLoss 0.3012 (0.2671)\tPrec@1 88.672 (91.170)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [108][100/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.000 (0.013)\tLoss 0.3377 (0.2690)\tPrec@1 87.500 (91.089)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [108][110/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.012)\tLoss 0.3058 (0.2693)\tPrec@1 89.844 (91.086)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [108][120/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.007 (0.011)\tLoss 0.2584 (0.2699)\tPrec@1 92.969 (91.038)\tPrec@5 99.219 (99.748)\n",
            "Epoch: [108][130/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.000 (0.011)\tLoss 0.2157 (0.2678)\tPrec@1 93.750 (91.078)\tPrec@5 99.609 (99.744)\n",
            "Epoch: [108][140/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.006 (0.011)\tLoss 0.2562 (0.2685)\tPrec@1 92.578 (91.113)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [108][150/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.004 (0.010)\tLoss 0.3195 (0.2695)\tPrec@1 88.672 (91.109)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [108][160/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.010)\tLoss 0.3108 (0.2705)\tPrec@1 89.453 (91.037)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [108][170/329], lr: 0.01000\tTime 0.113 (0.093)\tData 0.006 (0.010)\tLoss 0.2515 (0.2704)\tPrec@1 91.016 (91.052)\tPrec@5 99.609 (99.719)\n",
            "Epoch: [108][180/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.000 (0.010)\tLoss 0.3197 (0.2697)\tPrec@1 90.625 (91.078)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [108][190/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.012 (0.009)\tLoss 0.2519 (0.2686)\tPrec@1 92.188 (91.104)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [108][200/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.010 (0.009)\tLoss 0.2612 (0.2674)\tPrec@1 91.016 (91.134)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [108][210/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.009)\tLoss 0.2856 (0.2668)\tPrec@1 90.234 (91.147)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [108][220/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.005 (0.009)\tLoss 0.2734 (0.2660)\tPrec@1 90.234 (91.141)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [108][230/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.004 (0.009)\tLoss 0.3850 (0.2673)\tPrec@1 88.281 (91.097)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [108][240/329], lr: 0.01000\tTime 0.058 (0.092)\tData 0.000 (0.009)\tLoss 0.3014 (0.2676)\tPrec@1 89.844 (91.092)\tPrec@5 99.219 (99.721)\n",
            "Epoch: [108][250/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.005 (0.009)\tLoss 0.2961 (0.2685)\tPrec@1 90.234 (91.073)\tPrec@5 98.828 (99.711)\n",
            "Epoch: [108][260/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.005 (0.009)\tLoss 0.2275 (0.2684)\tPrec@1 91.797 (91.070)\tPrec@5 99.609 (99.716)\n",
            "Epoch: [108][270/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.007 (0.009)\tLoss 0.3005 (0.2677)\tPrec@1 90.234 (91.079)\tPrec@5 99.609 (99.717)\n",
            "Epoch: [108][280/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.005 (0.009)\tLoss 0.2940 (0.2676)\tPrec@1 90.234 (91.102)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [108][290/329], lr: 0.01000\tTime 0.106 (0.092)\tData 0.006 (0.009)\tLoss 0.2765 (0.2677)\tPrec@1 91.016 (91.095)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [108][300/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.000 (0.009)\tLoss 0.2342 (0.2678)\tPrec@1 91.406 (91.070)\tPrec@5 100.000 (99.713)\n",
            "Epoch: [108][310/329], lr: 0.01000\tTime 0.071 (0.091)\tData 0.010 (0.009)\tLoss 0.1954 (0.2682)\tPrec@1 92.578 (91.050)\tPrec@5 99.609 (99.707)\n",
            "Epoch: [108][320/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.057 (0.009)\tLoss 0.3530 (0.2682)\tPrec@1 89.844 (91.053)\tPrec@5 98.438 (99.709)\n",
            "Test: [0/100]\tTime 0.402 (0.402)\tLoss 2.3810 (2.3810)\tPrec@1 49.000 (49.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.012 (0.057)\tLoss 1.8231 (2.2484)\tPrec@1 56.000 (50.273)\tPrec@5 96.000 (92.818)\n",
            "Test: [20/100]\tTime 0.024 (0.042)\tLoss 1.8825 (2.2434)\tPrec@1 60.000 (51.286)\tPrec@5 92.000 (92.810)\n",
            "Test: [30/100]\tTime 0.009 (0.035)\tLoss 2.1803 (2.2117)\tPrec@1 51.000 (51.516)\tPrec@5 94.000 (92.774)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 2.3118 (2.2163)\tPrec@1 50.000 (51.585)\tPrec@5 89.000 (92.634)\n",
            "Test: [50/100]\tTime 0.020 (0.031)\tLoss 2.1546 (2.2086)\tPrec@1 55.000 (51.412)\tPrec@5 92.000 (92.608)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 2.0987 (2.2231)\tPrec@1 47.000 (51.033)\tPrec@5 93.000 (92.230)\n",
            "Test: [70/100]\tTime 0.009 (0.029)\tLoss 2.1773 (2.2252)\tPrec@1 55.000 (51.197)\tPrec@5 91.000 (92.169)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.9425 (2.2236)\tPrec@1 52.000 (51.210)\tPrec@5 93.000 (92.370)\n",
            "Test: [90/100]\tTime 0.036 (0.028)\tLoss 2.2616 (2.2334)\tPrec@1 46.000 (51.000)\tPrec@5 97.000 (92.341)\n",
            "val Results: Prec@1 51.100 Prec@5 92.360 Loss 2.23209\n",
            "val Class Accuracy: [0.777,0.998,0.501,0.055,0.381,0.437,0.784,0.427,0.601,0.149]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [109][0/329], lr: 0.01000\tTime 0.567 (0.567)\tData 0.486 (0.486)\tLoss 0.3995 (0.3995)\tPrec@1 86.328 (86.328)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [109][10/329], lr: 0.01000\tTime 0.104 (0.137)\tData 0.001 (0.049)\tLoss 0.7534 (0.9674)\tPrec@1 71.875 (70.632)\tPrec@5 98.047 (97.834)\n",
            "Epoch: [109][20/329], lr: 0.01000\tTime 0.104 (0.118)\tData 0.001 (0.033)\tLoss 0.6144 (0.8044)\tPrec@1 79.297 (74.833)\tPrec@5 98.438 (97.898)\n",
            "Epoch: [109][30/329], lr: 0.01000\tTime 0.088 (0.111)\tData 0.001 (0.025)\tLoss 0.4463 (0.7185)\tPrec@1 85.938 (77.180)\tPrec@5 99.609 (98.198)\n",
            "Epoch: [109][40/329], lr: 0.01000\tTime 0.074 (0.107)\tData 0.006 (0.021)\tLoss 0.5569 (0.6572)\tPrec@1 81.250 (78.878)\tPrec@5 99.609 (98.495)\n",
            "Epoch: [109][50/329], lr: 0.01000\tTime 0.093 (0.104)\tData 0.002 (0.018)\tLoss 0.4044 (0.6100)\tPrec@1 85.547 (80.377)\tPrec@5 99.609 (98.644)\n",
            "Epoch: [109][60/329], lr: 0.01000\tTime 0.088 (0.102)\tData 0.007 (0.016)\tLoss 0.3725 (0.5679)\tPrec@1 90.234 (81.673)\tPrec@5 99.609 (98.803)\n",
            "Epoch: [109][70/329], lr: 0.01000\tTime 0.061 (0.100)\tData 0.002 (0.015)\tLoss 0.2565 (0.5366)\tPrec@1 92.969 (82.702)\tPrec@5 99.609 (98.911)\n",
            "Epoch: [109][80/329], lr: 0.01000\tTime 0.070 (0.098)\tData 0.005 (0.014)\tLoss 0.3602 (0.5133)\tPrec@1 89.062 (83.391)\tPrec@5 99.609 (98.992)\n",
            "Epoch: [109][90/329], lr: 0.01000\tTime 0.071 (0.097)\tData 0.003 (0.014)\tLoss 0.2939 (0.4939)\tPrec@1 90.234 (84.027)\tPrec@5 100.000 (99.030)\n",
            "Epoch: [109][100/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.000 (0.013)\tLoss 0.4056 (0.4764)\tPrec@1 85.547 (84.537)\tPrec@5 98.438 (99.080)\n",
            "Epoch: [109][110/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.013)\tLoss 0.3949 (0.4655)\tPrec@1 88.281 (84.889)\tPrec@5 98.438 (99.106)\n",
            "Epoch: [109][120/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.010 (0.012)\tLoss 0.2961 (0.4531)\tPrec@1 88.672 (85.218)\tPrec@5 100.000 (99.161)\n",
            "Epoch: [109][130/329], lr: 0.01000\tTime 0.069 (0.095)\tData 0.000 (0.012)\tLoss 0.3113 (0.4448)\tPrec@1 89.062 (85.484)\tPrec@5 100.000 (99.192)\n",
            "Epoch: [109][140/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.007 (0.012)\tLoss 0.4100 (0.4362)\tPrec@1 87.500 (85.755)\tPrec@5 99.219 (99.208)\n",
            "Epoch: [109][150/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.007 (0.011)\tLoss 0.2892 (0.4275)\tPrec@1 91.016 (86.018)\tPrec@5 100.000 (99.229)\n",
            "Epoch: [109][160/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.003 (0.011)\tLoss 0.3275 (0.4198)\tPrec@1 88.672 (86.280)\tPrec@5 98.438 (99.255)\n",
            "Epoch: [109][170/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.009 (0.011)\tLoss 0.2093 (0.4099)\tPrec@1 93.750 (86.593)\tPrec@5 100.000 (99.276)\n",
            "Epoch: [109][180/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.000 (0.011)\tLoss 0.3577 (0.4038)\tPrec@1 89.062 (86.775)\tPrec@5 99.609 (99.296)\n",
            "Epoch: [109][190/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.011)\tLoss 0.4092 (0.3986)\tPrec@1 89.453 (86.946)\tPrec@5 98.828 (99.307)\n",
            "Epoch: [109][200/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.011)\tLoss 0.3260 (0.3933)\tPrec@1 91.016 (87.121)\tPrec@5 99.609 (99.326)\n",
            "Epoch: [109][210/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.3362 (0.3889)\tPrec@1 89.062 (87.245)\tPrec@5 99.609 (99.343)\n",
            "Epoch: [109][220/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.000 (0.010)\tLoss 0.2949 (0.3843)\tPrec@1 89.453 (87.357)\tPrec@5 99.609 (99.358)\n",
            "Epoch: [109][230/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.007 (0.010)\tLoss 0.3912 (0.3806)\tPrec@1 87.891 (87.485)\tPrec@5 99.609 (99.371)\n",
            "Epoch: [109][240/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.2925 (0.3765)\tPrec@1 90.234 (87.623)\tPrec@5 99.609 (99.384)\n",
            "Epoch: [109][250/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.006 (0.010)\tLoss 0.3037 (0.3732)\tPrec@1 89.062 (87.710)\tPrec@5 99.609 (99.388)\n",
            "Epoch: [109][260/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.006 (0.010)\tLoss 0.2808 (0.3699)\tPrec@1 91.016 (87.801)\tPrec@5 100.000 (99.406)\n",
            "Epoch: [109][270/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.007 (0.010)\tLoss 0.3061 (0.3670)\tPrec@1 90.234 (87.883)\tPrec@5 100.000 (99.412)\n",
            "Epoch: [109][280/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.007 (0.010)\tLoss 0.2679 (0.3642)\tPrec@1 92.188 (87.984)\tPrec@5 99.219 (99.412)\n",
            "Epoch: [109][290/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.001 (0.010)\tLoss 0.3027 (0.3624)\tPrec@1 92.188 (88.049)\tPrec@5 100.000 (99.409)\n",
            "Epoch: [109][300/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.000 (0.010)\tLoss 0.2424 (0.3596)\tPrec@1 91.406 (88.146)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [109][310/329], lr: 0.01000\tTime 0.069 (0.091)\tData 0.000 (0.009)\tLoss 0.2489 (0.3569)\tPrec@1 90.625 (88.235)\tPrec@5 100.000 (99.430)\n",
            "Epoch: [109][320/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.049 (0.009)\tLoss 0.2396 (0.3543)\tPrec@1 90.625 (88.314)\tPrec@5 99.609 (99.435)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 0.9289 (0.9289)\tPrec@1 71.000 (71.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.010 (0.060)\tLoss 0.8631 (0.9589)\tPrec@1 76.000 (71.545)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.020 (0.039)\tLoss 0.7463 (0.9515)\tPrec@1 75.000 (71.429)\tPrec@5 99.000 (98.333)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.0427 (0.9672)\tPrec@1 69.000 (71.516)\tPrec@5 99.000 (98.097)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 0.9847 (0.9700)\tPrec@1 74.000 (71.805)\tPrec@5 99.000 (98.000)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 1.0733 (0.9616)\tPrec@1 73.000 (72.020)\tPrec@5 95.000 (97.980)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 0.9509 (0.9646)\tPrec@1 69.000 (71.525)\tPrec@5 97.000 (98.000)\n",
            "Test: [70/100]\tTime 0.033 (0.029)\tLoss 1.0272 (0.9607)\tPrec@1 70.000 (71.521)\tPrec@5 99.000 (98.056)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 0.8132 (0.9494)\tPrec@1 79.000 (71.852)\tPrec@5 97.000 (98.025)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 0.7054 (0.9583)\tPrec@1 77.000 (71.516)\tPrec@5 100.000 (98.033)\n",
            "val Results: Prec@1 71.620 Prec@5 98.060 Loss 0.96008\n",
            "val Class Accuracy: [0.963,0.941,0.855,0.757,0.780,0.490,0.622,0.633,0.612,0.509]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [110][0/329], lr: 0.01000\tTime 0.618 (0.618)\tData 0.509 (0.509)\tLoss 0.2871 (0.2871)\tPrec@1 90.234 (90.234)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [110][10/329], lr: 0.01000\tTime 0.101 (0.145)\tData 0.000 (0.050)\tLoss 0.3321 (0.2930)\tPrec@1 90.625 (90.128)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [110][20/329], lr: 0.01000\tTime 0.086 (0.119)\tData 0.000 (0.029)\tLoss 0.3195 (0.2907)\tPrec@1 88.672 (90.011)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [110][30/329], lr: 0.01000\tTime 0.082 (0.109)\tData 0.000 (0.022)\tLoss 0.3077 (0.2930)\tPrec@1 89.062 (89.932)\tPrec@5 99.609 (99.559)\n",
            "Epoch: [110][40/329], lr: 0.01000\tTime 0.087 (0.104)\tData 0.000 (0.019)\tLoss 0.2863 (0.2893)\tPrec@1 92.578 (90.034)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [110][50/329], lr: 0.01000\tTime 0.079 (0.100)\tData 0.006 (0.016)\tLoss 0.2379 (0.2849)\tPrec@1 91.797 (90.265)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [110][60/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.010 (0.015)\tLoss 0.2562 (0.2765)\tPrec@1 93.359 (90.516)\tPrec@5 99.609 (99.654)\n",
            "Epoch: [110][70/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.000 (0.014)\tLoss 0.2358 (0.2762)\tPrec@1 93.359 (90.592)\tPrec@5 99.609 (99.653)\n",
            "Epoch: [110][80/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.006 (0.013)\tLoss 0.2614 (0.2740)\tPrec@1 92.188 (90.586)\tPrec@5 100.000 (99.662)\n",
            "Epoch: [110][90/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.012)\tLoss 0.2315 (0.2713)\tPrec@1 92.188 (90.758)\tPrec@5 100.000 (99.669)\n",
            "Epoch: [110][100/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.004 (0.012)\tLoss 0.3159 (0.2709)\tPrec@1 88.281 (90.764)\tPrec@5 100.000 (99.671)\n",
            "Epoch: [110][110/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.000 (0.011)\tLoss 0.3589 (0.2701)\tPrec@1 87.500 (90.822)\tPrec@5 100.000 (99.669)\n",
            "Epoch: [110][120/329], lr: 0.01000\tTime 0.069 (0.093)\tData 0.000 (0.011)\tLoss 0.2702 (0.2707)\tPrec@1 91.016 (90.790)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [110][130/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.007 (0.011)\tLoss 0.2352 (0.2710)\tPrec@1 91.406 (90.810)\tPrec@5 100.000 (99.675)\n",
            "Epoch: [110][140/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.2889 (0.2708)\tPrec@1 87.891 (90.800)\tPrec@5 99.609 (99.673)\n",
            "Epoch: [110][150/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.010)\tLoss 0.2753 (0.2682)\tPrec@1 90.234 (90.930)\tPrec@5 100.000 (99.677)\n",
            "Epoch: [110][160/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.009 (0.010)\tLoss 0.2235 (0.2675)\tPrec@1 92.188 (90.999)\tPrec@5 100.000 (99.680)\n",
            "Epoch: [110][170/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.002 (0.010)\tLoss 0.2479 (0.2665)\tPrec@1 92.188 (91.045)\tPrec@5 100.000 (99.689)\n",
            "Epoch: [110][180/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.013 (0.010)\tLoss 0.2999 (0.2674)\tPrec@1 89.844 (91.033)\tPrec@5 100.000 (99.700)\n",
            "Epoch: [110][190/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.000 (0.010)\tLoss 0.2725 (0.2665)\tPrec@1 93.750 (91.054)\tPrec@5 99.609 (99.708)\n",
            "Epoch: [110][200/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.005 (0.010)\tLoss 0.2973 (0.2660)\tPrec@1 90.625 (91.072)\tPrec@5 99.609 (99.703)\n",
            "Epoch: [110][210/329], lr: 0.01000\tTime 0.067 (0.091)\tData 0.000 (0.010)\tLoss 0.2336 (0.2659)\tPrec@1 92.969 (91.067)\tPrec@5 99.609 (99.707)\n",
            "Epoch: [110][220/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.009 (0.010)\tLoss 0.2282 (0.2651)\tPrec@1 94.141 (91.081)\tPrec@5 99.219 (99.705)\n",
            "Epoch: [110][230/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.000 (0.009)\tLoss 0.2729 (0.2659)\tPrec@1 90.234 (91.060)\tPrec@5 100.000 (99.704)\n",
            "Epoch: [110][240/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.003 (0.009)\tLoss 0.3736 (0.2662)\tPrec@1 89.062 (91.089)\tPrec@5 100.000 (99.708)\n",
            "Epoch: [110][250/329], lr: 0.01000\tTime 0.105 (0.090)\tData 0.004 (0.009)\tLoss 0.2848 (0.2656)\tPrec@1 91.406 (91.111)\tPrec@5 99.219 (99.707)\n",
            "Epoch: [110][260/329], lr: 0.01000\tTime 0.082 (0.090)\tData 0.007 (0.009)\tLoss 0.3194 (0.2657)\tPrec@1 88.672 (91.098)\tPrec@5 100.000 (99.708)\n",
            "Epoch: [110][270/329], lr: 0.01000\tTime 0.090 (0.090)\tData 0.006 (0.009)\tLoss 0.2345 (0.2651)\tPrec@1 91.797 (91.131)\tPrec@5 100.000 (99.707)\n",
            "Epoch: [110][280/329], lr: 0.01000\tTime 0.103 (0.090)\tData 0.007 (0.009)\tLoss 0.2450 (0.2654)\tPrec@1 89.844 (91.106)\tPrec@5 100.000 (99.711)\n",
            "Epoch: [110][290/329], lr: 0.01000\tTime 0.082 (0.090)\tData 0.008 (0.009)\tLoss 0.2873 (0.2661)\tPrec@1 90.625 (91.076)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [110][300/329], lr: 0.01000\tTime 0.096 (0.090)\tData 0.007 (0.009)\tLoss 0.2743 (0.2662)\tPrec@1 92.188 (91.066)\tPrec@5 99.609 (99.713)\n",
            "Epoch: [110][310/329], lr: 0.01000\tTime 0.102 (0.090)\tData 0.006 (0.009)\tLoss 0.2754 (0.2666)\tPrec@1 91.406 (91.051)\tPrec@5 99.609 (99.711)\n",
            "Epoch: [110][320/329], lr: 0.01000\tTime 0.101 (0.090)\tData 0.058 (0.009)\tLoss 0.2329 (0.2662)\tPrec@1 92.188 (91.064)\tPrec@5 100.000 (99.716)\n",
            "Test: [0/100]\tTime 0.406 (0.406)\tLoss 0.7708 (0.7708)\tPrec@1 78.000 (78.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.027 (0.058)\tLoss 0.7250 (0.8344)\tPrec@1 80.000 (74.727)\tPrec@5 98.000 (98.000)\n",
            "Test: [20/100]\tTime 0.020 (0.043)\tLoss 0.6175 (0.8029)\tPrec@1 77.000 (75.524)\tPrec@5 100.000 (98.000)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 0.9658 (0.8304)\tPrec@1 71.000 (74.871)\tPrec@5 97.000 (97.645)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 0.9161 (0.8348)\tPrec@1 73.000 (74.707)\tPrec@5 97.000 (97.634)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 0.7840 (0.8224)\tPrec@1 77.000 (74.784)\tPrec@5 97.000 (97.765)\n",
            "Test: [60/100]\tTime 0.036 (0.031)\tLoss 0.8622 (0.8371)\tPrec@1 75.000 (74.393)\tPrec@5 98.000 (97.918)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 0.8529 (0.8266)\tPrec@1 74.000 (74.648)\tPrec@5 98.000 (98.000)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 0.8168 (0.8213)\tPrec@1 77.000 (74.790)\tPrec@5 98.000 (98.037)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 0.7151 (0.8273)\tPrec@1 72.000 (74.604)\tPrec@5 99.000 (98.055)\n",
            "val Results: Prec@1 74.550 Prec@5 98.000 Loss 0.82986\n",
            "val Class Accuracy: [0.931,0.940,0.753,0.864,0.790,0.603,0.824,0.568,0.631,0.551]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [111][0/329], lr: 0.01000\tTime 0.634 (0.634)\tData 0.548 (0.548)\tLoss 0.1993 (0.1993)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][10/329], lr: 0.01000\tTime 0.100 (0.141)\tData 0.000 (0.055)\tLoss 0.2582 (0.2348)\tPrec@1 89.844 (91.939)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [111][20/329], lr: 0.01000\tTime 0.094 (0.118)\tData 0.000 (0.030)\tLoss 0.2250 (0.2397)\tPrec@1 92.188 (91.667)\tPrec@5 99.609 (99.777)\n",
            "Epoch: [111][30/329], lr: 0.01000\tTime 0.083 (0.110)\tData 0.000 (0.022)\tLoss 0.2211 (0.2436)\tPrec@1 91.797 (91.595)\tPrec@5 98.828 (99.735)\n",
            "Epoch: [111][40/329], lr: 0.01000\tTime 0.090 (0.105)\tData 0.004 (0.018)\tLoss 0.1535 (0.2392)\tPrec@1 94.531 (91.730)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [111][50/329], lr: 0.01000\tTime 0.098 (0.103)\tData 0.000 (0.016)\tLoss 0.1446 (0.2382)\tPrec@1 96.094 (91.766)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [111][60/329], lr: 0.01000\tTime 0.094 (0.100)\tData 0.007 (0.014)\tLoss 0.2733 (0.2442)\tPrec@1 92.188 (91.682)\tPrec@5 99.219 (99.744)\n",
            "Epoch: [111][70/329], lr: 0.01000\tTime 0.108 (0.099)\tData 0.005 (0.013)\tLoss 0.2587 (0.2443)\tPrec@1 89.453 (91.588)\tPrec@5 99.219 (99.708)\n",
            "Epoch: [111][80/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.000 (0.012)\tLoss 0.3843 (0.2459)\tPrec@1 89.453 (91.594)\tPrec@5 99.219 (99.701)\n",
            "Epoch: [111][90/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.010 (0.012)\tLoss 0.4034 (0.2486)\tPrec@1 84.375 (91.514)\tPrec@5 100.000 (99.708)\n",
            "Epoch: [111][100/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.004 (0.011)\tLoss 0.2832 (0.2459)\tPrec@1 91.016 (91.696)\tPrec@5 100.000 (99.725)\n",
            "Epoch: [111][110/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.005 (0.011)\tLoss 0.2066 (0.2468)\tPrec@1 93.750 (91.681)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [111][120/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.000 (0.010)\tLoss 0.2015 (0.2464)\tPrec@1 93.359 (91.710)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [111][130/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.000 (0.010)\tLoss 0.1783 (0.2461)\tPrec@1 94.922 (91.719)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [111][140/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.004 (0.010)\tLoss 0.2748 (0.2475)\tPrec@1 91.016 (91.650)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [111][150/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.007 (0.010)\tLoss 0.2198 (0.2488)\tPrec@1 92.188 (91.577)\tPrec@5 100.000 (99.726)\n",
            "Epoch: [111][160/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.000 (0.010)\tLoss 0.2282 (0.2490)\tPrec@1 92.969 (91.593)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [111][170/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.008 (0.009)\tLoss 0.2019 (0.2488)\tPrec@1 94.141 (91.582)\tPrec@5 99.609 (99.724)\n",
            "Epoch: [111][180/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.000 (0.009)\tLoss 0.2287 (0.2490)\tPrec@1 89.844 (91.570)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [111][190/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.000 (0.009)\tLoss 0.2713 (0.2501)\tPrec@1 91.016 (91.525)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [111][200/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.000 (0.009)\tLoss 0.2870 (0.2505)\tPrec@1 91.016 (91.517)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [111][210/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.000 (0.009)\tLoss 0.2840 (0.2518)\tPrec@1 91.797 (91.464)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [111][220/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.005 (0.009)\tLoss 0.2700 (0.2520)\tPrec@1 89.844 (91.456)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [111][230/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.004 (0.009)\tLoss 0.1740 (0.2516)\tPrec@1 93.750 (91.472)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [111][240/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.011 (0.008)\tLoss 0.3047 (0.2518)\tPrec@1 90.234 (91.481)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [111][250/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.016 (0.008)\tLoss 0.2822 (0.2523)\tPrec@1 92.969 (91.472)\tPrec@5 98.828 (99.737)\n",
            "Epoch: [111][260/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.008 (0.008)\tLoss 0.2412 (0.2525)\tPrec@1 92.578 (91.466)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [111][270/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.009 (0.008)\tLoss 0.2822 (0.2528)\tPrec@1 91.797 (91.468)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [111][280/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.000 (0.008)\tLoss 0.2321 (0.2529)\tPrec@1 91.797 (91.449)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [111][290/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.007 (0.008)\tLoss 0.1838 (0.2525)\tPrec@1 93.359 (91.442)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [111][300/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.005 (0.008)\tLoss 0.3730 (0.2535)\tPrec@1 86.328 (91.402)\tPrec@5 99.219 (99.744)\n",
            "Epoch: [111][310/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.013 (0.008)\tLoss 0.2538 (0.2540)\tPrec@1 91.797 (91.399)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [111][320/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.076 (0.009)\tLoss 0.2150 (0.2542)\tPrec@1 92.188 (91.412)\tPrec@5 99.609 (99.744)\n",
            "Test: [0/100]\tTime 0.394 (0.394)\tLoss 0.8547 (0.8547)\tPrec@1 72.000 (72.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.029 (0.057)\tLoss 0.7114 (1.0455)\tPrec@1 74.000 (68.545)\tPrec@5 99.000 (97.727)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 0.8588 (1.0409)\tPrec@1 71.000 (69.238)\tPrec@5 100.000 (97.714)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.3486 (1.0634)\tPrec@1 61.000 (69.129)\tPrec@5 96.000 (97.484)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 1.2546 (1.0579)\tPrec@1 72.000 (69.390)\tPrec@5 95.000 (97.561)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 1.0199 (1.0472)\tPrec@1 72.000 (69.686)\tPrec@5 97.000 (97.588)\n",
            "Test: [60/100]\tTime 0.038 (0.030)\tLoss 0.8893 (1.0533)\tPrec@1 70.000 (69.656)\tPrec@5 99.000 (97.508)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 1.2103 (1.0462)\tPrec@1 68.000 (69.775)\tPrec@5 95.000 (97.521)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 0.9284 (1.0440)\tPrec@1 74.000 (69.790)\tPrec@5 98.000 (97.543)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 1.1241 (1.0584)\tPrec@1 68.000 (69.582)\tPrec@5 99.000 (97.473)\n",
            "val Results: Prec@1 69.580 Prec@5 97.420 Loss 1.05922\n",
            "val Class Accuracy: [0.974,0.948,0.562,0.473,0.796,0.838,0.907,0.413,0.324,0.723]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [112][0/329], lr: 0.01000\tTime 0.692 (0.692)\tData 0.622 (0.622)\tLoss 0.3318 (0.3318)\tPrec@1 88.672 (88.672)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [112][10/329], lr: 0.01000\tTime 0.090 (0.152)\tData 0.000 (0.063)\tLoss 0.4486 (0.4547)\tPrec@1 85.938 (85.298)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [112][20/329], lr: 0.01000\tTime 0.090 (0.122)\tData 0.000 (0.036)\tLoss 0.3077 (0.4134)\tPrec@1 89.062 (86.328)\tPrec@5 100.000 (99.423)\n",
            "Epoch: [112][30/329], lr: 0.01000\tTime 0.103 (0.112)\tData 0.000 (0.027)\tLoss 0.3463 (0.3855)\tPrec@1 89.453 (87.135)\tPrec@5 99.219 (99.496)\n",
            "Epoch: [112][40/329], lr: 0.01000\tTime 0.099 (0.106)\tData 0.002 (0.021)\tLoss 0.3201 (0.3618)\tPrec@1 90.234 (87.757)\tPrec@5 98.828 (99.514)\n",
            "Epoch: [112][50/329], lr: 0.01000\tTime 0.085 (0.103)\tData 0.008 (0.019)\tLoss 0.2042 (0.3492)\tPrec@1 93.750 (88.327)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [112][60/329], lr: 0.01000\tTime 0.076 (0.100)\tData 0.006 (0.017)\tLoss 0.2150 (0.3363)\tPrec@1 92.969 (88.794)\tPrec@5 99.219 (99.545)\n",
            "Epoch: [112][70/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.007 (0.016)\tLoss 0.2722 (0.3251)\tPrec@1 90.234 (89.145)\tPrec@5 100.000 (99.576)\n",
            "Epoch: [112][80/329], lr: 0.01000\tTime 0.076 (0.097)\tData 0.000 (0.015)\tLoss 0.2912 (0.3201)\tPrec@1 91.016 (89.352)\tPrec@5 100.000 (99.585)\n",
            "Epoch: [112][90/329], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.014)\tLoss 0.1932 (0.3120)\tPrec@1 94.531 (89.681)\tPrec@5 100.000 (99.588)\n",
            "Epoch: [112][100/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.000 (0.013)\tLoss 0.2588 (0.3075)\tPrec@1 92.578 (89.851)\tPrec@5 99.219 (99.609)\n",
            "Epoch: [112][110/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.007 (0.013)\tLoss 0.2016 (0.3042)\tPrec@1 94.141 (89.921)\tPrec@5 100.000 (99.620)\n",
            "Epoch: [112][120/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.006 (0.012)\tLoss 0.1622 (0.2996)\tPrec@1 94.141 (90.034)\tPrec@5 99.609 (99.629)\n",
            "Epoch: [112][130/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.006 (0.012)\tLoss 0.2108 (0.2951)\tPrec@1 92.969 (90.219)\tPrec@5 100.000 (99.639)\n",
            "Epoch: [112][140/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.005 (0.012)\tLoss 0.2153 (0.2924)\tPrec@1 94.141 (90.326)\tPrec@5 99.609 (99.645)\n",
            "Epoch: [112][150/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.005 (0.012)\tLoss 0.2468 (0.2892)\tPrec@1 93.359 (90.413)\tPrec@5 99.609 (99.640)\n",
            "Epoch: [112][160/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.011 (0.011)\tLoss 0.3297 (0.2874)\tPrec@1 89.844 (90.472)\tPrec@5 99.609 (99.653)\n",
            "Epoch: [112][170/329], lr: 0.01000\tTime 0.097 (0.093)\tData 0.008 (0.011)\tLoss 0.2497 (0.2850)\tPrec@1 91.406 (90.552)\tPrec@5 100.000 (99.662)\n",
            "Epoch: [112][180/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.000 (0.011)\tLoss 0.1992 (0.2819)\tPrec@1 93.750 (90.657)\tPrec@5 99.609 (99.668)\n",
            "Epoch: [112][190/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.000 (0.011)\tLoss 0.2990 (0.2814)\tPrec@1 89.844 (90.654)\tPrec@5 100.000 (99.673)\n",
            "Epoch: [112][200/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.005 (0.011)\tLoss 0.2678 (0.2795)\tPrec@1 92.188 (90.666)\tPrec@5 100.000 (99.685)\n",
            "Epoch: [112][210/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.007 (0.011)\tLoss 0.2176 (0.2795)\tPrec@1 91.797 (90.638)\tPrec@5 100.000 (99.683)\n",
            "Epoch: [112][220/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.009 (0.010)\tLoss 0.2435 (0.2786)\tPrec@1 90.234 (90.676)\tPrec@5 100.000 (99.691)\n",
            "Epoch: [112][230/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.007 (0.010)\tLoss 0.2043 (0.2770)\tPrec@1 93.359 (90.740)\tPrec@5 100.000 (99.692)\n",
            "Epoch: [112][240/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.005 (0.010)\tLoss 0.3009 (0.2770)\tPrec@1 86.328 (90.727)\tPrec@5 100.000 (99.697)\n",
            "Epoch: [112][250/329], lr: 0.01000\tTime 0.100 (0.091)\tData 0.000 (0.010)\tLoss 0.2933 (0.2759)\tPrec@1 90.234 (90.746)\tPrec@5 99.609 (99.704)\n",
            "Epoch: [112][260/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.007 (0.010)\tLoss 0.2394 (0.2752)\tPrec@1 91.016 (90.766)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [112][270/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.001 (0.010)\tLoss 0.2744 (0.2740)\tPrec@1 90.625 (90.788)\tPrec@5 100.000 (99.710)\n",
            "Epoch: [112][280/329], lr: 0.01000\tTime 0.100 (0.091)\tData 0.006 (0.010)\tLoss 0.2181 (0.2729)\tPrec@1 92.188 (90.827)\tPrec@5 100.000 (99.711)\n",
            "Epoch: [112][290/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.005 (0.010)\tLoss 0.2598 (0.2725)\tPrec@1 90.625 (90.841)\tPrec@5 100.000 (99.717)\n",
            "Epoch: [112][300/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.000 (0.010)\tLoss 0.2157 (0.2712)\tPrec@1 94.141 (90.890)\tPrec@5 98.828 (99.716)\n",
            "Epoch: [112][310/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.007 (0.010)\tLoss 0.2798 (0.2709)\tPrec@1 88.672 (90.903)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [112][320/329], lr: 0.01000\tTime 0.122 (0.091)\tData 0.071 (0.010)\tLoss 0.1931 (0.2697)\tPrec@1 91.797 (90.949)\tPrec@5 99.609 (99.713)\n",
            "Test: [0/100]\tTime 0.406 (0.406)\tLoss 0.7877 (0.7877)\tPrec@1 76.000 (76.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.016 (0.057)\tLoss 0.8142 (0.8990)\tPrec@1 73.000 (74.000)\tPrec@5 99.000 (97.364)\n",
            "Test: [20/100]\tTime 0.026 (0.041)\tLoss 0.7337 (0.8893)\tPrec@1 78.000 (74.190)\tPrec@5 99.000 (97.571)\n",
            "Test: [30/100]\tTime 0.027 (0.036)\tLoss 1.2296 (0.9005)\tPrec@1 69.000 (73.903)\tPrec@5 93.000 (97.484)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 0.9441 (0.9080)\tPrec@1 76.000 (73.463)\tPrec@5 97.000 (97.610)\n",
            "Test: [50/100]\tTime 0.032 (0.032)\tLoss 0.7635 (0.8987)\tPrec@1 78.000 (73.627)\tPrec@5 96.000 (97.647)\n",
            "Test: [60/100]\tTime 0.035 (0.031)\tLoss 0.9250 (0.9063)\tPrec@1 79.000 (73.590)\tPrec@5 98.000 (97.705)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 0.9931 (0.9050)\tPrec@1 71.000 (73.479)\tPrec@5 99.000 (97.690)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 0.9046 (0.8957)\tPrec@1 73.000 (73.481)\tPrec@5 98.000 (97.716)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 0.8125 (0.9085)\tPrec@1 72.000 (73.143)\tPrec@5 97.000 (97.681)\n",
            "val Results: Prec@1 73.210 Prec@5 97.700 Loss 0.90306\n",
            "val Class Accuracy: [0.889,0.724,0.756,0.546,0.701,0.867,0.735,0.759,0.483,0.861]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [113][0/329], lr: 0.01000\tTime 0.509 (0.509)\tData 0.442 (0.442)\tLoss 0.2955 (0.2955)\tPrec@1 90.234 (90.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][10/329], lr: 0.01000\tTime 0.094 (0.147)\tData 0.000 (0.058)\tLoss 0.6169 (0.6749)\tPrec@1 77.344 (77.770)\tPrec@5 98.438 (98.651)\n",
            "Epoch: [113][20/329], lr: 0.01000\tTime 0.083 (0.121)\tData 0.000 (0.032)\tLoss 0.5400 (0.5991)\tPrec@1 79.688 (80.227)\tPrec@5 99.219 (98.940)\n",
            "Epoch: [113][30/329], lr: 0.01000\tTime 0.104 (0.112)\tData 0.007 (0.025)\tLoss 0.4449 (0.5468)\tPrec@1 85.547 (81.930)\tPrec@5 99.219 (99.093)\n",
            "Epoch: [113][40/329], lr: 0.01000\tTime 0.108 (0.107)\tData 0.001 (0.021)\tLoss 0.3545 (0.5024)\tPrec@1 89.062 (83.222)\tPrec@5 99.609 (99.171)\n",
            "Epoch: [113][50/329], lr: 0.01000\tTime 0.102 (0.104)\tData 0.006 (0.018)\tLoss 0.3707 (0.4708)\tPrec@1 87.109 (84.275)\tPrec@5 98.828 (99.234)\n",
            "Epoch: [113][60/329], lr: 0.01000\tTime 0.107 (0.102)\tData 0.000 (0.016)\tLoss 0.3459 (0.4448)\tPrec@1 88.281 (85.067)\tPrec@5 98.047 (99.308)\n",
            "Epoch: [113][70/329], lr: 0.01000\tTime 0.077 (0.099)\tData 0.000 (0.015)\tLoss 0.2874 (0.4221)\tPrec@1 91.016 (85.855)\tPrec@5 100.000 (99.367)\n",
            "Epoch: [113][80/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.000 (0.014)\tLoss 0.3052 (0.4093)\tPrec@1 89.844 (86.256)\tPrec@5 100.000 (99.407)\n",
            "Epoch: [113][90/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.012 (0.013)\tLoss 0.2358 (0.3936)\tPrec@1 91.016 (86.779)\tPrec@5 99.219 (99.429)\n",
            "Epoch: [113][100/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.007 (0.013)\tLoss 0.2925 (0.3833)\tPrec@1 91.016 (87.129)\tPrec@5 100.000 (99.428)\n",
            "Epoch: [113][110/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.000 (0.012)\tLoss 0.3152 (0.3739)\tPrec@1 88.281 (87.426)\tPrec@5 99.219 (99.462)\n",
            "Epoch: [113][120/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.002 (0.012)\tLoss 0.2082 (0.3648)\tPrec@1 92.188 (87.742)\tPrec@5 100.000 (99.493)\n",
            "Epoch: [113][130/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.006 (0.012)\tLoss 0.3161 (0.3587)\tPrec@1 89.062 (87.989)\tPrec@5 99.609 (99.514)\n",
            "Epoch: [113][140/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 0.3098 (0.3535)\tPrec@1 89.062 (88.165)\tPrec@5 100.000 (99.521)\n",
            "Epoch: [113][150/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.008 (0.011)\tLoss 0.3227 (0.3487)\tPrec@1 89.062 (88.359)\tPrec@5 99.609 (99.519)\n",
            "Epoch: [113][160/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.003 (0.011)\tLoss 0.3450 (0.3441)\tPrec@1 91.016 (88.558)\tPrec@5 99.609 (99.517)\n",
            "Epoch: [113][170/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.011)\tLoss 0.3013 (0.3398)\tPrec@1 90.625 (88.686)\tPrec@5 99.609 (99.536)\n",
            "Epoch: [113][180/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.2776 (0.3374)\tPrec@1 91.797 (88.786)\tPrec@5 99.609 (99.540)\n",
            "Epoch: [113][190/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.006 (0.010)\tLoss 0.3029 (0.3340)\tPrec@1 88.672 (88.893)\tPrec@5 100.000 (99.550)\n",
            "Epoch: [113][200/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.006 (0.010)\tLoss 0.2632 (0.3309)\tPrec@1 90.625 (88.979)\tPrec@5 100.000 (99.561)\n",
            "Epoch: [113][210/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.006 (0.010)\tLoss 0.2599 (0.3295)\tPrec@1 90.625 (88.994)\tPrec@5 99.609 (99.567)\n",
            "Epoch: [113][220/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.010)\tLoss 0.2448 (0.3265)\tPrec@1 92.188 (89.094)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [113][230/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.006 (0.010)\tLoss 0.2278 (0.3235)\tPrec@1 92.188 (89.194)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [113][240/329], lr: 0.01000\tTime 0.071 (0.091)\tData 0.006 (0.010)\tLoss 0.2029 (0.3205)\tPrec@1 92.188 (89.299)\tPrec@5 100.000 (99.580)\n",
            "Epoch: [113][250/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.009)\tLoss 0.2119 (0.3180)\tPrec@1 93.359 (89.383)\tPrec@5 100.000 (99.588)\n",
            "Epoch: [113][260/329], lr: 0.01000\tTime 0.103 (0.091)\tData 0.000 (0.009)\tLoss 0.2715 (0.3150)\tPrec@1 90.625 (89.483)\tPrec@5 100.000 (99.596)\n",
            "Epoch: [113][270/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.000 (0.009)\tLoss 0.2295 (0.3128)\tPrec@1 92.969 (89.563)\tPrec@5 100.000 (99.602)\n",
            "Epoch: [113][280/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.012 (0.009)\tLoss 0.2679 (0.3106)\tPrec@1 90.234 (89.652)\tPrec@5 100.000 (99.607)\n",
            "Epoch: [113][290/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.012 (0.009)\tLoss 0.2581 (0.3096)\tPrec@1 91.016 (89.667)\tPrec@5 99.609 (99.607)\n",
            "Epoch: [113][300/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.000 (0.009)\tLoss 0.2913 (0.3081)\tPrec@1 89.453 (89.704)\tPrec@5 99.609 (99.611)\n",
            "Epoch: [113][310/329], lr: 0.01000\tTime 0.069 (0.091)\tData 0.000 (0.009)\tLoss 0.2455 (0.3065)\tPrec@1 91.406 (89.755)\tPrec@5 99.609 (99.607)\n",
            "Epoch: [113][320/329], lr: 0.01000\tTime 0.100 (0.091)\tData 0.068 (0.009)\tLoss 0.3024 (0.3053)\tPrec@1 88.672 (89.793)\tPrec@5 100.000 (99.611)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 1.2095 (1.2095)\tPrec@1 68.000 (68.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.035 (0.059)\tLoss 0.9447 (1.2999)\tPrec@1 69.000 (64.909)\tPrec@5 97.000 (94.455)\n",
            "Test: [20/100]\tTime 0.015 (0.039)\tLoss 1.1747 (1.2657)\tPrec@1 64.000 (65.857)\tPrec@5 96.000 (94.857)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 1.3722 (1.2897)\tPrec@1 63.000 (65.419)\tPrec@5 91.000 (94.516)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 1.2406 (1.3116)\tPrec@1 66.000 (65.268)\tPrec@5 93.000 (94.634)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.2127 (1.2995)\tPrec@1 68.000 (65.647)\tPrec@5 93.000 (94.608)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.3570 (1.3107)\tPrec@1 59.000 (65.213)\tPrec@5 94.000 (94.574)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 1.3320 (1.3142)\tPrec@1 64.000 (64.958)\tPrec@5 95.000 (94.634)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 1.1600 (1.3083)\tPrec@1 76.000 (65.333)\tPrec@5 92.000 (94.630)\n",
            "Test: [90/100]\tTime 0.036 (0.028)\tLoss 1.2488 (1.3179)\tPrec@1 62.000 (65.209)\tPrec@5 95.000 (94.549)\n",
            "val Results: Prec@1 65.310 Prec@5 94.590 Loss 1.31743\n",
            "val Class Accuracy: [0.573,0.980,0.920,0.631,0.698,0.519,0.864,0.257,0.612,0.477]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [114][0/329], lr: 0.01000\tTime 0.554 (0.554)\tData 0.471 (0.471)\tLoss 0.2849 (0.2849)\tPrec@1 91.797 (91.797)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [114][10/329], lr: 0.01000\tTime 0.093 (0.142)\tData 0.000 (0.052)\tLoss 0.5279 (0.5791)\tPrec@1 83.203 (81.996)\tPrec@5 98.828 (99.077)\n",
            "Epoch: [114][20/329], lr: 0.01000\tTime 0.101 (0.120)\tData 0.000 (0.030)\tLoss 0.4556 (0.5305)\tPrec@1 82.812 (83.147)\tPrec@5 99.219 (99.182)\n",
            "Epoch: [114][30/329], lr: 0.01000\tTime 0.086 (0.111)\tData 0.006 (0.022)\tLoss 0.2684 (0.4763)\tPrec@1 88.281 (84.728)\tPrec@5 100.000 (99.269)\n",
            "Epoch: [114][40/329], lr: 0.01000\tTime 0.091 (0.106)\tData 0.005 (0.018)\tLoss 0.2563 (0.4451)\tPrec@1 91.797 (85.747)\tPrec@5 99.609 (99.352)\n",
            "Epoch: [114][50/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.000 (0.016)\tLoss 0.3146 (0.4186)\tPrec@1 90.234 (86.405)\tPrec@5 99.219 (99.387)\n",
            "Epoch: [114][60/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.006 (0.015)\tLoss 0.2282 (0.3969)\tPrec@1 92.188 (87.001)\tPrec@5 100.000 (99.443)\n",
            "Epoch: [114][70/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.015 (0.014)\tLoss 0.3647 (0.3840)\tPrec@1 87.500 (87.434)\tPrec@5 100.000 (99.461)\n",
            "Epoch: [114][80/329], lr: 0.01000\tTime 0.076 (0.097)\tData 0.008 (0.013)\tLoss 0.2870 (0.3728)\tPrec@1 92.578 (87.799)\tPrec@5 99.609 (99.494)\n",
            "Epoch: [114][90/329], lr: 0.01000\tTime 0.075 (0.096)\tData 0.000 (0.012)\tLoss 0.2745 (0.3621)\tPrec@1 92.188 (88.144)\tPrec@5 99.609 (99.502)\n",
            "Epoch: [114][100/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.012)\tLoss 0.2389 (0.3549)\tPrec@1 93.359 (88.359)\tPrec@5 99.609 (99.517)\n",
            "Epoch: [114][110/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.006 (0.011)\tLoss 0.2774 (0.3455)\tPrec@1 90.234 (88.640)\tPrec@5 99.609 (99.539)\n",
            "Epoch: [114][120/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.015 (0.011)\tLoss 0.3022 (0.3388)\tPrec@1 89.844 (88.807)\tPrec@5 100.000 (99.545)\n",
            "Epoch: [114][130/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.002 (0.011)\tLoss 0.2383 (0.3337)\tPrec@1 91.406 (88.964)\tPrec@5 99.609 (99.562)\n",
            "Epoch: [114][140/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.006 (0.011)\tLoss 0.3413 (0.3279)\tPrec@1 89.844 (89.132)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [114][150/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.004 (0.010)\tLoss 0.2648 (0.3258)\tPrec@1 91.406 (89.241)\tPrec@5 99.609 (99.563)\n",
            "Epoch: [114][160/329], lr: 0.01000\tTime 0.106 (0.092)\tData 0.005 (0.010)\tLoss 0.2657 (0.3222)\tPrec@1 89.844 (89.346)\tPrec@5 99.609 (99.568)\n",
            "Epoch: [114][170/329], lr: 0.01000\tTime 0.065 (0.092)\tData 0.001 (0.010)\tLoss 0.2446 (0.3188)\tPrec@1 93.359 (89.469)\tPrec@5 100.000 (99.587)\n",
            "Epoch: [114][180/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.007 (0.010)\tLoss 0.3736 (0.3173)\tPrec@1 88.672 (89.520)\tPrec@5 100.000 (99.588)\n",
            "Epoch: [114][190/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.007 (0.010)\tLoss 0.2543 (0.3145)\tPrec@1 91.797 (89.600)\tPrec@5 99.609 (99.597)\n",
            "Epoch: [114][200/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.001 (0.009)\tLoss 0.2310 (0.3114)\tPrec@1 90.625 (89.675)\tPrec@5 99.609 (99.604)\n",
            "Epoch: [114][210/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.000 (0.009)\tLoss 0.2897 (0.3102)\tPrec@1 89.062 (89.701)\tPrec@5 99.609 (99.608)\n",
            "Epoch: [114][220/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.3040 (0.3082)\tPrec@1 91.797 (89.770)\tPrec@5 100.000 (99.620)\n",
            "Epoch: [114][230/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.006 (0.009)\tLoss 0.3362 (0.3071)\tPrec@1 88.672 (89.790)\tPrec@5 99.609 (99.623)\n",
            "Epoch: [114][240/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.006 (0.009)\tLoss 0.2660 (0.3051)\tPrec@1 92.969 (89.852)\tPrec@5 99.609 (99.632)\n",
            "Epoch: [114][250/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.001 (0.009)\tLoss 0.2720 (0.3044)\tPrec@1 90.625 (89.884)\tPrec@5 99.609 (99.633)\n",
            "Epoch: [114][260/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.005 (0.009)\tLoss 0.2749 (0.3033)\tPrec@1 91.406 (89.935)\tPrec@5 99.609 (99.635)\n",
            "Epoch: [114][270/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.005 (0.009)\tLoss 0.2220 (0.3013)\tPrec@1 91.016 (89.991)\tPrec@5 99.609 (99.637)\n",
            "Epoch: [114][280/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.000 (0.009)\tLoss 0.1923 (0.3001)\tPrec@1 93.750 (90.020)\tPrec@5 99.609 (99.639)\n",
            "Epoch: [114][290/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.012 (0.008)\tLoss 0.3401 (0.2993)\tPrec@1 88.281 (90.036)\tPrec@5 100.000 (99.646)\n",
            "Epoch: [114][300/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.007 (0.008)\tLoss 0.2868 (0.2981)\tPrec@1 89.844 (90.064)\tPrec@5 99.609 (99.647)\n",
            "Epoch: [114][310/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.005 (0.008)\tLoss 0.2067 (0.2968)\tPrec@1 92.969 (90.100)\tPrec@5 99.609 (99.652)\n",
            "Epoch: [114][320/329], lr: 0.01000\tTime 0.103 (0.090)\tData 0.064 (0.009)\tLoss 0.3051 (0.2961)\tPrec@1 91.797 (90.118)\tPrec@5 99.219 (99.653)\n",
            "Test: [0/100]\tTime 0.406 (0.406)\tLoss 0.5371 (0.5371)\tPrec@1 78.000 (78.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.026 (0.058)\tLoss 0.5801 (0.7143)\tPrec@1 81.000 (77.273)\tPrec@5 100.000 (98.727)\n",
            "Test: [20/100]\tTime 0.025 (0.042)\tLoss 0.5788 (0.7007)\tPrec@1 83.000 (78.333)\tPrec@5 100.000 (98.857)\n",
            "Test: [30/100]\tTime 0.043 (0.036)\tLoss 0.7598 (0.7053)\tPrec@1 78.000 (78.774)\tPrec@5 98.000 (98.548)\n",
            "Test: [40/100]\tTime 0.025 (0.032)\tLoss 0.7389 (0.7147)\tPrec@1 75.000 (78.415)\tPrec@5 99.000 (98.585)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 0.6004 (0.7052)\tPrec@1 81.000 (78.451)\tPrec@5 99.000 (98.627)\n",
            "Test: [60/100]\tTime 0.020 (0.030)\tLoss 0.6972 (0.7025)\tPrec@1 78.000 (78.279)\tPrec@5 100.000 (98.738)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 0.7386 (0.7028)\tPrec@1 81.000 (78.352)\tPrec@5 100.000 (98.704)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 0.6216 (0.7021)\tPrec@1 78.000 (78.259)\tPrec@5 99.000 (98.741)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 0.6859 (0.7086)\tPrec@1 81.000 (78.088)\tPrec@5 100.000 (98.692)\n",
            "val Results: Prec@1 77.920 Prec@5 98.690 Loss 0.71179\n",
            "val Class Accuracy: [0.926,0.978,0.774,0.640,0.770,0.793,0.890,0.768,0.715,0.538]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [115][0/329], lr: 0.01000\tTime 0.542 (0.542)\tData 0.469 (0.469)\tLoss 0.1527 (0.1527)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][10/329], lr: 0.01000\tTime 0.104 (0.140)\tData 0.000 (0.049)\tLoss 0.3058 (0.2349)\tPrec@1 92.578 (92.365)\tPrec@5 99.219 (99.751)\n",
            "Epoch: [115][20/329], lr: 0.01000\tTime 0.102 (0.118)\tData 0.000 (0.028)\tLoss 0.1985 (0.2401)\tPrec@1 92.188 (91.946)\tPrec@5 99.609 (99.721)\n",
            "Epoch: [115][30/329], lr: 0.01000\tTime 0.086 (0.111)\tData 0.006 (0.021)\tLoss 0.2446 (0.2423)\tPrec@1 93.359 (91.872)\tPrec@5 100.000 (99.761)\n",
            "Epoch: [115][40/329], lr: 0.01000\tTime 0.106 (0.107)\tData 0.011 (0.017)\tLoss 0.2489 (0.2445)\tPrec@1 91.797 (91.749)\tPrec@5 99.609 (99.752)\n",
            "Epoch: [115][50/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.003 (0.016)\tLoss 0.2540 (0.2473)\tPrec@1 87.891 (91.544)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [115][60/329], lr: 0.01000\tTime 0.081 (0.101)\tData 0.000 (0.014)\tLoss 0.2306 (0.2460)\tPrec@1 92.188 (91.701)\tPrec@5 100.000 (99.750)\n",
            "Epoch: [115][70/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.001 (0.014)\tLoss 0.1718 (0.2434)\tPrec@1 93.359 (91.775)\tPrec@5 99.609 (99.747)\n",
            "Epoch: [115][80/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.005 (0.013)\tLoss 0.2481 (0.2450)\tPrec@1 91.406 (91.758)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [115][90/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.000 (0.012)\tLoss 0.2092 (0.2437)\tPrec@1 92.188 (91.767)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [115][100/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.007 (0.012)\tLoss 0.2056 (0.2419)\tPrec@1 94.531 (91.855)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [115][110/329], lr: 0.01000\tTime 0.072 (0.095)\tData 0.000 (0.011)\tLoss 0.3068 (0.2425)\tPrec@1 91.016 (91.853)\tPrec@5 99.609 (99.757)\n",
            "Epoch: [115][120/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.000 (0.011)\tLoss 0.2910 (0.2432)\tPrec@1 89.453 (91.855)\tPrec@5 99.609 (99.742)\n",
            "Epoch: [115][130/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.002 (0.011)\tLoss 0.1853 (0.2449)\tPrec@1 92.578 (91.785)\tPrec@5 99.609 (99.735)\n",
            "Epoch: [115][140/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.005 (0.011)\tLoss 0.3221 (0.2458)\tPrec@1 89.844 (91.747)\tPrec@5 99.219 (99.729)\n",
            "Epoch: [115][150/329], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.010)\tLoss 0.2123 (0.2466)\tPrec@1 94.141 (91.722)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [115][160/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.001 (0.010)\tLoss 0.3168 (0.2482)\tPrec@1 89.062 (91.685)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [115][170/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.010)\tLoss 0.2917 (0.2486)\tPrec@1 91.016 (91.685)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [115][180/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.000 (0.010)\tLoss 0.2768 (0.2489)\tPrec@1 90.234 (91.644)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [115][190/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.012 (0.010)\tLoss 0.2091 (0.2486)\tPrec@1 94.141 (91.676)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [115][200/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.010)\tLoss 0.2890 (0.2483)\tPrec@1 90.234 (91.690)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [115][210/329], lr: 0.01000\tTime 0.069 (0.093)\tData 0.000 (0.010)\tLoss 0.2092 (0.2488)\tPrec@1 92.188 (91.686)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [115][220/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.006 (0.009)\tLoss 0.2758 (0.2493)\tPrec@1 90.625 (91.652)\tPrec@5 99.219 (99.749)\n",
            "Epoch: [115][230/329], lr: 0.01000\tTime 0.101 (0.092)\tData 0.006 (0.009)\tLoss 0.2445 (0.2491)\tPrec@1 92.578 (91.682)\tPrec@5 99.219 (99.743)\n",
            "Epoch: [115][240/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.009)\tLoss 0.2623 (0.2494)\tPrec@1 89.844 (91.649)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [115][250/329], lr: 0.01000\tTime 0.121 (0.092)\tData 0.000 (0.009)\tLoss 0.2448 (0.2498)\tPrec@1 92.578 (91.630)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [115][260/329], lr: 0.01000\tTime 0.124 (0.093)\tData 0.000 (0.009)\tLoss 0.2299 (0.2499)\tPrec@1 92.969 (91.629)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [115][270/329], lr: 0.01000\tTime 0.117 (0.094)\tData 0.010 (0.009)\tLoss 0.1985 (0.2496)\tPrec@1 92.969 (91.627)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [115][280/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.000 (0.009)\tLoss 0.2525 (0.2496)\tPrec@1 90.625 (91.637)\tPrec@5 100.000 (99.747)\n",
            "Epoch: [115][290/329], lr: 0.01000\tTime 0.113 (0.094)\tData 0.005 (0.009)\tLoss 0.2689 (0.2499)\tPrec@1 91.797 (91.645)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [115][300/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.002 (0.009)\tLoss 0.2839 (0.2488)\tPrec@1 92.188 (91.689)\tPrec@5 99.609 (99.742)\n",
            "Epoch: [115][310/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.007 (0.009)\tLoss 0.2956 (0.2495)\tPrec@1 89.453 (91.665)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [115][320/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.060 (0.009)\tLoss 0.2472 (0.2488)\tPrec@1 92.969 (91.686)\tPrec@5 99.219 (99.746)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 1.0459 (1.0459)\tPrec@1 70.000 (70.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.055)\tLoss 0.8396 (1.0407)\tPrec@1 77.000 (71.455)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/100]\tTime 0.036 (0.042)\tLoss 0.9938 (1.0181)\tPrec@1 69.000 (71.476)\tPrec@5 99.000 (97.667)\n",
            "Test: [30/100]\tTime 0.016 (0.036)\tLoss 1.2831 (1.0378)\tPrec@1 68.000 (71.516)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/100]\tTime 0.025 (0.032)\tLoss 0.8958 (1.0412)\tPrec@1 77.000 (71.317)\tPrec@5 98.000 (97.732)\n",
            "Test: [50/100]\tTime 0.017 (0.029)\tLoss 1.0411 (1.0254)\tPrec@1 74.000 (71.471)\tPrec@5 97.000 (97.745)\n",
            "Test: [60/100]\tTime 0.023 (0.029)\tLoss 0.9512 (1.0341)\tPrec@1 74.000 (71.361)\tPrec@5 98.000 (97.754)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 0.9484 (1.0340)\tPrec@1 70.000 (71.254)\tPrec@5 100.000 (97.732)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 0.9077 (1.0277)\tPrec@1 72.000 (71.272)\tPrec@5 98.000 (97.802)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.0764 (1.0451)\tPrec@1 68.000 (70.934)\tPrec@5 98.000 (97.736)\n",
            "val Results: Prec@1 71.090 Prec@5 97.770 Loss 1.04213\n",
            "val Class Accuracy: [0.792,0.965,0.679,0.892,0.757,0.639,0.590,0.612,0.535,0.648]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [116][0/329], lr: 0.01000\tTime 0.725 (0.725)\tData 0.635 (0.635)\tLoss 0.2604 (0.2604)\tPrec@1 91.406 (91.406)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [116][10/329], lr: 0.01000\tTime 0.091 (0.145)\tData 0.003 (0.062)\tLoss 0.8007 (0.6809)\tPrec@1 75.781 (78.942)\tPrec@5 98.047 (97.514)\n",
            "Epoch: [116][20/329], lr: 0.01000\tTime 0.089 (0.121)\tData 0.000 (0.034)\tLoss 0.3123 (0.5860)\tPrec@1 90.625 (81.306)\tPrec@5 99.609 (98.289)\n",
            "Epoch: [116][30/329], lr: 0.01000\tTime 0.075 (0.111)\tData 0.009 (0.026)\tLoss 0.3780 (0.5252)\tPrec@1 87.109 (82.976)\tPrec@5 99.219 (98.652)\n",
            "Epoch: [116][40/329], lr: 0.01000\tTime 0.106 (0.106)\tData 0.000 (0.022)\tLoss 0.2805 (0.4795)\tPrec@1 91.797 (84.499)\tPrec@5 99.609 (98.847)\n",
            "Epoch: [116][50/329], lr: 0.01000\tTime 0.093 (0.103)\tData 0.000 (0.018)\tLoss 0.2638 (0.4474)\tPrec@1 91.016 (85.501)\tPrec@5 100.000 (99.004)\n",
            "Epoch: [116][60/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.007 (0.016)\tLoss 0.3407 (0.4255)\tPrec@1 89.453 (86.232)\tPrec@5 99.609 (99.033)\n",
            "Epoch: [116][70/329], lr: 0.01000\tTime 0.090 (0.098)\tData 0.007 (0.015)\tLoss 0.2749 (0.4076)\tPrec@1 90.625 (86.768)\tPrec@5 98.828 (99.087)\n",
            "Epoch: [116][80/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.000 (0.014)\tLoss 0.2740 (0.3930)\tPrec@1 89.844 (87.220)\tPrec@5 100.000 (99.151)\n",
            "Epoch: [116][90/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.000 (0.013)\tLoss 0.2648 (0.3809)\tPrec@1 90.234 (87.573)\tPrec@5 99.609 (99.193)\n",
            "Epoch: [116][100/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.008 (0.013)\tLoss 0.3041 (0.3720)\tPrec@1 89.844 (87.825)\tPrec@5 99.609 (99.250)\n",
            "Epoch: [116][110/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.000 (0.012)\tLoss 0.3109 (0.3644)\tPrec@1 90.234 (88.070)\tPrec@5 98.828 (99.289)\n",
            "Epoch: [116][120/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.000 (0.012)\tLoss 0.2806 (0.3569)\tPrec@1 91.797 (88.320)\tPrec@5 99.609 (99.319)\n",
            "Epoch: [116][130/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.007 (0.011)\tLoss 0.2308 (0.3493)\tPrec@1 91.797 (88.535)\tPrec@5 100.000 (99.344)\n",
            "Epoch: [116][140/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.000 (0.011)\tLoss 0.2996 (0.3450)\tPrec@1 91.797 (88.711)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [116][150/329], lr: 0.01000\tTime 0.070 (0.093)\tData 0.004 (0.011)\tLoss 0.2755 (0.3403)\tPrec@1 91.016 (88.850)\tPrec@5 100.000 (99.374)\n",
            "Epoch: [116][160/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.009 (0.011)\tLoss 0.4667 (0.3375)\tPrec@1 84.766 (88.934)\tPrec@5 99.219 (99.391)\n",
            "Epoch: [116][170/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.002 (0.010)\tLoss 0.2439 (0.3345)\tPrec@1 91.016 (89.017)\tPrec@5 99.219 (99.404)\n",
            "Epoch: [116][180/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.010)\tLoss 0.3000 (0.3312)\tPrec@1 89.062 (89.110)\tPrec@5 99.609 (99.422)\n",
            "Epoch: [116][190/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.006 (0.010)\tLoss 0.2053 (0.3272)\tPrec@1 91.797 (89.228)\tPrec@5 99.609 (99.436)\n",
            "Epoch: [116][200/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.004 (0.010)\tLoss 0.2643 (0.3232)\tPrec@1 93.750 (89.350)\tPrec@5 100.000 (99.460)\n",
            "Epoch: [116][210/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.000 (0.010)\tLoss 0.2066 (0.3199)\tPrec@1 94.531 (89.453)\tPrec@5 99.609 (99.476)\n",
            "Epoch: [116][220/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.010)\tLoss 0.2510 (0.3164)\tPrec@1 91.406 (89.572)\tPrec@5 99.609 (99.491)\n",
            "Epoch: [116][230/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.006 (0.010)\tLoss 0.2474 (0.3142)\tPrec@1 90.234 (89.641)\tPrec@5 99.609 (99.501)\n",
            "Epoch: [116][240/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.014 (0.010)\tLoss 0.1989 (0.3115)\tPrec@1 94.141 (89.738)\tPrec@5 99.609 (99.506)\n",
            "Epoch: [116][250/329], lr: 0.01000\tTime 0.074 (0.091)\tData 0.005 (0.009)\tLoss 0.1941 (0.3092)\tPrec@1 94.531 (89.827)\tPrec@5 100.000 (99.514)\n",
            "Epoch: [116][260/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.006 (0.009)\tLoss 0.2067 (0.3072)\tPrec@1 94.141 (89.892)\tPrec@5 100.000 (99.523)\n",
            "Epoch: [116][270/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.3162 (0.3054)\tPrec@1 88.672 (89.942)\tPrec@5 99.609 (99.530)\n",
            "Epoch: [116][280/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.005 (0.009)\tLoss 0.2631 (0.3040)\tPrec@1 91.016 (89.979)\tPrec@5 99.609 (99.541)\n",
            "Epoch: [116][290/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.3110 (0.3029)\tPrec@1 91.797 (90.020)\tPrec@5 99.609 (99.546)\n",
            "Epoch: [116][300/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.006 (0.009)\tLoss 0.1641 (0.3016)\tPrec@1 94.141 (90.046)\tPrec@5 100.000 (99.547)\n",
            "Epoch: [116][310/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.000 (0.009)\tLoss 0.2714 (0.3009)\tPrec@1 92.188 (90.076)\tPrec@5 100.000 (99.545)\n",
            "Epoch: [116][320/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.061 (0.009)\tLoss 0.2724 (0.2996)\tPrec@1 88.672 (90.093)\tPrec@5 100.000 (99.553)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 1.0278 (1.0278)\tPrec@1 66.000 (66.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.030 (0.054)\tLoss 0.9080 (1.0225)\tPrec@1 74.000 (72.364)\tPrec@5 97.000 (98.182)\n",
            "Test: [20/100]\tTime 0.019 (0.041)\tLoss 0.6725 (1.0002)\tPrec@1 74.000 (72.381)\tPrec@5 100.000 (97.905)\n",
            "Test: [30/100]\tTime 0.031 (0.036)\tLoss 1.2310 (1.0181)\tPrec@1 68.000 (72.000)\tPrec@5 99.000 (97.871)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 1.0378 (1.0172)\tPrec@1 72.000 (72.024)\tPrec@5 98.000 (97.854)\n",
            "Test: [50/100]\tTime 0.019 (0.031)\tLoss 1.0815 (1.0062)\tPrec@1 69.000 (72.118)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 0.7825 (1.0014)\tPrec@1 75.000 (71.951)\tPrec@5 99.000 (97.934)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 1.1669 (1.0039)\tPrec@1 67.000 (71.746)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.014 (0.028)\tLoss 0.9924 (0.9957)\tPrec@1 74.000 (71.975)\tPrec@5 99.000 (98.012)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 0.8016 (1.0102)\tPrec@1 78.000 (71.714)\tPrec@5 99.000 (97.989)\n",
            "val Results: Prec@1 71.610 Prec@5 98.030 Loss 1.01089\n",
            "val Class Accuracy: [0.968,0.949,0.849,0.723,0.745,0.727,0.481,0.601,0.572,0.546]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [117][0/329], lr: 0.01000\tTime 0.637 (0.637)\tData 0.564 (0.564)\tLoss 0.1880 (0.1880)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][10/329], lr: 0.01000\tTime 0.082 (0.145)\tData 0.000 (0.055)\tLoss 0.4363 (0.3385)\tPrec@1 85.156 (88.707)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [117][20/329], lr: 0.01000\tTime 0.100 (0.119)\tData 0.000 (0.031)\tLoss 0.2798 (0.3461)\tPrec@1 90.625 (88.337)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [117][30/329], lr: 0.01000\tTime 0.080 (0.109)\tData 0.000 (0.023)\tLoss 0.2606 (0.3273)\tPrec@1 90.625 (88.962)\tPrec@5 100.000 (99.672)\n",
            "Epoch: [117][40/329], lr: 0.01000\tTime 0.101 (0.105)\tData 0.000 (0.019)\tLoss 0.2361 (0.3150)\tPrec@1 91.797 (89.358)\tPrec@5 99.609 (99.705)\n",
            "Epoch: [117][50/329], lr: 0.01000\tTime 0.117 (0.101)\tData 0.007 (0.017)\tLoss 0.1797 (0.3069)\tPrec@1 93.359 (89.568)\tPrec@5 100.000 (99.694)\n",
            "Epoch: [117][60/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.000 (0.015)\tLoss 0.2057 (0.2954)\tPrec@1 92.969 (89.953)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [117][70/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.000 (0.014)\tLoss 0.2306 (0.2886)\tPrec@1 91.406 (90.201)\tPrec@5 99.609 (99.719)\n",
            "Epoch: [117][80/329], lr: 0.01000\tTime 0.077 (0.096)\tData 0.006 (0.013)\tLoss 0.2344 (0.2812)\tPrec@1 92.188 (90.485)\tPrec@5 100.000 (99.720)\n",
            "Epoch: [117][90/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.007 (0.012)\tLoss 0.2762 (0.2814)\tPrec@1 89.844 (90.470)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [117][100/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.000 (0.012)\tLoss 0.2075 (0.2784)\tPrec@1 92.578 (90.594)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [117][110/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.006 (0.012)\tLoss 0.1922 (0.2738)\tPrec@1 92.578 (90.748)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [117][120/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.000 (0.011)\tLoss 0.2847 (0.2734)\tPrec@1 89.453 (90.773)\tPrec@5 99.609 (99.709)\n",
            "Epoch: [117][130/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.011)\tLoss 0.2007 (0.2703)\tPrec@1 92.578 (90.878)\tPrec@5 99.609 (99.714)\n",
            "Epoch: [117][140/329], lr: 0.01000\tTime 0.067 (0.093)\tData 0.005 (0.010)\tLoss 0.2159 (0.2683)\tPrec@1 93.359 (90.955)\tPrec@5 100.000 (99.715)\n",
            "Epoch: [117][150/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.001 (0.010)\tLoss 0.2056 (0.2677)\tPrec@1 92.188 (90.979)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [117][160/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.012 (0.010)\tLoss 0.2108 (0.2666)\tPrec@1 93.359 (91.025)\tPrec@5 99.609 (99.723)\n",
            "Epoch: [117][170/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.008 (0.010)\tLoss 0.2475 (0.2656)\tPrec@1 90.234 (91.068)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [117][180/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.000 (0.010)\tLoss 0.2715 (0.2647)\tPrec@1 92.188 (91.108)\tPrec@5 100.000 (99.726)\n",
            "Epoch: [117][190/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.002 (0.009)\tLoss 0.2225 (0.2642)\tPrec@1 92.578 (91.112)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [117][200/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.2605 (0.2635)\tPrec@1 91.797 (91.142)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [117][210/329], lr: 0.01000\tTime 0.067 (0.091)\tData 0.000 (0.009)\tLoss 0.2295 (0.2637)\tPrec@1 92.578 (91.145)\tPrec@5 100.000 (99.732)\n",
            "Epoch: [117][220/329], lr: 0.01000\tTime 0.105 (0.091)\tData 0.006 (0.009)\tLoss 0.2401 (0.2624)\tPrec@1 91.406 (91.199)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [117][230/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.006 (0.009)\tLoss 0.2032 (0.2614)\tPrec@1 91.797 (91.229)\tPrec@5 100.000 (99.729)\n",
            "Epoch: [117][240/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.007 (0.009)\tLoss 0.2478 (0.2608)\tPrec@1 92.578 (91.244)\tPrec@5 99.219 (99.721)\n",
            "Epoch: [117][250/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.005 (0.009)\tLoss 0.1954 (0.2600)\tPrec@1 94.922 (91.279)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [117][260/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.006 (0.009)\tLoss 0.2419 (0.2595)\tPrec@1 89.453 (91.267)\tPrec@5 100.000 (99.720)\n",
            "Epoch: [117][270/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.005 (0.009)\tLoss 0.1954 (0.2585)\tPrec@1 93.359 (91.304)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [117][280/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.001 (0.009)\tLoss 0.2472 (0.2595)\tPrec@1 94.141 (91.294)\tPrec@5 99.609 (99.723)\n",
            "Epoch: [117][290/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.000 (0.009)\tLoss 0.2667 (0.2601)\tPrec@1 90.625 (91.268)\tPrec@5 99.219 (99.722)\n",
            "Epoch: [117][300/329], lr: 0.01000\tTime 0.114 (0.091)\tData 0.000 (0.009)\tLoss 0.2394 (0.2600)\tPrec@1 92.188 (91.273)\tPrec@5 100.000 (99.725)\n",
            "Epoch: [117][310/329], lr: 0.01000\tTime 0.057 (0.091)\tData 0.007 (0.009)\tLoss 0.2154 (0.2599)\tPrec@1 92.969 (91.274)\tPrec@5 100.000 (99.720)\n",
            "Epoch: [117][320/329], lr: 0.01000\tTime 0.109 (0.091)\tData 0.064 (0.009)\tLoss 0.2781 (0.2608)\tPrec@1 90.234 (91.246)\tPrec@5 100.000 (99.724)\n",
            "Test: [0/100]\tTime 0.356 (0.356)\tLoss 0.7544 (0.7544)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.040 (0.061)\tLoss 1.0329 (1.0080)\tPrec@1 75.000 (69.545)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.019 (0.044)\tLoss 1.0541 (1.0066)\tPrec@1 66.000 (70.476)\tPrec@5 100.000 (97.857)\n",
            "Test: [30/100]\tTime 0.011 (0.037)\tLoss 1.1868 (1.0228)\tPrec@1 66.000 (70.323)\tPrec@5 98.000 (97.710)\n",
            "Test: [40/100]\tTime 0.039 (0.035)\tLoss 1.0951 (1.0364)\tPrec@1 68.000 (70.220)\tPrec@5 99.000 (97.415)\n",
            "Test: [50/100]\tTime 0.035 (0.033)\tLoss 0.9474 (1.0242)\tPrec@1 68.000 (70.235)\tPrec@5 99.000 (97.647)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 1.0254 (1.0334)\tPrec@1 72.000 (70.066)\tPrec@5 99.000 (97.787)\n",
            "Test: [70/100]\tTime 0.039 (0.031)\tLoss 0.8747 (1.0192)\tPrec@1 72.000 (70.239)\tPrec@5 98.000 (97.845)\n",
            "Test: [80/100]\tTime 0.032 (0.030)\tLoss 0.9686 (1.0171)\tPrec@1 70.000 (70.346)\tPrec@5 100.000 (97.938)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 0.9780 (1.0257)\tPrec@1 71.000 (70.088)\tPrec@5 98.000 (97.868)\n",
            "val Results: Prec@1 70.240 Prec@5 97.870 Loss 1.02603\n",
            "val Class Accuracy: [0.881,0.871,0.786,0.926,0.718,0.306,0.738,0.594,0.724,0.480]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [118][0/329], lr: 0.01000\tTime 0.674 (0.674)\tData 0.590 (0.590)\tLoss 0.2534 (0.2534)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [118][10/329], lr: 0.01000\tTime 0.087 (0.154)\tData 0.000 (0.061)\tLoss 0.3773 (0.4881)\tPrec@1 86.719 (84.624)\tPrec@5 99.609 (98.793)\n",
            "Epoch: [118][20/329], lr: 0.01000\tTime 0.083 (0.123)\tData 0.012 (0.035)\tLoss 0.4050 (0.4486)\tPrec@1 86.328 (86.235)\tPrec@5 99.219 (99.014)\n",
            "Epoch: [118][30/329], lr: 0.01000\tTime 0.103 (0.113)\tData 0.000 (0.026)\tLoss 0.2795 (0.4112)\tPrec@1 91.406 (87.122)\tPrec@5 99.609 (99.194)\n",
            "Epoch: [118][40/329], lr: 0.01000\tTime 0.096 (0.107)\tData 0.000 (0.021)\tLoss 0.2579 (0.3846)\tPrec@1 92.188 (87.843)\tPrec@5 99.609 (99.295)\n",
            "Epoch: [118][50/329], lr: 0.01000\tTime 0.078 (0.103)\tData 0.006 (0.018)\tLoss 0.3165 (0.3682)\tPrec@1 89.453 (88.235)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [118][60/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.010 (0.016)\tLoss 0.2981 (0.3581)\tPrec@1 91.016 (88.448)\tPrec@5 99.609 (99.392)\n",
            "Epoch: [118][70/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.006 (0.015)\tLoss 0.2775 (0.3468)\tPrec@1 90.625 (88.809)\tPrec@5 100.000 (99.433)\n",
            "Epoch: [118][80/329], lr: 0.01000\tTime 0.093 (0.098)\tData 0.006 (0.015)\tLoss 0.3385 (0.3381)\tPrec@1 90.625 (89.101)\tPrec@5 99.219 (99.450)\n",
            "Epoch: [118][90/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.009 (0.014)\tLoss 0.2924 (0.3312)\tPrec@1 92.188 (89.294)\tPrec@5 99.609 (99.459)\n",
            "Epoch: [118][100/329], lr: 0.01000\tTime 0.097 (0.096)\tData 0.007 (0.013)\tLoss 0.2524 (0.3241)\tPrec@1 92.188 (89.503)\tPrec@5 99.609 (99.493)\n",
            "Epoch: [118][110/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.008 (0.012)\tLoss 0.3217 (0.3216)\tPrec@1 88.672 (89.573)\tPrec@5 100.000 (99.500)\n",
            "Epoch: [118][120/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.006 (0.012)\tLoss 0.2621 (0.3151)\tPrec@1 91.406 (89.766)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [118][130/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.000 (0.012)\tLoss 0.2658 (0.3110)\tPrec@1 91.406 (89.897)\tPrec@5 100.000 (99.523)\n",
            "Epoch: [118][140/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.005 (0.011)\tLoss 0.2341 (0.3084)\tPrec@1 92.188 (89.963)\tPrec@5 100.000 (99.535)\n",
            "Epoch: [118][150/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.003 (0.011)\tLoss 0.2962 (0.3066)\tPrec@1 91.016 (90.025)\tPrec@5 99.609 (99.547)\n",
            "Epoch: [118][160/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.011)\tLoss 0.2602 (0.3039)\tPrec@1 91.406 (90.149)\tPrec@5 99.609 (99.554)\n",
            "Epoch: [118][170/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.005 (0.010)\tLoss 0.2491 (0.3009)\tPrec@1 91.406 (90.244)\tPrec@5 99.219 (99.555)\n",
            "Epoch: [118][180/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.011 (0.010)\tLoss 0.2783 (0.2991)\tPrec@1 87.891 (90.256)\tPrec@5 100.000 (99.564)\n",
            "Epoch: [118][190/329], lr: 0.01000\tTime 0.071 (0.093)\tData 0.004 (0.010)\tLoss 0.3339 (0.2964)\tPrec@1 88.672 (90.343)\tPrec@5 99.609 (99.579)\n",
            "Epoch: [118][200/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.000 (0.010)\tLoss 0.2204 (0.2936)\tPrec@1 94.531 (90.409)\tPrec@5 99.219 (99.584)\n",
            "Epoch: [118][210/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.004 (0.010)\tLoss 0.2626 (0.2925)\tPrec@1 90.234 (90.407)\tPrec@5 99.609 (99.585)\n",
            "Epoch: [118][220/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.005 (0.010)\tLoss 0.2877 (0.2904)\tPrec@1 91.797 (90.469)\tPrec@5 100.000 (99.592)\n",
            "Epoch: [118][230/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.2201 (0.2892)\tPrec@1 92.578 (90.495)\tPrec@5 99.609 (99.596)\n",
            "Epoch: [118][240/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.006 (0.010)\tLoss 0.3333 (0.2886)\tPrec@1 89.062 (90.489)\tPrec@5 99.219 (99.593)\n",
            "Epoch: [118][250/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.007 (0.009)\tLoss 0.2441 (0.2875)\tPrec@1 92.188 (90.522)\tPrec@5 100.000 (99.598)\n",
            "Epoch: [118][260/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.009)\tLoss 0.2470 (0.2860)\tPrec@1 92.188 (90.570)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [118][270/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.006 (0.009)\tLoss 0.2565 (0.2853)\tPrec@1 91.406 (90.566)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [118][280/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.001 (0.009)\tLoss 0.3255 (0.2845)\tPrec@1 89.062 (90.594)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [118][290/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.005 (0.009)\tLoss 0.1710 (0.2831)\tPrec@1 95.312 (90.634)\tPrec@5 100.000 (99.616)\n",
            "Epoch: [118][300/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.007 (0.009)\tLoss 0.2159 (0.2821)\tPrec@1 92.969 (90.660)\tPrec@5 99.609 (99.621)\n",
            "Epoch: [118][310/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.013 (0.009)\tLoss 0.2448 (0.2804)\tPrec@1 92.578 (90.719)\tPrec@5 99.609 (99.628)\n",
            "Epoch: [118][320/329], lr: 0.01000\tTime 0.072 (0.091)\tData 0.033 (0.009)\tLoss 0.2781 (0.2791)\tPrec@1 90.234 (90.755)\tPrec@5 99.609 (99.631)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.5904 (0.5904)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.037 (0.055)\tLoss 0.7472 (0.7470)\tPrec@1 80.000 (77.727)\tPrec@5 99.000 (98.727)\n",
            "Test: [20/100]\tTime 0.014 (0.043)\tLoss 0.7442 (0.7490)\tPrec@1 79.000 (78.000)\tPrec@5 98.000 (98.524)\n",
            "Test: [30/100]\tTime 0.025 (0.037)\tLoss 0.7778 (0.7570)\tPrec@1 75.000 (77.710)\tPrec@5 99.000 (98.452)\n",
            "Test: [40/100]\tTime 0.026 (0.034)\tLoss 0.7686 (0.7609)\tPrec@1 75.000 (77.537)\tPrec@5 98.000 (98.341)\n",
            "Test: [50/100]\tTime 0.025 (0.033)\tLoss 0.6956 (0.7563)\tPrec@1 78.000 (77.588)\tPrec@5 98.000 (98.373)\n",
            "Test: [60/100]\tTime 0.037 (0.031)\tLoss 0.6939 (0.7564)\tPrec@1 76.000 (77.426)\tPrec@5 99.000 (98.295)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 0.7431 (0.7529)\tPrec@1 81.000 (77.282)\tPrec@5 99.000 (98.352)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 0.6571 (0.7468)\tPrec@1 85.000 (77.543)\tPrec@5 96.000 (98.395)\n",
            "Test: [90/100]\tTime 0.021 (0.029)\tLoss 0.7907 (0.7561)\tPrec@1 80.000 (77.319)\tPrec@5 100.000 (98.385)\n",
            "val Results: Prec@1 77.290 Prec@5 98.380 Loss 0.75837\n",
            "val Class Accuracy: [0.937,0.990,0.764,0.723,0.728,0.764,0.851,0.709,0.616,0.647]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [119][0/329], lr: 0.01000\tTime 0.673 (0.673)\tData 0.570 (0.570)\tLoss 0.1921 (0.1921)\tPrec@1 93.750 (93.750)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [119][10/329], lr: 0.01000\tTime 0.123 (0.154)\tData 0.012 (0.058)\tLoss 0.1468 (0.2171)\tPrec@1 95.703 (93.146)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [119][20/329], lr: 0.01000\tTime 0.085 (0.124)\tData 0.000 (0.032)\tLoss 0.2611 (0.2270)\tPrec@1 91.406 (92.727)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [119][30/329], lr: 0.01000\tTime 0.083 (0.113)\tData 0.000 (0.024)\tLoss 0.3053 (0.2290)\tPrec@1 89.844 (92.654)\tPrec@5 98.828 (99.773)\n",
            "Epoch: [119][40/329], lr: 0.01000\tTime 0.088 (0.107)\tData 0.014 (0.020)\tLoss 0.1995 (0.2255)\tPrec@1 93.750 (92.664)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [119][50/329], lr: 0.01000\tTime 0.085 (0.103)\tData 0.001 (0.018)\tLoss 0.3496 (0.2332)\tPrec@1 88.281 (92.387)\tPrec@5 99.609 (99.747)\n",
            "Epoch: [119][60/329], lr: 0.01000\tTime 0.064 (0.100)\tData 0.000 (0.016)\tLoss 0.2363 (0.2319)\tPrec@1 92.188 (92.348)\tPrec@5 100.000 (99.757)\n",
            "Epoch: [119][70/329], lr: 0.01000\tTime 0.097 (0.099)\tData 0.006 (0.015)\tLoss 0.2102 (0.2335)\tPrec@1 92.578 (92.309)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [119][80/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.000 (0.014)\tLoss 0.1701 (0.2336)\tPrec@1 96.094 (92.347)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [119][90/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.004 (0.013)\tLoss 0.2850 (0.2366)\tPrec@1 90.625 (92.248)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [119][100/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.007 (0.013)\tLoss 0.2041 (0.2361)\tPrec@1 93.359 (92.269)\tPrec@5 100.000 (99.756)\n",
            "Epoch: [119][110/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.013)\tLoss 0.2362 (0.2374)\tPrec@1 91.797 (92.209)\tPrec@5 100.000 (99.764)\n",
            "Epoch: [119][120/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.007 (0.012)\tLoss 0.2576 (0.2361)\tPrec@1 90.625 (92.236)\tPrec@5 100.000 (99.764)\n",
            "Epoch: [119][130/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.003 (0.012)\tLoss 0.2528 (0.2372)\tPrec@1 91.406 (92.161)\tPrec@5 99.219 (99.755)\n",
            "Epoch: [119][140/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.005 (0.011)\tLoss 0.2713 (0.2370)\tPrec@1 92.188 (92.165)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [119][150/329], lr: 0.01000\tTime 0.105 (0.094)\tData 0.000 (0.011)\tLoss 0.2390 (0.2374)\tPrec@1 93.359 (92.169)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [119][160/329], lr: 0.01000\tTime 0.068 (0.094)\tData 0.006 (0.011)\tLoss 0.2737 (0.2381)\tPrec@1 89.453 (92.151)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [119][170/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.011)\tLoss 0.2603 (0.2390)\tPrec@1 91.016 (92.135)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [119][180/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.005 (0.010)\tLoss 0.2663 (0.2392)\tPrec@1 91.016 (92.116)\tPrec@5 99.219 (99.737)\n",
            "Epoch: [119][190/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.014 (0.010)\tLoss 0.2100 (0.2398)\tPrec@1 93.750 (92.102)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [119][200/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.007 (0.010)\tLoss 0.2360 (0.2397)\tPrec@1 92.188 (92.108)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [119][210/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.007 (0.010)\tLoss 0.2258 (0.2410)\tPrec@1 91.016 (92.069)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [119][220/329], lr: 0.01000\tTime 0.066 (0.092)\tData 0.004 (0.010)\tLoss 0.2924 (0.2422)\tPrec@1 92.188 (92.020)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [119][230/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.009 (0.010)\tLoss 0.2581 (0.2418)\tPrec@1 92.188 (92.029)\tPrec@5 100.000 (99.726)\n",
            "Epoch: [119][240/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.005 (0.010)\tLoss 0.2189 (0.2419)\tPrec@1 93.359 (92.030)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [119][250/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.010)\tLoss 0.2768 (0.2423)\tPrec@1 91.406 (92.043)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [119][260/329], lr: 0.01000\tTime 0.119 (0.092)\tData 0.004 (0.010)\tLoss 0.1949 (0.2424)\tPrec@1 94.531 (92.035)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [119][270/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.008 (0.009)\tLoss 0.3118 (0.2427)\tPrec@1 89.453 (92.028)\tPrec@5 99.609 (99.735)\n",
            "Epoch: [119][280/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.001 (0.009)\tLoss 0.2824 (0.2422)\tPrec@1 89.453 (92.042)\tPrec@5 100.000 (99.739)\n",
            "Epoch: [119][290/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.009)\tLoss 0.2010 (0.2417)\tPrec@1 94.531 (92.064)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [119][300/329], lr: 0.01000\tTime 0.128 (0.092)\tData 0.008 (0.009)\tLoss 0.2457 (0.2419)\tPrec@1 91.016 (92.040)\tPrec@5 99.219 (99.738)\n",
            "Epoch: [119][310/329], lr: 0.01000\tTime 0.127 (0.093)\tData 0.000 (0.009)\tLoss 0.2106 (0.2422)\tPrec@1 92.188 (92.023)\tPrec@5 100.000 (99.735)\n",
            "Epoch: [119][320/329], lr: 0.01000\tTime 0.214 (0.095)\tData 0.109 (0.009)\tLoss 0.2617 (0.2423)\tPrec@1 90.625 (92.011)\tPrec@5 100.000 (99.735)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 1.0629 (1.0629)\tPrec@1 67.000 (67.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.029 (0.059)\tLoss 1.0512 (1.0740)\tPrec@1 69.000 (69.636)\tPrec@5 99.000 (98.000)\n",
            "Test: [20/100]\tTime 0.016 (0.041)\tLoss 0.8165 (1.0079)\tPrec@1 75.000 (71.095)\tPrec@5 100.000 (98.190)\n",
            "Test: [30/100]\tTime 0.027 (0.036)\tLoss 1.2807 (1.0081)\tPrec@1 62.000 (70.935)\tPrec@5 97.000 (98.226)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 1.0530 (1.0084)\tPrec@1 72.000 (71.122)\tPrec@5 99.000 (98.146)\n",
            "Test: [50/100]\tTime 0.031 (0.033)\tLoss 1.2858 (1.0087)\tPrec@1 71.000 (71.137)\tPrec@5 96.000 (98.255)\n",
            "Test: [60/100]\tTime 0.015 (0.032)\tLoss 0.8776 (1.0154)\tPrec@1 77.000 (70.967)\tPrec@5 99.000 (98.377)\n",
            "Test: [70/100]\tTime 0.016 (0.031)\tLoss 0.9856 (1.0182)\tPrec@1 71.000 (70.859)\tPrec@5 100.000 (98.380)\n",
            "Test: [80/100]\tTime 0.015 (0.030)\tLoss 0.9857 (1.0146)\tPrec@1 71.000 (71.086)\tPrec@5 97.000 (98.370)\n",
            "Test: [90/100]\tTime 0.018 (0.030)\tLoss 0.8287 (1.0279)\tPrec@1 75.000 (70.681)\tPrec@5 98.000 (98.352)\n",
            "val Results: Prec@1 70.660 Prec@5 98.400 Loss 1.02190\n",
            "val Class Accuracy: [0.810,0.880,0.803,0.454,0.690,0.918,0.450,0.547,0.690,0.824]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [120][0/329], lr: 0.01000\tTime 0.705 (0.705)\tData 0.608 (0.608)\tLoss 0.3158 (0.3158)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [120][10/329], lr: 0.01000\tTime 0.080 (0.148)\tData 0.000 (0.060)\tLoss 0.3462 (0.4291)\tPrec@1 91.797 (86.186)\tPrec@5 98.438 (99.183)\n",
            "Epoch: [120][20/329], lr: 0.01000\tTime 0.102 (0.126)\tData 0.005 (0.035)\tLoss 0.3585 (0.3866)\tPrec@1 85.938 (87.072)\tPrec@5 99.609 (99.405)\n",
            "Epoch: [120][30/329], lr: 0.01000\tTime 0.081 (0.114)\tData 0.006 (0.026)\tLoss 0.2809 (0.3649)\tPrec@1 89.453 (87.727)\tPrec@5 100.000 (99.534)\n",
            "Epoch: [120][40/329], lr: 0.01000\tTime 0.079 (0.109)\tData 0.000 (0.022)\tLoss 0.2659 (0.3433)\tPrec@1 92.188 (88.338)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [120][50/329], lr: 0.01000\tTime 0.075 (0.105)\tData 0.007 (0.019)\tLoss 0.2460 (0.3258)\tPrec@1 92.578 (89.009)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [120][60/329], lr: 0.01000\tTime 0.074 (0.103)\tData 0.003 (0.017)\tLoss 0.2300 (0.3140)\tPrec@1 91.797 (89.421)\tPrec@5 100.000 (99.654)\n",
            "Epoch: [120][70/329], lr: 0.01000\tTime 0.085 (0.101)\tData 0.007 (0.016)\tLoss 0.2119 (0.3033)\tPrec@1 93.359 (89.816)\tPrec@5 100.000 (99.642)\n",
            "Epoch: [120][80/329], lr: 0.01000\tTime 0.101 (0.100)\tData 0.005 (0.015)\tLoss 0.2613 (0.2951)\tPrec@1 92.578 (90.085)\tPrec@5 99.609 (99.672)\n",
            "Epoch: [120][90/329], lr: 0.01000\tTime 0.071 (0.099)\tData 0.001 (0.014)\tLoss 0.2946 (0.2890)\tPrec@1 88.281 (90.247)\tPrec@5 99.609 (99.674)\n",
            "Epoch: [120][100/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.004 (0.013)\tLoss 0.2866 (0.2844)\tPrec@1 92.188 (90.408)\tPrec@5 100.000 (99.679)\n",
            "Epoch: [120][110/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.007 (0.012)\tLoss 0.1644 (0.2802)\tPrec@1 94.922 (90.586)\tPrec@5 100.000 (99.690)\n",
            "Epoch: [120][120/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.010 (0.012)\tLoss 0.2592 (0.2786)\tPrec@1 90.625 (90.673)\tPrec@5 100.000 (99.700)\n",
            "Epoch: [120][130/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.005 (0.012)\tLoss 0.3148 (0.2766)\tPrec@1 90.625 (90.726)\tPrec@5 99.609 (99.702)\n",
            "Epoch: [120][140/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.011)\tLoss 0.2921 (0.2732)\tPrec@1 91.797 (90.855)\tPrec@5 100.000 (99.706)\n",
            "Epoch: [120][150/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.007 (0.011)\tLoss 0.2071 (0.2718)\tPrec@1 91.016 (90.884)\tPrec@5 100.000 (99.713)\n",
            "Epoch: [120][160/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.001 (0.011)\tLoss 0.2663 (0.2710)\tPrec@1 91.406 (90.931)\tPrec@5 99.609 (99.714)\n",
            "Epoch: [120][170/329], lr: 0.01000\tTime 0.072 (0.095)\tData 0.005 (0.011)\tLoss 0.2740 (0.2695)\tPrec@1 89.844 (90.952)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [120][180/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.006 (0.010)\tLoss 0.1864 (0.2690)\tPrec@1 94.922 (90.947)\tPrec@5 100.000 (99.715)\n",
            "Epoch: [120][190/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.015 (0.010)\tLoss 0.2546 (0.2681)\tPrec@1 91.406 (90.950)\tPrec@5 99.609 (99.712)\n",
            "Epoch: [120][200/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.001 (0.010)\tLoss 0.2275 (0.2672)\tPrec@1 92.578 (90.998)\tPrec@5 99.609 (99.708)\n",
            "Epoch: [120][210/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.004 (0.010)\tLoss 0.3082 (0.2655)\tPrec@1 90.625 (91.064)\tPrec@5 99.609 (99.713)\n",
            "Epoch: [120][220/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.000 (0.010)\tLoss 0.2858 (0.2647)\tPrec@1 90.625 (91.102)\tPrec@5 99.219 (99.703)\n",
            "Epoch: [120][230/329], lr: 0.01000\tTime 0.067 (0.094)\tData 0.000 (0.010)\tLoss 0.2436 (0.2645)\tPrec@1 92.188 (91.122)\tPrec@5 100.000 (99.704)\n",
            "Epoch: [120][240/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.006 (0.010)\tLoss 0.2062 (0.2637)\tPrec@1 92.188 (91.139)\tPrec@5 100.000 (99.708)\n",
            "Epoch: [120][250/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.005 (0.010)\tLoss 0.2560 (0.2621)\tPrec@1 91.797 (91.209)\tPrec@5 99.219 (99.712)\n",
            "Epoch: [120][260/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.005 (0.009)\tLoss 0.2251 (0.2618)\tPrec@1 92.578 (91.209)\tPrec@5 99.609 (99.716)\n",
            "Epoch: [120][270/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.007 (0.009)\tLoss 0.2898 (0.2619)\tPrec@1 89.453 (91.229)\tPrec@5 99.219 (99.713)\n",
            "Epoch: [120][280/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.007 (0.009)\tLoss 0.2241 (0.2610)\tPrec@1 92.578 (91.251)\tPrec@5 99.609 (99.715)\n",
            "Epoch: [120][290/329], lr: 0.01000\tTime 0.069 (0.093)\tData 0.000 (0.009)\tLoss 0.1903 (0.2610)\tPrec@1 92.578 (91.224)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [120][300/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.005 (0.009)\tLoss 0.2990 (0.2611)\tPrec@1 91.797 (91.226)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [120][310/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.009 (0.009)\tLoss 0.2347 (0.2600)\tPrec@1 92.578 (91.263)\tPrec@5 100.000 (99.719)\n",
            "Epoch: [120][320/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.034 (0.009)\tLoss 0.2772 (0.2594)\tPrec@1 91.406 (91.274)\tPrec@5 100.000 (99.725)\n",
            "Test: [0/100]\tTime 0.376 (0.376)\tLoss 1.8437 (1.8437)\tPrec@1 57.000 (57.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.037 (0.059)\tLoss 1.5974 (1.9661)\tPrec@1 59.000 (56.000)\tPrec@5 93.000 (90.182)\n",
            "Test: [20/100]\tTime 0.022 (0.042)\tLoss 1.6511 (1.9444)\tPrec@1 57.000 (55.048)\tPrec@5 95.000 (91.048)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 1.9459 (1.9561)\tPrec@1 55.000 (55.194)\tPrec@5 92.000 (90.581)\n",
            "Test: [40/100]\tTime 0.025 (0.032)\tLoss 1.9191 (1.9673)\tPrec@1 55.000 (55.171)\tPrec@5 92.000 (90.415)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 1.8915 (1.9497)\tPrec@1 53.000 (55.471)\tPrec@5 86.000 (90.549)\n",
            "Test: [60/100]\tTime 0.039 (0.030)\tLoss 1.5192 (1.9507)\tPrec@1 64.000 (55.279)\tPrec@5 94.000 (90.393)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 2.0802 (1.9445)\tPrec@1 46.000 (55.056)\tPrec@5 90.000 (90.366)\n",
            "Test: [80/100]\tTime 0.042 (0.029)\tLoss 2.1687 (1.9386)\tPrec@1 54.000 (55.037)\tPrec@5 86.000 (90.370)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.7654 (1.9594)\tPrec@1 59.000 (54.769)\tPrec@5 93.000 (90.396)\n",
            "val Results: Prec@1 54.800 Prec@5 90.280 Loss 1.97190\n",
            "val Class Accuracy: [0.941,0.429,0.785,0.739,0.549,0.490,0.723,0.389,0.358,0.077]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [121][0/329], lr: 0.01000\tTime 0.652 (0.652)\tData 0.581 (0.581)\tLoss 0.2446 (0.2446)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][10/329], lr: 0.01000\tTime 0.087 (0.145)\tData 0.000 (0.057)\tLoss 0.6853 (0.7127)\tPrec@1 77.344 (77.024)\tPrec@5 99.219 (98.509)\n",
            "Epoch: [121][20/329], lr: 0.01000\tTime 0.100 (0.121)\tData 0.000 (0.033)\tLoss 0.4926 (0.5994)\tPrec@1 81.641 (80.190)\tPrec@5 99.219 (98.772)\n",
            "Epoch: [121][30/329], lr: 0.01000\tTime 0.090 (0.111)\tData 0.007 (0.024)\tLoss 0.3572 (0.5358)\tPrec@1 89.062 (82.497)\tPrec@5 99.219 (98.992)\n",
            "Epoch: [121][40/329], lr: 0.01000\tTime 0.081 (0.106)\tData 0.000 (0.020)\tLoss 0.3902 (0.4932)\tPrec@1 87.891 (83.975)\tPrec@5 99.609 (99.104)\n",
            "Epoch: [121][50/329], lr: 0.01000\tTime 0.080 (0.102)\tData 0.000 (0.017)\tLoss 0.2800 (0.4576)\tPrec@1 91.016 (85.072)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [121][60/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.006 (0.016)\tLoss 0.3069 (0.4344)\tPrec@1 89.844 (85.867)\tPrec@5 99.219 (99.270)\n",
            "Epoch: [121][70/329], lr: 0.01000\tTime 0.107 (0.099)\tData 0.007 (0.015)\tLoss 0.2694 (0.4181)\tPrec@1 91.406 (86.356)\tPrec@5 100.000 (99.318)\n",
            "Epoch: [121][80/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.007 (0.014)\tLoss 0.3237 (0.4005)\tPrec@1 90.234 (86.892)\tPrec@5 100.000 (99.363)\n",
            "Epoch: [121][90/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.012 (0.013)\tLoss 0.3164 (0.3872)\tPrec@1 89.453 (87.272)\tPrec@5 99.609 (99.399)\n",
            "Epoch: [121][100/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.000 (0.013)\tLoss 0.2437 (0.3780)\tPrec@1 90.625 (87.550)\tPrec@5 100.000 (99.412)\n",
            "Epoch: [121][110/329], lr: 0.01000\tTime 0.076 (0.095)\tData 0.001 (0.012)\tLoss 0.1933 (0.3701)\tPrec@1 95.703 (87.792)\tPrec@5 99.609 (99.447)\n",
            "Epoch: [121][120/329], lr: 0.01000\tTime 0.069 (0.094)\tData 0.000 (0.012)\tLoss 0.2925 (0.3616)\tPrec@1 91.016 (88.094)\tPrec@5 99.609 (99.461)\n",
            "Epoch: [121][130/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.006 (0.011)\tLoss 0.2842 (0.3573)\tPrec@1 88.672 (88.195)\tPrec@5 98.438 (99.478)\n",
            "Epoch: [121][140/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.005 (0.011)\tLoss 0.2923 (0.3515)\tPrec@1 89.844 (88.339)\tPrec@5 99.219 (99.499)\n",
            "Epoch: [121][150/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.000 (0.011)\tLoss 0.1934 (0.3458)\tPrec@1 92.969 (88.530)\tPrec@5 100.000 (99.519)\n",
            "Epoch: [121][160/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.008 (0.011)\tLoss 0.3511 (0.3414)\tPrec@1 88.672 (88.686)\tPrec@5 99.609 (99.534)\n",
            "Epoch: [121][170/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.000 (0.010)\tLoss 0.2845 (0.3368)\tPrec@1 91.016 (88.800)\tPrec@5 100.000 (99.545)\n",
            "Epoch: [121][180/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.005 (0.010)\tLoss 0.2324 (0.3333)\tPrec@1 91.797 (88.907)\tPrec@5 100.000 (99.558)\n",
            "Epoch: [121][190/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.002 (0.010)\tLoss 0.1916 (0.3290)\tPrec@1 92.969 (89.024)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [121][200/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.007 (0.010)\tLoss 0.2886 (0.3248)\tPrec@1 91.016 (89.171)\tPrec@5 100.000 (99.582)\n",
            "Epoch: [121][210/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.006 (0.010)\tLoss 0.3233 (0.3221)\tPrec@1 89.453 (89.242)\tPrec@5 98.828 (99.580)\n",
            "Epoch: [121][220/329], lr: 0.01000\tTime 0.106 (0.092)\tData 0.002 (0.010)\tLoss 0.2798 (0.3197)\tPrec@1 91.406 (89.344)\tPrec@5 99.219 (99.585)\n",
            "Epoch: [121][230/329], lr: 0.01000\tTime 0.101 (0.092)\tData 0.006 (0.010)\tLoss 0.2595 (0.3164)\tPrec@1 92.188 (89.455)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [121][240/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.000 (0.010)\tLoss 0.2590 (0.3144)\tPrec@1 91.016 (89.534)\tPrec@5 100.000 (99.605)\n",
            "Epoch: [121][250/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 0.2223 (0.3123)\tPrec@1 92.578 (89.604)\tPrec@5 99.219 (99.606)\n",
            "Epoch: [121][260/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.004 (0.009)\tLoss 0.2800 (0.3111)\tPrec@1 89.453 (89.649)\tPrec@5 99.609 (99.614)\n",
            "Epoch: [121][270/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.012 (0.009)\tLoss 0.2343 (0.3091)\tPrec@1 92.188 (89.713)\tPrec@5 99.219 (99.621)\n",
            "Epoch: [121][280/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.007 (0.009)\tLoss 0.2730 (0.3066)\tPrec@1 91.797 (89.799)\tPrec@5 98.828 (99.623)\n",
            "Epoch: [121][290/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.010 (0.009)\tLoss 0.3122 (0.3056)\tPrec@1 90.625 (89.834)\tPrec@5 99.609 (99.625)\n",
            "Epoch: [121][300/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.009 (0.009)\tLoss 0.2844 (0.3032)\tPrec@1 91.406 (89.907)\tPrec@5 99.609 (99.626)\n",
            "Epoch: [121][310/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.007 (0.009)\tLoss 0.2426 (0.3011)\tPrec@1 91.406 (89.968)\tPrec@5 100.000 (99.637)\n",
            "Epoch: [121][320/329], lr: 0.01000\tTime 0.102 (0.091)\tData 0.063 (0.009)\tLoss 0.2138 (0.2995)\tPrec@1 93.359 (90.013)\tPrec@5 99.609 (99.639)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 1.1040 (1.1040)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.031 (0.060)\tLoss 1.1494 (1.2110)\tPrec@1 70.000 (63.545)\tPrec@5 100.000 (97.182)\n",
            "Test: [20/100]\tTime 0.011 (0.040)\tLoss 1.1812 (1.1529)\tPrec@1 64.000 (65.524)\tPrec@5 98.000 (97.143)\n",
            "Test: [30/100]\tTime 0.042 (0.036)\tLoss 1.2045 (1.1517)\tPrec@1 67.000 (66.323)\tPrec@5 95.000 (97.097)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 1.3730 (1.1819)\tPrec@1 66.000 (65.512)\tPrec@5 95.000 (96.878)\n",
            "Test: [50/100]\tTime 0.032 (0.032)\tLoss 1.0564 (1.1717)\tPrec@1 67.000 (65.725)\tPrec@5 97.000 (97.020)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 1.4167 (1.1885)\tPrec@1 64.000 (65.311)\tPrec@5 97.000 (97.049)\n",
            "Test: [70/100]\tTime 0.034 (0.030)\tLoss 1.1363 (1.1896)\tPrec@1 68.000 (65.521)\tPrec@5 99.000 (97.183)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 1.0498 (1.1875)\tPrec@1 68.000 (65.556)\tPrec@5 97.000 (97.185)\n",
            "Test: [90/100]\tTime 0.039 (0.028)\tLoss 1.2808 (1.2010)\tPrec@1 64.000 (65.462)\tPrec@5 98.000 (97.154)\n",
            "val Results: Prec@1 65.240 Prec@5 97.180 Loss 1.20122\n",
            "val Class Accuracy: [0.572,0.995,0.532,0.641,0.854,0.478,0.645,0.521,0.677,0.609]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [122][0/329], lr: 0.01000\tTime 0.646 (0.646)\tData 0.585 (0.585)\tLoss 0.4920 (0.4920)\tPrec@1 83.203 (83.203)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [122][10/329], lr: 0.01000\tTime 0.106 (0.145)\tData 0.000 (0.059)\tLoss 0.6912 (0.8342)\tPrec@1 77.734 (73.722)\tPrec@5 97.266 (98.509)\n",
            "Epoch: [122][20/329], lr: 0.01000\tTime 0.092 (0.119)\tData 0.004 (0.034)\tLoss 0.5376 (0.6855)\tPrec@1 80.469 (78.237)\tPrec@5 99.609 (98.828)\n",
            "Epoch: [122][30/329], lr: 0.01000\tTime 0.091 (0.111)\tData 0.001 (0.025)\tLoss 0.4332 (0.6090)\tPrec@1 85.547 (80.418)\tPrec@5 100.000 (98.979)\n",
            "Epoch: [122][40/329], lr: 0.01000\tTime 0.099 (0.106)\tData 0.004 (0.020)\tLoss 0.4167 (0.5540)\tPrec@1 84.766 (81.917)\tPrec@5 99.219 (99.038)\n",
            "Epoch: [122][50/329], lr: 0.01000\tTime 0.075 (0.103)\tData 0.005 (0.018)\tLoss 0.4081 (0.5200)\tPrec@1 87.500 (83.027)\tPrec@5 99.219 (99.104)\n",
            "Epoch: [122][60/329], lr: 0.01000\tTime 0.072 (0.101)\tData 0.001 (0.016)\tLoss 0.2623 (0.4852)\tPrec@1 91.797 (84.061)\tPrec@5 99.219 (99.161)\n",
            "Epoch: [122][70/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.007 (0.015)\tLoss 0.3349 (0.4621)\tPrec@1 89.844 (84.881)\tPrec@5 99.219 (99.202)\n",
            "Epoch: [122][80/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.001 (0.014)\tLoss 0.2744 (0.4461)\tPrec@1 90.234 (85.340)\tPrec@5 99.609 (99.228)\n",
            "Epoch: [122][90/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.004 (0.013)\tLoss 0.2963 (0.4310)\tPrec@1 88.672 (85.826)\tPrec@5 100.000 (99.283)\n",
            "Epoch: [122][100/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.010 (0.012)\tLoss 0.2702 (0.4163)\tPrec@1 91.406 (86.305)\tPrec@5 99.609 (99.335)\n",
            "Epoch: [122][110/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.004 (0.012)\tLoss 0.3113 (0.4073)\tPrec@1 90.234 (86.610)\tPrec@5 99.219 (99.356)\n",
            "Epoch: [122][120/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.012)\tLoss 0.3446 (0.3959)\tPrec@1 87.500 (86.974)\tPrec@5 100.000 (99.377)\n",
            "Epoch: [122][130/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.004 (0.011)\tLoss 0.3402 (0.3863)\tPrec@1 90.625 (87.312)\tPrec@5 100.000 (99.389)\n",
            "Epoch: [122][140/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.006 (0.011)\tLoss 0.2110 (0.3801)\tPrec@1 92.969 (87.500)\tPrec@5 100.000 (99.415)\n",
            "Epoch: [122][150/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.005 (0.011)\tLoss 0.2734 (0.3722)\tPrec@1 90.625 (87.704)\tPrec@5 100.000 (99.441)\n",
            "Epoch: [122][160/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.008 (0.010)\tLoss 0.2231 (0.3655)\tPrec@1 91.797 (87.956)\tPrec@5 99.609 (99.464)\n",
            "Epoch: [122][170/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.000 (0.010)\tLoss 0.2560 (0.3596)\tPrec@1 91.016 (88.140)\tPrec@5 99.219 (99.481)\n",
            "Epoch: [122][180/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.006 (0.010)\tLoss 0.2696 (0.3544)\tPrec@1 90.234 (88.303)\tPrec@5 100.000 (99.497)\n",
            "Epoch: [122][190/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.000 (0.010)\tLoss 0.2557 (0.3499)\tPrec@1 91.797 (88.451)\tPrec@5 99.219 (99.497)\n",
            "Epoch: [122][200/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.005 (0.010)\tLoss 0.3362 (0.3459)\tPrec@1 89.453 (88.582)\tPrec@5 99.609 (99.506)\n",
            "Epoch: [122][210/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.011 (0.010)\tLoss 0.2822 (0.3427)\tPrec@1 90.234 (88.672)\tPrec@5 99.609 (99.509)\n",
            "Epoch: [122][220/329], lr: 0.01000\tTime 0.073 (0.092)\tData 0.007 (0.010)\tLoss 0.2951 (0.3391)\tPrec@1 89.844 (88.764)\tPrec@5 99.609 (99.517)\n",
            "Epoch: [122][230/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.007 (0.010)\tLoss 0.1754 (0.3368)\tPrec@1 93.750 (88.863)\tPrec@5 100.000 (99.520)\n",
            "Epoch: [122][240/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.006 (0.010)\tLoss 0.3070 (0.3344)\tPrec@1 89.844 (88.930)\tPrec@5 99.609 (99.523)\n",
            "Epoch: [122][250/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.007 (0.010)\tLoss 0.3284 (0.3322)\tPrec@1 91.406 (88.985)\tPrec@5 99.609 (99.530)\n",
            "Epoch: [122][260/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.007 (0.010)\tLoss 0.3417 (0.3299)\tPrec@1 90.234 (89.073)\tPrec@5 98.828 (99.532)\n",
            "Epoch: [122][270/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.005 (0.009)\tLoss 0.2652 (0.3271)\tPrec@1 91.406 (89.162)\tPrec@5 100.000 (99.546)\n",
            "Epoch: [122][280/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.000 (0.009)\tLoss 0.2802 (0.3257)\tPrec@1 91.797 (89.207)\tPrec@5 99.609 (99.557)\n",
            "Epoch: [122][290/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.005 (0.009)\tLoss 0.2105 (0.3241)\tPrec@1 92.969 (89.284)\tPrec@5 99.609 (99.557)\n",
            "Epoch: [122][300/329], lr: 0.01000\tTime 0.109 (0.091)\tData 0.000 (0.009)\tLoss 0.3044 (0.3224)\tPrec@1 90.625 (89.342)\tPrec@5 99.609 (99.557)\n",
            "Epoch: [122][310/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.001 (0.009)\tLoss 0.2355 (0.3199)\tPrec@1 93.750 (89.414)\tPrec@5 98.828 (99.560)\n",
            "Epoch: [122][320/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.064 (0.009)\tLoss 0.1993 (0.3186)\tPrec@1 94.531 (89.469)\tPrec@5 100.000 (99.562)\n",
            "Test: [0/100]\tTime 0.393 (0.393)\tLoss 0.8251 (0.8251)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.059)\tLoss 0.8950 (1.0279)\tPrec@1 77.000 (71.364)\tPrec@5 97.000 (97.636)\n",
            "Test: [20/100]\tTime 0.023 (0.042)\tLoss 1.0120 (0.9974)\tPrec@1 67.000 (71.381)\tPrec@5 100.000 (97.619)\n",
            "Test: [30/100]\tTime 0.020 (0.037)\tLoss 1.1258 (0.9977)\tPrec@1 69.000 (71.323)\tPrec@5 99.000 (97.387)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 1.0053 (1.0127)\tPrec@1 72.000 (71.268)\tPrec@5 99.000 (97.415)\n",
            "Test: [50/100]\tTime 0.010 (0.032)\tLoss 1.1239 (1.0088)\tPrec@1 75.000 (71.333)\tPrec@5 96.000 (97.333)\n",
            "Test: [60/100]\tTime 0.013 (0.030)\tLoss 0.8211 (1.0150)\tPrec@1 77.000 (70.918)\tPrec@5 98.000 (97.459)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 0.8179 (1.0066)\tPrec@1 75.000 (71.070)\tPrec@5 99.000 (97.380)\n",
            "Test: [80/100]\tTime 0.013 (0.028)\tLoss 0.9807 (0.9921)\tPrec@1 75.000 (71.321)\tPrec@5 99.000 (97.432)\n",
            "Test: [90/100]\tTime 0.040 (0.028)\tLoss 0.9611 (1.0063)\tPrec@1 72.000 (70.989)\tPrec@5 99.000 (97.341)\n",
            "val Results: Prec@1 71.080 Prec@5 97.290 Loss 1.00538\n",
            "val Class Accuracy: [0.822,0.920,0.895,0.804,0.759,0.704,0.587,0.451,0.585,0.581]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [123][0/329], lr: 0.01000\tTime 0.667 (0.667)\tData 0.575 (0.575)\tLoss 0.2113 (0.2113)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][10/329], lr: 0.01000\tTime 0.076 (0.149)\tData 0.000 (0.060)\tLoss 0.2196 (0.2255)\tPrec@1 91.016 (92.401)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [123][20/329], lr: 0.01000\tTime 0.094 (0.121)\tData 0.005 (0.035)\tLoss 0.2735 (0.2382)\tPrec@1 91.016 (92.076)\tPrec@5 99.609 (99.758)\n",
            "Epoch: [123][30/329], lr: 0.01000\tTime 0.099 (0.112)\tData 0.009 (0.026)\tLoss 0.2432 (0.2290)\tPrec@1 94.141 (92.528)\tPrec@5 99.609 (99.811)\n",
            "Epoch: [123][40/329], lr: 0.01000\tTime 0.109 (0.107)\tData 0.004 (0.021)\tLoss 0.1903 (0.2328)\tPrec@1 94.141 (92.283)\tPrec@5 99.609 (99.781)\n",
            "Epoch: [123][50/329], lr: 0.01000\tTime 0.100 (0.103)\tData 0.000 (0.018)\tLoss 0.2471 (0.2386)\tPrec@1 90.625 (91.889)\tPrec@5 99.609 (99.763)\n",
            "Epoch: [123][60/329], lr: 0.01000\tTime 0.089 (0.102)\tData 0.019 (0.016)\tLoss 0.2255 (0.2403)\tPrec@1 91.797 (91.778)\tPrec@5 99.609 (99.744)\n",
            "Epoch: [123][70/329], lr: 0.01000\tTime 0.109 (0.100)\tData 0.007 (0.015)\tLoss 0.2049 (0.2419)\tPrec@1 93.359 (91.764)\tPrec@5 100.000 (99.725)\n",
            "Epoch: [123][80/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.000 (0.014)\tLoss 0.2499 (0.2427)\tPrec@1 91.016 (91.739)\tPrec@5 100.000 (99.715)\n",
            "Epoch: [123][90/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.000 (0.013)\tLoss 0.2150 (0.2412)\tPrec@1 91.797 (91.763)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [123][100/329], lr: 0.01000\tTime 0.074 (0.098)\tData 0.010 (0.012)\tLoss 0.3204 (0.2426)\tPrec@1 92.969 (91.805)\tPrec@5 99.219 (99.725)\n",
            "Epoch: [123][110/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.003 (0.012)\tLoss 0.2168 (0.2418)\tPrec@1 92.188 (91.797)\tPrec@5 99.609 (99.733)\n",
            "Epoch: [123][120/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.006 (0.011)\tLoss 0.3129 (0.2411)\tPrec@1 89.453 (91.826)\tPrec@5 100.000 (99.739)\n",
            "Epoch: [123][130/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.007 (0.011)\tLoss 0.3082 (0.2424)\tPrec@1 89.453 (91.821)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [123][140/329], lr: 0.01000\tTime 0.115 (0.096)\tData 0.011 (0.011)\tLoss 0.2428 (0.2432)\tPrec@1 92.578 (91.813)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [123][150/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.007 (0.011)\tLoss 0.2455 (0.2442)\tPrec@1 92.578 (91.781)\tPrec@5 99.609 (99.731)\n",
            "Epoch: [123][160/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.013 (0.011)\tLoss 0.2019 (0.2454)\tPrec@1 92.188 (91.705)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [123][170/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.004 (0.011)\tLoss 0.1922 (0.2446)\tPrec@1 94.922 (91.733)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [123][180/329], lr: 0.01000\tTime 0.117 (0.094)\tData 0.000 (0.010)\tLoss 0.2234 (0.2446)\tPrec@1 92.188 (91.732)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [123][190/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 0.2557 (0.2445)\tPrec@1 92.578 (91.740)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [123][200/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.007 (0.010)\tLoss 0.2619 (0.2460)\tPrec@1 91.016 (91.678)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [123][210/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.007 (0.010)\tLoss 0.3583 (0.2474)\tPrec@1 89.453 (91.664)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [123][220/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.006 (0.010)\tLoss 0.2074 (0.2484)\tPrec@1 93.359 (91.643)\tPrec@5 99.609 (99.730)\n",
            "Epoch: [123][230/329], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.010)\tLoss 0.1601 (0.2486)\tPrec@1 95.312 (91.631)\tPrec@5 99.609 (99.731)\n",
            "Epoch: [123][240/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.009 (0.010)\tLoss 0.2733 (0.2491)\tPrec@1 91.016 (91.617)\tPrec@5 99.609 (99.733)\n",
            "Epoch: [123][250/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.005 (0.010)\tLoss 0.1948 (0.2488)\tPrec@1 94.531 (91.623)\tPrec@5 99.609 (99.734)\n",
            "Epoch: [123][260/329], lr: 0.01000\tTime 0.051 (0.093)\tData 0.008 (0.010)\tLoss 0.3051 (0.2496)\tPrec@1 91.016 (91.614)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [123][270/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.009)\tLoss 0.2838 (0.2506)\tPrec@1 91.016 (91.584)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [123][280/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.004 (0.009)\tLoss 0.2174 (0.2506)\tPrec@1 90.625 (91.580)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [123][290/329], lr: 0.01000\tTime 0.105 (0.093)\tData 0.000 (0.009)\tLoss 0.1892 (0.2500)\tPrec@1 93.359 (91.601)\tPrec@5 99.609 (99.734)\n",
            "Epoch: [123][300/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.010 (0.009)\tLoss 0.2519 (0.2496)\tPrec@1 92.969 (91.618)\tPrec@5 99.219 (99.733)\n",
            "Epoch: [123][310/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.000 (0.009)\tLoss 0.2873 (0.2498)\tPrec@1 90.234 (91.626)\tPrec@5 98.828 (99.725)\n",
            "Epoch: [123][320/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.031 (0.009)\tLoss 0.3861 (0.2504)\tPrec@1 87.109 (91.602)\tPrec@5 99.609 (99.723)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 1.5912 (1.5912)\tPrec@1 58.000 (58.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.021 (0.055)\tLoss 1.1036 (1.4925)\tPrec@1 68.000 (62.364)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/100]\tTime 0.048 (0.044)\tLoss 1.4799 (1.5438)\tPrec@1 66.000 (62.286)\tPrec@5 97.000 (97.048)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 1.5860 (1.5800)\tPrec@1 63.000 (61.806)\tPrec@5 96.000 (96.742)\n",
            "Test: [40/100]\tTime 0.034 (0.034)\tLoss 1.8339 (1.5991)\tPrec@1 64.000 (61.707)\tPrec@5 94.000 (96.683)\n",
            "Test: [50/100]\tTime 0.008 (0.032)\tLoss 1.2917 (1.5874)\tPrec@1 64.000 (61.745)\tPrec@5 97.000 (96.686)\n",
            "Test: [60/100]\tTime 0.029 (0.031)\tLoss 1.1426 (1.5842)\tPrec@1 71.000 (61.820)\tPrec@5 95.000 (96.639)\n",
            "Test: [70/100]\tTime 0.038 (0.030)\tLoss 1.8822 (1.5845)\tPrec@1 58.000 (61.789)\tPrec@5 96.000 (96.690)\n",
            "Test: [80/100]\tTime 0.037 (0.030)\tLoss 1.5683 (1.5770)\tPrec@1 59.000 (61.889)\tPrec@5 98.000 (96.716)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.7033 (1.6012)\tPrec@1 60.000 (61.560)\tPrec@5 99.000 (96.615)\n",
            "val Results: Prec@1 61.630 Prec@5 96.490 Loss 1.61034\n",
            "val Class Accuracy: [0.970,0.621,0.646,0.696,0.869,0.729,0.818,0.286,0.273,0.255]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [124][0/329], lr: 0.01000\tTime 1.023 (1.023)\tData 0.935 (0.935)\tLoss 0.3608 (0.3608)\tPrec@1 87.891 (87.891)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [124][10/329], lr: 0.01000\tTime 0.118 (0.203)\tData 0.009 (0.106)\tLoss 0.5673 (0.7624)\tPrec@1 79.688 (77.947)\tPrec@5 99.219 (98.970)\n",
            "Epoch: [124][20/329], lr: 0.01000\tTime 0.094 (0.161)\tData 0.000 (0.067)\tLoss 0.4361 (0.6798)\tPrec@1 88.672 (79.427)\tPrec@5 98.828 (98.865)\n",
            "Epoch: [124][30/329], lr: 0.01000\tTime 0.088 (0.140)\tData 0.005 (0.048)\tLoss 0.3942 (0.6062)\tPrec@1 86.719 (81.023)\tPrec@5 99.609 (98.979)\n",
            "Epoch: [124][40/329], lr: 0.01000\tTime 0.080 (0.128)\tData 0.003 (0.038)\tLoss 0.3660 (0.5633)\tPrec@1 89.844 (82.269)\tPrec@5 98.828 (98.990)\n",
            "Epoch: [124][50/329], lr: 0.01000\tTime 0.091 (0.122)\tData 0.005 (0.032)\tLoss 0.3141 (0.5215)\tPrec@1 90.234 (83.494)\tPrec@5 100.000 (99.081)\n",
            "Epoch: [124][60/329], lr: 0.01000\tTime 0.092 (0.117)\tData 0.003 (0.028)\tLoss 0.3456 (0.4915)\tPrec@1 90.234 (84.381)\tPrec@5 99.609 (99.142)\n",
            "Epoch: [124][70/329], lr: 0.01000\tTime 0.083 (0.113)\tData 0.006 (0.025)\tLoss 0.2338 (0.4674)\tPrec@1 91.016 (85.035)\tPrec@5 100.000 (99.235)\n",
            "Epoch: [124][80/329], lr: 0.01000\tTime 0.086 (0.110)\tData 0.011 (0.023)\tLoss 0.4175 (0.4482)\tPrec@1 87.891 (85.624)\tPrec@5 98.828 (99.262)\n",
            "Epoch: [124][90/329], lr: 0.01000\tTime 0.080 (0.107)\tData 0.008 (0.021)\tLoss 0.3495 (0.4334)\tPrec@1 87.891 (85.976)\tPrec@5 100.000 (99.322)\n",
            "Epoch: [124][100/329], lr: 0.01000\tTime 0.082 (0.106)\tData 0.007 (0.020)\tLoss 0.2921 (0.4194)\tPrec@1 92.188 (86.363)\tPrec@5 99.219 (99.350)\n",
            "Epoch: [124][110/329], lr: 0.01000\tTime 0.084 (0.104)\tData 0.004 (0.019)\tLoss 0.3451 (0.4080)\tPrec@1 87.109 (86.698)\tPrec@5 100.000 (99.374)\n",
            "Epoch: [124][120/329], lr: 0.01000\tTime 0.106 (0.102)\tData 0.010 (0.018)\tLoss 0.2964 (0.3969)\tPrec@1 89.453 (87.035)\tPrec@5 98.828 (99.403)\n",
            "Epoch: [124][130/329], lr: 0.01000\tTime 0.097 (0.101)\tData 0.004 (0.017)\tLoss 0.2888 (0.3902)\tPrec@1 90.234 (87.253)\tPrec@5 99.219 (99.407)\n",
            "Epoch: [124][140/329], lr: 0.01000\tTime 0.078 (0.101)\tData 0.007 (0.016)\tLoss 0.3184 (0.3809)\tPrec@1 85.938 (87.539)\tPrec@5 99.609 (99.424)\n",
            "Epoch: [124][150/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.000 (0.016)\tLoss 0.3346 (0.3744)\tPrec@1 90.234 (87.756)\tPrec@5 99.219 (99.428)\n",
            "Epoch: [124][160/329], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.016)\tLoss 0.2808 (0.3693)\tPrec@1 88.281 (87.898)\tPrec@5 99.609 (99.444)\n",
            "Epoch: [124][170/329], lr: 0.01000\tTime 0.100 (0.098)\tData 0.000 (0.015)\tLoss 0.2131 (0.3619)\tPrec@1 94.531 (88.128)\tPrec@5 100.000 (99.468)\n",
            "Epoch: [124][180/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.006 (0.015)\tLoss 0.2989 (0.3561)\tPrec@1 91.406 (88.348)\tPrec@5 99.219 (99.489)\n",
            "Epoch: [124][190/329], lr: 0.01000\tTime 0.078 (0.097)\tData 0.005 (0.014)\tLoss 0.2349 (0.3503)\tPrec@1 91.406 (88.523)\tPrec@5 100.000 (99.505)\n",
            "Epoch: [124][200/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.011 (0.014)\tLoss 0.2522 (0.3466)\tPrec@1 92.578 (88.635)\tPrec@5 99.609 (99.518)\n",
            "Epoch: [124][210/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.000 (0.014)\tLoss 0.1597 (0.3431)\tPrec@1 94.922 (88.763)\tPrec@5 99.609 (99.508)\n",
            "Epoch: [124][220/329], lr: 0.01000\tTime 0.112 (0.096)\tData 0.008 (0.013)\tLoss 0.3054 (0.3398)\tPrec@1 90.234 (88.843)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [124][230/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.010 (0.013)\tLoss 0.2548 (0.3362)\tPrec@1 88.672 (88.951)\tPrec@5 100.000 (99.532)\n",
            "Epoch: [124][240/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.005 (0.013)\tLoss 0.2639 (0.3337)\tPrec@1 92.578 (89.028)\tPrec@5 99.219 (99.543)\n",
            "Epoch: [124][250/329], lr: 0.01000\tTime 0.067 (0.096)\tData 0.000 (0.012)\tLoss 0.2031 (0.3307)\tPrec@1 91.797 (89.098)\tPrec@5 99.609 (99.547)\n",
            "Epoch: [124][260/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.012)\tLoss 0.3272 (0.3283)\tPrec@1 89.453 (89.163)\tPrec@5 99.609 (99.558)\n",
            "Epoch: [124][270/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.007 (0.012)\tLoss 0.1760 (0.3252)\tPrec@1 94.922 (89.270)\tPrec@5 100.000 (99.569)\n",
            "Epoch: [124][280/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.011 (0.012)\tLoss 0.3076 (0.3225)\tPrec@1 89.844 (89.332)\tPrec@5 99.609 (99.575)\n",
            "Epoch: [124][290/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.007 (0.012)\tLoss 0.1943 (0.3197)\tPrec@1 92.188 (89.416)\tPrec@5 100.000 (99.585)\n",
            "Epoch: [124][300/329], lr: 0.01000\tTime 0.102 (0.095)\tData 0.008 (0.012)\tLoss 0.2987 (0.3181)\tPrec@1 91.016 (89.465)\tPrec@5 99.609 (99.589)\n",
            "Epoch: [124][310/329], lr: 0.01000\tTime 0.062 (0.095)\tData 0.000 (0.011)\tLoss 0.2566 (0.3173)\tPrec@1 91.406 (89.483)\tPrec@5 99.219 (99.587)\n",
            "Epoch: [124][320/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.033 (0.011)\tLoss 0.2198 (0.3154)\tPrec@1 91.406 (89.550)\tPrec@5 100.000 (99.595)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 0.7174 (0.7174)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.028 (0.058)\tLoss 0.8350 (0.8575)\tPrec@1 78.000 (75.182)\tPrec@5 99.000 (98.000)\n",
            "Test: [20/100]\tTime 0.027 (0.042)\tLoss 0.7717 (0.8455)\tPrec@1 75.000 (75.333)\tPrec@5 100.000 (98.048)\n",
            "Test: [30/100]\tTime 0.012 (0.036)\tLoss 0.8957 (0.8353)\tPrec@1 70.000 (75.613)\tPrec@5 98.000 (98.194)\n",
            "Test: [40/100]\tTime 0.033 (0.033)\tLoss 0.8350 (0.8471)\tPrec@1 73.000 (75.585)\tPrec@5 98.000 (98.049)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 0.5204 (0.8378)\tPrec@1 85.000 (75.784)\tPrec@5 99.000 (97.941)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 0.7041 (0.8418)\tPrec@1 78.000 (75.557)\tPrec@5 99.000 (97.984)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 0.7170 (0.8347)\tPrec@1 82.000 (75.577)\tPrec@5 99.000 (98.113)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 0.7739 (0.8236)\tPrec@1 79.000 (75.753)\tPrec@5 99.000 (98.259)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 0.6970 (0.8375)\tPrec@1 80.000 (75.352)\tPrec@5 99.000 (98.242)\n",
            "val Results: Prec@1 75.310 Prec@5 98.250 Loss 0.83713\n",
            "val Class Accuracy: [0.954,0.958,0.849,0.481,0.823,0.762,0.683,0.737,0.614,0.670]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [125][0/329], lr: 0.01000\tTime 0.677 (0.677)\tData 0.588 (0.588)\tLoss 0.2798 (0.2798)\tPrec@1 90.234 (90.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][10/329], lr: 0.01000\tTime 0.118 (0.151)\tData 0.000 (0.060)\tLoss 0.2614 (0.2773)\tPrec@1 91.797 (90.518)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [125][20/329], lr: 0.01000\tTime 0.095 (0.123)\tData 0.004 (0.033)\tLoss 0.2576 (0.2666)\tPrec@1 93.750 (91.016)\tPrec@5 99.219 (99.702)\n",
            "Epoch: [125][30/329], lr: 0.01000\tTime 0.090 (0.114)\tData 0.012 (0.025)\tLoss 0.2559 (0.2603)\tPrec@1 91.797 (91.268)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [125][40/329], lr: 0.01000\tTime 0.077 (0.108)\tData 0.000 (0.020)\tLoss 0.2633 (0.2609)\tPrec@1 91.406 (91.216)\tPrec@5 99.609 (99.676)\n",
            "Epoch: [125][50/329], lr: 0.01000\tTime 0.097 (0.104)\tData 0.005 (0.018)\tLoss 0.1945 (0.2589)\tPrec@1 93.750 (91.291)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [125][60/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.000 (0.016)\tLoss 0.2628 (0.2530)\tPrec@1 91.016 (91.470)\tPrec@5 99.609 (99.731)\n",
            "Epoch: [125][70/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.000 (0.014)\tLoss 0.2075 (0.2507)\tPrec@1 93.359 (91.588)\tPrec@5 100.000 (99.719)\n",
            "Epoch: [125][80/329], lr: 0.01000\tTime 0.101 (0.099)\tData 0.007 (0.013)\tLoss 0.2035 (0.2513)\tPrec@1 92.188 (91.532)\tPrec@5 100.000 (99.735)\n",
            "Epoch: [125][90/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.003 (0.012)\tLoss 0.2539 (0.2495)\tPrec@1 91.797 (91.599)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [125][100/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.013 (0.012)\tLoss 0.2907 (0.2499)\tPrec@1 87.891 (91.565)\tPrec@5 99.219 (99.741)\n",
            "Epoch: [125][110/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.006 (0.012)\tLoss 0.2198 (0.2493)\tPrec@1 92.969 (91.596)\tPrec@5 99.609 (99.736)\n",
            "Epoch: [125][120/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.004 (0.011)\tLoss 0.2582 (0.2485)\tPrec@1 91.797 (91.648)\tPrec@5 99.609 (99.739)\n",
            "Epoch: [125][130/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.007 (0.011)\tLoss 0.3113 (0.2493)\tPrec@1 89.844 (91.642)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [125][140/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.011)\tLoss 0.3727 (0.2514)\tPrec@1 87.109 (91.556)\tPrec@5 98.828 (99.734)\n",
            "Epoch: [125][150/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.007 (0.010)\tLoss 0.2476 (0.2508)\tPrec@1 92.188 (91.593)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [125][160/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.006 (0.010)\tLoss 0.2185 (0.2507)\tPrec@1 92.969 (91.612)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [125][170/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.000 (0.010)\tLoss 0.1435 (0.2502)\tPrec@1 95.312 (91.632)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [125][180/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.004 (0.010)\tLoss 0.2489 (0.2496)\tPrec@1 91.016 (91.620)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [125][190/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.006 (0.010)\tLoss 0.2283 (0.2495)\tPrec@1 91.797 (91.637)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [125][200/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.002 (0.009)\tLoss 0.2516 (0.2501)\tPrec@1 92.969 (91.616)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [125][210/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 0.2587 (0.2501)\tPrec@1 90.234 (91.628)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [125][220/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.000 (0.009)\tLoss 0.2228 (0.2498)\tPrec@1 92.969 (91.655)\tPrec@5 99.609 (99.742)\n",
            "Epoch: [125][230/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.000 (0.009)\tLoss 0.2783 (0.2503)\tPrec@1 90.625 (91.611)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [125][240/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.000 (0.009)\tLoss 0.3287 (0.2511)\tPrec@1 88.281 (91.567)\tPrec@5 99.219 (99.739)\n",
            "Epoch: [125][250/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 0.3037 (0.2515)\tPrec@1 91.016 (91.565)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [125][260/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.007 (0.009)\tLoss 0.2876 (0.2516)\tPrec@1 89.844 (91.551)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [125][270/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.000 (0.009)\tLoss 0.2429 (0.2507)\tPrec@1 92.578 (91.601)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [125][280/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.006 (0.009)\tLoss 0.2159 (0.2501)\tPrec@1 92.969 (91.629)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [125][290/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.3549 (0.2500)\tPrec@1 90.234 (91.606)\tPrec@5 99.219 (99.741)\n",
            "Epoch: [125][300/329], lr: 0.01000\tTime 0.104 (0.092)\tData 0.006 (0.008)\tLoss 0.2909 (0.2495)\tPrec@1 91.016 (91.616)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [125][310/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.007 (0.008)\tLoss 0.2517 (0.2491)\tPrec@1 91.406 (91.646)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [125][320/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.063 (0.009)\tLoss 0.2653 (0.2489)\tPrec@1 91.016 (91.658)\tPrec@5 100.000 (99.742)\n",
            "Test: [0/100]\tTime 0.396 (0.396)\tLoss 0.7955 (0.7955)\tPrec@1 70.000 (70.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.015 (0.054)\tLoss 0.7525 (0.8484)\tPrec@1 78.000 (72.909)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.031 (0.041)\tLoss 0.8955 (0.9023)\tPrec@1 75.000 (73.286)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.028 (0.037)\tLoss 1.0556 (0.9115)\tPrec@1 69.000 (73.097)\tPrec@5 95.000 (97.548)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 0.9164 (0.9232)\tPrec@1 74.000 (72.732)\tPrec@5 94.000 (97.488)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 0.7183 (0.8992)\tPrec@1 78.000 (73.196)\tPrec@5 98.000 (97.510)\n",
            "Test: [60/100]\tTime 0.037 (0.030)\tLoss 0.8075 (0.9062)\tPrec@1 75.000 (72.820)\tPrec@5 98.000 (97.443)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 0.9346 (0.9052)\tPrec@1 74.000 (72.859)\tPrec@5 99.000 (97.549)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 0.7098 (0.8999)\tPrec@1 78.000 (73.025)\tPrec@5 98.000 (97.617)\n",
            "Test: [90/100]\tTime 0.021 (0.028)\tLoss 0.8197 (0.9051)\tPrec@1 74.000 (73.110)\tPrec@5 100.000 (97.626)\n",
            "val Results: Prec@1 73.220 Prec@5 97.610 Loss 0.90132\n",
            "val Class Accuracy: [0.884,0.962,0.765,0.722,0.775,0.553,0.687,0.540,0.758,0.676]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [126][0/329], lr: 0.01000\tTime 0.704 (0.704)\tData 0.622 (0.622)\tLoss 0.2446 (0.2446)\tPrec@1 91.016 (91.016)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [126][10/329], lr: 0.01000\tTime 0.074 (0.150)\tData 0.000 (0.063)\tLoss 0.7721 (0.7615)\tPrec@1 74.219 (77.592)\tPrec@5 97.656 (97.905)\n",
            "Epoch: [126][20/329], lr: 0.01000\tTime 0.079 (0.122)\tData 0.000 (0.037)\tLoss 0.5335 (0.6741)\tPrec@1 79.688 (79.036)\tPrec@5 100.000 (98.251)\n",
            "Epoch: [126][30/329], lr: 0.01000\tTime 0.088 (0.111)\tData 0.000 (0.028)\tLoss 0.4351 (0.6303)\tPrec@1 85.547 (80.103)\tPrec@5 99.219 (98.412)\n",
            "Epoch: [126][40/329], lr: 0.01000\tTime 0.086 (0.105)\tData 0.000 (0.023)\tLoss 0.3680 (0.5732)\tPrec@1 87.109 (81.755)\tPrec@5 99.219 (98.666)\n",
            "Epoch: [126][50/329], lr: 0.01000\tTime 0.092 (0.102)\tData 0.000 (0.019)\tLoss 0.3975 (0.5392)\tPrec@1 85.547 (82.621)\tPrec@5 100.000 (98.828)\n",
            "Epoch: [126][60/329], lr: 0.01000\tTime 0.090 (0.100)\tData 0.006 (0.017)\tLoss 0.3264 (0.5110)\tPrec@1 90.625 (83.440)\tPrec@5 100.000 (98.905)\n",
            "Epoch: [126][70/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.016 (0.016)\tLoss 0.2975 (0.4898)\tPrec@1 89.453 (84.034)\tPrec@5 100.000 (99.004)\n",
            "Epoch: [126][80/329], lr: 0.01000\tTime 0.115 (0.097)\tData 0.000 (0.015)\tLoss 0.3977 (0.4703)\tPrec@1 85.156 (84.606)\tPrec@5 99.609 (99.079)\n",
            "Epoch: [126][90/329], lr: 0.01000\tTime 0.067 (0.095)\tData 0.000 (0.014)\tLoss 0.3445 (0.4506)\tPrec@1 87.500 (85.169)\tPrec@5 99.219 (99.133)\n",
            "Epoch: [126][100/329], lr: 0.01000\tTime 0.102 (0.095)\tData 0.006 (0.013)\tLoss 0.3267 (0.4376)\tPrec@1 88.281 (85.582)\tPrec@5 100.000 (99.188)\n",
            "Epoch: [126][110/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.000 (0.013)\tLoss 0.3699 (0.4254)\tPrec@1 87.891 (85.906)\tPrec@5 100.000 (99.243)\n",
            "Epoch: [126][120/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.006 (0.012)\tLoss 0.2520 (0.4134)\tPrec@1 92.578 (86.328)\tPrec@5 99.609 (99.274)\n",
            "Epoch: [126][130/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.006 (0.012)\tLoss 0.2986 (0.4040)\tPrec@1 89.844 (86.617)\tPrec@5 100.000 (99.308)\n",
            "Epoch: [126][140/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.006 (0.012)\tLoss 0.2457 (0.3941)\tPrec@1 91.406 (86.932)\tPrec@5 99.609 (99.343)\n",
            "Epoch: [126][150/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.000 (0.011)\tLoss 0.3187 (0.3858)\tPrec@1 90.234 (87.192)\tPrec@5 100.000 (99.377)\n",
            "Epoch: [126][160/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.004 (0.011)\tLoss 0.3635 (0.3808)\tPrec@1 87.109 (87.340)\tPrec@5 99.219 (99.381)\n",
            "Epoch: [126][170/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.000 (0.011)\tLoss 0.2390 (0.3761)\tPrec@1 93.359 (87.498)\tPrec@5 99.609 (99.395)\n",
            "Epoch: [126][180/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.010)\tLoss 0.2739 (0.3712)\tPrec@1 90.625 (87.675)\tPrec@5 99.609 (99.400)\n",
            "Epoch: [126][190/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.2300 (0.3677)\tPrec@1 92.969 (87.809)\tPrec@5 100.000 (99.411)\n",
            "Epoch: [126][200/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.002 (0.010)\tLoss 0.2768 (0.3621)\tPrec@1 89.844 (87.947)\tPrec@5 100.000 (99.429)\n",
            "Epoch: [126][210/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.000 (0.010)\tLoss 0.2526 (0.3574)\tPrec@1 91.406 (88.109)\tPrec@5 100.000 (99.443)\n",
            "Epoch: [126][220/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.010)\tLoss 0.2589 (0.3526)\tPrec@1 93.359 (88.267)\tPrec@5 100.000 (99.461)\n",
            "Epoch: [126][230/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.006 (0.009)\tLoss 0.3724 (0.3489)\tPrec@1 89.062 (88.395)\tPrec@5 99.609 (99.476)\n",
            "Epoch: [126][240/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.006 (0.009)\tLoss 0.3189 (0.3466)\tPrec@1 90.234 (88.477)\tPrec@5 99.219 (99.483)\n",
            "Epoch: [126][250/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.000 (0.009)\tLoss 0.2368 (0.3432)\tPrec@1 91.406 (88.582)\tPrec@5 99.609 (99.494)\n",
            "Epoch: [126][260/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.000 (0.009)\tLoss 0.3310 (0.3403)\tPrec@1 90.625 (88.663)\tPrec@5 99.219 (99.500)\n",
            "Epoch: [126][270/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.005 (0.009)\tLoss 0.2498 (0.3373)\tPrec@1 89.453 (88.763)\tPrec@5 99.609 (99.504)\n",
            "Epoch: [126][280/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.004 (0.009)\tLoss 0.2571 (0.3345)\tPrec@1 92.188 (88.848)\tPrec@5 100.000 (99.509)\n",
            "Epoch: [126][290/329], lr: 0.01000\tTime 0.102 (0.091)\tData 0.000 (0.009)\tLoss 0.2267 (0.3315)\tPrec@1 92.188 (88.950)\tPrec@5 100.000 (99.518)\n",
            "Epoch: [126][300/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.012 (0.009)\tLoss 0.3305 (0.3290)\tPrec@1 87.500 (89.034)\tPrec@5 100.000 (99.521)\n",
            "Epoch: [126][310/329], lr: 0.01000\tTime 0.078 (0.090)\tData 0.000 (0.009)\tLoss 0.3235 (0.3271)\tPrec@1 88.281 (89.088)\tPrec@5 98.828 (99.525)\n",
            "Epoch: [126][320/329], lr: 0.01000\tTime 0.098 (0.090)\tData 0.063 (0.009)\tLoss 0.2260 (0.3250)\tPrec@1 92.578 (89.146)\tPrec@5 100.000 (99.535)\n",
            "Test: [0/100]\tTime 0.369 (0.369)\tLoss 0.7500 (0.7500)\tPrec@1 78.000 (78.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.062)\tLoss 0.7447 (0.8472)\tPrec@1 78.000 (73.455)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.041 (0.045)\tLoss 0.7337 (0.8318)\tPrec@1 75.000 (74.619)\tPrec@5 100.000 (98.333)\n",
            "Test: [30/100]\tTime 0.031 (0.038)\tLoss 1.0141 (0.8540)\tPrec@1 69.000 (74.516)\tPrec@5 99.000 (98.129)\n",
            "Test: [40/100]\tTime 0.018 (0.035)\tLoss 1.0040 (0.8727)\tPrec@1 77.000 (74.317)\tPrec@5 97.000 (98.024)\n",
            "Test: [50/100]\tTime 0.029 (0.033)\tLoss 0.9674 (0.8656)\tPrec@1 73.000 (74.588)\tPrec@5 97.000 (97.980)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 0.7766 (0.8784)\tPrec@1 77.000 (74.180)\tPrec@5 99.000 (98.066)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 0.7836 (0.8724)\tPrec@1 78.000 (74.380)\tPrec@5 100.000 (98.099)\n",
            "Test: [80/100]\tTime 0.043 (0.029)\tLoss 0.8008 (0.8664)\tPrec@1 73.000 (74.383)\tPrec@5 98.000 (98.148)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 0.7744 (0.8747)\tPrec@1 71.000 (74.165)\tPrec@5 100.000 (98.143)\n",
            "val Results: Prec@1 74.200 Prec@5 98.120 Loss 0.87492\n",
            "val Class Accuracy: [0.895,0.940,0.828,0.902,0.708,0.482,0.698,0.534,0.792,0.641]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [127][0/329], lr: 0.01000\tTime 0.701 (0.701)\tData 0.584 (0.584)\tLoss 0.2518 (0.2518)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][10/329], lr: 0.01000\tTime 0.102 (0.152)\tData 0.004 (0.058)\tLoss 0.2130 (0.2363)\tPrec@1 92.578 (92.081)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [127][20/329], lr: 0.01000\tTime 0.094 (0.124)\tData 0.000 (0.033)\tLoss 0.2058 (0.2316)\tPrec@1 92.188 (92.206)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [127][30/329], lr: 0.01000\tTime 0.115 (0.114)\tData 0.007 (0.024)\tLoss 0.2803 (0.2449)\tPrec@1 91.406 (91.847)\tPrec@5 99.219 (99.710)\n",
            "Epoch: [127][40/329], lr: 0.01000\tTime 0.093 (0.109)\tData 0.000 (0.019)\tLoss 0.2561 (0.2455)\tPrec@1 90.625 (91.749)\tPrec@5 99.219 (99.752)\n",
            "Epoch: [127][50/329], lr: 0.01000\tTime 0.090 (0.104)\tData 0.005 (0.017)\tLoss 0.2966 (0.2477)\tPrec@1 90.234 (91.697)\tPrec@5 100.000 (99.770)\n",
            "Epoch: [127][60/329], lr: 0.01000\tTime 0.077 (0.102)\tData 0.000 (0.015)\tLoss 0.2732 (0.2456)\tPrec@1 88.281 (91.701)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [127][70/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.000 (0.014)\tLoss 0.2710 (0.2467)\tPrec@1 91.797 (91.698)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [127][80/329], lr: 0.01000\tTime 0.071 (0.099)\tData 0.000 (0.013)\tLoss 0.3261 (0.2457)\tPrec@1 88.672 (91.773)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [127][90/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.017 (0.013)\tLoss 0.1962 (0.2479)\tPrec@1 94.141 (91.681)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [127][100/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.000 (0.012)\tLoss 0.3204 (0.2485)\tPrec@1 89.453 (91.677)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [127][110/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.006 (0.012)\tLoss 0.2058 (0.2501)\tPrec@1 93.750 (91.565)\tPrec@5 100.000 (99.747)\n",
            "Epoch: [127][120/329], lr: 0.01000\tTime 0.070 (0.096)\tData 0.000 (0.011)\tLoss 0.3191 (0.2502)\tPrec@1 89.062 (91.529)\tPrec@5 99.609 (99.739)\n",
            "Epoch: [127][130/329], lr: 0.01000\tTime 0.065 (0.095)\tData 0.006 (0.011)\tLoss 0.2345 (0.2494)\tPrec@1 91.797 (91.597)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [127][140/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.010 (0.011)\tLoss 0.2429 (0.2498)\tPrec@1 91.406 (91.581)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [127][150/329], lr: 0.01000\tTime 0.103 (0.095)\tData 0.000 (0.010)\tLoss 0.2546 (0.2496)\tPrec@1 92.188 (91.572)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [127][160/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.000 (0.010)\tLoss 0.3020 (0.2506)\tPrec@1 89.844 (91.554)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [127][170/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 0.3198 (0.2500)\tPrec@1 88.281 (91.603)\tPrec@5 99.609 (99.733)\n",
            "Epoch: [127][180/329], lr: 0.01000\tTime 0.106 (0.094)\tData 0.009 (0.010)\tLoss 0.2115 (0.2505)\tPrec@1 93.750 (91.596)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [127][190/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.010)\tLoss 0.2927 (0.2511)\tPrec@1 91.797 (91.613)\tPrec@5 99.609 (99.718)\n",
            "Epoch: [127][200/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.011 (0.010)\tLoss 0.2789 (0.2517)\tPrec@1 91.016 (91.595)\tPrec@5 99.609 (99.724)\n",
            "Epoch: [127][210/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.007 (0.009)\tLoss 0.1761 (0.2506)\tPrec@1 93.359 (91.614)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [127][220/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.005 (0.009)\tLoss 0.2847 (0.2503)\tPrec@1 91.016 (91.608)\tPrec@5 99.609 (99.733)\n",
            "Epoch: [127][230/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.007 (0.009)\tLoss 0.2487 (0.2502)\tPrec@1 92.578 (91.599)\tPrec@5 99.609 (99.741)\n",
            "Epoch: [127][240/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.009)\tLoss 0.2536 (0.2501)\tPrec@1 91.016 (91.593)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [127][250/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.004 (0.009)\tLoss 0.3726 (0.2519)\tPrec@1 88.672 (91.556)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [127][260/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.005 (0.009)\tLoss 0.2473 (0.2522)\tPrec@1 91.016 (91.547)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [127][270/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.004 (0.009)\tLoss 0.2324 (0.2513)\tPrec@1 92.969 (91.573)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [127][280/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.005 (0.009)\tLoss 0.3501 (0.2510)\tPrec@1 86.328 (91.576)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [127][290/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.006 (0.009)\tLoss 0.2782 (0.2512)\tPrec@1 90.625 (91.582)\tPrec@5 100.000 (99.749)\n",
            "Epoch: [127][300/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.000 (0.009)\tLoss 0.2450 (0.2511)\tPrec@1 92.969 (91.591)\tPrec@5 99.219 (99.747)\n",
            "Epoch: [127][310/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.010 (0.009)\tLoss 0.2597 (0.2515)\tPrec@1 92.188 (91.586)\tPrec@5 99.609 (99.749)\n",
            "Epoch: [127][320/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.039 (0.009)\tLoss 0.2209 (0.2514)\tPrec@1 92.188 (91.602)\tPrec@5 100.000 (99.749)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 0.6856 (0.6856)\tPrec@1 79.000 (79.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.037 (0.061)\tLoss 0.8525 (0.8057)\tPrec@1 74.000 (75.545)\tPrec@5 97.000 (98.455)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 0.7704 (0.8239)\tPrec@1 73.000 (75.571)\tPrec@5 98.000 (98.095)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 0.9034 (0.8309)\tPrec@1 74.000 (75.129)\tPrec@5 97.000 (98.000)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 0.9598 (0.8362)\tPrec@1 72.000 (74.854)\tPrec@5 96.000 (97.976)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 0.9845 (0.8385)\tPrec@1 72.000 (74.922)\tPrec@5 98.000 (98.020)\n",
            "Test: [60/100]\tTime 0.021 (0.030)\tLoss 0.7583 (0.8493)\tPrec@1 83.000 (74.607)\tPrec@5 99.000 (98.131)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 0.9109 (0.8509)\tPrec@1 73.000 (74.535)\tPrec@5 100.000 (98.099)\n",
            "Test: [80/100]\tTime 0.041 (0.028)\tLoss 0.7757 (0.8409)\tPrec@1 78.000 (74.679)\tPrec@5 97.000 (98.185)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 0.8596 (0.8522)\tPrec@1 75.000 (74.396)\tPrec@5 100.000 (98.088)\n",
            "val Results: Prec@1 74.330 Prec@5 98.100 Loss 0.85234\n",
            "val Class Accuracy: [0.918,0.968,0.883,0.678,0.593,0.762,0.823,0.588,0.618,0.602]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [128][0/329], lr: 0.01000\tTime 0.553 (0.553)\tData 0.484 (0.484)\tLoss 0.2502 (0.2502)\tPrec@1 91.797 (91.797)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [128][10/329], lr: 0.01000\tTime 0.102 (0.142)\tData 0.001 (0.049)\tLoss 0.1850 (0.2528)\tPrec@1 94.922 (92.152)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [128][20/329], lr: 0.01000\tTime 0.097 (0.119)\tData 0.000 (0.029)\tLoss 0.2668 (0.2372)\tPrec@1 91.406 (92.411)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [128][30/329], lr: 0.01000\tTime 0.099 (0.110)\tData 0.000 (0.021)\tLoss 0.3431 (0.2418)\tPrec@1 89.062 (92.087)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [128][40/329], lr: 0.01000\tTime 0.089 (0.105)\tData 0.006 (0.017)\tLoss 0.3525 (0.2450)\tPrec@1 87.500 (91.825)\tPrec@5 99.609 (99.790)\n",
            "Epoch: [128][50/329], lr: 0.01000\tTime 0.092 (0.102)\tData 0.006 (0.015)\tLoss 0.1957 (0.2441)\tPrec@1 92.969 (91.973)\tPrec@5 100.000 (99.763)\n",
            "Epoch: [128][60/329], lr: 0.01000\tTime 0.118 (0.104)\tData 0.000 (0.014)\tLoss 0.2078 (0.2402)\tPrec@1 92.578 (92.034)\tPrec@5 99.609 (99.789)\n",
            "Epoch: [128][70/329], lr: 0.01000\tTime 0.150 (0.107)\tData 0.000 (0.012)\tLoss 0.2111 (0.2385)\tPrec@1 92.578 (92.044)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [128][80/329], lr: 0.01000\tTime 0.080 (0.107)\tData 0.004 (0.011)\tLoss 0.2204 (0.2388)\tPrec@1 93.750 (92.028)\tPrec@5 100.000 (99.802)\n",
            "Epoch: [128][90/329], lr: 0.01000\tTime 0.076 (0.105)\tData 0.004 (0.011)\tLoss 0.1802 (0.2369)\tPrec@1 94.531 (92.054)\tPrec@5 100.000 (99.807)\n",
            "Epoch: [128][100/329], lr: 0.01000\tTime 0.085 (0.104)\tData 0.004 (0.010)\tLoss 0.2506 (0.2388)\tPrec@1 91.797 (92.025)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [128][110/329], lr: 0.01000\tTime 0.084 (0.103)\tData 0.000 (0.010)\tLoss 0.2706 (0.2399)\tPrec@1 89.062 (91.938)\tPrec@5 100.000 (99.792)\n",
            "Epoch: [128][120/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.007 (0.010)\tLoss 0.2727 (0.2411)\tPrec@1 91.406 (91.939)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [128][130/329], lr: 0.01000\tTime 0.094 (0.102)\tData 0.000 (0.009)\tLoss 0.2820 (0.2429)\tPrec@1 91.016 (91.854)\tPrec@5 98.828 (99.773)\n",
            "Epoch: [128][140/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.007 (0.009)\tLoss 0.2266 (0.2436)\tPrec@1 92.578 (91.855)\tPrec@5 100.000 (99.765)\n",
            "Epoch: [128][150/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.000 (0.009)\tLoss 0.2453 (0.2437)\tPrec@1 92.969 (91.846)\tPrec@5 100.000 (99.759)\n",
            "Epoch: [128][160/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.006 (0.009)\tLoss 0.1869 (0.2440)\tPrec@1 93.750 (91.838)\tPrec@5 100.000 (99.765)\n",
            "Epoch: [128][170/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.005 (0.009)\tLoss 0.2693 (0.2443)\tPrec@1 92.969 (91.838)\tPrec@5 99.609 (99.760)\n",
            "Epoch: [128][180/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.006 (0.009)\tLoss 0.2671 (0.2439)\tPrec@1 90.625 (91.853)\tPrec@5 99.609 (99.763)\n",
            "Epoch: [128][190/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.007 (0.009)\tLoss 0.2264 (0.2442)\tPrec@1 92.578 (91.844)\tPrec@5 100.000 (99.763)\n",
            "Epoch: [128][200/329], lr: 0.01000\tTime 0.071 (0.097)\tData 0.000 (0.009)\tLoss 0.2393 (0.2434)\tPrec@1 92.578 (91.894)\tPrec@5 99.609 (99.761)\n",
            "Epoch: [128][210/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.006 (0.009)\tLoss 0.2680 (0.2438)\tPrec@1 90.234 (91.893)\tPrec@5 100.000 (99.756)\n",
            "Epoch: [128][220/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.000 (0.009)\tLoss 0.2614 (0.2439)\tPrec@1 91.797 (91.887)\tPrec@5 99.219 (99.749)\n",
            "Epoch: [128][230/329], lr: 0.01000\tTime 0.116 (0.096)\tData 0.005 (0.009)\tLoss 0.2199 (0.2445)\tPrec@1 90.625 (91.849)\tPrec@5 100.000 (99.746)\n",
            "Epoch: [128][240/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.009 (0.009)\tLoss 0.1273 (0.2441)\tPrec@1 96.875 (91.849)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [128][250/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.011 (0.009)\tLoss 0.2932 (0.2439)\tPrec@1 90.625 (91.851)\tPrec@5 99.609 (99.748)\n",
            "Epoch: [128][260/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.009 (0.009)\tLoss 0.3114 (0.2440)\tPrec@1 89.062 (91.840)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [128][270/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.000 (0.009)\tLoss 0.2414 (0.2442)\tPrec@1 92.969 (91.826)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [128][280/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.007 (0.009)\tLoss 0.2699 (0.2442)\tPrec@1 91.406 (91.821)\tPrec@5 99.609 (99.746)\n",
            "Epoch: [128][290/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.000 (0.008)\tLoss 0.2075 (0.2429)\tPrec@1 94.141 (91.861)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [128][300/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.008)\tLoss 0.2300 (0.2434)\tPrec@1 92.578 (91.841)\tPrec@5 99.609 (99.746)\n",
            "Epoch: [128][310/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.008 (0.008)\tLoss 0.2784 (0.2440)\tPrec@1 91.406 (91.835)\tPrec@5 98.828 (99.736)\n",
            "Epoch: [128][320/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.061 (0.009)\tLoss 0.2878 (0.2439)\tPrec@1 90.625 (91.831)\tPrec@5 99.609 (99.737)\n",
            "Test: [0/100]\tTime 0.419 (0.419)\tLoss 1.4582 (1.4582)\tPrec@1 60.000 (60.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.017 (0.061)\tLoss 1.9305 (1.7853)\tPrec@1 56.000 (56.545)\tPrec@5 89.000 (92.909)\n",
            "Test: [20/100]\tTime 0.020 (0.042)\tLoss 1.7421 (1.7620)\tPrec@1 53.000 (55.905)\tPrec@5 95.000 (93.810)\n",
            "Test: [30/100]\tTime 0.016 (0.037)\tLoss 1.7705 (1.7078)\tPrec@1 56.000 (56.161)\tPrec@5 91.000 (94.032)\n",
            "Test: [40/100]\tTime 0.032 (0.034)\tLoss 1.3983 (1.7262)\tPrec@1 62.000 (55.829)\tPrec@5 97.000 (94.195)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 1.2536 (1.6942)\tPrec@1 62.000 (56.294)\tPrec@5 97.000 (94.314)\n",
            "Test: [60/100]\tTime 0.020 (0.031)\tLoss 1.4997 (1.6707)\tPrec@1 56.000 (56.443)\tPrec@5 94.000 (94.508)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 1.3452 (1.6812)\tPrec@1 63.000 (56.127)\tPrec@5 97.000 (94.423)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 1.3619 (1.6724)\tPrec@1 58.000 (56.395)\tPrec@5 97.000 (94.457)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 1.9480 (1.6870)\tPrec@1 54.000 (56.319)\tPrec@5 92.000 (94.418)\n",
            "val Results: Prec@1 56.420 Prec@5 94.460 Loss 1.67894\n",
            "val Class Accuracy: [0.616,0.950,0.774,0.695,0.522,0.332,0.391,0.759,0.202,0.401]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [129][0/329], lr: 0.01000\tTime 0.575 (0.575)\tData 0.487 (0.487)\tLoss 0.3679 (0.3679)\tPrec@1 91.016 (91.016)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [129][10/329], lr: 0.01000\tTime 0.082 (0.143)\tData 0.001 (0.049)\tLoss 0.8651 (1.0715)\tPrec@1 70.312 (69.070)\tPrec@5 96.875 (96.342)\n",
            "Epoch: [129][20/329], lr: 0.01000\tTime 0.074 (0.119)\tData 0.000 (0.029)\tLoss 0.8073 (0.9459)\tPrec@1 73.047 (71.410)\tPrec@5 98.828 (96.838)\n",
            "Epoch: [129][30/329], lr: 0.01000\tTime 0.105 (0.110)\tData 0.008 (0.022)\tLoss 0.6019 (0.8521)\tPrec@1 78.516 (73.311)\tPrec@5 98.828 (97.429)\n",
            "Epoch: [129][40/329], lr: 0.01000\tTime 0.093 (0.105)\tData 0.007 (0.018)\tLoss 0.5152 (0.7847)\tPrec@1 82.031 (75.105)\tPrec@5 99.609 (97.771)\n",
            "Epoch: [129][50/329], lr: 0.01000\tTime 0.092 (0.102)\tData 0.000 (0.016)\tLoss 0.4755 (0.7277)\tPrec@1 83.203 (76.785)\tPrec@5 99.219 (98.055)\n",
            "Epoch: [129][60/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.012 (0.015)\tLoss 0.4123 (0.6861)\tPrec@1 87.109 (78.067)\tPrec@5 99.609 (98.194)\n",
            "Epoch: [129][70/329], lr: 0.01000\tTime 0.075 (0.098)\tData 0.005 (0.014)\tLoss 0.3834 (0.6489)\tPrec@1 87.500 (79.176)\tPrec@5 98.828 (98.371)\n",
            "Epoch: [129][80/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.006 (0.013)\tLoss 0.4651 (0.6226)\tPrec@1 84.766 (79.909)\tPrec@5 98.828 (98.471)\n",
            "Epoch: [129][90/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.004 (0.012)\tLoss 0.3394 (0.6026)\tPrec@1 89.844 (80.495)\tPrec@5 99.219 (98.545)\n",
            "Epoch: [129][100/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.010 (0.012)\tLoss 0.3426 (0.5826)\tPrec@1 89.844 (81.115)\tPrec@5 99.609 (98.615)\n",
            "Epoch: [129][110/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.000 (0.011)\tLoss 0.3803 (0.5653)\tPrec@1 86.719 (81.627)\tPrec@5 100.000 (98.673)\n",
            "Epoch: [129][120/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.005 (0.011)\tLoss 0.3975 (0.5506)\tPrec@1 87.891 (82.083)\tPrec@5 99.609 (98.741)\n",
            "Epoch: [129][130/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.004 (0.011)\tLoss 0.3207 (0.5379)\tPrec@1 89.844 (82.529)\tPrec@5 99.219 (98.774)\n",
            "Epoch: [129][140/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.007 (0.010)\tLoss 0.2392 (0.5245)\tPrec@1 94.531 (82.932)\tPrec@5 100.000 (98.820)\n",
            "Epoch: [129][150/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.000 (0.010)\tLoss 0.3105 (0.5131)\tPrec@1 87.891 (83.281)\tPrec@5 100.000 (98.870)\n",
            "Epoch: [129][160/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.006 (0.010)\tLoss 0.3673 (0.5036)\tPrec@1 86.328 (83.553)\tPrec@5 99.609 (98.908)\n",
            "Epoch: [129][170/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.010)\tLoss 0.3508 (0.4957)\tPrec@1 85.547 (83.758)\tPrec@5 100.000 (98.949)\n",
            "Epoch: [129][180/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.010)\tLoss 0.3188 (0.4872)\tPrec@1 91.016 (84.060)\tPrec@5 99.609 (98.973)\n",
            "Epoch: [129][190/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 0.3285 (0.4792)\tPrec@1 91.016 (84.326)\tPrec@5 100.000 (99.002)\n",
            "Epoch: [129][200/329], lr: 0.01000\tTime 0.062 (0.093)\tData 0.005 (0.009)\tLoss 0.3305 (0.4721)\tPrec@1 88.672 (84.540)\tPrec@5 100.000 (99.026)\n",
            "Epoch: [129][210/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.004 (0.009)\tLoss 0.3905 (0.4673)\tPrec@1 86.719 (84.673)\tPrec@5 99.609 (99.050)\n",
            "Epoch: [129][220/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.003 (0.009)\tLoss 0.3756 (0.4590)\tPrec@1 88.281 (84.964)\tPrec@5 99.219 (99.079)\n",
            "Epoch: [129][230/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.009)\tLoss 0.3504 (0.4537)\tPrec@1 87.891 (85.128)\tPrec@5 98.828 (99.097)\n",
            "Epoch: [129][240/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.015 (0.009)\tLoss 0.3645 (0.4498)\tPrec@1 87.891 (85.244)\tPrec@5 99.609 (99.117)\n",
            "Epoch: [129][250/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.009)\tLoss 0.3608 (0.4448)\tPrec@1 87.109 (85.376)\tPrec@5 99.219 (99.125)\n",
            "Epoch: [129][260/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.006 (0.009)\tLoss 0.2812 (0.4402)\tPrec@1 91.797 (85.515)\tPrec@5 99.609 (99.147)\n",
            "Epoch: [129][270/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.006 (0.009)\tLoss 0.2687 (0.4364)\tPrec@1 90.625 (85.642)\tPrec@5 100.000 (99.163)\n",
            "Epoch: [129][280/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.008 (0.009)\tLoss 0.3786 (0.4317)\tPrec@1 87.500 (85.793)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [129][290/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.001 (0.009)\tLoss 0.3439 (0.4270)\tPrec@1 87.891 (85.942)\tPrec@5 99.609 (99.197)\n",
            "Epoch: [129][300/329], lr: 0.01000\tTime 0.066 (0.091)\tData 0.001 (0.009)\tLoss 0.3608 (0.4233)\tPrec@1 87.500 (86.058)\tPrec@5 99.219 (99.206)\n",
            "Epoch: [129][310/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.010 (0.009)\tLoss 0.3148 (0.4204)\tPrec@1 90.625 (86.159)\tPrec@5 99.219 (99.210)\n",
            "Epoch: [129][320/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.062 (0.009)\tLoss 0.3115 (0.4168)\tPrec@1 89.844 (86.264)\tPrec@5 99.219 (99.218)\n",
            "Test: [0/100]\tTime 0.391 (0.391)\tLoss 0.6821 (0.6821)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.028 (0.058)\tLoss 0.7226 (0.8872)\tPrec@1 78.000 (72.909)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.036 (0.042)\tLoss 0.7327 (0.8989)\tPrec@1 76.000 (72.238)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 0.9833 (0.9070)\tPrec@1 73.000 (71.839)\tPrec@5 98.000 (97.677)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 0.9159 (0.9148)\tPrec@1 62.000 (71.366)\tPrec@5 97.000 (97.512)\n",
            "Test: [50/100]\tTime 0.012 (0.032)\tLoss 0.8756 (0.9080)\tPrec@1 67.000 (71.529)\tPrec@5 97.000 (97.667)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 0.8090 (0.9072)\tPrec@1 71.000 (71.295)\tPrec@5 99.000 (97.705)\n",
            "Test: [70/100]\tTime 0.009 (0.030)\tLoss 0.8601 (0.9053)\tPrec@1 73.000 (71.211)\tPrec@5 99.000 (97.676)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 0.5787 (0.8936)\tPrec@1 80.000 (71.494)\tPrec@5 99.000 (97.840)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 0.8877 (0.9036)\tPrec@1 70.000 (71.066)\tPrec@5 100.000 (97.846)\n",
            "val Results: Prec@1 71.110 Prec@5 97.850 Loss 0.90268\n",
            "val Class Accuracy: [0.915,0.986,0.823,0.717,0.647,0.668,0.733,0.684,0.590,0.348]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [130][0/329], lr: 0.01000\tTime 0.670 (0.670)\tData 0.577 (0.577)\tLoss 0.2362 (0.2362)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][10/329], lr: 0.01000\tTime 0.101 (0.150)\tData 0.000 (0.057)\tLoss 0.3063 (0.3140)\tPrec@1 89.062 (89.276)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [130][20/329], lr: 0.01000\tTime 0.109 (0.122)\tData 0.000 (0.033)\tLoss 0.2921 (0.2975)\tPrec@1 89.453 (89.937)\tPrec@5 99.219 (99.684)\n",
            "Epoch: [130][30/329], lr: 0.01000\tTime 0.096 (0.113)\tData 0.005 (0.024)\tLoss 0.3275 (0.3013)\tPrec@1 89.453 (89.655)\tPrec@5 99.609 (99.647)\n",
            "Epoch: [130][40/329], lr: 0.01000\tTime 0.075 (0.107)\tData 0.005 (0.020)\tLoss 0.2953 (0.3002)\tPrec@1 87.891 (89.834)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [130][50/329], lr: 0.01000\tTime 0.123 (0.105)\tData 0.012 (0.018)\tLoss 0.3094 (0.2962)\tPrec@1 91.016 (90.066)\tPrec@5 98.438 (99.617)\n",
            "Epoch: [130][60/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.000 (0.016)\tLoss 0.2475 (0.2974)\tPrec@1 91.797 (90.036)\tPrec@5 99.609 (99.590)\n",
            "Epoch: [130][70/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.000 (0.015)\tLoss 0.2824 (0.2968)\tPrec@1 90.625 (90.086)\tPrec@5 99.609 (99.631)\n",
            "Epoch: [130][80/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.004 (0.014)\tLoss 0.2632 (0.2935)\tPrec@1 91.406 (90.167)\tPrec@5 100.000 (99.653)\n",
            "Epoch: [130][90/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.007 (0.013)\tLoss 0.2599 (0.2917)\tPrec@1 91.797 (90.269)\tPrec@5 99.609 (99.648)\n",
            "Epoch: [130][100/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.000 (0.012)\tLoss 0.2302 (0.2913)\tPrec@1 92.969 (90.219)\tPrec@5 99.609 (99.656)\n",
            "Epoch: [130][110/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.001 (0.012)\tLoss 0.3161 (0.2894)\tPrec@1 89.453 (90.248)\tPrec@5 100.000 (99.666)\n",
            "Epoch: [130][120/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.006 (0.012)\tLoss 0.2566 (0.2896)\tPrec@1 90.625 (90.228)\tPrec@5 100.000 (99.667)\n",
            "Epoch: [130][130/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.005 (0.011)\tLoss 0.3102 (0.2916)\tPrec@1 87.891 (90.127)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [130][140/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.000 (0.011)\tLoss 0.3636 (0.2928)\tPrec@1 85.938 (90.096)\tPrec@5 99.219 (99.670)\n",
            "Epoch: [130][150/329], lr: 0.01000\tTime 0.078 (0.094)\tData 0.000 (0.011)\tLoss 0.3419 (0.2924)\tPrec@1 87.500 (90.110)\tPrec@5 99.219 (99.677)\n",
            "Epoch: [130][160/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.001 (0.010)\tLoss 0.2852 (0.2909)\tPrec@1 89.844 (90.162)\tPrec@5 100.000 (99.685)\n",
            "Epoch: [130][170/329], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.010)\tLoss 0.2232 (0.2907)\tPrec@1 92.969 (90.191)\tPrec@5 100.000 (99.676)\n",
            "Epoch: [130][180/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.010)\tLoss 0.3035 (0.2907)\tPrec@1 91.406 (90.208)\tPrec@5 99.219 (99.672)\n",
            "Epoch: [130][190/329], lr: 0.01000\tTime 0.067 (0.093)\tData 0.000 (0.010)\tLoss 0.2595 (0.2893)\tPrec@1 91.406 (90.245)\tPrec@5 99.609 (99.675)\n",
            "Epoch: [130][200/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.000 (0.010)\tLoss 0.2345 (0.2888)\tPrec@1 92.578 (90.252)\tPrec@5 100.000 (99.677)\n",
            "Epoch: [130][210/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.003 (0.010)\tLoss 0.2059 (0.2882)\tPrec@1 94.531 (90.283)\tPrec@5 99.609 (99.680)\n",
            "Epoch: [130][220/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.009)\tLoss 0.2990 (0.2881)\tPrec@1 87.891 (90.254)\tPrec@5 100.000 (99.680)\n",
            "Epoch: [130][230/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 0.2078 (0.2878)\tPrec@1 93.750 (90.275)\tPrec@5 100.000 (99.680)\n",
            "Epoch: [130][240/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.007 (0.009)\tLoss 0.3059 (0.2888)\tPrec@1 89.062 (90.281)\tPrec@5 100.000 (99.673)\n",
            "Epoch: [130][250/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.009)\tLoss 0.2495 (0.2880)\tPrec@1 92.188 (90.328)\tPrec@5 99.609 (99.669)\n",
            "Epoch: [130][260/329], lr: 0.01000\tTime 0.101 (0.092)\tData 0.013 (0.009)\tLoss 0.1994 (0.2875)\tPrec@1 94.141 (90.348)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [130][270/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.000 (0.009)\tLoss 0.2431 (0.2867)\tPrec@1 92.969 (90.390)\tPrec@5 100.000 (99.671)\n",
            "Epoch: [130][280/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.006 (0.009)\tLoss 0.2802 (0.2864)\tPrec@1 89.453 (90.393)\tPrec@5 99.609 (99.672)\n",
            "Epoch: [130][290/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.005 (0.009)\tLoss 0.2257 (0.2862)\tPrec@1 92.578 (90.399)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [130][300/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.000 (0.009)\tLoss 0.2364 (0.2861)\tPrec@1 90.234 (90.395)\tPrec@5 99.219 (99.666)\n",
            "Epoch: [130][310/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.000 (0.009)\tLoss 0.3210 (0.2861)\tPrec@1 89.062 (90.381)\tPrec@5 100.000 (99.666)\n",
            "Epoch: [130][320/329], lr: 0.01000\tTime 0.109 (0.091)\tData 0.057 (0.009)\tLoss 0.2007 (0.2861)\tPrec@1 93.359 (90.369)\tPrec@5 100.000 (99.664)\n",
            "Test: [0/100]\tTime 0.385 (0.385)\tLoss 0.8296 (0.8296)\tPrec@1 74.000 (74.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.026 (0.056)\tLoss 0.8935 (0.9976)\tPrec@1 75.000 (71.273)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.010 (0.041)\tLoss 1.1608 (0.9848)\tPrec@1 69.000 (71.381)\tPrec@5 99.000 (98.429)\n",
            "Test: [30/100]\tTime 0.034 (0.036)\tLoss 0.9089 (0.9898)\tPrec@1 72.000 (71.129)\tPrec@5 99.000 (98.387)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 1.1154 (0.9953)\tPrec@1 73.000 (71.073)\tPrec@5 98.000 (98.244)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 0.8675 (0.9713)\tPrec@1 78.000 (71.608)\tPrec@5 98.000 (98.333)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 0.7732 (0.9794)\tPrec@1 81.000 (71.311)\tPrec@5 99.000 (98.426)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 0.9977 (0.9726)\tPrec@1 73.000 (71.507)\tPrec@5 99.000 (98.521)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 0.9786 (0.9740)\tPrec@1 71.000 (71.543)\tPrec@5 98.000 (98.568)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 0.8774 (0.9852)\tPrec@1 74.000 (71.385)\tPrec@5 100.000 (98.538)\n",
            "val Results: Prec@1 71.380 Prec@5 98.490 Loss 0.98905\n",
            "val Class Accuracy: [0.952,0.890,0.706,0.822,0.890,0.541,0.572,0.568,0.600,0.597]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [131][0/329], lr: 0.01000\tTime 0.652 (0.652)\tData 0.566 (0.566)\tLoss 0.2209 (0.2209)\tPrec@1 93.359 (93.359)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][10/329], lr: 0.01000\tTime 0.102 (0.142)\tData 0.000 (0.056)\tLoss 0.4057 (0.4137)\tPrec@1 86.328 (87.038)\tPrec@5 99.609 (99.325)\n",
            "Epoch: [131][20/329], lr: 0.01000\tTime 0.114 (0.118)\tData 0.020 (0.032)\tLoss 0.2486 (0.3868)\tPrec@1 91.797 (87.221)\tPrec@5 100.000 (99.535)\n",
            "Epoch: [131][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.000 (0.023)\tLoss 0.3582 (0.3741)\tPrec@1 89.453 (87.601)\tPrec@5 99.219 (99.546)\n",
            "Epoch: [131][40/329], lr: 0.01000\tTime 0.099 (0.107)\tData 0.000 (0.019)\tLoss 0.2856 (0.3553)\tPrec@1 90.234 (88.205)\tPrec@5 100.000 (99.552)\n",
            "Epoch: [131][50/329], lr: 0.01000\tTime 0.085 (0.104)\tData 0.004 (0.016)\tLoss 0.2736 (0.3424)\tPrec@1 91.406 (88.565)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [131][60/329], lr: 0.01000\tTime 0.094 (0.101)\tData 0.006 (0.015)\tLoss 0.3241 (0.3333)\tPrec@1 88.672 (88.928)\tPrec@5 99.609 (99.552)\n",
            "Epoch: [131][70/329], lr: 0.01000\tTime 0.071 (0.100)\tData 0.000 (0.014)\tLoss 0.2185 (0.3209)\tPrec@1 92.188 (89.299)\tPrec@5 100.000 (99.587)\n",
            "Epoch: [131][80/329], lr: 0.01000\tTime 0.107 (0.099)\tData 0.005 (0.013)\tLoss 0.2088 (0.3129)\tPrec@1 93.359 (89.545)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [131][90/329], lr: 0.01000\tTime 0.094 (0.098)\tData 0.000 (0.012)\tLoss 0.2843 (0.3067)\tPrec@1 92.188 (89.779)\tPrec@5 100.000 (99.644)\n",
            "Epoch: [131][100/329], lr: 0.01000\tTime 0.117 (0.097)\tData 0.006 (0.012)\tLoss 0.2633 (0.3054)\tPrec@1 90.625 (89.859)\tPrec@5 99.609 (99.621)\n",
            "Epoch: [131][110/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.010 (0.011)\tLoss 0.2718 (0.3025)\tPrec@1 92.188 (89.995)\tPrec@5 100.000 (99.602)\n",
            "Epoch: [131][120/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.011)\tLoss 0.3631 (0.3026)\tPrec@1 88.281 (90.018)\tPrec@5 100.000 (99.603)\n",
            "Epoch: [131][130/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.006 (0.011)\tLoss 0.2360 (0.3001)\tPrec@1 93.359 (90.070)\tPrec@5 99.219 (99.624)\n",
            "Epoch: [131][140/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.011)\tLoss 0.2237 (0.2972)\tPrec@1 92.578 (90.154)\tPrec@5 100.000 (99.632)\n",
            "Epoch: [131][150/329], lr: 0.01000\tTime 0.064 (0.094)\tData 0.005 (0.011)\tLoss 0.2961 (0.2955)\tPrec@1 89.062 (90.170)\tPrec@5 100.000 (99.646)\n",
            "Epoch: [131][160/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.007 (0.010)\tLoss 0.3197 (0.2936)\tPrec@1 90.234 (90.237)\tPrec@5 99.219 (99.648)\n",
            "Epoch: [131][170/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 0.2891 (0.2926)\tPrec@1 88.281 (90.244)\tPrec@5 99.609 (99.662)\n",
            "Epoch: [131][180/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.010)\tLoss 0.2469 (0.2919)\tPrec@1 92.578 (90.265)\tPrec@5 100.000 (99.659)\n",
            "Epoch: [131][190/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 0.3121 (0.2907)\tPrec@1 89.062 (90.286)\tPrec@5 100.000 (99.658)\n",
            "Epoch: [131][200/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.006 (0.010)\tLoss 0.3413 (0.2897)\tPrec@1 87.891 (90.330)\tPrec@5 98.828 (99.664)\n",
            "Epoch: [131][210/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.000 (0.010)\tLoss 0.2787 (0.2885)\tPrec@1 90.625 (90.332)\tPrec@5 100.000 (99.663)\n",
            "Epoch: [131][220/329], lr: 0.01000\tTime 0.071 (0.092)\tData 0.000 (0.010)\tLoss 0.2654 (0.2873)\tPrec@1 91.016 (90.353)\tPrec@5 99.609 (99.668)\n",
            "Epoch: [131][230/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.005 (0.010)\tLoss 0.2936 (0.2876)\tPrec@1 91.406 (90.344)\tPrec@5 99.609 (99.663)\n",
            "Epoch: [131][240/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.000 (0.009)\tLoss 0.3441 (0.2867)\tPrec@1 88.281 (90.377)\tPrec@5 99.609 (99.663)\n",
            "Epoch: [131][250/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.006 (0.009)\tLoss 0.1915 (0.2852)\tPrec@1 92.188 (90.430)\tPrec@5 100.000 (99.661)\n",
            "Epoch: [131][260/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.015 (0.009)\tLoss 0.2353 (0.2840)\tPrec@1 91.406 (90.481)\tPrec@5 99.609 (99.665)\n",
            "Epoch: [131][270/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.003 (0.009)\tLoss 0.2201 (0.2830)\tPrec@1 93.750 (90.515)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [131][280/329], lr: 0.01000\tTime 0.108 (0.091)\tData 0.000 (0.009)\tLoss 0.2969 (0.2834)\tPrec@1 91.016 (90.504)\tPrec@5 99.609 (99.671)\n",
            "Epoch: [131][290/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.000 (0.009)\tLoss 0.2689 (0.2824)\tPrec@1 91.016 (90.551)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [131][300/329], lr: 0.01000\tTime 0.097 (0.091)\tData 0.000 (0.009)\tLoss 0.2685 (0.2816)\tPrec@1 91.016 (90.576)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [131][310/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.002 (0.009)\tLoss 0.2678 (0.2812)\tPrec@1 90.625 (90.586)\tPrec@5 100.000 (99.676)\n",
            "Epoch: [131][320/329], lr: 0.01000\tTime 0.071 (0.091)\tData 0.032 (0.009)\tLoss 0.2646 (0.2809)\tPrec@1 91.406 (90.593)\tPrec@5 100.000 (99.673)\n",
            "Test: [0/100]\tTime 0.368 (0.368)\tLoss 1.1480 (1.1480)\tPrec@1 59.000 (59.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.030 (0.059)\tLoss 1.2311 (1.4473)\tPrec@1 72.000 (63.909)\tPrec@5 94.000 (94.909)\n",
            "Test: [20/100]\tTime 0.024 (0.043)\tLoss 1.1869 (1.3949)\tPrec@1 65.000 (64.238)\tPrec@5 97.000 (95.619)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 1.5831 (1.3969)\tPrec@1 62.000 (63.871)\tPrec@5 93.000 (95.484)\n",
            "Test: [40/100]\tTime 0.032 (0.034)\tLoss 1.2570 (1.3921)\tPrec@1 64.000 (63.585)\tPrec@5 98.000 (95.585)\n",
            "Test: [50/100]\tTime 0.039 (0.032)\tLoss 1.2144 (1.3681)\tPrec@1 67.000 (64.118)\tPrec@5 97.000 (95.608)\n",
            "Test: [60/100]\tTime 0.032 (0.029)\tLoss 1.1883 (1.3852)\tPrec@1 70.000 (63.770)\tPrec@5 97.000 (95.721)\n",
            "Test: [70/100]\tTime 0.039 (0.029)\tLoss 1.0938 (1.3907)\tPrec@1 63.000 (63.592)\tPrec@5 99.000 (95.732)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 1.2229 (1.3728)\tPrec@1 70.000 (63.914)\tPrec@5 96.000 (95.852)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 1.4962 (1.3848)\tPrec@1 61.000 (63.670)\tPrec@5 94.000 (95.692)\n",
            "val Results: Prec@1 63.670 Prec@5 95.680 Loss 1.38146\n",
            "val Class Accuracy: [0.737,0.951,0.728,0.884,0.530,0.545,0.409,0.789,0.321,0.473]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [132][0/329], lr: 0.01000\tTime 0.695 (0.695)\tData 0.602 (0.602)\tLoss 0.4384 (0.4384)\tPrec@1 85.547 (85.547)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [132][10/329], lr: 0.01000\tTime 0.081 (0.154)\tData 0.000 (0.066)\tLoss 0.4253 (0.5615)\tPrec@1 85.938 (82.315)\tPrec@5 99.219 (98.580)\n",
            "Epoch: [132][20/329], lr: 0.01000\tTime 0.093 (0.123)\tData 0.000 (0.038)\tLoss 0.3953 (0.5040)\tPrec@1 87.109 (83.761)\tPrec@5 98.438 (98.828)\n",
            "Epoch: [132][30/329], lr: 0.01000\tTime 0.070 (0.112)\tData 0.000 (0.027)\tLoss 0.2855 (0.4542)\tPrec@1 91.797 (85.522)\tPrec@5 99.609 (99.093)\n",
            "Epoch: [132][40/329], lr: 0.01000\tTime 0.090 (0.107)\tData 0.003 (0.023)\tLoss 0.3426 (0.4268)\tPrec@1 89.844 (86.347)\tPrec@5 100.000 (99.238)\n",
            "Epoch: [132][50/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.000 (0.020)\tLoss 0.2316 (0.4010)\tPrec@1 91.797 (87.079)\tPrec@5 100.000 (99.349)\n",
            "Epoch: [132][60/329], lr: 0.01000\tTime 0.092 (0.101)\tData 0.000 (0.018)\tLoss 0.3727 (0.3827)\tPrec@1 89.453 (87.596)\tPrec@5 99.609 (99.404)\n",
            "Epoch: [132][70/329], lr: 0.01000\tTime 0.069 (0.099)\tData 0.000 (0.016)\tLoss 0.2691 (0.3684)\tPrec@1 89.453 (87.990)\tPrec@5 100.000 (99.422)\n",
            "Epoch: [132][80/329], lr: 0.01000\tTime 0.073 (0.098)\tData 0.007 (0.015)\tLoss 0.2612 (0.3570)\tPrec@1 90.625 (88.349)\tPrec@5 99.609 (99.455)\n",
            "Epoch: [132][90/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.003 (0.014)\tLoss 0.3471 (0.3483)\tPrec@1 86.719 (88.530)\tPrec@5 99.609 (99.485)\n",
            "Epoch: [132][100/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.000 (0.014)\tLoss 0.3214 (0.3433)\tPrec@1 88.672 (88.722)\tPrec@5 99.609 (99.497)\n",
            "Epoch: [132][110/329], lr: 0.01000\tTime 0.117 (0.095)\tData 0.000 (0.013)\tLoss 0.3519 (0.3403)\tPrec@1 87.500 (88.799)\tPrec@5 99.609 (99.511)\n",
            "Epoch: [132][120/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.002 (0.012)\tLoss 0.3086 (0.3359)\tPrec@1 89.453 (88.956)\tPrec@5 99.219 (99.535)\n",
            "Epoch: [132][130/329], lr: 0.01000\tTime 0.113 (0.097)\tData 0.008 (0.012)\tLoss 0.3057 (0.3335)\tPrec@1 90.234 (89.051)\tPrec@5 99.609 (99.535)\n",
            "Epoch: [132][140/329], lr: 0.01000\tTime 0.106 (0.099)\tData 0.039 (0.012)\tLoss 0.3616 (0.3312)\tPrec@1 86.328 (89.126)\tPrec@5 99.219 (99.548)\n",
            "Epoch: [132][150/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.001 (0.012)\tLoss 0.2883 (0.3272)\tPrec@1 91.406 (89.249)\tPrec@5 100.000 (99.555)\n",
            "Epoch: [132][160/329], lr: 0.01000\tTime 0.095 (0.099)\tData 0.000 (0.011)\tLoss 0.3277 (0.3239)\tPrec@1 86.719 (89.291)\tPrec@5 100.000 (99.568)\n",
            "Epoch: [132][170/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.001 (0.011)\tLoss 0.2651 (0.3191)\tPrec@1 92.188 (89.423)\tPrec@5 100.000 (99.587)\n",
            "Epoch: [132][180/329], lr: 0.01000\tTime 0.067 (0.098)\tData 0.001 (0.011)\tLoss 0.3206 (0.3179)\tPrec@1 88.672 (89.475)\tPrec@5 99.609 (99.583)\n",
            "Epoch: [132][190/329], lr: 0.01000\tTime 0.108 (0.098)\tData 0.007 (0.010)\tLoss 0.2126 (0.3132)\tPrec@1 92.578 (89.652)\tPrec@5 100.000 (99.599)\n",
            "Epoch: [132][200/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.009 (0.010)\tLoss 0.2319 (0.3114)\tPrec@1 92.188 (89.706)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [132][210/329], lr: 0.01000\tTime 0.086 (0.097)\tData 0.000 (0.010)\tLoss 0.2716 (0.3093)\tPrec@1 92.188 (89.781)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [132][220/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.000 (0.010)\tLoss 0.1778 (0.3066)\tPrec@1 93.750 (89.879)\tPrec@5 100.000 (99.615)\n",
            "Epoch: [132][230/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.004 (0.010)\tLoss 0.3258 (0.3056)\tPrec@1 88.281 (89.901)\tPrec@5 99.219 (99.611)\n",
            "Epoch: [132][240/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.000 (0.010)\tLoss 0.2309 (0.3030)\tPrec@1 92.188 (89.982)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [132][250/329], lr: 0.01000\tTime 0.077 (0.096)\tData 0.004 (0.010)\tLoss 0.1929 (0.3011)\tPrec@1 94.531 (90.051)\tPrec@5 98.828 (99.617)\n",
            "Epoch: [132][260/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.007 (0.009)\tLoss 0.2576 (0.2994)\tPrec@1 94.531 (90.133)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [132][270/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.011 (0.009)\tLoss 0.2699 (0.2986)\tPrec@1 91.406 (90.157)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [132][280/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.000 (0.009)\tLoss 0.1819 (0.2973)\tPrec@1 94.141 (90.209)\tPrec@5 100.000 (99.630)\n",
            "Epoch: [132][290/329], lr: 0.01000\tTime 0.075 (0.095)\tData 0.000 (0.009)\tLoss 0.2274 (0.2955)\tPrec@1 92.188 (90.264)\tPrec@5 99.609 (99.635)\n",
            "Epoch: [132][300/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.007 (0.009)\tLoss 0.3369 (0.2944)\tPrec@1 88.672 (90.303)\tPrec@5 99.219 (99.635)\n",
            "Epoch: [132][310/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.004 (0.009)\tLoss 0.3183 (0.2942)\tPrec@1 88.281 (90.278)\tPrec@5 100.000 (99.638)\n",
            "Epoch: [132][320/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.047 (0.009)\tLoss 0.2485 (0.2931)\tPrec@1 89.453 (90.309)\tPrec@5 99.609 (99.637)\n",
            "Test: [0/100]\tTime 0.362 (0.362)\tLoss 0.7637 (0.7637)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.042 (0.064)\tLoss 0.7502 (0.8364)\tPrec@1 82.000 (75.455)\tPrec@5 97.000 (98.545)\n",
            "Test: [20/100]\tTime 0.026 (0.043)\tLoss 0.7570 (0.8500)\tPrec@1 72.000 (74.857)\tPrec@5 98.000 (97.857)\n",
            "Test: [30/100]\tTime 0.026 (0.038)\tLoss 1.0542 (0.8746)\tPrec@1 71.000 (74.774)\tPrec@5 97.000 (97.645)\n",
            "Test: [40/100]\tTime 0.028 (0.035)\tLoss 1.1801 (0.8804)\tPrec@1 69.000 (74.463)\tPrec@5 94.000 (97.585)\n",
            "Test: [50/100]\tTime 0.010 (0.032)\tLoss 0.9065 (0.8743)\tPrec@1 73.000 (74.392)\tPrec@5 98.000 (97.588)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 0.6839 (0.8862)\tPrec@1 82.000 (74.180)\tPrec@5 99.000 (97.557)\n",
            "Test: [70/100]\tTime 0.019 (0.031)\tLoss 1.0005 (0.8743)\tPrec@1 74.000 (74.465)\tPrec@5 99.000 (97.563)\n",
            "Test: [80/100]\tTime 0.022 (0.030)\tLoss 0.8381 (0.8687)\tPrec@1 76.000 (74.420)\tPrec@5 97.000 (97.556)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 0.6659 (0.8787)\tPrec@1 83.000 (74.231)\tPrec@5 98.000 (97.484)\n",
            "val Results: Prec@1 74.270 Prec@5 97.490 Loss 0.87556\n",
            "val Class Accuracy: [0.966,0.953,0.816,0.581,0.629,0.819,0.797,0.444,0.682,0.740]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [133][0/329], lr: 0.01000\tTime 0.500 (0.500)\tData 0.425 (0.425)\tLoss 0.2711 (0.2711)\tPrec@1 93.359 (93.359)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [133][10/329], lr: 0.01000\tTime 0.102 (0.149)\tData 0.000 (0.060)\tLoss 0.1637 (0.2381)\tPrec@1 93.750 (92.401)\tPrec@5 99.609 (99.503)\n",
            "Epoch: [133][20/329], lr: 0.01000\tTime 0.102 (0.122)\tData 0.007 (0.033)\tLoss 0.2534 (0.2360)\tPrec@1 91.797 (92.243)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [133][30/329], lr: 0.01000\tTime 0.096 (0.111)\tData 0.006 (0.024)\tLoss 0.2483 (0.2325)\tPrec@1 91.797 (92.490)\tPrec@5 100.000 (99.660)\n",
            "Epoch: [133][40/329], lr: 0.01000\tTime 0.092 (0.106)\tData 0.012 (0.020)\tLoss 0.2850 (0.2390)\tPrec@1 88.672 (92.035)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [133][50/329], lr: 0.01000\tTime 0.103 (0.102)\tData 0.006 (0.018)\tLoss 0.2337 (0.2420)\tPrec@1 93.359 (92.004)\tPrec@5 99.219 (99.678)\n",
            "Epoch: [133][60/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.007 (0.016)\tLoss 0.2666 (0.2440)\tPrec@1 89.453 (91.874)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [133][70/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.000 (0.014)\tLoss 0.1970 (0.2428)\tPrec@1 93.359 (91.863)\tPrec@5 99.219 (99.719)\n",
            "Epoch: [133][80/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.004 (0.013)\tLoss 0.2127 (0.2428)\tPrec@1 92.188 (91.889)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [133][90/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.013)\tLoss 0.3207 (0.2473)\tPrec@1 89.844 (91.771)\tPrec@5 100.000 (99.717)\n",
            "Epoch: [133][100/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.005 (0.012)\tLoss 0.2195 (0.2480)\tPrec@1 94.141 (91.692)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [133][110/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.012)\tLoss 0.3078 (0.2501)\tPrec@1 91.016 (91.642)\tPrec@5 99.219 (99.718)\n",
            "Epoch: [133][120/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.016 (0.012)\tLoss 0.2131 (0.2509)\tPrec@1 92.578 (91.626)\tPrec@5 99.609 (99.716)\n",
            "Epoch: [133][130/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.009 (0.011)\tLoss 0.2124 (0.2484)\tPrec@1 92.578 (91.719)\tPrec@5 100.000 (99.729)\n",
            "Epoch: [133][140/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.011)\tLoss 0.2625 (0.2489)\tPrec@1 91.797 (91.675)\tPrec@5 99.219 (99.709)\n",
            "Epoch: [133][150/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.007 (0.011)\tLoss 0.2789 (0.2481)\tPrec@1 91.016 (91.724)\tPrec@5 99.609 (99.713)\n",
            "Epoch: [133][160/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.006 (0.010)\tLoss 0.2685 (0.2481)\tPrec@1 89.844 (91.741)\tPrec@5 99.609 (99.711)\n",
            "Epoch: [133][170/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.000 (0.010)\tLoss 0.2377 (0.2488)\tPrec@1 91.016 (91.676)\tPrec@5 100.000 (99.712)\n",
            "Epoch: [133][180/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.1781 (0.2475)\tPrec@1 92.969 (91.704)\tPrec@5 100.000 (99.722)\n",
            "Epoch: [133][190/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.000 (0.010)\tLoss 0.2448 (0.2484)\tPrec@1 92.188 (91.682)\tPrec@5 99.219 (99.728)\n",
            "Epoch: [133][200/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.006 (0.010)\tLoss 0.2596 (0.2481)\tPrec@1 92.188 (91.698)\tPrec@5 99.609 (99.730)\n",
            "Epoch: [133][210/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.000 (0.010)\tLoss 0.2951 (0.2492)\tPrec@1 87.891 (91.649)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [133][220/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.000 (0.010)\tLoss 0.2665 (0.2496)\tPrec@1 91.016 (91.641)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [133][230/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.007 (0.010)\tLoss 0.2248 (0.2484)\tPrec@1 92.969 (91.687)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [133][240/329], lr: 0.01000\tTime 0.065 (0.091)\tData 0.000 (0.009)\tLoss 0.2368 (0.2478)\tPrec@1 92.578 (91.690)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [133][250/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.002 (0.009)\tLoss 0.3345 (0.2486)\tPrec@1 88.281 (91.655)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [133][260/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.007 (0.009)\tLoss 0.2405 (0.2487)\tPrec@1 92.578 (91.662)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [133][270/329], lr: 0.01000\tTime 0.058 (0.091)\tData 0.000 (0.009)\tLoss 0.2702 (0.2487)\tPrec@1 92.578 (91.663)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [133][280/329], lr: 0.01000\tTime 0.070 (0.091)\tData 0.000 (0.009)\tLoss 0.2952 (0.2487)\tPrec@1 88.672 (91.640)\tPrec@5 98.828 (99.739)\n",
            "Epoch: [133][290/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.004 (0.009)\tLoss 0.2775 (0.2489)\tPrec@1 91.016 (91.649)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [133][300/329], lr: 0.01000\tTime 0.076 (0.091)\tData 0.010 (0.009)\tLoss 0.3094 (0.2492)\tPrec@1 88.672 (91.622)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [133][310/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.007 (0.009)\tLoss 0.2704 (0.2499)\tPrec@1 89.844 (91.583)\tPrec@5 99.609 (99.731)\n",
            "Epoch: [133][320/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.053 (0.009)\tLoss 0.1865 (0.2497)\tPrec@1 93.359 (91.589)\tPrec@5 100.000 (99.733)\n",
            "Test: [0/100]\tTime 0.360 (0.360)\tLoss 0.9335 (0.9335)\tPrec@1 68.000 (68.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.027 (0.060)\tLoss 0.9008 (1.0099)\tPrec@1 77.000 (72.818)\tPrec@5 96.000 (97.000)\n",
            "Test: [20/100]\tTime 0.019 (0.042)\tLoss 0.7945 (0.9915)\tPrec@1 70.000 (72.000)\tPrec@5 99.000 (97.476)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.2250 (1.0189)\tPrec@1 70.000 (71.774)\tPrec@5 95.000 (97.323)\n",
            "Test: [40/100]\tTime 0.015 (0.033)\tLoss 1.0911 (1.0264)\tPrec@1 73.000 (71.537)\tPrec@5 98.000 (97.268)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 0.9209 (1.0151)\tPrec@1 71.000 (71.588)\tPrec@5 97.000 (97.412)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 0.6820 (1.0090)\tPrec@1 77.000 (71.525)\tPrec@5 99.000 (97.623)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 1.0428 (1.0054)\tPrec@1 74.000 (71.493)\tPrec@5 99.000 (97.592)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.0520 (1.0040)\tPrec@1 72.000 (71.457)\tPrec@5 97.000 (97.617)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 0.9580 (1.0174)\tPrec@1 76.000 (71.330)\tPrec@5 99.000 (97.571)\n",
            "val Results: Prec@1 71.270 Prec@5 97.570 Loss 1.02318\n",
            "val Class Accuracy: [0.970,0.766,0.715,0.664,0.786,0.759,0.582,0.862,0.623,0.400]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [134][0/329], lr: 0.01000\tTime 0.667 (0.667)\tData 0.583 (0.583)\tLoss 0.3333 (0.3333)\tPrec@1 87.891 (87.891)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [134][10/329], lr: 0.01000\tTime 0.098 (0.157)\tData 0.000 (0.060)\tLoss 0.4137 (0.4271)\tPrec@1 87.500 (86.080)\tPrec@5 99.609 (99.396)\n",
            "Epoch: [134][20/329], lr: 0.01000\tTime 0.097 (0.127)\tData 0.006 (0.035)\tLoss 0.3573 (0.3914)\tPrec@1 87.109 (87.091)\tPrec@5 99.219 (99.405)\n",
            "Epoch: [134][30/329], lr: 0.01000\tTime 0.126 (0.117)\tData 0.005 (0.025)\tLoss 0.3223 (0.3553)\tPrec@1 88.281 (88.155)\tPrec@5 100.000 (99.483)\n",
            "Epoch: [134][40/329], lr: 0.01000\tTime 0.107 (0.110)\tData 0.006 (0.021)\tLoss 0.2981 (0.3374)\tPrec@1 89.844 (88.805)\tPrec@5 100.000 (99.543)\n",
            "Epoch: [134][50/329], lr: 0.01000\tTime 0.091 (0.106)\tData 0.000 (0.019)\tLoss 0.2745 (0.3237)\tPrec@1 89.453 (89.239)\tPrec@5 99.219 (99.548)\n",
            "Epoch: [134][60/329], lr: 0.01000\tTime 0.087 (0.103)\tData 0.006 (0.017)\tLoss 0.2038 (0.3126)\tPrec@1 94.922 (89.581)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [134][70/329], lr: 0.01000\tTime 0.093 (0.102)\tData 0.000 (0.015)\tLoss 0.2166 (0.3080)\tPrec@1 92.188 (89.805)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [134][80/329], lr: 0.01000\tTime 0.079 (0.100)\tData 0.000 (0.014)\tLoss 0.2042 (0.3010)\tPrec@1 93.750 (89.950)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [134][90/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.012 (0.014)\tLoss 0.2802 (0.2973)\tPrec@1 90.234 (90.084)\tPrec@5 99.609 (99.631)\n",
            "Epoch: [134][100/329], lr: 0.01000\tTime 0.107 (0.098)\tData 0.000 (0.013)\tLoss 0.2812 (0.2935)\tPrec@1 89.062 (90.149)\tPrec@5 99.609 (99.640)\n",
            "Epoch: [134][110/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.007 (0.012)\tLoss 0.2178 (0.2892)\tPrec@1 92.188 (90.266)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [134][120/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.000 (0.012)\tLoss 0.3366 (0.2873)\tPrec@1 87.109 (90.338)\tPrec@5 98.828 (99.648)\n",
            "Epoch: [134][130/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.000 (0.011)\tLoss 0.2085 (0.2856)\tPrec@1 92.969 (90.413)\tPrec@5 100.000 (99.639)\n",
            "Epoch: [134][140/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.008 (0.011)\tLoss 0.1416 (0.2841)\tPrec@1 96.094 (90.511)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [134][150/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.001 (0.011)\tLoss 0.2598 (0.2823)\tPrec@1 93.359 (90.563)\tPrec@5 100.000 (99.653)\n",
            "Epoch: [134][160/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.005 (0.010)\tLoss 0.1712 (0.2800)\tPrec@1 94.922 (90.630)\tPrec@5 100.000 (99.655)\n",
            "Epoch: [134][170/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.010)\tLoss 0.3103 (0.2781)\tPrec@1 88.281 (90.694)\tPrec@5 100.000 (99.664)\n",
            "Epoch: [134][180/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.007 (0.010)\tLoss 0.2276 (0.2784)\tPrec@1 92.578 (90.685)\tPrec@5 99.219 (99.668)\n",
            "Epoch: [134][190/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.010 (0.010)\tLoss 0.1304 (0.2774)\tPrec@1 96.094 (90.721)\tPrec@5 100.000 (99.673)\n",
            "Epoch: [134][200/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.010)\tLoss 0.2319 (0.2759)\tPrec@1 92.969 (90.747)\tPrec@5 99.609 (99.670)\n",
            "Epoch: [134][210/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.002 (0.010)\tLoss 0.2090 (0.2753)\tPrec@1 92.578 (90.768)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [134][220/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.006 (0.010)\tLoss 0.2650 (0.2742)\tPrec@1 92.188 (90.805)\tPrec@5 99.609 (99.675)\n",
            "Epoch: [134][230/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.005 (0.010)\tLoss 0.2380 (0.2723)\tPrec@1 92.188 (90.847)\tPrec@5 100.000 (99.684)\n",
            "Epoch: [134][240/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.010)\tLoss 0.1644 (0.2719)\tPrec@1 93.750 (90.878)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [134][250/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.000 (0.009)\tLoss 0.3262 (0.2704)\tPrec@1 90.234 (90.921)\tPrec@5 99.609 (99.683)\n",
            "Epoch: [134][260/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.000 (0.009)\tLoss 0.2631 (0.2696)\tPrec@1 92.578 (90.966)\tPrec@5 99.609 (99.690)\n",
            "Epoch: [134][270/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.005 (0.009)\tLoss 0.2014 (0.2688)\tPrec@1 93.359 (90.987)\tPrec@5 99.609 (99.694)\n",
            "Epoch: [134][280/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.004 (0.009)\tLoss 0.2304 (0.2674)\tPrec@1 93.359 (91.049)\tPrec@5 99.609 (99.694)\n",
            "Epoch: [134][290/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.000 (0.009)\tLoss 0.1754 (0.2667)\tPrec@1 92.969 (91.055)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [134][300/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.005 (0.009)\tLoss 0.2947 (0.2657)\tPrec@1 91.797 (91.095)\tPrec@5 98.828 (99.698)\n",
            "Epoch: [134][310/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.007 (0.009)\tLoss 0.1949 (0.2647)\tPrec@1 93.359 (91.127)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [134][320/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.036 (0.009)\tLoss 0.2347 (0.2642)\tPrec@1 91.797 (91.153)\tPrec@5 99.219 (99.698)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 0.6019 (0.6019)\tPrec@1 78.000 (78.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.013 (0.056)\tLoss 0.6492 (0.6982)\tPrec@1 80.000 (78.364)\tPrec@5 98.000 (98.636)\n",
            "Test: [20/100]\tTime 0.043 (0.042)\tLoss 0.6520 (0.6832)\tPrec@1 81.000 (78.857)\tPrec@5 99.000 (98.333)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 0.8867 (0.7199)\tPrec@1 74.000 (77.839)\tPrec@5 98.000 (98.065)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 0.7098 (0.7282)\tPrec@1 80.000 (77.829)\tPrec@5 97.000 (97.854)\n",
            "Test: [50/100]\tTime 0.032 (0.031)\tLoss 0.6703 (0.7197)\tPrec@1 75.000 (78.039)\tPrec@5 98.000 (97.863)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 0.7342 (0.7268)\tPrec@1 81.000 (77.869)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 0.7039 (0.7176)\tPrec@1 80.000 (78.127)\tPrec@5 99.000 (97.958)\n",
            "Test: [80/100]\tTime 0.027 (0.028)\tLoss 0.6676 (0.7133)\tPrec@1 81.000 (78.148)\tPrec@5 97.000 (97.963)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 0.6463 (0.7214)\tPrec@1 83.000 (77.824)\tPrec@5 100.000 (97.967)\n",
            "val Results: Prec@1 77.760 Prec@5 98.010 Loss 0.72391\n",
            "val Class Accuracy: [0.897,0.970,0.804,0.782,0.838,0.747,0.837,0.586,0.684,0.631]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [135][0/329], lr: 0.01000\tTime 0.673 (0.673)\tData 0.588 (0.588)\tLoss 0.2344 (0.2344)\tPrec@1 92.578 (92.578)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [135][10/329], lr: 0.01000\tTime 0.104 (0.146)\tData 0.005 (0.059)\tLoss 0.2205 (0.2477)\tPrec@1 92.969 (91.229)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [135][20/329], lr: 0.01000\tTime 0.093 (0.122)\tData 0.005 (0.035)\tLoss 0.2365 (0.2409)\tPrec@1 91.016 (91.499)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [135][30/329], lr: 0.01000\tTime 0.084 (0.112)\tData 0.000 (0.025)\tLoss 0.2311 (0.2465)\tPrec@1 92.188 (91.431)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [135][40/329], lr: 0.01000\tTime 0.064 (0.105)\tData 0.007 (0.021)\tLoss 0.1732 (0.2400)\tPrec@1 94.141 (91.663)\tPrec@5 99.609 (99.790)\n",
            "Epoch: [135][50/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.000 (0.018)\tLoss 0.2860 (0.2392)\tPrec@1 92.188 (91.766)\tPrec@5 100.000 (99.809)\n",
            "Epoch: [135][60/329], lr: 0.01000\tTime 0.090 (0.100)\tData 0.006 (0.017)\tLoss 0.2547 (0.2398)\tPrec@1 91.406 (91.797)\tPrec@5 100.000 (99.789)\n",
            "Epoch: [135][70/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.004 (0.015)\tLoss 0.2916 (0.2388)\tPrec@1 89.453 (91.852)\tPrec@5 99.219 (99.763)\n",
            "Epoch: [135][80/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.000 (0.014)\tLoss 0.3311 (0.2441)\tPrec@1 88.672 (91.700)\tPrec@5 99.609 (99.749)\n",
            "Epoch: [135][90/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.009 (0.014)\tLoss 0.1973 (0.2413)\tPrec@1 95.312 (91.831)\tPrec@5 100.000 (99.755)\n",
            "Epoch: [135][100/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.007 (0.013)\tLoss 0.2222 (0.2406)\tPrec@1 92.969 (91.890)\tPrec@5 100.000 (99.749)\n",
            "Epoch: [135][110/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.007 (0.013)\tLoss 0.2048 (0.2394)\tPrec@1 92.188 (91.917)\tPrec@5 100.000 (99.761)\n",
            "Epoch: [135][120/329], lr: 0.01000\tTime 0.108 (0.095)\tData 0.007 (0.012)\tLoss 0.2537 (0.2396)\tPrec@1 91.797 (91.926)\tPrec@5 99.609 (99.755)\n",
            "Epoch: [135][130/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.007 (0.012)\tLoss 0.1978 (0.2405)\tPrec@1 92.578 (91.928)\tPrec@5 100.000 (99.741)\n",
            "Epoch: [135][140/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.000 (0.011)\tLoss 0.2293 (0.2381)\tPrec@1 93.750 (92.010)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [135][150/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.006 (0.011)\tLoss 0.2297 (0.2389)\tPrec@1 93.750 (91.999)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [135][160/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.006 (0.011)\tLoss 0.2325 (0.2381)\tPrec@1 91.797 (92.020)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [135][170/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.007 (0.010)\tLoss 0.3006 (0.2397)\tPrec@1 90.625 (91.970)\tPrec@5 99.609 (99.744)\n",
            "Epoch: [135][180/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.000 (0.010)\tLoss 0.2449 (0.2414)\tPrec@1 91.797 (91.924)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [135][190/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.004 (0.010)\tLoss 0.2372 (0.2419)\tPrec@1 93.359 (91.899)\tPrec@5 99.219 (99.736)\n",
            "Epoch: [135][200/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.007 (0.010)\tLoss 0.1992 (0.2414)\tPrec@1 92.578 (91.912)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [135][210/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.006 (0.010)\tLoss 0.1771 (0.2419)\tPrec@1 94.922 (91.889)\tPrec@5 100.000 (99.726)\n",
            "Epoch: [135][220/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.000 (0.010)\tLoss 0.2343 (0.2418)\tPrec@1 92.578 (91.880)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [135][230/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.000 (0.010)\tLoss 0.3395 (0.2414)\tPrec@1 90.234 (91.892)\tPrec@5 100.000 (99.738)\n",
            "Epoch: [135][240/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.015 (0.010)\tLoss 0.3281 (0.2413)\tPrec@1 87.891 (91.896)\tPrec@5 99.609 (99.734)\n",
            "Epoch: [135][250/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.000 (0.010)\tLoss 0.2282 (0.2416)\tPrec@1 92.969 (91.909)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [135][260/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.005 (0.009)\tLoss 0.3256 (0.2419)\tPrec@1 87.109 (91.903)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [135][270/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.010 (0.009)\tLoss 0.2351 (0.2418)\tPrec@1 91.797 (91.927)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [135][280/329], lr: 0.01000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.2320 (0.2422)\tPrec@1 91.797 (91.911)\tPrec@5 100.000 (99.729)\n",
            "Epoch: [135][290/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.001 (0.009)\tLoss 0.3249 (0.2428)\tPrec@1 88.672 (91.863)\tPrec@5 100.000 (99.732)\n",
            "Epoch: [135][300/329], lr: 0.01000\tTime 0.072 (0.091)\tData 0.001 (0.009)\tLoss 0.2417 (0.2431)\tPrec@1 89.844 (91.844)\tPrec@5 100.000 (99.739)\n",
            "Epoch: [135][310/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.000 (0.009)\tLoss 0.2648 (0.2433)\tPrec@1 89.844 (91.830)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [135][320/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.044 (0.009)\tLoss 0.2727 (0.2439)\tPrec@1 91.797 (91.822)\tPrec@5 99.219 (99.736)\n",
            "Test: [0/100]\tTime 0.384 (0.384)\tLoss 1.4079 (1.4079)\tPrec@1 65.000 (65.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.024 (0.057)\tLoss 1.6996 (1.4753)\tPrec@1 63.000 (63.273)\tPrec@5 95.000 (97.636)\n",
            "Test: [20/100]\tTime 0.041 (0.044)\tLoss 1.2034 (1.4007)\tPrec@1 70.000 (65.429)\tPrec@5 100.000 (97.810)\n",
            "Test: [30/100]\tTime 0.010 (0.037)\tLoss 1.6900 (1.3695)\tPrec@1 59.000 (65.323)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 1.2860 (1.3604)\tPrec@1 69.000 (65.488)\tPrec@5 98.000 (97.659)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 1.4207 (1.3500)\tPrec@1 68.000 (65.196)\tPrec@5 98.000 (97.725)\n",
            "Test: [60/100]\tTime 0.014 (0.031)\tLoss 1.2399 (1.3661)\tPrec@1 68.000 (64.672)\tPrec@5 97.000 (97.820)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 1.4154 (1.3621)\tPrec@1 67.000 (64.958)\tPrec@5 100.000 (97.873)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 0.9070 (1.3458)\tPrec@1 78.000 (65.210)\tPrec@5 97.000 (97.914)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.1261 (1.3635)\tPrec@1 72.000 (64.824)\tPrec@5 98.000 (97.857)\n",
            "val Results: Prec@1 64.760 Prec@5 97.870 Loss 1.35868\n",
            "val Class Accuracy: [0.821,0.947,0.958,0.562,0.494,0.539,0.178,0.722,0.554,0.701]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [136][0/329], lr: 0.01000\tTime 0.705 (0.705)\tData 0.613 (0.613)\tLoss 0.2872 (0.2872)\tPrec@1 90.625 (90.625)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [136][10/329], lr: 0.01000\tTime 0.097 (0.149)\tData 0.012 (0.060)\tLoss 0.8056 (0.7443)\tPrec@1 79.297 (77.202)\tPrec@5 96.875 (98.331)\n",
            "Epoch: [136][20/329], lr: 0.01000\tTime 0.081 (0.122)\tData 0.000 (0.033)\tLoss 0.4693 (0.6523)\tPrec@1 85.938 (79.725)\tPrec@5 99.219 (98.382)\n",
            "Epoch: [136][30/329], lr: 0.01000\tTime 0.090 (0.112)\tData 0.004 (0.024)\tLoss 0.3367 (0.5848)\tPrec@1 88.281 (81.641)\tPrec@5 100.000 (98.614)\n",
            "Epoch: [136][40/329], lr: 0.01000\tTime 0.090 (0.106)\tData 0.000 (0.020)\tLoss 0.3380 (0.5353)\tPrec@1 89.062 (83.041)\tPrec@5 100.000 (98.771)\n",
            "Epoch: [136][50/329], lr: 0.01000\tTime 0.099 (0.103)\tData 0.006 (0.018)\tLoss 0.3326 (0.4990)\tPrec@1 90.234 (84.153)\tPrec@5 99.609 (98.935)\n",
            "Epoch: [136][60/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.000 (0.017)\tLoss 0.3134 (0.4736)\tPrec@1 87.891 (84.887)\tPrec@5 100.000 (99.039)\n",
            "Epoch: [136][70/329], lr: 0.01000\tTime 0.095 (0.099)\tData 0.000 (0.015)\tLoss 0.2884 (0.4502)\tPrec@1 89.453 (85.607)\tPrec@5 100.000 (99.114)\n",
            "Epoch: [136][80/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.000 (0.014)\tLoss 0.3803 (0.4350)\tPrec@1 86.719 (85.976)\tPrec@5 99.219 (99.185)\n",
            "Epoch: [136][90/329], lr: 0.01000\tTime 0.113 (0.097)\tData 0.013 (0.014)\tLoss 0.3337 (0.4229)\tPrec@1 88.672 (86.367)\tPrec@5 100.000 (99.245)\n",
            "Epoch: [136][100/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.005 (0.013)\tLoss 0.3133 (0.4072)\tPrec@1 91.016 (86.850)\tPrec@5 99.609 (99.288)\n",
            "Epoch: [136][110/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.012)\tLoss 0.2511 (0.3958)\tPrec@1 91.406 (87.233)\tPrec@5 99.609 (99.328)\n",
            "Epoch: [136][120/329], lr: 0.01000\tTime 0.075 (0.095)\tData 0.000 (0.012)\tLoss 0.2551 (0.3860)\tPrec@1 89.844 (87.536)\tPrec@5 99.609 (99.361)\n",
            "Epoch: [136][130/329], lr: 0.01000\tTime 0.072 (0.095)\tData 0.011 (0.012)\tLoss 0.2934 (0.3789)\tPrec@1 89.844 (87.756)\tPrec@5 100.000 (99.371)\n",
            "Epoch: [136][140/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.007 (0.012)\tLoss 0.2826 (0.3712)\tPrec@1 90.625 (87.996)\tPrec@5 99.609 (99.396)\n",
            "Epoch: [136][150/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.002 (0.011)\tLoss 0.2926 (0.3640)\tPrec@1 90.234 (88.204)\tPrec@5 100.000 (99.426)\n",
            "Epoch: [136][160/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 0.2536 (0.3593)\tPrec@1 92.188 (88.386)\tPrec@5 100.000 (99.447)\n",
            "Epoch: [136][170/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.003 (0.011)\tLoss 0.2993 (0.3541)\tPrec@1 89.062 (88.539)\tPrec@5 100.000 (99.461)\n",
            "Epoch: [136][180/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.008 (0.011)\tLoss 0.1983 (0.3494)\tPrec@1 94.922 (88.652)\tPrec@5 100.000 (99.480)\n",
            "Epoch: [136][190/329], lr: 0.01000\tTime 0.111 (0.097)\tData 0.000 (0.010)\tLoss 0.2372 (0.3452)\tPrec@1 91.797 (88.768)\tPrec@5 100.000 (99.489)\n",
            "Epoch: [136][200/329], lr: 0.01000\tTime 0.105 (0.097)\tData 0.000 (0.010)\tLoss 0.2619 (0.3413)\tPrec@1 90.234 (88.876)\tPrec@5 99.219 (99.489)\n",
            "Epoch: [136][210/329], lr: 0.01000\tTime 0.093 (0.098)\tData 0.005 (0.010)\tLoss 0.2820 (0.3380)\tPrec@1 89.062 (88.964)\tPrec@5 100.000 (99.498)\n",
            "Epoch: [136][220/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.000 (0.010)\tLoss 0.2220 (0.3341)\tPrec@1 92.578 (89.110)\tPrec@5 100.000 (99.514)\n",
            "Epoch: [136][230/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.006 (0.010)\tLoss 0.2601 (0.3307)\tPrec@1 91.797 (89.193)\tPrec@5 100.000 (99.530)\n",
            "Epoch: [136][240/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.010)\tLoss 0.2805 (0.3274)\tPrec@1 91.016 (89.265)\tPrec@5 99.609 (99.543)\n",
            "Epoch: [136][250/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.000 (0.010)\tLoss 0.3118 (0.3254)\tPrec@1 90.234 (89.321)\tPrec@5 100.000 (99.547)\n",
            "Epoch: [136][260/329], lr: 0.01000\tTime 0.068 (0.097)\tData 0.000 (0.009)\tLoss 0.1717 (0.3227)\tPrec@1 93.750 (89.402)\tPrec@5 100.000 (99.550)\n",
            "Epoch: [136][270/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.007 (0.009)\tLoss 0.2536 (0.3203)\tPrec@1 91.016 (89.459)\tPrec@5 100.000 (99.557)\n",
            "Epoch: [136][280/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.000 (0.009)\tLoss 0.2534 (0.3179)\tPrec@1 91.797 (89.530)\tPrec@5 100.000 (99.570)\n",
            "Epoch: [136][290/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.007 (0.009)\tLoss 0.2960 (0.3158)\tPrec@1 91.016 (89.607)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [136][300/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.009)\tLoss 0.2504 (0.3135)\tPrec@1 92.188 (89.682)\tPrec@5 100.000 (99.583)\n",
            "Epoch: [136][310/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.008 (0.009)\tLoss 0.2615 (0.3120)\tPrec@1 92.578 (89.728)\tPrec@5 99.609 (99.588)\n",
            "Epoch: [136][320/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.030 (0.009)\tLoss 0.3821 (0.3109)\tPrec@1 86.719 (89.756)\tPrec@5 99.219 (99.592)\n",
            "Test: [0/100]\tTime 0.398 (0.398)\tLoss 1.2420 (1.2420)\tPrec@1 66.000 (66.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.021 (0.058)\tLoss 1.2893 (1.3114)\tPrec@1 71.000 (65.364)\tPrec@5 96.000 (95.455)\n",
            "Test: [20/100]\tTime 0.021 (0.042)\tLoss 1.1003 (1.2605)\tPrec@1 68.000 (67.143)\tPrec@5 98.000 (95.190)\n",
            "Test: [30/100]\tTime 0.043 (0.038)\tLoss 1.6593 (1.2755)\tPrec@1 57.000 (66.806)\tPrec@5 95.000 (95.613)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 1.3824 (1.2715)\tPrec@1 68.000 (66.805)\tPrec@5 94.000 (95.659)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.3660 (1.2561)\tPrec@1 67.000 (66.863)\tPrec@5 96.000 (95.667)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 1.1363 (1.2528)\tPrec@1 72.000 (67.000)\tPrec@5 94.000 (95.820)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 1.0523 (1.2483)\tPrec@1 71.000 (66.859)\tPrec@5 97.000 (95.887)\n",
            "Test: [80/100]\tTime 0.027 (0.030)\tLoss 1.1606 (1.2359)\tPrec@1 64.000 (67.025)\tPrec@5 96.000 (95.975)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.3209 (1.2552)\tPrec@1 66.000 (66.615)\tPrec@5 96.000 (95.879)\n",
            "val Results: Prec@1 66.780 Prec@5 95.870 Loss 1.24804\n",
            "val Class Accuracy: [0.710,0.948,0.805,0.491,0.664,0.922,0.575,0.612,0.347,0.604]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [137][0/329], lr: 0.01000\tTime 0.701 (0.701)\tData 0.611 (0.611)\tLoss 0.3157 (0.3157)\tPrec@1 86.328 (86.328)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][10/329], lr: 0.01000\tTime 0.087 (0.150)\tData 0.000 (0.062)\tLoss 0.3682 (0.4647)\tPrec@1 87.109 (85.050)\tPrec@5 99.609 (99.077)\n",
            "Epoch: [137][20/329], lr: 0.01000\tTime 0.092 (0.123)\tData 0.004 (0.036)\tLoss 0.3495 (0.4286)\tPrec@1 87.891 (86.161)\tPrec@5 99.219 (99.237)\n",
            "Epoch: [137][30/329], lr: 0.01000\tTime 0.081 (0.112)\tData 0.000 (0.026)\tLoss 0.3257 (0.3941)\tPrec@1 89.844 (87.349)\tPrec@5 99.609 (99.370)\n",
            "Epoch: [137][40/329], lr: 0.01000\tTime 0.081 (0.107)\tData 0.000 (0.022)\tLoss 0.2816 (0.3730)\tPrec@1 92.188 (87.986)\tPrec@5 99.609 (99.447)\n",
            "Epoch: [137][50/329], lr: 0.01000\tTime 0.097 (0.103)\tData 0.000 (0.018)\tLoss 0.2544 (0.3552)\tPrec@1 91.797 (88.603)\tPrec@5 99.609 (99.472)\n",
            "Epoch: [137][60/329], lr: 0.01000\tTime 0.078 (0.101)\tData 0.000 (0.016)\tLoss 0.2204 (0.3397)\tPrec@1 94.531 (89.062)\tPrec@5 100.000 (99.520)\n",
            "Epoch: [137][70/329], lr: 0.01000\tTime 0.082 (0.101)\tData 0.000 (0.015)\tLoss 0.2066 (0.3265)\tPrec@1 92.578 (89.503)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [137][80/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.007 (0.014)\tLoss 0.2562 (0.3161)\tPrec@1 90.625 (89.776)\tPrec@5 99.609 (99.556)\n",
            "Epoch: [137][90/329], lr: 0.01000\tTime 0.079 (0.098)\tData 0.005 (0.013)\tLoss 0.2829 (0.3080)\tPrec@1 89.844 (89.990)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [137][100/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.000 (0.013)\tLoss 0.2574 (0.3024)\tPrec@1 92.969 (90.145)\tPrec@5 100.000 (99.590)\n",
            "Epoch: [137][110/329], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.012)\tLoss 0.2666 (0.2978)\tPrec@1 91.797 (90.301)\tPrec@5 99.219 (99.588)\n",
            "Epoch: [137][120/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.005 (0.012)\tLoss 0.3127 (0.2947)\tPrec@1 89.062 (90.367)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [137][130/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.006 (0.012)\tLoss 0.1585 (0.2902)\tPrec@1 94.531 (90.503)\tPrec@5 100.000 (99.618)\n",
            "Epoch: [137][140/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.006 (0.011)\tLoss 0.2086 (0.2865)\tPrec@1 94.922 (90.614)\tPrec@5 99.219 (99.626)\n",
            "Epoch: [137][150/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.005 (0.011)\tLoss 0.2109 (0.2849)\tPrec@1 92.578 (90.677)\tPrec@5 98.828 (99.622)\n",
            "Epoch: [137][160/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.011 (0.011)\tLoss 0.2623 (0.2824)\tPrec@1 91.406 (90.751)\tPrec@5 100.000 (99.636)\n",
            "Epoch: [137][170/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.006 (0.011)\tLoss 0.2765 (0.2806)\tPrec@1 92.188 (90.803)\tPrec@5 100.000 (99.641)\n",
            "Epoch: [137][180/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.004 (0.011)\tLoss 0.2982 (0.2787)\tPrec@1 92.188 (90.849)\tPrec@5 99.609 (99.653)\n",
            "Epoch: [137][190/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.007 (0.010)\tLoss 0.2832 (0.2771)\tPrec@1 89.844 (90.872)\tPrec@5 100.000 (99.661)\n",
            "Epoch: [137][200/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.005 (0.010)\tLoss 0.2379 (0.2761)\tPrec@1 93.359 (90.893)\tPrec@5 99.609 (99.668)\n",
            "Epoch: [137][210/329], lr: 0.01000\tTime 0.068 (0.093)\tData 0.007 (0.010)\tLoss 0.2722 (0.2757)\tPrec@1 90.625 (90.908)\tPrec@5 98.828 (99.667)\n",
            "Epoch: [137][220/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.2561 (0.2753)\tPrec@1 91.797 (90.917)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [137][230/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.007 (0.010)\tLoss 0.2247 (0.2750)\tPrec@1 92.969 (90.918)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [137][240/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.000 (0.010)\tLoss 0.3418 (0.2752)\tPrec@1 87.891 (90.905)\tPrec@5 99.219 (99.668)\n",
            "Epoch: [137][250/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.004 (0.010)\tLoss 0.3615 (0.2752)\tPrec@1 87.500 (90.904)\tPrec@5 99.609 (99.670)\n",
            "Epoch: [137][260/329], lr: 0.01000\tTime 0.061 (0.092)\tData 0.000 (0.010)\tLoss 0.2388 (0.2741)\tPrec@1 91.797 (90.932)\tPrec@5 99.219 (99.669)\n",
            "Epoch: [137][270/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.004 (0.009)\tLoss 0.2069 (0.2737)\tPrec@1 93.359 (90.948)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [137][280/329], lr: 0.01000\tTime 0.113 (0.092)\tData 0.011 (0.009)\tLoss 0.1868 (0.2723)\tPrec@1 95.312 (90.982)\tPrec@5 99.219 (99.669)\n",
            "Epoch: [137][290/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.005 (0.009)\tLoss 0.2554 (0.2710)\tPrec@1 91.406 (91.025)\tPrec@5 100.000 (99.667)\n",
            "Epoch: [137][300/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.000 (0.009)\tLoss 0.3087 (0.2709)\tPrec@1 89.062 (91.013)\tPrec@5 100.000 (99.666)\n",
            "Epoch: [137][310/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.004 (0.009)\tLoss 0.2492 (0.2706)\tPrec@1 91.016 (91.033)\tPrec@5 99.609 (99.666)\n",
            "Epoch: [137][320/329], lr: 0.01000\tTime 0.112 (0.092)\tData 0.070 (0.009)\tLoss 0.2355 (0.2693)\tPrec@1 91.016 (91.066)\tPrec@5 100.000 (99.674)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 1.8970 (1.8970)\tPrec@1 50.000 (50.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.033 (0.064)\tLoss 1.5769 (1.7360)\tPrec@1 58.000 (55.182)\tPrec@5 97.000 (96.182)\n",
            "Test: [20/100]\tTime 0.034 (0.044)\tLoss 1.6441 (1.7852)\tPrec@1 55.000 (55.095)\tPrec@5 99.000 (96.190)\n",
            "Test: [30/100]\tTime 0.011 (0.037)\tLoss 2.1261 (1.7887)\tPrec@1 54.000 (55.226)\tPrec@5 97.000 (96.452)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 1.6741 (1.7783)\tPrec@1 61.000 (55.220)\tPrec@5 97.000 (96.390)\n",
            "Test: [50/100]\tTime 0.048 (0.033)\tLoss 1.9896 (1.7624)\tPrec@1 50.000 (55.686)\tPrec@5 93.000 (96.196)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 1.5669 (1.7675)\tPrec@1 57.000 (55.475)\tPrec@5 97.000 (96.279)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 1.3464 (1.7564)\tPrec@1 60.000 (55.634)\tPrec@5 97.000 (96.366)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 1.8332 (1.7504)\tPrec@1 53.000 (55.951)\tPrec@5 96.000 (96.272)\n",
            "Test: [90/100]\tTime 0.031 (0.029)\tLoss 1.7745 (1.7661)\tPrec@1 64.000 (55.846)\tPrec@5 98.000 (96.220)\n",
            "val Results: Prec@1 55.850 Prec@5 96.160 Loss 1.76685\n",
            "val Class Accuracy: [0.519,0.568,0.689,0.967,0.547,0.348,0.413,0.695,0.249,0.590]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [138][0/329], lr: 0.01000\tTime 0.672 (0.672)\tData 0.596 (0.596)\tLoss 0.3692 (0.3692)\tPrec@1 87.891 (87.891)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][10/329], lr: 0.01000\tTime 0.099 (0.149)\tData 0.005 (0.060)\tLoss 0.7815 (0.8770)\tPrec@1 74.219 (73.686)\tPrec@5 96.875 (97.692)\n",
            "Epoch: [138][20/329], lr: 0.01000\tTime 0.088 (0.125)\tData 0.004 (0.035)\tLoss 0.5483 (0.7818)\tPrec@1 84.375 (75.856)\tPrec@5 98.438 (97.749)\n",
            "Epoch: [138][30/329], lr: 0.01000\tTime 0.091 (0.113)\tData 0.000 (0.026)\tLoss 0.4862 (0.6786)\tPrec@1 83.984 (78.831)\tPrec@5 99.609 (98.185)\n",
            "Epoch: [138][40/329], lr: 0.01000\tTime 0.079 (0.107)\tData 0.000 (0.021)\tLoss 0.3721 (0.6108)\tPrec@1 87.500 (80.783)\tPrec@5 98.828 (98.447)\n",
            "Epoch: [138][50/329], lr: 0.01000\tTime 0.090 (0.104)\tData 0.000 (0.018)\tLoss 0.2789 (0.5677)\tPrec@1 90.234 (82.161)\tPrec@5 99.609 (98.598)\n",
            "Epoch: [138][60/329], lr: 0.01000\tTime 0.083 (0.102)\tData 0.010 (0.016)\tLoss 0.3407 (0.5310)\tPrec@1 88.672 (83.190)\tPrec@5 99.609 (98.764)\n",
            "Epoch: [138][70/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.006 (0.015)\tLoss 0.3170 (0.5013)\tPrec@1 87.891 (84.072)\tPrec@5 99.219 (98.845)\n",
            "Epoch: [138][80/329], lr: 0.01000\tTime 0.102 (0.098)\tData 0.007 (0.014)\tLoss 0.3521 (0.4813)\tPrec@1 87.109 (84.587)\tPrec@5 100.000 (98.934)\n",
            "Epoch: [138][90/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.006 (0.013)\tLoss 0.2771 (0.4613)\tPrec@1 91.797 (85.255)\tPrec@5 99.609 (98.996)\n",
            "Epoch: [138][100/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.008 (0.012)\tLoss 0.2464 (0.4466)\tPrec@1 92.969 (85.667)\tPrec@5 100.000 (99.041)\n",
            "Epoch: [138][110/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.004 (0.012)\tLoss 0.3466 (0.4335)\tPrec@1 86.719 (86.040)\tPrec@5 99.219 (99.096)\n",
            "Epoch: [138][120/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.002 (0.011)\tLoss 0.2499 (0.4240)\tPrec@1 91.797 (86.360)\tPrec@5 99.609 (99.115)\n",
            "Epoch: [138][130/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.012 (0.011)\tLoss 0.2768 (0.4135)\tPrec@1 91.797 (86.665)\tPrec@5 99.219 (99.147)\n",
            "Epoch: [138][140/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.012 (0.011)\tLoss 0.2996 (0.4050)\tPrec@1 89.453 (86.896)\tPrec@5 99.609 (99.194)\n",
            "Epoch: [138][150/329], lr: 0.01000\tTime 0.110 (0.096)\tData 0.007 (0.010)\tLoss 0.2627 (0.3984)\tPrec@1 90.234 (87.089)\tPrec@5 100.000 (99.214)\n",
            "Epoch: [138][160/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.004 (0.010)\tLoss 0.2743 (0.3928)\tPrec@1 89.062 (87.233)\tPrec@5 100.000 (99.236)\n",
            "Epoch: [138][170/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.004 (0.010)\tLoss 0.4383 (0.3870)\tPrec@1 85.938 (87.436)\tPrec@5 99.609 (99.255)\n",
            "Epoch: [138][180/329], lr: 0.01000\tTime 0.124 (0.096)\tData 0.005 (0.010)\tLoss 0.2878 (0.3823)\tPrec@1 90.234 (87.576)\tPrec@5 99.609 (99.286)\n",
            "Epoch: [138][190/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.010)\tLoss 0.2638 (0.3761)\tPrec@1 89.062 (87.741)\tPrec@5 100.000 (99.321)\n",
            "Epoch: [138][200/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.005 (0.010)\tLoss 0.2897 (0.3714)\tPrec@1 89.062 (87.877)\tPrec@5 100.000 (99.343)\n",
            "Epoch: [138][210/329], lr: 0.01000\tTime 0.073 (0.095)\tData 0.004 (0.010)\tLoss 0.3133 (0.3679)\tPrec@1 91.406 (87.974)\tPrec@5 99.609 (99.352)\n",
            "Epoch: [138][220/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.008 (0.010)\tLoss 0.2491 (0.3634)\tPrec@1 91.406 (88.113)\tPrec@5 100.000 (99.371)\n",
            "Epoch: [138][230/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.006 (0.009)\tLoss 0.2798 (0.3597)\tPrec@1 92.188 (88.247)\tPrec@5 100.000 (99.390)\n",
            "Epoch: [138][240/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.005 (0.009)\tLoss 0.2873 (0.3559)\tPrec@1 90.625 (88.364)\tPrec@5 99.219 (99.400)\n",
            "Epoch: [138][250/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.009)\tLoss 0.2103 (0.3525)\tPrec@1 93.359 (88.466)\tPrec@5 99.219 (99.410)\n",
            "Epoch: [138][260/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.004 (0.009)\tLoss 0.1857 (0.3492)\tPrec@1 94.922 (88.561)\tPrec@5 100.000 (99.416)\n",
            "Epoch: [138][270/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.007 (0.009)\tLoss 0.2430 (0.3467)\tPrec@1 92.969 (88.642)\tPrec@5 99.609 (99.431)\n",
            "Epoch: [138][280/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.004 (0.009)\tLoss 0.2067 (0.3438)\tPrec@1 94.531 (88.726)\tPrec@5 100.000 (99.438)\n",
            "Epoch: [138][290/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.007 (0.009)\tLoss 0.2658 (0.3411)\tPrec@1 89.844 (88.795)\tPrec@5 99.219 (99.444)\n",
            "Epoch: [138][300/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.009)\tLoss 0.3053 (0.3386)\tPrec@1 88.672 (88.868)\tPrec@5 100.000 (99.454)\n",
            "Epoch: [138][310/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.004 (0.009)\tLoss 0.2299 (0.3362)\tPrec@1 91.406 (88.927)\tPrec@5 100.000 (99.466)\n",
            "Epoch: [138][320/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.052 (0.009)\tLoss 0.2978 (0.3335)\tPrec@1 90.625 (89.004)\tPrec@5 100.000 (99.478)\n",
            "Test: [0/100]\tTime 0.391 (0.391)\tLoss 0.6055 (0.6055)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.029 (0.062)\tLoss 0.6568 (0.7416)\tPrec@1 80.000 (76.818)\tPrec@5 98.000 (98.636)\n",
            "Test: [20/100]\tTime 0.043 (0.046)\tLoss 0.6388 (0.7306)\tPrec@1 78.000 (77.762)\tPrec@5 100.000 (98.524)\n",
            "Test: [30/100]\tTime 0.029 (0.037)\tLoss 0.8115 (0.7369)\tPrec@1 74.000 (77.355)\tPrec@5 99.000 (98.581)\n",
            "Test: [40/100]\tTime 0.022 (0.035)\tLoss 0.8091 (0.7419)\tPrec@1 77.000 (77.195)\tPrec@5 99.000 (98.512)\n",
            "Test: [50/100]\tTime 0.030 (0.033)\tLoss 0.7078 (0.7322)\tPrec@1 80.000 (77.431)\tPrec@5 98.000 (98.569)\n",
            "Test: [60/100]\tTime 0.021 (0.033)\tLoss 0.8147 (0.7379)\tPrec@1 77.000 (77.295)\tPrec@5 98.000 (98.623)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 0.8020 (0.7402)\tPrec@1 78.000 (77.239)\tPrec@5 99.000 (98.662)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 0.7065 (0.7346)\tPrec@1 79.000 (77.358)\tPrec@5 98.000 (98.667)\n",
            "Test: [90/100]\tTime 0.027 (0.030)\tLoss 0.6780 (0.7459)\tPrec@1 80.000 (77.165)\tPrec@5 99.000 (98.692)\n",
            "val Results: Prec@1 77.260 Prec@5 98.690 Loss 0.74327\n",
            "val Class Accuracy: [0.915,0.941,0.876,0.609,0.818,0.689,0.785,0.687,0.696,0.710]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [139][0/329], lr: 0.01000\tTime 0.658 (0.658)\tData 0.552 (0.552)\tLoss 0.2482 (0.2482)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][10/329], lr: 0.01000\tTime 0.090 (0.150)\tData 0.004 (0.056)\tLoss 0.2931 (0.2453)\tPrec@1 90.234 (91.193)\tPrec@5 98.828 (99.787)\n",
            "Epoch: [139][20/329], lr: 0.01000\tTime 0.090 (0.126)\tData 0.000 (0.033)\tLoss 0.2338 (0.2428)\tPrec@1 90.234 (91.629)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [139][30/329], lr: 0.01000\tTime 0.088 (0.114)\tData 0.005 (0.024)\tLoss 0.2516 (0.2451)\tPrec@1 89.844 (91.557)\tPrec@5 100.000 (99.786)\n",
            "Epoch: [139][40/329], lr: 0.01000\tTime 0.089 (0.108)\tData 0.000 (0.020)\tLoss 0.1905 (0.2468)\tPrec@1 92.188 (91.502)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [139][50/329], lr: 0.01000\tTime 0.090 (0.105)\tData 0.000 (0.017)\tLoss 0.1926 (0.2497)\tPrec@1 93.359 (91.498)\tPrec@5 99.609 (99.747)\n",
            "Epoch: [139][60/329], lr: 0.01000\tTime 0.072 (0.102)\tData 0.007 (0.016)\tLoss 0.2630 (0.2530)\tPrec@1 89.062 (91.413)\tPrec@5 99.609 (99.731)\n",
            "Epoch: [139][70/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.007 (0.014)\tLoss 0.2453 (0.2532)\tPrec@1 91.406 (91.434)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [139][80/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.000 (0.014)\tLoss 0.3426 (0.2531)\tPrec@1 88.672 (91.440)\tPrec@5 98.828 (99.725)\n",
            "Epoch: [139][90/329], lr: 0.01000\tTime 0.104 (0.099)\tData 0.000 (0.013)\tLoss 0.2280 (0.2526)\tPrec@1 92.969 (91.453)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [139][100/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.009 (0.013)\tLoss 0.2563 (0.2517)\tPrec@1 90.234 (91.507)\tPrec@5 99.609 (99.745)\n",
            "Epoch: [139][110/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.000 (0.012)\tLoss 0.3791 (0.2530)\tPrec@1 88.672 (91.441)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [139][120/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.007 (0.012)\tLoss 0.2326 (0.2522)\tPrec@1 93.359 (91.484)\tPrec@5 100.000 (99.742)\n",
            "Epoch: [139][130/329], lr: 0.01000\tTime 0.110 (0.097)\tData 0.005 (0.012)\tLoss 0.2304 (0.2530)\tPrec@1 93.359 (91.508)\tPrec@5 100.000 (99.735)\n",
            "Epoch: [139][140/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.012 (0.011)\tLoss 0.2890 (0.2522)\tPrec@1 91.016 (91.572)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [139][150/329], lr: 0.01000\tTime 0.068 (0.096)\tData 0.000 (0.011)\tLoss 0.3083 (0.2528)\tPrec@1 89.844 (91.593)\tPrec@5 99.609 (99.726)\n",
            "Epoch: [139][160/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.011)\tLoss 0.2104 (0.2504)\tPrec@1 93.750 (91.668)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [139][170/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.007 (0.011)\tLoss 0.2754 (0.2509)\tPrec@1 90.625 (91.660)\tPrec@5 99.219 (99.737)\n",
            "Epoch: [139][180/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.004 (0.010)\tLoss 0.2383 (0.2506)\tPrec@1 91.406 (91.687)\tPrec@5 99.609 (99.728)\n",
            "Epoch: [139][190/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.010)\tLoss 0.3324 (0.2512)\tPrec@1 89.062 (91.639)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [139][200/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.000 (0.010)\tLoss 0.2489 (0.2505)\tPrec@1 92.188 (91.663)\tPrec@5 100.000 (99.738)\n",
            "Epoch: [139][210/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.008 (0.010)\tLoss 0.2162 (0.2504)\tPrec@1 93.359 (91.691)\tPrec@5 99.609 (99.733)\n",
            "Epoch: [139][220/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.012 (0.010)\tLoss 0.2697 (0.2501)\tPrec@1 91.406 (91.707)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [139][230/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.005 (0.010)\tLoss 0.2437 (0.2507)\tPrec@1 92.578 (91.690)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [139][240/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.004 (0.010)\tLoss 0.2789 (0.2494)\tPrec@1 89.844 (91.721)\tPrec@5 99.609 (99.737)\n",
            "Epoch: [139][250/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.006 (0.010)\tLoss 0.2951 (0.2493)\tPrec@1 88.672 (91.713)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [139][260/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.006 (0.010)\tLoss 0.2710 (0.2490)\tPrec@1 91.406 (91.725)\tPrec@5 99.609 (99.747)\n",
            "Epoch: [139][270/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.005 (0.010)\tLoss 0.3643 (0.2495)\tPrec@1 87.500 (91.703)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [139][280/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.001 (0.010)\tLoss 0.2137 (0.2495)\tPrec@1 91.406 (91.700)\tPrec@5 99.609 (99.746)\n",
            "Epoch: [139][290/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.000 (0.010)\tLoss 0.2451 (0.2496)\tPrec@1 90.234 (91.669)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [139][300/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.011 (0.009)\tLoss 0.1720 (0.2495)\tPrec@1 93.750 (91.666)\tPrec@5 100.000 (99.746)\n",
            "Epoch: [139][310/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.007 (0.009)\tLoss 0.2561 (0.2498)\tPrec@1 90.625 (91.656)\tPrec@5 99.609 (99.748)\n",
            "Epoch: [139][320/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.050 (0.009)\tLoss 0.2112 (0.2502)\tPrec@1 93.359 (91.651)\tPrec@5 99.609 (99.741)\n",
            "Test: [0/100]\tTime 0.370 (0.370)\tLoss 0.5583 (0.5583)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.049 (0.059)\tLoss 0.6412 (0.7391)\tPrec@1 78.000 (77.000)\tPrec@5 99.000 (98.636)\n",
            "Test: [20/100]\tTime 0.020 (0.043)\tLoss 0.7594 (0.7262)\tPrec@1 80.000 (78.286)\tPrec@5 99.000 (98.476)\n",
            "Test: [30/100]\tTime 0.016 (0.037)\tLoss 0.8662 (0.7300)\tPrec@1 79.000 (78.065)\tPrec@5 99.000 (98.387)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 0.7947 (0.7319)\tPrec@1 77.000 (78.073)\tPrec@5 99.000 (98.439)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 0.6756 (0.7263)\tPrec@1 82.000 (78.275)\tPrec@5 98.000 (98.392)\n",
            "Test: [60/100]\tTime 0.038 (0.030)\tLoss 0.6684 (0.7250)\tPrec@1 77.000 (78.164)\tPrec@5 99.000 (98.541)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 0.6450 (0.7185)\tPrec@1 81.000 (78.169)\tPrec@5 99.000 (98.592)\n",
            "Test: [80/100]\tTime 0.050 (0.029)\tLoss 0.7161 (0.7163)\tPrec@1 78.000 (78.136)\tPrec@5 98.000 (98.630)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 0.6910 (0.7232)\tPrec@1 80.000 (77.989)\tPrec@5 100.000 (98.626)\n",
            "val Results: Prec@1 77.930 Prec@5 98.640 Loss 0.71845\n",
            "val Class Accuracy: [0.852,0.982,0.769,0.558,0.737,0.907,0.811,0.692,0.819,0.666]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [140][0/329], lr: 0.01000\tTime 0.558 (0.558)\tData 0.485 (0.485)\tLoss 0.2470 (0.2470)\tPrec@1 91.797 (91.797)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [140][10/329], lr: 0.01000\tTime 0.114 (0.151)\tData 0.012 (0.058)\tLoss 0.4146 (0.3244)\tPrec@1 83.984 (88.636)\tPrec@5 99.609 (99.645)\n",
            "Epoch: [140][20/329], lr: 0.01000\tTime 0.077 (0.123)\tData 0.012 (0.034)\tLoss 0.2781 (0.3149)\tPrec@1 92.969 (89.435)\tPrec@5 99.609 (99.665)\n",
            "Epoch: [140][30/329], lr: 0.01000\tTime 0.105 (0.112)\tData 0.007 (0.026)\tLoss 0.2157 (0.3035)\tPrec@1 93.359 (89.856)\tPrec@5 99.609 (99.698)\n",
            "Epoch: [140][40/329], lr: 0.01000\tTime 0.094 (0.107)\tData 0.006 (0.021)\tLoss 0.2183 (0.2950)\tPrec@1 92.969 (90.158)\tPrec@5 99.609 (99.667)\n",
            "Epoch: [140][50/329], lr: 0.01000\tTime 0.071 (0.103)\tData 0.000 (0.018)\tLoss 0.2365 (0.2849)\tPrec@1 92.578 (90.541)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [140][60/329], lr: 0.01000\tTime 0.080 (0.101)\tData 0.000 (0.016)\tLoss 0.2416 (0.2801)\tPrec@1 92.188 (90.715)\tPrec@5 99.609 (99.718)\n",
            "Epoch: [140][70/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.007 (0.015)\tLoss 0.2085 (0.2733)\tPrec@1 93.359 (90.939)\tPrec@5 99.609 (99.736)\n",
            "Epoch: [140][80/329], lr: 0.01000\tTime 0.059 (0.099)\tData 0.000 (0.014)\tLoss 0.2086 (0.2695)\tPrec@1 94.141 (91.054)\tPrec@5 99.609 (99.735)\n",
            "Epoch: [140][90/329], lr: 0.01000\tTime 0.103 (0.099)\tData 0.014 (0.013)\tLoss 0.2044 (0.2686)\tPrec@1 94.141 (91.106)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [140][100/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.006 (0.013)\tLoss 0.1961 (0.2640)\tPrec@1 94.531 (91.259)\tPrec@5 100.000 (99.760)\n",
            "Epoch: [140][110/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.006 (0.012)\tLoss 0.2170 (0.2641)\tPrec@1 94.141 (91.255)\tPrec@5 100.000 (99.764)\n",
            "Epoch: [140][120/329], lr: 0.01000\tTime 0.075 (0.096)\tData 0.000 (0.012)\tLoss 0.2570 (0.2630)\tPrec@1 91.406 (91.293)\tPrec@5 99.609 (99.764)\n",
            "Epoch: [140][130/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.000 (0.011)\tLoss 0.3525 (0.2631)\tPrec@1 88.281 (91.302)\tPrec@5 99.609 (99.761)\n",
            "Epoch: [140][140/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.006 (0.011)\tLoss 0.2362 (0.2612)\tPrec@1 91.016 (91.356)\tPrec@5 100.000 (99.762)\n",
            "Epoch: [140][150/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.000 (0.011)\tLoss 0.2929 (0.2592)\tPrec@1 91.406 (91.424)\tPrec@5 99.609 (99.765)\n",
            "Epoch: [140][160/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.006 (0.010)\tLoss 0.2234 (0.2594)\tPrec@1 92.578 (91.404)\tPrec@5 100.000 (99.760)\n",
            "Epoch: [140][170/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.010)\tLoss 0.2735 (0.2585)\tPrec@1 92.188 (91.418)\tPrec@5 99.609 (99.762)\n",
            "Epoch: [140][180/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.007 (0.010)\tLoss 0.2188 (0.2584)\tPrec@1 91.406 (91.421)\tPrec@5 100.000 (99.754)\n",
            "Epoch: [140][190/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.005 (0.010)\tLoss 0.2901 (0.2587)\tPrec@1 89.062 (91.447)\tPrec@5 100.000 (99.757)\n",
            "Epoch: [140][200/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.000 (0.010)\tLoss 0.2791 (0.2577)\tPrec@1 87.891 (91.437)\tPrec@5 100.000 (99.763)\n",
            "Epoch: [140][210/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.007 (0.009)\tLoss 0.3130 (0.2576)\tPrec@1 90.234 (91.404)\tPrec@5 99.219 (99.759)\n",
            "Epoch: [140][220/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.009 (0.009)\tLoss 0.2244 (0.2554)\tPrec@1 92.969 (91.472)\tPrec@5 99.609 (99.765)\n",
            "Epoch: [140][230/329], lr: 0.01000\tTime 0.131 (0.096)\tData 0.014 (0.010)\tLoss 0.1692 (0.2554)\tPrec@1 93.750 (91.476)\tPrec@5 100.000 (99.767)\n",
            "Epoch: [140][240/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.006 (0.011)\tLoss 0.2404 (0.2547)\tPrec@1 92.578 (91.523)\tPrec@5 99.219 (99.758)\n",
            "Epoch: [140][250/329], lr: 0.01000\tTime 0.135 (0.096)\tData 0.008 (0.011)\tLoss 0.2012 (0.2537)\tPrec@1 93.359 (91.567)\tPrec@5 100.000 (99.756)\n",
            "Epoch: [140][260/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.005 (0.011)\tLoss 0.2808 (0.2542)\tPrec@1 90.625 (91.554)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [140][270/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.000 (0.011)\tLoss 0.1975 (0.2539)\tPrec@1 92.578 (91.562)\tPrec@5 100.000 (99.761)\n",
            "Epoch: [140][280/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.011)\tLoss 0.2044 (0.2540)\tPrec@1 93.750 (91.545)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [140][290/329], lr: 0.01000\tTime 0.071 (0.096)\tData 0.000 (0.010)\tLoss 0.2337 (0.2538)\tPrec@1 92.188 (91.547)\tPrec@5 100.000 (99.760)\n",
            "Epoch: [140][300/329], lr: 0.01000\tTime 0.068 (0.096)\tData 0.008 (0.010)\tLoss 0.2460 (0.2536)\tPrec@1 92.188 (91.578)\tPrec@5 100.000 (99.756)\n",
            "Epoch: [140][310/329], lr: 0.01000\tTime 0.068 (0.095)\tData 0.000 (0.010)\tLoss 0.3358 (0.2536)\tPrec@1 88.672 (91.596)\tPrec@5 99.609 (99.756)\n",
            "Epoch: [140][320/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.037 (0.010)\tLoss 0.2521 (0.2533)\tPrec@1 89.844 (91.594)\tPrec@5 100.000 (99.759)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 0.6642 (0.6642)\tPrec@1 79.000 (79.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.018 (0.059)\tLoss 0.5904 (0.7761)\tPrec@1 83.000 (77.182)\tPrec@5 99.000 (99.000)\n",
            "Test: [20/100]\tTime 0.027 (0.040)\tLoss 0.7394 (0.7568)\tPrec@1 76.000 (78.143)\tPrec@5 100.000 (98.524)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 0.9219 (0.7620)\tPrec@1 68.000 (77.452)\tPrec@5 98.000 (98.484)\n",
            "Test: [40/100]\tTime 0.013 (0.032)\tLoss 0.9353 (0.7757)\tPrec@1 73.000 (77.122)\tPrec@5 97.000 (98.220)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 0.8678 (0.7649)\tPrec@1 78.000 (77.314)\tPrec@5 97.000 (98.235)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 0.8260 (0.7768)\tPrec@1 78.000 (76.836)\tPrec@5 99.000 (98.262)\n",
            "Test: [70/100]\tTime 0.011 (0.029)\tLoss 0.7625 (0.7714)\tPrec@1 76.000 (76.845)\tPrec@5 99.000 (98.324)\n",
            "Test: [80/100]\tTime 0.066 (0.029)\tLoss 0.6009 (0.7638)\tPrec@1 80.000 (76.877)\tPrec@5 98.000 (98.346)\n",
            "Test: [90/100]\tTime 0.025 (0.028)\tLoss 0.7301 (0.7773)\tPrec@1 76.000 (76.451)\tPrec@5 99.000 (98.275)\n",
            "val Results: Prec@1 76.450 Prec@5 98.290 Loss 0.77850\n",
            "val Class Accuracy: [0.915,0.979,0.795,0.746,0.893,0.722,0.776,0.467,0.644,0.708]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [141][0/329], lr: 0.01000\tTime 0.689 (0.689)\tData 0.602 (0.602)\tLoss 0.2396 (0.2396)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [141][10/329], lr: 0.01000\tTime 0.081 (0.150)\tData 0.004 (0.062)\tLoss 0.2822 (0.2402)\tPrec@1 91.797 (92.116)\tPrec@5 99.219 (99.787)\n",
            "Epoch: [141][20/329], lr: 0.01000\tTime 0.105 (0.125)\tData 0.000 (0.036)\tLoss 0.2812 (0.2403)\tPrec@1 91.406 (92.094)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [141][30/329], lr: 0.01000\tTime 0.086 (0.114)\tData 0.008 (0.027)\tLoss 0.2770 (0.2310)\tPrec@1 90.234 (92.351)\tPrec@5 99.609 (99.773)\n",
            "Epoch: [141][40/329], lr: 0.01000\tTime 0.082 (0.108)\tData 0.006 (0.023)\tLoss 0.2735 (0.2311)\tPrec@1 91.406 (92.311)\tPrec@5 99.219 (99.800)\n",
            "Epoch: [141][50/329], lr: 0.01000\tTime 0.091 (0.104)\tData 0.000 (0.020)\tLoss 0.2320 (0.2311)\tPrec@1 92.188 (92.371)\tPrec@5 100.000 (99.809)\n",
            "Epoch: [141][60/329], lr: 0.01000\tTime 0.067 (0.101)\tData 0.007 (0.018)\tLoss 0.2225 (0.2343)\tPrec@1 92.969 (92.296)\tPrec@5 99.609 (99.801)\n",
            "Epoch: [141][70/329], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.016)\tLoss 0.2398 (0.2368)\tPrec@1 92.969 (92.193)\tPrec@5 99.609 (99.802)\n",
            "Epoch: [141][80/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.007 (0.015)\tLoss 0.2474 (0.2357)\tPrec@1 92.969 (92.250)\tPrec@5 99.609 (99.802)\n",
            "Epoch: [141][90/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.004 (0.015)\tLoss 0.3736 (0.2343)\tPrec@1 90.234 (92.329)\tPrec@5 99.609 (99.807)\n",
            "Epoch: [141][100/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.005 (0.014)\tLoss 0.3000 (0.2353)\tPrec@1 91.016 (92.288)\tPrec@5 98.438 (99.791)\n",
            "Epoch: [141][110/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.011 (0.013)\tLoss 0.2888 (0.2383)\tPrec@1 89.844 (92.195)\tPrec@5 100.000 (99.803)\n",
            "Epoch: [141][120/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.012 (0.013)\tLoss 0.2085 (0.2392)\tPrec@1 93.359 (92.142)\tPrec@5 100.000 (99.793)\n",
            "Epoch: [141][130/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.001 (0.012)\tLoss 0.2079 (0.2379)\tPrec@1 93.750 (92.182)\tPrec@5 100.000 (99.791)\n",
            "Epoch: [141][140/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.005 (0.012)\tLoss 0.2398 (0.2388)\tPrec@1 90.234 (92.146)\tPrec@5 99.609 (99.781)\n",
            "Epoch: [141][150/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.003 (0.011)\tLoss 0.2838 (0.2381)\tPrec@1 91.016 (92.169)\tPrec@5 99.219 (99.780)\n",
            "Epoch: [141][160/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.004 (0.011)\tLoss 0.2389 (0.2388)\tPrec@1 91.406 (92.117)\tPrec@5 100.000 (99.774)\n",
            "Epoch: [141][170/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.000 (0.011)\tLoss 0.2358 (0.2389)\tPrec@1 92.969 (92.105)\tPrec@5 99.609 (99.772)\n",
            "Epoch: [141][180/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.000 (0.010)\tLoss 0.1675 (0.2387)\tPrec@1 93.750 (92.099)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [141][190/329], lr: 0.01000\tTime 0.106 (0.094)\tData 0.010 (0.010)\tLoss 0.2210 (0.2396)\tPrec@1 91.406 (92.050)\tPrec@5 99.609 (99.761)\n",
            "Epoch: [141][200/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.006 (0.010)\tLoss 0.2059 (0.2399)\tPrec@1 91.016 (92.020)\tPrec@5 100.000 (99.767)\n",
            "Epoch: [141][210/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.008 (0.010)\tLoss 0.2379 (0.2395)\tPrec@1 92.578 (92.043)\tPrec@5 100.000 (99.761)\n",
            "Epoch: [141][220/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.012 (0.010)\tLoss 0.2474 (0.2392)\tPrec@1 91.016 (92.034)\tPrec@5 99.219 (99.761)\n",
            "Epoch: [141][230/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.000 (0.010)\tLoss 0.2634 (0.2393)\tPrec@1 89.062 (92.017)\tPrec@5 99.609 (99.762)\n",
            "Epoch: [141][240/329], lr: 0.01000\tTime 0.069 (0.093)\tData 0.000 (0.010)\tLoss 0.1985 (0.2393)\tPrec@1 92.969 (92.011)\tPrec@5 100.000 (99.770)\n",
            "Epoch: [141][250/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.000 (0.010)\tLoss 0.3150 (0.2398)\tPrec@1 89.062 (91.987)\tPrec@5 99.219 (99.767)\n",
            "Epoch: [141][260/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.003 (0.009)\tLoss 0.1980 (0.2402)\tPrec@1 92.578 (91.979)\tPrec@5 99.219 (99.759)\n",
            "Epoch: [141][270/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.000 (0.009)\tLoss 0.2856 (0.2404)\tPrec@1 90.625 (91.963)\tPrec@5 99.219 (99.758)\n",
            "Epoch: [141][280/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.009)\tLoss 0.2011 (0.2401)\tPrec@1 92.969 (91.972)\tPrec@5 100.000 (99.760)\n",
            "Epoch: [141][290/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.000 (0.009)\tLoss 0.2624 (0.2399)\tPrec@1 90.625 (91.978)\tPrec@5 100.000 (99.762)\n",
            "Epoch: [141][300/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.015 (0.009)\tLoss 0.2530 (0.2395)\tPrec@1 91.406 (91.980)\tPrec@5 100.000 (99.766)\n",
            "Epoch: [141][310/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.009)\tLoss 0.2938 (0.2401)\tPrec@1 89.844 (91.959)\tPrec@5 100.000 (99.759)\n",
            "Epoch: [141][320/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.065 (0.009)\tLoss 0.1766 (0.2404)\tPrec@1 94.531 (91.966)\tPrec@5 100.000 (99.759)\n",
            "Test: [0/100]\tTime 0.336 (0.336)\tLoss 0.8942 (0.8942)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.060)\tLoss 0.9369 (1.1898)\tPrec@1 75.000 (68.273)\tPrec@5 96.000 (96.000)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 0.9800 (1.1616)\tPrec@1 69.000 (69.238)\tPrec@5 99.000 (96.095)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 1.3419 (1.1933)\tPrec@1 68.000 (68.839)\tPrec@5 93.000 (95.645)\n",
            "Test: [40/100]\tTime 0.027 (0.034)\tLoss 1.4073 (1.2098)\tPrec@1 66.000 (68.854)\tPrec@5 96.000 (95.585)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 1.4110 (1.2082)\tPrec@1 67.000 (69.039)\tPrec@5 94.000 (95.608)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 0.9565 (1.2073)\tPrec@1 73.000 (68.934)\tPrec@5 96.000 (95.607)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 1.2977 (1.1963)\tPrec@1 65.000 (69.028)\tPrec@5 97.000 (95.704)\n",
            "Test: [80/100]\tTime 0.038 (0.030)\tLoss 1.1729 (1.1889)\tPrec@1 68.000 (68.938)\tPrec@5 94.000 (95.728)\n",
            "Test: [90/100]\tTime 0.035 (0.029)\tLoss 1.2139 (1.1942)\tPrec@1 66.000 (68.846)\tPrec@5 98.000 (95.670)\n",
            "val Results: Prec@1 68.640 Prec@5 95.590 Loss 1.19893\n",
            "val Class Accuracy: [0.932,0.915,0.725,0.706,0.691,0.694,0.926,0.313,0.523,0.439]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [142][0/329], lr: 0.01000\tTime 0.577 (0.577)\tData 0.492 (0.492)\tLoss 0.2371 (0.2371)\tPrec@1 93.359 (93.359)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][10/329], lr: 0.01000\tTime 0.093 (0.140)\tData 0.005 (0.059)\tLoss 0.4305 (0.4313)\tPrec@1 85.156 (86.151)\tPrec@5 98.828 (99.148)\n",
            "Epoch: [142][20/329], lr: 0.01000\tTime 0.095 (0.118)\tData 0.035 (0.040)\tLoss 0.3837 (0.4051)\tPrec@1 87.109 (86.830)\tPrec@5 99.219 (99.200)\n",
            "Epoch: [142][30/329], lr: 0.01000\tTime 0.073 (0.110)\tData 0.000 (0.029)\tLoss 0.2327 (0.3646)\tPrec@1 93.359 (88.080)\tPrec@5 99.609 (99.408)\n",
            "Epoch: [142][40/329], lr: 0.01000\tTime 0.072 (0.106)\tData 0.009 (0.024)\tLoss 0.2504 (0.3439)\tPrec@1 90.625 (88.729)\tPrec@5 100.000 (99.476)\n",
            "Epoch: [142][50/329], lr: 0.01000\tTime 0.114 (0.104)\tData 0.000 (0.020)\tLoss 0.2430 (0.3305)\tPrec@1 91.797 (89.170)\tPrec@5 100.000 (99.517)\n",
            "Epoch: [142][60/329], lr: 0.01000\tTime 0.090 (0.102)\tData 0.007 (0.018)\tLoss 0.2900 (0.3183)\tPrec@1 88.672 (89.600)\tPrec@5 99.609 (99.533)\n",
            "Epoch: [142][70/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.000 (0.017)\tLoss 0.2827 (0.3092)\tPrec@1 93.359 (89.816)\tPrec@5 99.609 (99.576)\n",
            "Epoch: [142][80/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.000 (0.016)\tLoss 0.4336 (0.3045)\tPrec@1 85.156 (89.882)\tPrec@5 99.219 (99.590)\n",
            "Epoch: [142][90/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.004 (0.015)\tLoss 0.2420 (0.2991)\tPrec@1 91.797 (90.037)\tPrec@5 100.000 (99.605)\n",
            "Epoch: [142][100/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.007 (0.014)\tLoss 0.2231 (0.2925)\tPrec@1 91.406 (90.258)\tPrec@5 100.000 (99.629)\n",
            "Epoch: [142][110/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.013)\tLoss 0.2404 (0.2885)\tPrec@1 92.188 (90.361)\tPrec@5 99.609 (99.648)\n",
            "Epoch: [142][120/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.013)\tLoss 0.1807 (0.2835)\tPrec@1 94.141 (90.509)\tPrec@5 100.000 (99.651)\n",
            "Epoch: [142][130/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.000 (0.012)\tLoss 0.2439 (0.2801)\tPrec@1 92.188 (90.625)\tPrec@5 99.609 (99.654)\n",
            "Epoch: [142][140/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.005 (0.012)\tLoss 0.3417 (0.2788)\tPrec@1 88.672 (90.678)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [142][150/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.011 (0.012)\tLoss 0.2292 (0.2763)\tPrec@1 93.750 (90.788)\tPrec@5 99.609 (99.661)\n",
            "Epoch: [142][160/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.000 (0.012)\tLoss 0.2081 (0.2728)\tPrec@1 92.578 (90.923)\tPrec@5 100.000 (99.670)\n",
            "Epoch: [142][170/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.011)\tLoss 0.2523 (0.2713)\tPrec@1 91.797 (90.986)\tPrec@5 99.219 (99.680)\n",
            "Epoch: [142][180/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.000 (0.011)\tLoss 0.3512 (0.2701)\tPrec@1 89.062 (91.039)\tPrec@5 99.609 (99.681)\n",
            "Epoch: [142][190/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.007 (0.011)\tLoss 0.2775 (0.2692)\tPrec@1 89.062 (91.044)\tPrec@5 99.219 (99.679)\n",
            "Epoch: [142][200/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.011)\tLoss 0.1472 (0.2678)\tPrec@1 95.312 (91.080)\tPrec@5 100.000 (99.687)\n",
            "Epoch: [142][210/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.011)\tLoss 0.2874 (0.2674)\tPrec@1 91.797 (91.088)\tPrec@5 99.609 (99.685)\n",
            "Epoch: [142][220/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.011)\tLoss 0.2132 (0.2659)\tPrec@1 92.969 (91.134)\tPrec@5 100.000 (99.691)\n",
            "Epoch: [142][230/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.008 (0.010)\tLoss 0.2780 (0.2650)\tPrec@1 92.188 (91.176)\tPrec@5 99.609 (99.689)\n",
            "Epoch: [142][240/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.009 (0.010)\tLoss 0.2436 (0.2640)\tPrec@1 90.234 (91.204)\tPrec@5 99.609 (99.697)\n",
            "Epoch: [142][250/329], lr: 0.01000\tTime 0.067 (0.093)\tData 0.000 (0.010)\tLoss 0.2803 (0.2629)\tPrec@1 91.797 (91.237)\tPrec@5 100.000 (99.701)\n",
            "Epoch: [142][260/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.007 (0.010)\tLoss 0.2786 (0.2623)\tPrec@1 91.016 (91.257)\tPrec@5 99.219 (99.704)\n",
            "Epoch: [142][270/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.000 (0.010)\tLoss 0.2479 (0.2618)\tPrec@1 90.234 (91.272)\tPrec@5 99.609 (99.705)\n",
            "Epoch: [142][280/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.008 (0.010)\tLoss 0.1944 (0.2614)\tPrec@1 92.188 (91.277)\tPrec@5 99.609 (99.708)\n",
            "Epoch: [142][290/329], lr: 0.01000\tTime 0.105 (0.093)\tData 0.000 (0.010)\tLoss 0.2916 (0.2618)\tPrec@1 91.406 (91.276)\tPrec@5 100.000 (99.713)\n",
            "Epoch: [142][300/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.007 (0.010)\tLoss 0.2692 (0.2618)\tPrec@1 90.625 (91.263)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [142][310/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.001 (0.010)\tLoss 0.2290 (0.2615)\tPrec@1 91.406 (91.256)\tPrec@5 100.000 (99.711)\n",
            "Epoch: [142][320/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.058 (0.010)\tLoss 0.2214 (0.2605)\tPrec@1 91.406 (91.265)\tPrec@5 100.000 (99.713)\n",
            "Test: [0/100]\tTime 0.424 (0.424)\tLoss 1.1317 (1.1317)\tPrec@1 68.000 (68.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.057)\tLoss 1.0884 (1.2745)\tPrec@1 75.000 (66.636)\tPrec@5 96.000 (98.636)\n",
            "Test: [20/100]\tTime 0.016 (0.042)\tLoss 1.1899 (1.2764)\tPrec@1 70.000 (67.714)\tPrec@5 100.000 (98.524)\n",
            "Test: [30/100]\tTime 0.024 (0.038)\tLoss 1.4369 (1.3032)\tPrec@1 65.000 (67.839)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/100]\tTime 0.045 (0.035)\tLoss 1.3124 (1.2975)\tPrec@1 65.000 (67.659)\tPrec@5 99.000 (98.341)\n",
            "Test: [50/100]\tTime 0.034 (0.033)\tLoss 1.2621 (1.2776)\tPrec@1 65.000 (68.078)\tPrec@5 97.000 (98.255)\n",
            "Test: [60/100]\tTime 0.025 (0.032)\tLoss 1.3492 (1.2919)\tPrec@1 67.000 (67.443)\tPrec@5 98.000 (98.230)\n",
            "Test: [70/100]\tTime 0.026 (0.031)\tLoss 1.1141 (1.2733)\tPrec@1 71.000 (67.563)\tPrec@5 100.000 (98.296)\n",
            "Test: [80/100]\tTime 0.011 (0.031)\tLoss 0.9874 (1.2621)\tPrec@1 77.000 (67.840)\tPrec@5 95.000 (98.272)\n",
            "Test: [90/100]\tTime 0.029 (0.030)\tLoss 1.2916 (1.2774)\tPrec@1 66.000 (67.516)\tPrec@5 98.000 (98.231)\n",
            "val Results: Prec@1 67.620 Prec@5 98.230 Loss 1.27270\n",
            "val Class Accuracy: [0.924,0.957,0.618,0.955,0.577,0.447,0.491,0.550,0.611,0.632]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [143][0/329], lr: 0.01000\tTime 0.681 (0.681)\tData 0.601 (0.601)\tLoss 0.2114 (0.2114)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][10/329], lr: 0.01000\tTime 0.094 (0.154)\tData 0.001 (0.060)\tLoss 0.4505 (0.5147)\tPrec@1 82.422 (83.168)\tPrec@5 99.609 (99.112)\n",
            "Epoch: [143][20/329], lr: 0.01000\tTime 0.091 (0.125)\tData 0.006 (0.034)\tLoss 0.4553 (0.4993)\tPrec@1 84.766 (83.705)\tPrec@5 99.219 (99.163)\n",
            "Epoch: [143][30/329], lr: 0.01000\tTime 0.113 (0.114)\tData 0.005 (0.025)\tLoss 0.3688 (0.4534)\tPrec@1 88.281 (84.917)\tPrec@5 100.000 (99.282)\n",
            "Epoch: [143][40/329], lr: 0.01000\tTime 0.086 (0.109)\tData 0.004 (0.020)\tLoss 0.3446 (0.4248)\tPrec@1 88.672 (85.756)\tPrec@5 99.219 (99.381)\n",
            "Epoch: [143][50/329], lr: 0.01000\tTime 0.099 (0.105)\tData 0.000 (0.018)\tLoss 0.2354 (0.3994)\tPrec@1 92.969 (86.566)\tPrec@5 100.000 (99.433)\n",
            "Epoch: [143][60/329], lr: 0.01000\tTime 0.102 (0.103)\tData 0.012 (0.016)\tLoss 0.3927 (0.3820)\tPrec@1 87.891 (87.212)\tPrec@5 99.219 (99.488)\n",
            "Epoch: [143][70/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.010 (0.014)\tLoss 0.3213 (0.3705)\tPrec@1 88.672 (87.522)\tPrec@5 99.609 (99.527)\n",
            "Epoch: [143][80/329], lr: 0.01000\tTime 0.101 (0.100)\tData 0.005 (0.014)\tLoss 0.2856 (0.3583)\tPrec@1 89.844 (87.948)\tPrec@5 100.000 (99.561)\n",
            "Epoch: [143][90/329], lr: 0.01000\tTime 0.097 (0.099)\tData 0.005 (0.013)\tLoss 0.2672 (0.3518)\tPrec@1 91.406 (88.161)\tPrec@5 100.000 (99.584)\n",
            "Epoch: [143][100/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.010 (0.013)\tLoss 0.2798 (0.3435)\tPrec@1 91.406 (88.448)\tPrec@5 98.438 (99.582)\n",
            "Epoch: [143][110/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.004 (0.012)\tLoss 0.2938 (0.3346)\tPrec@1 90.234 (88.767)\tPrec@5 99.609 (99.588)\n",
            "Epoch: [143][120/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.001 (0.012)\tLoss 0.3221 (0.3311)\tPrec@1 88.672 (88.869)\tPrec@5 99.609 (99.587)\n",
            "Epoch: [143][130/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.000 (0.011)\tLoss 0.2218 (0.3232)\tPrec@1 92.188 (89.140)\tPrec@5 100.000 (99.612)\n",
            "Epoch: [143][140/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.000 (0.011)\tLoss 0.2645 (0.3210)\tPrec@1 90.625 (89.179)\tPrec@5 100.000 (99.623)\n",
            "Epoch: [143][150/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.001 (0.011)\tLoss 0.2625 (0.3171)\tPrec@1 91.406 (89.308)\tPrec@5 100.000 (99.630)\n",
            "Epoch: [143][160/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.007 (0.011)\tLoss 0.2419 (0.3137)\tPrec@1 92.969 (89.426)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [143][170/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.006 (0.010)\tLoss 0.2363 (0.3095)\tPrec@1 94.531 (89.567)\tPrec@5 99.609 (99.650)\n",
            "Epoch: [143][180/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.000 (0.010)\tLoss 0.2334 (0.3057)\tPrec@1 91.406 (89.686)\tPrec@5 100.000 (99.655)\n",
            "Epoch: [143][190/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.000 (0.010)\tLoss 0.2579 (0.3030)\tPrec@1 92.188 (89.772)\tPrec@5 99.219 (99.658)\n",
            "Epoch: [143][200/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.010)\tLoss 0.2261 (0.2999)\tPrec@1 93.359 (89.877)\tPrec@5 100.000 (99.664)\n",
            "Epoch: [143][210/329], lr: 0.01000\tTime 0.069 (0.094)\tData 0.000 (0.010)\tLoss 0.2334 (0.2970)\tPrec@1 91.016 (89.984)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [143][220/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.018 (0.010)\tLoss 0.2553 (0.2953)\tPrec@1 91.406 (90.043)\tPrec@5 99.219 (99.669)\n",
            "Epoch: [143][230/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.000 (0.010)\tLoss 0.3069 (0.2938)\tPrec@1 89.453 (90.099)\tPrec@5 99.609 (99.675)\n",
            "Epoch: [143][240/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.006 (0.010)\tLoss 0.2936 (0.2929)\tPrec@1 90.234 (90.134)\tPrec@5 99.609 (99.673)\n",
            "Epoch: [143][250/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.009)\tLoss 0.2178 (0.2918)\tPrec@1 93.750 (90.153)\tPrec@5 100.000 (99.670)\n",
            "Epoch: [143][260/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.009)\tLoss 0.2603 (0.2913)\tPrec@1 88.672 (90.169)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [143][270/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.005 (0.009)\tLoss 0.3044 (0.2908)\tPrec@1 91.406 (90.170)\tPrec@5 99.609 (99.666)\n",
            "Epoch: [143][280/329], lr: 0.01000\tTime 0.070 (0.093)\tData 0.000 (0.009)\tLoss 0.2800 (0.2895)\tPrec@1 90.234 (90.222)\tPrec@5 100.000 (99.666)\n",
            "Epoch: [143][290/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.009 (0.009)\tLoss 0.2501 (0.2883)\tPrec@1 94.531 (90.269)\tPrec@5 99.609 (99.667)\n",
            "Epoch: [143][300/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.005 (0.009)\tLoss 0.1733 (0.2875)\tPrec@1 96.484 (90.316)\tPrec@5 100.000 (99.673)\n",
            "Epoch: [143][310/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.000 (0.009)\tLoss 0.2092 (0.2863)\tPrec@1 93.750 (90.365)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [143][320/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.036 (0.009)\tLoss 0.3757 (0.2857)\tPrec@1 87.500 (90.401)\tPrec@5 99.219 (99.675)\n",
            "Test: [0/100]\tTime 0.330 (0.330)\tLoss 0.6120 (0.6120)\tPrec@1 76.000 (76.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.057)\tLoss 0.7279 (0.8014)\tPrec@1 77.000 (75.818)\tPrec@5 99.000 (98.818)\n",
            "Test: [20/100]\tTime 0.039 (0.043)\tLoss 0.6922 (0.8044)\tPrec@1 76.000 (75.619)\tPrec@5 99.000 (98.476)\n",
            "Test: [30/100]\tTime 0.021 (0.038)\tLoss 0.9590 (0.8004)\tPrec@1 69.000 (75.742)\tPrec@5 99.000 (98.290)\n",
            "Test: [40/100]\tTime 0.038 (0.035)\tLoss 0.8841 (0.8070)\tPrec@1 76.000 (75.878)\tPrec@5 99.000 (98.366)\n",
            "Test: [50/100]\tTime 0.014 (0.032)\tLoss 0.9451 (0.7992)\tPrec@1 70.000 (75.922)\tPrec@5 98.000 (98.431)\n",
            "Test: [60/100]\tTime 0.032 (0.031)\tLoss 0.7888 (0.8112)\tPrec@1 80.000 (75.623)\tPrec@5 98.000 (98.410)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 0.8859 (0.8031)\tPrec@1 79.000 (75.831)\tPrec@5 98.000 (98.380)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 0.7077 (0.8039)\tPrec@1 82.000 (75.877)\tPrec@5 96.000 (98.395)\n",
            "Test: [90/100]\tTime 0.037 (0.029)\tLoss 0.7091 (0.8148)\tPrec@1 81.000 (75.604)\tPrec@5 100.000 (98.308)\n",
            "val Results: Prec@1 75.590 Prec@5 98.250 Loss 0.81746\n",
            "val Class Accuracy: [0.944,0.986,0.828,0.808,0.756,0.638,0.785,0.687,0.614,0.513]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [144][0/329], lr: 0.01000\tTime 0.575 (0.575)\tData 0.500 (0.500)\tLoss 0.2801 (0.2801)\tPrec@1 94.141 (94.141)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [144][10/329], lr: 0.01000\tTime 0.091 (0.140)\tData 0.000 (0.051)\tLoss 0.2081 (0.2319)\tPrec@1 91.797 (92.720)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [144][20/329], lr: 0.01000\tTime 0.076 (0.118)\tData 0.000 (0.029)\tLoss 0.2244 (0.2311)\tPrec@1 92.969 (92.578)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [144][30/329], lr: 0.01000\tTime 0.078 (0.111)\tData 0.000 (0.021)\tLoss 0.2020 (0.2381)\tPrec@1 92.578 (92.112)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [144][40/329], lr: 0.01000\tTime 0.094 (0.107)\tData 0.006 (0.017)\tLoss 0.2651 (0.2400)\tPrec@1 91.016 (92.045)\tPrec@5 99.219 (99.800)\n",
            "Epoch: [144][50/329], lr: 0.01000\tTime 0.110 (0.105)\tData 0.000 (0.015)\tLoss 0.2926 (0.2417)\tPrec@1 91.016 (91.996)\tPrec@5 100.000 (99.786)\n",
            "Epoch: [144][60/329], lr: 0.01000\tTime 0.068 (0.102)\tData 0.000 (0.014)\tLoss 0.2210 (0.2417)\tPrec@1 93.359 (91.983)\tPrec@5 100.000 (99.789)\n",
            "Epoch: [144][70/329], lr: 0.01000\tTime 0.090 (0.101)\tData 0.010 (0.013)\tLoss 0.2862 (0.2414)\tPrec@1 91.797 (91.989)\tPrec@5 99.609 (99.774)\n",
            "Epoch: [144][80/329], lr: 0.01000\tTime 0.084 (0.100)\tData 0.007 (0.013)\tLoss 0.2019 (0.2423)\tPrec@1 95.312 (91.999)\tPrec@5 99.609 (99.773)\n",
            "Epoch: [144][90/329], lr: 0.01000\tTime 0.118 (0.099)\tData 0.006 (0.012)\tLoss 0.1976 (0.2443)\tPrec@1 92.969 (91.926)\tPrec@5 100.000 (99.768)\n",
            "Epoch: [144][100/329], lr: 0.01000\tTime 0.097 (0.099)\tData 0.007 (0.012)\tLoss 0.2037 (0.2437)\tPrec@1 94.531 (91.944)\tPrec@5 100.000 (99.768)\n",
            "Epoch: [144][110/329], lr: 0.01000\tTime 0.104 (0.098)\tData 0.008 (0.011)\tLoss 0.2618 (0.2424)\tPrec@1 92.188 (91.976)\tPrec@5 99.609 (99.785)\n",
            "Epoch: [144][120/329], lr: 0.01000\tTime 0.069 (0.097)\tData 0.007 (0.011)\tLoss 0.1578 (0.2405)\tPrec@1 94.922 (92.026)\tPrec@5 99.609 (99.784)\n",
            "Epoch: [144][130/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.008 (0.011)\tLoss 0.2161 (0.2395)\tPrec@1 92.188 (92.038)\tPrec@5 99.609 (99.785)\n",
            "Epoch: [144][140/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.011 (0.011)\tLoss 0.2301 (0.2385)\tPrec@1 90.625 (92.013)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [144][150/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.010 (0.011)\tLoss 0.2644 (0.2393)\tPrec@1 91.797 (91.999)\tPrec@5 99.609 (99.793)\n",
            "Epoch: [144][160/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.007 (0.010)\tLoss 0.2800 (0.2389)\tPrec@1 90.234 (92.023)\tPrec@5 99.609 (99.784)\n",
            "Epoch: [144][170/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.005 (0.010)\tLoss 0.3217 (0.2412)\tPrec@1 91.016 (91.973)\tPrec@5 99.609 (99.778)\n",
            "Epoch: [144][180/329], lr: 0.01000\tTime 0.112 (0.095)\tData 0.000 (0.010)\tLoss 0.2009 (0.2419)\tPrec@1 93.359 (91.939)\tPrec@5 100.000 (99.773)\n",
            "Epoch: [144][190/329], lr: 0.01000\tTime 0.070 (0.094)\tData 0.000 (0.010)\tLoss 0.2701 (0.2407)\tPrec@1 92.188 (91.979)\tPrec@5 99.609 (99.781)\n",
            "Epoch: [144][200/329], lr: 0.01000\tTime 0.070 (0.094)\tData 0.004 (0.010)\tLoss 0.2508 (0.2406)\tPrec@1 90.234 (91.976)\tPrec@5 99.609 (99.786)\n",
            "Epoch: [144][210/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.007 (0.010)\tLoss 0.3477 (0.2404)\tPrec@1 87.891 (91.995)\tPrec@5 100.000 (99.783)\n",
            "Epoch: [144][220/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.000 (0.010)\tLoss 0.2175 (0.2416)\tPrec@1 91.797 (91.947)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [144][230/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.007 (0.010)\tLoss 0.2287 (0.2416)\tPrec@1 92.188 (91.934)\tPrec@5 100.000 (99.775)\n",
            "Epoch: [144][240/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.009)\tLoss 0.2056 (0.2413)\tPrec@1 92.578 (91.944)\tPrec@5 100.000 (99.775)\n",
            "Epoch: [144][250/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.006 (0.009)\tLoss 0.2878 (0.2419)\tPrec@1 89.453 (91.912)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [144][260/329], lr: 0.01000\tTime 0.142 (0.094)\tData 0.009 (0.009)\tLoss 0.1847 (0.2420)\tPrec@1 93.750 (91.903)\tPrec@5 100.000 (99.773)\n",
            "Epoch: [144][270/329], lr: 0.01000\tTime 0.114 (0.095)\tData 0.000 (0.009)\tLoss 0.2382 (0.2421)\tPrec@1 91.797 (91.898)\tPrec@5 100.000 (99.774)\n",
            "Epoch: [144][280/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.000 (0.009)\tLoss 0.3071 (0.2419)\tPrec@1 89.453 (91.898)\tPrec@5 99.609 (99.775)\n",
            "Epoch: [144][290/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.000 (0.009)\tLoss 0.1982 (0.2424)\tPrec@1 92.969 (91.869)\tPrec@5 100.000 (99.772)\n",
            "Epoch: [144][300/329], lr: 0.01000\tTime 0.121 (0.096)\tData 0.000 (0.009)\tLoss 0.2185 (0.2420)\tPrec@1 93.750 (91.867)\tPrec@5 99.609 (99.774)\n",
            "Epoch: [144][310/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.000 (0.009)\tLoss 0.2171 (0.2416)\tPrec@1 94.141 (91.891)\tPrec@5 99.609 (99.775)\n",
            "Epoch: [144][320/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.066 (0.009)\tLoss 0.2192 (0.2415)\tPrec@1 91.016 (91.889)\tPrec@5 100.000 (99.780)\n",
            "Test: [0/100]\tTime 0.348 (0.348)\tLoss 0.8694 (0.8694)\tPrec@1 71.000 (71.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.057 (0.062)\tLoss 0.8486 (0.9400)\tPrec@1 74.000 (73.000)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.026 (0.043)\tLoss 0.7956 (0.9312)\tPrec@1 74.000 (72.571)\tPrec@5 100.000 (97.667)\n",
            "Test: [30/100]\tTime 0.029 (0.038)\tLoss 0.9621 (0.9387)\tPrec@1 72.000 (72.323)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.016 (0.035)\tLoss 0.9785 (0.9358)\tPrec@1 67.000 (72.634)\tPrec@5 100.000 (97.780)\n",
            "Test: [50/100]\tTime 0.009 (0.032)\tLoss 0.9899 (0.9262)\tPrec@1 72.000 (72.686)\tPrec@5 97.000 (97.941)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 0.6849 (0.9358)\tPrec@1 81.000 (72.361)\tPrec@5 98.000 (98.016)\n",
            "Test: [70/100]\tTime 0.010 (0.031)\tLoss 1.0630 (0.9294)\tPrec@1 72.000 (72.451)\tPrec@5 100.000 (98.127)\n",
            "Test: [80/100]\tTime 0.027 (0.030)\tLoss 0.9068 (0.9230)\tPrec@1 74.000 (72.679)\tPrec@5 97.000 (98.185)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 0.9256 (0.9381)\tPrec@1 75.000 (72.176)\tPrec@5 98.000 (98.187)\n",
            "val Results: Prec@1 72.280 Prec@5 98.220 Loss 0.93527\n",
            "val Class Accuracy: [0.962,0.939,0.844,0.531,0.596,0.853,0.595,0.835,0.663,0.410]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [145][0/329], lr: 0.01000\tTime 0.694 (0.694)\tData 0.608 (0.608)\tLoss 0.3303 (0.3303)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][10/329], lr: 0.01000\tTime 0.087 (0.157)\tData 0.018 (0.063)\tLoss 0.2588 (0.3076)\tPrec@1 90.625 (89.382)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [145][20/329], lr: 0.01000\tTime 0.085 (0.128)\tData 0.000 (0.037)\tLoss 0.2247 (0.3047)\tPrec@1 92.578 (89.807)\tPrec@5 100.000 (99.684)\n",
            "Epoch: [145][30/329], lr: 0.01000\tTime 0.080 (0.116)\tData 0.000 (0.028)\tLoss 0.2625 (0.2951)\tPrec@1 92.188 (90.209)\tPrec@5 99.609 (99.698)\n",
            "Epoch: [145][40/329], lr: 0.01000\tTime 0.070 (0.109)\tData 0.001 (0.023)\tLoss 0.2184 (0.2884)\tPrec@1 92.188 (90.377)\tPrec@5 99.609 (99.705)\n",
            "Epoch: [145][50/329], lr: 0.01000\tTime 0.106 (0.107)\tData 0.007 (0.020)\tLoss 0.2160 (0.2820)\tPrec@1 91.797 (90.556)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [145][60/329], lr: 0.01000\tTime 0.094 (0.104)\tData 0.001 (0.018)\tLoss 0.1759 (0.2760)\tPrec@1 94.922 (90.791)\tPrec@5 100.000 (99.712)\n",
            "Epoch: [145][70/329], lr: 0.01000\tTime 0.088 (0.102)\tData 0.007 (0.016)\tLoss 0.2916 (0.2695)\tPrec@1 91.016 (91.027)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [145][80/329], lr: 0.01000\tTime 0.072 (0.100)\tData 0.005 (0.015)\tLoss 0.2726 (0.2660)\tPrec@1 90.625 (91.131)\tPrec@5 98.828 (99.725)\n",
            "Epoch: [145][90/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.008 (0.014)\tLoss 0.1763 (0.2630)\tPrec@1 93.750 (91.209)\tPrec@5 100.000 (99.721)\n",
            "Epoch: [145][100/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.000 (0.013)\tLoss 0.2367 (0.2621)\tPrec@1 92.578 (91.217)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [145][110/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.000 (0.013)\tLoss 0.1597 (0.2588)\tPrec@1 95.703 (91.350)\tPrec@5 100.000 (99.704)\n",
            "Epoch: [145][120/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.006 (0.013)\tLoss 0.2061 (0.2575)\tPrec@1 94.531 (91.416)\tPrec@5 99.609 (99.706)\n",
            "Epoch: [145][130/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.005 (0.012)\tLoss 0.2581 (0.2559)\tPrec@1 91.406 (91.481)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [145][140/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.005 (0.012)\tLoss 0.2406 (0.2548)\tPrec@1 91.797 (91.464)\tPrec@5 99.609 (99.720)\n",
            "Epoch: [145][150/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.003 (0.012)\tLoss 0.2308 (0.2528)\tPrec@1 91.406 (91.520)\tPrec@5 100.000 (99.721)\n",
            "Epoch: [145][160/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.008 (0.012)\tLoss 0.1878 (0.2521)\tPrec@1 94.141 (91.576)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [145][170/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.006 (0.011)\tLoss 0.2649 (0.2526)\tPrec@1 91.406 (91.559)\tPrec@5 100.000 (99.701)\n",
            "Epoch: [145][180/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.007 (0.011)\tLoss 0.2363 (0.2526)\tPrec@1 90.625 (91.562)\tPrec@5 100.000 (99.704)\n",
            "Epoch: [145][190/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.008 (0.011)\tLoss 0.1806 (0.2516)\tPrec@1 94.141 (91.574)\tPrec@5 99.609 (99.712)\n",
            "Epoch: [145][200/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.011)\tLoss 0.3220 (0.2521)\tPrec@1 89.062 (91.540)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [145][210/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.013 (0.011)\tLoss 0.2057 (0.2521)\tPrec@1 93.359 (91.578)\tPrec@5 100.000 (99.715)\n",
            "Epoch: [145][220/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.001 (0.011)\tLoss 0.1721 (0.2509)\tPrec@1 94.141 (91.613)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [145][230/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.011 (0.010)\tLoss 0.2502 (0.2494)\tPrec@1 89.453 (91.663)\tPrec@5 99.609 (99.729)\n",
            "Epoch: [145][240/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.000 (0.010)\tLoss 0.2315 (0.2492)\tPrec@1 92.578 (91.669)\tPrec@5 98.828 (99.729)\n",
            "Epoch: [145][250/329], lr: 0.01000\tTime 0.124 (0.094)\tData 0.006 (0.010)\tLoss 0.2732 (0.2497)\tPrec@1 91.406 (91.640)\tPrec@5 99.219 (99.725)\n",
            "Epoch: [145][260/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.000 (0.010)\tLoss 0.2350 (0.2485)\tPrec@1 91.016 (91.683)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [145][270/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.005 (0.010)\tLoss 0.2330 (0.2484)\tPrec@1 91.797 (91.680)\tPrec@5 100.000 (99.728)\n",
            "Epoch: [145][280/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.000 (0.010)\tLoss 0.2732 (0.2487)\tPrec@1 89.453 (91.679)\tPrec@5 100.000 (99.732)\n",
            "Epoch: [145][290/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.006 (0.010)\tLoss 0.2040 (0.2484)\tPrec@1 93.750 (91.683)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [145][300/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.000 (0.010)\tLoss 0.1452 (0.2482)\tPrec@1 95.703 (91.706)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [145][310/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.004 (0.010)\tLoss 0.1960 (0.2483)\tPrec@1 94.531 (91.706)\tPrec@5 99.609 (99.724)\n",
            "Epoch: [145][320/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.064 (0.010)\tLoss 0.2210 (0.2479)\tPrec@1 91.016 (91.725)\tPrec@5 99.219 (99.726)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 0.9380 (0.9380)\tPrec@1 70.000 (70.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.030 (0.057)\tLoss 1.0420 (1.1164)\tPrec@1 70.000 (67.364)\tPrec@5 95.000 (97.636)\n",
            "Test: [20/100]\tTime 0.029 (0.042)\tLoss 0.9249 (1.0799)\tPrec@1 66.000 (68.333)\tPrec@5 99.000 (97.762)\n",
            "Test: [30/100]\tTime 0.029 (0.037)\tLoss 1.3817 (1.0985)\tPrec@1 61.000 (67.806)\tPrec@5 95.000 (97.645)\n",
            "Test: [40/100]\tTime 0.042 (0.033)\tLoss 1.2647 (1.1136)\tPrec@1 71.000 (68.098)\tPrec@5 96.000 (97.341)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 1.2638 (1.1038)\tPrec@1 65.000 (67.941)\tPrec@5 97.000 (97.333)\n",
            "Test: [60/100]\tTime 0.039 (0.031)\tLoss 0.9745 (1.1148)\tPrec@1 71.000 (67.459)\tPrec@5 97.000 (97.279)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 0.9939 (1.1070)\tPrec@1 71.000 (67.592)\tPrec@5 98.000 (97.310)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 0.9095 (1.0978)\tPrec@1 69.000 (67.802)\tPrec@5 99.000 (97.407)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 0.9285 (1.1127)\tPrec@1 73.000 (67.505)\tPrec@5 100.000 (97.308)\n",
            "val Results: Prec@1 67.600 Prec@5 97.230 Loss 1.11205\n",
            "val Class Accuracy: [0.926,0.964,0.819,0.791,0.688,0.530,0.598,0.480,0.520,0.444]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [146][0/329], lr: 0.01000\tTime 0.727 (0.727)\tData 0.644 (0.644)\tLoss 0.2252 (0.2252)\tPrec@1 90.234 (90.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [146][10/329], lr: 0.01000\tTime 0.098 (0.152)\tData 0.007 (0.064)\tLoss 0.4542 (0.5452)\tPrec@1 83.203 (82.386)\tPrec@5 98.828 (98.757)\n",
            "Epoch: [146][20/329], lr: 0.01000\tTime 0.075 (0.124)\tData 0.000 (0.037)\tLoss 0.5222 (0.5102)\tPrec@1 83.984 (83.575)\tPrec@5 99.609 (99.051)\n",
            "Epoch: [146][30/329], lr: 0.01000\tTime 0.078 (0.111)\tData 0.014 (0.027)\tLoss 0.2809 (0.4650)\tPrec@1 91.016 (84.955)\tPrec@5 99.219 (99.105)\n",
            "Epoch: [146][40/329], lr: 0.01000\tTime 0.099 (0.106)\tData 0.001 (0.022)\tLoss 0.3116 (0.4417)\tPrec@1 90.234 (85.728)\tPrec@5 100.000 (99.200)\n",
            "Epoch: [146][50/329], lr: 0.01000\tTime 0.089 (0.103)\tData 0.004 (0.019)\tLoss 0.3443 (0.4147)\tPrec@1 87.109 (86.497)\tPrec@5 100.000 (99.226)\n",
            "Epoch: [146][60/329], lr: 0.01000\tTime 0.080 (0.101)\tData 0.006 (0.017)\tLoss 0.2179 (0.3935)\tPrec@1 92.188 (87.173)\tPrec@5 99.609 (99.270)\n",
            "Epoch: [146][70/329], lr: 0.01000\tTime 0.093 (0.100)\tData 0.000 (0.016)\tLoss 0.2876 (0.3792)\tPrec@1 91.016 (87.698)\tPrec@5 99.609 (99.334)\n",
            "Epoch: [146][80/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.000 (0.014)\tLoss 0.3257 (0.3661)\tPrec@1 90.625 (88.103)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [146][90/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.003 (0.014)\tLoss 0.2033 (0.3558)\tPrec@1 92.969 (88.414)\tPrec@5 100.000 (99.416)\n",
            "Epoch: [146][100/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.000 (0.013)\tLoss 0.2279 (0.3465)\tPrec@1 91.797 (88.707)\tPrec@5 100.000 (99.455)\n",
            "Epoch: [146][110/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.002 (0.013)\tLoss 0.2196 (0.3380)\tPrec@1 92.578 (88.918)\tPrec@5 100.000 (99.490)\n",
            "Epoch: [146][120/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.012)\tLoss 0.2002 (0.3310)\tPrec@1 94.141 (89.098)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [146][130/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.005 (0.012)\tLoss 0.3142 (0.3265)\tPrec@1 89.453 (89.250)\tPrec@5 99.609 (99.532)\n",
            "Epoch: [146][140/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.000 (0.011)\tLoss 0.2076 (0.3199)\tPrec@1 92.578 (89.445)\tPrec@5 99.609 (99.546)\n",
            "Epoch: [146][150/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.004 (0.011)\tLoss 0.1602 (0.3152)\tPrec@1 94.141 (89.572)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [146][160/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.007 (0.011)\tLoss 0.2790 (0.3113)\tPrec@1 90.234 (89.708)\tPrec@5 99.609 (99.585)\n",
            "Epoch: [146][170/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.011)\tLoss 0.2262 (0.3083)\tPrec@1 93.750 (89.803)\tPrec@5 100.000 (99.598)\n",
            "Epoch: [146][180/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.010 (0.010)\tLoss 0.2680 (0.3063)\tPrec@1 92.188 (89.835)\tPrec@5 100.000 (99.599)\n",
            "Epoch: [146][190/329], lr: 0.01000\tTime 0.105 (0.094)\tData 0.000 (0.010)\tLoss 0.2680 (0.3037)\tPrec@1 90.234 (89.899)\tPrec@5 99.609 (99.607)\n",
            "Epoch: [146][200/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.006 (0.010)\tLoss 0.3056 (0.3014)\tPrec@1 90.625 (89.978)\tPrec@5 98.828 (99.609)\n",
            "Epoch: [146][210/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.2537 (0.2982)\tPrec@1 92.188 (90.094)\tPrec@5 99.609 (99.615)\n",
            "Epoch: [146][220/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.000 (0.010)\tLoss 0.1836 (0.2958)\tPrec@1 94.141 (90.160)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [146][230/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.004 (0.010)\tLoss 0.2211 (0.2944)\tPrec@1 92.188 (90.190)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [146][240/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.010)\tLoss 0.2905 (0.2925)\tPrec@1 90.625 (90.254)\tPrec@5 99.219 (99.613)\n",
            "Epoch: [146][250/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.005 (0.009)\tLoss 0.2472 (0.2906)\tPrec@1 91.016 (90.309)\tPrec@5 100.000 (99.619)\n",
            "Epoch: [146][260/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.013 (0.010)\tLoss 0.3258 (0.2888)\tPrec@1 90.625 (90.365)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [146][270/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.000 (0.009)\tLoss 0.2289 (0.2867)\tPrec@1 93.750 (90.430)\tPrec@5 99.609 (99.630)\n",
            "Epoch: [146][280/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.000 (0.009)\tLoss 0.2063 (0.2852)\tPrec@1 92.969 (90.485)\tPrec@5 100.000 (99.633)\n",
            "Epoch: [146][290/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.002 (0.009)\tLoss 0.2022 (0.2831)\tPrec@1 92.188 (90.562)\tPrec@5 99.219 (99.635)\n",
            "Epoch: [146][300/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.005 (0.009)\tLoss 0.2062 (0.2819)\tPrec@1 94.922 (90.595)\tPrec@5 100.000 (99.639)\n",
            "Epoch: [146][310/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.004 (0.009)\tLoss 0.2572 (0.2813)\tPrec@1 92.578 (90.607)\tPrec@5 100.000 (99.646)\n",
            "Epoch: [146][320/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.066 (0.009)\tLoss 0.2418 (0.2805)\tPrec@1 91.797 (90.630)\tPrec@5 99.609 (99.651)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.8833 (0.8833)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.061)\tLoss 0.6863 (1.0118)\tPrec@1 74.000 (70.909)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.013 (0.042)\tLoss 1.0704 (1.0166)\tPrec@1 70.000 (70.667)\tPrec@5 98.000 (98.238)\n",
            "Test: [30/100]\tTime 0.030 (0.038)\tLoss 1.0564 (1.0078)\tPrec@1 70.000 (70.806)\tPrec@5 99.000 (98.258)\n",
            "Test: [40/100]\tTime 0.014 (0.034)\tLoss 0.9134 (1.0223)\tPrec@1 75.000 (70.829)\tPrec@5 98.000 (98.195)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 1.1147 (1.0149)\tPrec@1 72.000 (70.980)\tPrec@5 97.000 (98.255)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 0.9146 (1.0245)\tPrec@1 77.000 (70.721)\tPrec@5 98.000 (98.262)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 0.8376 (1.0170)\tPrec@1 79.000 (70.831)\tPrec@5 100.000 (98.338)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 0.8271 (1.0082)\tPrec@1 75.000 (70.914)\tPrec@5 98.000 (98.370)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.0548 (1.0224)\tPrec@1 68.000 (70.473)\tPrec@5 100.000 (98.341)\n",
            "val Results: Prec@1 70.460 Prec@5 98.300 Loss 1.02136\n",
            "val Class Accuracy: [0.834,0.962,0.923,0.654,0.665,0.608,0.760,0.670,0.571,0.399]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [147][0/329], lr: 0.01000\tTime 0.702 (0.702)\tData 0.610 (0.610)\tLoss 0.1698 (0.1698)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][10/329], lr: 0.01000\tTime 0.082 (0.149)\tData 0.004 (0.061)\tLoss 0.5662 (0.4566)\tPrec@1 84.375 (85.050)\tPrec@5 98.438 (99.361)\n",
            "Epoch: [147][20/329], lr: 0.01000\tTime 0.093 (0.125)\tData 0.000 (0.034)\tLoss 0.3440 (0.4146)\tPrec@1 89.453 (86.496)\tPrec@5 99.609 (99.349)\n",
            "Epoch: [147][30/329], lr: 0.01000\tTime 0.115 (0.116)\tData 0.000 (0.025)\tLoss 0.3510 (0.3847)\tPrec@1 88.281 (87.286)\tPrec@5 99.609 (99.420)\n",
            "Epoch: [147][40/329], lr: 0.01000\tTime 0.071 (0.109)\tData 0.000 (0.020)\tLoss 0.2625 (0.3648)\tPrec@1 90.625 (87.805)\tPrec@5 99.219 (99.447)\n",
            "Epoch: [147][50/329], lr: 0.01000\tTime 0.065 (0.106)\tData 0.000 (0.017)\tLoss 0.2708 (0.3496)\tPrec@1 91.016 (88.182)\tPrec@5 100.000 (99.502)\n",
            "Epoch: [147][60/329], lr: 0.01000\tTime 0.075 (0.104)\tData 0.007 (0.016)\tLoss 0.2162 (0.3324)\tPrec@1 93.750 (88.729)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [147][70/329], lr: 0.01000\tTime 0.084 (0.102)\tData 0.000 (0.015)\tLoss 0.1975 (0.3192)\tPrec@1 94.141 (89.151)\tPrec@5 100.000 (99.576)\n",
            "Epoch: [147][80/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.005 (0.014)\tLoss 0.3147 (0.3080)\tPrec@1 87.891 (89.530)\tPrec@5 99.609 (99.605)\n",
            "Epoch: [147][90/329], lr: 0.01000\tTime 0.111 (0.100)\tData 0.008 (0.013)\tLoss 0.2748 (0.3030)\tPrec@1 89.062 (89.681)\tPrec@5 99.609 (99.635)\n",
            "Epoch: [147][100/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.010 (0.012)\tLoss 0.2907 (0.2992)\tPrec@1 90.234 (89.809)\tPrec@5 100.000 (99.636)\n",
            "Epoch: [147][110/329], lr: 0.01000\tTime 0.075 (0.098)\tData 0.008 (0.012)\tLoss 0.2481 (0.2945)\tPrec@1 92.969 (89.995)\tPrec@5 99.609 (99.652)\n",
            "Epoch: [147][120/329], lr: 0.01000\tTime 0.046 (0.097)\tData 0.001 (0.012)\tLoss 0.2832 (0.2904)\tPrec@1 91.797 (90.128)\tPrec@5 99.219 (99.661)\n",
            "Epoch: [147][130/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.000 (0.011)\tLoss 0.2044 (0.2866)\tPrec@1 92.188 (90.261)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [147][140/329], lr: 0.01000\tTime 0.075 (0.097)\tData 0.000 (0.011)\tLoss 0.2291 (0.2851)\tPrec@1 92.188 (90.301)\tPrec@5 99.219 (99.670)\n",
            "Epoch: [147][150/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.011)\tLoss 0.2729 (0.2828)\tPrec@1 90.625 (90.382)\tPrec@5 99.609 (99.666)\n",
            "Epoch: [147][160/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.005 (0.011)\tLoss 0.2576 (0.2810)\tPrec@1 91.016 (90.462)\tPrec@5 99.609 (99.668)\n",
            "Epoch: [147][170/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.009 (0.011)\tLoss 0.2350 (0.2788)\tPrec@1 92.188 (90.536)\tPrec@5 99.219 (99.673)\n",
            "Epoch: [147][180/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.007 (0.010)\tLoss 0.3405 (0.2775)\tPrec@1 90.625 (90.580)\tPrec@5 99.609 (99.678)\n",
            "Epoch: [147][190/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.013 (0.010)\tLoss 0.2007 (0.2776)\tPrec@1 92.188 (90.580)\tPrec@5 100.000 (99.673)\n",
            "Epoch: [147][200/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.005 (0.010)\tLoss 0.3206 (0.2760)\tPrec@1 89.062 (90.633)\tPrec@5 99.609 (99.685)\n",
            "Epoch: [147][210/329], lr: 0.01000\tTime 0.078 (0.094)\tData 0.007 (0.010)\tLoss 0.2929 (0.2749)\tPrec@1 91.016 (90.668)\tPrec@5 99.609 (99.683)\n",
            "Epoch: [147][220/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.004 (0.010)\tLoss 0.2576 (0.2739)\tPrec@1 92.578 (90.722)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [147][230/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.005 (0.010)\tLoss 0.2901 (0.2726)\tPrec@1 91.016 (90.769)\tPrec@5 99.609 (99.679)\n",
            "Epoch: [147][240/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.000 (0.010)\tLoss 0.2064 (0.2704)\tPrec@1 94.141 (90.844)\tPrec@5 100.000 (99.686)\n",
            "Epoch: [147][250/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.010)\tLoss 0.3150 (0.2689)\tPrec@1 89.453 (90.886)\tPrec@5 99.219 (99.689)\n",
            "Epoch: [147][260/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.003 (0.010)\tLoss 0.2613 (0.2690)\tPrec@1 90.234 (90.870)\tPrec@5 99.609 (99.692)\n",
            "Epoch: [147][270/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 0.3087 (0.2683)\tPrec@1 92.188 (90.920)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [147][280/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.007 (0.010)\tLoss 0.2285 (0.2669)\tPrec@1 92.969 (90.979)\tPrec@5 99.609 (99.705)\n",
            "Epoch: [147][290/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.007 (0.010)\tLoss 0.2477 (0.2662)\tPrec@1 89.844 (91.017)\tPrec@5 99.609 (99.711)\n",
            "Epoch: [147][300/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.000 (0.010)\tLoss 0.2880 (0.2661)\tPrec@1 91.016 (91.017)\tPrec@5 99.609 (99.713)\n",
            "Epoch: [147][310/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.006 (0.009)\tLoss 0.2933 (0.2662)\tPrec@1 91.406 (91.002)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [147][320/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.051 (0.010)\tLoss 0.3037 (0.2655)\tPrec@1 90.234 (91.029)\tPrec@5 100.000 (99.709)\n",
            "Test: [0/100]\tTime 0.409 (0.409)\tLoss 1.3915 (1.3915)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.049 (0.062)\tLoss 1.7322 (1.6204)\tPrec@1 63.000 (61.000)\tPrec@5 92.000 (95.364)\n",
            "Test: [20/100]\tTime 0.039 (0.044)\tLoss 1.4226 (1.5791)\tPrec@1 61.000 (60.857)\tPrec@5 98.000 (95.905)\n",
            "Test: [30/100]\tTime 0.049 (0.036)\tLoss 1.6862 (1.5919)\tPrec@1 64.000 (60.645)\tPrec@5 94.000 (95.774)\n",
            "Test: [40/100]\tTime 0.024 (0.035)\tLoss 1.2879 (1.5986)\tPrec@1 68.000 (60.610)\tPrec@5 95.000 (95.634)\n",
            "Test: [50/100]\tTime 0.013 (0.033)\tLoss 1.4202 (1.5767)\tPrec@1 65.000 (61.020)\tPrec@5 98.000 (95.686)\n",
            "Test: [60/100]\tTime 0.033 (0.032)\tLoss 1.4599 (1.5837)\tPrec@1 66.000 (60.934)\tPrec@5 94.000 (95.738)\n",
            "Test: [70/100]\tTime 0.055 (0.031)\tLoss 1.0507 (1.5974)\tPrec@1 72.000 (60.775)\tPrec@5 98.000 (95.775)\n",
            "Test: [80/100]\tTime 0.054 (0.030)\tLoss 1.6938 (1.5947)\tPrec@1 62.000 (60.852)\tPrec@5 93.000 (95.728)\n",
            "Test: [90/100]\tTime 0.029 (0.030)\tLoss 1.2330 (1.6192)\tPrec@1 67.000 (60.549)\tPrec@5 95.000 (95.560)\n",
            "val Results: Prec@1 60.670 Prec@5 95.590 Loss 1.62411\n",
            "val Class Accuracy: [0.664,0.668,0.641,0.888,0.611,0.220,0.522,0.852,0.358,0.643]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [148][0/329], lr: 0.01000\tTime 0.648 (0.648)\tData 0.568 (0.568)\tLoss 0.2486 (0.2486)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][10/329], lr: 0.01000\tTime 0.103 (0.152)\tData 0.000 (0.057)\tLoss 0.7627 (0.9223)\tPrec@1 73.438 (72.053)\tPrec@5 96.484 (96.697)\n",
            "Epoch: [148][20/329], lr: 0.01000\tTime 0.090 (0.125)\tData 0.001 (0.033)\tLoss 0.5982 (0.8485)\tPrec@1 78.906 (73.047)\tPrec@5 98.438 (97.266)\n",
            "Epoch: [148][30/329], lr: 0.01000\tTime 0.088 (0.114)\tData 0.000 (0.025)\tLoss 0.6316 (0.7826)\tPrec@1 78.516 (74.509)\tPrec@5 98.438 (97.543)\n",
            "Epoch: [148][40/329], lr: 0.01000\tTime 0.091 (0.109)\tData 0.001 (0.020)\tLoss 0.5070 (0.7197)\tPrec@1 83.984 (76.562)\tPrec@5 98.828 (97.856)\n",
            "Epoch: [148][50/329], lr: 0.01000\tTime 0.080 (0.107)\tData 0.007 (0.018)\tLoss 0.3859 (0.6715)\tPrec@1 87.109 (77.987)\tPrec@5 100.000 (98.131)\n",
            "Epoch: [148][60/329], lr: 0.01000\tTime 0.106 (0.107)\tData 0.000 (0.016)\tLoss 0.5152 (0.6354)\tPrec@1 82.812 (79.143)\tPrec@5 99.219 (98.290)\n",
            "Epoch: [148][70/329], lr: 0.01000\tTime 0.088 (0.106)\tData 0.008 (0.015)\tLoss 0.3865 (0.6058)\tPrec@1 88.281 (80.128)\tPrec@5 100.000 (98.410)\n",
            "Epoch: [148][80/329], lr: 0.01000\tTime 0.091 (0.105)\tData 0.000 (0.013)\tLoss 0.3746 (0.5770)\tPrec@1 87.109 (81.038)\tPrec@5 99.609 (98.568)\n",
            "Epoch: [148][90/329], lr: 0.01000\tTime 0.079 (0.104)\tData 0.001 (0.013)\tLoss 0.4855 (0.5582)\tPrec@1 83.203 (81.615)\tPrec@5 99.219 (98.652)\n",
            "Epoch: [148][100/329], lr: 0.01000\tTime 0.086 (0.103)\tData 0.000 (0.013)\tLoss 0.4071 (0.5406)\tPrec@1 87.500 (82.140)\tPrec@5 99.609 (98.724)\n",
            "Epoch: [148][110/329], lr: 0.01000\tTime 0.112 (0.102)\tData 0.005 (0.012)\tLoss 0.3669 (0.5252)\tPrec@1 87.109 (82.626)\tPrec@5 100.000 (98.768)\n",
            "Epoch: [148][120/329], lr: 0.01000\tTime 0.090 (0.101)\tData 0.004 (0.012)\tLoss 0.2944 (0.5111)\tPrec@1 88.672 (83.084)\tPrec@5 99.219 (98.806)\n",
            "Epoch: [148][130/329], lr: 0.01000\tTime 0.116 (0.101)\tData 0.000 (0.011)\tLoss 0.3658 (0.4978)\tPrec@1 86.328 (83.519)\tPrec@5 99.219 (98.855)\n",
            "Epoch: [148][140/329], lr: 0.01000\tTime 0.101 (0.100)\tData 0.000 (0.011)\tLoss 0.3534 (0.4877)\tPrec@1 89.062 (83.890)\tPrec@5 100.000 (98.900)\n",
            "Epoch: [148][150/329], lr: 0.01000\tTime 0.100 (0.100)\tData 0.008 (0.011)\tLoss 0.3519 (0.4788)\tPrec@1 87.109 (84.173)\tPrec@5 99.609 (98.939)\n",
            "Epoch: [148][160/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.000 (0.010)\tLoss 0.3769 (0.4694)\tPrec@1 88.672 (84.462)\tPrec@5 98.438 (98.969)\n",
            "Epoch: [148][170/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.011 (0.010)\tLoss 0.3606 (0.4610)\tPrec@1 85.938 (84.722)\tPrec@5 100.000 (99.011)\n",
            "Epoch: [148][180/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.000 (0.010)\tLoss 0.3849 (0.4534)\tPrec@1 88.672 (84.973)\tPrec@5 99.609 (99.046)\n",
            "Epoch: [148][190/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.000 (0.010)\tLoss 0.3711 (0.4457)\tPrec@1 87.500 (85.214)\tPrec@5 99.609 (99.082)\n",
            "Epoch: [148][200/329], lr: 0.01000\tTime 0.104 (0.097)\tData 0.002 (0.010)\tLoss 0.2917 (0.4396)\tPrec@1 92.578 (85.438)\tPrec@5 99.609 (99.106)\n",
            "Epoch: [148][210/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.002 (0.010)\tLoss 0.2874 (0.4343)\tPrec@1 90.234 (85.623)\tPrec@5 100.000 (99.128)\n",
            "Epoch: [148][220/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.000 (0.009)\tLoss 0.3861 (0.4277)\tPrec@1 89.453 (85.840)\tPrec@5 98.828 (99.148)\n",
            "Epoch: [148][230/329], lr: 0.01000\tTime 0.124 (0.097)\tData 0.001 (0.009)\tLoss 0.2671 (0.4233)\tPrec@1 91.016 (86.010)\tPrec@5 100.000 (99.165)\n",
            "Epoch: [148][240/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.005 (0.009)\tLoss 0.3011 (0.4175)\tPrec@1 89.844 (86.197)\tPrec@5 100.000 (99.180)\n",
            "Epoch: [148][250/329], lr: 0.01000\tTime 0.107 (0.097)\tData 0.005 (0.009)\tLoss 0.3364 (0.4134)\tPrec@1 88.672 (86.316)\tPrec@5 99.609 (99.199)\n",
            "Epoch: [148][260/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.015 (0.009)\tLoss 0.2292 (0.4080)\tPrec@1 92.578 (86.473)\tPrec@5 100.000 (99.217)\n",
            "Epoch: [148][270/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.009)\tLoss 0.2800 (0.4041)\tPrec@1 89.844 (86.612)\tPrec@5 99.219 (99.229)\n",
            "Epoch: [148][280/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.005 (0.009)\tLoss 0.2629 (0.4002)\tPrec@1 91.016 (86.751)\tPrec@5 100.000 (99.237)\n",
            "Epoch: [148][290/329], lr: 0.01000\tTime 0.119 (0.098)\tData 0.002 (0.009)\tLoss 0.2729 (0.3959)\tPrec@1 91.016 (86.903)\tPrec@5 99.609 (99.251)\n",
            "Epoch: [148][300/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.018 (0.010)\tLoss 0.2411 (0.3921)\tPrec@1 90.625 (87.021)\tPrec@5 100.000 (99.268)\n",
            "Epoch: [148][310/329], lr: 0.01000\tTime 0.111 (0.100)\tData 0.000 (0.010)\tLoss 0.3410 (0.3891)\tPrec@1 87.500 (87.118)\tPrec@5 99.609 (99.271)\n",
            "Epoch: [148][320/329], lr: 0.01000\tTime 0.181 (0.100)\tData 0.098 (0.010)\tLoss 0.2624 (0.3859)\tPrec@1 92.578 (87.229)\tPrec@5 99.609 (99.282)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 0.7123 (0.7123)\tPrec@1 78.000 (78.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.013 (0.063)\tLoss 0.6882 (0.8952)\tPrec@1 76.000 (73.273)\tPrec@5 100.000 (97.636)\n",
            "Test: [20/100]\tTime 0.019 (0.044)\tLoss 0.7480 (0.9037)\tPrec@1 75.000 (72.952)\tPrec@5 99.000 (97.476)\n",
            "Test: [30/100]\tTime 0.023 (0.038)\tLoss 1.1785 (0.9254)\tPrec@1 70.000 (72.839)\tPrec@5 95.000 (97.387)\n",
            "Test: [40/100]\tTime 0.032 (0.035)\tLoss 1.0170 (0.9359)\tPrec@1 72.000 (72.780)\tPrec@5 95.000 (97.195)\n",
            "Test: [50/100]\tTime 0.030 (0.033)\tLoss 1.0665 (0.9248)\tPrec@1 73.000 (73.039)\tPrec@5 97.000 (97.294)\n",
            "Test: [60/100]\tTime 0.017 (0.032)\tLoss 0.8874 (0.9408)\tPrec@1 76.000 (72.590)\tPrec@5 97.000 (97.377)\n",
            "Test: [70/100]\tTime 0.011 (0.031)\tLoss 1.1366 (0.9375)\tPrec@1 72.000 (72.535)\tPrec@5 98.000 (97.451)\n",
            "Test: [80/100]\tTime 0.019 (0.031)\tLoss 0.9260 (0.9320)\tPrec@1 75.000 (72.716)\tPrec@5 96.000 (97.457)\n",
            "Test: [90/100]\tTime 0.036 (0.030)\tLoss 0.6782 (0.9435)\tPrec@1 78.000 (72.484)\tPrec@5 98.000 (97.495)\n",
            "val Results: Prec@1 72.540 Prec@5 97.460 Loss 0.94347\n",
            "val Class Accuracy: [0.954,0.933,0.855,0.517,0.619,0.796,0.807,0.367,0.636,0.770]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [149][0/329], lr: 0.01000\tTime 0.699 (0.699)\tData 0.633 (0.633)\tLoss 0.3386 (0.3386)\tPrec@1 88.672 (88.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][10/329], lr: 0.01000\tTime 0.083 (0.153)\tData 0.005 (0.065)\tLoss 0.2720 (0.2797)\tPrec@1 88.281 (90.874)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [149][20/329], lr: 0.01000\tTime 0.108 (0.131)\tData 0.004 (0.037)\tLoss 0.2577 (0.2861)\tPrec@1 89.844 (90.662)\tPrec@5 100.000 (99.535)\n",
            "Epoch: [149][30/329], lr: 0.01000\tTime 0.076 (0.118)\tData 0.000 (0.027)\tLoss 0.2283 (0.2884)\tPrec@1 92.969 (90.524)\tPrec@5 100.000 (99.635)\n",
            "Epoch: [149][40/329], lr: 0.01000\tTime 0.093 (0.115)\tData 0.000 (0.024)\tLoss 0.2265 (0.2890)\tPrec@1 93.359 (90.415)\tPrec@5 98.828 (99.590)\n",
            "Epoch: [149][50/329], lr: 0.01000\tTime 0.091 (0.110)\tData 0.000 (0.020)\tLoss 0.2491 (0.2877)\tPrec@1 91.797 (90.403)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [149][60/329], lr: 0.01000\tTime 0.093 (0.109)\tData 0.003 (0.018)\tLoss 0.2787 (0.2864)\tPrec@1 91.797 (90.567)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [149][70/329], lr: 0.01000\tTime 0.096 (0.107)\tData 0.008 (0.016)\tLoss 0.3784 (0.2853)\tPrec@1 89.453 (90.575)\tPrec@5 99.219 (99.604)\n",
            "Epoch: [149][80/329], lr: 0.01000\tTime 0.085 (0.105)\tData 0.000 (0.015)\tLoss 0.3034 (0.2845)\tPrec@1 87.891 (90.514)\tPrec@5 100.000 (99.633)\n",
            "Epoch: [149][90/329], lr: 0.01000\tTime 0.111 (0.104)\tData 0.005 (0.014)\tLoss 0.2158 (0.2827)\tPrec@1 93.359 (90.548)\tPrec@5 99.609 (99.639)\n",
            "Epoch: [149][100/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.004 (0.013)\tLoss 0.1970 (0.2807)\tPrec@1 93.359 (90.602)\tPrec@5 100.000 (99.660)\n",
            "Epoch: [149][110/329], lr: 0.01000\tTime 0.130 (0.102)\tData 0.008 (0.013)\tLoss 0.2989 (0.2791)\tPrec@1 88.672 (90.702)\tPrec@5 99.219 (99.638)\n",
            "Epoch: [149][120/329], lr: 0.01000\tTime 0.096 (0.101)\tData 0.001 (0.012)\tLoss 0.2198 (0.2775)\tPrec@1 92.969 (90.777)\tPrec@5 99.609 (99.648)\n",
            "Epoch: [149][130/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.007 (0.012)\tLoss 0.2804 (0.2761)\tPrec@1 91.406 (90.852)\tPrec@5 99.609 (99.657)\n",
            "Epoch: [149][140/329], lr: 0.01000\tTime 0.110 (0.099)\tData 0.000 (0.012)\tLoss 0.2769 (0.2759)\tPrec@1 92.188 (90.910)\tPrec@5 99.219 (99.656)\n",
            "Epoch: [149][150/329], lr: 0.01000\tTime 0.068 (0.098)\tData 0.000 (0.011)\tLoss 0.2918 (0.2742)\tPrec@1 91.406 (90.974)\tPrec@5 99.609 (99.661)\n",
            "Epoch: [149][160/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.000 (0.011)\tLoss 0.2664 (0.2743)\tPrec@1 90.234 (90.987)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [149][170/329], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.011)\tLoss 0.2449 (0.2739)\tPrec@1 91.406 (90.968)\tPrec@5 100.000 (99.671)\n",
            "Epoch: [149][180/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.005 (0.011)\tLoss 0.2222 (0.2738)\tPrec@1 92.578 (90.975)\tPrec@5 100.000 (99.670)\n",
            "Epoch: [149][190/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.011)\tLoss 0.3480 (0.2722)\tPrec@1 88.672 (91.024)\tPrec@5 98.828 (99.675)\n",
            "Epoch: [149][200/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.000 (0.010)\tLoss 0.2535 (0.2709)\tPrec@1 91.797 (91.068)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [149][210/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.007 (0.010)\tLoss 0.2240 (0.2699)\tPrec@1 90.625 (91.084)\tPrec@5 99.609 (99.678)\n",
            "Epoch: [149][220/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.003 (0.010)\tLoss 0.3250 (0.2712)\tPrec@1 91.406 (91.058)\tPrec@5 98.828 (99.671)\n",
            "Epoch: [149][230/329], lr: 0.01000\tTime 0.124 (0.095)\tData 0.006 (0.010)\tLoss 0.2374 (0.2711)\tPrec@1 91.797 (91.073)\tPrec@5 100.000 (99.669)\n",
            "Epoch: [149][240/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.003 (0.010)\tLoss 0.2211 (0.2705)\tPrec@1 91.016 (91.095)\tPrec@5 100.000 (99.668)\n",
            "Epoch: [149][250/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.007 (0.010)\tLoss 0.3200 (0.2711)\tPrec@1 89.062 (91.075)\tPrec@5 99.219 (99.673)\n",
            "Epoch: [149][260/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.004 (0.009)\tLoss 0.3152 (0.2715)\tPrec@1 89.844 (91.059)\tPrec@5 99.219 (99.669)\n",
            "Epoch: [149][270/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.008 (0.009)\tLoss 0.2497 (0.2701)\tPrec@1 91.406 (91.098)\tPrec@5 99.609 (99.679)\n",
            "Epoch: [149][280/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.009 (0.009)\tLoss 0.3225 (0.2703)\tPrec@1 89.062 (91.102)\tPrec@5 99.219 (99.671)\n",
            "Epoch: [149][290/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.009)\tLoss 0.2478 (0.2695)\tPrec@1 91.797 (91.127)\tPrec@5 99.609 (99.668)\n",
            "Epoch: [149][300/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.000 (0.009)\tLoss 0.3011 (0.2699)\tPrec@1 90.234 (91.095)\tPrec@5 99.609 (99.670)\n",
            "Epoch: [149][310/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.009)\tLoss 0.1992 (0.2699)\tPrec@1 91.016 (91.077)\tPrec@5 99.609 (99.672)\n",
            "Epoch: [149][320/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.065 (0.009)\tLoss 0.3502 (0.2710)\tPrec@1 90.234 (91.055)\tPrec@5 98.438 (99.664)\n",
            "Test: [0/100]\tTime 0.375 (0.375)\tLoss 1.1434 (1.1434)\tPrec@1 70.000 (70.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.010 (0.052)\tLoss 1.0056 (1.2318)\tPrec@1 69.000 (67.273)\tPrec@5 98.000 (96.909)\n",
            "Test: [20/100]\tTime 0.028 (0.044)\tLoss 1.2107 (1.2259)\tPrec@1 67.000 (67.476)\tPrec@5 97.000 (96.810)\n",
            "Test: [30/100]\tTime 0.020 (0.037)\tLoss 1.2766 (1.2709)\tPrec@1 62.000 (66.903)\tPrec@5 96.000 (96.226)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 1.2412 (1.2715)\tPrec@1 73.000 (67.171)\tPrec@5 96.000 (96.220)\n",
            "Test: [50/100]\tTime 0.040 (0.033)\tLoss 1.4074 (1.2735)\tPrec@1 63.000 (67.294)\tPrec@5 93.000 (96.176)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 1.0860 (1.2874)\tPrec@1 73.000 (66.984)\tPrec@5 93.000 (96.049)\n",
            "Test: [70/100]\tTime 0.009 (0.030)\tLoss 1.5700 (1.2865)\tPrec@1 64.000 (67.070)\tPrec@5 96.000 (96.000)\n",
            "Test: [80/100]\tTime 0.030 (0.028)\tLoss 1.2498 (1.2803)\tPrec@1 62.000 (66.938)\tPrec@5 95.000 (96.012)\n",
            "Test: [90/100]\tTime 0.029 (0.028)\tLoss 1.2796 (1.2936)\tPrec@1 58.000 (66.560)\tPrec@5 99.000 (96.033)\n",
            "val Results: Prec@1 66.450 Prec@5 95.920 Loss 1.30410\n",
            "val Class Accuracy: [0.967,0.720,0.706,0.501,0.768,0.708,0.953,0.315,0.524,0.483]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [150][0/329], lr: 0.01000\tTime 0.651 (0.651)\tData 0.577 (0.577)\tLoss 0.3067 (0.3067)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][10/329], lr: 0.01000\tTime 0.086 (0.147)\tData 0.005 (0.056)\tLoss 0.6071 (0.5611)\tPrec@1 78.125 (81.676)\tPrec@5 99.219 (98.331)\n",
            "Epoch: [150][20/329], lr: 0.01000\tTime 0.094 (0.122)\tData 0.001 (0.033)\tLoss 0.3453 (0.4868)\tPrec@1 88.672 (83.780)\tPrec@5 99.609 (98.958)\n",
            "Epoch: [150][30/329], lr: 0.01000\tTime 0.070 (0.113)\tData 0.007 (0.025)\tLoss 0.3071 (0.4476)\tPrec@1 87.500 (85.106)\tPrec@5 99.609 (99.030)\n",
            "Epoch: [150][40/329], lr: 0.01000\tTime 0.087 (0.107)\tData 0.000 (0.020)\tLoss 0.3517 (0.4161)\tPrec@1 89.062 (86.128)\tPrec@5 99.609 (99.162)\n",
            "Epoch: [150][50/329], lr: 0.01000\tTime 0.074 (0.104)\tData 0.000 (0.017)\tLoss 0.3388 (0.3967)\tPrec@1 88.281 (86.749)\tPrec@5 98.828 (99.219)\n",
            "Epoch: [150][60/329], lr: 0.01000\tTime 0.098 (0.101)\tData 0.000 (0.016)\tLoss 0.2570 (0.3803)\tPrec@1 92.578 (87.263)\tPrec@5 100.000 (99.315)\n",
            "Epoch: [150][70/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.005 (0.014)\tLoss 0.2876 (0.3663)\tPrec@1 90.625 (87.753)\tPrec@5 100.000 (99.384)\n",
            "Epoch: [150][80/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.000 (0.014)\tLoss 0.2049 (0.3544)\tPrec@1 93.359 (88.209)\tPrec@5 100.000 (99.421)\n",
            "Epoch: [150][90/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.007 (0.013)\tLoss 0.3674 (0.3439)\tPrec@1 88.672 (88.573)\tPrec@5 99.609 (99.455)\n",
            "Epoch: [150][100/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.005 (0.012)\tLoss 0.2372 (0.3380)\tPrec@1 92.188 (88.780)\tPrec@5 100.000 (99.455)\n",
            "Epoch: [150][110/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.011 (0.012)\tLoss 0.2956 (0.3334)\tPrec@1 89.453 (88.950)\tPrec@5 99.609 (99.469)\n",
            "Epoch: [150][120/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.006 (0.012)\tLoss 0.2874 (0.3284)\tPrec@1 89.453 (89.082)\tPrec@5 100.000 (99.490)\n",
            "Epoch: [150][130/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.007 (0.011)\tLoss 0.2919 (0.3238)\tPrec@1 91.797 (89.244)\tPrec@5 99.609 (99.511)\n",
            "Epoch: [150][140/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.011)\tLoss 0.3044 (0.3210)\tPrec@1 90.625 (89.351)\tPrec@5 99.609 (99.512)\n",
            "Epoch: [150][150/329], lr: 0.01000\tTime 0.066 (0.094)\tData 0.005 (0.011)\tLoss 0.2631 (0.3176)\tPrec@1 91.406 (89.479)\tPrec@5 99.609 (99.527)\n",
            "Epoch: [150][160/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.005 (0.011)\tLoss 0.2402 (0.3154)\tPrec@1 91.406 (89.550)\tPrec@5 99.609 (99.532)\n",
            "Epoch: [150][170/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.007 (0.011)\tLoss 0.2945 (0.3124)\tPrec@1 91.016 (89.631)\tPrec@5 99.609 (99.539)\n",
            "Epoch: [150][180/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.004 (0.010)\tLoss 0.2960 (0.3089)\tPrec@1 90.625 (89.762)\tPrec@5 99.609 (99.553)\n",
            "Epoch: [150][190/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.005 (0.010)\tLoss 0.1822 (0.3061)\tPrec@1 93.359 (89.868)\tPrec@5 100.000 (99.558)\n",
            "Epoch: [150][200/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.000 (0.010)\tLoss 0.2728 (0.3035)\tPrec@1 92.578 (89.955)\tPrec@5 99.219 (99.567)\n",
            "Epoch: [150][210/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.006 (0.010)\tLoss 0.2921 (0.3007)\tPrec@1 90.234 (90.049)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [150][220/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.007 (0.010)\tLoss 0.2953 (0.2995)\tPrec@1 92.578 (90.112)\tPrec@5 99.219 (99.572)\n",
            "Epoch: [150][230/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.012 (0.010)\tLoss 0.2927 (0.2979)\tPrec@1 92.188 (90.165)\tPrec@5 98.828 (99.584)\n",
            "Epoch: [150][240/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.010)\tLoss 0.2264 (0.2956)\tPrec@1 92.188 (90.241)\tPrec@5 99.609 (99.592)\n",
            "Epoch: [150][250/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.009)\tLoss 0.2438 (0.2938)\tPrec@1 92.578 (90.322)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [150][260/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.005 (0.009)\tLoss 0.2875 (0.2916)\tPrec@1 91.016 (90.386)\tPrec@5 100.000 (99.606)\n",
            "Epoch: [150][270/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.005 (0.009)\tLoss 0.2944 (0.2908)\tPrec@1 90.234 (90.397)\tPrec@5 99.609 (99.614)\n",
            "Epoch: [150][280/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.009)\tLoss 0.1845 (0.2899)\tPrec@1 93.359 (90.408)\tPrec@5 100.000 (99.618)\n",
            "Epoch: [150][290/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.007 (0.009)\tLoss 0.2716 (0.2889)\tPrec@1 90.234 (90.444)\tPrec@5 99.609 (99.620)\n",
            "Epoch: [150][300/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.007 (0.009)\tLoss 0.2586 (0.2881)\tPrec@1 91.016 (90.469)\tPrec@5 99.609 (99.622)\n",
            "Epoch: [150][310/329], lr: 0.01000\tTime 0.110 (0.092)\tData 0.012 (0.009)\tLoss 0.2641 (0.2877)\tPrec@1 91.406 (90.482)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [150][320/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.062 (0.009)\tLoss 0.2829 (0.2868)\tPrec@1 90.234 (90.503)\tPrec@5 98.828 (99.631)\n",
            "Test: [0/100]\tTime 0.429 (0.429)\tLoss 0.9499 (0.9499)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 0.8359 (1.0878)\tPrec@1 70.000 (68.455)\tPrec@5 98.000 (96.455)\n",
            "Test: [20/100]\tTime 0.024 (0.043)\tLoss 0.9288 (1.0605)\tPrec@1 72.000 (69.048)\tPrec@5 99.000 (96.143)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 1.1822 (1.0791)\tPrec@1 68.000 (68.548)\tPrec@5 97.000 (96.129)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 1.0803 (1.0930)\tPrec@1 68.000 (68.610)\tPrec@5 94.000 (96.049)\n",
            "Test: [50/100]\tTime 0.058 (0.033)\tLoss 1.0629 (1.0768)\tPrec@1 77.000 (69.431)\tPrec@5 94.000 (95.961)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 1.0278 (1.0801)\tPrec@1 74.000 (69.508)\tPrec@5 96.000 (95.918)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 0.9043 (1.0711)\tPrec@1 74.000 (69.746)\tPrec@5 97.000 (96.000)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 1.0168 (1.0595)\tPrec@1 69.000 (69.840)\tPrec@5 96.000 (96.111)\n",
            "Test: [90/100]\tTime 0.018 (0.030)\tLoss 1.0386 (1.0630)\tPrec@1 70.000 (69.780)\tPrec@5 98.000 (96.077)\n",
            "val Results: Prec@1 69.840 Prec@5 96.090 Loss 1.06222\n",
            "val Class Accuracy: [0.817,0.969,0.752,0.622,0.732,0.798,0.834,0.310,0.543,0.607]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [151][0/329], lr: 0.01000\tTime 0.548 (0.548)\tData 0.464 (0.464)\tLoss 0.2964 (0.2964)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][10/329], lr: 0.01000\tTime 0.077 (0.145)\tData 0.000 (0.052)\tLoss 0.8216 (0.6523)\tPrec@1 74.609 (78.018)\tPrec@5 98.828 (99.006)\n",
            "Epoch: [151][20/329], lr: 0.01000\tTime 0.113 (0.123)\tData 0.012 (0.031)\tLoss 0.4434 (0.5835)\tPrec@1 83.984 (80.450)\tPrec@5 100.000 (99.051)\n",
            "Epoch: [151][30/329], lr: 0.01000\tTime 0.080 (0.113)\tData 0.000 (0.023)\tLoss 0.4968 (0.5377)\tPrec@1 85.547 (82.182)\tPrec@5 99.219 (99.055)\n",
            "Epoch: [151][40/329], lr: 0.01000\tTime 0.078 (0.107)\tData 0.004 (0.019)\tLoss 0.4062 (0.5073)\tPrec@1 86.328 (83.241)\tPrec@5 98.438 (99.066)\n",
            "Epoch: [151][50/329], lr: 0.01000\tTime 0.074 (0.104)\tData 0.007 (0.017)\tLoss 0.4873 (0.4829)\tPrec@1 84.375 (83.992)\tPrec@5 99.609 (99.157)\n",
            "Epoch: [151][60/329], lr: 0.01000\tTime 0.094 (0.101)\tData 0.007 (0.015)\tLoss 0.3223 (0.4593)\tPrec@1 89.062 (84.702)\tPrec@5 98.438 (99.180)\n",
            "Epoch: [151][70/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.008 (0.014)\tLoss 0.3157 (0.4412)\tPrec@1 91.016 (85.288)\tPrec@5 100.000 (99.208)\n",
            "Epoch: [151][80/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.009 (0.013)\tLoss 0.2212 (0.4233)\tPrec@1 91.797 (85.894)\tPrec@5 100.000 (99.257)\n",
            "Epoch: [151][90/329], lr: 0.01000\tTime 0.077 (0.098)\tData 0.000 (0.012)\tLoss 0.2831 (0.4059)\tPrec@1 90.625 (86.478)\tPrec@5 100.000 (99.313)\n",
            "Epoch: [151][100/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.011 (0.012)\tLoss 0.2954 (0.3944)\tPrec@1 90.234 (86.835)\tPrec@5 99.609 (99.323)\n",
            "Epoch: [151][110/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.006 (0.012)\tLoss 0.2080 (0.3831)\tPrec@1 92.969 (87.187)\tPrec@5 100.000 (99.363)\n",
            "Epoch: [151][120/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.007 (0.011)\tLoss 0.2648 (0.3748)\tPrec@1 90.625 (87.429)\tPrec@5 100.000 (99.387)\n",
            "Epoch: [151][130/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.010 (0.011)\tLoss 0.3246 (0.3704)\tPrec@1 91.406 (87.631)\tPrec@5 99.219 (99.398)\n",
            "Epoch: [151][140/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.005 (0.011)\tLoss 0.2230 (0.3657)\tPrec@1 93.359 (87.813)\tPrec@5 98.828 (99.413)\n",
            "Epoch: [151][150/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.005 (0.011)\tLoss 0.2128 (0.3610)\tPrec@1 92.188 (87.981)\tPrec@5 99.609 (99.423)\n",
            "Epoch: [151][160/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.007 (0.011)\tLoss 0.2502 (0.3545)\tPrec@1 90.234 (88.167)\tPrec@5 100.000 (99.452)\n",
            "Epoch: [151][170/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.008 (0.011)\tLoss 0.2990 (0.3500)\tPrec@1 90.625 (88.309)\tPrec@5 99.219 (99.459)\n",
            "Epoch: [151][180/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.004 (0.010)\tLoss 0.3652 (0.3455)\tPrec@1 86.328 (88.430)\tPrec@5 99.609 (99.471)\n",
            "Epoch: [151][190/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.004 (0.010)\tLoss 0.3207 (0.3419)\tPrec@1 88.672 (88.535)\tPrec@5 99.609 (99.483)\n",
            "Epoch: [151][200/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.005 (0.010)\tLoss 0.2140 (0.3383)\tPrec@1 92.188 (88.645)\tPrec@5 100.000 (99.508)\n",
            "Epoch: [151][210/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.005 (0.010)\tLoss 0.3149 (0.3351)\tPrec@1 89.062 (88.777)\tPrec@5 99.609 (99.513)\n",
            "Epoch: [151][220/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.012 (0.010)\tLoss 0.2272 (0.3309)\tPrec@1 92.188 (88.933)\tPrec@5 99.609 (99.523)\n",
            "Epoch: [151][230/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.000 (0.010)\tLoss 0.3300 (0.3289)\tPrec@1 90.234 (88.995)\tPrec@5 99.609 (99.533)\n",
            "Epoch: [151][240/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.000 (0.010)\tLoss 0.2668 (0.3273)\tPrec@1 91.016 (89.058)\tPrec@5 99.609 (99.538)\n",
            "Epoch: [151][250/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.004 (0.010)\tLoss 0.2828 (0.3257)\tPrec@1 89.844 (89.133)\tPrec@5 99.609 (99.546)\n",
            "Epoch: [151][260/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.3042 (0.3238)\tPrec@1 90.234 (89.194)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [151][270/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.008 (0.009)\tLoss 0.2692 (0.3214)\tPrec@1 91.406 (89.276)\tPrec@5 99.609 (99.560)\n",
            "Epoch: [151][280/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.006 (0.009)\tLoss 0.3138 (0.3203)\tPrec@1 90.234 (89.313)\tPrec@5 99.609 (99.568)\n",
            "Epoch: [151][290/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.005 (0.009)\tLoss 0.2862 (0.3190)\tPrec@1 89.844 (89.348)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [151][300/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.005 (0.009)\tLoss 0.2715 (0.3172)\tPrec@1 90.625 (89.408)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [151][310/329], lr: 0.01000\tTime 0.068 (0.092)\tData 0.000 (0.009)\tLoss 0.2661 (0.3154)\tPrec@1 89.844 (89.467)\tPrec@5 99.609 (99.579)\n",
            "Epoch: [151][320/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.043 (0.009)\tLoss 0.3097 (0.3142)\tPrec@1 91.016 (89.509)\tPrec@5 99.219 (99.587)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 2.0072 (2.0072)\tPrec@1 58.000 (58.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.055 (0.058)\tLoss 2.0353 (2.4219)\tPrec@1 55.000 (49.364)\tPrec@5 95.000 (92.364)\n",
            "Test: [20/100]\tTime 0.044 (0.044)\tLoss 2.1855 (2.3659)\tPrec@1 51.000 (49.667)\tPrec@5 96.000 (93.143)\n",
            "Test: [30/100]\tTime 0.032 (0.038)\tLoss 2.4855 (2.4289)\tPrec@1 46.000 (49.097)\tPrec@5 97.000 (93.065)\n",
            "Test: [40/100]\tTime 0.029 (0.035)\tLoss 2.2447 (2.4395)\tPrec@1 50.000 (49.171)\tPrec@5 96.000 (92.659)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 2.4507 (2.4267)\tPrec@1 50.000 (49.510)\tPrec@5 91.000 (92.706)\n",
            "Test: [60/100]\tTime 0.012 (0.031)\tLoss 1.9918 (2.4436)\tPrec@1 51.000 (49.377)\tPrec@5 97.000 (92.787)\n",
            "Test: [70/100]\tTime 0.066 (0.030)\tLoss 2.1378 (2.4378)\tPrec@1 59.000 (49.380)\tPrec@5 95.000 (92.761)\n",
            "Test: [80/100]\tTime 0.038 (0.030)\tLoss 2.4395 (2.4333)\tPrec@1 51.000 (49.247)\tPrec@5 90.000 (92.815)\n",
            "Test: [90/100]\tTime 0.032 (0.029)\tLoss 2.2105 (2.4510)\tPrec@1 50.000 (49.022)\tPrec@5 94.000 (92.714)\n",
            "val Results: Prec@1 49.400 Prec@5 92.770 Loss 2.43949\n",
            "val Class Accuracy: [0.552,0.583,0.802,0.850,0.284,0.223,0.628,0.414,0.431,0.173]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [152][0/329], lr: 0.01000\tTime 0.686 (0.686)\tData 0.597 (0.597)\tLoss 0.4126 (0.4126)\tPrec@1 86.328 (86.328)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][10/329], lr: 0.01000\tTime 0.074 (0.155)\tData 0.000 (0.063)\tLoss 1.1770 (1.1106)\tPrec@1 66.016 (66.868)\tPrec@5 94.922 (95.774)\n",
            "Epoch: [152][20/329], lr: 0.01000\tTime 0.076 (0.125)\tData 0.000 (0.036)\tLoss 0.8938 (1.0160)\tPrec@1 69.922 (68.657)\tPrec@5 96.094 (96.391)\n",
            "Epoch: [152][30/329], lr: 0.01000\tTime 0.090 (0.113)\tData 0.008 (0.028)\tLoss 0.6644 (0.9318)\tPrec@1 76.953 (70.514)\tPrec@5 97.656 (96.825)\n",
            "Epoch: [152][40/329], lr: 0.01000\tTime 0.096 (0.108)\tData 0.002 (0.023)\tLoss 0.5649 (0.8585)\tPrec@1 81.641 (72.732)\tPrec@5 98.438 (97.142)\n",
            "Epoch: [152][50/329], lr: 0.01000\tTime 0.079 (0.104)\tData 0.000 (0.020)\tLoss 0.4776 (0.8000)\tPrec@1 84.375 (74.502)\tPrec@5 99.609 (97.503)\n",
            "Epoch: [152][60/329], lr: 0.01000\tTime 0.089 (0.102)\tData 0.006 (0.018)\tLoss 0.4320 (0.7533)\tPrec@1 82.422 (75.736)\tPrec@5 99.219 (97.797)\n",
            "Epoch: [152][70/329], lr: 0.01000\tTime 0.106 (0.101)\tData 0.007 (0.016)\tLoss 0.4181 (0.7170)\tPrec@1 86.719 (76.766)\tPrec@5 98.438 (97.975)\n",
            "Epoch: [152][80/329], lr: 0.01000\tTime 0.110 (0.100)\tData 0.006 (0.015)\tLoss 0.3935 (0.6849)\tPrec@1 85.156 (77.773)\tPrec@5 99.609 (98.148)\n",
            "Epoch: [152][90/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.014)\tLoss 0.5305 (0.6589)\tPrec@1 83.984 (78.559)\tPrec@5 97.656 (98.249)\n",
            "Epoch: [152][100/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.000 (0.014)\tLoss 0.3045 (0.6377)\tPrec@1 90.625 (79.235)\tPrec@5 100.000 (98.345)\n",
            "Epoch: [152][110/329], lr: 0.01000\tTime 0.099 (0.097)\tData 0.007 (0.014)\tLoss 0.3961 (0.6156)\tPrec@1 85.156 (79.885)\tPrec@5 99.219 (98.462)\n",
            "Epoch: [152][120/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.011 (0.013)\tLoss 0.3306 (0.5977)\tPrec@1 89.844 (80.482)\tPrec@5 100.000 (98.534)\n",
            "Epoch: [152][130/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.013)\tLoss 0.3848 (0.5822)\tPrec@1 87.891 (80.958)\tPrec@5 100.000 (98.607)\n",
            "Epoch: [152][140/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.007 (0.013)\tLoss 0.3244 (0.5672)\tPrec@1 89.062 (81.369)\tPrec@5 99.609 (98.651)\n",
            "Epoch: [152][150/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.003 (0.012)\tLoss 0.4838 (0.5551)\tPrec@1 84.766 (81.762)\tPrec@5 98.828 (98.694)\n",
            "Epoch: [152][160/329], lr: 0.01000\tTime 0.112 (0.095)\tData 0.012 (0.012)\tLoss 0.3018 (0.5428)\tPrec@1 90.625 (82.174)\tPrec@5 99.609 (98.726)\n",
            "Epoch: [152][170/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.004 (0.011)\tLoss 0.4059 (0.5322)\tPrec@1 86.719 (82.509)\tPrec@5 100.000 (98.792)\n",
            "Epoch: [152][180/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.008 (0.011)\tLoss 0.3443 (0.5225)\tPrec@1 88.672 (82.834)\tPrec@5 99.609 (98.830)\n",
            "Epoch: [152][190/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.007 (0.011)\tLoss 0.2970 (0.5129)\tPrec@1 91.406 (83.179)\tPrec@5 98.047 (98.855)\n",
            "Epoch: [152][200/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.011)\tLoss 0.3005 (0.5040)\tPrec@1 89.844 (83.471)\tPrec@5 100.000 (98.888)\n",
            "Epoch: [152][210/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.007 (0.011)\tLoss 0.4107 (0.4962)\tPrec@1 87.109 (83.731)\tPrec@5 99.609 (98.917)\n",
            "Epoch: [152][220/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.005 (0.011)\tLoss 0.3642 (0.4882)\tPrec@1 86.328 (83.995)\tPrec@5 100.000 (98.945)\n",
            "Epoch: [152][230/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.006 (0.010)\tLoss 0.2958 (0.4809)\tPrec@1 90.234 (84.248)\tPrec@5 100.000 (98.968)\n",
            "Epoch: [152][240/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.010 (0.010)\tLoss 0.3968 (0.4741)\tPrec@1 87.109 (84.490)\tPrec@5 99.219 (98.992)\n",
            "Epoch: [152][250/329], lr: 0.01000\tTime 0.105 (0.093)\tData 0.007 (0.010)\tLoss 0.3252 (0.4679)\tPrec@1 89.062 (84.689)\tPrec@5 99.609 (99.012)\n",
            "Epoch: [152][260/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.000 (0.010)\tLoss 0.2502 (0.4618)\tPrec@1 91.016 (84.872)\tPrec@5 100.000 (99.038)\n",
            "Epoch: [152][270/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.004 (0.010)\tLoss 0.3678 (0.4580)\tPrec@1 86.719 (84.960)\tPrec@5 99.609 (99.059)\n",
            "Epoch: [152][280/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.005 (0.010)\tLoss 0.4104 (0.4536)\tPrec@1 87.891 (85.083)\tPrec@5 98.828 (99.069)\n",
            "Epoch: [152][290/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 0.3395 (0.4492)\tPrec@1 89.453 (85.217)\tPrec@5 99.609 (99.080)\n",
            "Epoch: [152][300/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.004 (0.010)\tLoss 0.3231 (0.4445)\tPrec@1 87.891 (85.377)\tPrec@5 99.609 (99.101)\n",
            "Epoch: [152][310/329], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.010)\tLoss 0.2302 (0.4395)\tPrec@1 92.578 (85.544)\tPrec@5 100.000 (99.121)\n",
            "Epoch: [152][320/329], lr: 0.01000\tTime 0.229 (0.093)\tData 0.153 (0.010)\tLoss 0.3438 (0.4351)\tPrec@1 86.719 (85.683)\tPrec@5 100.000 (99.140)\n",
            "Test: [0/100]\tTime 0.579 (0.579)\tLoss 0.9711 (0.9711)\tPrec@1 76.000 (76.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.041 (0.089)\tLoss 0.6663 (0.9050)\tPrec@1 76.000 (73.091)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.030 (0.062)\tLoss 1.0611 (0.8972)\tPrec@1 67.000 (72.905)\tPrec@5 100.000 (98.476)\n",
            "Test: [30/100]\tTime 0.023 (0.049)\tLoss 1.1596 (0.9268)\tPrec@1 65.000 (72.548)\tPrec@5 97.000 (98.323)\n",
            "Test: [40/100]\tTime 0.014 (0.043)\tLoss 0.9445 (0.9411)\tPrec@1 71.000 (72.317)\tPrec@5 100.000 (98.268)\n",
            "Test: [50/100]\tTime 0.032 (0.040)\tLoss 0.7631 (0.9423)\tPrec@1 80.000 (72.627)\tPrec@5 98.000 (98.059)\n",
            "Test: [60/100]\tTime 0.018 (0.037)\tLoss 1.0439 (0.9441)\tPrec@1 69.000 (72.525)\tPrec@5 100.000 (98.164)\n",
            "Test: [70/100]\tTime 0.046 (0.035)\tLoss 1.0471 (0.9419)\tPrec@1 68.000 (72.507)\tPrec@5 98.000 (98.268)\n",
            "Test: [80/100]\tTime 0.031 (0.034)\tLoss 0.8110 (0.9439)\tPrec@1 76.000 (72.432)\tPrec@5 98.000 (98.259)\n",
            "Test: [90/100]\tTime 0.010 (0.032)\tLoss 0.7906 (0.9557)\tPrec@1 79.000 (72.231)\tPrec@5 100.000 (98.220)\n",
            "val Results: Prec@1 72.160 Prec@5 98.170 Loss 0.95911\n",
            "val Class Accuracy: [0.920,0.956,0.537,0.352,0.942,0.642,0.807,0.629,0.686,0.745]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [153][0/329], lr: 0.01000\tTime 0.616 (0.616)\tData 0.548 (0.548)\tLoss 0.3719 (0.3719)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [153][10/329], lr: 0.01000\tTime 0.100 (0.143)\tData 0.000 (0.054)\tLoss 0.3776 (0.4779)\tPrec@1 85.547 (83.771)\tPrec@5 99.609 (99.361)\n",
            "Epoch: [153][20/329], lr: 0.01000\tTime 0.132 (0.122)\tData 0.007 (0.030)\tLoss 0.2736 (0.4368)\tPrec@1 90.234 (85.454)\tPrec@5 99.219 (99.312)\n",
            "Epoch: [153][30/329], lr: 0.01000\tTime 0.101 (0.112)\tData 0.006 (0.022)\tLoss 0.3205 (0.4075)\tPrec@1 89.062 (86.164)\tPrec@5 99.609 (99.433)\n",
            "Epoch: [153][40/329], lr: 0.01000\tTime 0.093 (0.106)\tData 0.000 (0.018)\tLoss 0.4034 (0.3826)\tPrec@1 86.719 (87.033)\tPrec@5 99.609 (99.457)\n",
            "Epoch: [153][50/329], lr: 0.01000\tTime 0.077 (0.103)\tData 0.000 (0.016)\tLoss 0.3334 (0.3683)\tPrec@1 89.453 (87.515)\tPrec@5 99.609 (99.456)\n",
            "Epoch: [153][60/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.000 (0.015)\tLoss 0.3372 (0.3612)\tPrec@1 90.234 (87.743)\tPrec@5 100.000 (99.494)\n",
            "Epoch: [153][70/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.007 (0.014)\tLoss 0.2726 (0.3488)\tPrec@1 89.844 (88.210)\tPrec@5 99.609 (99.494)\n",
            "Epoch: [153][80/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.000 (0.013)\tLoss 0.3144 (0.3420)\tPrec@1 90.234 (88.513)\tPrec@5 99.609 (99.513)\n",
            "Epoch: [153][90/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.004 (0.012)\tLoss 0.2536 (0.3347)\tPrec@1 91.406 (88.758)\tPrec@5 100.000 (99.528)\n",
            "Epoch: [153][100/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.012)\tLoss 0.3290 (0.3321)\tPrec@1 89.844 (88.842)\tPrec@5 99.609 (99.551)\n",
            "Epoch: [153][110/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.002 (0.011)\tLoss 0.2483 (0.3279)\tPrec@1 91.797 (88.996)\tPrec@5 100.000 (99.578)\n",
            "Epoch: [153][120/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.005 (0.011)\tLoss 0.3682 (0.3243)\tPrec@1 87.891 (89.108)\tPrec@5 99.609 (99.587)\n",
            "Epoch: [153][130/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.009 (0.011)\tLoss 0.3270 (0.3202)\tPrec@1 89.062 (89.235)\tPrec@5 99.219 (99.597)\n",
            "Epoch: [153][140/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.004 (0.011)\tLoss 0.3147 (0.3182)\tPrec@1 89.844 (89.312)\tPrec@5 100.000 (99.593)\n",
            "Epoch: [153][150/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.000 (0.011)\tLoss 0.2150 (0.3154)\tPrec@1 92.188 (89.401)\tPrec@5 100.000 (99.599)\n",
            "Epoch: [153][160/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.010)\tLoss 0.2394 (0.3137)\tPrec@1 91.797 (89.436)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [153][170/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.004 (0.010)\tLoss 0.3800 (0.3125)\tPrec@1 87.500 (89.481)\tPrec@5 100.000 (99.612)\n",
            "Epoch: [153][180/329], lr: 0.01000\tTime 0.068 (0.093)\tData 0.006 (0.010)\tLoss 0.3284 (0.3107)\tPrec@1 90.625 (89.574)\tPrec@5 99.609 (99.620)\n",
            "Epoch: [153][190/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.000 (0.010)\tLoss 0.2517 (0.3093)\tPrec@1 92.188 (89.623)\tPrec@5 99.609 (99.634)\n",
            "Epoch: [153][200/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.009 (0.010)\tLoss 0.3336 (0.3077)\tPrec@1 89.844 (89.665)\tPrec@5 99.219 (99.633)\n",
            "Epoch: [153][210/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.004 (0.010)\tLoss 0.3057 (0.3063)\tPrec@1 90.625 (89.729)\tPrec@5 99.219 (99.628)\n",
            "Epoch: [153][220/329], lr: 0.01000\tTime 0.115 (0.092)\tData 0.005 (0.010)\tLoss 0.2758 (0.3057)\tPrec@1 89.453 (89.745)\tPrec@5 99.609 (99.625)\n",
            "Epoch: [153][230/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.000 (0.009)\tLoss 0.2760 (0.3060)\tPrec@1 89.453 (89.727)\tPrec@5 100.000 (99.621)\n",
            "Epoch: [153][240/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.005 (0.009)\tLoss 0.2448 (0.3047)\tPrec@1 89.453 (89.753)\tPrec@5 100.000 (99.622)\n",
            "Epoch: [153][250/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.006 (0.009)\tLoss 0.3422 (0.3042)\tPrec@1 88.281 (89.785)\tPrec@5 99.609 (99.619)\n",
            "Epoch: [153][260/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.009)\tLoss 0.2784 (0.3039)\tPrec@1 90.625 (89.808)\tPrec@5 99.609 (99.612)\n",
            "Epoch: [153][270/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.007 (0.009)\tLoss 0.3067 (0.3024)\tPrec@1 89.453 (89.861)\tPrec@5 100.000 (99.619)\n",
            "Epoch: [153][280/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.005 (0.009)\tLoss 0.3158 (0.3024)\tPrec@1 90.234 (89.891)\tPrec@5 99.609 (99.615)\n",
            "Epoch: [153][290/329], lr: 0.01000\tTime 0.063 (0.091)\tData 0.007 (0.009)\tLoss 0.2590 (0.3019)\tPrec@1 91.016 (89.922)\tPrec@5 99.609 (99.619)\n",
            "Epoch: [153][300/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.002 (0.009)\tLoss 0.2622 (0.3014)\tPrec@1 90.625 (89.932)\tPrec@5 99.219 (99.621)\n",
            "Epoch: [153][310/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.006 (0.009)\tLoss 0.3458 (0.3005)\tPrec@1 87.500 (89.954)\tPrec@5 99.609 (99.624)\n",
            "Epoch: [153][320/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.035 (0.009)\tLoss 0.2299 (0.2997)\tPrec@1 92.188 (89.989)\tPrec@5 100.000 (99.623)\n",
            "Test: [0/100]\tTime 0.405 (0.405)\tLoss 0.5488 (0.5488)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.029 (0.061)\tLoss 0.7163 (0.7873)\tPrec@1 76.000 (76.273)\tPrec@5 99.000 (98.818)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 0.6169 (0.7811)\tPrec@1 80.000 (75.857)\tPrec@5 99.000 (98.476)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 0.7571 (0.7988)\tPrec@1 74.000 (75.613)\tPrec@5 98.000 (98.484)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 0.8052 (0.8074)\tPrec@1 73.000 (75.195)\tPrec@5 99.000 (98.512)\n",
            "Test: [50/100]\tTime 0.026 (0.031)\tLoss 0.8139 (0.8045)\tPrec@1 81.000 (75.608)\tPrec@5 98.000 (98.549)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 0.7712 (0.8029)\tPrec@1 79.000 (75.623)\tPrec@5 100.000 (98.689)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 0.9580 (0.7977)\tPrec@1 76.000 (75.775)\tPrec@5 99.000 (98.690)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 0.7801 (0.7931)\tPrec@1 76.000 (75.926)\tPrec@5 96.000 (98.654)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 0.6572 (0.8022)\tPrec@1 78.000 (75.758)\tPrec@5 100.000 (98.582)\n",
            "val Results: Prec@1 75.790 Prec@5 98.590 Loss 0.80245\n",
            "val Class Accuracy: [0.962,0.966,0.775,0.693,0.866,0.737,0.744,0.664,0.562,0.610]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [154][0/329], lr: 0.01000\tTime 0.647 (0.647)\tData 0.564 (0.564)\tLoss 0.2384 (0.2384)\tPrec@1 92.578 (92.578)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [154][10/329], lr: 0.01000\tTime 0.092 (0.145)\tData 0.000 (0.055)\tLoss 0.2170 (0.2750)\tPrec@1 92.578 (91.229)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [154][20/329], lr: 0.01000\tTime 0.085 (0.121)\tData 0.000 (0.032)\tLoss 0.2289 (0.2642)\tPrec@1 93.750 (91.592)\tPrec@5 99.609 (99.758)\n",
            "Epoch: [154][30/329], lr: 0.01000\tTime 0.102 (0.111)\tData 0.005 (0.024)\tLoss 0.3019 (0.2553)\tPrec@1 89.844 (91.822)\tPrec@5 99.219 (99.773)\n",
            "Epoch: [154][40/329], lr: 0.01000\tTime 0.079 (0.105)\tData 0.006 (0.020)\tLoss 0.1542 (0.2534)\tPrec@1 95.703 (91.806)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [154][50/329], lr: 0.01000\tTime 0.070 (0.102)\tData 0.007 (0.017)\tLoss 0.2034 (0.2544)\tPrec@1 93.750 (91.835)\tPrec@5 100.000 (99.732)\n",
            "Epoch: [154][60/329], lr: 0.01000\tTime 0.089 (0.100)\tData 0.000 (0.016)\tLoss 0.3014 (0.2585)\tPrec@1 90.625 (91.573)\tPrec@5 98.828 (99.699)\n",
            "Epoch: [154][70/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.007 (0.015)\tLoss 0.3439 (0.2619)\tPrec@1 88.672 (91.500)\tPrec@5 99.609 (99.692)\n",
            "Epoch: [154][80/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.000 (0.014)\tLoss 0.2528 (0.2660)\tPrec@1 91.406 (91.339)\tPrec@5 99.609 (99.662)\n",
            "Epoch: [154][90/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.007 (0.013)\tLoss 0.1861 (0.2652)\tPrec@1 93.359 (91.359)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [154][100/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.006 (0.012)\tLoss 0.3035 (0.2664)\tPrec@1 89.453 (91.294)\tPrec@5 100.000 (99.675)\n",
            "Epoch: [154][110/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.011 (0.012)\tLoss 0.3273 (0.2658)\tPrec@1 87.891 (91.258)\tPrec@5 100.000 (99.683)\n",
            "Epoch: [154][120/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.000 (0.011)\tLoss 0.2423 (0.2647)\tPrec@1 92.578 (91.322)\tPrec@5 100.000 (99.690)\n",
            "Epoch: [154][130/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.007 (0.011)\tLoss 0.1917 (0.2632)\tPrec@1 93.750 (91.373)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [154][140/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.011)\tLoss 0.2749 (0.2625)\tPrec@1 89.453 (91.376)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [154][150/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.002 (0.010)\tLoss 0.1773 (0.2618)\tPrec@1 93.750 (91.367)\tPrec@5 99.609 (99.697)\n",
            "Epoch: [154][160/329], lr: 0.01000\tTime 0.118 (0.094)\tData 0.000 (0.010)\tLoss 0.3249 (0.2635)\tPrec@1 90.234 (91.290)\tPrec@5 100.000 (99.699)\n",
            "Epoch: [154][170/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.006 (0.010)\tLoss 0.3300 (0.2652)\tPrec@1 87.891 (91.217)\tPrec@5 100.000 (99.694)\n",
            "Epoch: [154][180/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.000 (0.010)\tLoss 0.3354 (0.2657)\tPrec@1 89.062 (91.206)\tPrec@5 99.219 (99.698)\n",
            "Epoch: [154][190/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.010)\tLoss 0.2700 (0.2660)\tPrec@1 91.406 (91.183)\tPrec@5 99.609 (99.695)\n",
            "Epoch: [154][200/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.012 (0.010)\tLoss 0.2928 (0.2656)\tPrec@1 89.453 (91.216)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [154][210/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.010 (0.009)\tLoss 0.2184 (0.2646)\tPrec@1 92.188 (91.282)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [154][220/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.005 (0.009)\tLoss 0.2485 (0.2643)\tPrec@1 90.625 (91.295)\tPrec@5 100.000 (99.703)\n",
            "Epoch: [154][230/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.009)\tLoss 0.2220 (0.2631)\tPrec@1 93.750 (91.340)\tPrec@5 100.000 (99.713)\n",
            "Epoch: [154][240/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.009)\tLoss 0.2767 (0.2620)\tPrec@1 91.406 (91.374)\tPrec@5 99.609 (99.710)\n",
            "Epoch: [154][250/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.005 (0.009)\tLoss 0.2918 (0.2623)\tPrec@1 89.453 (91.358)\tPrec@5 99.609 (99.709)\n",
            "Epoch: [154][260/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.009 (0.009)\tLoss 0.2598 (0.2636)\tPrec@1 89.844 (91.316)\tPrec@5 100.000 (99.710)\n",
            "Epoch: [154][270/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.007 (0.009)\tLoss 0.4109 (0.2644)\tPrec@1 87.500 (91.304)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [154][280/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.006 (0.009)\tLoss 0.2337 (0.2642)\tPrec@1 90.234 (91.295)\tPrec@5 99.609 (99.698)\n",
            "Epoch: [154][290/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.004 (0.009)\tLoss 0.3484 (0.2641)\tPrec@1 89.062 (91.318)\tPrec@5 99.219 (99.694)\n",
            "Epoch: [154][300/329], lr: 0.01000\tTime 0.064 (0.092)\tData 0.000 (0.009)\tLoss 0.2390 (0.2637)\tPrec@1 91.797 (91.328)\tPrec@5 99.219 (99.696)\n",
            "Epoch: [154][310/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.007 (0.009)\tLoss 0.2733 (0.2643)\tPrec@1 89.844 (91.311)\tPrec@5 99.609 (99.696)\n",
            "Epoch: [154][320/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.040 (0.009)\tLoss 0.2496 (0.2638)\tPrec@1 90.625 (91.319)\tPrec@5 99.609 (99.692)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 0.8619 (0.8619)\tPrec@1 70.000 (70.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.037 (0.059)\tLoss 0.9067 (0.9066)\tPrec@1 72.000 (73.091)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.031 (0.043)\tLoss 0.6566 (0.9028)\tPrec@1 79.000 (73.381)\tPrec@5 100.000 (98.286)\n",
            "Test: [30/100]\tTime 0.026 (0.037)\tLoss 0.9884 (0.9038)\tPrec@1 70.000 (73.516)\tPrec@5 98.000 (98.194)\n",
            "Test: [40/100]\tTime 0.025 (0.034)\tLoss 0.9817 (0.9020)\tPrec@1 71.000 (73.220)\tPrec@5 99.000 (98.146)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 0.9787 (0.9002)\tPrec@1 71.000 (73.216)\tPrec@5 98.000 (98.137)\n",
            "Test: [60/100]\tTime 0.020 (0.031)\tLoss 0.7933 (0.9096)\tPrec@1 78.000 (72.918)\tPrec@5 98.000 (98.164)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 1.1491 (0.9057)\tPrec@1 71.000 (72.873)\tPrec@5 98.000 (98.310)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 0.8034 (0.9021)\tPrec@1 75.000 (72.926)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 0.8496 (0.9124)\tPrec@1 73.000 (72.791)\tPrec@5 99.000 (98.308)\n",
            "val Results: Prec@1 72.860 Prec@5 98.290 Loss 0.90955\n",
            "val Class Accuracy: [0.979,0.931,0.740,0.640,0.825,0.722,0.595,0.584,0.601,0.669]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [155][0/329], lr: 0.01000\tTime 0.561 (0.561)\tData 0.499 (0.499)\tLoss 0.3227 (0.3227)\tPrec@1 88.672 (88.672)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [155][10/329], lr: 0.01000\tTime 0.087 (0.139)\tData 0.000 (0.057)\tLoss 0.5229 (0.4864)\tPrec@1 82.422 (83.771)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [155][20/329], lr: 0.01000\tTime 0.112 (0.119)\tData 0.000 (0.032)\tLoss 0.3017 (0.4269)\tPrec@1 90.625 (85.528)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [155][30/329], lr: 0.01000\tTime 0.087 (0.109)\tData 0.000 (0.023)\tLoss 0.3498 (0.3973)\tPrec@1 89.453 (86.492)\tPrec@5 100.000 (99.496)\n",
            "Epoch: [155][40/329], lr: 0.01000\tTime 0.091 (0.106)\tData 0.000 (0.019)\tLoss 0.3051 (0.3768)\tPrec@1 89.844 (87.309)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [155][50/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.000 (0.017)\tLoss 0.2257 (0.3563)\tPrec@1 93.359 (87.983)\tPrec@5 99.609 (99.571)\n",
            "Epoch: [155][60/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.002 (0.015)\tLoss 0.2343 (0.3446)\tPrec@1 93.750 (88.326)\tPrec@5 99.609 (99.577)\n",
            "Epoch: [155][70/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.000 (0.014)\tLoss 0.2975 (0.3347)\tPrec@1 89.062 (88.556)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [155][80/329], lr: 0.01000\tTime 0.080 (0.097)\tData 0.002 (0.013)\tLoss 0.2799 (0.3265)\tPrec@1 89.453 (88.903)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [155][90/329], lr: 0.01000\tTime 0.080 (0.097)\tData 0.000 (0.013)\tLoss 0.2595 (0.3203)\tPrec@1 91.406 (89.144)\tPrec@5 99.219 (99.635)\n",
            "Epoch: [155][100/329], lr: 0.01000\tTime 0.105 (0.096)\tData 0.005 (0.012)\tLoss 0.2394 (0.3145)\tPrec@1 91.406 (89.360)\tPrec@5 100.000 (99.633)\n",
            "Epoch: [155][110/329], lr: 0.01000\tTime 0.103 (0.095)\tData 0.005 (0.012)\tLoss 0.2209 (0.3117)\tPrec@1 92.969 (89.443)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [155][120/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.000 (0.011)\tLoss 0.2487 (0.3069)\tPrec@1 91.406 (89.621)\tPrec@5 99.219 (99.664)\n",
            "Epoch: [155][130/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.001 (0.011)\tLoss 0.2737 (0.3044)\tPrec@1 90.625 (89.695)\tPrec@5 99.609 (99.675)\n",
            "Epoch: [155][140/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.004 (0.011)\tLoss 0.2849 (0.3015)\tPrec@1 90.234 (89.797)\tPrec@5 99.219 (99.673)\n",
            "Epoch: [155][150/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.000 (0.011)\tLoss 0.2743 (0.2992)\tPrec@1 89.844 (89.888)\tPrec@5 100.000 (99.684)\n",
            "Epoch: [155][160/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.007 (0.010)\tLoss 0.3012 (0.2977)\tPrec@1 90.234 (89.953)\tPrec@5 99.609 (99.685)\n",
            "Epoch: [155][170/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.004 (0.010)\tLoss 0.2794 (0.2953)\tPrec@1 91.016 (90.070)\tPrec@5 100.000 (99.687)\n",
            "Epoch: [155][180/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.006 (0.010)\tLoss 0.2768 (0.2937)\tPrec@1 88.281 (90.116)\tPrec@5 99.609 (99.683)\n",
            "Epoch: [155][190/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.000 (0.010)\tLoss 0.2846 (0.2923)\tPrec@1 89.062 (90.183)\tPrec@5 100.000 (99.677)\n",
            "Epoch: [155][200/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.006 (0.010)\tLoss 0.1806 (0.2890)\tPrec@1 94.141 (90.297)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [155][210/329], lr: 0.01000\tTime 0.068 (0.093)\tData 0.000 (0.010)\tLoss 0.2656 (0.2874)\tPrec@1 89.844 (90.331)\tPrec@5 100.000 (99.685)\n",
            "Epoch: [155][220/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.005 (0.010)\tLoss 0.3207 (0.2871)\tPrec@1 88.672 (90.342)\tPrec@5 100.000 (99.685)\n",
            "Epoch: [155][230/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.004 (0.010)\tLoss 0.1774 (0.2849)\tPrec@1 94.922 (90.453)\tPrec@5 99.609 (99.684)\n",
            "Epoch: [155][240/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.007 (0.010)\tLoss 0.2963 (0.2836)\tPrec@1 88.672 (90.479)\tPrec@5 100.000 (99.689)\n",
            "Epoch: [155][250/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.009)\tLoss 0.2940 (0.2845)\tPrec@1 88.281 (90.458)\tPrec@5 99.219 (99.679)\n",
            "Epoch: [155][260/329], lr: 0.01000\tTime 0.112 (0.092)\tData 0.004 (0.009)\tLoss 0.2811 (0.2830)\tPrec@1 91.016 (90.511)\tPrec@5 100.000 (99.680)\n",
            "Epoch: [155][270/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.009)\tLoss 0.3206 (0.2816)\tPrec@1 88.672 (90.556)\tPrec@5 99.609 (99.681)\n",
            "Epoch: [155][280/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.009 (0.009)\tLoss 0.2832 (0.2812)\tPrec@1 90.234 (90.578)\tPrec@5 99.219 (99.677)\n",
            "Epoch: [155][290/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.006 (0.009)\tLoss 0.1492 (0.2800)\tPrec@1 95.312 (90.620)\tPrec@5 100.000 (99.683)\n",
            "Epoch: [155][300/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.007 (0.009)\tLoss 0.2778 (0.2795)\tPrec@1 91.406 (90.651)\tPrec@5 99.609 (99.681)\n",
            "Epoch: [155][310/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.2364 (0.2788)\tPrec@1 92.969 (90.671)\tPrec@5 99.609 (99.681)\n",
            "Epoch: [155][320/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.035 (0.009)\tLoss 0.2135 (0.2779)\tPrec@1 93.750 (90.700)\tPrec@5 100.000 (99.679)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 5.2388 (5.2388)\tPrec@1 26.000 (26.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.025 (0.059)\tLoss 4.9784 (5.2351)\tPrec@1 24.000 (26.091)\tPrec@5 89.000 (87.727)\n",
            "Test: [20/100]\tTime 0.024 (0.042)\tLoss 4.8447 (4.9257)\tPrec@1 32.000 (28.857)\tPrec@5 91.000 (89.190)\n",
            "Test: [30/100]\tTime 0.027 (0.038)\tLoss 4.7151 (4.9447)\tPrec@1 36.000 (29.355)\tPrec@5 91.000 (89.161)\n",
            "Test: [40/100]\tTime 0.013 (0.034)\tLoss 4.3239 (4.9310)\tPrec@1 33.000 (29.463)\tPrec@5 92.000 (89.415)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 4.8898 (4.9562)\tPrec@1 29.000 (29.686)\tPrec@5 90.000 (89.275)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 4.2921 (4.9551)\tPrec@1 37.000 (29.574)\tPrec@5 92.000 (89.410)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 4.4577 (4.9606)\tPrec@1 28.000 (29.493)\tPrec@5 92.000 (89.169)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 5.3355 (4.9651)\tPrec@1 26.000 (29.346)\tPrec@5 90.000 (89.346)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 4.2880 (4.9897)\tPrec@1 31.000 (29.154)\tPrec@5 94.000 (89.011)\n",
            "val Results: Prec@1 29.050 Prec@5 89.050 Loss 4.99500\n",
            "val Class Accuracy: [0.087,0.251,0.382,0.022,0.951,0.669,0.291,0.038,0.106,0.108]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [156][0/329], lr: 0.01000\tTime 0.688 (0.688)\tData 0.589 (0.589)\tLoss 0.4132 (0.4132)\tPrec@1 87.891 (87.891)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][10/329], lr: 0.01000\tTime 0.085 (0.155)\tData 0.012 (0.062)\tLoss 1.0572 (1.0579)\tPrec@1 67.969 (68.786)\tPrec@5 94.531 (95.810)\n",
            "Epoch: [156][20/329], lr: 0.01000\tTime 0.080 (0.125)\tData 0.011 (0.036)\tLoss 0.8093 (0.9569)\tPrec@1 72.656 (70.294)\tPrec@5 96.875 (96.243)\n",
            "Epoch: [156][30/329], lr: 0.01000\tTime 0.073 (0.113)\tData 0.000 (0.026)\tLoss 0.6557 (0.8856)\tPrec@1 77.734 (71.673)\tPrec@5 97.656 (96.749)\n",
            "Epoch: [156][40/329], lr: 0.01000\tTime 0.086 (0.108)\tData 0.000 (0.022)\tLoss 0.5669 (0.8207)\tPrec@1 82.422 (73.647)\tPrec@5 97.266 (97.151)\n",
            "Epoch: [156][50/329], lr: 0.01000\tTime 0.083 (0.104)\tData 0.005 (0.019)\tLoss 0.5865 (0.7731)\tPrec@1 78.516 (74.962)\tPrec@5 98.828 (97.495)\n",
            "Epoch: [156][60/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.000 (0.017)\tLoss 0.5087 (0.7368)\tPrec@1 83.594 (76.025)\tPrec@5 98.438 (97.682)\n",
            "Epoch: [156][70/329], lr: 0.01000\tTime 0.106 (0.100)\tData 0.011 (0.016)\tLoss 0.4729 (0.7055)\tPrec@1 85.547 (77.041)\tPrec@5 98.047 (97.816)\n",
            "Epoch: [156][80/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.001 (0.014)\tLoss 0.4821 (0.6746)\tPrec@1 84.766 (77.898)\tPrec@5 99.609 (97.994)\n",
            "Epoch: [156][90/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.000 (0.013)\tLoss 0.3783 (0.6474)\tPrec@1 90.234 (78.773)\tPrec@5 100.000 (98.158)\n",
            "Epoch: [156][100/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.001 (0.013)\tLoss 0.3552 (0.6246)\tPrec@1 87.500 (79.483)\tPrec@5 100.000 (98.291)\n",
            "Epoch: [156][110/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.000 (0.012)\tLoss 0.3616 (0.6058)\tPrec@1 88.672 (80.061)\tPrec@5 99.219 (98.374)\n",
            "Epoch: [156][120/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.012)\tLoss 0.3563 (0.5866)\tPrec@1 89.453 (80.650)\tPrec@5 99.219 (98.457)\n",
            "Epoch: [156][130/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.005 (0.012)\tLoss 0.4445 (0.5728)\tPrec@1 85.547 (81.107)\tPrec@5 99.609 (98.506)\n",
            "Epoch: [156][140/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.006 (0.012)\tLoss 0.4346 (0.5597)\tPrec@1 87.891 (81.552)\tPrec@5 100.000 (98.570)\n",
            "Epoch: [156][150/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.009 (0.011)\tLoss 0.3275 (0.5480)\tPrec@1 87.109 (81.923)\tPrec@5 100.000 (98.629)\n",
            "Epoch: [156][160/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.006 (0.011)\tLoss 0.3828 (0.5363)\tPrec@1 87.891 (82.322)\tPrec@5 99.609 (98.690)\n",
            "Epoch: [156][170/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.007 (0.011)\tLoss 0.4357 (0.5276)\tPrec@1 86.328 (82.577)\tPrec@5 99.219 (98.728)\n",
            "Epoch: [156][180/329], lr: 0.01000\tTime 0.067 (0.094)\tData 0.000 (0.011)\tLoss 0.2918 (0.5186)\tPrec@1 89.453 (82.892)\tPrec@5 100.000 (98.770)\n",
            "Epoch: [156][190/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.007 (0.011)\tLoss 0.3171 (0.5095)\tPrec@1 89.844 (83.156)\tPrec@5 100.000 (98.799)\n",
            "Epoch: [156][200/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.008 (0.010)\tLoss 0.3204 (0.5009)\tPrec@1 88.672 (83.444)\tPrec@5 100.000 (98.830)\n",
            "Epoch: [156][210/329], lr: 0.01000\tTime 0.070 (0.093)\tData 0.007 (0.010)\tLoss 0.3650 (0.4948)\tPrec@1 87.500 (83.640)\tPrec@5 99.609 (98.860)\n",
            "Epoch: [156][220/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.000 (0.010)\tLoss 0.3013 (0.4876)\tPrec@1 88.672 (83.880)\tPrec@5 99.609 (98.881)\n",
            "Epoch: [156][230/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.010)\tLoss 0.3807 (0.4808)\tPrec@1 87.891 (84.103)\tPrec@5 98.828 (98.918)\n",
            "Epoch: [156][240/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.007 (0.010)\tLoss 0.4421 (0.4759)\tPrec@1 83.203 (84.242)\tPrec@5 98.828 (98.935)\n",
            "Epoch: [156][250/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.011 (0.010)\tLoss 0.3289 (0.4697)\tPrec@1 86.719 (84.422)\tPrec@5 99.609 (98.959)\n",
            "Epoch: [156][260/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.008 (0.010)\tLoss 0.3410 (0.4645)\tPrec@1 88.672 (84.591)\tPrec@5 99.609 (98.985)\n",
            "Epoch: [156][270/329], lr: 0.01000\tTime 0.106 (0.092)\tData 0.000 (0.010)\tLoss 0.3598 (0.4594)\tPrec@1 87.891 (84.754)\tPrec@5 99.609 (99.003)\n",
            "Epoch: [156][280/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.006 (0.009)\tLoss 0.2528 (0.4543)\tPrec@1 91.797 (84.906)\tPrec@5 100.000 (99.026)\n",
            "Epoch: [156][290/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 0.3410 (0.4505)\tPrec@1 90.625 (85.069)\tPrec@5 99.609 (99.044)\n",
            "Epoch: [156][300/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 0.3286 (0.4453)\tPrec@1 89.844 (85.261)\tPrec@5 98.438 (99.055)\n",
            "Epoch: [156][310/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.009)\tLoss 0.3017 (0.4409)\tPrec@1 91.016 (85.389)\tPrec@5 99.609 (99.069)\n",
            "Epoch: [156][320/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.041 (0.009)\tLoss 0.3155 (0.4367)\tPrec@1 92.969 (85.542)\tPrec@5 99.609 (99.085)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 1.3978 (1.3978)\tPrec@1 59.000 (59.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.023 (0.059)\tLoss 1.2998 (1.5822)\tPrec@1 63.000 (57.455)\tPrec@5 96.000 (96.818)\n",
            "Test: [20/100]\tTime 0.021 (0.042)\tLoss 1.5590 (1.5789)\tPrec@1 61.000 (57.524)\tPrec@5 96.000 (96.143)\n",
            "Test: [30/100]\tTime 0.045 (0.036)\tLoss 1.7635 (1.5973)\tPrec@1 53.000 (57.097)\tPrec@5 94.000 (95.871)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 1.8488 (1.5987)\tPrec@1 54.000 (56.805)\tPrec@5 93.000 (95.683)\n",
            "Test: [50/100]\tTime 0.018 (0.030)\tLoss 1.7238 (1.6009)\tPrec@1 55.000 (57.059)\tPrec@5 94.000 (95.784)\n",
            "Test: [60/100]\tTime 0.017 (0.029)\tLoss 1.6002 (1.6364)\tPrec@1 59.000 (56.033)\tPrec@5 92.000 (95.754)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 1.5731 (1.6333)\tPrec@1 60.000 (56.085)\tPrec@5 96.000 (95.873)\n",
            "Test: [80/100]\tTime 0.031 (0.028)\tLoss 1.1849 (1.6278)\tPrec@1 67.000 (56.198)\tPrec@5 96.000 (95.840)\n",
            "Test: [90/100]\tTime 0.009 (0.027)\tLoss 1.3921 (1.6454)\tPrec@1 57.000 (55.967)\tPrec@5 96.000 (95.857)\n",
            "val Results: Prec@1 56.140 Prec@5 95.750 Loss 1.63900\n",
            "val Class Accuracy: [0.924,0.924,0.933,0.348,0.320,0.252,0.400,0.316,0.713,0.484]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [157][0/329], lr: 0.01000\tTime 0.669 (0.669)\tData 0.574 (0.574)\tLoss 0.3434 (0.3434)\tPrec@1 88.672 (88.672)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [157][10/329], lr: 0.01000\tTime 0.103 (0.158)\tData 0.000 (0.059)\tLoss 0.6281 (0.4944)\tPrec@1 79.297 (83.452)\tPrec@5 99.609 (99.112)\n",
            "Epoch: [157][20/329], lr: 0.01000\tTime 0.129 (0.141)\tData 0.009 (0.041)\tLoss 0.3660 (0.4708)\tPrec@1 87.109 (84.505)\tPrec@5 99.219 (99.107)\n",
            "Epoch: [157][30/329], lr: 0.01000\tTime 0.104 (0.138)\tData 0.036 (0.040)\tLoss 0.4389 (0.4424)\tPrec@1 84.375 (85.471)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [157][40/329], lr: 0.01000\tTime 0.127 (0.129)\tData 0.002 (0.032)\tLoss 0.3035 (0.4215)\tPrec@1 88.672 (86.147)\tPrec@5 99.609 (99.295)\n",
            "Epoch: [157][50/329], lr: 0.01000\tTime 0.091 (0.123)\tData 0.005 (0.027)\tLoss 0.2854 (0.4063)\tPrec@1 91.016 (86.665)\tPrec@5 99.219 (99.318)\n",
            "Epoch: [157][60/329], lr: 0.01000\tTime 0.078 (0.117)\tData 0.000 (0.023)\tLoss 0.2905 (0.3925)\tPrec@1 89.453 (87.077)\tPrec@5 99.609 (99.392)\n",
            "Epoch: [157][70/329], lr: 0.01000\tTime 0.092 (0.113)\tData 0.000 (0.021)\tLoss 0.2110 (0.3803)\tPrec@1 92.969 (87.439)\tPrec@5 100.000 (99.428)\n",
            "Epoch: [157][80/329], lr: 0.01000\tTime 0.104 (0.110)\tData 0.005 (0.019)\tLoss 0.4242 (0.3710)\tPrec@1 83.594 (87.765)\tPrec@5 100.000 (99.445)\n",
            "Epoch: [157][90/329], lr: 0.01000\tTime 0.092 (0.108)\tData 0.001 (0.018)\tLoss 0.2893 (0.3629)\tPrec@1 89.062 (87.989)\tPrec@5 99.219 (99.463)\n",
            "Epoch: [157][100/329], lr: 0.01000\tTime 0.092 (0.106)\tData 0.008 (0.017)\tLoss 0.3110 (0.3555)\tPrec@1 87.500 (88.219)\tPrec@5 100.000 (99.489)\n",
            "Epoch: [157][110/329], lr: 0.01000\tTime 0.095 (0.104)\tData 0.004 (0.016)\tLoss 0.2458 (0.3484)\tPrec@1 89.844 (88.429)\tPrec@5 100.000 (99.514)\n",
            "Epoch: [157][120/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.006 (0.015)\tLoss 0.2524 (0.3436)\tPrec@1 91.797 (88.585)\tPrec@5 100.000 (99.525)\n",
            "Epoch: [157][130/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.000 (0.014)\tLoss 0.2193 (0.3387)\tPrec@1 92.969 (88.723)\tPrec@5 100.000 (99.547)\n",
            "Epoch: [157][140/329], lr: 0.01000\tTime 0.070 (0.101)\tData 0.000 (0.014)\tLoss 0.2462 (0.3363)\tPrec@1 91.797 (88.805)\tPrec@5 98.828 (99.543)\n",
            "Epoch: [157][150/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.007 (0.014)\tLoss 0.3721 (0.3348)\tPrec@1 87.891 (88.889)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [157][160/329], lr: 0.01000\tTime 0.089 (0.100)\tData 0.005 (0.013)\tLoss 0.3020 (0.3326)\tPrec@1 89.062 (88.968)\tPrec@5 99.609 (99.541)\n",
            "Epoch: [157][170/329], lr: 0.01000\tTime 0.071 (0.099)\tData 0.001 (0.013)\tLoss 0.2213 (0.3303)\tPrec@1 92.969 (89.062)\tPrec@5 100.000 (99.541)\n",
            "Epoch: [157][180/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.012)\tLoss 0.4145 (0.3284)\tPrec@1 86.328 (89.119)\tPrec@5 99.609 (99.555)\n",
            "Epoch: [157][190/329], lr: 0.01000\tTime 0.075 (0.098)\tData 0.006 (0.012)\tLoss 0.3423 (0.3256)\tPrec@1 87.109 (89.187)\tPrec@5 99.609 (99.566)\n",
            "Epoch: [157][200/329], lr: 0.01000\tTime 0.067 (0.098)\tData 0.000 (0.012)\tLoss 0.3059 (0.3236)\tPrec@1 89.062 (89.245)\tPrec@5 99.609 (99.565)\n",
            "Epoch: [157][210/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.008 (0.012)\tLoss 0.2512 (0.3216)\tPrec@1 91.016 (89.272)\tPrec@5 100.000 (99.567)\n",
            "Epoch: [157][220/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.005 (0.012)\tLoss 0.1967 (0.3198)\tPrec@1 94.531 (89.322)\tPrec@5 99.609 (99.560)\n",
            "Epoch: [157][230/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.001 (0.012)\tLoss 0.3146 (0.3186)\tPrec@1 90.234 (89.379)\tPrec@5 99.609 (99.560)\n",
            "Epoch: [157][240/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.000 (0.011)\tLoss 0.1871 (0.3170)\tPrec@1 94.531 (89.439)\tPrec@5 100.000 (99.564)\n",
            "Epoch: [157][250/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.005 (0.011)\tLoss 0.3122 (0.3162)\tPrec@1 89.453 (89.473)\tPrec@5 99.609 (99.566)\n",
            "Epoch: [157][260/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.012 (0.011)\tLoss 0.2767 (0.3154)\tPrec@1 89.453 (89.504)\tPrec@5 99.609 (99.573)\n",
            "Epoch: [157][270/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.007 (0.011)\tLoss 0.2340 (0.3135)\tPrec@1 92.969 (89.579)\tPrec@5 99.609 (99.578)\n",
            "Epoch: [157][280/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.007 (0.011)\tLoss 0.2712 (0.3127)\tPrec@1 91.016 (89.596)\tPrec@5 100.000 (99.580)\n",
            "Epoch: [157][290/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.005 (0.011)\tLoss 0.2581 (0.3120)\tPrec@1 92.188 (89.620)\tPrec@5 99.219 (99.577)\n",
            "Epoch: [157][300/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.000 (0.010)\tLoss 0.2998 (0.3113)\tPrec@1 87.109 (89.649)\tPrec@5 100.000 (99.580)\n",
            "Epoch: [157][310/329], lr: 0.01000\tTime 0.073 (0.095)\tData 0.007 (0.011)\tLoss 0.2574 (0.3106)\tPrec@1 91.016 (89.665)\tPrec@5 100.000 (99.586)\n",
            "Epoch: [157][320/329], lr: 0.01000\tTime 0.115 (0.094)\tData 0.067 (0.011)\tLoss 0.2901 (0.3094)\tPrec@1 90.234 (89.716)\tPrec@5 99.609 (99.591)\n",
            "Test: [0/100]\tTime 0.366 (0.366)\tLoss 0.6504 (0.6504)\tPrec@1 79.000 (79.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.013 (0.057)\tLoss 0.6582 (0.8038)\tPrec@1 82.000 (76.364)\tPrec@5 99.000 (98.091)\n",
            "Test: [20/100]\tTime 0.021 (0.041)\tLoss 0.8495 (0.7817)\tPrec@1 73.000 (76.619)\tPrec@5 98.000 (98.000)\n",
            "Test: [30/100]\tTime 0.027 (0.036)\tLoss 0.8460 (0.8025)\tPrec@1 74.000 (76.194)\tPrec@5 99.000 (97.871)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 0.7802 (0.8147)\tPrec@1 74.000 (75.902)\tPrec@5 97.000 (97.902)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 0.8227 (0.8026)\tPrec@1 81.000 (76.176)\tPrec@5 97.000 (97.922)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 0.8488 (0.8207)\tPrec@1 78.000 (75.311)\tPrec@5 100.000 (97.984)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 0.6742 (0.8193)\tPrec@1 80.000 (75.268)\tPrec@5 98.000 (97.986)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 0.8812 (0.8158)\tPrec@1 73.000 (75.210)\tPrec@5 95.000 (97.975)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 0.7017 (0.8245)\tPrec@1 78.000 (75.022)\tPrec@5 100.000 (97.901)\n",
            "val Results: Prec@1 75.040 Prec@5 97.920 Loss 0.82108\n",
            "val Class Accuracy: [0.849,0.964,0.860,0.817,0.769,0.539,0.787,0.595,0.653,0.671]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [158][0/329], lr: 0.01000\tTime 0.659 (0.659)\tData 0.579 (0.579)\tLoss 0.2612 (0.2612)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][10/329], lr: 0.01000\tTime 0.081 (0.150)\tData 0.005 (0.059)\tLoss 0.4002 (0.4515)\tPrec@1 84.766 (85.156)\tPrec@5 99.609 (99.538)\n",
            "Epoch: [158][20/329], lr: 0.01000\tTime 0.092 (0.125)\tData 0.000 (0.035)\tLoss 0.4478 (0.4503)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.330)\n",
            "Epoch: [158][30/329], lr: 0.01000\tTime 0.085 (0.114)\tData 0.010 (0.026)\tLoss 0.3593 (0.4260)\tPrec@1 87.891 (85.774)\tPrec@5 99.219 (99.383)\n",
            "Epoch: [158][40/329], lr: 0.01000\tTime 0.090 (0.108)\tData 0.000 (0.021)\tLoss 0.2980 (0.4031)\tPrec@1 89.453 (86.433)\tPrec@5 99.609 (99.371)\n",
            "Epoch: [158][50/329], lr: 0.01000\tTime 0.085 (0.104)\tData 0.005 (0.019)\tLoss 0.2868 (0.3855)\tPrec@1 91.016 (87.194)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [158][60/329], lr: 0.01000\tTime 0.083 (0.102)\tData 0.010 (0.017)\tLoss 0.3065 (0.3698)\tPrec@1 91.797 (87.724)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [158][70/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.000 (0.016)\tLoss 0.3214 (0.3573)\tPrec@1 89.062 (88.067)\tPrec@5 99.609 (99.466)\n",
            "Epoch: [158][80/329], lr: 0.01000\tTime 0.072 (0.098)\tData 0.003 (0.015)\tLoss 0.3417 (0.3496)\tPrec@1 87.891 (88.325)\tPrec@5 99.609 (99.479)\n",
            "Epoch: [158][90/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.000 (0.014)\tLoss 0.2977 (0.3430)\tPrec@1 89.453 (88.565)\tPrec@5 100.000 (99.506)\n",
            "Epoch: [158][100/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.009 (0.013)\tLoss 0.4048 (0.3387)\tPrec@1 86.719 (88.749)\tPrec@5 99.219 (99.517)\n",
            "Epoch: [158][110/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.013)\tLoss 0.2890 (0.3337)\tPrec@1 89.844 (88.880)\tPrec@5 99.609 (99.543)\n",
            "Epoch: [158][120/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.007 (0.012)\tLoss 0.2974 (0.3303)\tPrec@1 89.844 (88.933)\tPrec@5 99.609 (99.561)\n",
            "Epoch: [158][130/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.006 (0.012)\tLoss 0.3047 (0.3258)\tPrec@1 90.234 (89.143)\tPrec@5 98.828 (99.574)\n",
            "Epoch: [158][140/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.005 (0.012)\tLoss 0.2586 (0.3212)\tPrec@1 91.016 (89.281)\tPrec@5 99.609 (99.579)\n",
            "Epoch: [158][150/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.007 (0.011)\tLoss 0.2337 (0.3169)\tPrec@1 91.406 (89.430)\tPrec@5 99.219 (99.584)\n",
            "Epoch: [158][160/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.012 (0.011)\tLoss 0.2743 (0.3142)\tPrec@1 92.578 (89.545)\tPrec@5 99.609 (99.588)\n",
            "Epoch: [158][170/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.006 (0.011)\tLoss 0.3022 (0.3126)\tPrec@1 89.453 (89.627)\tPrec@5 100.000 (99.593)\n",
            "Epoch: [158][180/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.001 (0.011)\tLoss 0.3108 (0.3095)\tPrec@1 88.672 (89.703)\tPrec@5 99.609 (99.599)\n",
            "Epoch: [158][190/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.011 (0.011)\tLoss 0.2509 (0.3090)\tPrec@1 90.625 (89.731)\tPrec@5 100.000 (99.601)\n",
            "Epoch: [158][200/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.006 (0.010)\tLoss 0.1831 (0.3061)\tPrec@1 91.797 (89.822)\tPrec@5 100.000 (99.605)\n",
            "Epoch: [158][210/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.005 (0.010)\tLoss 0.2707 (0.3045)\tPrec@1 89.844 (89.846)\tPrec@5 100.000 (99.611)\n",
            "Epoch: [158][220/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.007 (0.010)\tLoss 0.2307 (0.3033)\tPrec@1 93.750 (89.891)\tPrec@5 99.609 (99.615)\n",
            "Epoch: [158][230/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.010)\tLoss 0.2124 (0.3023)\tPrec@1 94.141 (89.938)\tPrec@5 100.000 (99.618)\n",
            "Epoch: [158][240/329], lr: 0.01000\tTime 0.056 (0.092)\tData 0.000 (0.010)\tLoss 0.3022 (0.3008)\tPrec@1 91.797 (89.996)\tPrec@5 99.219 (99.619)\n",
            "Epoch: [158][250/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.006 (0.010)\tLoss 0.2828 (0.3003)\tPrec@1 89.062 (89.998)\tPrec@5 99.609 (99.625)\n",
            "Epoch: [158][260/329], lr: 0.01000\tTime 0.066 (0.092)\tData 0.006 (0.010)\tLoss 0.2473 (0.2983)\tPrec@1 90.234 (90.085)\tPrec@5 100.000 (99.627)\n",
            "Epoch: [158][270/329], lr: 0.01000\tTime 0.102 (0.091)\tData 0.000 (0.010)\tLoss 0.3021 (0.2978)\tPrec@1 89.453 (90.105)\tPrec@5 99.609 (99.625)\n",
            "Epoch: [158][280/329], lr: 0.01000\tTime 0.061 (0.091)\tData 0.000 (0.010)\tLoss 0.1453 (0.2960)\tPrec@1 96.094 (90.151)\tPrec@5 100.000 (99.625)\n",
            "Epoch: [158][290/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.006 (0.010)\tLoss 0.2790 (0.2945)\tPrec@1 90.625 (90.189)\tPrec@5 99.609 (99.630)\n",
            "Epoch: [158][300/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.006 (0.010)\tLoss 0.2409 (0.2935)\tPrec@1 92.969 (90.236)\tPrec@5 100.000 (99.629)\n",
            "Epoch: [158][310/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.006 (0.009)\tLoss 0.2532 (0.2917)\tPrec@1 91.406 (90.277)\tPrec@5 99.609 (99.636)\n",
            "Epoch: [158][320/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.048 (0.009)\tLoss 0.3500 (0.2913)\tPrec@1 88.672 (90.299)\tPrec@5 100.000 (99.637)\n",
            "Test: [0/100]\tTime 0.376 (0.376)\tLoss 0.6001 (0.6001)\tPrec@1 81.000 (81.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.020 (0.054)\tLoss 0.5947 (0.7707)\tPrec@1 79.000 (75.636)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.009 (0.040)\tLoss 0.7510 (0.7403)\tPrec@1 81.000 (77.000)\tPrec@5 100.000 (98.238)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 0.9920 (0.7690)\tPrec@1 73.000 (76.742)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/100]\tTime 0.016 (0.033)\tLoss 0.6728 (0.7848)\tPrec@1 76.000 (76.195)\tPrec@5 97.000 (98.098)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 0.7094 (0.7748)\tPrec@1 80.000 (76.667)\tPrec@5 97.000 (98.039)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 0.7432 (0.7781)\tPrec@1 79.000 (76.328)\tPrec@5 99.000 (98.180)\n",
            "Test: [70/100]\tTime 0.019 (0.028)\tLoss 0.6216 (0.7677)\tPrec@1 81.000 (76.662)\tPrec@5 100.000 (98.225)\n",
            "Test: [80/100]\tTime 0.043 (0.028)\tLoss 0.6917 (0.7691)\tPrec@1 78.000 (76.444)\tPrec@5 97.000 (98.235)\n",
            "Test: [90/100]\tTime 0.041 (0.028)\tLoss 0.8034 (0.7791)\tPrec@1 75.000 (76.132)\tPrec@5 97.000 (98.209)\n",
            "val Results: Prec@1 76.030 Prec@5 98.230 Loss 0.77991\n",
            "val Class Accuracy: [0.866,0.890,0.556,0.825,0.910,0.621,0.738,0.693,0.711,0.793]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [159][0/329], lr: 0.01000\tTime 0.597 (0.597)\tData 0.514 (0.514)\tLoss 0.2508 (0.2508)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][10/329], lr: 0.01000\tTime 0.090 (0.143)\tData 0.005 (0.052)\tLoss 0.3128 (0.2682)\tPrec@1 89.844 (91.193)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [159][20/329], lr: 0.01000\tTime 0.087 (0.117)\tData 0.005 (0.030)\tLoss 0.3049 (0.2720)\tPrec@1 86.719 (90.755)\tPrec@5 99.609 (99.777)\n",
            "Epoch: [159][30/329], lr: 0.01000\tTime 0.119 (0.110)\tData 0.000 (0.021)\tLoss 0.2850 (0.2719)\tPrec@1 91.016 (90.890)\tPrec@5 99.609 (99.685)\n",
            "Epoch: [159][40/329], lr: 0.01000\tTime 0.083 (0.106)\tData 0.007 (0.017)\tLoss 0.2060 (0.2660)\tPrec@1 93.750 (91.197)\tPrec@5 99.609 (99.676)\n",
            "Epoch: [159][50/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.000 (0.015)\tLoss 0.2959 (0.2629)\tPrec@1 89.844 (91.230)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [159][60/329], lr: 0.01000\tTime 0.100 (0.102)\tData 0.001 (0.014)\tLoss 0.3212 (0.2610)\tPrec@1 88.672 (91.304)\tPrec@5 99.609 (99.750)\n",
            "Epoch: [159][70/329], lr: 0.01000\tTime 0.072 (0.100)\tData 0.004 (0.013)\tLoss 0.3194 (0.2663)\tPrec@1 88.281 (91.148)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [159][80/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.004 (0.012)\tLoss 0.3219 (0.2669)\tPrec@1 90.625 (91.127)\tPrec@5 99.219 (99.744)\n",
            "Epoch: [159][90/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.008 (0.011)\tLoss 0.2276 (0.2648)\tPrec@1 93.359 (91.196)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [159][100/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.006 (0.011)\tLoss 0.2547 (0.2638)\tPrec@1 89.844 (91.224)\tPrec@5 99.609 (99.749)\n",
            "Epoch: [159][110/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.008 (0.011)\tLoss 0.2308 (0.2619)\tPrec@1 92.188 (91.315)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [159][120/329], lr: 0.01000\tTime 0.069 (0.096)\tData 0.007 (0.010)\tLoss 0.1772 (0.2610)\tPrec@1 94.141 (91.303)\tPrec@5 99.609 (99.748)\n",
            "Epoch: [159][130/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.007 (0.010)\tLoss 0.2448 (0.2603)\tPrec@1 91.406 (91.335)\tPrec@5 99.609 (99.738)\n",
            "Epoch: [159][140/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.010)\tLoss 0.3150 (0.2595)\tPrec@1 89.062 (91.373)\tPrec@5 99.219 (99.742)\n",
            "Epoch: [159][150/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.006 (0.010)\tLoss 0.2750 (0.2599)\tPrec@1 91.797 (91.404)\tPrec@5 100.000 (99.734)\n",
            "Epoch: [159][160/329], lr: 0.01000\tTime 0.088 (0.094)\tData 0.000 (0.009)\tLoss 0.2636 (0.2602)\tPrec@1 89.062 (91.348)\tPrec@5 100.000 (99.743)\n",
            "Epoch: [159][170/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.012 (0.009)\tLoss 0.3632 (0.2624)\tPrec@1 87.500 (91.271)\tPrec@5 99.609 (99.749)\n",
            "Epoch: [159][180/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.007 (0.009)\tLoss 0.2354 (0.2609)\tPrec@1 92.188 (91.322)\tPrec@5 100.000 (99.754)\n",
            "Epoch: [159][190/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.009)\tLoss 0.2346 (0.2601)\tPrec@1 91.797 (91.318)\tPrec@5 99.609 (99.748)\n",
            "Epoch: [159][200/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.007 (0.009)\tLoss 0.2336 (0.2594)\tPrec@1 90.234 (91.346)\tPrec@5 100.000 (99.747)\n",
            "Epoch: [159][210/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.000 (0.009)\tLoss 0.3301 (0.2593)\tPrec@1 89.844 (91.367)\tPrec@5 100.000 (99.745)\n",
            "Epoch: [159][220/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.006 (0.009)\tLoss 0.2337 (0.2592)\tPrec@1 91.016 (91.350)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [159][230/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.005 (0.009)\tLoss 0.2592 (0.2594)\tPrec@1 90.234 (91.342)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [159][240/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.002 (0.009)\tLoss 0.2871 (0.2593)\tPrec@1 90.625 (91.335)\tPrec@5 98.828 (99.734)\n",
            "Epoch: [159][250/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.000 (0.009)\tLoss 0.1632 (0.2580)\tPrec@1 94.922 (91.395)\tPrec@5 100.000 (99.737)\n",
            "Epoch: [159][260/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.005 (0.009)\tLoss 0.1963 (0.2565)\tPrec@1 92.969 (91.474)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [159][270/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.001 (0.009)\tLoss 0.2722 (0.2568)\tPrec@1 92.578 (91.493)\tPrec@5 99.219 (99.735)\n",
            "Epoch: [159][280/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.005 (0.009)\tLoss 0.3110 (0.2571)\tPrec@1 88.672 (91.479)\tPrec@5 99.219 (99.734)\n",
            "Epoch: [159][290/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.000 (0.009)\tLoss 0.3116 (0.2579)\tPrec@1 89.844 (91.449)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [159][300/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.005 (0.009)\tLoss 0.2258 (0.2579)\tPrec@1 92.188 (91.459)\tPrec@5 99.609 (99.734)\n",
            "Epoch: [159][310/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.006 (0.009)\tLoss 0.3242 (0.2573)\tPrec@1 89.453 (91.495)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [159][320/329], lr: 0.01000\tTime 0.116 (0.092)\tData 0.055 (0.009)\tLoss 0.2288 (0.2575)\tPrec@1 92.188 (91.495)\tPrec@5 100.000 (99.730)\n",
            "Test: [0/100]\tTime 0.350 (0.350)\tLoss 0.7456 (0.7456)\tPrec@1 80.000 (80.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.036 (0.059)\tLoss 0.7807 (0.8823)\tPrec@1 77.000 (74.455)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.034 (0.043)\tLoss 0.7739 (0.8649)\tPrec@1 77.000 (74.905)\tPrec@5 100.000 (98.429)\n",
            "Test: [30/100]\tTime 0.024 (0.037)\tLoss 1.0916 (0.9009)\tPrec@1 68.000 (74.226)\tPrec@5 99.000 (98.290)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 1.0162 (0.9192)\tPrec@1 76.000 (74.171)\tPrec@5 97.000 (98.220)\n",
            "Test: [50/100]\tTime 0.013 (0.032)\tLoss 1.0433 (0.9033)\tPrec@1 77.000 (74.745)\tPrec@5 98.000 (98.196)\n",
            "Test: [60/100]\tTime 0.010 (0.031)\tLoss 0.8202 (0.9173)\tPrec@1 75.000 (74.246)\tPrec@5 100.000 (98.230)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 0.8836 (0.9088)\tPrec@1 75.000 (74.211)\tPrec@5 99.000 (98.254)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 0.7866 (0.9020)\tPrec@1 77.000 (74.370)\tPrec@5 98.000 (98.284)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 0.7711 (0.9111)\tPrec@1 76.000 (74.176)\tPrec@5 100.000 (98.220)\n",
            "val Results: Prec@1 74.200 Prec@5 98.170 Loss 0.90596\n",
            "val Class Accuracy: [0.877,0.938,0.762,0.901,0.678,0.593,0.684,0.548,0.674,0.765]\n",
            "Best Prec@1: 78.750\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [160][0/329], lr: 0.00010\tTime 0.586 (0.586)\tData 0.501 (0.501)\tLoss 0.2342 (0.2342)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][10/329], lr: 0.00010\tTime 0.103 (0.137)\tData 0.009 (0.052)\tLoss 0.2018 (0.2500)\tPrec@1 91.797 (91.335)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [160][20/329], lr: 0.00010\tTime 0.088 (0.116)\tData 0.000 (0.028)\tLoss 0.2319 (0.2488)\tPrec@1 91.797 (91.592)\tPrec@5 99.609 (99.758)\n",
            "Epoch: [160][30/329], lr: 0.00010\tTime 0.094 (0.109)\tData 0.001 (0.020)\tLoss 0.2749 (0.2417)\tPrec@1 90.625 (91.822)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [160][40/329], lr: 0.00010\tTime 0.097 (0.104)\tData 0.005 (0.017)\tLoss 0.2080 (0.2398)\tPrec@1 92.969 (91.825)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [160][50/329], lr: 0.00010\tTime 0.095 (0.102)\tData 0.005 (0.015)\tLoss 0.1704 (0.2420)\tPrec@1 94.531 (91.896)\tPrec@5 99.609 (99.763)\n",
            "Epoch: [160][60/329], lr: 0.00010\tTime 0.120 (0.101)\tData 0.000 (0.013)\tLoss 0.2745 (0.2436)\tPrec@1 91.016 (91.778)\tPrec@5 99.609 (99.725)\n",
            "Epoch: [160][70/329], lr: 0.00010\tTime 0.099 (0.100)\tData 0.001 (0.012)\tLoss 0.3078 (0.2410)\tPrec@1 89.844 (91.901)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [160][80/329], lr: 0.00010\tTime 0.079 (0.099)\tData 0.000 (0.011)\tLoss 0.2761 (0.2394)\tPrec@1 91.016 (91.956)\tPrec@5 99.219 (99.749)\n",
            "Epoch: [160][90/329], lr: 0.00010\tTime 0.093 (0.098)\tData 0.000 (0.010)\tLoss 0.2620 (0.2378)\tPrec@1 91.406 (92.024)\tPrec@5 100.000 (99.768)\n",
            "Epoch: [160][100/329], lr: 0.00010\tTime 0.086 (0.097)\tData 0.006 (0.010)\tLoss 0.2002 (0.2364)\tPrec@1 93.359 (92.122)\tPrec@5 100.000 (99.780)\n",
            "Epoch: [160][110/329], lr: 0.00010\tTime 0.088 (0.097)\tData 0.008 (0.010)\tLoss 0.2246 (0.2351)\tPrec@1 91.406 (92.121)\tPrec@5 100.000 (99.789)\n",
            "Epoch: [160][120/329], lr: 0.00010\tTime 0.084 (0.096)\tData 0.000 (0.010)\tLoss 0.2121 (0.2347)\tPrec@1 92.188 (92.065)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [160][130/329], lr: 0.00010\tTime 0.088 (0.096)\tData 0.000 (0.009)\tLoss 0.2706 (0.2356)\tPrec@1 88.672 (92.050)\tPrec@5 100.000 (99.791)\n",
            "Epoch: [160][140/329], lr: 0.00010\tTime 0.090 (0.095)\tData 0.000 (0.009)\tLoss 0.2386 (0.2345)\tPrec@1 92.578 (92.052)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [160][150/329], lr: 0.00010\tTime 0.075 (0.095)\tData 0.000 (0.009)\tLoss 0.3178 (0.2339)\tPrec@1 91.406 (92.102)\tPrec@5 100.000 (99.796)\n",
            "Epoch: [160][160/329], lr: 0.00010\tTime 0.080 (0.094)\tData 0.000 (0.009)\tLoss 0.2510 (0.2343)\tPrec@1 91.406 (92.095)\tPrec@5 100.000 (99.796)\n",
            "Epoch: [160][170/329], lr: 0.00010\tTime 0.098 (0.094)\tData 0.000 (0.009)\tLoss 0.1622 (0.2341)\tPrec@1 94.531 (92.105)\tPrec@5 99.219 (99.792)\n",
            "Epoch: [160][180/329], lr: 0.00010\tTime 0.097 (0.094)\tData 0.007 (0.009)\tLoss 0.2523 (0.2335)\tPrec@1 90.234 (92.118)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [160][190/329], lr: 0.00010\tTime 0.082 (0.093)\tData 0.006 (0.009)\tLoss 0.2653 (0.2334)\tPrec@1 92.969 (92.108)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [160][200/329], lr: 0.00010\tTime 0.085 (0.093)\tData 0.000 (0.009)\tLoss 0.1744 (0.2326)\tPrec@1 94.141 (92.135)\tPrec@5 100.000 (99.792)\n",
            "Epoch: [160][210/329], lr: 0.00010\tTime 0.095 (0.093)\tData 0.001 (0.009)\tLoss 0.2134 (0.2314)\tPrec@1 93.750 (92.188)\tPrec@5 100.000 (99.793)\n",
            "Epoch: [160][220/329], lr: 0.00010\tTime 0.075 (0.093)\tData 0.006 (0.008)\tLoss 0.1883 (0.2315)\tPrec@1 92.188 (92.184)\tPrec@5 100.000 (99.791)\n",
            "Epoch: [160][230/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.000 (0.008)\tLoss 0.2449 (0.2305)\tPrec@1 92.969 (92.218)\tPrec@5 100.000 (99.794)\n",
            "Epoch: [160][240/329], lr: 0.00010\tTime 0.097 (0.092)\tData 0.001 (0.008)\tLoss 0.3190 (0.2312)\tPrec@1 91.016 (92.183)\tPrec@5 99.609 (99.791)\n",
            "Epoch: [160][250/329], lr: 0.00010\tTime 0.068 (0.092)\tData 0.000 (0.008)\tLoss 0.1681 (0.2304)\tPrec@1 94.141 (92.208)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [160][260/329], lr: 0.00010\tTime 0.106 (0.092)\tData 0.000 (0.008)\tLoss 0.2413 (0.2300)\tPrec@1 91.406 (92.213)\tPrec@5 99.609 (99.790)\n",
            "Epoch: [160][270/329], lr: 0.00010\tTime 0.092 (0.092)\tData 0.000 (0.008)\tLoss 0.1887 (0.2299)\tPrec@1 93.750 (92.226)\tPrec@5 99.609 (99.785)\n",
            "Epoch: [160][280/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.007 (0.008)\tLoss 0.2711 (0.2293)\tPrec@1 91.797 (92.265)\tPrec@5 99.219 (99.786)\n",
            "Epoch: [160][290/329], lr: 0.00010\tTime 0.094 (0.092)\tData 0.005 (0.008)\tLoss 0.2136 (0.2289)\tPrec@1 92.578 (92.299)\tPrec@5 100.000 (99.785)\n",
            "Epoch: [160][300/329], lr: 0.00010\tTime 0.088 (0.091)\tData 0.007 (0.008)\tLoss 0.2636 (0.2283)\tPrec@1 91.016 (92.320)\tPrec@5 99.609 (99.788)\n",
            "Epoch: [160][310/329], lr: 0.00010\tTime 0.083 (0.091)\tData 0.007 (0.008)\tLoss 0.2423 (0.2281)\tPrec@1 93.750 (92.348)\tPrec@5 99.609 (99.793)\n",
            "Epoch: [160][320/329], lr: 0.00010\tTime 0.108 (0.091)\tData 0.069 (0.008)\tLoss 0.2263 (0.2285)\tPrec@1 92.969 (92.337)\tPrec@5 99.609 (99.788)\n",
            "Test: [0/100]\tTime 0.386 (0.386)\tLoss 0.5351 (0.5351)\tPrec@1 82.000 (82.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.058)\tLoss 0.5195 (0.6530)\tPrec@1 82.000 (80.364)\tPrec@5 99.000 (99.364)\n",
            "Test: [20/100]\tTime 0.026 (0.042)\tLoss 0.6127 (0.6578)\tPrec@1 82.000 (80.333)\tPrec@5 100.000 (98.952)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 0.7622 (0.6768)\tPrec@1 77.000 (80.000)\tPrec@5 99.000 (98.839)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 0.7096 (0.6796)\tPrec@1 79.000 (79.902)\tPrec@5 98.000 (98.756)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6356 (0.6742)\tPrec@1 89.000 (80.098)\tPrec@5 98.000 (98.725)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 0.5071 (0.6780)\tPrec@1 84.000 (79.590)\tPrec@5 100.000 (98.754)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 0.7435 (0.6739)\tPrec@1 81.000 (79.521)\tPrec@5 99.000 (98.775)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 0.5771 (0.6670)\tPrec@1 85.000 (79.691)\tPrec@5 98.000 (98.802)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 0.5601 (0.6759)\tPrec@1 84.000 (79.451)\tPrec@5 100.000 (98.758)\n",
            "val Results: Prec@1 79.340 Prec@5 98.770 Loss 0.67612\n",
            "val Class Accuracy: [0.958,0.973,0.847,0.709,0.825,0.761,0.807,0.702,0.630,0.722]\n",
            "Best Prec@1: 79.340\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [161][0/329], lr: 0.00010\tTime 0.696 (0.696)\tData 0.603 (0.603)\tLoss 0.2552 (0.2552)\tPrec@1 90.625 (90.625)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [161][10/329], lr: 0.00010\tTime 0.098 (0.150)\tData 0.000 (0.060)\tLoss 0.1840 (0.2343)\tPrec@1 93.359 (92.223)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [161][20/329], lr: 0.00010\tTime 0.098 (0.125)\tData 0.010 (0.034)\tLoss 0.1939 (0.2234)\tPrec@1 94.531 (92.522)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [161][30/329], lr: 0.00010\tTime 0.083 (0.115)\tData 0.007 (0.026)\tLoss 0.1918 (0.2210)\tPrec@1 92.578 (92.427)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [161][40/329], lr: 0.00010\tTime 0.098 (0.108)\tData 0.000 (0.021)\tLoss 0.1678 (0.2179)\tPrec@1 94.141 (92.550)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [161][50/329], lr: 0.00010\tTime 0.069 (0.104)\tData 0.000 (0.018)\tLoss 0.2884 (0.2165)\tPrec@1 90.234 (92.685)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [161][60/329], lr: 0.00010\tTime 0.077 (0.102)\tData 0.005 (0.016)\tLoss 0.1669 (0.2155)\tPrec@1 94.922 (92.693)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [161][70/329], lr: 0.00010\tTime 0.105 (0.100)\tData 0.012 (0.015)\tLoss 0.2165 (0.2156)\tPrec@1 93.750 (92.655)\tPrec@5 98.828 (99.818)\n",
            "Epoch: [161][80/329], lr: 0.00010\tTime 0.088 (0.099)\tData 0.000 (0.013)\tLoss 0.1662 (0.2132)\tPrec@1 92.578 (92.752)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [161][90/329], lr: 0.00010\tTime 0.115 (0.100)\tData 0.000 (0.013)\tLoss 0.2117 (0.2135)\tPrec@1 91.406 (92.750)\tPrec@5 99.609 (99.820)\n",
            "Epoch: [161][100/329], lr: 0.00010\tTime 0.151 (0.102)\tData 0.000 (0.012)\tLoss 0.2134 (0.2145)\tPrec@1 92.578 (92.702)\tPrec@5 99.219 (99.810)\n",
            "Epoch: [161][110/329], lr: 0.00010\tTime 0.128 (0.103)\tData 0.005 (0.012)\tLoss 0.2337 (0.2158)\tPrec@1 91.406 (92.705)\tPrec@5 99.609 (99.810)\n",
            "Epoch: [161][120/329], lr: 0.00010\tTime 0.098 (0.102)\tData 0.001 (0.011)\tLoss 0.3236 (0.2162)\tPrec@1 89.844 (92.685)\tPrec@5 99.219 (99.813)\n",
            "Epoch: [161][130/329], lr: 0.00010\tTime 0.067 (0.102)\tData 0.000 (0.011)\tLoss 0.2215 (0.2154)\tPrec@1 93.750 (92.703)\tPrec@5 99.219 (99.815)\n",
            "Epoch: [161][140/329], lr: 0.00010\tTime 0.085 (0.101)\tData 0.000 (0.011)\tLoss 0.2084 (0.2144)\tPrec@1 92.578 (92.694)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [161][150/329], lr: 0.00010\tTime 0.087 (0.101)\tData 0.000 (0.010)\tLoss 0.1698 (0.2129)\tPrec@1 94.531 (92.762)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [161][160/329], lr: 0.00010\tTime 0.069 (0.100)\tData 0.000 (0.010)\tLoss 0.1769 (0.2121)\tPrec@1 94.531 (92.811)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [161][170/329], lr: 0.00010\tTime 0.096 (0.099)\tData 0.000 (0.010)\tLoss 0.1873 (0.2119)\tPrec@1 93.750 (92.825)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [161][180/329], lr: 0.00010\tTime 0.090 (0.099)\tData 0.006 (0.010)\tLoss 0.1784 (0.2112)\tPrec@1 94.141 (92.835)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [161][190/329], lr: 0.00010\tTime 0.085 (0.098)\tData 0.007 (0.010)\tLoss 0.2067 (0.2108)\tPrec@1 92.188 (92.838)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [161][200/329], lr: 0.00010\tTime 0.085 (0.098)\tData 0.003 (0.010)\tLoss 0.2261 (0.2097)\tPrec@1 93.359 (92.868)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [161][210/329], lr: 0.00010\tTime 0.078 (0.097)\tData 0.005 (0.009)\tLoss 0.1829 (0.2103)\tPrec@1 94.141 (92.845)\tPrec@5 99.609 (99.839)\n",
            "Epoch: [161][220/329], lr: 0.00010\tTime 0.089 (0.097)\tData 0.004 (0.009)\tLoss 0.1547 (0.2103)\tPrec@1 95.312 (92.864)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [161][230/329], lr: 0.00010\tTime 0.082 (0.096)\tData 0.007 (0.009)\tLoss 0.3004 (0.2109)\tPrec@1 92.188 (92.862)\tPrec@5 98.828 (99.831)\n",
            "Epoch: [161][240/329], lr: 0.00010\tTime 0.093 (0.096)\tData 0.000 (0.009)\tLoss 0.1713 (0.2111)\tPrec@1 94.141 (92.872)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [161][250/329], lr: 0.00010\tTime 0.099 (0.096)\tData 0.005 (0.009)\tLoss 0.2100 (0.2106)\tPrec@1 91.797 (92.883)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [161][260/329], lr: 0.00010\tTime 0.104 (0.096)\tData 0.011 (0.009)\tLoss 0.2211 (0.2108)\tPrec@1 92.969 (92.882)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [161][270/329], lr: 0.00010\tTime 0.086 (0.095)\tData 0.000 (0.009)\tLoss 0.2182 (0.2117)\tPrec@1 93.359 (92.861)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [161][280/329], lr: 0.00010\tTime 0.086 (0.095)\tData 0.004 (0.009)\tLoss 0.1594 (0.2118)\tPrec@1 94.141 (92.852)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [161][290/329], lr: 0.00010\tTime 0.084 (0.095)\tData 0.004 (0.009)\tLoss 0.2221 (0.2114)\tPrec@1 93.359 (92.875)\tPrec@5 99.609 (99.817)\n",
            "Epoch: [161][300/329], lr: 0.00010\tTime 0.094 (0.095)\tData 0.009 (0.009)\tLoss 0.2104 (0.2120)\tPrec@1 93.750 (92.864)\tPrec@5 99.609 (99.811)\n",
            "Epoch: [161][310/329], lr: 0.00010\tTime 0.080 (0.094)\tData 0.000 (0.009)\tLoss 0.2268 (0.2124)\tPrec@1 91.406 (92.837)\tPrec@5 100.000 (99.808)\n",
            "Epoch: [161][320/329], lr: 0.00010\tTime 0.118 (0.094)\tData 0.062 (0.009)\tLoss 0.2375 (0.2126)\tPrec@1 91.406 (92.841)\tPrec@5 100.000 (99.807)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 0.5067 (0.5067)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.030 (0.056)\tLoss 0.5164 (0.6447)\tPrec@1 84.000 (80.636)\tPrec@5 99.000 (99.455)\n",
            "Test: [20/100]\tTime 0.010 (0.042)\tLoss 0.6398 (0.6463)\tPrec@1 81.000 (80.476)\tPrec@5 100.000 (98.810)\n",
            "Test: [30/100]\tTime 0.016 (0.035)\tLoss 0.8085 (0.6666)\tPrec@1 77.000 (80.161)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.011 (0.033)\tLoss 0.6813 (0.6711)\tPrec@1 81.000 (80.171)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.049 (0.031)\tLoss 0.6535 (0.6652)\tPrec@1 87.000 (80.431)\tPrec@5 98.000 (98.608)\n",
            "Test: [60/100]\tTime 0.029 (0.030)\tLoss 0.5304 (0.6684)\tPrec@1 84.000 (80.033)\tPrec@5 100.000 (98.656)\n",
            "Test: [70/100]\tTime 0.038 (0.029)\tLoss 0.7232 (0.6637)\tPrec@1 82.000 (80.099)\tPrec@5 99.000 (98.676)\n",
            "Test: [80/100]\tTime 0.012 (0.029)\tLoss 0.5498 (0.6564)\tPrec@1 86.000 (80.309)\tPrec@5 98.000 (98.728)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 0.5289 (0.6637)\tPrec@1 85.000 (80.055)\tPrec@5 100.000 (98.681)\n",
            "val Results: Prec@1 79.990 Prec@5 98.680 Loss 0.66148\n",
            "val Class Accuracy: [0.937,0.986,0.850,0.757,0.812,0.769,0.815,0.655,0.674,0.744]\n",
            "Best Prec@1: 79.990\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [162][0/329], lr: 0.00010\tTime 0.699 (0.699)\tData 0.616 (0.616)\tLoss 0.2039 (0.2039)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][10/329], lr: 0.00010\tTime 0.082 (0.155)\tData 0.005 (0.062)\tLoss 0.2213 (0.2028)\tPrec@1 93.359 (92.720)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [162][20/329], lr: 0.00010\tTime 0.093 (0.124)\tData 0.005 (0.037)\tLoss 0.1957 (0.1991)\tPrec@1 94.141 (93.043)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [162][30/329], lr: 0.00010\tTime 0.094 (0.112)\tData 0.000 (0.027)\tLoss 0.1526 (0.1973)\tPrec@1 95.312 (93.183)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [162][40/329], lr: 0.00010\tTime 0.091 (0.106)\tData 0.005 (0.022)\tLoss 0.2018 (0.2012)\tPrec@1 94.141 (93.131)\tPrec@5 99.219 (99.857)\n",
            "Epoch: [162][50/329], lr: 0.00010\tTime 0.108 (0.103)\tData 0.008 (0.019)\tLoss 0.2223 (0.2047)\tPrec@1 92.578 (93.061)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [162][60/329], lr: 0.00010\tTime 0.083 (0.101)\tData 0.000 (0.017)\tLoss 0.1686 (0.2093)\tPrec@1 96.094 (92.962)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [162][70/329], lr: 0.00010\tTime 0.101 (0.099)\tData 0.000 (0.015)\tLoss 0.2158 (0.2082)\tPrec@1 92.188 (93.007)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [162][80/329], lr: 0.00010\tTime 0.090 (0.098)\tData 0.000 (0.014)\tLoss 0.2169 (0.2095)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [162][90/329], lr: 0.00010\tTime 0.077 (0.097)\tData 0.007 (0.013)\tLoss 0.1960 (0.2089)\tPrec@1 93.359 (92.973)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [162][100/329], lr: 0.00010\tTime 0.097 (0.096)\tData 0.007 (0.013)\tLoss 0.1836 (0.2064)\tPrec@1 94.531 (93.054)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [162][110/329], lr: 0.00010\tTime 0.088 (0.095)\tData 0.005 (0.012)\tLoss 0.2630 (0.2059)\tPrec@1 91.797 (93.092)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [162][120/329], lr: 0.00010\tTime 0.084 (0.095)\tData 0.006 (0.012)\tLoss 0.1795 (0.2070)\tPrec@1 94.141 (93.066)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [162][130/329], lr: 0.00010\tTime 0.079 (0.094)\tData 0.000 (0.012)\tLoss 0.1720 (0.2064)\tPrec@1 94.531 (93.118)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [162][140/329], lr: 0.00010\tTime 0.091 (0.094)\tData 0.005 (0.011)\tLoss 0.2526 (0.2074)\tPrec@1 92.188 (93.055)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [162][150/329], lr: 0.00010\tTime 0.086 (0.094)\tData 0.011 (0.011)\tLoss 0.2604 (0.2098)\tPrec@1 92.188 (92.969)\tPrec@5 99.219 (99.824)\n",
            "Epoch: [162][160/329], lr: 0.00010\tTime 0.075 (0.093)\tData 0.000 (0.011)\tLoss 0.2130 (0.2094)\tPrec@1 94.922 (93.012)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [162][170/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.005 (0.011)\tLoss 0.2042 (0.2095)\tPrec@1 93.750 (93.037)\tPrec@5 99.609 (99.820)\n",
            "Epoch: [162][180/329], lr: 0.00010\tTime 0.096 (0.093)\tData 0.000 (0.010)\tLoss 0.2502 (0.2095)\tPrec@1 90.234 (93.027)\tPrec@5 99.219 (99.819)\n",
            "Epoch: [162][190/329], lr: 0.00010\tTime 0.085 (0.093)\tData 0.009 (0.010)\tLoss 0.1817 (0.2085)\tPrec@1 94.922 (93.061)\tPrec@5 99.609 (99.816)\n",
            "Epoch: [162][200/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.000 (0.010)\tLoss 0.2044 (0.2080)\tPrec@1 93.750 (93.091)\tPrec@5 99.609 (99.810)\n",
            "Epoch: [162][210/329], lr: 0.00010\tTime 0.091 (0.092)\tData 0.000 (0.010)\tLoss 0.1945 (0.2083)\tPrec@1 94.531 (93.095)\tPrec@5 99.609 (99.809)\n",
            "Epoch: [162][220/329], lr: 0.00010\tTime 0.088 (0.092)\tData 0.006 (0.010)\tLoss 0.2092 (0.2081)\tPrec@1 92.969 (93.092)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [162][230/329], lr: 0.00010\tTime 0.091 (0.092)\tData 0.008 (0.010)\tLoss 0.2398 (0.2084)\tPrec@1 91.016 (93.079)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [162][240/329], lr: 0.00010\tTime 0.091 (0.092)\tData 0.005 (0.010)\tLoss 0.2186 (0.2078)\tPrec@1 91.797 (93.095)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [162][250/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 0.2471 (0.2088)\tPrec@1 90.625 (93.048)\tPrec@5 100.000 (99.815)\n",
            "Epoch: [162][260/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.000 (0.009)\tLoss 0.1906 (0.2089)\tPrec@1 92.188 (93.056)\tPrec@5 100.000 (99.808)\n",
            "Epoch: [162][270/329], lr: 0.00010\tTime 0.082 (0.091)\tData 0.007 (0.009)\tLoss 0.1838 (0.2089)\tPrec@1 94.141 (93.049)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [162][280/329], lr: 0.00010\tTime 0.096 (0.091)\tData 0.000 (0.009)\tLoss 0.1631 (0.2086)\tPrec@1 95.312 (93.061)\tPrec@5 100.000 (99.812)\n",
            "Epoch: [162][290/329], lr: 0.00010\tTime 0.068 (0.091)\tData 0.000 (0.009)\tLoss 0.2026 (0.2085)\tPrec@1 94.141 (93.061)\tPrec@5 100.000 (99.808)\n",
            "Epoch: [162][300/329], lr: 0.00010\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.2058 (0.2085)\tPrec@1 92.188 (93.063)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [162][310/329], lr: 0.00010\tTime 0.087 (0.091)\tData 0.000 (0.009)\tLoss 0.2561 (0.2087)\tPrec@1 91.406 (93.055)\tPrec@5 99.609 (99.812)\n",
            "Epoch: [162][320/329], lr: 0.00010\tTime 0.107 (0.091)\tData 0.068 (0.009)\tLoss 0.1916 (0.2084)\tPrec@1 93.359 (93.069)\tPrec@5 100.000 (99.815)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.5064 (0.5064)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.033 (0.060)\tLoss 0.5442 (0.6568)\tPrec@1 83.000 (80.364)\tPrec@5 97.000 (99.364)\n",
            "Test: [20/100]\tTime 0.010 (0.043)\tLoss 0.5846 (0.6650)\tPrec@1 80.000 (79.714)\tPrec@5 100.000 (98.857)\n",
            "Test: [30/100]\tTime 0.019 (0.037)\tLoss 0.7674 (0.6829)\tPrec@1 78.000 (79.677)\tPrec@5 99.000 (98.742)\n",
            "Test: [40/100]\tTime 0.019 (0.035)\tLoss 0.7104 (0.6893)\tPrec@1 82.000 (79.732)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.012 (0.032)\tLoss 0.6749 (0.6840)\tPrec@1 85.000 (79.922)\tPrec@5 98.000 (98.706)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 0.5193 (0.6887)\tPrec@1 86.000 (79.311)\tPrec@5 100.000 (98.738)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 0.7569 (0.6826)\tPrec@1 79.000 (79.268)\tPrec@5 99.000 (98.803)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 0.5976 (0.6765)\tPrec@1 84.000 (79.383)\tPrec@5 98.000 (98.840)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 0.5641 (0.6842)\tPrec@1 83.000 (79.220)\tPrec@5 100.000 (98.824)\n",
            "val Results: Prec@1 79.190 Prec@5 98.810 Loss 0.68312\n",
            "val Class Accuracy: [0.967,0.978,0.826,0.797,0.781,0.720,0.773,0.675,0.690,0.712]\n",
            "Best Prec@1: 79.990\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [163][0/329], lr: 0.00010\tTime 0.739 (0.739)\tData 0.680 (0.680)\tLoss 0.1845 (0.1845)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][10/329], lr: 0.00010\tTime 0.111 (0.158)\tData 0.009 (0.070)\tLoss 0.2930 (0.2041)\tPrec@1 88.672 (92.969)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [163][20/329], lr: 0.00010\tTime 0.103 (0.125)\tData 0.000 (0.040)\tLoss 0.1911 (0.2022)\tPrec@1 94.141 (93.192)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [163][30/329], lr: 0.00010\tTime 0.062 (0.113)\tData 0.000 (0.029)\tLoss 0.1642 (0.1993)\tPrec@1 94.531 (93.359)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [163][40/329], lr: 0.00010\tTime 0.080 (0.108)\tData 0.005 (0.024)\tLoss 0.2254 (0.2028)\tPrec@1 94.141 (93.150)\tPrec@5 99.219 (99.790)\n",
            "Epoch: [163][50/329], lr: 0.00010\tTime 0.086 (0.104)\tData 0.006 (0.020)\tLoss 0.2717 (0.2009)\tPrec@1 89.453 (93.222)\tPrec@5 99.219 (99.770)\n",
            "Epoch: [163][60/329], lr: 0.00010\tTime 0.087 (0.101)\tData 0.007 (0.018)\tLoss 0.2223 (0.2049)\tPrec@1 93.359 (93.116)\tPrec@5 99.219 (99.782)\n",
            "Epoch: [163][70/329], lr: 0.00010\tTime 0.069 (0.099)\tData 0.000 (0.016)\tLoss 0.1528 (0.2035)\tPrec@1 95.703 (93.255)\tPrec@5 100.000 (99.774)\n",
            "Epoch: [163][80/329], lr: 0.00010\tTime 0.085 (0.099)\tData 0.007 (0.015)\tLoss 0.2543 (0.2025)\tPrec@1 90.625 (93.258)\tPrec@5 99.609 (99.773)\n",
            "Epoch: [163][90/329], lr: 0.00010\tTime 0.083 (0.097)\tData 0.000 (0.015)\tLoss 0.2049 (0.2042)\tPrec@1 92.969 (93.231)\tPrec@5 99.609 (99.768)\n",
            "Epoch: [163][100/329], lr: 0.00010\tTime 0.100 (0.097)\tData 0.000 (0.014)\tLoss 0.1230 (0.2042)\tPrec@1 94.922 (93.228)\tPrec@5 100.000 (99.776)\n",
            "Epoch: [163][110/329], lr: 0.00010\tTime 0.102 (0.096)\tData 0.007 (0.014)\tLoss 0.2805 (0.2041)\tPrec@1 90.625 (93.229)\tPrec@5 100.000 (99.782)\n",
            "Epoch: [163][120/329], lr: 0.00010\tTime 0.091 (0.095)\tData 0.006 (0.013)\tLoss 0.3034 (0.2047)\tPrec@1 89.453 (93.195)\tPrec@5 100.000 (99.793)\n",
            "Epoch: [163][130/329], lr: 0.00010\tTime 0.089 (0.095)\tData 0.000 (0.012)\tLoss 0.2511 (0.2064)\tPrec@1 91.406 (93.160)\tPrec@5 99.609 (99.794)\n",
            "Epoch: [163][140/329], lr: 0.00010\tTime 0.092 (0.094)\tData 0.007 (0.012)\tLoss 0.1527 (0.2050)\tPrec@1 94.922 (93.196)\tPrec@5 99.609 (99.803)\n",
            "Epoch: [163][150/329], lr: 0.00010\tTime 0.083 (0.094)\tData 0.000 (0.012)\tLoss 0.1942 (0.2045)\tPrec@1 91.797 (93.186)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [163][160/329], lr: 0.00010\tTime 0.070 (0.094)\tData 0.000 (0.011)\tLoss 0.2123 (0.2046)\tPrec@1 93.359 (93.177)\tPrec@5 99.609 (99.796)\n",
            "Epoch: [163][170/329], lr: 0.00010\tTime 0.090 (0.094)\tData 0.012 (0.011)\tLoss 0.1919 (0.2048)\tPrec@1 94.531 (93.183)\tPrec@5 100.000 (99.785)\n",
            "Epoch: [163][180/329], lr: 0.00010\tTime 0.096 (0.093)\tData 0.000 (0.011)\tLoss 0.2335 (0.2051)\tPrec@1 91.406 (93.174)\tPrec@5 99.219 (99.780)\n",
            "Epoch: [163][190/329], lr: 0.00010\tTime 0.099 (0.093)\tData 0.012 (0.011)\tLoss 0.1755 (0.2045)\tPrec@1 93.750 (93.200)\tPrec@5 99.609 (99.775)\n",
            "Epoch: [163][200/329], lr: 0.00010\tTime 0.110 (0.093)\tData 0.009 (0.011)\tLoss 0.1911 (0.2041)\tPrec@1 92.578 (93.210)\tPrec@5 100.000 (99.778)\n",
            "Epoch: [163][210/329], lr: 0.00010\tTime 0.088 (0.093)\tData 0.000 (0.011)\tLoss 0.2126 (0.2053)\tPrec@1 92.578 (93.167)\tPrec@5 99.609 (99.783)\n",
            "Epoch: [163][220/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.1683 (0.2056)\tPrec@1 93.359 (93.147)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [163][230/329], lr: 0.00010\tTime 0.083 (0.093)\tData 0.004 (0.010)\tLoss 0.2293 (0.2053)\tPrec@1 93.750 (93.158)\tPrec@5 100.000 (99.792)\n",
            "Epoch: [163][240/329], lr: 0.00010\tTime 0.080 (0.092)\tData 0.000 (0.010)\tLoss 0.2362 (0.2055)\tPrec@1 92.969 (93.186)\tPrec@5 100.000 (99.797)\n",
            "Epoch: [163][250/329], lr: 0.00010\tTime 0.084 (0.092)\tData 0.007 (0.010)\tLoss 0.2089 (0.2056)\tPrec@1 93.359 (93.173)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [163][260/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.1708 (0.2059)\tPrec@1 94.531 (93.145)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [163][270/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.011 (0.010)\tLoss 0.1845 (0.2056)\tPrec@1 94.531 (93.152)\tPrec@5 100.000 (99.797)\n",
            "Epoch: [163][280/329], lr: 0.00010\tTime 0.089 (0.092)\tData 0.007 (0.010)\tLoss 0.1461 (0.2051)\tPrec@1 96.094 (93.181)\tPrec@5 100.000 (99.796)\n",
            "Epoch: [163][290/329], lr: 0.00010\tTime 0.081 (0.092)\tData 0.006 (0.010)\tLoss 0.2685 (0.2053)\tPrec@1 92.578 (93.173)\tPrec@5 99.609 (99.795)\n",
            "Epoch: [163][300/329], lr: 0.00010\tTime 0.072 (0.092)\tData 0.008 (0.010)\tLoss 0.1993 (0.2049)\tPrec@1 93.750 (93.192)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [163][310/329], lr: 0.00010\tTime 0.103 (0.091)\tData 0.005 (0.009)\tLoss 0.2072 (0.2043)\tPrec@1 92.578 (93.201)\tPrec@5 99.609 (99.797)\n",
            "Epoch: [163][320/329], lr: 0.00010\tTime 0.113 (0.091)\tData 0.079 (0.010)\tLoss 0.2037 (0.2055)\tPrec@1 92.969 (93.154)\tPrec@5 100.000 (99.797)\n",
            "Test: [0/100]\tTime 0.394 (0.394)\tLoss 0.4956 (0.4956)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.054 (0.063)\tLoss 0.5164 (0.6519)\tPrec@1 83.000 (80.727)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 0.6306 (0.6513)\tPrec@1 79.000 (80.571)\tPrec@5 100.000 (98.905)\n",
            "Test: [30/100]\tTime 0.023 (0.036)\tLoss 0.7683 (0.6681)\tPrec@1 78.000 (80.097)\tPrec@5 99.000 (98.806)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 0.7043 (0.6721)\tPrec@1 79.000 (79.951)\tPrec@5 98.000 (98.732)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6620 (0.6675)\tPrec@1 85.000 (80.059)\tPrec@5 98.000 (98.706)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 0.5079 (0.6691)\tPrec@1 88.000 (79.803)\tPrec@5 100.000 (98.738)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 0.7344 (0.6645)\tPrec@1 82.000 (79.901)\tPrec@5 99.000 (98.775)\n",
            "Test: [80/100]\tTime 0.023 (0.030)\tLoss 0.5334 (0.6575)\tPrec@1 88.000 (80.198)\tPrec@5 98.000 (98.827)\n",
            "Test: [90/100]\tTime 0.016 (0.029)\tLoss 0.5322 (0.6666)\tPrec@1 86.000 (79.912)\tPrec@5 100.000 (98.813)\n",
            "val Results: Prec@1 79.920 Prec@5 98.800 Loss 0.66513\n",
            "val Class Accuracy: [0.944,0.990,0.868,0.676,0.825,0.798,0.808,0.674,0.712,0.697]\n",
            "Best Prec@1: 79.990\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [164][0/329], lr: 0.00010\tTime 0.644 (0.644)\tData 0.560 (0.560)\tLoss 0.1837 (0.1837)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [164][10/329], lr: 0.00010\tTime 0.100 (0.152)\tData 0.000 (0.059)\tLoss 0.2344 (0.1919)\tPrec@1 91.406 (93.359)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [164][20/329], lr: 0.00010\tTime 0.088 (0.123)\tData 0.000 (0.036)\tLoss 0.1981 (0.1913)\tPrec@1 94.141 (93.564)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [164][30/329], lr: 0.00010\tTime 0.080 (0.113)\tData 0.000 (0.027)\tLoss 0.2662 (0.2014)\tPrec@1 91.016 (93.196)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [164][40/329], lr: 0.00010\tTime 0.079 (0.107)\tData 0.000 (0.022)\tLoss 0.2207 (0.2027)\tPrec@1 92.969 (93.121)\tPrec@5 99.609 (99.819)\n",
            "Epoch: [164][50/329], lr: 0.00010\tTime 0.075 (0.103)\tData 0.005 (0.019)\tLoss 0.2153 (0.2022)\tPrec@1 92.188 (93.122)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [164][60/329], lr: 0.00010\tTime 0.097 (0.101)\tData 0.000 (0.017)\tLoss 0.1827 (0.2011)\tPrec@1 94.922 (93.193)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [164][70/329], lr: 0.00010\tTime 0.087 (0.100)\tData 0.000 (0.016)\tLoss 0.2035 (0.2016)\tPrec@1 92.578 (93.167)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [164][80/329], lr: 0.00010\tTime 0.088 (0.099)\tData 0.000 (0.015)\tLoss 0.1918 (0.2020)\tPrec@1 92.969 (93.162)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [164][90/329], lr: 0.00010\tTime 0.087 (0.097)\tData 0.005 (0.014)\tLoss 0.1184 (0.2009)\tPrec@1 96.875 (93.192)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [164][100/329], lr: 0.00010\tTime 0.096 (0.097)\tData 0.005 (0.013)\tLoss 0.1640 (0.2014)\tPrec@1 94.141 (93.205)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [164][110/329], lr: 0.00010\tTime 0.103 (0.096)\tData 0.003 (0.013)\tLoss 0.1526 (0.2007)\tPrec@1 94.531 (93.257)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [164][120/329], lr: 0.00010\tTime 0.094 (0.095)\tData 0.007 (0.013)\tLoss 0.1936 (0.2010)\tPrec@1 93.359 (93.256)\tPrec@5 99.219 (99.822)\n",
            "Epoch: [164][130/329], lr: 0.00010\tTime 0.091 (0.094)\tData 0.007 (0.012)\tLoss 0.1963 (0.2009)\tPrec@1 94.531 (93.270)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [164][140/329], lr: 0.00010\tTime 0.088 (0.094)\tData 0.008 (0.012)\tLoss 0.2628 (0.2016)\tPrec@1 90.625 (93.262)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [164][150/329], lr: 0.00010\tTime 0.077 (0.094)\tData 0.000 (0.011)\tLoss 0.1859 (0.2023)\tPrec@1 94.141 (93.230)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [164][160/329], lr: 0.00010\tTime 0.067 (0.093)\tData 0.002 (0.011)\tLoss 0.1865 (0.2015)\tPrec@1 93.359 (93.248)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [164][170/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.000 (0.011)\tLoss 0.2012 (0.2012)\tPrec@1 92.188 (93.275)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [164][180/329], lr: 0.00010\tTime 0.066 (0.093)\tData 0.000 (0.011)\tLoss 0.1418 (0.2005)\tPrec@1 94.922 (93.314)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [164][190/329], lr: 0.00010\tTime 0.087 (0.093)\tData 0.007 (0.010)\tLoss 0.1974 (0.2005)\tPrec@1 92.969 (93.314)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [164][200/329], lr: 0.00010\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.1859 (0.2003)\tPrec@1 95.312 (93.336)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [164][210/329], lr: 0.00010\tTime 0.082 (0.092)\tData 0.006 (0.010)\tLoss 0.1852 (0.2015)\tPrec@1 93.750 (93.282)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [164][220/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.1436 (0.2014)\tPrec@1 94.922 (93.287)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [164][230/329], lr: 0.00010\tTime 0.078 (0.092)\tData 0.000 (0.010)\tLoss 0.2605 (0.2010)\tPrec@1 92.188 (93.305)\tPrec@5 98.828 (99.834)\n",
            "Epoch: [164][240/329], lr: 0.00010\tTime 0.096 (0.092)\tData 0.005 (0.010)\tLoss 0.1523 (0.2016)\tPrec@1 95.312 (93.288)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [164][250/329], lr: 0.00010\tTime 0.081 (0.092)\tData 0.005 (0.010)\tLoss 0.2811 (0.2021)\tPrec@1 89.453 (93.261)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [164][260/329], lr: 0.00010\tTime 0.114 (0.092)\tData 0.005 (0.010)\tLoss 0.1896 (0.2027)\tPrec@1 94.922 (93.250)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [164][270/329], lr: 0.00010\tTime 0.067 (0.092)\tData 0.005 (0.010)\tLoss 0.1459 (0.2022)\tPrec@1 94.922 (93.271)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [164][280/329], lr: 0.00010\tTime 0.099 (0.092)\tData 0.012 (0.009)\tLoss 0.1817 (0.2019)\tPrec@1 92.969 (93.266)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [164][290/329], lr: 0.00010\tTime 0.089 (0.092)\tData 0.007 (0.009)\tLoss 0.1878 (0.2021)\tPrec@1 94.531 (93.259)\tPrec@5 99.219 (99.839)\n",
            "Epoch: [164][300/329], lr: 0.00010\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.1815 (0.2015)\tPrec@1 93.750 (93.274)\tPrec@5 99.609 (99.839)\n",
            "Epoch: [164][310/329], lr: 0.00010\tTime 0.082 (0.091)\tData 0.000 (0.009)\tLoss 0.2153 (0.2017)\tPrec@1 93.750 (93.251)\tPrec@5 99.219 (99.833)\n",
            "Epoch: [164][320/329], lr: 0.00010\tTime 0.089 (0.091)\tData 0.051 (0.009)\tLoss 0.1678 (0.2016)\tPrec@1 94.531 (93.264)\tPrec@5 100.000 (99.837)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 0.4974 (0.4974)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.058)\tLoss 0.5148 (0.6468)\tPrec@1 82.000 (80.364)\tPrec@5 98.000 (99.182)\n",
            "Test: [20/100]\tTime 0.029 (0.043)\tLoss 0.6048 (0.6463)\tPrec@1 84.000 (80.429)\tPrec@5 100.000 (98.905)\n",
            "Test: [30/100]\tTime 0.031 (0.036)\tLoss 0.7578 (0.6686)\tPrec@1 76.000 (80.194)\tPrec@5 99.000 (98.839)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 0.7188 (0.6749)\tPrec@1 80.000 (80.024)\tPrec@5 98.000 (98.780)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 0.6438 (0.6682)\tPrec@1 86.000 (80.196)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 0.5323 (0.6735)\tPrec@1 86.000 (79.607)\tPrec@5 100.000 (98.787)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 0.7341 (0.6669)\tPrec@1 81.000 (79.817)\tPrec@5 99.000 (98.831)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 0.5966 (0.6620)\tPrec@1 83.000 (79.901)\tPrec@5 99.000 (98.877)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 0.5898 (0.6699)\tPrec@1 80.000 (79.758)\tPrec@5 100.000 (98.846)\n",
            "val Results: Prec@1 79.610 Prec@5 98.840 Loss 0.66946\n",
            "val Class Accuracy: [0.964,0.967,0.790,0.806,0.853,0.703,0.826,0.659,0.688,0.705]\n",
            "Best Prec@1: 79.990\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [165][0/329], lr: 0.00010\tTime 0.744 (0.744)\tData 0.657 (0.657)\tLoss 0.2086 (0.2086)\tPrec@1 91.406 (91.406)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [165][10/329], lr: 0.00010\tTime 0.082 (0.151)\tData 0.000 (0.067)\tLoss 0.2516 (0.2088)\tPrec@1 91.406 (92.827)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [165][20/329], lr: 0.00010\tTime 0.085 (0.123)\tData 0.004 (0.038)\tLoss 0.2237 (0.2067)\tPrec@1 93.359 (92.969)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [165][30/329], lr: 0.00010\tTime 0.104 (0.113)\tData 0.000 (0.028)\tLoss 0.2341 (0.2055)\tPrec@1 92.578 (93.044)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [165][40/329], lr: 0.00010\tTime 0.121 (0.107)\tData 0.003 (0.022)\tLoss 0.2755 (0.2096)\tPrec@1 93.359 (92.950)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [165][50/329], lr: 0.00010\tTime 0.069 (0.103)\tData 0.000 (0.019)\tLoss 0.1395 (0.2076)\tPrec@1 94.141 (92.946)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [165][60/329], lr: 0.00010\tTime 0.110 (0.102)\tData 0.007 (0.017)\tLoss 0.2856 (0.2070)\tPrec@1 90.234 (93.071)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [165][70/329], lr: 0.00010\tTime 0.101 (0.100)\tData 0.005 (0.016)\tLoss 0.1748 (0.2062)\tPrec@1 93.750 (93.073)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [165][80/329], lr: 0.00010\tTime 0.082 (0.098)\tData 0.003 (0.015)\tLoss 0.1706 (0.2032)\tPrec@1 93.359 (93.186)\tPrec@5 100.000 (99.860)\n",
            "Epoch: [165][90/329], lr: 0.00010\tTime 0.087 (0.098)\tData 0.007 (0.014)\tLoss 0.1790 (0.2029)\tPrec@1 95.312 (93.218)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [165][100/329], lr: 0.00010\tTime 0.092 (0.097)\tData 0.000 (0.013)\tLoss 0.1799 (0.2028)\tPrec@1 93.359 (93.197)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [165][110/329], lr: 0.00010\tTime 0.081 (0.097)\tData 0.000 (0.013)\tLoss 0.1646 (0.2020)\tPrec@1 92.969 (93.194)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [165][120/329], lr: 0.00010\tTime 0.100 (0.096)\tData 0.007 (0.013)\tLoss 0.1910 (0.2023)\tPrec@1 93.750 (93.156)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [165][130/329], lr: 0.00010\tTime 0.090 (0.095)\tData 0.004 (0.012)\tLoss 0.1951 (0.2025)\tPrec@1 93.750 (93.174)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [165][140/329], lr: 0.00010\tTime 0.102 (0.095)\tData 0.013 (0.012)\tLoss 0.1918 (0.2026)\tPrec@1 92.969 (93.149)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [165][150/329], lr: 0.00010\tTime 0.077 (0.095)\tData 0.007 (0.011)\tLoss 0.1800 (0.2015)\tPrec@1 94.531 (93.189)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [165][160/329], lr: 0.00010\tTime 0.099 (0.095)\tData 0.004 (0.011)\tLoss 0.2310 (0.2020)\tPrec@1 91.797 (93.182)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [165][170/329], lr: 0.00010\tTime 0.128 (0.096)\tData 0.000 (0.011)\tLoss 0.2263 (0.2017)\tPrec@1 93.359 (93.209)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [165][180/329], lr: 0.00010\tTime 0.076 (0.097)\tData 0.000 (0.011)\tLoss 0.2029 (0.2015)\tPrec@1 92.969 (93.226)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [165][190/329], lr: 0.00010\tTime 0.091 (0.098)\tData 0.000 (0.012)\tLoss 0.1651 (0.2013)\tPrec@1 94.141 (93.253)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [165][200/329], lr: 0.00010\tTime 0.096 (0.097)\tData 0.009 (0.012)\tLoss 0.2330 (0.2014)\tPrec@1 92.969 (93.254)\tPrec@5 98.828 (99.835)\n",
            "Epoch: [165][210/329], lr: 0.00010\tTime 0.096 (0.097)\tData 0.000 (0.012)\tLoss 0.1904 (0.2013)\tPrec@1 92.969 (93.226)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [165][220/329], lr: 0.00010\tTime 0.095 (0.097)\tData 0.000 (0.011)\tLoss 0.2294 (0.2019)\tPrec@1 92.578 (93.227)\tPrec@5 99.609 (99.832)\n",
            "Epoch: [165][230/329], lr: 0.00010\tTime 0.088 (0.097)\tData 0.009 (0.011)\tLoss 0.1732 (0.2019)\tPrec@1 92.969 (93.214)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [165][240/329], lr: 0.00010\tTime 0.082 (0.096)\tData 0.000 (0.011)\tLoss 0.1827 (0.2024)\tPrec@1 95.312 (93.202)\tPrec@5 99.219 (99.828)\n",
            "Epoch: [165][250/329], lr: 0.00010\tTime 0.086 (0.096)\tData 0.000 (0.011)\tLoss 0.2343 (0.2025)\tPrec@1 92.578 (93.208)\tPrec@5 99.219 (99.823)\n",
            "Epoch: [165][260/329], lr: 0.00010\tTime 0.088 (0.096)\tData 0.005 (0.011)\tLoss 0.2253 (0.2024)\tPrec@1 90.625 (93.183)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [165][270/329], lr: 0.00010\tTime 0.081 (0.096)\tData 0.000 (0.011)\tLoss 0.1996 (0.2020)\tPrec@1 93.750 (93.211)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [165][280/329], lr: 0.00010\tTime 0.080 (0.095)\tData 0.009 (0.011)\tLoss 0.1840 (0.2009)\tPrec@1 94.141 (93.269)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [165][290/329], lr: 0.00010\tTime 0.105 (0.095)\tData 0.000 (0.011)\tLoss 0.2027 (0.2007)\tPrec@1 92.969 (93.284)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [165][300/329], lr: 0.00010\tTime 0.089 (0.095)\tData 0.012 (0.010)\tLoss 0.2216 (0.2006)\tPrec@1 92.578 (93.275)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [165][310/329], lr: 0.00010\tTime 0.085 (0.094)\tData 0.007 (0.010)\tLoss 0.1732 (0.2003)\tPrec@1 94.922 (93.290)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [165][320/329], lr: 0.00010\tTime 0.116 (0.094)\tData 0.077 (0.010)\tLoss 0.1755 (0.1999)\tPrec@1 92.969 (93.294)\tPrec@5 100.000 (99.825)\n",
            "Test: [0/100]\tTime 0.396 (0.396)\tLoss 0.4746 (0.4746)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.010 (0.056)\tLoss 0.5009 (0.6499)\tPrec@1 83.000 (81.364)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.038 (0.041)\tLoss 0.6038 (0.6564)\tPrec@1 82.000 (80.762)\tPrec@5 100.000 (98.905)\n",
            "Test: [30/100]\tTime 0.035 (0.036)\tLoss 0.7493 (0.6761)\tPrec@1 76.000 (80.419)\tPrec@5 99.000 (98.806)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 0.7144 (0.6817)\tPrec@1 80.000 (80.341)\tPrec@5 99.000 (98.707)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 0.6663 (0.6761)\tPrec@1 86.000 (80.451)\tPrec@5 98.000 (98.667)\n",
            "Test: [60/100]\tTime 0.016 (0.030)\tLoss 0.5202 (0.6796)\tPrec@1 85.000 (79.836)\tPrec@5 100.000 (98.705)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 0.7812 (0.6746)\tPrec@1 82.000 (80.014)\tPrec@5 99.000 (98.732)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 0.5619 (0.6685)\tPrec@1 86.000 (80.259)\tPrec@5 98.000 (98.765)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 0.5803 (0.6771)\tPrec@1 84.000 (80.044)\tPrec@5 100.000 (98.758)\n",
            "val Results: Prec@1 79.940 Prec@5 98.740 Loss 0.67640\n",
            "val Class Accuracy: [0.966,0.985,0.839,0.754,0.816,0.722,0.853,0.666,0.710,0.683]\n",
            "Best Prec@1: 79.990\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [166][0/329], lr: 0.00010\tTime 0.698 (0.698)\tData 0.624 (0.624)\tLoss 0.2150 (0.2150)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][10/329], lr: 0.00010\tTime 0.073 (0.155)\tData 0.000 (0.063)\tLoss 0.2216 (0.2075)\tPrec@1 92.969 (92.898)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [166][20/329], lr: 0.00010\tTime 0.076 (0.125)\tData 0.007 (0.037)\tLoss 0.1636 (0.2023)\tPrec@1 94.141 (93.118)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [166][30/329], lr: 0.00010\tTime 0.089 (0.112)\tData 0.006 (0.028)\tLoss 0.1755 (0.2005)\tPrec@1 95.703 (93.233)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [166][40/329], lr: 0.00010\tTime 0.087 (0.106)\tData 0.012 (0.023)\tLoss 0.1815 (0.1969)\tPrec@1 93.359 (93.397)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [166][50/329], lr: 0.00010\tTime 0.092 (0.103)\tData 0.000 (0.019)\tLoss 0.1941 (0.1964)\tPrec@1 94.531 (93.505)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [166][60/329], lr: 0.00010\tTime 0.093 (0.100)\tData 0.005 (0.017)\tLoss 0.2188 (0.1964)\tPrec@1 92.969 (93.513)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [166][70/329], lr: 0.00010\tTime 0.077 (0.099)\tData 0.001 (0.016)\tLoss 0.1886 (0.1955)\tPrec@1 93.750 (93.541)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [166][80/329], lr: 0.00010\tTime 0.088 (0.098)\tData 0.000 (0.015)\tLoss 0.1713 (0.1959)\tPrec@1 94.531 (93.475)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [166][90/329], lr: 0.00010\tTime 0.088 (0.097)\tData 0.007 (0.014)\tLoss 0.2919 (0.1968)\tPrec@1 90.625 (93.488)\tPrec@5 99.219 (99.845)\n",
            "Epoch: [166][100/329], lr: 0.00010\tTime 0.085 (0.096)\tData 0.005 (0.013)\tLoss 0.2070 (0.1974)\tPrec@1 91.016 (93.433)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [166][110/329], lr: 0.00010\tTime 0.090 (0.095)\tData 0.000 (0.013)\tLoss 0.1955 (0.1980)\tPrec@1 93.359 (93.388)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [166][120/329], lr: 0.00010\tTime 0.090 (0.095)\tData 0.006 (0.012)\tLoss 0.1326 (0.1965)\tPrec@1 94.922 (93.434)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [166][130/329], lr: 0.00010\tTime 0.082 (0.094)\tData 0.005 (0.012)\tLoss 0.2428 (0.1968)\tPrec@1 92.578 (93.425)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [166][140/329], lr: 0.00010\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 0.1347 (0.1961)\tPrec@1 95.312 (93.462)\tPrec@5 99.609 (99.817)\n",
            "Epoch: [166][150/329], lr: 0.00010\tTime 0.092 (0.093)\tData 0.000 (0.011)\tLoss 0.1978 (0.1963)\tPrec@1 94.141 (93.455)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [166][160/329], lr: 0.00010\tTime 0.061 (0.093)\tData 0.000 (0.011)\tLoss 0.2359 (0.1970)\tPrec@1 92.578 (93.425)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [166][170/329], lr: 0.00010\tTime 0.113 (0.093)\tData 0.007 (0.011)\tLoss 0.1667 (0.1957)\tPrec@1 94.922 (93.448)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [166][180/329], lr: 0.00010\tTime 0.088 (0.093)\tData 0.000 (0.010)\tLoss 0.3170 (0.1967)\tPrec@1 89.062 (93.409)\tPrec@5 99.609 (99.832)\n",
            "Epoch: [166][190/329], lr: 0.00010\tTime 0.100 (0.093)\tData 0.008 (0.010)\tLoss 0.1876 (0.1956)\tPrec@1 93.359 (93.441)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [166][200/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 0.3107 (0.1965)\tPrec@1 91.016 (93.418)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [166][210/329], lr: 0.00010\tTime 0.096 (0.093)\tData 0.007 (0.010)\tLoss 0.2347 (0.1972)\tPrec@1 91.016 (93.408)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [166][220/329], lr: 0.00010\tTime 0.099 (0.092)\tData 0.008 (0.010)\tLoss 0.1972 (0.1974)\tPrec@1 92.188 (93.398)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [166][230/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 0.2072 (0.1973)\tPrec@1 92.969 (93.415)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [166][240/329], lr: 0.00010\tTime 0.108 (0.092)\tData 0.007 (0.010)\tLoss 0.2125 (0.1979)\tPrec@1 92.969 (93.390)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [166][250/329], lr: 0.00010\tTime 0.093 (0.092)\tData 0.006 (0.009)\tLoss 0.2706 (0.1978)\tPrec@1 91.406 (93.414)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [166][260/329], lr: 0.00010\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.2469 (0.1985)\tPrec@1 91.406 (93.397)\tPrec@5 99.609 (99.844)\n",
            "Epoch: [166][270/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.005 (0.009)\tLoss 0.1956 (0.1987)\tPrec@1 92.969 (93.381)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [166][280/329], lr: 0.00010\tTime 0.083 (0.092)\tData 0.000 (0.009)\tLoss 0.1777 (0.1988)\tPrec@1 93.750 (93.361)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [166][290/329], lr: 0.00010\tTime 0.076 (0.092)\tData 0.000 (0.009)\tLoss 0.2668 (0.1987)\tPrec@1 91.797 (93.373)\tPrec@5 99.219 (99.839)\n",
            "Epoch: [166][300/329], lr: 0.00010\tTime 0.096 (0.092)\tData 0.007 (0.009)\tLoss 0.2141 (0.1991)\tPrec@1 92.578 (93.353)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [166][310/329], lr: 0.00010\tTime 0.091 (0.092)\tData 0.003 (0.009)\tLoss 0.1947 (0.1993)\tPrec@1 93.359 (93.351)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [166][320/329], lr: 0.00010\tTime 0.096 (0.092)\tData 0.067 (0.009)\tLoss 0.1611 (0.1987)\tPrec@1 94.531 (93.359)\tPrec@5 100.000 (99.828)\n",
            "Test: [0/100]\tTime 0.404 (0.404)\tLoss 0.4699 (0.4699)\tPrec@1 86.000 (86.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.032 (0.059)\tLoss 0.4915 (0.6327)\tPrec@1 85.000 (81.455)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.029 (0.043)\tLoss 0.6086 (0.6358)\tPrec@1 81.000 (81.048)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 0.7519 (0.6534)\tPrec@1 74.000 (80.645)\tPrec@5 99.000 (98.774)\n",
            "Test: [40/100]\tTime 0.013 (0.034)\tLoss 0.6955 (0.6582)\tPrec@1 80.000 (80.512)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 0.6398 (0.6517)\tPrec@1 85.000 (80.686)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 0.5163 (0.6568)\tPrec@1 87.000 (80.131)\tPrec@5 100.000 (98.803)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 0.7139 (0.6514)\tPrec@1 81.000 (80.141)\tPrec@5 99.000 (98.789)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 0.5822 (0.6452)\tPrec@1 84.000 (80.272)\tPrec@5 99.000 (98.827)\n",
            "Test: [90/100]\tTime 0.035 (0.029)\tLoss 0.5260 (0.6542)\tPrec@1 84.000 (80.066)\tPrec@5 100.000 (98.813)\n",
            "val Results: Prec@1 80.040 Prec@5 98.800 Loss 0.65375\n",
            "val Class Accuracy: [0.965,0.964,0.865,0.743,0.833,0.715,0.835,0.680,0.687,0.717]\n",
            "Best Prec@1: 80.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [167][0/329], lr: 0.00010\tTime 0.677 (0.677)\tData 0.613 (0.613)\tLoss 0.1897 (0.1897)\tPrec@1 91.797 (91.797)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][10/329], lr: 0.00010\tTime 0.075 (0.151)\tData 0.000 (0.064)\tLoss 0.1915 (0.1786)\tPrec@1 92.969 (94.070)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [167][20/329], lr: 0.00010\tTime 0.075 (0.123)\tData 0.000 (0.036)\tLoss 0.1715 (0.1917)\tPrec@1 92.969 (93.676)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [167][30/329], lr: 0.00010\tTime 0.068 (0.112)\tData 0.000 (0.026)\tLoss 0.2229 (0.1970)\tPrec@1 91.016 (93.473)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [167][40/329], lr: 0.00010\tTime 0.083 (0.107)\tData 0.008 (0.021)\tLoss 0.1867 (0.1943)\tPrec@1 92.969 (93.474)\tPrec@5 99.609 (99.819)\n",
            "Epoch: [167][50/329], lr: 0.00010\tTime 0.098 (0.105)\tData 0.000 (0.019)\tLoss 0.1822 (0.1935)\tPrec@1 93.750 (93.444)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [167][60/329], lr: 0.00010\tTime 0.074 (0.102)\tData 0.000 (0.017)\tLoss 0.1690 (0.1921)\tPrec@1 94.531 (93.583)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [167][70/329], lr: 0.00010\tTime 0.096 (0.100)\tData 0.005 (0.016)\tLoss 0.2208 (0.1917)\tPrec@1 93.359 (93.651)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [167][80/329], lr: 0.00010\tTime 0.081 (0.099)\tData 0.000 (0.015)\tLoss 0.2246 (0.1920)\tPrec@1 93.359 (93.663)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [167][90/329], lr: 0.00010\tTime 0.088 (0.098)\tData 0.008 (0.013)\tLoss 0.1754 (0.1950)\tPrec@1 94.141 (93.591)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [167][100/329], lr: 0.00010\tTime 0.069 (0.097)\tData 0.005 (0.013)\tLoss 0.2643 (0.1973)\tPrec@1 92.578 (93.549)\tPrec@5 98.828 (99.814)\n",
            "Epoch: [167][110/329], lr: 0.00010\tTime 0.096 (0.096)\tData 0.011 (0.012)\tLoss 0.2109 (0.1958)\tPrec@1 92.188 (93.567)\tPrec@5 99.609 (99.821)\n",
            "Epoch: [167][120/329], lr: 0.00010\tTime 0.076 (0.096)\tData 0.000 (0.012)\tLoss 0.1911 (0.1952)\tPrec@1 92.969 (93.563)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [167][130/329], lr: 0.00010\tTime 0.066 (0.095)\tData 0.000 (0.011)\tLoss 0.1492 (0.1942)\tPrec@1 95.703 (93.598)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [167][140/329], lr: 0.00010\tTime 0.074 (0.094)\tData 0.004 (0.011)\tLoss 0.2104 (0.1958)\tPrec@1 92.188 (93.551)\tPrec@5 99.219 (99.823)\n",
            "Epoch: [167][150/329], lr: 0.00010\tTime 0.083 (0.094)\tData 0.000 (0.011)\tLoss 0.2025 (0.1981)\tPrec@1 93.750 (93.460)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [167][160/329], lr: 0.00010\tTime 0.093 (0.094)\tData 0.000 (0.010)\tLoss 0.1449 (0.1969)\tPrec@1 95.703 (93.527)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [167][170/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.005 (0.010)\tLoss 0.1968 (0.1966)\tPrec@1 94.141 (93.544)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [167][180/329], lr: 0.00010\tTime 0.097 (0.093)\tData 0.004 (0.010)\tLoss 0.2061 (0.1967)\tPrec@1 92.969 (93.510)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [167][190/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.007 (0.010)\tLoss 0.2504 (0.1964)\tPrec@1 91.016 (93.527)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [167][200/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.005 (0.010)\tLoss 0.1977 (0.1973)\tPrec@1 92.969 (93.484)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [167][210/329], lr: 0.00010\tTime 0.122 (0.093)\tData 0.009 (0.010)\tLoss 0.1983 (0.1979)\tPrec@1 93.750 (93.439)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [167][220/329], lr: 0.00010\tTime 0.109 (0.092)\tData 0.006 (0.010)\tLoss 0.2300 (0.1979)\tPrec@1 92.578 (93.430)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [167][230/329], lr: 0.00010\tTime 0.084 (0.092)\tData 0.000 (0.010)\tLoss 0.2100 (0.1982)\tPrec@1 92.969 (93.403)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [167][240/329], lr: 0.00010\tTime 0.091 (0.092)\tData 0.000 (0.010)\tLoss 0.1647 (0.1976)\tPrec@1 94.531 (93.411)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [167][250/329], lr: 0.00010\tTime 0.110 (0.092)\tData 0.013 (0.010)\tLoss 0.1411 (0.1972)\tPrec@1 95.312 (93.437)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [167][260/329], lr: 0.00010\tTime 0.088 (0.092)\tData 0.000 (0.009)\tLoss 0.2249 (0.1978)\tPrec@1 92.969 (93.401)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [167][270/329], lr: 0.00010\tTime 0.089 (0.092)\tData 0.005 (0.009)\tLoss 0.2034 (0.1981)\tPrec@1 93.359 (93.384)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [167][280/329], lr: 0.00010\tTime 0.080 (0.092)\tData 0.005 (0.009)\tLoss 0.1778 (0.1977)\tPrec@1 93.359 (93.404)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [167][290/329], lr: 0.00010\tTime 0.079 (0.091)\tData 0.006 (0.009)\tLoss 0.1441 (0.1971)\tPrec@1 95.703 (93.418)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [167][300/329], lr: 0.00010\tTime 0.092 (0.091)\tData 0.007 (0.009)\tLoss 0.1596 (0.1967)\tPrec@1 94.531 (93.441)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [167][310/329], lr: 0.00010\tTime 0.097 (0.091)\tData 0.007 (0.009)\tLoss 0.2129 (0.1970)\tPrec@1 92.188 (93.423)\tPrec@5 99.609 (99.832)\n",
            "Epoch: [167][320/329], lr: 0.00010\tTime 0.104 (0.091)\tData 0.067 (0.009)\tLoss 0.1861 (0.1967)\tPrec@1 91.797 (93.435)\tPrec@5 100.000 (99.830)\n",
            "Test: [0/100]\tTime 0.366 (0.366)\tLoss 0.4671 (0.4671)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.009 (0.059)\tLoss 0.4807 (0.6216)\tPrec@1 85.000 (81.727)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 0.6439 (0.6205)\tPrec@1 80.000 (81.762)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 0.8122 (0.6403)\tPrec@1 77.000 (81.226)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.026 (0.034)\tLoss 0.6532 (0.6461)\tPrec@1 79.000 (80.951)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 0.6582 (0.6391)\tPrec@1 86.000 (81.118)\tPrec@5 98.000 (98.667)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 0.4943 (0.6426)\tPrec@1 88.000 (80.754)\tPrec@5 100.000 (98.754)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 0.6752 (0.6363)\tPrec@1 83.000 (80.845)\tPrec@5 100.000 (98.831)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 0.5473 (0.6292)\tPrec@1 87.000 (81.099)\tPrec@5 99.000 (98.889)\n",
            "Test: [90/100]\tTime 0.032 (0.028)\tLoss 0.4933 (0.6364)\tPrec@1 85.000 (80.857)\tPrec@5 100.000 (98.868)\n",
            "val Results: Prec@1 80.860 Prec@5 98.860 Loss 0.63291\n",
            "val Class Accuracy: [0.929,0.980,0.867,0.743,0.829,0.789,0.816,0.669,0.716,0.748]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [168][0/329], lr: 0.00010\tTime 0.670 (0.670)\tData 0.592 (0.592)\tLoss 0.2145 (0.2145)\tPrec@1 91.797 (91.797)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [168][10/329], lr: 0.00010\tTime 0.089 (0.141)\tData 0.000 (0.059)\tLoss 0.1839 (0.2052)\tPrec@1 93.359 (92.685)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [168][20/329], lr: 0.00010\tTime 0.102 (0.120)\tData 0.008 (0.034)\tLoss 0.1804 (0.1956)\tPrec@1 94.531 (93.211)\tPrec@5 99.609 (99.777)\n",
            "Epoch: [168][30/329], lr: 0.00010\tTime 0.103 (0.111)\tData 0.000 (0.025)\tLoss 0.1613 (0.1927)\tPrec@1 94.141 (93.385)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [168][40/329], lr: 0.00010\tTime 0.083 (0.105)\tData 0.000 (0.020)\tLoss 0.1712 (0.1890)\tPrec@1 94.141 (93.521)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [168][50/329], lr: 0.00010\tTime 0.081 (0.102)\tData 0.000 (0.018)\tLoss 0.1449 (0.1914)\tPrec@1 96.094 (93.451)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [168][60/329], lr: 0.00010\tTime 0.100 (0.100)\tData 0.007 (0.016)\tLoss 0.1361 (0.1925)\tPrec@1 95.703 (93.411)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [168][70/329], lr: 0.00010\tTime 0.095 (0.098)\tData 0.000 (0.015)\tLoss 0.2010 (0.1923)\tPrec@1 92.578 (93.403)\tPrec@5 99.609 (99.857)\n",
            "Epoch: [168][80/329], lr: 0.00010\tTime 0.077 (0.097)\tData 0.004 (0.014)\tLoss 0.1935 (0.1924)\tPrec@1 94.141 (93.379)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [168][90/329], lr: 0.00010\tTime 0.075 (0.096)\tData 0.000 (0.013)\tLoss 0.1999 (0.1942)\tPrec@1 93.359 (93.338)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [168][100/329], lr: 0.00010\tTime 0.085 (0.096)\tData 0.006 (0.012)\tLoss 0.1479 (0.1946)\tPrec@1 95.703 (93.367)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [168][110/329], lr: 0.00010\tTime 0.068 (0.095)\tData 0.005 (0.012)\tLoss 0.1484 (0.1951)\tPrec@1 96.094 (93.391)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [168][120/329], lr: 0.00010\tTime 0.088 (0.095)\tData 0.000 (0.012)\tLoss 0.1760 (0.1946)\tPrec@1 92.188 (93.398)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [168][130/329], lr: 0.00010\tTime 0.087 (0.094)\tData 0.005 (0.012)\tLoss 0.1819 (0.1934)\tPrec@1 94.922 (93.452)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [168][140/329], lr: 0.00010\tTime 0.092 (0.094)\tData 0.000 (0.011)\tLoss 0.1554 (0.1921)\tPrec@1 94.531 (93.473)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [168][150/329], lr: 0.00010\tTime 0.087 (0.094)\tData 0.007 (0.011)\tLoss 0.2106 (0.1942)\tPrec@1 92.969 (93.401)\tPrec@5 98.828 (99.827)\n",
            "Epoch: [168][160/329], lr: 0.00010\tTime 0.092 (0.093)\tData 0.006 (0.011)\tLoss 0.2470 (0.1936)\tPrec@1 92.578 (93.452)\tPrec@5 99.219 (99.833)\n",
            "Epoch: [168][170/329], lr: 0.00010\tTime 0.077 (0.093)\tData 0.000 (0.011)\tLoss 0.1942 (0.1933)\tPrec@1 92.969 (93.467)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [168][180/329], lr: 0.00010\tTime 0.079 (0.093)\tData 0.006 (0.010)\tLoss 0.1909 (0.1941)\tPrec@1 93.359 (93.437)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [168][190/329], lr: 0.00010\tTime 0.090 (0.093)\tData 0.005 (0.010)\tLoss 0.1658 (0.1945)\tPrec@1 94.922 (93.445)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [168][200/329], lr: 0.00010\tTime 0.084 (0.092)\tData 0.007 (0.010)\tLoss 0.1846 (0.1944)\tPrec@1 94.531 (93.439)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [168][210/329], lr: 0.00010\tTime 0.086 (0.092)\tData 0.003 (0.010)\tLoss 0.2904 (0.1952)\tPrec@1 89.062 (93.420)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [168][220/329], lr: 0.00010\tTime 0.088 (0.092)\tData 0.000 (0.010)\tLoss 0.2281 (0.1961)\tPrec@1 92.578 (93.400)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [168][230/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.007 (0.010)\tLoss 0.2775 (0.1972)\tPrec@1 92.188 (93.368)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [168][240/329], lr: 0.00010\tTime 0.089 (0.092)\tData 0.007 (0.010)\tLoss 0.2311 (0.1976)\tPrec@1 91.406 (93.364)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [168][250/329], lr: 0.00010\tTime 0.095 (0.092)\tData 0.007 (0.010)\tLoss 0.2179 (0.1979)\tPrec@1 92.188 (93.345)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [168][260/329], lr: 0.00010\tTime 0.067 (0.092)\tData 0.000 (0.010)\tLoss 0.1919 (0.1976)\tPrec@1 92.969 (93.364)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [168][270/329], lr: 0.00010\tTime 0.106 (0.092)\tData 0.005 (0.010)\tLoss 0.2419 (0.1975)\tPrec@1 92.969 (93.375)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [168][280/329], lr: 0.00010\tTime 0.090 (0.091)\tData 0.000 (0.009)\tLoss 0.2142 (0.1976)\tPrec@1 91.406 (93.379)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [168][290/329], lr: 0.00010\tTime 0.106 (0.091)\tData 0.007 (0.009)\tLoss 0.1703 (0.1973)\tPrec@1 94.531 (93.388)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [168][300/329], lr: 0.00010\tTime 0.093 (0.091)\tData 0.000 (0.009)\tLoss 0.2042 (0.1972)\tPrec@1 93.750 (93.387)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [168][310/329], lr: 0.00010\tTime 0.088 (0.091)\tData 0.000 (0.009)\tLoss 0.2587 (0.1968)\tPrec@1 91.016 (93.401)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [168][320/329], lr: 0.00010\tTime 0.087 (0.091)\tData 0.036 (0.009)\tLoss 0.2621 (0.1975)\tPrec@1 92.578 (93.387)\tPrec@5 99.219 (99.828)\n",
            "Test: [0/100]\tTime 0.373 (0.373)\tLoss 0.4596 (0.4596)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.060)\tLoss 0.4971 (0.6324)\tPrec@1 83.000 (81.727)\tPrec@5 97.000 (99.091)\n",
            "Test: [20/100]\tTime 0.034 (0.043)\tLoss 0.6212 (0.6402)\tPrec@1 82.000 (81.286)\tPrec@5 100.000 (98.714)\n",
            "Test: [30/100]\tTime 0.021 (0.038)\tLoss 0.8255 (0.6591)\tPrec@1 77.000 (80.839)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.017 (0.034)\tLoss 0.6921 (0.6642)\tPrec@1 79.000 (80.805)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 0.6647 (0.6572)\tPrec@1 82.000 (80.824)\tPrec@5 98.000 (98.647)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 0.5218 (0.6612)\tPrec@1 86.000 (80.328)\tPrec@5 100.000 (98.721)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 0.7183 (0.6549)\tPrec@1 79.000 (80.310)\tPrec@5 99.000 (98.746)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 0.5802 (0.6486)\tPrec@1 86.000 (80.494)\tPrec@5 99.000 (98.815)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 0.5428 (0.6563)\tPrec@1 86.000 (80.209)\tPrec@5 100.000 (98.780)\n",
            "val Results: Prec@1 80.200 Prec@5 98.750 Loss 0.65405\n",
            "val Class Accuracy: [0.957,0.981,0.850,0.758,0.810,0.777,0.828,0.659,0.669,0.731]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [169][0/329], lr: 0.00010\tTime 0.649 (0.649)\tData 0.555 (0.555)\tLoss 0.2280 (0.2280)\tPrec@1 94.141 (94.141)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [169][10/329], lr: 0.00010\tTime 0.092 (0.150)\tData 0.003 (0.055)\tLoss 0.1737 (0.1934)\tPrec@1 93.750 (93.857)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [169][20/329], lr: 0.00010\tTime 0.096 (0.123)\tData 0.006 (0.031)\tLoss 0.1884 (0.1966)\tPrec@1 93.359 (93.508)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [169][30/329], lr: 0.00010\tTime 0.099 (0.112)\tData 0.007 (0.023)\tLoss 0.1609 (0.1946)\tPrec@1 93.359 (93.485)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [169][40/329], lr: 0.00010\tTime 0.093 (0.107)\tData 0.000 (0.019)\tLoss 0.1647 (0.1897)\tPrec@1 93.359 (93.626)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [169][50/329], lr: 0.00010\tTime 0.089 (0.103)\tData 0.014 (0.017)\tLoss 0.2364 (0.1932)\tPrec@1 92.188 (93.428)\tPrec@5 99.219 (99.816)\n",
            "Epoch: [169][60/329], lr: 0.00010\tTime 0.079 (0.100)\tData 0.000 (0.015)\tLoss 0.1023 (0.1925)\tPrec@1 97.266 (93.404)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [169][70/329], lr: 0.00010\tTime 0.113 (0.099)\tData 0.000 (0.014)\tLoss 0.2098 (0.1930)\tPrec@1 94.141 (93.381)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [169][80/329], lr: 0.00010\tTime 0.086 (0.098)\tData 0.006 (0.013)\tLoss 0.1833 (0.1920)\tPrec@1 94.141 (93.422)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [169][90/329], lr: 0.00010\tTime 0.087 (0.097)\tData 0.000 (0.013)\tLoss 0.2755 (0.1940)\tPrec@1 89.453 (93.355)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [169][100/329], lr: 0.00010\tTime 0.095 (0.096)\tData 0.000 (0.012)\tLoss 0.0964 (0.1929)\tPrec@1 96.875 (93.410)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [169][110/329], lr: 0.00010\tTime 0.099 (0.095)\tData 0.005 (0.012)\tLoss 0.1682 (0.1921)\tPrec@1 94.141 (93.472)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [169][120/329], lr: 0.00010\tTime 0.103 (0.095)\tData 0.000 (0.011)\tLoss 0.1994 (0.1920)\tPrec@1 92.188 (93.495)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [169][130/329], lr: 0.00010\tTime 0.067 (0.094)\tData 0.001 (0.011)\tLoss 0.1762 (0.1927)\tPrec@1 94.141 (93.491)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [169][140/329], lr: 0.00010\tTime 0.071 (0.094)\tData 0.000 (0.011)\tLoss 0.2058 (0.1926)\tPrec@1 94.531 (93.515)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [169][150/329], lr: 0.00010\tTime 0.083 (0.093)\tData 0.000 (0.011)\tLoss 0.1855 (0.1929)\tPrec@1 94.141 (93.538)\tPrec@5 99.219 (99.832)\n",
            "Epoch: [169][160/329], lr: 0.00010\tTime 0.087 (0.093)\tData 0.006 (0.010)\tLoss 0.2350 (0.1934)\tPrec@1 92.188 (93.520)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [169][170/329], lr: 0.00010\tTime 0.082 (0.093)\tData 0.000 (0.010)\tLoss 0.1602 (0.1934)\tPrec@1 94.922 (93.503)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [169][180/329], lr: 0.00010\tTime 0.078 (0.093)\tData 0.005 (0.010)\tLoss 0.2005 (0.1943)\tPrec@1 92.578 (93.478)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [169][190/329], lr: 0.00010\tTime 0.089 (0.093)\tData 0.004 (0.010)\tLoss 0.2387 (0.1949)\tPrec@1 92.969 (93.468)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [169][200/329], lr: 0.00010\tTime 0.097 (0.093)\tData 0.006 (0.010)\tLoss 0.1877 (0.1950)\tPrec@1 92.969 (93.464)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [169][210/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.005 (0.010)\tLoss 0.2959 (0.1951)\tPrec@1 90.625 (93.459)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [169][220/329], lr: 0.00010\tTime 0.095 (0.092)\tData 0.016 (0.010)\tLoss 0.1954 (0.1953)\tPrec@1 92.969 (93.455)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [169][230/329], lr: 0.00010\tTime 0.073 (0.092)\tData 0.000 (0.010)\tLoss 0.2309 (0.1957)\tPrec@1 91.797 (93.429)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [169][240/329], lr: 0.00010\tTime 0.141 (0.093)\tData 0.000 (0.009)\tLoss 0.1842 (0.1956)\tPrec@1 94.141 (93.429)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [169][250/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.009)\tLoss 0.2357 (0.1959)\tPrec@1 91.797 (93.415)\tPrec@5 99.609 (99.832)\n",
            "Epoch: [169][260/329], lr: 0.00010\tTime 0.119 (0.094)\tData 0.011 (0.009)\tLoss 0.2041 (0.1958)\tPrec@1 92.578 (93.409)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [169][270/329], lr: 0.00010\tTime 0.094 (0.095)\tData 0.004 (0.009)\tLoss 0.1457 (0.1962)\tPrec@1 94.922 (93.403)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [169][280/329], lr: 0.00010\tTime 0.079 (0.095)\tData 0.002 (0.009)\tLoss 0.2180 (0.1958)\tPrec@1 93.359 (93.411)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [169][290/329], lr: 0.00010\tTime 0.087 (0.094)\tData 0.005 (0.009)\tLoss 0.1373 (0.1956)\tPrec@1 95.703 (93.431)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [169][300/329], lr: 0.00010\tTime 0.071 (0.094)\tData 0.000 (0.009)\tLoss 0.2721 (0.1955)\tPrec@1 92.188 (93.435)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [169][310/329], lr: 0.00010\tTime 0.088 (0.094)\tData 0.012 (0.009)\tLoss 0.1981 (0.1954)\tPrec@1 93.359 (93.436)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [169][320/329], lr: 0.00010\tTime 0.104 (0.094)\tData 0.055 (0.009)\tLoss 0.2090 (0.1961)\tPrec@1 92.578 (93.398)\tPrec@5 100.000 (99.832)\n",
            "Test: [0/100]\tTime 0.406 (0.406)\tLoss 0.4674 (0.4674)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.038 (0.061)\tLoss 0.5081 (0.6449)\tPrec@1 84.000 (81.818)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.027 (0.041)\tLoss 0.5995 (0.6510)\tPrec@1 80.000 (81.190)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.026 (0.037)\tLoss 0.7628 (0.6663)\tPrec@1 76.000 (80.613)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.019 (0.032)\tLoss 0.7106 (0.6699)\tPrec@1 78.000 (80.585)\tPrec@5 99.000 (98.659)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 0.6347 (0.6631)\tPrec@1 86.000 (80.627)\tPrec@5 98.000 (98.686)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 0.5146 (0.6680)\tPrec@1 87.000 (80.115)\tPrec@5 100.000 (98.787)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 0.7384 (0.6631)\tPrec@1 80.000 (80.042)\tPrec@5 99.000 (98.845)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 0.5766 (0.6566)\tPrec@1 84.000 (80.210)\tPrec@5 99.000 (98.889)\n",
            "Test: [90/100]\tTime 0.024 (0.028)\tLoss 0.5339 (0.6659)\tPrec@1 86.000 (80.088)\tPrec@5 100.000 (98.846)\n",
            "val Results: Prec@1 79.980 Prec@5 98.820 Loss 0.66516\n",
            "val Class Accuracy: [0.969,0.973,0.870,0.705,0.821,0.747,0.810,0.708,0.695,0.700]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [170][0/329], lr: 0.00010\tTime 0.663 (0.663)\tData 0.573 (0.573)\tLoss 0.1736 (0.1736)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][10/329], lr: 0.00010\tTime 0.104 (0.146)\tData 0.004 (0.056)\tLoss 0.1471 (0.1885)\tPrec@1 96.094 (93.892)\tPrec@5 99.609 (99.929)\n",
            "Epoch: [170][20/329], lr: 0.00010\tTime 0.076 (0.119)\tData 0.000 (0.032)\tLoss 0.3214 (0.1925)\tPrec@1 87.891 (93.694)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [170][30/329], lr: 0.00010\tTime 0.083 (0.110)\tData 0.005 (0.024)\tLoss 0.2159 (0.1954)\tPrec@1 92.578 (93.548)\tPrec@5 99.609 (99.798)\n",
            "Epoch: [170][40/329], lr: 0.00010\tTime 0.094 (0.106)\tData 0.000 (0.020)\tLoss 0.1431 (0.1936)\tPrec@1 94.922 (93.502)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [170][50/329], lr: 0.00010\tTime 0.095 (0.103)\tData 0.000 (0.017)\tLoss 0.1843 (0.1942)\tPrec@1 93.750 (93.436)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [170][60/329], lr: 0.00010\tTime 0.097 (0.100)\tData 0.000 (0.015)\tLoss 0.1639 (0.1939)\tPrec@1 94.141 (93.532)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [170][70/329], lr: 0.00010\tTime 0.102 (0.100)\tData 0.011 (0.014)\tLoss 0.2005 (0.1941)\tPrec@1 92.578 (93.513)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [170][80/329], lr: 0.00010\tTime 0.089 (0.098)\tData 0.000 (0.013)\tLoss 0.2441 (0.1930)\tPrec@1 92.578 (93.576)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [170][90/329], lr: 0.00010\tTime 0.099 (0.097)\tData 0.007 (0.013)\tLoss 0.1836 (0.1911)\tPrec@1 93.750 (93.638)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [170][100/329], lr: 0.00010\tTime 0.092 (0.096)\tData 0.005 (0.012)\tLoss 0.1774 (0.1909)\tPrec@1 94.531 (93.649)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [170][110/329], lr: 0.00010\tTime 0.078 (0.096)\tData 0.000 (0.012)\tLoss 0.1560 (0.1938)\tPrec@1 94.141 (93.571)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [170][120/329], lr: 0.00010\tTime 0.087 (0.095)\tData 0.004 (0.011)\tLoss 0.2627 (0.1937)\tPrec@1 92.188 (93.585)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [170][130/329], lr: 0.00010\tTime 0.081 (0.094)\tData 0.000 (0.011)\tLoss 0.2012 (0.1933)\tPrec@1 91.797 (93.550)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [170][140/329], lr: 0.00010\tTime 0.105 (0.094)\tData 0.003 (0.011)\tLoss 0.1392 (0.1916)\tPrec@1 94.531 (93.617)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [170][150/329], lr: 0.00010\tTime 0.090 (0.094)\tData 0.005 (0.011)\tLoss 0.1950 (0.1914)\tPrec@1 93.359 (93.608)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [170][160/329], lr: 0.00010\tTime 0.099 (0.093)\tData 0.000 (0.010)\tLoss 0.1733 (0.1911)\tPrec@1 93.359 (93.621)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [170][170/329], lr: 0.00010\tTime 0.074 (0.093)\tData 0.000 (0.010)\tLoss 0.1399 (0.1909)\tPrec@1 95.312 (93.606)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [170][180/329], lr: 0.00010\tTime 0.099 (0.093)\tData 0.001 (0.010)\tLoss 0.1798 (0.1911)\tPrec@1 93.359 (93.601)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [170][190/329], lr: 0.00010\tTime 0.083 (0.092)\tData 0.006 (0.010)\tLoss 0.1982 (0.1908)\tPrec@1 92.969 (93.609)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [170][200/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.006 (0.010)\tLoss 0.1825 (0.1902)\tPrec@1 94.922 (93.635)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [170][210/329], lr: 0.00010\tTime 0.102 (0.092)\tData 0.010 (0.010)\tLoss 0.1468 (0.1899)\tPrec@1 95.312 (93.628)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [170][220/329], lr: 0.00010\tTime 0.098 (0.092)\tData 0.004 (0.010)\tLoss 0.2202 (0.1908)\tPrec@1 92.578 (93.614)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [170][230/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.009 (0.010)\tLoss 0.1964 (0.1909)\tPrec@1 93.359 (93.623)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [170][240/329], lr: 0.00010\tTime 0.098 (0.092)\tData 0.000 (0.010)\tLoss 0.1431 (0.1908)\tPrec@1 94.531 (93.615)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [170][250/329], lr: 0.00010\tTime 0.078 (0.091)\tData 0.000 (0.010)\tLoss 0.2358 (0.1917)\tPrec@1 90.625 (93.582)\tPrec@5 99.219 (99.823)\n",
            "Epoch: [170][260/329], lr: 0.00010\tTime 0.080 (0.091)\tData 0.007 (0.010)\tLoss 0.2406 (0.1919)\tPrec@1 93.359 (93.584)\tPrec@5 100.000 (99.823)\n",
            "Epoch: [170][270/329], lr: 0.00010\tTime 0.090 (0.091)\tData 0.007 (0.009)\tLoss 0.1546 (0.1919)\tPrec@1 95.703 (93.580)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [170][280/329], lr: 0.00010\tTime 0.112 (0.091)\tData 0.006 (0.009)\tLoss 0.2309 (0.1922)\tPrec@1 91.406 (93.562)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [170][290/329], lr: 0.00010\tTime 0.087 (0.091)\tData 0.000 (0.009)\tLoss 0.1841 (0.1920)\tPrec@1 94.531 (93.590)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [170][300/329], lr: 0.00010\tTime 0.110 (0.091)\tData 0.010 (0.009)\tLoss 0.2695 (0.1924)\tPrec@1 91.797 (93.583)\tPrec@5 99.609 (99.817)\n",
            "Epoch: [170][310/329], lr: 0.00010\tTime 0.080 (0.091)\tData 0.005 (0.009)\tLoss 0.2087 (0.1924)\tPrec@1 93.359 (93.577)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [170][320/329], lr: 0.00010\tTime 0.083 (0.091)\tData 0.045 (0.009)\tLoss 0.1712 (0.1920)\tPrec@1 93.359 (93.595)\tPrec@5 100.000 (99.820)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 0.4527 (0.4527)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.035 (0.061)\tLoss 0.4922 (0.6333)\tPrec@1 84.000 (81.455)\tPrec@5 97.000 (99.091)\n",
            "Test: [20/100]\tTime 0.014 (0.042)\tLoss 0.6231 (0.6447)\tPrec@1 81.000 (81.381)\tPrec@5 100.000 (98.571)\n",
            "Test: [30/100]\tTime 0.010 (0.036)\tLoss 0.7912 (0.6598)\tPrec@1 78.000 (81.000)\tPrec@5 99.000 (98.613)\n",
            "Test: [40/100]\tTime 0.036 (0.033)\tLoss 0.7021 (0.6651)\tPrec@1 80.000 (80.878)\tPrec@5 99.000 (98.585)\n",
            "Test: [50/100]\tTime 0.035 (0.033)\tLoss 0.6573 (0.6577)\tPrec@1 83.000 (80.980)\tPrec@5 98.000 (98.588)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 0.5017 (0.6625)\tPrec@1 89.000 (80.607)\tPrec@5 100.000 (98.672)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 0.7365 (0.6570)\tPrec@1 80.000 (80.634)\tPrec@5 99.000 (98.718)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 0.5598 (0.6500)\tPrec@1 87.000 (80.802)\tPrec@5 98.000 (98.778)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 0.5179 (0.6581)\tPrec@1 86.000 (80.571)\tPrec@5 100.000 (98.747)\n",
            "val Results: Prec@1 80.550 Prec@5 98.720 Loss 0.65543\n",
            "val Class Accuracy: [0.954,0.981,0.878,0.729,0.787,0.770,0.827,0.682,0.707,0.740]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [171][0/329], lr: 0.00010\tTime 0.686 (0.686)\tData 0.603 (0.603)\tLoss 0.2124 (0.2124)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][10/329], lr: 0.00010\tTime 0.083 (0.151)\tData 0.000 (0.060)\tLoss 0.2014 (0.2107)\tPrec@1 93.359 (93.111)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [171][20/329], lr: 0.00010\tTime 0.107 (0.123)\tData 0.000 (0.034)\tLoss 0.1637 (0.1997)\tPrec@1 94.922 (93.304)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [171][30/329], lr: 0.00010\tTime 0.094 (0.112)\tData 0.007 (0.024)\tLoss 0.1862 (0.1980)\tPrec@1 92.578 (93.309)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [171][40/329], lr: 0.00010\tTime 0.095 (0.106)\tData 0.000 (0.019)\tLoss 0.1806 (0.1966)\tPrec@1 94.922 (93.407)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [171][50/329], lr: 0.00010\tTime 0.134 (0.104)\tData 0.006 (0.017)\tLoss 0.1965 (0.1956)\tPrec@1 94.531 (93.413)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [171][60/329], lr: 0.00010\tTime 0.077 (0.100)\tData 0.000 (0.015)\tLoss 0.2267 (0.1937)\tPrec@1 93.750 (93.519)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [171][70/329], lr: 0.00010\tTime 0.098 (0.099)\tData 0.006 (0.014)\tLoss 0.1551 (0.1941)\tPrec@1 94.141 (93.513)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [171][80/329], lr: 0.00010\tTime 0.079 (0.098)\tData 0.000 (0.013)\tLoss 0.1701 (0.1943)\tPrec@1 93.359 (93.432)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [171][90/329], lr: 0.00010\tTime 0.084 (0.096)\tData 0.006 (0.012)\tLoss 0.2174 (0.1957)\tPrec@1 91.797 (93.402)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [171][100/329], lr: 0.00010\tTime 0.096 (0.095)\tData 0.007 (0.012)\tLoss 0.2168 (0.1977)\tPrec@1 92.188 (93.328)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [171][110/329], lr: 0.00010\tTime 0.073 (0.095)\tData 0.001 (0.012)\tLoss 0.1901 (0.1951)\tPrec@1 94.141 (93.426)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [171][120/329], lr: 0.00010\tTime 0.073 (0.094)\tData 0.005 (0.011)\tLoss 0.2245 (0.1951)\tPrec@1 93.750 (93.479)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [171][130/329], lr: 0.00010\tTime 0.074 (0.094)\tData 0.000 (0.011)\tLoss 0.2295 (0.1948)\tPrec@1 91.016 (93.470)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [171][140/329], lr: 0.00010\tTime 0.105 (0.093)\tData 0.007 (0.011)\tLoss 0.2517 (0.1949)\tPrec@1 91.797 (93.462)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [171][150/329], lr: 0.00010\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 0.1790 (0.1944)\tPrec@1 91.797 (93.476)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [171][160/329], lr: 0.00010\tTime 0.097 (0.093)\tData 0.005 (0.010)\tLoss 0.2489 (0.1942)\tPrec@1 90.234 (93.461)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [171][170/329], lr: 0.00010\tTime 0.088 (0.092)\tData 0.000 (0.010)\tLoss 0.2131 (0.1936)\tPrec@1 92.188 (93.501)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [171][180/329], lr: 0.00010\tTime 0.103 (0.092)\tData 0.007 (0.010)\tLoss 0.2037 (0.1931)\tPrec@1 92.969 (93.510)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [171][190/329], lr: 0.00010\tTime 0.070 (0.092)\tData 0.000 (0.010)\tLoss 0.2012 (0.1938)\tPrec@1 92.969 (93.480)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [171][200/329], lr: 0.00010\tTime 0.098 (0.091)\tData 0.000 (0.009)\tLoss 0.2910 (0.1937)\tPrec@1 90.234 (93.474)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [171][210/329], lr: 0.00010\tTime 0.070 (0.091)\tData 0.000 (0.009)\tLoss 0.1787 (0.1938)\tPrec@1 94.531 (93.491)\tPrec@5 98.828 (99.826)\n",
            "Epoch: [171][220/329], lr: 0.00010\tTime 0.104 (0.091)\tData 0.000 (0.009)\tLoss 0.2089 (0.1939)\tPrec@1 92.188 (93.494)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [171][230/329], lr: 0.00010\tTime 0.083 (0.091)\tData 0.000 (0.009)\tLoss 0.1508 (0.1934)\tPrec@1 94.141 (93.491)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [171][240/329], lr: 0.00010\tTime 0.066 (0.091)\tData 0.004 (0.009)\tLoss 0.1955 (0.1939)\tPrec@1 94.141 (93.478)\tPrec@5 100.000 (99.823)\n",
            "Epoch: [171][250/329], lr: 0.00010\tTime 0.099 (0.091)\tData 0.000 (0.009)\tLoss 0.2309 (0.1943)\tPrec@1 92.969 (93.467)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [171][260/329], lr: 0.00010\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.1881 (0.1940)\tPrec@1 95.312 (93.496)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [171][270/329], lr: 0.00010\tTime 0.097 (0.091)\tData 0.012 (0.009)\tLoss 0.1607 (0.1935)\tPrec@1 93.359 (93.508)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [171][280/329], lr: 0.00010\tTime 0.083 (0.091)\tData 0.000 (0.009)\tLoss 0.1806 (0.1930)\tPrec@1 93.750 (93.532)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [171][290/329], lr: 0.00010\tTime 0.110 (0.090)\tData 0.000 (0.009)\tLoss 0.2507 (0.1932)\tPrec@1 92.578 (93.533)\tPrec@5 99.609 (99.821)\n",
            "Epoch: [171][300/329], lr: 0.00010\tTime 0.100 (0.090)\tData 0.004 (0.008)\tLoss 0.2297 (0.1932)\tPrec@1 92.188 (93.532)\tPrec@5 99.609 (99.821)\n",
            "Epoch: [171][310/329], lr: 0.00010\tTime 0.091 (0.090)\tData 0.000 (0.008)\tLoss 0.2258 (0.1939)\tPrec@1 92.969 (93.519)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [171][320/329], lr: 0.00010\tTime 0.097 (0.090)\tData 0.059 (0.008)\tLoss 0.1873 (0.1933)\tPrec@1 92.969 (93.537)\tPrec@5 100.000 (99.820)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 0.4468 (0.4468)\tPrec@1 85.000 (85.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.024 (0.061)\tLoss 0.4927 (0.6318)\tPrec@1 85.000 (81.455)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.030 (0.044)\tLoss 0.5906 (0.6391)\tPrec@1 82.000 (81.429)\tPrec@5 100.000 (98.714)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 0.8246 (0.6566)\tPrec@1 77.000 (81.226)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 0.6680 (0.6625)\tPrec@1 81.000 (80.976)\tPrec@5 99.000 (98.659)\n",
            "Test: [50/100]\tTime 0.039 (0.032)\tLoss 0.6872 (0.6552)\tPrec@1 82.000 (81.098)\tPrec@5 98.000 (98.667)\n",
            "Test: [60/100]\tTime 0.014 (0.031)\tLoss 0.5326 (0.6610)\tPrec@1 85.000 (80.508)\tPrec@5 100.000 (98.754)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 0.7104 (0.6535)\tPrec@1 79.000 (80.634)\tPrec@5 99.000 (98.803)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 0.5898 (0.6471)\tPrec@1 87.000 (80.815)\tPrec@5 99.000 (98.864)\n",
            "Test: [90/100]\tTime 0.028 (0.028)\tLoss 0.5281 (0.6539)\tPrec@1 84.000 (80.560)\tPrec@5 100.000 (98.846)\n",
            "val Results: Prec@1 80.470 Prec@5 98.800 Loss 0.65097\n",
            "val Class Accuracy: [0.956,0.980,0.838,0.816,0.797,0.728,0.813,0.669,0.715,0.735]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [172][0/329], lr: 0.00010\tTime 0.635 (0.635)\tData 0.553 (0.553)\tLoss 0.2121 (0.2121)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][10/329], lr: 0.00010\tTime 0.107 (0.152)\tData 0.005 (0.056)\tLoss 0.1505 (0.2127)\tPrec@1 94.922 (92.507)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [172][20/329], lr: 0.00010\tTime 0.070 (0.124)\tData 0.000 (0.032)\tLoss 0.2175 (0.2034)\tPrec@1 93.750 (92.969)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [172][30/329], lr: 0.00010\tTime 0.108 (0.114)\tData 0.004 (0.024)\tLoss 0.1950 (0.1983)\tPrec@1 93.750 (93.271)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [172][40/329], lr: 0.00010\tTime 0.118 (0.108)\tData 0.012 (0.020)\tLoss 0.2840 (0.1995)\tPrec@1 89.844 (93.188)\tPrec@5 99.219 (99.809)\n",
            "Epoch: [172][50/329], lr: 0.00010\tTime 0.098 (0.103)\tData 0.007 (0.018)\tLoss 0.2103 (0.1954)\tPrec@1 92.578 (93.321)\tPrec@5 99.609 (99.809)\n",
            "Epoch: [172][60/329], lr: 0.00010\tTime 0.090 (0.101)\tData 0.007 (0.016)\tLoss 0.2510 (0.1968)\tPrec@1 91.797 (93.340)\tPrec@5 99.219 (99.808)\n",
            "Epoch: [172][70/329], lr: 0.00010\tTime 0.094 (0.099)\tData 0.000 (0.014)\tLoss 0.1696 (0.1931)\tPrec@1 94.531 (93.453)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [172][80/329], lr: 0.00010\tTime 0.108 (0.098)\tData 0.006 (0.013)\tLoss 0.2365 (0.1950)\tPrec@1 92.578 (93.393)\tPrec@5 99.219 (99.812)\n",
            "Epoch: [172][90/329], lr: 0.00010\tTime 0.086 (0.097)\tData 0.006 (0.013)\tLoss 0.2072 (0.1965)\tPrec@1 92.969 (93.316)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [172][100/329], lr: 0.00010\tTime 0.088 (0.096)\tData 0.007 (0.012)\tLoss 0.2103 (0.1955)\tPrec@1 92.188 (93.321)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [172][110/329], lr: 0.00010\tTime 0.086 (0.095)\tData 0.013 (0.012)\tLoss 0.2488 (0.1954)\tPrec@1 91.406 (93.342)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [172][120/329], lr: 0.00010\tTime 0.071 (0.094)\tData 0.009 (0.011)\tLoss 0.2353 (0.1952)\tPrec@1 91.406 (93.324)\tPrec@5 99.609 (99.826)\n",
            "Epoch: [172][130/329], lr: 0.00010\tTime 0.080 (0.094)\tData 0.002 (0.011)\tLoss 0.1579 (0.1953)\tPrec@1 94.141 (93.309)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [172][140/329], lr: 0.00010\tTime 0.080 (0.094)\tData 0.012 (0.011)\tLoss 0.1737 (0.1944)\tPrec@1 94.922 (93.351)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [172][150/329], lr: 0.00010\tTime 0.080 (0.093)\tData 0.005 (0.011)\tLoss 0.1993 (0.1950)\tPrec@1 92.969 (93.336)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [172][160/329], lr: 0.00010\tTime 0.109 (0.093)\tData 0.004 (0.011)\tLoss 0.2265 (0.1957)\tPrec@1 92.578 (93.321)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [172][170/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.007 (0.011)\tLoss 0.2386 (0.1953)\tPrec@1 92.188 (93.341)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [172][180/329], lr: 0.00010\tTime 0.079 (0.092)\tData 0.010 (0.011)\tLoss 0.2376 (0.1958)\tPrec@1 92.969 (93.344)\tPrec@5 99.219 (99.845)\n",
            "Epoch: [172][190/329], lr: 0.00010\tTime 0.072 (0.092)\tData 0.002 (0.010)\tLoss 0.2695 (0.1957)\tPrec@1 90.625 (93.339)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [172][200/329], lr: 0.00010\tTime 0.072 (0.092)\tData 0.006 (0.010)\tLoss 0.2473 (0.1967)\tPrec@1 92.188 (93.303)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [172][210/329], lr: 0.00010\tTime 0.084 (0.092)\tData 0.017 (0.010)\tLoss 0.2270 (0.1953)\tPrec@1 92.188 (93.333)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [172][220/329], lr: 0.00010\tTime 0.118 (0.092)\tData 0.008 (0.010)\tLoss 0.1790 (0.1944)\tPrec@1 93.750 (93.379)\tPrec@5 99.609 (99.839)\n",
            "Epoch: [172][230/329], lr: 0.00010\tTime 0.087 (0.092)\tData 0.004 (0.010)\tLoss 0.1727 (0.1939)\tPrec@1 94.141 (93.410)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [172][240/329], lr: 0.00010\tTime 0.097 (0.092)\tData 0.000 (0.010)\tLoss 0.2037 (0.1942)\tPrec@1 92.188 (93.418)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [172][250/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.000 (0.010)\tLoss 0.2019 (0.1937)\tPrec@1 93.359 (93.440)\tPrec@5 99.219 (99.837)\n",
            "Epoch: [172][260/329], lr: 0.00010\tTime 0.076 (0.091)\tData 0.007 (0.010)\tLoss 0.2368 (0.1941)\tPrec@1 91.406 (93.443)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [172][270/329], lr: 0.00010\tTime 0.083 (0.091)\tData 0.006 (0.010)\tLoss 0.1716 (0.1936)\tPrec@1 96.094 (93.462)\tPrec@5 99.219 (99.839)\n",
            "Epoch: [172][280/329], lr: 0.00010\tTime 0.077 (0.091)\tData 0.015 (0.010)\tLoss 0.1796 (0.1926)\tPrec@1 94.531 (93.490)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [172][290/329], lr: 0.00010\tTime 0.090 (0.091)\tData 0.007 (0.009)\tLoss 0.1594 (0.1919)\tPrec@1 93.750 (93.506)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [172][300/329], lr: 0.00010\tTime 0.097 (0.091)\tData 0.000 (0.009)\tLoss 0.2759 (0.1920)\tPrec@1 92.578 (93.525)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [172][310/329], lr: 0.00010\tTime 0.075 (0.091)\tData 0.007 (0.009)\tLoss 0.1942 (0.1920)\tPrec@1 91.797 (93.518)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [172][320/329], lr: 0.00010\tTime 0.104 (0.091)\tData 0.063 (0.009)\tLoss 0.1615 (0.1921)\tPrec@1 94.531 (93.504)\tPrec@5 100.000 (99.841)\n",
            "Test: [0/100]\tTime 0.397 (0.397)\tLoss 0.4378 (0.4378)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.044 (0.058)\tLoss 0.4920 (0.6283)\tPrec@1 86.000 (82.273)\tPrec@5 98.000 (99.182)\n",
            "Test: [20/100]\tTime 0.026 (0.043)\tLoss 0.6062 (0.6346)\tPrec@1 83.000 (81.810)\tPrec@5 100.000 (98.857)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 0.7922 (0.6528)\tPrec@1 76.000 (81.226)\tPrec@5 99.000 (98.806)\n",
            "Test: [40/100]\tTime 0.032 (0.033)\tLoss 0.6950 (0.6572)\tPrec@1 78.000 (81.098)\tPrec@5 98.000 (98.780)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 0.6411 (0.6506)\tPrec@1 84.000 (81.294)\tPrec@5 98.000 (98.804)\n",
            "Test: [60/100]\tTime 0.056 (0.031)\tLoss 0.5185 (0.6561)\tPrec@1 87.000 (80.705)\tPrec@5 100.000 (98.902)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 0.6908 (0.6493)\tPrec@1 79.000 (80.704)\tPrec@5 99.000 (98.901)\n",
            "Test: [80/100]\tTime 0.018 (0.030)\tLoss 0.5863 (0.6427)\tPrec@1 84.000 (80.914)\tPrec@5 99.000 (98.951)\n",
            "Test: [90/100]\tTime 0.039 (0.029)\tLoss 0.5211 (0.6512)\tPrec@1 86.000 (80.615)\tPrec@5 100.000 (98.923)\n",
            "val Results: Prec@1 80.560 Prec@5 98.900 Loss 0.64902\n",
            "val Class Accuracy: [0.959,0.974,0.869,0.764,0.828,0.729,0.810,0.702,0.683,0.738]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [173][0/329], lr: 0.00010\tTime 0.671 (0.671)\tData 0.581 (0.581)\tLoss 0.2029 (0.2029)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][10/329], lr: 0.00010\tTime 0.084 (0.151)\tData 0.000 (0.058)\tLoss 0.1365 (0.1746)\tPrec@1 96.484 (94.212)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [173][20/329], lr: 0.00010\tTime 0.098 (0.124)\tData 0.000 (0.034)\tLoss 0.2140 (0.1826)\tPrec@1 94.141 (93.917)\tPrec@5 99.219 (99.814)\n",
            "Epoch: [173][30/329], lr: 0.00010\tTime 0.094 (0.113)\tData 0.007 (0.025)\tLoss 0.2450 (0.1860)\tPrec@1 92.969 (93.964)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [173][40/329], lr: 0.00010\tTime 0.091 (0.107)\tData 0.004 (0.020)\tLoss 0.2369 (0.1804)\tPrec@1 92.578 (94.122)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [173][50/329], lr: 0.00010\tTime 0.085 (0.103)\tData 0.004 (0.017)\tLoss 0.2099 (0.1850)\tPrec@1 92.969 (94.033)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [173][60/329], lr: 0.00010\tTime 0.082 (0.101)\tData 0.000 (0.015)\tLoss 0.1463 (0.1856)\tPrec@1 94.922 (93.955)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [173][70/329], lr: 0.00010\tTime 0.095 (0.099)\tData 0.005 (0.014)\tLoss 0.1835 (0.1859)\tPrec@1 94.922 (93.926)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [173][80/329], lr: 0.00010\tTime 0.094 (0.098)\tData 0.002 (0.013)\tLoss 0.1851 (0.1863)\tPrec@1 95.312 (93.904)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [173][90/329], lr: 0.00010\tTime 0.077 (0.097)\tData 0.005 (0.013)\tLoss 0.2226 (0.1882)\tPrec@1 92.969 (93.759)\tPrec@5 99.609 (99.820)\n",
            "Epoch: [173][100/329], lr: 0.00010\tTime 0.071 (0.097)\tData 0.007 (0.012)\tLoss 0.2326 (0.1881)\tPrec@1 91.797 (93.731)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [173][110/329], lr: 0.00010\tTime 0.102 (0.096)\tData 0.007 (0.012)\tLoss 0.2265 (0.1888)\tPrec@1 92.578 (93.743)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [173][120/329], lr: 0.00010\tTime 0.076 (0.095)\tData 0.005 (0.012)\tLoss 0.2092 (0.1886)\tPrec@1 92.969 (93.756)\tPrec@5 99.609 (99.832)\n",
            "Epoch: [173][130/329], lr: 0.00010\tTime 0.101 (0.095)\tData 0.010 (0.012)\tLoss 0.1781 (0.1887)\tPrec@1 92.969 (93.753)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [173][140/329], lr: 0.00010\tTime 0.073 (0.094)\tData 0.015 (0.011)\tLoss 0.1952 (0.1897)\tPrec@1 94.141 (93.736)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [173][150/329], lr: 0.00010\tTime 0.114 (0.094)\tData 0.005 (0.011)\tLoss 0.2159 (0.1900)\tPrec@1 92.188 (93.729)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [173][160/329], lr: 0.00010\tTime 0.109 (0.094)\tData 0.007 (0.011)\tLoss 0.1954 (0.1903)\tPrec@1 92.578 (93.714)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [173][170/329], lr: 0.00010\tTime 0.111 (0.093)\tData 0.006 (0.011)\tLoss 0.1790 (0.1901)\tPrec@1 94.531 (93.704)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [173][180/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.011)\tLoss 0.2191 (0.1896)\tPrec@1 91.406 (93.709)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [173][190/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.011)\tLoss 0.2082 (0.1906)\tPrec@1 94.141 (93.658)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [173][200/329], lr: 0.00010\tTime 0.095 (0.093)\tData 0.005 (0.010)\tLoss 0.1508 (0.1907)\tPrec@1 94.531 (93.666)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [173][210/329], lr: 0.00010\tTime 0.082 (0.093)\tData 0.000 (0.010)\tLoss 0.2163 (0.1909)\tPrec@1 92.969 (93.654)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [173][220/329], lr: 0.00010\tTime 0.098 (0.093)\tData 0.007 (0.010)\tLoss 0.1651 (0.1915)\tPrec@1 94.922 (93.612)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [173][230/329], lr: 0.00010\tTime 0.086 (0.092)\tData 0.000 (0.010)\tLoss 0.2174 (0.1914)\tPrec@1 92.578 (93.591)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [173][240/329], lr: 0.00010\tTime 0.082 (0.093)\tData 0.006 (0.010)\tLoss 0.1580 (0.1911)\tPrec@1 94.531 (93.596)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [173][250/329], lr: 0.00010\tTime 0.078 (0.092)\tData 0.008 (0.010)\tLoss 0.2127 (0.1904)\tPrec@1 92.969 (93.619)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [173][260/329], lr: 0.00010\tTime 0.094 (0.093)\tData 0.005 (0.010)\tLoss 0.1983 (0.1904)\tPrec@1 94.531 (93.620)\tPrec@5 99.609 (99.826)\n",
            "Epoch: [173][270/329], lr: 0.00010\tTime 0.076 (0.092)\tData 0.000 (0.010)\tLoss 0.2024 (0.1903)\tPrec@1 95.312 (93.622)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [173][280/329], lr: 0.00010\tTime 0.093 (0.092)\tData 0.003 (0.010)\tLoss 0.2331 (0.1912)\tPrec@1 92.969 (93.590)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [173][290/329], lr: 0.00010\tTime 0.075 (0.092)\tData 0.003 (0.010)\tLoss 0.1563 (0.1914)\tPrec@1 94.141 (93.585)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [173][300/329], lr: 0.00010\tTime 0.083 (0.092)\tData 0.001 (0.010)\tLoss 0.1705 (0.1917)\tPrec@1 94.922 (93.583)\tPrec@5 100.000 (99.825)\n",
            "Epoch: [173][310/329], lr: 0.00010\tTime 0.086 (0.092)\tData 0.000 (0.009)\tLoss 0.0673 (0.1921)\tPrec@1 98.828 (93.568)\tPrec@5 100.000 (99.823)\n",
            "Epoch: [173][320/329], lr: 0.00010\tTime 0.131 (0.092)\tData 0.078 (0.010)\tLoss 0.1559 (0.1919)\tPrec@1 94.922 (93.564)\tPrec@5 100.000 (99.826)\n",
            "Test: [0/100]\tTime 0.619 (0.619)\tLoss 0.4470 (0.4470)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.041 (0.091)\tLoss 0.5280 (0.6698)\tPrec@1 82.000 (81.000)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.033 (0.067)\tLoss 0.6184 (0.6748)\tPrec@1 83.000 (80.476)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.027 (0.057)\tLoss 0.7719 (0.6925)\tPrec@1 76.000 (80.226)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.052 (0.051)\tLoss 0.7115 (0.6969)\tPrec@1 80.000 (80.122)\tPrec@5 99.000 (98.659)\n",
            "Test: [50/100]\tTime 0.031 (0.046)\tLoss 0.6606 (0.6912)\tPrec@1 83.000 (80.255)\tPrec@5 98.000 (98.667)\n",
            "Test: [60/100]\tTime 0.013 (0.042)\tLoss 0.5335 (0.6949)\tPrec@1 84.000 (79.623)\tPrec@5 100.000 (98.754)\n",
            "Test: [70/100]\tTime 0.034 (0.040)\tLoss 0.7738 (0.6888)\tPrec@1 81.000 (79.732)\tPrec@5 99.000 (98.789)\n",
            "Test: [80/100]\tTime 0.024 (0.038)\tLoss 0.5995 (0.6832)\tPrec@1 83.000 (79.988)\tPrec@5 99.000 (98.827)\n",
            "Test: [90/100]\tTime 0.025 (0.036)\tLoss 0.5843 (0.6924)\tPrec@1 84.000 (79.857)\tPrec@5 100.000 (98.813)\n",
            "val Results: Prec@1 79.770 Prec@5 98.790 Loss 0.69107\n",
            "val Class Accuracy: [0.964,0.986,0.846,0.754,0.825,0.735,0.828,0.684,0.696,0.659]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [174][0/329], lr: 0.00010\tTime 0.703 (0.703)\tData 0.653 (0.653)\tLoss 0.1194 (0.1194)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][10/329], lr: 0.00010\tTime 0.072 (0.150)\tData 0.000 (0.065)\tLoss 0.1687 (0.1992)\tPrec@1 93.750 (93.004)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [174][20/329], lr: 0.00010\tTime 0.084 (0.125)\tData 0.001 (0.038)\tLoss 0.2003 (0.1915)\tPrec@1 92.578 (93.471)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [174][30/329], lr: 0.00010\tTime 0.084 (0.114)\tData 0.000 (0.028)\tLoss 0.2555 (0.1983)\tPrec@1 89.453 (93.208)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [174][40/329], lr: 0.00010\tTime 0.087 (0.108)\tData 0.007 (0.023)\tLoss 0.1971 (0.2020)\tPrec@1 92.578 (93.169)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [174][50/329], lr: 0.00010\tTime 0.092 (0.104)\tData 0.007 (0.020)\tLoss 0.1935 (0.1953)\tPrec@1 90.234 (93.382)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [174][60/329], lr: 0.00010\tTime 0.075 (0.102)\tData 0.004 (0.018)\tLoss 0.1112 (0.1934)\tPrec@1 96.484 (93.455)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [174][70/329], lr: 0.00010\tTime 0.077 (0.100)\tData 0.000 (0.017)\tLoss 0.1617 (0.1946)\tPrec@1 96.094 (93.486)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [174][80/329], lr: 0.00010\tTime 0.090 (0.099)\tData 0.000 (0.015)\tLoss 0.1797 (0.1943)\tPrec@1 92.188 (93.533)\tPrec@5 99.609 (99.817)\n",
            "Epoch: [174][90/329], lr: 0.00010\tTime 0.099 (0.097)\tData 0.006 (0.014)\tLoss 0.1814 (0.1927)\tPrec@1 93.750 (93.595)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [174][100/329], lr: 0.00010\tTime 0.080 (0.096)\tData 0.008 (0.014)\tLoss 0.2316 (0.1930)\tPrec@1 92.188 (93.599)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [174][110/329], lr: 0.00010\tTime 0.093 (0.096)\tData 0.012 (0.013)\tLoss 0.1703 (0.1931)\tPrec@1 93.750 (93.599)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [174][120/329], lr: 0.00010\tTime 0.088 (0.095)\tData 0.006 (0.012)\tLoss 0.2174 (0.1944)\tPrec@1 92.578 (93.582)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [174][130/329], lr: 0.00010\tTime 0.099 (0.095)\tData 0.009 (0.012)\tLoss 0.1717 (0.1932)\tPrec@1 94.531 (93.607)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [174][140/329], lr: 0.00010\tTime 0.083 (0.094)\tData 0.006 (0.012)\tLoss 0.1897 (0.1920)\tPrec@1 92.188 (93.620)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [174][150/329], lr: 0.00010\tTime 0.076 (0.094)\tData 0.013 (0.012)\tLoss 0.1880 (0.1925)\tPrec@1 93.359 (93.600)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [174][160/329], lr: 0.00010\tTime 0.109 (0.094)\tData 0.006 (0.011)\tLoss 0.1742 (0.1915)\tPrec@1 93.750 (93.597)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [174][170/329], lr: 0.00010\tTime 0.077 (0.094)\tData 0.000 (0.011)\tLoss 0.2147 (0.1914)\tPrec@1 93.359 (93.604)\tPrec@5 99.219 (99.845)\n",
            "Epoch: [174][180/329], lr: 0.00010\tTime 0.087 (0.093)\tData 0.007 (0.011)\tLoss 0.1776 (0.1910)\tPrec@1 93.359 (93.597)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [174][190/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 0.1864 (0.1906)\tPrec@1 92.578 (93.580)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [174][200/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.005 (0.010)\tLoss 0.2008 (0.1905)\tPrec@1 92.969 (93.558)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [174][210/329], lr: 0.00010\tTime 0.083 (0.092)\tData 0.001 (0.010)\tLoss 0.2149 (0.1905)\tPrec@1 92.578 (93.548)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [174][220/329], lr: 0.00010\tTime 0.105 (0.092)\tData 0.006 (0.010)\tLoss 0.2355 (0.1907)\tPrec@1 92.969 (93.533)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [174][230/329], lr: 0.00010\tTime 0.079 (0.092)\tData 0.005 (0.010)\tLoss 0.2521 (0.1907)\tPrec@1 92.578 (93.545)\tPrec@5 99.219 (99.841)\n",
            "Epoch: [174][240/329], lr: 0.00010\tTime 0.075 (0.092)\tData 0.001 (0.010)\tLoss 0.2155 (0.1906)\tPrec@1 92.188 (93.551)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [174][250/329], lr: 0.00010\tTime 0.094 (0.092)\tData 0.006 (0.010)\tLoss 0.1452 (0.1911)\tPrec@1 95.312 (93.541)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [174][260/329], lr: 0.00010\tTime 0.097 (0.091)\tData 0.007 (0.010)\tLoss 0.1371 (0.1910)\tPrec@1 96.094 (93.543)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [174][270/329], lr: 0.00010\tTime 0.080 (0.091)\tData 0.007 (0.010)\tLoss 0.1778 (0.1908)\tPrec@1 93.750 (93.537)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [174][280/329], lr: 0.00010\tTime 0.109 (0.091)\tData 0.011 (0.010)\tLoss 0.2042 (0.1911)\tPrec@1 92.188 (93.514)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [174][290/329], lr: 0.00010\tTime 0.072 (0.091)\tData 0.000 (0.009)\tLoss 0.1692 (0.1909)\tPrec@1 93.359 (93.518)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [174][300/329], lr: 0.00010\tTime 0.108 (0.091)\tData 0.012 (0.009)\tLoss 0.2578 (0.1914)\tPrec@1 92.188 (93.497)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [174][310/329], lr: 0.00010\tTime 0.081 (0.091)\tData 0.004 (0.009)\tLoss 0.1815 (0.1916)\tPrec@1 92.969 (93.499)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [174][320/329], lr: 0.00010\tTime 0.090 (0.091)\tData 0.053 (0.009)\tLoss 0.2333 (0.1919)\tPrec@1 89.844 (93.485)\tPrec@5 100.000 (99.841)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 0.4482 (0.4482)\tPrec@1 86.000 (86.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.059)\tLoss 0.5033 (0.6479)\tPrec@1 83.000 (81.455)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.022 (0.044)\tLoss 0.6404 (0.6449)\tPrec@1 80.000 (81.381)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.042 (0.038)\tLoss 0.8410 (0.6640)\tPrec@1 78.000 (81.065)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 0.6952 (0.6708)\tPrec@1 78.000 (80.854)\tPrec@5 98.000 (98.585)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 0.6562 (0.6629)\tPrec@1 84.000 (80.961)\tPrec@5 98.000 (98.627)\n",
            "Test: [60/100]\tTime 0.041 (0.031)\tLoss 0.5330 (0.6668)\tPrec@1 87.000 (80.443)\tPrec@5 100.000 (98.738)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 0.6807 (0.6605)\tPrec@1 81.000 (80.549)\tPrec@5 100.000 (98.789)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 0.6030 (0.6540)\tPrec@1 86.000 (80.691)\tPrec@5 99.000 (98.864)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 0.5288 (0.6619)\tPrec@1 87.000 (80.440)\tPrec@5 100.000 (98.824)\n",
            "val Results: Prec@1 80.430 Prec@5 98.840 Loss 0.65863\n",
            "val Class Accuracy: [0.941,0.985,0.862,0.770,0.820,0.775,0.796,0.685,0.694,0.715]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [175][0/329], lr: 0.00010\tTime 0.705 (0.705)\tData 0.601 (0.601)\tLoss 0.2002 (0.2002)\tPrec@1 93.359 (93.359)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][10/329], lr: 0.00010\tTime 0.094 (0.155)\tData 0.005 (0.059)\tLoss 0.2516 (0.1908)\tPrec@1 92.188 (93.821)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [175][20/329], lr: 0.00010\tTime 0.093 (0.124)\tData 0.005 (0.034)\tLoss 0.1694 (0.1800)\tPrec@1 93.359 (94.103)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [175][30/329], lr: 0.00010\tTime 0.084 (0.112)\tData 0.000 (0.025)\tLoss 0.2371 (0.1783)\tPrec@1 92.188 (94.216)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [175][40/329], lr: 0.00010\tTime 0.073 (0.107)\tData 0.003 (0.020)\tLoss 0.1185 (0.1848)\tPrec@1 96.484 (93.950)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [175][50/329], lr: 0.00010\tTime 0.087 (0.104)\tData 0.004 (0.018)\tLoss 0.1896 (0.1870)\tPrec@1 92.969 (93.742)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [175][60/329], lr: 0.00010\tTime 0.095 (0.102)\tData 0.000 (0.016)\tLoss 0.1475 (0.1857)\tPrec@1 94.922 (93.833)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [175][70/329], lr: 0.00010\tTime 0.095 (0.099)\tData 0.007 (0.015)\tLoss 0.2219 (0.1853)\tPrec@1 92.188 (93.822)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [175][80/329], lr: 0.00010\tTime 0.089 (0.098)\tData 0.003 (0.014)\tLoss 0.2136 (0.1842)\tPrec@1 92.578 (93.895)\tPrec@5 99.219 (99.812)\n",
            "Epoch: [175][90/329], lr: 0.00010\tTime 0.077 (0.097)\tData 0.000 (0.013)\tLoss 0.1708 (0.1845)\tPrec@1 95.703 (93.896)\tPrec@5 99.609 (99.820)\n",
            "Epoch: [175][100/329], lr: 0.00010\tTime 0.091 (0.096)\tData 0.000 (0.012)\tLoss 0.1531 (0.1861)\tPrec@1 94.141 (93.854)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [175][110/329], lr: 0.00010\tTime 0.115 (0.096)\tData 0.004 (0.012)\tLoss 0.2028 (0.1869)\tPrec@1 94.531 (93.873)\tPrec@5 99.609 (99.817)\n",
            "Epoch: [175][120/329], lr: 0.00010\tTime 0.103 (0.095)\tData 0.007 (0.011)\tLoss 0.1608 (0.1852)\tPrec@1 94.141 (93.857)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [175][130/329], lr: 0.00010\tTime 0.101 (0.095)\tData 0.006 (0.011)\tLoss 0.1739 (0.1862)\tPrec@1 94.922 (93.863)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [175][140/329], lr: 0.00010\tTime 0.093 (0.094)\tData 0.006 (0.011)\tLoss 0.1941 (0.1864)\tPrec@1 93.359 (93.822)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [175][150/329], lr: 0.00010\tTime 0.089 (0.094)\tData 0.014 (0.010)\tLoss 0.2145 (0.1853)\tPrec@1 92.578 (93.874)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [175][160/329], lr: 0.00010\tTime 0.080 (0.094)\tData 0.000 (0.010)\tLoss 0.1554 (0.1865)\tPrec@1 94.922 (93.825)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [175][170/329], lr: 0.00010\tTime 0.089 (0.094)\tData 0.006 (0.010)\tLoss 0.2091 (0.1878)\tPrec@1 93.359 (93.743)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [175][180/329], lr: 0.00010\tTime 0.093 (0.093)\tData 0.000 (0.010)\tLoss 0.1515 (0.1878)\tPrec@1 95.703 (93.744)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [175][190/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.012 (0.010)\tLoss 0.2666 (0.1874)\tPrec@1 91.406 (93.756)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [175][200/329], lr: 0.00010\tTime 0.098 (0.093)\tData 0.012 (0.009)\tLoss 0.1575 (0.1869)\tPrec@1 94.922 (93.752)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [175][210/329], lr: 0.00010\tTime 0.093 (0.093)\tData 0.000 (0.009)\tLoss 0.1175 (0.1868)\tPrec@1 97.266 (93.767)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [175][220/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.005 (0.009)\tLoss 0.1768 (0.1872)\tPrec@1 94.141 (93.741)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [175][230/329], lr: 0.00010\tTime 0.099 (0.093)\tData 0.007 (0.009)\tLoss 0.2437 (0.1874)\tPrec@1 93.359 (93.750)\tPrec@5 99.219 (99.834)\n",
            "Epoch: [175][240/329], lr: 0.00010\tTime 0.111 (0.093)\tData 0.012 (0.009)\tLoss 0.1888 (0.1880)\tPrec@1 92.969 (93.739)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [175][250/329], lr: 0.00010\tTime 0.070 (0.092)\tData 0.005 (0.009)\tLoss 0.1535 (0.1879)\tPrec@1 93.359 (93.734)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [175][260/329], lr: 0.00010\tTime 0.099 (0.092)\tData 0.000 (0.009)\tLoss 0.1857 (0.1876)\tPrec@1 93.359 (93.735)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [175][270/329], lr: 0.00010\tTime 0.093 (0.092)\tData 0.004 (0.009)\tLoss 0.1999 (0.1879)\tPrec@1 94.141 (93.737)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [175][280/329], lr: 0.00010\tTime 0.083 (0.092)\tData 0.000 (0.009)\tLoss 0.2029 (0.1882)\tPrec@1 93.359 (93.717)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [175][290/329], lr: 0.00010\tTime 0.097 (0.092)\tData 0.000 (0.009)\tLoss 0.1340 (0.1883)\tPrec@1 95.703 (93.720)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [175][300/329], lr: 0.00010\tTime 0.089 (0.092)\tData 0.005 (0.009)\tLoss 0.2017 (0.1883)\tPrec@1 92.578 (93.718)\tPrec@5 99.609 (99.844)\n",
            "Epoch: [175][310/329], lr: 0.00010\tTime 0.107 (0.092)\tData 0.009 (0.009)\tLoss 0.1613 (0.1886)\tPrec@1 96.094 (93.710)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [175][320/329], lr: 0.00010\tTime 0.098 (0.092)\tData 0.058 (0.009)\tLoss 0.2073 (0.1883)\tPrec@1 94.141 (93.727)\tPrec@5 99.609 (99.838)\n",
            "Test: [0/100]\tTime 0.356 (0.356)\tLoss 0.4410 (0.4410)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 0.5005 (0.6302)\tPrec@1 83.000 (81.636)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.031 (0.043)\tLoss 0.6167 (0.6353)\tPrec@1 81.000 (81.857)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.041 (0.037)\tLoss 0.7665 (0.6515)\tPrec@1 78.000 (81.323)\tPrec@5 99.000 (98.677)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 0.7074 (0.6564)\tPrec@1 77.000 (81.073)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 0.6120 (0.6507)\tPrec@1 84.000 (81.078)\tPrec@5 98.000 (98.706)\n",
            "Test: [60/100]\tTime 0.036 (0.031)\tLoss 0.5217 (0.6544)\tPrec@1 87.000 (80.754)\tPrec@5 100.000 (98.820)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 0.6935 (0.6496)\tPrec@1 81.000 (80.746)\tPrec@5 99.000 (98.859)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 0.5645 (0.6439)\tPrec@1 87.000 (80.951)\tPrec@5 99.000 (98.914)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 0.5220 (0.6532)\tPrec@1 87.000 (80.769)\tPrec@5 100.000 (98.879)\n",
            "val Results: Prec@1 80.750 Prec@5 98.870 Loss 0.65132\n",
            "val Class Accuracy: [0.957,0.982,0.872,0.710,0.822,0.772,0.845,0.718,0.672,0.725]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [176][0/329], lr: 0.00010\tTime 0.670 (0.670)\tData 0.597 (0.597)\tLoss 0.1158 (0.1158)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][10/329], lr: 0.00010\tTime 0.093 (0.148)\tData 0.000 (0.057)\tLoss 0.1960 (0.1860)\tPrec@1 92.578 (93.750)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [176][20/329], lr: 0.00010\tTime 0.083 (0.121)\tData 0.000 (0.032)\tLoss 0.1981 (0.1826)\tPrec@1 93.750 (94.029)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [176][30/329], lr: 0.00010\tTime 0.092 (0.111)\tData 0.000 (0.025)\tLoss 0.2057 (0.1831)\tPrec@1 92.969 (93.901)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [176][40/329], lr: 0.00010\tTime 0.106 (0.106)\tData 0.000 (0.021)\tLoss 0.2556 (0.1836)\tPrec@1 92.188 (93.864)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [176][50/329], lr: 0.00010\tTime 0.110 (0.103)\tData 0.009 (0.018)\tLoss 0.2020 (0.1822)\tPrec@1 92.578 (93.972)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [176][60/329], lr: 0.00010\tTime 0.078 (0.100)\tData 0.000 (0.016)\tLoss 0.1774 (0.1822)\tPrec@1 93.359 (93.904)\tPrec@5 99.609 (99.821)\n",
            "Epoch: [176][70/329], lr: 0.00010\tTime 0.111 (0.099)\tData 0.000 (0.014)\tLoss 0.1954 (0.1842)\tPrec@1 94.141 (93.822)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [176][80/329], lr: 0.00010\tTime 0.090 (0.098)\tData 0.010 (0.014)\tLoss 0.2065 (0.1841)\tPrec@1 93.359 (93.822)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [176][90/329], lr: 0.00010\tTime 0.077 (0.097)\tData 0.006 (0.013)\tLoss 0.1354 (0.1859)\tPrec@1 94.922 (93.771)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [176][100/329], lr: 0.00010\tTime 0.087 (0.096)\tData 0.003 (0.012)\tLoss 0.1894 (0.1852)\tPrec@1 92.969 (93.735)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [176][110/329], lr: 0.00010\tTime 0.087 (0.096)\tData 0.006 (0.012)\tLoss 0.1982 (0.1870)\tPrec@1 92.969 (93.697)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [176][120/329], lr: 0.00010\tTime 0.094 (0.095)\tData 0.006 (0.011)\tLoss 0.2797 (0.1888)\tPrec@1 89.844 (93.621)\tPrec@5 99.219 (99.832)\n",
            "Epoch: [176][130/329], lr: 0.00010\tTime 0.081 (0.095)\tData 0.007 (0.011)\tLoss 0.1264 (0.1897)\tPrec@1 95.703 (93.559)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [176][140/329], lr: 0.00010\tTime 0.097 (0.094)\tData 0.006 (0.011)\tLoss 0.1738 (0.1903)\tPrec@1 93.359 (93.523)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [176][150/329], lr: 0.00010\tTime 0.094 (0.094)\tData 0.000 (0.010)\tLoss 0.2231 (0.1902)\tPrec@1 92.188 (93.533)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [176][160/329], lr: 0.00010\tTime 0.086 (0.093)\tData 0.002 (0.010)\tLoss 0.2186 (0.1904)\tPrec@1 92.969 (93.549)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [176][170/329], lr: 0.00010\tTime 0.096 (0.093)\tData 0.000 (0.010)\tLoss 0.1431 (0.1894)\tPrec@1 94.922 (93.579)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [176][180/329], lr: 0.00010\tTime 0.092 (0.093)\tData 0.000 (0.010)\tLoss 0.1491 (0.1896)\tPrec@1 94.531 (93.577)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [176][190/329], lr: 0.00010\tTime 0.102 (0.093)\tData 0.008 (0.010)\tLoss 0.2422 (0.1894)\tPrec@1 92.188 (93.588)\tPrec@5 99.219 (99.840)\n",
            "Epoch: [176][200/329], lr: 0.00010\tTime 0.089 (0.093)\tData 0.001 (0.010)\tLoss 0.1667 (0.1894)\tPrec@1 95.312 (93.595)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [176][210/329], lr: 0.00010\tTime 0.073 (0.092)\tData 0.006 (0.010)\tLoss 0.2094 (0.1896)\tPrec@1 92.969 (93.580)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [176][220/329], lr: 0.00010\tTime 0.104 (0.092)\tData 0.000 (0.010)\tLoss 0.2691 (0.1897)\tPrec@1 92.188 (93.570)\tPrec@5 99.219 (99.830)\n",
            "Epoch: [176][230/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.009 (0.009)\tLoss 0.1274 (0.1892)\tPrec@1 96.094 (93.589)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [176][240/329], lr: 0.00010\tTime 0.079 (0.092)\tData 0.006 (0.009)\tLoss 0.2104 (0.1891)\tPrec@1 92.188 (93.607)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [176][250/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.006 (0.009)\tLoss 0.1621 (0.1893)\tPrec@1 94.922 (93.583)\tPrec@5 99.609 (99.827)\n",
            "Epoch: [176][260/329], lr: 0.00010\tTime 0.100 (0.092)\tData 0.000 (0.009)\tLoss 0.2187 (0.1893)\tPrec@1 93.359 (93.590)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [176][270/329], lr: 0.00010\tTime 0.077 (0.092)\tData 0.006 (0.009)\tLoss 0.2166 (0.1891)\tPrec@1 94.531 (93.574)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [176][280/329], lr: 0.00010\tTime 0.080 (0.091)\tData 0.008 (0.009)\tLoss 0.2125 (0.1901)\tPrec@1 92.578 (93.532)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [176][290/329], lr: 0.00010\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 0.2694 (0.1903)\tPrec@1 89.844 (93.531)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [176][300/329], lr: 0.00010\tTime 0.104 (0.091)\tData 0.004 (0.009)\tLoss 0.2819 (0.1901)\tPrec@1 89.453 (93.540)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [176][310/329], lr: 0.00010\tTime 0.089 (0.091)\tData 0.007 (0.009)\tLoss 0.2295 (0.1902)\tPrec@1 91.406 (93.540)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [176][320/329], lr: 0.00010\tTime 0.076 (0.091)\tData 0.037 (0.009)\tLoss 0.1899 (0.1897)\tPrec@1 92.969 (93.565)\tPrec@5 100.000 (99.838)\n",
            "Test: [0/100]\tTime 0.392 (0.392)\tLoss 0.4586 (0.4586)\tPrec@1 84.000 (84.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.029 (0.061)\tLoss 0.5182 (0.6653)\tPrec@1 84.000 (80.727)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.036 (0.043)\tLoss 0.6352 (0.6692)\tPrec@1 82.000 (80.857)\tPrec@5 100.000 (98.619)\n",
            "Test: [30/100]\tTime 0.041 (0.038)\tLoss 0.8348 (0.6869)\tPrec@1 74.000 (80.355)\tPrec@5 99.000 (98.581)\n",
            "Test: [40/100]\tTime 0.032 (0.034)\tLoss 0.7412 (0.6933)\tPrec@1 75.000 (80.244)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/100]\tTime 0.020 (0.033)\tLoss 0.7046 (0.6861)\tPrec@1 83.000 (80.373)\tPrec@5 98.000 (98.549)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 0.5304 (0.6914)\tPrec@1 85.000 (79.852)\tPrec@5 100.000 (98.656)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 0.7355 (0.6858)\tPrec@1 79.000 (79.831)\tPrec@5 99.000 (98.648)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 0.6476 (0.6791)\tPrec@1 84.000 (79.988)\tPrec@5 99.000 (98.741)\n",
            "Test: [90/100]\tTime 0.017 (0.029)\tLoss 0.5463 (0.6875)\tPrec@1 87.000 (79.791)\tPrec@5 100.000 (98.714)\n",
            "val Results: Prec@1 79.730 Prec@5 98.720 Loss 0.68571\n",
            "val Class Accuracy: [0.956,0.965,0.877,0.767,0.800,0.754,0.832,0.668,0.661,0.693]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [177][0/329], lr: 0.00010\tTime 0.661 (0.661)\tData 0.577 (0.577)\tLoss 0.2171 (0.2171)\tPrec@1 92.969 (92.969)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [177][10/329], lr: 0.00010\tTime 0.106 (0.148)\tData 0.000 (0.059)\tLoss 0.1403 (0.1873)\tPrec@1 96.094 (93.750)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [177][20/329], lr: 0.00010\tTime 0.097 (0.122)\tData 0.004 (0.033)\tLoss 0.1594 (0.1829)\tPrec@1 95.312 (93.899)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [177][30/329], lr: 0.00010\tTime 0.078 (0.113)\tData 0.000 (0.024)\tLoss 0.2267 (0.1823)\tPrec@1 92.188 (93.851)\tPrec@5 99.609 (99.874)\n",
            "Epoch: [177][40/329], lr: 0.00010\tTime 0.077 (0.108)\tData 0.008 (0.020)\tLoss 0.2059 (0.1806)\tPrec@1 92.578 (93.855)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [177][50/329], lr: 0.00010\tTime 0.088 (0.105)\tData 0.006 (0.017)\tLoss 0.1598 (0.1827)\tPrec@1 95.312 (93.850)\tPrec@5 99.609 (99.809)\n",
            "Epoch: [177][60/329], lr: 0.00010\tTime 0.084 (0.102)\tData 0.004 (0.016)\tLoss 0.1246 (0.1832)\tPrec@1 96.094 (93.852)\tPrec@5 99.609 (99.827)\n",
            "Epoch: [177][70/329], lr: 0.00010\tTime 0.079 (0.100)\tData 0.000 (0.015)\tLoss 0.1905 (0.1836)\tPrec@1 94.531 (93.943)\tPrec@5 99.219 (99.818)\n",
            "Epoch: [177][80/329], lr: 0.00010\tTime 0.089 (0.099)\tData 0.005 (0.014)\tLoss 0.2390 (0.1849)\tPrec@1 92.969 (93.890)\tPrec@5 99.219 (99.826)\n",
            "Epoch: [177][90/329], lr: 0.00010\tTime 0.081 (0.098)\tData 0.001 (0.013)\tLoss 0.1925 (0.1856)\tPrec@1 92.969 (93.853)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [177][100/329], lr: 0.00010\tTime 0.099 (0.097)\tData 0.010 (0.012)\tLoss 0.2091 (0.1854)\tPrec@1 91.797 (93.866)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [177][110/329], lr: 0.00010\tTime 0.096 (0.097)\tData 0.013 (0.012)\tLoss 0.2173 (0.1855)\tPrec@1 93.750 (93.852)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [177][120/329], lr: 0.00010\tTime 0.107 (0.096)\tData 0.000 (0.011)\tLoss 0.2135 (0.1859)\tPrec@1 92.578 (93.831)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [177][130/329], lr: 0.00010\tTime 0.100 (0.096)\tData 0.007 (0.011)\tLoss 0.1448 (0.1862)\tPrec@1 94.531 (93.756)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [177][140/329], lr: 0.00010\tTime 0.103 (0.095)\tData 0.006 (0.011)\tLoss 0.2147 (0.1860)\tPrec@1 93.750 (93.769)\tPrec@5 99.609 (99.853)\n",
            "Epoch: [177][150/329], lr: 0.00010\tTime 0.089 (0.095)\tData 0.007 (0.011)\tLoss 0.2277 (0.1867)\tPrec@1 92.578 (93.758)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [177][160/329], lr: 0.00010\tTime 0.090 (0.094)\tData 0.006 (0.010)\tLoss 0.1402 (0.1864)\tPrec@1 95.312 (93.782)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [177][170/329], lr: 0.00010\tTime 0.095 (0.094)\tData 0.002 (0.010)\tLoss 0.2453 (0.1864)\tPrec@1 92.188 (93.768)\tPrec@5 99.609 (99.856)\n",
            "Epoch: [177][180/329], lr: 0.00010\tTime 0.067 (0.094)\tData 0.000 (0.010)\tLoss 0.1874 (0.1856)\tPrec@1 93.750 (93.787)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [177][190/329], lr: 0.00010\tTime 0.105 (0.094)\tData 0.011 (0.010)\tLoss 0.1852 (0.1854)\tPrec@1 91.797 (93.756)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [177][200/329], lr: 0.00010\tTime 0.089 (0.094)\tData 0.009 (0.010)\tLoss 0.1477 (0.1854)\tPrec@1 95.312 (93.769)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [177][210/329], lr: 0.00010\tTime 0.091 (0.094)\tData 0.007 (0.009)\tLoss 0.2112 (0.1862)\tPrec@1 92.578 (93.750)\tPrec@5 99.219 (99.865)\n",
            "Epoch: [177][220/329], lr: 0.00010\tTime 0.089 (0.093)\tData 0.000 (0.009)\tLoss 0.1373 (0.1864)\tPrec@1 96.875 (93.755)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [177][230/329], lr: 0.00010\tTime 0.091 (0.093)\tData 0.012 (0.009)\tLoss 0.1694 (0.1873)\tPrec@1 94.531 (93.721)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [177][240/329], lr: 0.00010\tTime 0.065 (0.093)\tData 0.000 (0.009)\tLoss 0.2236 (0.1872)\tPrec@1 92.969 (93.739)\tPrec@5 99.609 (99.869)\n",
            "Epoch: [177][250/329], lr: 0.00010\tTime 0.077 (0.093)\tData 0.014 (0.009)\tLoss 0.1948 (0.1874)\tPrec@1 93.359 (93.733)\tPrec@5 100.000 (99.871)\n",
            "Epoch: [177][260/329], lr: 0.00010\tTime 0.101 (0.093)\tData 0.007 (0.009)\tLoss 0.1951 (0.1880)\tPrec@1 91.797 (93.711)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [177][270/329], lr: 0.00010\tTime 0.084 (0.093)\tData 0.000 (0.009)\tLoss 0.2008 (0.1888)\tPrec@1 93.359 (93.692)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [177][280/329], lr: 0.00010\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 0.2077 (0.1889)\tPrec@1 93.359 (93.685)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [177][290/329], lr: 0.00010\tTime 0.077 (0.093)\tData 0.000 (0.009)\tLoss 0.1805 (0.1891)\tPrec@1 93.750 (93.675)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [177][300/329], lr: 0.00010\tTime 0.100 (0.092)\tData 0.001 (0.009)\tLoss 0.1667 (0.1891)\tPrec@1 93.750 (93.690)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [177][310/329], lr: 0.00010\tTime 0.097 (0.092)\tData 0.005 (0.009)\tLoss 0.1245 (0.1889)\tPrec@1 95.703 (93.687)\tPrec@5 99.609 (99.853)\n",
            "Epoch: [177][320/329], lr: 0.00010\tTime 0.099 (0.092)\tData 0.056 (0.009)\tLoss 0.1476 (0.1889)\tPrec@1 94.922 (93.681)\tPrec@5 100.000 (99.853)\n",
            "Test: [0/100]\tTime 0.404 (0.404)\tLoss 0.4426 (0.4426)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.011 (0.057)\tLoss 0.4929 (0.6294)\tPrec@1 84.000 (80.636)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.040 (0.041)\tLoss 0.6268 (0.6323)\tPrec@1 81.000 (81.190)\tPrec@5 100.000 (98.905)\n",
            "Test: [30/100]\tTime 0.027 (0.036)\tLoss 0.7716 (0.6479)\tPrec@1 75.000 (80.806)\tPrec@5 99.000 (98.806)\n",
            "Test: [40/100]\tTime 0.034 (0.033)\tLoss 0.6935 (0.6544)\tPrec@1 78.000 (80.829)\tPrec@5 99.000 (98.805)\n",
            "Test: [50/100]\tTime 0.020 (0.032)\tLoss 0.6522 (0.6476)\tPrec@1 82.000 (80.941)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.040 (0.031)\tLoss 0.5304 (0.6522)\tPrec@1 86.000 (80.557)\tPrec@5 100.000 (98.820)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 0.7087 (0.6458)\tPrec@1 82.000 (80.718)\tPrec@5 99.000 (98.859)\n",
            "Test: [80/100]\tTime 0.036 (0.030)\tLoss 0.5505 (0.6392)\tPrec@1 88.000 (80.975)\tPrec@5 99.000 (98.914)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 0.4954 (0.6472)\tPrec@1 87.000 (80.780)\tPrec@5 100.000 (98.879)\n",
            "val Results: Prec@1 80.760 Prec@5 98.860 Loss 0.64443\n",
            "val Class Accuracy: [0.947,0.982,0.876,0.747,0.826,0.724,0.841,0.666,0.733,0.734]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [178][0/329], lr: 0.00010\tTime 0.620 (0.620)\tData 0.536 (0.536)\tLoss 0.2310 (0.2310)\tPrec@1 91.797 (91.797)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][10/329], lr: 0.00010\tTime 0.082 (0.139)\tData 0.005 (0.054)\tLoss 0.1934 (0.1897)\tPrec@1 93.750 (93.537)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [178][20/329], lr: 0.00010\tTime 0.084 (0.118)\tData 0.003 (0.034)\tLoss 0.2378 (0.1889)\tPrec@1 91.797 (93.545)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [178][30/329], lr: 0.00010\tTime 0.101 (0.112)\tData 0.000 (0.025)\tLoss 0.1816 (0.1835)\tPrec@1 93.359 (93.775)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [178][40/329], lr: 0.00010\tTime 0.113 (0.114)\tData 0.002 (0.021)\tLoss 0.1735 (0.1841)\tPrec@1 94.141 (93.788)\tPrec@5 99.609 (99.876)\n",
            "Epoch: [178][50/329], lr: 0.00010\tTime 0.138 (0.117)\tData 0.027 (0.022)\tLoss 0.1948 (0.1870)\tPrec@1 92.188 (93.681)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [178][60/329], lr: 0.00010\tTime 0.088 (0.116)\tData 0.000 (0.020)\tLoss 0.2148 (0.1867)\tPrec@1 91.016 (93.686)\tPrec@5 99.609 (99.878)\n",
            "Epoch: [178][70/329], lr: 0.00010\tTime 0.096 (0.113)\tData 0.004 (0.018)\tLoss 0.1637 (0.1867)\tPrec@1 94.141 (93.684)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [178][80/329], lr: 0.00010\tTime 0.100 (0.111)\tData 0.014 (0.017)\tLoss 0.1452 (0.1862)\tPrec@1 95.312 (93.726)\tPrec@5 100.000 (99.875)\n",
            "Epoch: [178][90/329], lr: 0.00010\tTime 0.105 (0.108)\tData 0.004 (0.016)\tLoss 0.1757 (0.1864)\tPrec@1 94.531 (93.716)\tPrec@5 100.000 (99.880)\n",
            "Epoch: [178][100/329], lr: 0.00010\tTime 0.110 (0.106)\tData 0.000 (0.014)\tLoss 0.1785 (0.1877)\tPrec@1 92.969 (93.677)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [178][110/329], lr: 0.00010\tTime 0.102 (0.105)\tData 0.007 (0.014)\tLoss 0.2096 (0.1871)\tPrec@1 92.578 (93.704)\tPrec@5 99.609 (99.887)\n",
            "Epoch: [178][120/329], lr: 0.00010\tTime 0.076 (0.104)\tData 0.000 (0.013)\tLoss 0.1543 (0.1867)\tPrec@1 94.922 (93.708)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [178][130/329], lr: 0.00010\tTime 0.082 (0.103)\tData 0.000 (0.013)\tLoss 0.2391 (0.1885)\tPrec@1 91.406 (93.652)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [178][140/329], lr: 0.00010\tTime 0.127 (0.102)\tData 0.006 (0.012)\tLoss 0.1431 (0.1866)\tPrec@1 95.703 (93.722)\tPrec@5 99.609 (99.886)\n",
            "Epoch: [178][150/329], lr: 0.00010\tTime 0.086 (0.101)\tData 0.003 (0.012)\tLoss 0.1997 (0.1860)\tPrec@1 92.578 (93.734)\tPrec@5 99.219 (99.876)\n",
            "Epoch: [178][160/329], lr: 0.00010\tTime 0.085 (0.100)\tData 0.008 (0.012)\tLoss 0.2093 (0.1867)\tPrec@1 93.750 (93.714)\tPrec@5 98.828 (99.869)\n",
            "Epoch: [178][170/329], lr: 0.00010\tTime 0.091 (0.100)\tData 0.000 (0.011)\tLoss 0.2371 (0.1867)\tPrec@1 92.969 (93.732)\tPrec@5 98.828 (99.856)\n",
            "Epoch: [178][180/329], lr: 0.00010\tTime 0.076 (0.099)\tData 0.007 (0.011)\tLoss 0.2392 (0.1868)\tPrec@1 91.016 (93.739)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [178][190/329], lr: 0.00010\tTime 0.070 (0.099)\tData 0.000 (0.011)\tLoss 0.2890 (0.1873)\tPrec@1 91.016 (93.742)\tPrec@5 98.828 (99.847)\n",
            "Epoch: [178][200/329], lr: 0.00010\tTime 0.097 (0.098)\tData 0.007 (0.011)\tLoss 0.2080 (0.1872)\tPrec@1 91.797 (93.725)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [178][210/329], lr: 0.00010\tTime 0.100 (0.098)\tData 0.000 (0.011)\tLoss 0.1510 (0.1881)\tPrec@1 95.312 (93.691)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [178][220/329], lr: 0.00010\tTime 0.092 (0.097)\tData 0.000 (0.010)\tLoss 0.1740 (0.1885)\tPrec@1 94.141 (93.674)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [178][230/329], lr: 0.00010\tTime 0.080 (0.097)\tData 0.000 (0.010)\tLoss 0.1908 (0.1887)\tPrec@1 94.141 (93.660)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [178][240/329], lr: 0.00010\tTime 0.091 (0.097)\tData 0.004 (0.010)\tLoss 0.1852 (0.1886)\tPrec@1 94.922 (93.664)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [178][250/329], lr: 0.00010\tTime 0.078 (0.096)\tData 0.005 (0.010)\tLoss 0.2358 (0.1883)\tPrec@1 92.578 (93.691)\tPrec@5 99.219 (99.851)\n",
            "Epoch: [178][260/329], lr: 0.00010\tTime 0.090 (0.096)\tData 0.000 (0.010)\tLoss 0.2016 (0.1880)\tPrec@1 91.797 (93.692)\tPrec@5 98.828 (99.847)\n",
            "Epoch: [178][270/329], lr: 0.00010\tTime 0.095 (0.096)\tData 0.003 (0.009)\tLoss 0.1768 (0.1880)\tPrec@1 93.750 (93.684)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [178][280/329], lr: 0.00010\tTime 0.079 (0.095)\tData 0.000 (0.009)\tLoss 0.2118 (0.1885)\tPrec@1 94.531 (93.687)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [178][290/329], lr: 0.00010\tTime 0.073 (0.095)\tData 0.000 (0.009)\tLoss 0.2001 (0.1879)\tPrec@1 93.750 (93.706)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [178][300/329], lr: 0.00010\tTime 0.093 (0.095)\tData 0.000 (0.009)\tLoss 0.1407 (0.1878)\tPrec@1 94.922 (93.714)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [178][310/329], lr: 0.00010\tTime 0.084 (0.095)\tData 0.000 (0.009)\tLoss 0.2377 (0.1883)\tPrec@1 94.531 (93.697)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [178][320/329], lr: 0.00010\tTime 0.090 (0.095)\tData 0.040 (0.009)\tLoss 0.1332 (0.1884)\tPrec@1 96.484 (93.695)\tPrec@5 100.000 (99.850)\n",
            "Test: [0/100]\tTime 0.416 (0.416)\tLoss 0.4573 (0.4573)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.035 (0.057)\tLoss 0.5338 (0.6716)\tPrec@1 84.000 (80.818)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.030 (0.043)\tLoss 0.6324 (0.6805)\tPrec@1 82.000 (80.571)\tPrec@5 100.000 (98.619)\n",
            "Test: [30/100]\tTime 0.033 (0.037)\tLoss 0.8566 (0.6975)\tPrec@1 74.000 (80.323)\tPrec@5 98.000 (98.581)\n",
            "Test: [40/100]\tTime 0.031 (0.034)\tLoss 0.7840 (0.7025)\tPrec@1 75.000 (80.146)\tPrec@5 98.000 (98.585)\n",
            "Test: [50/100]\tTime 0.012 (0.032)\tLoss 0.6962 (0.6961)\tPrec@1 81.000 (80.157)\tPrec@5 98.000 (98.608)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 0.5391 (0.7021)\tPrec@1 85.000 (79.656)\tPrec@5 100.000 (98.705)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 0.7601 (0.6944)\tPrec@1 79.000 (79.718)\tPrec@5 99.000 (98.718)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 0.6428 (0.6882)\tPrec@1 84.000 (79.914)\tPrec@5 99.000 (98.790)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 0.5696 (0.6966)\tPrec@1 87.000 (79.758)\tPrec@5 100.000 (98.747)\n",
            "val Results: Prec@1 79.590 Prec@5 98.740 Loss 0.69521\n",
            "val Class Accuracy: [0.967,0.970,0.850,0.772,0.794,0.766,0.829,0.640,0.661,0.710]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [179][0/329], lr: 0.00010\tTime 0.637 (0.637)\tData 0.576 (0.576)\tLoss 0.1123 (0.1123)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][10/329], lr: 0.00010\tTime 0.077 (0.143)\tData 0.004 (0.057)\tLoss 0.1630 (0.1763)\tPrec@1 95.312 (93.892)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [179][20/329], lr: 0.00010\tTime 0.090 (0.119)\tData 0.000 (0.032)\tLoss 0.1901 (0.1818)\tPrec@1 93.750 (93.806)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [179][30/329], lr: 0.00010\tTime 0.086 (0.111)\tData 0.007 (0.024)\tLoss 0.1742 (0.1840)\tPrec@1 94.531 (93.725)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [179][40/329], lr: 0.00010\tTime 0.095 (0.106)\tData 0.000 (0.020)\tLoss 0.1566 (0.1832)\tPrec@1 94.531 (93.779)\tPrec@5 100.000 (99.876)\n",
            "Epoch: [179][50/329], lr: 0.00010\tTime 0.089 (0.102)\tData 0.005 (0.017)\tLoss 0.2401 (0.1847)\tPrec@1 90.625 (93.758)\tPrec@5 99.609 (99.877)\n",
            "Epoch: [179][60/329], lr: 0.00010\tTime 0.085 (0.100)\tData 0.000 (0.016)\tLoss 0.1020 (0.1852)\tPrec@1 96.875 (93.808)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [179][70/329], lr: 0.00010\tTime 0.085 (0.098)\tData 0.000 (0.014)\tLoss 0.1504 (0.1878)\tPrec@1 94.922 (93.750)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [179][80/329], lr: 0.00010\tTime 0.088 (0.097)\tData 0.000 (0.013)\tLoss 0.2462 (0.1879)\tPrec@1 89.844 (93.760)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [179][90/329], lr: 0.00010\tTime 0.100 (0.096)\tData 0.006 (0.012)\tLoss 0.1716 (0.1885)\tPrec@1 95.312 (93.724)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [179][100/329], lr: 0.00010\tTime 0.105 (0.095)\tData 0.003 (0.011)\tLoss 0.2132 (0.1883)\tPrec@1 94.141 (93.738)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [179][110/329], lr: 0.00010\tTime 0.092 (0.095)\tData 0.010 (0.011)\tLoss 0.2187 (0.1897)\tPrec@1 91.406 (93.616)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [179][120/329], lr: 0.00010\tTime 0.088 (0.094)\tData 0.006 (0.011)\tLoss 0.2095 (0.1892)\tPrec@1 92.578 (93.605)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [179][130/329], lr: 0.00010\tTime 0.078 (0.094)\tData 0.001 (0.011)\tLoss 0.1896 (0.1888)\tPrec@1 94.922 (93.622)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [179][140/329], lr: 0.00010\tTime 0.090 (0.093)\tData 0.000 (0.011)\tLoss 0.1672 (0.1889)\tPrec@1 94.141 (93.623)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [179][150/329], lr: 0.00010\tTime 0.092 (0.093)\tData 0.007 (0.010)\tLoss 0.2023 (0.1890)\tPrec@1 93.359 (93.592)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [179][160/329], lr: 0.00010\tTime 0.109 (0.093)\tData 0.000 (0.010)\tLoss 0.1801 (0.1898)\tPrec@1 92.578 (93.566)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [179][170/329], lr: 0.00010\tTime 0.081 (0.093)\tData 0.007 (0.010)\tLoss 0.1528 (0.1892)\tPrec@1 96.875 (93.581)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [179][180/329], lr: 0.00010\tTime 0.095 (0.093)\tData 0.009 (0.010)\tLoss 0.1600 (0.1885)\tPrec@1 95.312 (93.601)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [179][190/329], lr: 0.00010\tTime 0.099 (0.093)\tData 0.000 (0.009)\tLoss 0.2065 (0.1886)\tPrec@1 92.188 (93.599)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [179][200/329], lr: 0.00010\tTime 0.082 (0.092)\tData 0.011 (0.009)\tLoss 0.1866 (0.1875)\tPrec@1 94.141 (93.670)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [179][210/329], lr: 0.00010\tTime 0.074 (0.092)\tData 0.010 (0.009)\tLoss 0.1635 (0.1878)\tPrec@1 92.969 (93.678)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [179][220/329], lr: 0.00010\tTime 0.094 (0.092)\tData 0.004 (0.009)\tLoss 0.1875 (0.1879)\tPrec@1 91.797 (93.663)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [179][230/329], lr: 0.00010\tTime 0.073 (0.092)\tData 0.001 (0.009)\tLoss 0.1644 (0.1881)\tPrec@1 93.750 (93.647)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [179][240/329], lr: 0.00010\tTime 0.081 (0.092)\tData 0.000 (0.009)\tLoss 0.1725 (0.1878)\tPrec@1 96.094 (93.682)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [179][250/329], lr: 0.00010\tTime 0.106 (0.092)\tData 0.001 (0.009)\tLoss 0.1545 (0.1878)\tPrec@1 94.531 (93.691)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [179][260/329], lr: 0.00010\tTime 0.115 (0.092)\tData 0.005 (0.009)\tLoss 0.1478 (0.1878)\tPrec@1 95.312 (93.684)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [179][270/329], lr: 0.00010\tTime 0.100 (0.092)\tData 0.007 (0.009)\tLoss 0.1543 (0.1874)\tPrec@1 95.312 (93.688)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [179][280/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.007 (0.009)\tLoss 0.2395 (0.1874)\tPrec@1 91.016 (93.676)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [179][290/329], lr: 0.00010\tTime 0.090 (0.092)\tData 0.006 (0.009)\tLoss 0.1127 (0.1877)\tPrec@1 96.875 (93.663)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [179][300/329], lr: 0.00010\tTime 0.085 (0.092)\tData 0.007 (0.009)\tLoss 0.2554 (0.1879)\tPrec@1 90.234 (93.653)\tPrec@5 99.609 (99.827)\n",
            "Epoch: [179][310/329], lr: 0.00010\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.2145 (0.1883)\tPrec@1 92.188 (93.622)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [179][320/329], lr: 0.00010\tTime 0.105 (0.091)\tData 0.066 (0.009)\tLoss 0.1618 (0.1881)\tPrec@1 94.141 (93.639)\tPrec@5 100.000 (99.831)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 0.4326 (0.4326)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.5089 (0.6307)\tPrec@1 82.000 (82.364)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.024 (0.042)\tLoss 0.5930 (0.6304)\tPrec@1 82.000 (81.952)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 0.7944 (0.6490)\tPrec@1 77.000 (81.419)\tPrec@5 99.000 (98.677)\n",
            "Test: [40/100]\tTime 0.016 (0.034)\tLoss 0.7002 (0.6535)\tPrec@1 77.000 (81.220)\tPrec@5 98.000 (98.659)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 0.5845 (0.6463)\tPrec@1 87.000 (81.471)\tPrec@5 98.000 (98.706)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 0.5078 (0.6496)\tPrec@1 87.000 (80.918)\tPrec@5 100.000 (98.820)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 0.6936 (0.6424)\tPrec@1 82.000 (80.986)\tPrec@5 100.000 (98.915)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 0.5981 (0.6390)\tPrec@1 86.000 (81.086)\tPrec@5 99.000 (98.951)\n",
            "Test: [90/100]\tTime 0.026 (0.028)\tLoss 0.5731 (0.6470)\tPrec@1 84.000 (80.901)\tPrec@5 100.000 (98.912)\n",
            "val Results: Prec@1 80.790 Prec@5 98.890 Loss 0.64538\n",
            "val Class Accuracy: [0.962,0.981,0.785,0.783,0.852,0.765,0.818,0.721,0.695,0.717]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [180][0/329], lr: 0.00000\tTime 0.642 (0.642)\tData 0.558 (0.558)\tLoss 0.2241 (0.2241)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][10/329], lr: 0.00000\tTime 0.095 (0.144)\tData 0.007 (0.057)\tLoss 0.2439 (0.1890)\tPrec@1 89.844 (93.253)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [180][20/329], lr: 0.00000\tTime 0.094 (0.120)\tData 0.004 (0.032)\tLoss 0.1494 (0.1859)\tPrec@1 94.922 (93.452)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [180][30/329], lr: 0.00000\tTime 0.080 (0.112)\tData 0.008 (0.024)\tLoss 0.1761 (0.1857)\tPrec@1 94.141 (93.561)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [180][40/329], lr: 0.00000\tTime 0.099 (0.107)\tData 0.007 (0.020)\tLoss 0.1892 (0.1867)\tPrec@1 92.578 (93.493)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [180][50/329], lr: 0.00000\tTime 0.087 (0.103)\tData 0.006 (0.018)\tLoss 0.1863 (0.1844)\tPrec@1 94.141 (93.589)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [180][60/329], lr: 0.00000\tTime 0.100 (0.101)\tData 0.000 (0.016)\tLoss 0.2207 (0.1835)\tPrec@1 92.188 (93.628)\tPrec@5 100.000 (99.898)\n",
            "Epoch: [180][70/329], lr: 0.00000\tTime 0.128 (0.100)\tData 0.000 (0.015)\tLoss 0.1511 (0.1836)\tPrec@1 94.141 (93.667)\tPrec@5 99.609 (99.895)\n",
            "Epoch: [180][80/329], lr: 0.00000\tTime 0.099 (0.098)\tData 0.014 (0.014)\tLoss 0.1608 (0.1839)\tPrec@1 95.312 (93.682)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [180][90/329], lr: 0.00000\tTime 0.079 (0.097)\tData 0.000 (0.013)\tLoss 0.1757 (0.1850)\tPrec@1 93.750 (93.656)\tPrec@5 100.000 (99.884)\n",
            "Epoch: [180][100/329], lr: 0.00000\tTime 0.089 (0.096)\tData 0.007 (0.013)\tLoss 0.1709 (0.1850)\tPrec@1 94.141 (93.642)\tPrec@5 99.609 (99.872)\n",
            "Epoch: [180][110/329], lr: 0.00000\tTime 0.100 (0.096)\tData 0.003 (0.012)\tLoss 0.1802 (0.1836)\tPrec@1 93.750 (93.683)\tPrec@5 99.609 (99.873)\n",
            "Epoch: [180][120/329], lr: 0.00000\tTime 0.090 (0.095)\tData 0.000 (0.012)\tLoss 0.1147 (0.1825)\tPrec@1 96.094 (93.750)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [180][130/329], lr: 0.00000\tTime 0.092 (0.094)\tData 0.007 (0.011)\tLoss 0.2532 (0.1827)\tPrec@1 92.578 (93.756)\tPrec@5 99.609 (99.866)\n",
            "Epoch: [180][140/329], lr: 0.00000\tTime 0.107 (0.094)\tData 0.007 (0.011)\tLoss 0.1670 (0.1822)\tPrec@1 92.578 (93.758)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [180][150/329], lr: 0.00000\tTime 0.080 (0.094)\tData 0.000 (0.011)\tLoss 0.1950 (0.1819)\tPrec@1 92.188 (93.778)\tPrec@5 99.609 (99.876)\n",
            "Epoch: [180][160/329], lr: 0.00000\tTime 0.078 (0.093)\tData 0.000 (0.011)\tLoss 0.2600 (0.1821)\tPrec@1 90.234 (93.772)\tPrec@5 99.609 (99.879)\n",
            "Epoch: [180][170/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.010 (0.011)\tLoss 0.1995 (0.1818)\tPrec@1 92.969 (93.789)\tPrec@5 99.609 (99.874)\n",
            "Epoch: [180][180/329], lr: 0.00000\tTime 0.085 (0.093)\tData 0.006 (0.011)\tLoss 0.2202 (0.1814)\tPrec@1 92.969 (93.817)\tPrec@5 99.609 (99.879)\n",
            "Epoch: [180][190/329], lr: 0.00000\tTime 0.069 (0.092)\tData 0.000 (0.010)\tLoss 0.1701 (0.1819)\tPrec@1 94.922 (93.803)\tPrec@5 100.000 (99.875)\n",
            "Epoch: [180][200/329], lr: 0.00000\tTime 0.073 (0.092)\tData 0.004 (0.010)\tLoss 0.1851 (0.1834)\tPrec@1 95.312 (93.746)\tPrec@5 99.609 (99.876)\n",
            "Epoch: [180][210/329], lr: 0.00000\tTime 0.108 (0.092)\tData 0.004 (0.010)\tLoss 0.1601 (0.1835)\tPrec@1 94.922 (93.739)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [180][220/329], lr: 0.00000\tTime 0.068 (0.092)\tData 0.002 (0.010)\tLoss 0.1617 (0.1824)\tPrec@1 93.750 (93.778)\tPrec@5 99.609 (99.873)\n",
            "Epoch: [180][230/329], lr: 0.00000\tTime 0.096 (0.092)\tData 0.007 (0.010)\tLoss 0.2054 (0.1831)\tPrec@1 91.797 (93.752)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [180][240/329], lr: 0.00000\tTime 0.094 (0.092)\tData 0.005 (0.010)\tLoss 0.1536 (0.1831)\tPrec@1 96.094 (93.758)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [180][250/329], lr: 0.00000\tTime 0.105 (0.092)\tData 0.012 (0.010)\tLoss 0.1270 (0.1833)\tPrec@1 96.875 (93.750)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [180][260/329], lr: 0.00000\tTime 0.104 (0.092)\tData 0.007 (0.010)\tLoss 0.1974 (0.1836)\tPrec@1 93.359 (93.740)\tPrec@5 100.000 (99.876)\n",
            "Epoch: [180][270/329], lr: 0.00000\tTime 0.083 (0.091)\tData 0.000 (0.010)\tLoss 0.1477 (0.1842)\tPrec@1 96.484 (93.718)\tPrec@5 99.609 (99.869)\n",
            "Epoch: [180][280/329], lr: 0.00000\tTime 0.088 (0.091)\tData 0.004 (0.009)\tLoss 0.2029 (0.1842)\tPrec@1 93.359 (93.715)\tPrec@5 100.000 (99.869)\n",
            "Epoch: [180][290/329], lr: 0.00000\tTime 0.084 (0.091)\tData 0.005 (0.009)\tLoss 0.2192 (0.1853)\tPrec@1 91.797 (93.703)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [180][300/329], lr: 0.00000\tTime 0.083 (0.091)\tData 0.004 (0.009)\tLoss 0.1610 (0.1852)\tPrec@1 94.141 (93.719)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [180][310/329], lr: 0.00000\tTime 0.059 (0.091)\tData 0.000 (0.009)\tLoss 0.1790 (0.1857)\tPrec@1 94.141 (93.697)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [180][320/329], lr: 0.00000\tTime 0.091 (0.091)\tData 0.053 (0.009)\tLoss 0.1755 (0.1860)\tPrec@1 94.922 (93.687)\tPrec@5 100.000 (99.858)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.4620 (0.4620)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.042 (0.055)\tLoss 0.5667 (0.6929)\tPrec@1 82.000 (80.273)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 0.6599 (0.6944)\tPrec@1 82.000 (80.333)\tPrec@5 100.000 (98.524)\n",
            "Test: [30/100]\tTime 0.035 (0.037)\tLoss 0.8507 (0.7130)\tPrec@1 76.000 (80.097)\tPrec@5 99.000 (98.516)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 0.7579 (0.7177)\tPrec@1 77.000 (79.805)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 0.6979 (0.7103)\tPrec@1 82.000 (79.824)\tPrec@5 98.000 (98.569)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 0.5298 (0.7147)\tPrec@1 84.000 (79.164)\tPrec@5 100.000 (98.689)\n",
            "Test: [70/100]\tTime 0.017 (0.029)\tLoss 0.7574 (0.7080)\tPrec@1 81.000 (79.127)\tPrec@5 99.000 (98.690)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 0.6590 (0.7021)\tPrec@1 82.000 (79.333)\tPrec@5 99.000 (98.790)\n",
            "Test: [90/100]\tTime 0.035 (0.028)\tLoss 0.6006 (0.7100)\tPrec@1 86.000 (79.165)\tPrec@5 100.000 (98.758)\n",
            "val Results: Prec@1 79.080 Prec@5 98.770 Loss 0.70887\n",
            "val Class Accuracy: [0.956,0.980,0.869,0.789,0.826,0.719,0.800,0.678,0.680,0.611]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [181][0/329], lr: 0.00000\tTime 0.547 (0.547)\tData 0.478 (0.478)\tLoss 0.1949 (0.1949)\tPrec@1 95.312 (95.312)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [181][10/329], lr: 0.00000\tTime 0.068 (0.140)\tData 0.000 (0.054)\tLoss 0.2093 (0.1781)\tPrec@1 93.750 (94.247)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [181][20/329], lr: 0.00000\tTime 0.077 (0.115)\tData 0.001 (0.032)\tLoss 0.1736 (0.1813)\tPrec@1 94.531 (94.159)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [181][30/329], lr: 0.00000\tTime 0.094 (0.107)\tData 0.000 (0.023)\tLoss 0.1616 (0.1813)\tPrec@1 93.359 (93.964)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [181][40/329], lr: 0.00000\tTime 0.106 (0.105)\tData 0.000 (0.019)\tLoss 0.2059 (0.1803)\tPrec@1 91.797 (93.931)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [181][50/329], lr: 0.00000\tTime 0.102 (0.103)\tData 0.000 (0.017)\tLoss 0.1930 (0.1829)\tPrec@1 92.188 (93.972)\tPrec@5 100.000 (99.809)\n",
            "Epoch: [181][60/329], lr: 0.00000\tTime 0.096 (0.101)\tData 0.006 (0.016)\tLoss 0.1681 (0.1838)\tPrec@1 94.141 (93.910)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [181][70/329], lr: 0.00000\tTime 0.095 (0.099)\tData 0.000 (0.014)\tLoss 0.2086 (0.1807)\tPrec@1 92.969 (93.998)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [181][80/329], lr: 0.00000\tTime 0.092 (0.098)\tData 0.000 (0.013)\tLoss 0.1638 (0.1812)\tPrec@1 93.750 (93.996)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [181][90/329], lr: 0.00000\tTime 0.091 (0.097)\tData 0.005 (0.013)\tLoss 0.1347 (0.1795)\tPrec@1 96.094 (94.085)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [181][100/329], lr: 0.00000\tTime 0.095 (0.097)\tData 0.000 (0.012)\tLoss 0.1600 (0.1817)\tPrec@1 95.312 (94.040)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [181][110/329], lr: 0.00000\tTime 0.118 (0.096)\tData 0.005 (0.012)\tLoss 0.1155 (0.1815)\tPrec@1 96.484 (94.000)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [181][120/329], lr: 0.00000\tTime 0.093 (0.095)\tData 0.004 (0.011)\tLoss 0.1891 (0.1831)\tPrec@1 93.750 (93.940)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [181][130/329], lr: 0.00000\tTime 0.086 (0.095)\tData 0.000 (0.011)\tLoss 0.1695 (0.1833)\tPrec@1 94.141 (93.935)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [181][140/329], lr: 0.00000\tTime 0.106 (0.094)\tData 0.000 (0.011)\tLoss 0.1965 (0.1839)\tPrec@1 92.578 (93.880)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [181][150/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.007 (0.010)\tLoss 0.1500 (0.1834)\tPrec@1 94.141 (93.892)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [181][160/329], lr: 0.00000\tTime 0.087 (0.094)\tData 0.007 (0.010)\tLoss 0.1966 (0.1835)\tPrec@1 92.578 (93.859)\tPrec@5 99.609 (99.830)\n",
            "Epoch: [181][170/329], lr: 0.00000\tTime 0.078 (0.094)\tData 0.008 (0.010)\tLoss 0.1902 (0.1841)\tPrec@1 92.188 (93.844)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [181][180/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.009 (0.010)\tLoss 0.1763 (0.1835)\tPrec@1 94.531 (93.875)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [181][190/329], lr: 0.00000\tTime 0.079 (0.093)\tData 0.002 (0.010)\tLoss 0.2543 (0.1842)\tPrec@1 89.844 (93.852)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [181][200/329], lr: 0.00000\tTime 0.067 (0.093)\tData 0.000 (0.010)\tLoss 0.2272 (0.1844)\tPrec@1 92.969 (93.845)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [181][210/329], lr: 0.00000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 0.2314 (0.1839)\tPrec@1 91.406 (93.861)\tPrec@5 99.219 (99.832)\n",
            "Epoch: [181][220/329], lr: 0.00000\tTime 0.084 (0.093)\tData 0.006 (0.009)\tLoss 0.2003 (0.1850)\tPrec@1 92.969 (93.833)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [181][230/329], lr: 0.00000\tTime 0.114 (0.093)\tData 0.012 (0.009)\tLoss 0.2886 (0.1849)\tPrec@1 90.625 (93.850)\tPrec@5 99.219 (99.828)\n",
            "Epoch: [181][240/329], lr: 0.00000\tTime 0.086 (0.093)\tData 0.001 (0.009)\tLoss 0.1675 (0.1853)\tPrec@1 94.531 (93.847)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [181][250/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.001 (0.009)\tLoss 0.1511 (0.1852)\tPrec@1 94.922 (93.840)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [181][260/329], lr: 0.00000\tTime 0.098 (0.093)\tData 0.005 (0.009)\tLoss 0.1669 (0.1852)\tPrec@1 94.922 (93.850)\tPrec@5 99.609 (99.829)\n",
            "Epoch: [181][270/329], lr: 0.00000\tTime 0.090 (0.092)\tData 0.001 (0.009)\tLoss 0.1956 (0.1851)\tPrec@1 93.750 (93.860)\tPrec@5 99.219 (99.828)\n",
            "Epoch: [181][280/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.005 (0.009)\tLoss 0.1553 (0.1854)\tPrec@1 95.312 (93.842)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [181][290/329], lr: 0.00000\tTime 0.071 (0.092)\tData 0.000 (0.009)\tLoss 0.1314 (0.1850)\tPrec@1 95.703 (93.847)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [181][300/329], lr: 0.00000\tTime 0.095 (0.092)\tData 0.004 (0.009)\tLoss 0.2746 (0.1851)\tPrec@1 91.406 (93.842)\tPrec@5 99.219 (99.830)\n",
            "Epoch: [181][310/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.000 (0.009)\tLoss 0.1586 (0.1852)\tPrec@1 94.141 (93.839)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [181][320/329], lr: 0.00000\tTime 0.108 (0.092)\tData 0.068 (0.009)\tLoss 0.1291 (0.1856)\tPrec@1 96.094 (93.829)\tPrec@5 99.609 (99.826)\n",
            "Test: [0/100]\tTime 0.353 (0.353)\tLoss 0.4346 (0.4346)\tPrec@1 87.000 (87.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.057)\tLoss 0.5075 (0.6475)\tPrec@1 84.000 (82.455)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.025 (0.043)\tLoss 0.5904 (0.6470)\tPrec@1 84.000 (82.190)\tPrec@5 100.000 (98.905)\n",
            "Test: [30/100]\tTime 0.010 (0.036)\tLoss 0.7539 (0.6632)\tPrec@1 77.000 (81.742)\tPrec@5 99.000 (98.806)\n",
            "Test: [40/100]\tTime 0.035 (0.033)\tLoss 0.6956 (0.6663)\tPrec@1 76.000 (81.341)\tPrec@5 99.000 (98.805)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 0.6050 (0.6584)\tPrec@1 86.000 (81.431)\tPrec@5 98.000 (98.784)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 0.5028 (0.6619)\tPrec@1 87.000 (80.836)\tPrec@5 100.000 (98.869)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 0.7400 (0.6550)\tPrec@1 81.000 (80.944)\tPrec@5 99.000 (98.901)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 0.5664 (0.6506)\tPrec@1 88.000 (81.086)\tPrec@5 99.000 (98.938)\n",
            "Test: [90/100]\tTime 0.040 (0.029)\tLoss 0.5473 (0.6585)\tPrec@1 86.000 (80.934)\tPrec@5 100.000 (98.923)\n",
            "val Results: Prec@1 80.850 Prec@5 98.900 Loss 0.65648\n",
            "val Class Accuracy: [0.964,0.990,0.808,0.752,0.834,0.778,0.834,0.694,0.721,0.710]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [182][0/329], lr: 0.00000\tTime 0.684 (0.684)\tData 0.579 (0.579)\tLoss 0.1757 (0.1757)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][10/329], lr: 0.00000\tTime 0.090 (0.147)\tData 0.000 (0.055)\tLoss 0.1931 (0.1998)\tPrec@1 92.969 (93.359)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [182][20/329], lr: 0.00000\tTime 0.106 (0.119)\tData 0.004 (0.031)\tLoss 0.1338 (0.1937)\tPrec@1 96.484 (93.620)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [182][30/329], lr: 0.00000\tTime 0.081 (0.111)\tData 0.012 (0.023)\tLoss 0.2085 (0.1977)\tPrec@1 92.969 (93.246)\tPrec@5 99.609 (99.811)\n",
            "Epoch: [182][40/329], lr: 0.00000\tTime 0.087 (0.105)\tData 0.000 (0.019)\tLoss 0.1433 (0.1968)\tPrec@1 95.703 (93.397)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [182][50/329], lr: 0.00000\tTime 0.099 (0.104)\tData 0.012 (0.016)\tLoss 0.1717 (0.1910)\tPrec@1 94.922 (93.589)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [182][60/329], lr: 0.00000\tTime 0.100 (0.102)\tData 0.016 (0.015)\tLoss 0.2354 (0.1894)\tPrec@1 93.750 (93.654)\tPrec@5 99.609 (99.827)\n",
            "Epoch: [182][70/329], lr: 0.00000\tTime 0.076 (0.100)\tData 0.000 (0.014)\tLoss 0.2285 (0.1902)\tPrec@1 92.969 (93.596)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [182][80/329], lr: 0.00000\tTime 0.085 (0.099)\tData 0.005 (0.013)\tLoss 0.2293 (0.1920)\tPrec@1 93.359 (93.562)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [182][90/329], lr: 0.00000\tTime 0.080 (0.098)\tData 0.007 (0.012)\tLoss 0.1275 (0.1906)\tPrec@1 94.922 (93.604)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [182][100/329], lr: 0.00000\tTime 0.103 (0.097)\tData 0.010 (0.012)\tLoss 0.1733 (0.1912)\tPrec@1 94.922 (93.568)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [182][110/329], lr: 0.00000\tTime 0.121 (0.099)\tData 0.000 (0.011)\tLoss 0.1656 (0.1919)\tPrec@1 95.312 (93.556)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [182][120/329], lr: 0.00000\tTime 0.120 (0.100)\tData 0.007 (0.011)\tLoss 0.1705 (0.1916)\tPrec@1 93.750 (93.553)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [182][130/329], lr: 0.00000\tTime 0.075 (0.101)\tData 0.027 (0.011)\tLoss 0.1697 (0.1899)\tPrec@1 94.531 (93.595)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [182][140/329], lr: 0.00000\tTime 0.097 (0.101)\tData 0.000 (0.011)\tLoss 0.1840 (0.1889)\tPrec@1 94.141 (93.642)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [182][150/329], lr: 0.00000\tTime 0.093 (0.101)\tData 0.005 (0.011)\tLoss 0.1856 (0.1868)\tPrec@1 94.531 (93.698)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [182][160/329], lr: 0.00000\tTime 0.089 (0.100)\tData 0.009 (0.011)\tLoss 0.1429 (0.1873)\tPrec@1 94.531 (93.668)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [182][170/329], lr: 0.00000\tTime 0.092 (0.100)\tData 0.000 (0.010)\tLoss 0.1472 (0.1876)\tPrec@1 95.312 (93.659)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [182][180/329], lr: 0.00000\tTime 0.110 (0.099)\tData 0.000 (0.010)\tLoss 0.2064 (0.1877)\tPrec@1 94.141 (93.670)\tPrec@5 99.609 (99.853)\n",
            "Epoch: [182][190/329], lr: 0.00000\tTime 0.076 (0.098)\tData 0.000 (0.010)\tLoss 0.1883 (0.1880)\tPrec@1 94.922 (93.683)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [182][200/329], lr: 0.00000\tTime 0.105 (0.098)\tData 0.001 (0.010)\tLoss 0.1704 (0.1877)\tPrec@1 94.531 (93.694)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [182][210/329], lr: 0.00000\tTime 0.079 (0.098)\tData 0.000 (0.010)\tLoss 0.2405 (0.1881)\tPrec@1 91.797 (93.687)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [182][220/329], lr: 0.00000\tTime 0.085 (0.097)\tData 0.000 (0.009)\tLoss 0.1969 (0.1878)\tPrec@1 92.969 (93.706)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [182][230/329], lr: 0.00000\tTime 0.097 (0.097)\tData 0.000 (0.009)\tLoss 0.1527 (0.1873)\tPrec@1 95.703 (93.731)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [182][240/329], lr: 0.00000\tTime 0.087 (0.097)\tData 0.007 (0.009)\tLoss 0.1891 (0.1880)\tPrec@1 92.578 (93.701)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [182][250/329], lr: 0.00000\tTime 0.100 (0.097)\tData 0.007 (0.009)\tLoss 0.2364 (0.1892)\tPrec@1 92.578 (93.668)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [182][260/329], lr: 0.00000\tTime 0.091 (0.096)\tData 0.012 (0.009)\tLoss 0.1932 (0.1889)\tPrec@1 91.797 (93.669)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [182][270/329], lr: 0.00000\tTime 0.089 (0.096)\tData 0.000 (0.009)\tLoss 0.1867 (0.1884)\tPrec@1 92.578 (93.689)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [182][280/329], lr: 0.00000\tTime 0.069 (0.096)\tData 0.000 (0.009)\tLoss 0.2112 (0.1879)\tPrec@1 92.188 (93.692)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [182][290/329], lr: 0.00000\tTime 0.086 (0.096)\tData 0.003 (0.009)\tLoss 0.1720 (0.1882)\tPrec@1 93.750 (93.675)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [182][300/329], lr: 0.00000\tTime 0.093 (0.095)\tData 0.007 (0.009)\tLoss 0.1452 (0.1879)\tPrec@1 94.141 (93.695)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [182][310/329], lr: 0.00000\tTime 0.084 (0.095)\tData 0.000 (0.009)\tLoss 0.1415 (0.1872)\tPrec@1 94.531 (93.729)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [182][320/329], lr: 0.00000\tTime 0.095 (0.095)\tData 0.053 (0.009)\tLoss 0.2458 (0.1869)\tPrec@1 91.797 (93.728)\tPrec@5 99.609 (99.845)\n",
            "Test: [0/100]\tTime 0.385 (0.385)\tLoss 0.4445 (0.4445)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.018 (0.057)\tLoss 0.5312 (0.6566)\tPrec@1 82.000 (81.182)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.015 (0.043)\tLoss 0.6352 (0.6642)\tPrec@1 82.000 (81.190)\tPrec@5 100.000 (98.524)\n",
            "Test: [30/100]\tTime 0.017 (0.037)\tLoss 0.8111 (0.6825)\tPrec@1 77.000 (80.903)\tPrec@5 99.000 (98.548)\n",
            "Test: [40/100]\tTime 0.044 (0.034)\tLoss 0.7165 (0.6868)\tPrec@1 77.000 (80.659)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6474 (0.6793)\tPrec@1 84.000 (80.843)\tPrec@5 98.000 (98.569)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 0.5453 (0.6842)\tPrec@1 83.000 (80.148)\tPrec@5 100.000 (98.672)\n",
            "Test: [70/100]\tTime 0.040 (0.030)\tLoss 0.7395 (0.6784)\tPrec@1 81.000 (80.183)\tPrec@5 99.000 (98.704)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 0.5948 (0.6726)\tPrec@1 86.000 (80.407)\tPrec@5 99.000 (98.765)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 0.5623 (0.6808)\tPrec@1 85.000 (80.154)\tPrec@5 100.000 (98.747)\n",
            "val Results: Prec@1 80.100 Prec@5 98.730 Loss 0.67865\n",
            "val Class Accuracy: [0.958,0.986,0.865,0.777,0.804,0.706,0.846,0.676,0.698,0.694]\n",
            "Best Prec@1: 80.860\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [183][0/329], lr: 0.00000\tTime 0.804 (0.804)\tData 0.713 (0.713)\tLoss 0.2455 (0.2455)\tPrec@1 91.406 (91.406)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [183][10/329], lr: 0.00000\tTime 0.116 (0.166)\tData 0.000 (0.072)\tLoss 0.1861 (0.1780)\tPrec@1 93.359 (93.714)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [183][20/329], lr: 0.00000\tTime 0.068 (0.127)\tData 0.000 (0.041)\tLoss 0.1199 (0.1774)\tPrec@1 96.094 (93.787)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [183][30/329], lr: 0.00000\tTime 0.087 (0.115)\tData 0.000 (0.030)\tLoss 0.2311 (0.1846)\tPrec@1 91.406 (93.611)\tPrec@5 99.609 (99.887)\n",
            "Epoch: [183][40/329], lr: 0.00000\tTime 0.091 (0.109)\tData 0.013 (0.025)\tLoss 0.1798 (0.1833)\tPrec@1 93.359 (93.712)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [183][50/329], lr: 0.00000\tTime 0.085 (0.105)\tData 0.006 (0.021)\tLoss 0.1978 (0.1808)\tPrec@1 94.141 (93.903)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [183][60/329], lr: 0.00000\tTime 0.081 (0.102)\tData 0.000 (0.019)\tLoss 0.2427 (0.1809)\tPrec@1 92.578 (93.949)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [183][70/329], lr: 0.00000\tTime 0.096 (0.100)\tData 0.005 (0.017)\tLoss 0.1354 (0.1825)\tPrec@1 95.312 (93.877)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [183][80/329], lr: 0.00000\tTime 0.113 (0.099)\tData 0.007 (0.016)\tLoss 0.1207 (0.1822)\tPrec@1 96.094 (93.890)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [183][90/329], lr: 0.00000\tTime 0.098 (0.098)\tData 0.016 (0.016)\tLoss 0.2847 (0.1849)\tPrec@1 90.625 (93.793)\tPrec@5 100.000 (99.871)\n",
            "Epoch: [183][100/329], lr: 0.00000\tTime 0.092 (0.097)\tData 0.007 (0.015)\tLoss 0.1593 (0.1863)\tPrec@1 94.922 (93.746)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [183][110/329], lr: 0.00000\tTime 0.083 (0.096)\tData 0.004 (0.014)\tLoss 0.1710 (0.1866)\tPrec@1 93.750 (93.729)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [183][120/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.005 (0.014)\tLoss 0.1332 (0.1864)\tPrec@1 96.484 (93.705)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [183][130/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.007 (0.013)\tLoss 0.1527 (0.1852)\tPrec@1 94.531 (93.729)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [183][140/329], lr: 0.00000\tTime 0.100 (0.095)\tData 0.004 (0.013)\tLoss 0.1237 (0.1858)\tPrec@1 94.531 (93.684)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [183][150/329], lr: 0.00000\tTime 0.076 (0.094)\tData 0.000 (0.013)\tLoss 0.2150 (0.1866)\tPrec@1 91.406 (93.662)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [183][160/329], lr: 0.00000\tTime 0.102 (0.094)\tData 0.005 (0.012)\tLoss 0.1499 (0.1866)\tPrec@1 95.703 (93.684)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [183][170/329], lr: 0.00000\tTime 0.072 (0.093)\tData 0.007 (0.012)\tLoss 0.2518 (0.1869)\tPrec@1 92.188 (93.670)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [183][180/329], lr: 0.00000\tTime 0.086 (0.093)\tData 0.009 (0.012)\tLoss 0.1114 (0.1855)\tPrec@1 96.094 (93.715)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [183][190/329], lr: 0.00000\tTime 0.085 (0.093)\tData 0.000 (0.011)\tLoss 0.1703 (0.1853)\tPrec@1 94.922 (93.715)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [183][200/329], lr: 0.00000\tTime 0.079 (0.093)\tData 0.000 (0.011)\tLoss 0.1509 (0.1844)\tPrec@1 95.312 (93.771)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [183][210/329], lr: 0.00000\tTime 0.085 (0.093)\tData 0.007 (0.011)\tLoss 0.1520 (0.1838)\tPrec@1 94.922 (93.789)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [183][220/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.006 (0.011)\tLoss 0.1635 (0.1835)\tPrec@1 92.969 (93.792)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [183][230/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.000 (0.011)\tLoss 0.1466 (0.1842)\tPrec@1 95.703 (93.747)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [183][240/329], lr: 0.00000\tTime 0.099 (0.092)\tData 0.003 (0.011)\tLoss 0.1876 (0.1843)\tPrec@1 93.359 (93.718)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [183][250/329], lr: 0.00000\tTime 0.087 (0.092)\tData 0.000 (0.011)\tLoss 0.1639 (0.1839)\tPrec@1 94.922 (93.752)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [183][260/329], lr: 0.00000\tTime 0.069 (0.092)\tData 0.003 (0.010)\tLoss 0.1455 (0.1842)\tPrec@1 94.531 (93.738)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [183][270/329], lr: 0.00000\tTime 0.079 (0.092)\tData 0.003 (0.010)\tLoss 0.2066 (0.1842)\tPrec@1 91.406 (93.744)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [183][280/329], lr: 0.00000\tTime 0.082 (0.092)\tData 0.000 (0.010)\tLoss 0.1777 (0.1851)\tPrec@1 94.141 (93.708)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [183][290/329], lr: 0.00000\tTime 0.095 (0.092)\tData 0.007 (0.010)\tLoss 0.1371 (0.1851)\tPrec@1 95.703 (93.691)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [183][300/329], lr: 0.00000\tTime 0.065 (0.091)\tData 0.006 (0.010)\tLoss 0.1442 (0.1847)\tPrec@1 94.531 (93.715)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [183][310/329], lr: 0.00000\tTime 0.082 (0.091)\tData 0.000 (0.010)\tLoss 0.1488 (0.1849)\tPrec@1 94.922 (93.710)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [183][320/329], lr: 0.00000\tTime 0.072 (0.091)\tData 0.031 (0.010)\tLoss 0.1630 (0.1851)\tPrec@1 94.141 (93.701)\tPrec@5 100.000 (99.842)\n",
            "Test: [0/100]\tTime 0.390 (0.390)\tLoss 0.3987 (0.3987)\tPrec@1 88.000 (88.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.062)\tLoss 0.4924 (0.6057)\tPrec@1 83.000 (82.182)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.013 (0.043)\tLoss 0.6248 (0.6065)\tPrec@1 83.000 (82.524)\tPrec@5 100.000 (98.619)\n",
            "Test: [30/100]\tTime 0.025 (0.037)\tLoss 0.7859 (0.6257)\tPrec@1 77.000 (82.161)\tPrec@5 99.000 (98.613)\n",
            "Test: [40/100]\tTime 0.023 (0.035)\tLoss 0.6408 (0.6311)\tPrec@1 77.000 (81.878)\tPrec@5 98.000 (98.659)\n",
            "Test: [50/100]\tTime 0.015 (0.034)\tLoss 0.6033 (0.6242)\tPrec@1 86.000 (82.078)\tPrec@5 99.000 (98.745)\n",
            "Test: [60/100]\tTime 0.027 (0.032)\tLoss 0.4979 (0.6266)\tPrec@1 86.000 (81.639)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.018 (0.031)\tLoss 0.6448 (0.6211)\tPrec@1 82.000 (81.761)\tPrec@5 100.000 (98.887)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 0.5455 (0.6159)\tPrec@1 86.000 (81.877)\tPrec@5 99.000 (98.938)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 0.5161 (0.6226)\tPrec@1 85.000 (81.659)\tPrec@5 100.000 (98.901)\n",
            "val Results: Prec@1 81.630 Prec@5 98.900 Loss 0.61891\n",
            "val Class Accuracy: [0.932,0.982,0.843,0.771,0.818,0.776,0.862,0.724,0.727,0.728]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [184][0/329], lr: 0.00000\tTime 0.629 (0.629)\tData 0.526 (0.526)\tLoss 0.2065 (0.2065)\tPrec@1 92.188 (92.188)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [184][10/329], lr: 0.00000\tTime 0.103 (0.148)\tData 0.000 (0.052)\tLoss 0.2625 (0.2000)\tPrec@1 91.016 (93.217)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [184][20/329], lr: 0.00000\tTime 0.106 (0.122)\tData 0.000 (0.030)\tLoss 0.1995 (0.1867)\tPrec@1 92.578 (93.527)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [184][30/329], lr: 0.00000\tTime 0.089 (0.111)\tData 0.000 (0.022)\tLoss 0.2526 (0.1858)\tPrec@1 91.406 (93.687)\tPrec@5 99.219 (99.899)\n",
            "Epoch: [184][40/329], lr: 0.00000\tTime 0.079 (0.105)\tData 0.006 (0.019)\tLoss 0.2401 (0.1861)\tPrec@1 91.016 (93.750)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [184][50/329], lr: 0.00000\tTime 0.071 (0.102)\tData 0.000 (0.016)\tLoss 0.1910 (0.1851)\tPrec@1 92.188 (93.658)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [184][60/329], lr: 0.00000\tTime 0.089 (0.100)\tData 0.007 (0.015)\tLoss 0.2206 (0.1881)\tPrec@1 91.406 (93.551)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [184][70/329], lr: 0.00000\tTime 0.085 (0.098)\tData 0.007 (0.014)\tLoss 0.1166 (0.1894)\tPrec@1 95.703 (93.530)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [184][80/329], lr: 0.00000\tTime 0.115 (0.097)\tData 0.012 (0.013)\tLoss 0.1554 (0.1884)\tPrec@1 93.750 (93.576)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [184][90/329], lr: 0.00000\tTime 0.086 (0.096)\tData 0.005 (0.013)\tLoss 0.1451 (0.1874)\tPrec@1 93.750 (93.591)\tPrec@5 100.000 (99.884)\n",
            "Epoch: [184][100/329], lr: 0.00000\tTime 0.085 (0.095)\tData 0.000 (0.012)\tLoss 0.1417 (0.1870)\tPrec@1 96.094 (93.638)\tPrec@5 100.000 (99.880)\n",
            "Epoch: [184][110/329], lr: 0.00000\tTime 0.087 (0.095)\tData 0.008 (0.012)\tLoss 0.1950 (0.1876)\tPrec@1 93.750 (93.634)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [184][120/329], lr: 0.00000\tTime 0.092 (0.095)\tData 0.000 (0.011)\tLoss 0.1598 (0.1853)\tPrec@1 95.312 (93.714)\tPrec@5 99.609 (99.864)\n",
            "Epoch: [184][130/329], lr: 0.00000\tTime 0.082 (0.094)\tData 0.000 (0.011)\tLoss 0.2528 (0.1865)\tPrec@1 92.578 (93.658)\tPrec@5 99.609 (99.869)\n",
            "Epoch: [184][140/329], lr: 0.00000\tTime 0.099 (0.094)\tData 0.000 (0.010)\tLoss 0.1414 (0.1864)\tPrec@1 95.703 (93.661)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [184][150/329], lr: 0.00000\tTime 0.079 (0.094)\tData 0.005 (0.010)\tLoss 0.1887 (0.1857)\tPrec@1 94.531 (93.685)\tPrec@5 99.609 (99.873)\n",
            "Epoch: [184][160/329], lr: 0.00000\tTime 0.112 (0.093)\tData 0.005 (0.010)\tLoss 0.2244 (0.1857)\tPrec@1 91.406 (93.638)\tPrec@5 100.000 (99.879)\n",
            "Epoch: [184][170/329], lr: 0.00000\tTime 0.083 (0.093)\tData 0.007 (0.010)\tLoss 0.1921 (0.1849)\tPrec@1 91.406 (93.665)\tPrec@5 100.000 (99.881)\n",
            "Epoch: [184][180/329], lr: 0.00000\tTime 0.112 (0.093)\tData 0.000 (0.010)\tLoss 0.2202 (0.1841)\tPrec@1 92.578 (93.720)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [184][190/329], lr: 0.00000\tTime 0.075 (0.093)\tData 0.008 (0.009)\tLoss 0.1816 (0.1835)\tPrec@1 92.578 (93.719)\tPrec@5 100.000 (99.890)\n",
            "Epoch: [184][200/329], lr: 0.00000\tTime 0.100 (0.093)\tData 0.001 (0.009)\tLoss 0.2579 (0.1840)\tPrec@1 91.797 (93.705)\tPrec@5 99.609 (99.881)\n",
            "Epoch: [184][210/329], lr: 0.00000\tTime 0.094 (0.092)\tData 0.000 (0.009)\tLoss 0.1559 (0.1852)\tPrec@1 93.359 (93.667)\tPrec@5 100.000 (99.878)\n",
            "Epoch: [184][220/329], lr: 0.00000\tTime 0.061 (0.092)\tData 0.000 (0.009)\tLoss 0.1474 (0.1845)\tPrec@1 93.750 (93.678)\tPrec@5 100.000 (99.880)\n",
            "Epoch: [184][230/329], lr: 0.00000\tTime 0.086 (0.092)\tData 0.002 (0.009)\tLoss 0.1680 (0.1851)\tPrec@1 94.531 (93.679)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [184][240/329], lr: 0.00000\tTime 0.094 (0.092)\tData 0.005 (0.009)\tLoss 0.2742 (0.1862)\tPrec@1 92.188 (93.669)\tPrec@5 99.609 (99.872)\n",
            "Epoch: [184][250/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.014 (0.009)\tLoss 0.1309 (0.1864)\tPrec@1 96.094 (93.672)\tPrec@5 100.000 (99.865)\n",
            "Epoch: [184][260/329], lr: 0.00000\tTime 0.098 (0.092)\tData 0.000 (0.009)\tLoss 0.1856 (0.1860)\tPrec@1 94.531 (93.690)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [184][270/329], lr: 0.00000\tTime 0.097 (0.092)\tData 0.000 (0.009)\tLoss 0.2076 (0.1861)\tPrec@1 92.969 (93.672)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [184][280/329], lr: 0.00000\tTime 0.098 (0.092)\tData 0.005 (0.009)\tLoss 0.1889 (0.1863)\tPrec@1 94.531 (93.672)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [184][290/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.001 (0.009)\tLoss 0.2170 (0.1860)\tPrec@1 94.141 (93.690)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [184][300/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.008 (0.009)\tLoss 0.1680 (0.1855)\tPrec@1 94.922 (93.728)\tPrec@5 99.609 (99.859)\n",
            "Epoch: [184][310/329], lr: 0.00000\tTime 0.108 (0.092)\tData 0.011 (0.009)\tLoss 0.1780 (0.1848)\tPrec@1 93.359 (93.756)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [184][320/329], lr: 0.00000\tTime 0.116 (0.092)\tData 0.073 (0.009)\tLoss 0.1937 (0.1845)\tPrec@1 92.188 (93.768)\tPrec@5 99.609 (99.861)\n",
            "Test: [0/100]\tTime 0.391 (0.391)\tLoss 0.4250 (0.4250)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.017 (0.059)\tLoss 0.4889 (0.6303)\tPrec@1 85.000 (81.636)\tPrec@5 97.000 (98.909)\n",
            "Test: [20/100]\tTime 0.032 (0.043)\tLoss 0.5930 (0.6399)\tPrec@1 81.000 (81.619)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.010 (0.037)\tLoss 0.7641 (0.6542)\tPrec@1 77.000 (81.226)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.023 (0.035)\tLoss 0.7163 (0.6594)\tPrec@1 78.000 (80.976)\tPrec@5 98.000 (98.634)\n",
            "Test: [50/100]\tTime 0.014 (0.032)\tLoss 0.6358 (0.6521)\tPrec@1 84.000 (81.216)\tPrec@5 98.000 (98.647)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 0.4942 (0.6574)\tPrec@1 86.000 (80.639)\tPrec@5 100.000 (98.738)\n",
            "Test: [70/100]\tTime 0.009 (0.030)\tLoss 0.7469 (0.6516)\tPrec@1 79.000 (80.704)\tPrec@5 99.000 (98.803)\n",
            "Test: [80/100]\tTime 0.037 (0.029)\tLoss 0.5701 (0.6456)\tPrec@1 87.000 (80.877)\tPrec@5 98.000 (98.840)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 0.5255 (0.6538)\tPrec@1 86.000 (80.692)\tPrec@5 100.000 (98.813)\n",
            "val Results: Prec@1 80.610 Prec@5 98.800 Loss 0.65139\n",
            "val Class Accuracy: [0.961,0.979,0.858,0.754,0.765,0.754,0.844,0.709,0.718,0.719]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [185][0/329], lr: 0.00000\tTime 0.639 (0.639)\tData 0.545 (0.545)\tLoss 0.2049 (0.2049)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][10/329], lr: 0.00000\tTime 0.115 (0.156)\tData 0.000 (0.055)\tLoss 0.2363 (0.1951)\tPrec@1 92.188 (93.395)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [185][20/329], lr: 0.00000\tTime 0.081 (0.125)\tData 0.008 (0.033)\tLoss 0.2780 (0.1995)\tPrec@1 90.625 (93.341)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [185][30/329], lr: 0.00000\tTime 0.081 (0.113)\tData 0.001 (0.025)\tLoss 0.1638 (0.1947)\tPrec@1 95.312 (93.410)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [185][40/329], lr: 0.00000\tTime 0.083 (0.108)\tData 0.006 (0.022)\tLoss 0.1732 (0.1903)\tPrec@1 94.141 (93.531)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [185][50/329], lr: 0.00000\tTime 0.092 (0.104)\tData 0.004 (0.019)\tLoss 0.2486 (0.1877)\tPrec@1 91.797 (93.673)\tPrec@5 99.609 (99.885)\n",
            "Epoch: [185][60/329], lr: 0.00000\tTime 0.104 (0.102)\tData 0.012 (0.016)\tLoss 0.1789 (0.1882)\tPrec@1 94.922 (93.718)\tPrec@5 99.219 (99.859)\n",
            "Epoch: [185][70/329], lr: 0.00000\tTime 0.079 (0.101)\tData 0.006 (0.015)\tLoss 0.1762 (0.1875)\tPrec@1 94.141 (93.700)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [185][80/329], lr: 0.00000\tTime 0.114 (0.099)\tData 0.006 (0.014)\tLoss 0.2187 (0.1907)\tPrec@1 92.188 (93.581)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [185][90/329], lr: 0.00000\tTime 0.099 (0.098)\tData 0.007 (0.013)\tLoss 0.1988 (0.1895)\tPrec@1 91.797 (93.630)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [185][100/329], lr: 0.00000\tTime 0.091 (0.097)\tData 0.017 (0.013)\tLoss 0.1373 (0.1886)\tPrec@1 95.703 (93.665)\tPrec@5 100.000 (99.830)\n",
            "Epoch: [185][110/329], lr: 0.00000\tTime 0.078 (0.097)\tData 0.007 (0.012)\tLoss 0.1672 (0.1896)\tPrec@1 92.578 (93.599)\tPrec@5 100.000 (99.835)\n",
            "Epoch: [185][120/329], lr: 0.00000\tTime 0.082 (0.096)\tData 0.005 (0.012)\tLoss 0.1732 (0.1884)\tPrec@1 93.750 (93.627)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [185][130/329], lr: 0.00000\tTime 0.093 (0.095)\tData 0.000 (0.011)\tLoss 0.2204 (0.1869)\tPrec@1 91.406 (93.664)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [185][140/329], lr: 0.00000\tTime 0.085 (0.095)\tData 0.003 (0.011)\tLoss 0.2539 (0.1880)\tPrec@1 91.016 (93.631)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [185][150/329], lr: 0.00000\tTime 0.092 (0.095)\tData 0.007 (0.011)\tLoss 0.1536 (0.1875)\tPrec@1 94.922 (93.652)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [185][160/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.000 (0.011)\tLoss 0.1967 (0.1885)\tPrec@1 93.359 (93.651)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [185][170/329], lr: 0.00000\tTime 0.084 (0.094)\tData 0.000 (0.011)\tLoss 0.2141 (0.1887)\tPrec@1 92.578 (93.633)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [185][180/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.004 (0.010)\tLoss 0.1867 (0.1873)\tPrec@1 93.359 (93.662)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [185][190/329], lr: 0.00000\tTime 0.075 (0.094)\tData 0.000 (0.010)\tLoss 0.1348 (0.1872)\tPrec@1 95.703 (93.668)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [185][200/329], lr: 0.00000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.1571 (0.1874)\tPrec@1 94.922 (93.657)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [185][210/329], lr: 0.00000\tTime 0.084 (0.093)\tData 0.011 (0.010)\tLoss 0.1687 (0.1868)\tPrec@1 94.141 (93.665)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [185][220/329], lr: 0.00000\tTime 0.095 (0.093)\tData 0.007 (0.010)\tLoss 0.1298 (0.1864)\tPrec@1 94.531 (93.667)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [185][230/329], lr: 0.00000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 0.2345 (0.1866)\tPrec@1 91.016 (93.657)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [185][240/329], lr: 0.00000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 0.2079 (0.1864)\tPrec@1 92.969 (93.667)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [185][250/329], lr: 0.00000\tTime 0.100 (0.093)\tData 0.007 (0.010)\tLoss 0.1286 (0.1862)\tPrec@1 96.484 (93.680)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [185][260/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.006 (0.010)\tLoss 0.1704 (0.1863)\tPrec@1 93.750 (93.675)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [185][270/329], lr: 0.00000\tTime 0.092 (0.092)\tData 0.000 (0.009)\tLoss 0.1852 (0.1864)\tPrec@1 92.188 (93.672)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [185][280/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.006 (0.009)\tLoss 0.1940 (0.1856)\tPrec@1 94.141 (93.694)\tPrec@5 99.609 (99.861)\n",
            "Epoch: [185][290/329], lr: 0.00000\tTime 0.075 (0.092)\tData 0.011 (0.009)\tLoss 0.1777 (0.1857)\tPrec@1 92.969 (93.682)\tPrec@5 100.000 (99.860)\n",
            "Epoch: [185][300/329], lr: 0.00000\tTime 0.102 (0.092)\tData 0.000 (0.009)\tLoss 0.2109 (0.1855)\tPrec@1 92.188 (93.689)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [185][310/329], lr: 0.00000\tTime 0.087 (0.092)\tData 0.006 (0.009)\tLoss 0.1714 (0.1856)\tPrec@1 94.531 (93.697)\tPrec@5 99.609 (99.856)\n",
            "Epoch: [185][320/329], lr: 0.00000\tTime 0.090 (0.092)\tData 0.058 (0.009)\tLoss 0.1997 (0.1858)\tPrec@1 92.188 (93.688)\tPrec@5 100.000 (99.860)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 0.4817 (0.4817)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.032 (0.059)\tLoss 0.5381 (0.6735)\tPrec@1 84.000 (80.909)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 0.6166 (0.6742)\tPrec@1 82.000 (80.429)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 0.7919 (0.6883)\tPrec@1 76.000 (80.226)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 0.7736 (0.6905)\tPrec@1 75.000 (80.024)\tPrec@5 99.000 (98.707)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 0.6397 (0.6835)\tPrec@1 86.000 (80.275)\tPrec@5 98.000 (98.765)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 0.5187 (0.6884)\tPrec@1 87.000 (79.918)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 0.7632 (0.6825)\tPrec@1 80.000 (79.944)\tPrec@5 99.000 (98.901)\n",
            "Test: [80/100]\tTime 0.048 (0.028)\tLoss 0.6196 (0.6768)\tPrec@1 83.000 (80.123)\tPrec@5 99.000 (98.963)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 0.5549 (0.6872)\tPrec@1 89.000 (80.000)\tPrec@5 100.000 (98.912)\n",
            "val Results: Prec@1 79.910 Prec@5 98.870 Loss 0.68744\n",
            "val Class Accuracy: [0.972,0.969,0.861,0.677,0.858,0.783,0.818,0.680,0.683,0.690]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [186][0/329], lr: 0.00000\tTime 0.659 (0.659)\tData 0.569 (0.569)\tLoss 0.2323 (0.2323)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][10/329], lr: 0.00000\tTime 0.092 (0.153)\tData 0.007 (0.060)\tLoss 0.1791 (0.1911)\tPrec@1 93.359 (93.395)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [186][20/329], lr: 0.00000\tTime 0.083 (0.123)\tData 0.000 (0.033)\tLoss 0.2456 (0.1879)\tPrec@1 91.406 (93.378)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [186][30/329], lr: 0.00000\tTime 0.072 (0.111)\tData 0.000 (0.024)\tLoss 0.2075 (0.1915)\tPrec@1 92.578 (93.448)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [186][40/329], lr: 0.00000\tTime 0.112 (0.107)\tData 0.012 (0.020)\tLoss 0.2670 (0.1871)\tPrec@1 91.016 (93.569)\tPrec@5 99.219 (99.848)\n",
            "Epoch: [186][50/329], lr: 0.00000\tTime 0.087 (0.104)\tData 0.005 (0.018)\tLoss 0.1882 (0.1854)\tPrec@1 94.531 (93.681)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [186][60/329], lr: 0.00000\tTime 0.080 (0.101)\tData 0.005 (0.016)\tLoss 0.2307 (0.1842)\tPrec@1 90.625 (93.731)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [186][70/329], lr: 0.00000\tTime 0.102 (0.099)\tData 0.005 (0.015)\tLoss 0.1799 (0.1830)\tPrec@1 93.750 (93.783)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [186][80/329], lr: 0.00000\tTime 0.101 (0.098)\tData 0.007 (0.014)\tLoss 0.2044 (0.1834)\tPrec@1 93.359 (93.769)\tPrec@5 100.000 (99.860)\n",
            "Epoch: [186][90/329], lr: 0.00000\tTime 0.094 (0.097)\tData 0.003 (0.013)\tLoss 0.1698 (0.1839)\tPrec@1 94.922 (93.771)\tPrec@5 99.609 (99.863)\n",
            "Epoch: [186][100/329], lr: 0.00000\tTime 0.094 (0.096)\tData 0.007 (0.013)\tLoss 0.2281 (0.1844)\tPrec@1 93.359 (93.750)\tPrec@5 99.609 (99.865)\n",
            "Epoch: [186][110/329], lr: 0.00000\tTime 0.087 (0.096)\tData 0.009 (0.012)\tLoss 0.1748 (0.1837)\tPrec@1 94.922 (93.810)\tPrec@5 99.609 (99.859)\n",
            "Epoch: [186][120/329], lr: 0.00000\tTime 0.089 (0.095)\tData 0.004 (0.012)\tLoss 0.1724 (0.1838)\tPrec@1 94.531 (93.792)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [186][130/329], lr: 0.00000\tTime 0.068 (0.095)\tData 0.007 (0.012)\tLoss 0.2514 (0.1825)\tPrec@1 89.453 (93.786)\tPrec@5 99.609 (99.857)\n",
            "Epoch: [186][140/329], lr: 0.00000\tTime 0.085 (0.094)\tData 0.006 (0.012)\tLoss 0.1478 (0.1824)\tPrec@1 95.312 (93.819)\tPrec@5 99.609 (99.859)\n",
            "Epoch: [186][150/329], lr: 0.00000\tTime 0.076 (0.094)\tData 0.000 (0.011)\tLoss 0.1655 (0.1829)\tPrec@1 94.531 (93.791)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [186][160/329], lr: 0.00000\tTime 0.094 (0.094)\tData 0.007 (0.011)\tLoss 0.1886 (0.1840)\tPrec@1 93.750 (93.760)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [186][170/329], lr: 0.00000\tTime 0.094 (0.094)\tData 0.007 (0.011)\tLoss 0.1835 (0.1840)\tPrec@1 94.141 (93.761)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [186][180/329], lr: 0.00000\tTime 0.149 (0.095)\tData 0.019 (0.011)\tLoss 0.2365 (0.1836)\tPrec@1 92.969 (93.793)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [186][190/329], lr: 0.00000\tTime 0.103 (0.097)\tData 0.003 (0.012)\tLoss 0.2548 (0.1832)\tPrec@1 92.188 (93.801)\tPrec@5 99.219 (99.847)\n",
            "Epoch: [186][200/329], lr: 0.00000\tTime 0.095 (0.097)\tData 0.000 (0.012)\tLoss 0.1771 (0.1836)\tPrec@1 94.141 (93.789)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [186][210/329], lr: 0.00000\tTime 0.096 (0.098)\tData 0.000 (0.012)\tLoss 0.1910 (0.1848)\tPrec@1 94.531 (93.763)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [186][220/329], lr: 0.00000\tTime 0.103 (0.098)\tData 0.005 (0.012)\tLoss 0.1429 (0.1845)\tPrec@1 95.312 (93.771)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [186][230/329], lr: 0.00000\tTime 0.076 (0.097)\tData 0.000 (0.011)\tLoss 0.2115 (0.1853)\tPrec@1 92.578 (93.747)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [186][240/329], lr: 0.00000\tTime 0.097 (0.097)\tData 0.005 (0.011)\tLoss 0.1107 (0.1847)\tPrec@1 96.875 (93.773)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [186][250/329], lr: 0.00000\tTime 0.081 (0.097)\tData 0.000 (0.011)\tLoss 0.2574 (0.1856)\tPrec@1 92.188 (93.719)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [186][260/329], lr: 0.00000\tTime 0.101 (0.097)\tData 0.007 (0.011)\tLoss 0.2048 (0.1862)\tPrec@1 92.188 (93.704)\tPrec@5 99.609 (99.844)\n",
            "Epoch: [186][270/329], lr: 0.00000\tTime 0.092 (0.097)\tData 0.015 (0.011)\tLoss 0.2099 (0.1859)\tPrec@1 94.141 (93.715)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [186][280/329], lr: 0.00000\tTime 0.099 (0.096)\tData 0.000 (0.011)\tLoss 0.2250 (0.1857)\tPrec@1 89.844 (93.708)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [186][290/329], lr: 0.00000\tTime 0.093 (0.096)\tData 0.010 (0.011)\tLoss 0.1990 (0.1864)\tPrec@1 92.578 (93.683)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [186][300/329], lr: 0.00000\tTime 0.092 (0.096)\tData 0.005 (0.010)\tLoss 0.1917 (0.1863)\tPrec@1 93.359 (93.680)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [186][310/329], lr: 0.00000\tTime 0.085 (0.095)\tData 0.000 (0.010)\tLoss 0.1933 (0.1858)\tPrec@1 93.359 (93.706)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [186][320/329], lr: 0.00000\tTime 0.110 (0.095)\tData 0.067 (0.010)\tLoss 0.1601 (0.1856)\tPrec@1 95.312 (93.723)\tPrec@5 100.000 (99.843)\n",
            "Test: [0/100]\tTime 0.368 (0.368)\tLoss 0.4431 (0.4431)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.034 (0.060)\tLoss 0.5103 (0.6418)\tPrec@1 85.000 (81.182)\tPrec@5 97.000 (99.000)\n",
            "Test: [20/100]\tTime 0.055 (0.044)\tLoss 0.6281 (0.6502)\tPrec@1 82.000 (81.333)\tPrec@5 100.000 (98.619)\n",
            "Test: [30/100]\tTime 0.020 (0.037)\tLoss 0.8253 (0.6672)\tPrec@1 77.000 (81.097)\tPrec@5 98.000 (98.613)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 0.7519 (0.6722)\tPrec@1 76.000 (80.902)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 0.6543 (0.6653)\tPrec@1 85.000 (81.000)\tPrec@5 98.000 (98.588)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 0.5183 (0.6714)\tPrec@1 87.000 (80.410)\tPrec@5 100.000 (98.689)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 0.7376 (0.6640)\tPrec@1 80.000 (80.437)\tPrec@5 99.000 (98.732)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 0.5969 (0.6585)\tPrec@1 86.000 (80.617)\tPrec@5 99.000 (98.802)\n",
            "Test: [90/100]\tTime 0.031 (0.029)\tLoss 0.5428 (0.6672)\tPrec@1 86.000 (80.440)\tPrec@5 100.000 (98.780)\n",
            "val Results: Prec@1 80.350 Prec@5 98.780 Loss 0.66518\n",
            "val Class Accuracy: [0.962,0.971,0.848,0.761,0.809,0.769,0.828,0.645,0.702,0.740]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [187][0/329], lr: 0.00000\tTime 0.661 (0.661)\tData 0.568 (0.568)\tLoss 0.1706 (0.1706)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][10/329], lr: 0.00000\tTime 0.103 (0.148)\tData 0.002 (0.058)\tLoss 0.1935 (0.1859)\tPrec@1 93.359 (93.679)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [187][20/329], lr: 0.00000\tTime 0.104 (0.123)\tData 0.000 (0.032)\tLoss 0.1800 (0.1818)\tPrec@1 92.969 (93.824)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [187][30/329], lr: 0.00000\tTime 0.095 (0.112)\tData 0.005 (0.024)\tLoss 0.1692 (0.1840)\tPrec@1 94.141 (93.775)\tPrec@5 100.000 (99.786)\n",
            "Epoch: [187][40/329], lr: 0.00000\tTime 0.093 (0.107)\tData 0.000 (0.020)\tLoss 0.1540 (0.1855)\tPrec@1 95.703 (93.817)\tPrec@5 100.000 (99.809)\n",
            "Epoch: [187][50/329], lr: 0.00000\tTime 0.094 (0.104)\tData 0.012 (0.017)\tLoss 0.1769 (0.1886)\tPrec@1 92.578 (93.597)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [187][60/329], lr: 0.00000\tTime 0.095 (0.102)\tData 0.011 (0.016)\tLoss 0.1579 (0.1895)\tPrec@1 94.922 (93.519)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [187][70/329], lr: 0.00000\tTime 0.101 (0.100)\tData 0.006 (0.015)\tLoss 0.2072 (0.1884)\tPrec@1 93.359 (93.557)\tPrec@5 99.219 (99.846)\n",
            "Epoch: [187][80/329], lr: 0.00000\tTime 0.104 (0.098)\tData 0.000 (0.014)\tLoss 0.1743 (0.1870)\tPrec@1 94.141 (93.634)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [187][90/329], lr: 0.00000\tTime 0.084 (0.098)\tData 0.000 (0.013)\tLoss 0.1697 (0.1865)\tPrec@1 93.750 (93.617)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [187][100/329], lr: 0.00000\tTime 0.090 (0.097)\tData 0.000 (0.012)\tLoss 0.2430 (0.1859)\tPrec@1 92.969 (93.665)\tPrec@5 99.609 (99.865)\n",
            "Epoch: [187][110/329], lr: 0.00000\tTime 0.087 (0.097)\tData 0.002 (0.012)\tLoss 0.1298 (0.1852)\tPrec@1 96.094 (93.697)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [187][120/329], lr: 0.00000\tTime 0.082 (0.096)\tData 0.000 (0.011)\tLoss 0.2400 (0.1864)\tPrec@1 92.188 (93.702)\tPrec@5 99.609 (99.868)\n",
            "Epoch: [187][130/329], lr: 0.00000\tTime 0.087 (0.096)\tData 0.005 (0.011)\tLoss 0.1342 (0.1874)\tPrec@1 95.703 (93.699)\tPrec@5 100.000 (99.869)\n",
            "Epoch: [187][140/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.007 (0.011)\tLoss 0.1688 (0.1885)\tPrec@1 93.750 (93.675)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [187][150/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.000 (0.010)\tLoss 0.1646 (0.1879)\tPrec@1 95.312 (93.685)\tPrec@5 99.609 (99.860)\n",
            "Epoch: [187][160/329], lr: 0.00000\tTime 0.084 (0.094)\tData 0.000 (0.010)\tLoss 0.2174 (0.1877)\tPrec@1 91.406 (93.680)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [187][170/329], lr: 0.00000\tTime 0.097 (0.094)\tData 0.000 (0.010)\tLoss 0.1499 (0.1874)\tPrec@1 94.531 (93.665)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [187][180/329], lr: 0.00000\tTime 0.092 (0.094)\tData 0.007 (0.010)\tLoss 0.2398 (0.1871)\tPrec@1 92.578 (93.705)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [187][190/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.007 (0.009)\tLoss 0.2003 (0.1877)\tPrec@1 94.531 (93.717)\tPrec@5 99.609 (99.857)\n",
            "Epoch: [187][200/329], lr: 0.00000\tTime 0.066 (0.093)\tData 0.015 (0.009)\tLoss 0.1902 (0.1871)\tPrec@1 92.969 (93.740)\tPrec@5 100.000 (99.860)\n",
            "Epoch: [187][210/329], lr: 0.00000\tTime 0.098 (0.093)\tData 0.005 (0.009)\tLoss 0.1706 (0.1873)\tPrec@1 93.359 (93.709)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [187][220/329], lr: 0.00000\tTime 0.110 (0.093)\tData 0.007 (0.009)\tLoss 0.2732 (0.1870)\tPrec@1 90.234 (93.723)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [187][230/329], lr: 0.00000\tTime 0.104 (0.093)\tData 0.000 (0.009)\tLoss 0.1810 (0.1865)\tPrec@1 93.750 (93.743)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [187][240/329], lr: 0.00000\tTime 0.073 (0.093)\tData 0.000 (0.009)\tLoss 0.1647 (0.1860)\tPrec@1 94.141 (93.761)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [187][250/329], lr: 0.00000\tTime 0.084 (0.092)\tData 0.004 (0.009)\tLoss 0.1254 (0.1854)\tPrec@1 96.875 (93.789)\tPrec@5 99.609 (99.860)\n",
            "Epoch: [187][260/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.000 (0.009)\tLoss 0.1580 (0.1856)\tPrec@1 95.703 (93.783)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [187][270/329], lr: 0.00000\tTime 0.097 (0.092)\tData 0.007 (0.009)\tLoss 0.1852 (0.1850)\tPrec@1 94.531 (93.800)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [187][280/329], lr: 0.00000\tTime 0.093 (0.092)\tData 0.006 (0.009)\tLoss 0.1913 (0.1857)\tPrec@1 92.578 (93.779)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [187][290/329], lr: 0.00000\tTime 0.078 (0.092)\tData 0.000 (0.009)\tLoss 0.1748 (0.1852)\tPrec@1 94.531 (93.794)\tPrec@5 100.000 (99.863)\n",
            "Epoch: [187][300/329], lr: 0.00000\tTime 0.081 (0.092)\tData 0.000 (0.008)\tLoss 0.1823 (0.1849)\tPrec@1 92.188 (93.788)\tPrec@5 99.609 (99.865)\n",
            "Epoch: [187][310/329], lr: 0.00000\tTime 0.115 (0.092)\tData 0.000 (0.008)\tLoss 0.2110 (0.1855)\tPrec@1 92.188 (93.775)\tPrec@5 99.219 (99.859)\n",
            "Epoch: [187][320/329], lr: 0.00000\tTime 0.081 (0.092)\tData 0.041 (0.008)\tLoss 0.2016 (0.1855)\tPrec@1 91.797 (93.760)\tPrec@5 99.609 (99.858)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 0.4309 (0.4309)\tPrec@1 87.000 (87.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.035 (0.059)\tLoss 0.4918 (0.6175)\tPrec@1 84.000 (82.364)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.019 (0.043)\tLoss 0.6111 (0.6173)\tPrec@1 85.000 (82.762)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 0.7565 (0.6348)\tPrec@1 75.000 (82.323)\tPrec@5 100.000 (98.645)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 0.6691 (0.6397)\tPrec@1 78.000 (81.951)\tPrec@5 98.000 (98.634)\n",
            "Test: [50/100]\tTime 0.010 (0.032)\tLoss 0.5995 (0.6312)\tPrec@1 86.000 (82.098)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 0.4999 (0.6349)\tPrec@1 86.000 (81.525)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.025 (0.030)\tLoss 0.6633 (0.6280)\tPrec@1 81.000 (81.577)\tPrec@5 100.000 (98.915)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 0.5716 (0.6225)\tPrec@1 86.000 (81.716)\tPrec@5 99.000 (98.975)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 0.4934 (0.6296)\tPrec@1 87.000 (81.560)\tPrec@5 100.000 (98.956)\n",
            "val Results: Prec@1 81.450 Prec@5 98.940 Loss 0.62738\n",
            "val Class Accuracy: [0.954,0.968,0.852,0.782,0.840,0.739,0.843,0.708,0.749,0.710]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [188][0/329], lr: 0.00000\tTime 0.708 (0.708)\tData 0.617 (0.617)\tLoss 0.1417 (0.1417)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][10/329], lr: 0.00000\tTime 0.093 (0.158)\tData 0.005 (0.063)\tLoss 0.2367 (0.1872)\tPrec@1 91.406 (93.714)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [188][20/329], lr: 0.00000\tTime 0.092 (0.126)\tData 0.005 (0.037)\tLoss 0.1169 (0.1860)\tPrec@1 95.703 (93.545)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [188][30/329], lr: 0.00000\tTime 0.094 (0.115)\tData 0.005 (0.027)\tLoss 0.1764 (0.1807)\tPrec@1 94.531 (93.889)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [188][40/329], lr: 0.00000\tTime 0.085 (0.108)\tData 0.006 (0.023)\tLoss 0.1893 (0.1770)\tPrec@1 92.969 (94.036)\tPrec@5 99.609 (99.828)\n",
            "Epoch: [188][50/329], lr: 0.00000\tTime 0.081 (0.104)\tData 0.000 (0.019)\tLoss 0.1684 (0.1784)\tPrec@1 93.750 (94.003)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [188][60/329], lr: 0.00000\tTime 0.059 (0.102)\tData 0.006 (0.017)\tLoss 0.1534 (0.1822)\tPrec@1 95.312 (93.936)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [188][70/329], lr: 0.00000\tTime 0.066 (0.100)\tData 0.000 (0.016)\tLoss 0.1933 (0.1828)\tPrec@1 94.922 (93.959)\tPrec@5 99.609 (99.813)\n",
            "Epoch: [188][80/329], lr: 0.00000\tTime 0.093 (0.099)\tData 0.007 (0.015)\tLoss 0.1526 (0.1842)\tPrec@1 94.922 (93.895)\tPrec@5 99.609 (99.807)\n",
            "Epoch: [188][90/329], lr: 0.00000\tTime 0.085 (0.098)\tData 0.006 (0.014)\tLoss 0.1779 (0.1855)\tPrec@1 94.141 (93.844)\tPrec@5 100.000 (99.815)\n",
            "Epoch: [188][100/329], lr: 0.00000\tTime 0.097 (0.097)\tData 0.007 (0.014)\tLoss 0.1739 (0.1858)\tPrec@1 92.969 (93.858)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [188][110/329], lr: 0.00000\tTime 0.086 (0.096)\tData 0.007 (0.013)\tLoss 0.1457 (0.1854)\tPrec@1 95.703 (93.813)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [188][120/329], lr: 0.00000\tTime 0.103 (0.096)\tData 0.011 (0.013)\tLoss 0.1794 (0.1836)\tPrec@1 95.703 (93.847)\tPrec@5 99.609 (99.829)\n",
            "Epoch: [188][130/329], lr: 0.00000\tTime 0.097 (0.095)\tData 0.006 (0.012)\tLoss 0.1607 (0.1833)\tPrec@1 95.703 (93.836)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [188][140/329], lr: 0.00000\tTime 0.082 (0.095)\tData 0.000 (0.012)\tLoss 0.1917 (0.1836)\tPrec@1 93.359 (93.850)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [188][150/329], lr: 0.00000\tTime 0.083 (0.095)\tData 0.004 (0.011)\tLoss 0.2238 (0.1831)\tPrec@1 91.797 (93.851)\tPrec@5 100.000 (99.834)\n",
            "Epoch: [188][160/329], lr: 0.00000\tTime 0.095 (0.094)\tData 0.000 (0.011)\tLoss 0.1509 (0.1834)\tPrec@1 93.750 (93.818)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [188][170/329], lr: 0.00000\tTime 0.093 (0.094)\tData 0.006 (0.011)\tLoss 0.2351 (0.1853)\tPrec@1 93.750 (93.755)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [188][180/329], lr: 0.00000\tTime 0.084 (0.094)\tData 0.005 (0.011)\tLoss 0.1301 (0.1844)\tPrec@1 96.484 (93.795)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [188][190/329], lr: 0.00000\tTime 0.104 (0.094)\tData 0.007 (0.010)\tLoss 0.2553 (0.1851)\tPrec@1 91.797 (93.785)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [188][200/329], lr: 0.00000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.1281 (0.1840)\tPrec@1 95.312 (93.824)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [188][210/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.002 (0.010)\tLoss 0.1975 (0.1841)\tPrec@1 92.578 (93.835)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [188][220/329], lr: 0.00000\tTime 0.091 (0.093)\tData 0.004 (0.010)\tLoss 0.2143 (0.1843)\tPrec@1 93.359 (93.833)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [188][230/329], lr: 0.00000\tTime 0.089 (0.093)\tData 0.004 (0.010)\tLoss 0.2028 (0.1847)\tPrec@1 92.578 (93.806)\tPrec@5 99.609 (99.834)\n",
            "Epoch: [188][240/329], lr: 0.00000\tTime 0.080 (0.093)\tData 0.000 (0.010)\tLoss 0.1744 (0.1856)\tPrec@1 93.359 (93.771)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [188][250/329], lr: 0.00000\tTime 0.098 (0.093)\tData 0.006 (0.010)\tLoss 0.1548 (0.1857)\tPrec@1 96.094 (93.772)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [188][260/329], lr: 0.00000\tTime 0.094 (0.092)\tData 0.006 (0.010)\tLoss 0.2493 (0.1859)\tPrec@1 92.188 (93.757)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [188][270/329], lr: 0.00000\tTime 0.075 (0.092)\tData 0.000 (0.009)\tLoss 0.1887 (0.1853)\tPrec@1 93.359 (93.789)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [188][280/329], lr: 0.00000\tTime 0.077 (0.092)\tData 0.005 (0.009)\tLoss 0.1949 (0.1855)\tPrec@1 94.531 (93.781)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [188][290/329], lr: 0.00000\tTime 0.081 (0.092)\tData 0.007 (0.009)\tLoss 0.2770 (0.1853)\tPrec@1 91.406 (93.776)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [188][300/329], lr: 0.00000\tTime 0.079 (0.092)\tData 0.000 (0.009)\tLoss 0.1941 (0.1854)\tPrec@1 94.141 (93.776)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [188][310/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.007 (0.009)\tLoss 0.2301 (0.1852)\tPrec@1 92.578 (93.793)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [188][320/329], lr: 0.00000\tTime 0.107 (0.092)\tData 0.066 (0.009)\tLoss 0.1739 (0.1850)\tPrec@1 94.922 (93.801)\tPrec@5 100.000 (99.841)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 0.4364 (0.4364)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.010 (0.059)\tLoss 0.4984 (0.6379)\tPrec@1 85.000 (81.727)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.016 (0.039)\tLoss 0.5973 (0.6415)\tPrec@1 83.000 (81.667)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 0.7928 (0.6583)\tPrec@1 76.000 (81.355)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 0.7146 (0.6634)\tPrec@1 75.000 (81.073)\tPrec@5 98.000 (98.634)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6389 (0.6561)\tPrec@1 86.000 (81.216)\tPrec@5 98.000 (98.667)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 0.4963 (0.6617)\tPrec@1 87.000 (80.541)\tPrec@5 100.000 (98.770)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 0.7262 (0.6538)\tPrec@1 81.000 (80.648)\tPrec@5 99.000 (98.845)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 0.6115 (0.6486)\tPrec@1 85.000 (80.840)\tPrec@5 99.000 (98.901)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 0.5396 (0.6562)\tPrec@1 85.000 (80.670)\tPrec@5 100.000 (98.857)\n",
            "val Results: Prec@1 80.580 Prec@5 98.830 Loss 0.65436\n",
            "val Class Accuracy: [0.963,0.970,0.839,0.782,0.816,0.760,0.829,0.676,0.705,0.718]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [189][0/329], lr: 0.00000\tTime 0.688 (0.688)\tData 0.611 (0.611)\tLoss 0.1586 (0.1586)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][10/329], lr: 0.00000\tTime 0.077 (0.151)\tData 0.000 (0.062)\tLoss 0.1876 (0.1910)\tPrec@1 93.750 (93.430)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [189][20/329], lr: 0.00000\tTime 0.094 (0.123)\tData 0.007 (0.035)\tLoss 0.1520 (0.1799)\tPrec@1 95.312 (93.973)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [189][30/329], lr: 0.00000\tTime 0.107 (0.111)\tData 0.006 (0.026)\tLoss 0.2162 (0.1848)\tPrec@1 92.969 (93.813)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [189][40/329], lr: 0.00000\tTime 0.103 (0.106)\tData 0.006 (0.022)\tLoss 0.1784 (0.1874)\tPrec@1 93.750 (93.883)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [189][50/329], lr: 0.00000\tTime 0.104 (0.102)\tData 0.010 (0.018)\tLoss 0.1665 (0.1853)\tPrec@1 95.312 (93.949)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [189][60/329], lr: 0.00000\tTime 0.118 (0.099)\tData 0.006 (0.016)\tLoss 0.2003 (0.1878)\tPrec@1 93.359 (93.910)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [189][70/329], lr: 0.00000\tTime 0.084 (0.098)\tData 0.000 (0.015)\tLoss 0.1642 (0.1883)\tPrec@1 94.141 (93.833)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [189][80/329], lr: 0.00000\tTime 0.108 (0.097)\tData 0.011 (0.014)\tLoss 0.2096 (0.1877)\tPrec@1 93.750 (93.842)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [189][90/329], lr: 0.00000\tTime 0.089 (0.096)\tData 0.007 (0.013)\tLoss 0.1700 (0.1882)\tPrec@1 95.703 (93.849)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [189][100/329], lr: 0.00000\tTime 0.095 (0.095)\tData 0.000 (0.013)\tLoss 0.1791 (0.1877)\tPrec@1 93.750 (93.812)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [189][110/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.000 (0.012)\tLoss 0.1741 (0.1887)\tPrec@1 96.484 (93.803)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [189][120/329], lr: 0.00000\tTime 0.095 (0.094)\tData 0.005 (0.012)\tLoss 0.1919 (0.1878)\tPrec@1 93.750 (93.782)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [189][130/329], lr: 0.00000\tTime 0.087 (0.094)\tData 0.000 (0.011)\tLoss 0.2294 (0.1888)\tPrec@1 93.750 (93.738)\tPrec@5 99.219 (99.833)\n",
            "Epoch: [189][140/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.000 (0.011)\tLoss 0.1907 (0.1881)\tPrec@1 93.359 (93.728)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [189][150/329], lr: 0.00000\tTime 0.086 (0.093)\tData 0.001 (0.011)\tLoss 0.2572 (0.1880)\tPrec@1 92.578 (93.737)\tPrec@5 98.828 (99.824)\n",
            "Epoch: [189][160/329], lr: 0.00000\tTime 0.101 (0.093)\tData 0.009 (0.011)\tLoss 0.1688 (0.1869)\tPrec@1 94.531 (93.743)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [189][170/329], lr: 0.00000\tTime 0.073 (0.093)\tData 0.000 (0.010)\tLoss 0.2019 (0.1870)\tPrec@1 92.578 (93.727)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [189][180/329], lr: 0.00000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.1719 (0.1857)\tPrec@1 95.703 (93.772)\tPrec@5 100.000 (99.832)\n",
            "Epoch: [189][190/329], lr: 0.00000\tTime 0.082 (0.092)\tData 0.005 (0.010)\tLoss 0.2050 (0.1863)\tPrec@1 92.188 (93.728)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [189][200/329], lr: 0.00000\tTime 0.103 (0.092)\tData 0.007 (0.010)\tLoss 0.1861 (0.1864)\tPrec@1 93.750 (93.715)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [189][210/329], lr: 0.00000\tTime 0.077 (0.092)\tData 0.006 (0.010)\tLoss 0.1689 (0.1859)\tPrec@1 94.531 (93.739)\tPrec@5 100.000 (99.843)\n",
            "Epoch: [189][220/329], lr: 0.00000\tTime 0.084 (0.092)\tData 0.007 (0.010)\tLoss 0.2318 (0.1861)\tPrec@1 94.141 (93.732)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [189][230/329], lr: 0.00000\tTime 0.086 (0.091)\tData 0.000 (0.010)\tLoss 0.1716 (0.1861)\tPrec@1 94.141 (93.735)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [189][240/329], lr: 0.00000\tTime 0.093 (0.091)\tData 0.000 (0.010)\tLoss 0.2332 (0.1865)\tPrec@1 91.797 (93.731)\tPrec@5 99.219 (99.838)\n",
            "Epoch: [189][250/329], lr: 0.00000\tTime 0.088 (0.091)\tData 0.008 (0.010)\tLoss 0.1170 (0.1856)\tPrec@1 96.875 (93.750)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [189][260/329], lr: 0.00000\tTime 0.064 (0.091)\tData 0.000 (0.010)\tLoss 0.1543 (0.1854)\tPrec@1 96.875 (93.772)\tPrec@5 99.609 (99.843)\n",
            "Epoch: [189][270/329], lr: 0.00000\tTime 0.070 (0.091)\tData 0.000 (0.009)\tLoss 0.1488 (0.1853)\tPrec@1 94.922 (93.782)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [189][280/329], lr: 0.00000\tTime 0.088 (0.091)\tData 0.008 (0.009)\tLoss 0.1294 (0.1850)\tPrec@1 95.703 (93.811)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [189][290/329], lr: 0.00000\tTime 0.085 (0.091)\tData 0.005 (0.009)\tLoss 0.1601 (0.1849)\tPrec@1 94.922 (93.816)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [189][300/329], lr: 0.00000\tTime 0.087 (0.091)\tData 0.007 (0.009)\tLoss 0.2220 (0.1851)\tPrec@1 91.797 (93.816)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [189][310/329], lr: 0.00000\tTime 0.094 (0.091)\tData 0.012 (0.009)\tLoss 0.2123 (0.1854)\tPrec@1 92.969 (93.795)\tPrec@5 98.828 (99.842)\n",
            "Epoch: [189][320/329], lr: 0.00000\tTime 0.104 (0.091)\tData 0.059 (0.009)\tLoss 0.1685 (0.1854)\tPrec@1 95.703 (93.794)\tPrec@5 100.000 (99.842)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.4418 (0.4418)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.023 (0.059)\tLoss 0.5079 (0.6477)\tPrec@1 85.000 (81.909)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.026 (0.043)\tLoss 0.6255 (0.6467)\tPrec@1 80.000 (81.571)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.025 (0.037)\tLoss 0.7480 (0.6638)\tPrec@1 78.000 (81.226)\tPrec@5 99.000 (98.742)\n",
            "Test: [40/100]\tTime 0.032 (0.034)\tLoss 0.7090 (0.6665)\tPrec@1 79.000 (80.902)\tPrec@5 99.000 (98.780)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 0.6097 (0.6587)\tPrec@1 84.000 (81.078)\tPrec@5 98.000 (98.804)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 0.5108 (0.6640)\tPrec@1 89.000 (80.672)\tPrec@5 100.000 (98.885)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 0.7298 (0.6578)\tPrec@1 82.000 (80.662)\tPrec@5 99.000 (98.915)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 0.5978 (0.6525)\tPrec@1 84.000 (80.778)\tPrec@5 99.000 (98.963)\n",
            "Test: [90/100]\tTime 0.016 (0.028)\tLoss 0.5466 (0.6617)\tPrec@1 86.000 (80.604)\tPrec@5 100.000 (98.890)\n",
            "val Results: Prec@1 80.490 Prec@5 98.870 Loss 0.66031\n",
            "val Class Accuracy: [0.959,0.973,0.859,0.745,0.848,0.738,0.833,0.694,0.708,0.692]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [190][0/329], lr: 0.00000\tTime 0.661 (0.661)\tData 0.553 (0.553)\tLoss 0.1975 (0.1975)\tPrec@1 91.797 (91.797)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [190][10/329], lr: 0.00000\tTime 0.088 (0.148)\tData 0.000 (0.055)\tLoss 0.1982 (0.1901)\tPrec@1 92.188 (93.395)\tPrec@5 99.609 (99.716)\n",
            "Epoch: [190][20/329], lr: 0.00000\tTime 0.083 (0.120)\tData 0.000 (0.032)\tLoss 0.2842 (0.2040)\tPrec@1 90.234 (93.341)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [190][30/329], lr: 0.00000\tTime 0.084 (0.111)\tData 0.002 (0.024)\tLoss 0.2342 (0.2025)\tPrec@1 94.141 (93.536)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [190][40/329], lr: 0.00000\tTime 0.092 (0.106)\tData 0.007 (0.020)\tLoss 0.2070 (0.2017)\tPrec@1 91.406 (93.417)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [190][50/329], lr: 0.00000\tTime 0.071 (0.102)\tData 0.000 (0.017)\tLoss 0.1851 (0.1960)\tPrec@1 94.141 (93.528)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [190][60/329], lr: 0.00000\tTime 0.100 (0.101)\tData 0.006 (0.016)\tLoss 0.1557 (0.1911)\tPrec@1 94.922 (93.667)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [190][70/329], lr: 0.00000\tTime 0.094 (0.100)\tData 0.006 (0.014)\tLoss 0.1788 (0.1879)\tPrec@1 93.359 (93.816)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [190][80/329], lr: 0.00000\tTime 0.086 (0.098)\tData 0.006 (0.013)\tLoss 0.2396 (0.1871)\tPrec@1 93.750 (93.846)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [190][90/329], lr: 0.00000\tTime 0.100 (0.097)\tData 0.000 (0.013)\tLoss 0.1646 (0.1890)\tPrec@1 94.531 (93.741)\tPrec@5 100.000 (99.880)\n",
            "Epoch: [190][100/329], lr: 0.00000\tTime 0.094 (0.096)\tData 0.000 (0.012)\tLoss 0.1515 (0.1869)\tPrec@1 94.531 (93.796)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [190][110/329], lr: 0.00000\tTime 0.083 (0.096)\tData 0.007 (0.012)\tLoss 0.1544 (0.1867)\tPrec@1 94.531 (93.764)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [190][120/329], lr: 0.00000\tTime 0.111 (0.096)\tData 0.007 (0.011)\tLoss 0.2061 (0.1878)\tPrec@1 91.016 (93.734)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [190][130/329], lr: 0.00000\tTime 0.109 (0.095)\tData 0.007 (0.011)\tLoss 0.2185 (0.1886)\tPrec@1 91.016 (93.720)\tPrec@5 100.000 (99.869)\n",
            "Epoch: [190][140/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.008 (0.011)\tLoss 0.1475 (0.1878)\tPrec@1 94.922 (93.725)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [190][150/329], lr: 0.00000\tTime 0.071 (0.094)\tData 0.005 (0.011)\tLoss 0.1586 (0.1872)\tPrec@1 95.703 (93.750)\tPrec@5 100.000 (99.865)\n",
            "Epoch: [190][160/329], lr: 0.00000\tTime 0.109 (0.094)\tData 0.007 (0.011)\tLoss 0.1305 (0.1865)\tPrec@1 96.094 (93.784)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [190][170/329], lr: 0.00000\tTime 0.107 (0.094)\tData 0.007 (0.010)\tLoss 0.2009 (0.1858)\tPrec@1 93.750 (93.809)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [190][180/329], lr: 0.00000\tTime 0.077 (0.093)\tData 0.001 (0.010)\tLoss 0.1200 (0.1858)\tPrec@1 96.875 (93.819)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [190][190/329], lr: 0.00000\tTime 0.122 (0.093)\tData 0.007 (0.010)\tLoss 0.2394 (0.1864)\tPrec@1 92.188 (93.779)\tPrec@5 99.219 (99.867)\n",
            "Epoch: [190][200/329], lr: 0.00000\tTime 0.084 (0.093)\tData 0.005 (0.010)\tLoss 0.1635 (0.1870)\tPrec@1 94.141 (93.760)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [190][210/329], lr: 0.00000\tTime 0.092 (0.093)\tData 0.000 (0.010)\tLoss 0.1781 (0.1864)\tPrec@1 94.531 (93.774)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [190][220/329], lr: 0.00000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 0.1434 (0.1868)\tPrec@1 94.531 (93.745)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [190][230/329], lr: 0.00000\tTime 0.064 (0.092)\tData 0.000 (0.010)\tLoss 0.2155 (0.1861)\tPrec@1 92.969 (93.784)\tPrec@5 99.609 (99.866)\n",
            "Epoch: [190][240/329], lr: 0.00000\tTime 0.112 (0.093)\tData 0.003 (0.009)\tLoss 0.1592 (0.1856)\tPrec@1 94.141 (93.794)\tPrec@5 100.000 (99.869)\n",
            "Epoch: [190][250/329], lr: 0.00000\tTime 0.108 (0.093)\tData 0.000 (0.009)\tLoss 0.1955 (0.1854)\tPrec@1 94.141 (93.800)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [190][260/329], lr: 0.00000\tTime 0.146 (0.094)\tData 0.045 (0.009)\tLoss 0.1739 (0.1852)\tPrec@1 94.922 (93.814)\tPrec@5 100.000 (99.865)\n",
            "Epoch: [190][270/329], lr: 0.00000\tTime 0.086 (0.095)\tData 0.000 (0.010)\tLoss 0.1675 (0.1853)\tPrec@1 95.312 (93.813)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [190][280/329], lr: 0.00000\tTime 0.091 (0.095)\tData 0.000 (0.010)\tLoss 0.2212 (0.1853)\tPrec@1 93.359 (93.808)\tPrec@5 99.609 (99.862)\n",
            "Epoch: [190][290/329], lr: 0.00000\tTime 0.093 (0.095)\tData 0.007 (0.010)\tLoss 0.2251 (0.1860)\tPrec@1 91.797 (93.769)\tPrec@5 99.609 (99.860)\n",
            "Epoch: [190][300/329], lr: 0.00000\tTime 0.080 (0.095)\tData 0.000 (0.010)\tLoss 0.1194 (0.1860)\tPrec@1 95.703 (93.768)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [190][310/329], lr: 0.00000\tTime 0.069 (0.095)\tData 0.000 (0.010)\tLoss 0.1305 (0.1857)\tPrec@1 96.484 (93.784)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [190][320/329], lr: 0.00000\tTime 0.109 (0.095)\tData 0.063 (0.010)\tLoss 0.1399 (0.1859)\tPrec@1 95.703 (93.789)\tPrec@5 99.609 (99.856)\n",
            "Test: [0/100]\tTime 0.379 (0.379)\tLoss 0.4313 (0.4313)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.033 (0.060)\tLoss 0.5057 (0.6282)\tPrec@1 86.000 (82.455)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.014 (0.043)\tLoss 0.6172 (0.6287)\tPrec@1 80.000 (82.286)\tPrec@5 100.000 (98.714)\n",
            "Test: [30/100]\tTime 0.031 (0.038)\tLoss 0.7766 (0.6458)\tPrec@1 76.000 (81.839)\tPrec@5 100.000 (98.710)\n",
            "Test: [40/100]\tTime 0.049 (0.035)\tLoss 0.6927 (0.6502)\tPrec@1 78.000 (81.439)\tPrec@5 98.000 (98.683)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 0.6024 (0.6429)\tPrec@1 86.000 (81.549)\tPrec@5 98.000 (98.765)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 0.5033 (0.6482)\tPrec@1 89.000 (81.098)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.048 (0.030)\tLoss 0.6871 (0.6423)\tPrec@1 82.000 (81.000)\tPrec@5 100.000 (98.859)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 0.6036 (0.6365)\tPrec@1 85.000 (81.160)\tPrec@5 99.000 (98.926)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 0.5141 (0.6449)\tPrec@1 87.000 (80.967)\tPrec@5 100.000 (98.901)\n",
            "val Results: Prec@1 80.880 Prec@5 98.880 Loss 0.64277\n",
            "val Class Accuracy: [0.955,0.967,0.871,0.749,0.844,0.743,0.818,0.722,0.688,0.731]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [191][0/329], lr: 0.00000\tTime 0.524 (0.524)\tData 0.463 (0.463)\tLoss 0.1851 (0.1851)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][10/329], lr: 0.00000\tTime 0.068 (0.140)\tData 0.000 (0.061)\tLoss 0.2128 (0.1903)\tPrec@1 92.188 (93.395)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [191][20/329], lr: 0.00000\tTime 0.122 (0.119)\tData 0.006 (0.036)\tLoss 0.1686 (0.1770)\tPrec@1 94.922 (94.215)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [191][30/329], lr: 0.00000\tTime 0.097 (0.109)\tData 0.004 (0.026)\tLoss 0.1949 (0.1799)\tPrec@1 94.141 (94.052)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [191][40/329], lr: 0.00000\tTime 0.088 (0.104)\tData 0.000 (0.022)\tLoss 0.1818 (0.1825)\tPrec@1 95.312 (94.112)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [191][50/329], lr: 0.00000\tTime 0.070 (0.101)\tData 0.005 (0.019)\tLoss 0.2234 (0.1845)\tPrec@1 92.188 (94.033)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [191][60/329], lr: 0.00000\tTime 0.096 (0.099)\tData 0.007 (0.017)\tLoss 0.1665 (0.1850)\tPrec@1 94.141 (94.057)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [191][70/329], lr: 0.00000\tTime 0.081 (0.098)\tData 0.008 (0.016)\tLoss 0.1165 (0.1840)\tPrec@1 96.484 (94.003)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [191][80/329], lr: 0.00000\tTime 0.089 (0.097)\tData 0.006 (0.015)\tLoss 0.2099 (0.1845)\tPrec@1 92.188 (93.943)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [191][90/329], lr: 0.00000\tTime 0.092 (0.097)\tData 0.000 (0.014)\tLoss 0.1928 (0.1858)\tPrec@1 94.141 (93.900)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [191][100/329], lr: 0.00000\tTime 0.088 (0.096)\tData 0.006 (0.013)\tLoss 0.1808 (0.1869)\tPrec@1 93.750 (93.835)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [191][110/329], lr: 0.00000\tTime 0.090 (0.095)\tData 0.000 (0.013)\tLoss 0.2112 (0.1875)\tPrec@1 92.969 (93.810)\tPrec@5 99.609 (99.873)\n",
            "Epoch: [191][120/329], lr: 0.00000\tTime 0.078 (0.094)\tData 0.000 (0.012)\tLoss 0.1947 (0.1875)\tPrec@1 92.969 (93.802)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [191][130/329], lr: 0.00000\tTime 0.083 (0.094)\tData 0.004 (0.012)\tLoss 0.1805 (0.1867)\tPrec@1 94.922 (93.810)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [191][140/329], lr: 0.00000\tTime 0.086 (0.093)\tData 0.007 (0.012)\tLoss 0.2467 (0.1860)\tPrec@1 91.016 (93.836)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [191][150/329], lr: 0.00000\tTime 0.081 (0.093)\tData 0.000 (0.011)\tLoss 0.1783 (0.1857)\tPrec@1 92.578 (93.861)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [191][160/329], lr: 0.00000\tTime 0.096 (0.092)\tData 0.000 (0.011)\tLoss 0.1765 (0.1856)\tPrec@1 92.578 (93.820)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [191][170/329], lr: 0.00000\tTime 0.096 (0.092)\tData 0.000 (0.010)\tLoss 0.2147 (0.1866)\tPrec@1 92.969 (93.750)\tPrec@5 99.609 (99.856)\n",
            "Epoch: [191][180/329], lr: 0.00000\tTime 0.085 (0.092)\tData 0.010 (0.010)\tLoss 0.1709 (0.1866)\tPrec@1 92.969 (93.731)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [191][190/329], lr: 0.00000\tTime 0.089 (0.092)\tData 0.000 (0.010)\tLoss 0.1891 (0.1875)\tPrec@1 92.578 (93.687)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [191][200/329], lr: 0.00000\tTime 0.082 (0.092)\tData 0.007 (0.010)\tLoss 0.1331 (0.1866)\tPrec@1 96.094 (93.723)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [191][210/329], lr: 0.00000\tTime 0.072 (0.092)\tData 0.001 (0.010)\tLoss 0.1395 (0.1865)\tPrec@1 95.312 (93.717)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [191][220/329], lr: 0.00000\tTime 0.080 (0.091)\tData 0.003 (0.010)\tLoss 0.1716 (0.1865)\tPrec@1 92.188 (93.711)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [191][230/329], lr: 0.00000\tTime 0.133 (0.091)\tData 0.006 (0.009)\tLoss 0.2105 (0.1860)\tPrec@1 93.750 (93.733)\tPrec@5 99.219 (99.848)\n",
            "Epoch: [191][240/329], lr: 0.00000\tTime 0.101 (0.092)\tData 0.003 (0.009)\tLoss 0.1339 (0.1851)\tPrec@1 96.094 (93.779)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [191][250/329], lr: 0.00000\tTime 0.090 (0.091)\tData 0.000 (0.009)\tLoss 0.1307 (0.1841)\tPrec@1 95.703 (93.798)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [191][260/329], lr: 0.00000\tTime 0.093 (0.091)\tData 0.000 (0.009)\tLoss 0.2098 (0.1844)\tPrec@1 92.969 (93.793)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [191][270/329], lr: 0.00000\tTime 0.084 (0.091)\tData 0.005 (0.009)\tLoss 0.1728 (0.1846)\tPrec@1 93.750 (93.785)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [191][280/329], lr: 0.00000\tTime 0.096 (0.091)\tData 0.004 (0.009)\tLoss 0.1387 (0.1850)\tPrec@1 95.312 (93.760)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [191][290/329], lr: 0.00000\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 0.2438 (0.1856)\tPrec@1 90.625 (93.727)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [191][300/329], lr: 0.00000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.1406 (0.1855)\tPrec@1 93.750 (93.731)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [191][310/329], lr: 0.00000\tTime 0.095 (0.091)\tData 0.011 (0.009)\tLoss 0.1549 (0.1857)\tPrec@1 94.531 (93.725)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [191][320/329], lr: 0.00000\tTime 0.107 (0.091)\tData 0.069 (0.009)\tLoss 0.1623 (0.1851)\tPrec@1 95.312 (93.746)\tPrec@5 100.000 (99.848)\n",
            "Test: [0/100]\tTime 0.362 (0.362)\tLoss 0.4388 (0.4388)\tPrec@1 86.000 (86.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.016 (0.060)\tLoss 0.5134 (0.6335)\tPrec@1 86.000 (82.364)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.028 (0.042)\tLoss 0.6146 (0.6364)\tPrec@1 81.000 (82.143)\tPrec@5 100.000 (98.714)\n",
            "Test: [30/100]\tTime 0.038 (0.037)\tLoss 0.8044 (0.6524)\tPrec@1 75.000 (81.677)\tPrec@5 100.000 (98.742)\n",
            "Test: [40/100]\tTime 0.033 (0.034)\tLoss 0.7093 (0.6568)\tPrec@1 76.000 (81.220)\tPrec@5 98.000 (98.732)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6350 (0.6492)\tPrec@1 85.000 (81.451)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.029 (0.030)\tLoss 0.5056 (0.6548)\tPrec@1 85.000 (80.885)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 0.6929 (0.6485)\tPrec@1 79.000 (80.761)\tPrec@5 99.000 (98.859)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 0.6134 (0.6423)\tPrec@1 84.000 (80.963)\tPrec@5 99.000 (98.926)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 0.5171 (0.6507)\tPrec@1 87.000 (80.736)\tPrec@5 100.000 (98.901)\n",
            "val Results: Prec@1 80.670 Prec@5 98.890 Loss 0.64900\n",
            "val Class Accuracy: [0.958,0.963,0.874,0.761,0.842,0.733,0.811,0.719,0.686,0.720]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [192][0/329], lr: 0.00000\tTime 0.705 (0.705)\tData 0.619 (0.619)\tLoss 0.2096 (0.2096)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][10/329], lr: 0.00000\tTime 0.102 (0.149)\tData 0.000 (0.061)\tLoss 0.1831 (0.1769)\tPrec@1 93.359 (93.928)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [192][20/329], lr: 0.00000\tTime 0.110 (0.123)\tData 0.007 (0.035)\tLoss 0.1262 (0.1871)\tPrec@1 96.094 (93.545)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [192][30/329], lr: 0.00000\tTime 0.090 (0.112)\tData 0.006 (0.025)\tLoss 0.2183 (0.1868)\tPrec@1 91.797 (93.498)\tPrec@5 99.609 (99.861)\n",
            "Epoch: [192][40/329], lr: 0.00000\tTime 0.077 (0.106)\tData 0.006 (0.020)\tLoss 0.1518 (0.1862)\tPrec@1 94.922 (93.521)\tPrec@5 99.219 (99.819)\n",
            "Epoch: [192][50/329], lr: 0.00000\tTime 0.082 (0.103)\tData 0.000 (0.018)\tLoss 0.1811 (0.1851)\tPrec@1 91.797 (93.543)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [192][60/329], lr: 0.00000\tTime 0.096 (0.102)\tData 0.000 (0.016)\tLoss 0.2140 (0.1855)\tPrec@1 91.406 (93.635)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [192][70/329], lr: 0.00000\tTime 0.078 (0.101)\tData 0.000 (0.014)\tLoss 0.1873 (0.1873)\tPrec@1 94.531 (93.651)\tPrec@5 99.609 (99.835)\n",
            "Epoch: [192][80/329], lr: 0.00000\tTime 0.095 (0.099)\tData 0.004 (0.013)\tLoss 0.1927 (0.1869)\tPrec@1 92.969 (93.687)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [192][90/329], lr: 0.00000\tTime 0.085 (0.099)\tData 0.000 (0.012)\tLoss 0.1734 (0.1866)\tPrec@1 93.750 (93.707)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [192][100/329], lr: 0.00000\tTime 0.085 (0.098)\tData 0.010 (0.012)\tLoss 0.1911 (0.1867)\tPrec@1 95.312 (93.773)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [192][110/329], lr: 0.00000\tTime 0.093 (0.097)\tData 0.000 (0.011)\tLoss 0.2196 (0.1871)\tPrec@1 94.531 (93.768)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [192][120/329], lr: 0.00000\tTime 0.078 (0.096)\tData 0.000 (0.011)\tLoss 0.1502 (0.1869)\tPrec@1 94.922 (93.786)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [192][130/329], lr: 0.00000\tTime 0.083 (0.096)\tData 0.004 (0.011)\tLoss 0.1954 (0.1874)\tPrec@1 93.750 (93.747)\tPrec@5 99.609 (99.836)\n",
            "Epoch: [192][140/329], lr: 0.00000\tTime 0.087 (0.095)\tData 0.003 (0.011)\tLoss 0.2166 (0.1873)\tPrec@1 92.578 (93.717)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [192][150/329], lr: 0.00000\tTime 0.072 (0.095)\tData 0.000 (0.010)\tLoss 0.1791 (0.1867)\tPrec@1 94.922 (93.740)\tPrec@5 99.609 (99.840)\n",
            "Epoch: [192][160/329], lr: 0.00000\tTime 0.082 (0.095)\tData 0.005 (0.010)\tLoss 0.1259 (0.1876)\tPrec@1 95.312 (93.687)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [192][170/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.007 (0.010)\tLoss 0.1840 (0.1875)\tPrec@1 93.750 (93.711)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [192][180/329], lr: 0.00000\tTime 0.077 (0.094)\tData 0.006 (0.010)\tLoss 0.1520 (0.1865)\tPrec@1 94.141 (93.726)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [192][190/329], lr: 0.00000\tTime 0.096 (0.094)\tData 0.006 (0.010)\tLoss 0.1675 (0.1863)\tPrec@1 93.750 (93.723)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [192][200/329], lr: 0.00000\tTime 0.080 (0.094)\tData 0.010 (0.010)\tLoss 0.1721 (0.1858)\tPrec@1 93.750 (93.736)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [192][210/329], lr: 0.00000\tTime 0.076 (0.094)\tData 0.007 (0.009)\tLoss 0.2541 (0.1861)\tPrec@1 91.016 (93.741)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [192][220/329], lr: 0.00000\tTime 0.074 (0.093)\tData 0.006 (0.009)\tLoss 0.1543 (0.1855)\tPrec@1 94.922 (93.764)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [192][230/329], lr: 0.00000\tTime 0.099 (0.094)\tData 0.006 (0.009)\tLoss 0.2161 (0.1861)\tPrec@1 94.141 (93.750)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [192][240/329], lr: 0.00000\tTime 0.077 (0.093)\tData 0.000 (0.009)\tLoss 0.1960 (0.1866)\tPrec@1 93.359 (93.742)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [192][250/329], lr: 0.00000\tTime 0.098 (0.093)\tData 0.006 (0.009)\tLoss 0.1669 (0.1867)\tPrec@1 96.484 (93.758)\tPrec@5 99.609 (99.851)\n",
            "Epoch: [192][260/329], lr: 0.00000\tTime 0.074 (0.093)\tData 0.016 (0.009)\tLoss 0.2343 (0.1873)\tPrec@1 91.016 (93.735)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [192][270/329], lr: 0.00000\tTime 0.085 (0.093)\tData 0.000 (0.009)\tLoss 0.1413 (0.1874)\tPrec@1 95.312 (93.730)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [192][280/329], lr: 0.00000\tTime 0.079 (0.093)\tData 0.005 (0.009)\tLoss 0.1630 (0.1867)\tPrec@1 94.922 (93.760)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [192][290/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.005 (0.009)\tLoss 0.1623 (0.1864)\tPrec@1 94.531 (93.759)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [192][300/329], lr: 0.00000\tTime 0.106 (0.092)\tData 0.005 (0.009)\tLoss 0.1586 (0.1866)\tPrec@1 95.703 (93.753)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [192][310/329], lr: 0.00000\tTime 0.099 (0.092)\tData 0.002 (0.009)\tLoss 0.1603 (0.1859)\tPrec@1 94.922 (93.780)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [192][320/329], lr: 0.00000\tTime 0.104 (0.092)\tData 0.057 (0.009)\tLoss 0.2248 (0.1866)\tPrec@1 91.797 (93.750)\tPrec@5 99.609 (99.844)\n",
            "Test: [0/100]\tTime 0.401 (0.401)\tLoss 0.4284 (0.4284)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.018 (0.056)\tLoss 0.4991 (0.6461)\tPrec@1 85.000 (81.636)\tPrec@5 98.000 (99.182)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 0.6130 (0.6522)\tPrec@1 78.000 (81.333)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.032 (0.035)\tLoss 0.7576 (0.6669)\tPrec@1 77.000 (81.161)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 0.7103 (0.6723)\tPrec@1 78.000 (80.951)\tPrec@5 99.000 (98.683)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 0.6591 (0.6642)\tPrec@1 83.000 (81.176)\tPrec@5 98.000 (98.686)\n",
            "Test: [60/100]\tTime 0.020 (0.030)\tLoss 0.4921 (0.6697)\tPrec@1 85.000 (80.541)\tPrec@5 100.000 (98.754)\n",
            "Test: [70/100]\tTime 0.041 (0.029)\tLoss 0.7555 (0.6642)\tPrec@1 82.000 (80.592)\tPrec@5 99.000 (98.803)\n",
            "Test: [80/100]\tTime 0.035 (0.029)\tLoss 0.5936 (0.6579)\tPrec@1 84.000 (80.815)\tPrec@5 99.000 (98.864)\n",
            "Test: [90/100]\tTime 0.012 (0.028)\tLoss 0.5254 (0.6656)\tPrec@1 87.000 (80.593)\tPrec@5 100.000 (98.835)\n",
            "val Results: Prec@1 80.500 Prec@5 98.830 Loss 0.66273\n",
            "val Class Accuracy: [0.956,0.978,0.881,0.761,0.778,0.748,0.838,0.697,0.728,0.685]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [193][0/329], lr: 0.00000\tTime 0.713 (0.713)\tData 0.636 (0.636)\tLoss 0.1973 (0.1973)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][10/329], lr: 0.00000\tTime 0.090 (0.148)\tData 0.007 (0.064)\tLoss 0.1911 (0.1869)\tPrec@1 92.969 (93.359)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [193][20/329], lr: 0.00000\tTime 0.097 (0.122)\tData 0.000 (0.037)\tLoss 0.1679 (0.1762)\tPrec@1 94.141 (93.899)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [193][30/329], lr: 0.00000\tTime 0.112 (0.113)\tData 0.016 (0.027)\tLoss 0.1592 (0.1767)\tPrec@1 96.094 (93.989)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [193][40/329], lr: 0.00000\tTime 0.094 (0.108)\tData 0.000 (0.022)\tLoss 0.1377 (0.1794)\tPrec@1 95.703 (94.026)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [193][50/329], lr: 0.00000\tTime 0.090 (0.104)\tData 0.001 (0.019)\tLoss 0.1702 (0.1815)\tPrec@1 95.703 (93.995)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [193][60/329], lr: 0.00000\tTime 0.098 (0.101)\tData 0.005 (0.017)\tLoss 0.2537 (0.1815)\tPrec@1 92.969 (94.051)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [193][70/329], lr: 0.00000\tTime 0.092 (0.100)\tData 0.010 (0.015)\tLoss 0.1718 (0.1822)\tPrec@1 94.141 (94.003)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [193][80/329], lr: 0.00000\tTime 0.094 (0.099)\tData 0.000 (0.014)\tLoss 0.1579 (0.1804)\tPrec@1 94.531 (94.030)\tPrec@5 100.000 (99.879)\n",
            "Epoch: [193][90/329], lr: 0.00000\tTime 0.099 (0.097)\tData 0.004 (0.014)\tLoss 0.1882 (0.1806)\tPrec@1 92.969 (93.969)\tPrec@5 100.000 (99.884)\n",
            "Epoch: [193][100/329], lr: 0.00000\tTime 0.084 (0.096)\tData 0.000 (0.013)\tLoss 0.2128 (0.1831)\tPrec@1 92.969 (93.905)\tPrec@5 100.000 (99.876)\n",
            "Epoch: [193][110/329], lr: 0.00000\tTime 0.102 (0.096)\tData 0.006 (0.013)\tLoss 0.2045 (0.1851)\tPrec@1 92.969 (93.817)\tPrec@5 99.609 (99.866)\n",
            "Epoch: [193][120/329], lr: 0.00000\tTime 0.084 (0.095)\tData 0.000 (0.012)\tLoss 0.1737 (0.1857)\tPrec@1 94.531 (93.805)\tPrec@5 99.609 (99.871)\n",
            "Epoch: [193][130/329], lr: 0.00000\tTime 0.078 (0.095)\tData 0.007 (0.012)\tLoss 0.1437 (0.1841)\tPrec@1 95.703 (93.863)\tPrec@5 99.609 (99.863)\n",
            "Epoch: [193][140/329], lr: 0.00000\tTime 0.080 (0.094)\tData 0.007 (0.012)\tLoss 0.1378 (0.1831)\tPrec@1 97.266 (93.877)\tPrec@5 99.609 (99.856)\n",
            "Epoch: [193][150/329], lr: 0.00000\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 0.1820 (0.1836)\tPrec@1 93.359 (93.859)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [193][160/329], lr: 0.00000\tTime 0.111 (0.093)\tData 0.009 (0.011)\tLoss 0.2048 (0.1841)\tPrec@1 93.750 (93.847)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [193][170/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.006 (0.011)\tLoss 0.1543 (0.1840)\tPrec@1 94.531 (93.857)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [193][180/329], lr: 0.00000\tTime 0.091 (0.093)\tData 0.006 (0.010)\tLoss 0.2204 (0.1840)\tPrec@1 91.797 (93.851)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [193][190/329], lr: 0.00000\tTime 0.096 (0.093)\tData 0.005 (0.010)\tLoss 0.2517 (0.1833)\tPrec@1 92.188 (93.865)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [193][200/329], lr: 0.00000\tTime 0.082 (0.092)\tData 0.000 (0.010)\tLoss 0.1377 (0.1830)\tPrec@1 94.922 (93.882)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [193][210/329], lr: 0.00000\tTime 0.087 (0.092)\tData 0.009 (0.010)\tLoss 0.1440 (0.1835)\tPrec@1 94.141 (93.828)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [193][220/329], lr: 0.00000\tTime 0.091 (0.092)\tData 0.002 (0.010)\tLoss 0.1787 (0.1838)\tPrec@1 93.359 (93.808)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [193][230/329], lr: 0.00000\tTime 0.074 (0.092)\tData 0.004 (0.010)\tLoss 0.1578 (0.1840)\tPrec@1 94.922 (93.797)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [193][240/329], lr: 0.00000\tTime 0.094 (0.091)\tData 0.000 (0.010)\tLoss 0.2088 (0.1840)\tPrec@1 94.141 (93.805)\tPrec@5 99.219 (99.846)\n",
            "Epoch: [193][250/329], lr: 0.00000\tTime 0.089 (0.091)\tData 0.000 (0.010)\tLoss 0.2400 (0.1840)\tPrec@1 92.188 (93.806)\tPrec@5 99.219 (99.843)\n",
            "Epoch: [193][260/329], lr: 0.00000\tTime 0.094 (0.091)\tData 0.000 (0.009)\tLoss 0.1681 (0.1835)\tPrec@1 95.312 (93.837)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [193][270/329], lr: 0.00000\tTime 0.081 (0.091)\tData 0.005 (0.009)\tLoss 0.2040 (0.1840)\tPrec@1 92.969 (93.824)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [193][280/329], lr: 0.00000\tTime 0.102 (0.091)\tData 0.006 (0.009)\tLoss 0.1994 (0.1844)\tPrec@1 93.359 (93.806)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [193][290/329], lr: 0.00000\tTime 0.077 (0.091)\tData 0.004 (0.009)\tLoss 0.2215 (0.1844)\tPrec@1 93.750 (93.820)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [193][300/329], lr: 0.00000\tTime 0.098 (0.091)\tData 0.000 (0.009)\tLoss 0.1424 (0.1845)\tPrec@1 94.922 (93.803)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [193][310/329], lr: 0.00000\tTime 0.084 (0.091)\tData 0.000 (0.009)\tLoss 0.1586 (0.1843)\tPrec@1 94.922 (93.810)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [193][320/329], lr: 0.00000\tTime 0.102 (0.090)\tData 0.061 (0.009)\tLoss 0.2819 (0.1847)\tPrec@1 91.016 (93.789)\tPrec@5 99.609 (99.841)\n",
            "Test: [0/100]\tTime 0.414 (0.414)\tLoss 0.4509 (0.4509)\tPrec@1 83.000 (83.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.044 (0.063)\tLoss 0.5395 (0.6568)\tPrec@1 82.000 (81.182)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.022 (0.043)\tLoss 0.6310 (0.6582)\tPrec@1 80.000 (81.048)\tPrec@5 100.000 (98.667)\n",
            "Test: [30/100]\tTime 0.016 (0.037)\tLoss 0.7763 (0.6716)\tPrec@1 77.000 (80.903)\tPrec@5 99.000 (98.645)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 0.7109 (0.6740)\tPrec@1 75.000 (80.488)\tPrec@5 99.000 (98.659)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 0.6334 (0.6674)\tPrec@1 87.000 (80.706)\tPrec@5 98.000 (98.745)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 0.4950 (0.6698)\tPrec@1 89.000 (80.377)\tPrec@5 100.000 (98.820)\n",
            "Test: [70/100]\tTime 0.017 (0.029)\tLoss 0.7348 (0.6646)\tPrec@1 82.000 (80.394)\tPrec@5 99.000 (98.887)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 0.5681 (0.6588)\tPrec@1 85.000 (80.617)\tPrec@5 99.000 (98.951)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 0.5384 (0.6679)\tPrec@1 88.000 (80.418)\tPrec@5 100.000 (98.923)\n",
            "val Results: Prec@1 80.420 Prec@5 98.890 Loss 0.66637\n",
            "val Class Accuracy: [0.958,0.987,0.874,0.691,0.838,0.782,0.809,0.720,0.706,0.677]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [194][0/329], lr: 0.00000\tTime 0.693 (0.693)\tData 0.598 (0.598)\tLoss 0.2082 (0.2082)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][10/329], lr: 0.00000\tTime 0.074 (0.153)\tData 0.004 (0.063)\tLoss 0.2160 (0.1949)\tPrec@1 92.188 (93.537)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [194][20/329], lr: 0.00000\tTime 0.097 (0.125)\tData 0.000 (0.035)\tLoss 0.1654 (0.1909)\tPrec@1 94.922 (93.824)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [194][30/329], lr: 0.00000\tTime 0.071 (0.114)\tData 0.006 (0.026)\tLoss 0.1685 (0.1908)\tPrec@1 93.750 (93.674)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [194][40/329], lr: 0.00000\tTime 0.108 (0.109)\tData 0.000 (0.021)\tLoss 0.1306 (0.1910)\tPrec@1 96.875 (93.702)\tPrec@5 99.609 (99.886)\n",
            "Epoch: [194][50/329], lr: 0.00000\tTime 0.102 (0.106)\tData 0.003 (0.018)\tLoss 0.1898 (0.1895)\tPrec@1 92.969 (93.681)\tPrec@5 99.609 (99.877)\n",
            "Epoch: [194][60/329], lr: 0.00000\tTime 0.119 (0.104)\tData 0.007 (0.016)\tLoss 0.1545 (0.1885)\tPrec@1 93.750 (93.641)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [194][70/329], lr: 0.00000\tTime 0.070 (0.102)\tData 0.000 (0.015)\tLoss 0.2218 (0.1877)\tPrec@1 92.969 (93.601)\tPrec@5 99.609 (99.873)\n",
            "Epoch: [194][80/329], lr: 0.00000\tTime 0.109 (0.101)\tData 0.009 (0.014)\tLoss 0.1758 (0.1909)\tPrec@1 94.531 (93.509)\tPrec@5 100.000 (99.860)\n",
            "Epoch: [194][90/329], lr: 0.00000\tTime 0.086 (0.099)\tData 0.000 (0.013)\tLoss 0.1626 (0.1907)\tPrec@1 94.141 (93.544)\tPrec@5 100.000 (99.863)\n",
            "Epoch: [194][100/329], lr: 0.00000\tTime 0.094 (0.099)\tData 0.013 (0.012)\tLoss 0.1908 (0.1901)\tPrec@1 94.922 (93.591)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [194][110/329], lr: 0.00000\tTime 0.120 (0.098)\tData 0.005 (0.012)\tLoss 0.1497 (0.1894)\tPrec@1 94.531 (93.585)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [194][120/329], lr: 0.00000\tTime 0.100 (0.097)\tData 0.008 (0.011)\tLoss 0.2157 (0.1873)\tPrec@1 91.406 (93.589)\tPrec@5 99.219 (99.874)\n",
            "Epoch: [194][130/329], lr: 0.00000\tTime 0.077 (0.096)\tData 0.005 (0.011)\tLoss 0.2144 (0.1872)\tPrec@1 92.188 (93.607)\tPrec@5 99.609 (99.866)\n",
            "Epoch: [194][140/329], lr: 0.00000\tTime 0.085 (0.096)\tData 0.009 (0.011)\tLoss 0.1609 (0.1867)\tPrec@1 94.141 (93.645)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [194][150/329], lr: 0.00000\tTime 0.085 (0.096)\tData 0.003 (0.011)\tLoss 0.1396 (0.1854)\tPrec@1 94.531 (93.678)\tPrec@5 100.000 (99.871)\n",
            "Epoch: [194][160/329], lr: 0.00000\tTime 0.079 (0.095)\tData 0.005 (0.011)\tLoss 0.1525 (0.1854)\tPrec@1 95.312 (93.689)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [194][170/329], lr: 0.00000\tTime 0.088 (0.095)\tData 0.006 (0.011)\tLoss 0.2099 (0.1858)\tPrec@1 91.406 (93.684)\tPrec@5 99.609 (99.865)\n",
            "Epoch: [194][180/329], lr: 0.00000\tTime 0.110 (0.095)\tData 0.003 (0.010)\tLoss 0.2266 (0.1857)\tPrec@1 93.359 (93.696)\tPrec@5 100.000 (99.871)\n",
            "Epoch: [194][190/329], lr: 0.00000\tTime 0.082 (0.094)\tData 0.000 (0.010)\tLoss 0.1951 (0.1859)\tPrec@1 94.531 (93.697)\tPrec@5 100.000 (99.873)\n",
            "Epoch: [194][200/329], lr: 0.00000\tTime 0.097 (0.094)\tData 0.006 (0.010)\tLoss 0.1291 (0.1861)\tPrec@1 95.703 (93.682)\tPrec@5 100.000 (99.866)\n",
            "Epoch: [194][210/329], lr: 0.00000\tTime 0.084 (0.094)\tData 0.004 (0.010)\tLoss 0.1409 (0.1858)\tPrec@1 95.312 (93.687)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [194][220/329], lr: 0.00000\tTime 0.096 (0.094)\tData 0.002 (0.010)\tLoss 0.2013 (0.1859)\tPrec@1 92.969 (93.679)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [194][230/329], lr: 0.00000\tTime 0.098 (0.094)\tData 0.006 (0.010)\tLoss 0.1375 (0.1862)\tPrec@1 96.875 (93.674)\tPrec@5 99.219 (99.865)\n",
            "Epoch: [194][240/329], lr: 0.00000\tTime 0.096 (0.093)\tData 0.004 (0.010)\tLoss 0.2228 (0.1866)\tPrec@1 94.141 (93.677)\tPrec@5 99.219 (99.864)\n",
            "Epoch: [194][250/329], lr: 0.00000\tTime 0.120 (0.093)\tData 0.009 (0.009)\tLoss 0.1668 (0.1858)\tPrec@1 92.969 (93.708)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [194][260/329], lr: 0.00000\tTime 0.095 (0.093)\tData 0.007 (0.009)\tLoss 0.2602 (0.1865)\tPrec@1 92.578 (93.710)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [194][270/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.000 (0.009)\tLoss 0.1871 (0.1867)\tPrec@1 94.922 (93.702)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [194][280/329], lr: 0.00000\tTime 0.092 (0.093)\tData 0.000 (0.009)\tLoss 0.1595 (0.1868)\tPrec@1 94.531 (93.699)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [194][290/329], lr: 0.00000\tTime 0.092 (0.093)\tData 0.007 (0.009)\tLoss 0.2000 (0.1863)\tPrec@1 94.922 (93.733)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [194][300/329], lr: 0.00000\tTime 0.090 (0.093)\tData 0.000 (0.009)\tLoss 0.1666 (0.1864)\tPrec@1 94.531 (93.734)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [194][310/329], lr: 0.00000\tTime 0.088 (0.093)\tData 0.000 (0.009)\tLoss 0.1688 (0.1864)\tPrec@1 93.750 (93.734)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [194][320/329], lr: 0.00000\tTime 0.107 (0.093)\tData 0.068 (0.009)\tLoss 0.1595 (0.1867)\tPrec@1 94.531 (93.727)\tPrec@5 100.000 (99.858)\n",
            "Test: [0/100]\tTime 0.576 (0.576)\tLoss 0.4457 (0.4457)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.029 (0.089)\tLoss 0.5224 (0.6485)\tPrec@1 85.000 (81.727)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.034 (0.064)\tLoss 0.6061 (0.6513)\tPrec@1 82.000 (81.333)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.046 (0.056)\tLoss 0.7729 (0.6681)\tPrec@1 75.000 (81.065)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.023 (0.051)\tLoss 0.7258 (0.6725)\tPrec@1 78.000 (80.732)\tPrec@5 99.000 (98.732)\n",
            "Test: [50/100]\tTime 0.030 (0.046)\tLoss 0.6227 (0.6644)\tPrec@1 86.000 (80.941)\tPrec@5 98.000 (98.765)\n",
            "Test: [60/100]\tTime 0.020 (0.042)\tLoss 0.5227 (0.6707)\tPrec@1 86.000 (80.328)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.027 (0.040)\tLoss 0.7183 (0.6634)\tPrec@1 81.000 (80.366)\tPrec@5 99.000 (98.887)\n",
            "Test: [80/100]\tTime 0.021 (0.038)\tLoss 0.6111 (0.6574)\tPrec@1 83.000 (80.543)\tPrec@5 99.000 (98.951)\n",
            "Test: [90/100]\tTime 0.013 (0.037)\tLoss 0.5388 (0.6662)\tPrec@1 87.000 (80.341)\tPrec@5 100.000 (98.912)\n",
            "val Results: Prec@1 80.240 Prec@5 98.900 Loss 0.66428\n",
            "val Class Accuracy: [0.966,0.967,0.858,0.787,0.846,0.686,0.801,0.698,0.705,0.710]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [195][0/329], lr: 0.00000\tTime 0.710 (0.710)\tData 0.606 (0.606)\tLoss 0.1811 (0.1811)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][10/329], lr: 0.00000\tTime 0.083 (0.148)\tData 0.004 (0.062)\tLoss 0.2119 (0.2025)\tPrec@1 93.359 (93.182)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [195][20/329], lr: 0.00000\tTime 0.075 (0.119)\tData 0.000 (0.035)\tLoss 0.2345 (0.1956)\tPrec@1 91.406 (93.452)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [195][30/329], lr: 0.00000\tTime 0.081 (0.111)\tData 0.003 (0.025)\tLoss 0.1923 (0.1926)\tPrec@1 92.578 (93.637)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [195][40/329], lr: 0.00000\tTime 0.128 (0.107)\tData 0.000 (0.020)\tLoss 0.1532 (0.1881)\tPrec@1 95.312 (93.750)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [195][50/329], lr: 0.00000\tTime 0.091 (0.104)\tData 0.008 (0.018)\tLoss 0.2249 (0.1858)\tPrec@1 91.406 (93.865)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [195][60/329], lr: 0.00000\tTime 0.098 (0.101)\tData 0.005 (0.016)\tLoss 0.1591 (0.1867)\tPrec@1 93.750 (93.814)\tPrec@5 100.000 (99.827)\n",
            "Epoch: [195][70/329], lr: 0.00000\tTime 0.102 (0.100)\tData 0.005 (0.014)\tLoss 0.1786 (0.1878)\tPrec@1 93.750 (93.728)\tPrec@5 100.000 (99.829)\n",
            "Epoch: [195][80/329], lr: 0.00000\tTime 0.084 (0.098)\tData 0.013 (0.013)\tLoss 0.1733 (0.1873)\tPrec@1 93.750 (93.736)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [195][90/329], lr: 0.00000\tTime 0.091 (0.097)\tData 0.000 (0.012)\tLoss 0.1176 (0.1865)\tPrec@1 95.312 (93.763)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [195][100/329], lr: 0.00000\tTime 0.087 (0.097)\tData 0.000 (0.012)\tLoss 0.2330 (0.1862)\tPrec@1 93.359 (93.777)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [195][110/329], lr: 0.00000\tTime 0.078 (0.096)\tData 0.000 (0.012)\tLoss 0.1846 (0.1867)\tPrec@1 94.531 (93.771)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [195][120/329], lr: 0.00000\tTime 0.095 (0.096)\tData 0.010 (0.011)\tLoss 0.2242 (0.1865)\tPrec@1 92.188 (93.769)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [195][130/329], lr: 0.00000\tTime 0.085 (0.095)\tData 0.005 (0.011)\tLoss 0.1553 (0.1863)\tPrec@1 95.312 (93.744)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [195][140/329], lr: 0.00000\tTime 0.103 (0.095)\tData 0.000 (0.010)\tLoss 0.2021 (0.1861)\tPrec@1 94.141 (93.756)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [195][150/329], lr: 0.00000\tTime 0.081 (0.094)\tData 0.005 (0.010)\tLoss 0.1324 (0.1862)\tPrec@1 96.094 (93.755)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [195][160/329], lr: 0.00000\tTime 0.081 (0.094)\tData 0.007 (0.010)\tLoss 0.1827 (0.1860)\tPrec@1 93.359 (93.745)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [195][170/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.010 (0.010)\tLoss 0.2517 (0.1865)\tPrec@1 91.406 (93.711)\tPrec@5 100.000 (99.863)\n",
            "Epoch: [195][180/329], lr: 0.00000\tTime 0.098 (0.093)\tData 0.007 (0.010)\tLoss 0.2011 (0.1870)\tPrec@1 93.359 (93.687)\tPrec@5 100.000 (99.864)\n",
            "Epoch: [195][190/329], lr: 0.00000\tTime 0.079 (0.093)\tData 0.004 (0.010)\tLoss 0.1481 (0.1864)\tPrec@1 95.703 (93.717)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [195][200/329], lr: 0.00000\tTime 0.086 (0.093)\tData 0.000 (0.009)\tLoss 0.1769 (0.1861)\tPrec@1 92.969 (93.709)\tPrec@5 100.000 (99.868)\n",
            "Epoch: [195][210/329], lr: 0.00000\tTime 0.076 (0.093)\tData 0.001 (0.009)\tLoss 0.2148 (0.1864)\tPrec@1 92.969 (93.713)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [195][220/329], lr: 0.00000\tTime 0.080 (0.093)\tData 0.011 (0.009)\tLoss 0.1811 (0.1858)\tPrec@1 94.531 (93.716)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [195][230/329], lr: 0.00000\tTime 0.070 (0.092)\tData 0.000 (0.009)\tLoss 0.1843 (0.1858)\tPrec@1 94.531 (93.721)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [195][240/329], lr: 0.00000\tTime 0.082 (0.092)\tData 0.006 (0.009)\tLoss 0.1851 (0.1865)\tPrec@1 92.188 (93.701)\tPrec@5 99.609 (99.844)\n",
            "Epoch: [195][250/329], lr: 0.00000\tTime 0.080 (0.092)\tData 0.000 (0.009)\tLoss 0.1934 (0.1865)\tPrec@1 94.531 (93.724)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [195][260/329], lr: 0.00000\tTime 0.103 (0.092)\tData 0.000 (0.009)\tLoss 0.1738 (0.1859)\tPrec@1 94.922 (93.738)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [195][270/329], lr: 0.00000\tTime 0.064 (0.092)\tData 0.005 (0.009)\tLoss 0.1362 (0.1852)\tPrec@1 95.703 (93.770)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [195][280/329], lr: 0.00000\tTime 0.085 (0.092)\tData 0.000 (0.009)\tLoss 0.2209 (0.1858)\tPrec@1 92.578 (93.735)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [195][290/329], lr: 0.00000\tTime 0.114 (0.092)\tData 0.006 (0.009)\tLoss 0.1704 (0.1855)\tPrec@1 94.531 (93.746)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [195][300/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.007 (0.009)\tLoss 0.1616 (0.1861)\tPrec@1 94.922 (93.716)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [195][310/329], lr: 0.00000\tTime 0.091 (0.092)\tData 0.006 (0.009)\tLoss 0.1676 (0.1859)\tPrec@1 93.750 (93.712)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [195][320/329], lr: 0.00000\tTime 0.127 (0.092)\tData 0.066 (0.009)\tLoss 0.1646 (0.1861)\tPrec@1 94.531 (93.713)\tPrec@5 99.609 (99.858)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 0.4433 (0.4433)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.018 (0.056)\tLoss 0.5045 (0.6410)\tPrec@1 85.000 (82.182)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.022 (0.042)\tLoss 0.6110 (0.6453)\tPrec@1 83.000 (81.857)\tPrec@5 100.000 (98.571)\n",
            "Test: [30/100]\tTime 0.045 (0.037)\tLoss 0.7991 (0.6609)\tPrec@1 75.000 (81.484)\tPrec@5 99.000 (98.581)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 0.7364 (0.6656)\tPrec@1 76.000 (81.220)\tPrec@5 99.000 (98.610)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 0.6387 (0.6572)\tPrec@1 85.000 (81.392)\tPrec@5 98.000 (98.686)\n",
            "Test: [60/100]\tTime 0.014 (0.031)\tLoss 0.5033 (0.6633)\tPrec@1 88.000 (80.803)\tPrec@5 100.000 (98.787)\n",
            "Test: [70/100]\tTime 0.012 (0.030)\tLoss 0.7090 (0.6555)\tPrec@1 80.000 (80.732)\tPrec@5 99.000 (98.859)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 0.6078 (0.6494)\tPrec@1 84.000 (80.889)\tPrec@5 99.000 (98.914)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 0.5183 (0.6579)\tPrec@1 88.000 (80.725)\tPrec@5 100.000 (98.912)\n",
            "val Results: Prec@1 80.600 Prec@5 98.890 Loss 0.65643\n",
            "val Class Accuracy: [0.962,0.963,0.864,0.760,0.834,0.753,0.803,0.682,0.712,0.727]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [196][0/329], lr: 0.00000\tTime 0.537 (0.537)\tData 0.451 (0.451)\tLoss 0.1700 (0.1700)\tPrec@1 94.531 (94.531)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [196][10/329], lr: 0.00000\tTime 0.100 (0.147)\tData 0.000 (0.061)\tLoss 0.2591 (0.1828)\tPrec@1 89.844 (93.253)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [196][20/329], lr: 0.00000\tTime 0.078 (0.123)\tData 0.007 (0.035)\tLoss 0.3098 (0.1984)\tPrec@1 90.625 (92.987)\tPrec@5 99.609 (99.721)\n",
            "Epoch: [196][30/329], lr: 0.00000\tTime 0.115 (0.115)\tData 0.007 (0.026)\tLoss 0.1942 (0.1941)\tPrec@1 93.750 (93.397)\tPrec@5 100.000 (99.786)\n",
            "Epoch: [196][40/329], lr: 0.00000\tTime 0.102 (0.110)\tData 0.007 (0.021)\tLoss 0.3303 (0.1942)\tPrec@1 89.453 (93.407)\tPrec@5 99.609 (99.809)\n",
            "Epoch: [196][50/329], lr: 0.00000\tTime 0.092 (0.106)\tData 0.000 (0.018)\tLoss 0.1822 (0.1923)\tPrec@1 92.969 (93.413)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [196][60/329], lr: 0.00000\tTime 0.068 (0.103)\tData 0.008 (0.016)\tLoss 0.1813 (0.1899)\tPrec@1 94.141 (93.455)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [196][70/329], lr: 0.00000\tTime 0.091 (0.102)\tData 0.006 (0.015)\tLoss 0.1540 (0.1893)\tPrec@1 94.922 (93.513)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [196][80/329], lr: 0.00000\tTime 0.081 (0.100)\tData 0.007 (0.014)\tLoss 0.1672 (0.1874)\tPrec@1 92.969 (93.610)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [196][90/329], lr: 0.00000\tTime 0.086 (0.099)\tData 0.007 (0.014)\tLoss 0.1619 (0.1859)\tPrec@1 95.312 (93.660)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [196][100/329], lr: 0.00000\tTime 0.090 (0.098)\tData 0.010 (0.013)\tLoss 0.1351 (0.1845)\tPrec@1 96.094 (93.719)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [196][110/329], lr: 0.00000\tTime 0.114 (0.097)\tData 0.005 (0.012)\tLoss 0.1845 (0.1833)\tPrec@1 92.578 (93.785)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [196][120/329], lr: 0.00000\tTime 0.060 (0.096)\tData 0.003 (0.012)\tLoss 0.2040 (0.1833)\tPrec@1 92.969 (93.779)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [196][130/329], lr: 0.00000\tTime 0.071 (0.096)\tData 0.009 (0.012)\tLoss 0.1565 (0.1826)\tPrec@1 93.750 (93.777)\tPrec@5 99.609 (99.851)\n",
            "Epoch: [196][140/329], lr: 0.00000\tTime 0.094 (0.096)\tData 0.000 (0.011)\tLoss 0.1743 (0.1835)\tPrec@1 94.141 (93.750)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [196][150/329], lr: 0.00000\tTime 0.096 (0.095)\tData 0.000 (0.011)\tLoss 0.1531 (0.1842)\tPrec@1 94.922 (93.758)\tPrec@5 99.609 (99.855)\n",
            "Epoch: [196][160/329], lr: 0.00000\tTime 0.097 (0.095)\tData 0.009 (0.011)\tLoss 0.2375 (0.1845)\tPrec@1 90.625 (93.711)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [196][170/329], lr: 0.00000\tTime 0.089 (0.094)\tData 0.006 (0.011)\tLoss 0.1681 (0.1850)\tPrec@1 93.750 (93.681)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [196][180/329], lr: 0.00000\tTime 0.090 (0.094)\tData 0.000 (0.011)\tLoss 0.1259 (0.1847)\tPrec@1 95.312 (93.707)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [196][190/329], lr: 0.00000\tTime 0.080 (0.094)\tData 0.005 (0.011)\tLoss 0.1837 (0.1840)\tPrec@1 92.969 (93.723)\tPrec@5 99.609 (99.853)\n",
            "Epoch: [196][200/329], lr: 0.00000\tTime 0.109 (0.094)\tData 0.004 (0.010)\tLoss 0.1585 (0.1838)\tPrec@1 94.141 (93.736)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [196][210/329], lr: 0.00000\tTime 0.092 (0.093)\tData 0.007 (0.010)\tLoss 0.1980 (0.1838)\tPrec@1 91.406 (93.737)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [196][220/329], lr: 0.00000\tTime 0.095 (0.093)\tData 0.007 (0.010)\tLoss 0.1708 (0.1834)\tPrec@1 94.531 (93.745)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [196][230/329], lr: 0.00000\tTime 0.084 (0.093)\tData 0.006 (0.010)\tLoss 0.1789 (0.1828)\tPrec@1 93.750 (93.757)\tPrec@5 99.609 (99.851)\n",
            "Epoch: [196][240/329], lr: 0.00000\tTime 0.075 (0.093)\tData 0.014 (0.010)\tLoss 0.2163 (0.1833)\tPrec@1 92.969 (93.740)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [196][250/329], lr: 0.00000\tTime 0.080 (0.092)\tData 0.000 (0.010)\tLoss 0.2609 (0.1835)\tPrec@1 91.406 (93.744)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [196][260/329], lr: 0.00000\tTime 0.084 (0.092)\tData 0.000 (0.010)\tLoss 0.1939 (0.1834)\tPrec@1 93.750 (93.749)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [196][270/329], lr: 0.00000\tTime 0.106 (0.092)\tData 0.000 (0.010)\tLoss 0.1836 (0.1842)\tPrec@1 92.969 (93.717)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [196][280/329], lr: 0.00000\tTime 0.076 (0.092)\tData 0.000 (0.010)\tLoss 0.1898 (0.1850)\tPrec@1 94.141 (93.697)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [196][290/329], lr: 0.00000\tTime 0.086 (0.092)\tData 0.000 (0.009)\tLoss 0.2328 (0.1855)\tPrec@1 90.625 (93.692)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [196][300/329], lr: 0.00000\tTime 0.063 (0.092)\tData 0.001 (0.009)\tLoss 0.1898 (0.1858)\tPrec@1 93.750 (93.699)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [196][310/329], lr: 0.00000\tTime 0.090 (0.092)\tData 0.007 (0.009)\tLoss 0.2364 (0.1860)\tPrec@1 92.188 (93.695)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [196][320/329], lr: 0.00000\tTime 0.101 (0.092)\tData 0.061 (0.009)\tLoss 0.2079 (0.1854)\tPrec@1 92.969 (93.720)\tPrec@5 100.000 (99.852)\n",
            "Test: [0/100]\tTime 0.366 (0.366)\tLoss 0.4202 (0.4202)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.017 (0.058)\tLoss 0.5032 (0.6210)\tPrec@1 85.000 (82.636)\tPrec@5 98.000 (99.000)\n",
            "Test: [20/100]\tTime 0.020 (0.042)\tLoss 0.6082 (0.6250)\tPrec@1 82.000 (82.381)\tPrec@5 100.000 (98.762)\n",
            "Test: [30/100]\tTime 0.037 (0.037)\tLoss 0.7729 (0.6399)\tPrec@1 77.000 (81.903)\tPrec@5 99.000 (98.710)\n",
            "Test: [40/100]\tTime 0.017 (0.035)\tLoss 0.6949 (0.6445)\tPrec@1 77.000 (81.610)\tPrec@5 99.000 (98.732)\n",
            "Test: [50/100]\tTime 0.043 (0.034)\tLoss 0.6135 (0.6372)\tPrec@1 86.000 (81.686)\tPrec@5 98.000 (98.765)\n",
            "Test: [60/100]\tTime 0.027 (0.033)\tLoss 0.4889 (0.6413)\tPrec@1 88.000 (81.197)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.027 (0.031)\tLoss 0.6858 (0.6345)\tPrec@1 80.000 (81.183)\tPrec@5 99.000 (98.901)\n",
            "Test: [80/100]\tTime 0.032 (0.030)\tLoss 0.5699 (0.6287)\tPrec@1 85.000 (81.346)\tPrec@5 99.000 (98.951)\n",
            "Test: [90/100]\tTime 0.047 (0.029)\tLoss 0.5021 (0.6365)\tPrec@1 88.000 (81.121)\tPrec@5 100.000 (98.923)\n",
            "val Results: Prec@1 81.020 Prec@5 98.910 Loss 0.63442\n",
            "val Class Accuracy: [0.959,0.975,0.867,0.753,0.831,0.760,0.817,0.704,0.722,0.714]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [197][0/329], lr: 0.00000\tTime 0.639 (0.639)\tData 0.550 (0.550)\tLoss 0.2229 (0.2229)\tPrec@1 91.016 (91.016)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [197][10/329], lr: 0.00000\tTime 0.092 (0.151)\tData 0.005 (0.058)\tLoss 0.1806 (0.1800)\tPrec@1 93.750 (94.034)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [197][20/329], lr: 0.00000\tTime 0.101 (0.124)\tData 0.006 (0.033)\tLoss 0.1575 (0.1881)\tPrec@1 94.922 (93.862)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [197][30/329], lr: 0.00000\tTime 0.086 (0.113)\tData 0.000 (0.024)\tLoss 0.2457 (0.1879)\tPrec@1 90.234 (93.662)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [197][40/329], lr: 0.00000\tTime 0.072 (0.107)\tData 0.000 (0.019)\tLoss 0.1638 (0.1845)\tPrec@1 94.922 (93.817)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [197][50/329], lr: 0.00000\tTime 0.082 (0.103)\tData 0.000 (0.017)\tLoss 0.1980 (0.1889)\tPrec@1 94.141 (93.727)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [197][60/329], lr: 0.00000\tTime 0.088 (0.101)\tData 0.005 (0.015)\tLoss 0.1622 (0.1897)\tPrec@1 94.141 (93.680)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [197][70/329], lr: 0.00000\tTime 0.097 (0.099)\tData 0.000 (0.014)\tLoss 0.1773 (0.1908)\tPrec@1 93.750 (93.695)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [197][80/329], lr: 0.00000\tTime 0.094 (0.098)\tData 0.006 (0.013)\tLoss 0.1870 (0.1878)\tPrec@1 95.312 (93.803)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [197][90/329], lr: 0.00000\tTime 0.089 (0.097)\tData 0.005 (0.013)\tLoss 0.2024 (0.1896)\tPrec@1 91.797 (93.694)\tPrec@5 100.000 (99.837)\n",
            "Epoch: [197][100/329], lr: 0.00000\tTime 0.086 (0.096)\tData 0.000 (0.012)\tLoss 0.1699 (0.1894)\tPrec@1 91.797 (93.642)\tPrec@5 100.000 (99.841)\n",
            "Epoch: [197][110/329], lr: 0.00000\tTime 0.099 (0.095)\tData 0.000 (0.011)\tLoss 0.2001 (0.1899)\tPrec@1 93.359 (93.609)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [197][120/329], lr: 0.00000\tTime 0.117 (0.095)\tData 0.007 (0.011)\tLoss 0.1758 (0.1910)\tPrec@1 93.750 (93.582)\tPrec@5 100.000 (99.842)\n",
            "Epoch: [197][130/329], lr: 0.00000\tTime 0.087 (0.094)\tData 0.009 (0.011)\tLoss 0.1664 (0.1908)\tPrec@1 93.750 (93.598)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [197][140/329], lr: 0.00000\tTime 0.102 (0.094)\tData 0.005 (0.010)\tLoss 0.2531 (0.1910)\tPrec@1 90.625 (93.614)\tPrec@5 99.219 (99.842)\n",
            "Epoch: [197][150/329], lr: 0.00000\tTime 0.119 (0.094)\tData 0.000 (0.010)\tLoss 0.2404 (0.1909)\tPrec@1 92.969 (93.639)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [197][160/329], lr: 0.00000\tTime 0.094 (0.093)\tData 0.006 (0.010)\tLoss 0.1137 (0.1899)\tPrec@1 96.484 (93.655)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [197][170/329], lr: 0.00000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 0.2124 (0.1913)\tPrec@1 91.797 (93.588)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [197][180/329], lr: 0.00000\tTime 0.074 (0.093)\tData 0.000 (0.010)\tLoss 0.1956 (0.1910)\tPrec@1 94.531 (93.597)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [197][190/329], lr: 0.00000\tTime 0.083 (0.092)\tData 0.004 (0.010)\tLoss 0.1534 (0.1905)\tPrec@1 94.141 (93.609)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [197][200/329], lr: 0.00000\tTime 0.071 (0.092)\tData 0.004 (0.009)\tLoss 0.2146 (0.1898)\tPrec@1 92.969 (93.641)\tPrec@5 99.609 (99.852)\n",
            "Epoch: [197][210/329], lr: 0.00000\tTime 0.080 (0.092)\tData 0.004 (0.009)\tLoss 0.1799 (0.1899)\tPrec@1 93.359 (93.650)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [197][220/329], lr: 0.00000\tTime 0.077 (0.092)\tData 0.006 (0.009)\tLoss 0.1949 (0.1896)\tPrec@1 95.312 (93.690)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [197][230/329], lr: 0.00000\tTime 0.064 (0.092)\tData 0.000 (0.009)\tLoss 0.2206 (0.1901)\tPrec@1 91.797 (93.640)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [197][240/329], lr: 0.00000\tTime 0.084 (0.092)\tData 0.007 (0.009)\tLoss 0.1556 (0.1892)\tPrec@1 95.703 (93.666)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [197][250/329], lr: 0.00000\tTime 0.088 (0.092)\tData 0.004 (0.009)\tLoss 0.2112 (0.1891)\tPrec@1 92.578 (93.686)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [197][260/329], lr: 0.00000\tTime 0.094 (0.092)\tData 0.004 (0.009)\tLoss 0.1755 (0.1877)\tPrec@1 94.531 (93.735)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [197][270/329], lr: 0.00000\tTime 0.096 (0.092)\tData 0.006 (0.009)\tLoss 0.1615 (0.1875)\tPrec@1 93.359 (93.721)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [197][280/329], lr: 0.00000\tTime 0.100 (0.092)\tData 0.003 (0.009)\tLoss 0.2176 (0.1872)\tPrec@1 93.750 (93.736)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [197][290/329], lr: 0.00000\tTime 0.091 (0.092)\tData 0.005 (0.009)\tLoss 0.1707 (0.1866)\tPrec@1 92.578 (93.747)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [197][300/329], lr: 0.00000\tTime 0.091 (0.092)\tData 0.014 (0.009)\tLoss 0.1758 (0.1865)\tPrec@1 94.531 (93.766)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [197][310/329], lr: 0.00000\tTime 0.110 (0.092)\tData 0.001 (0.009)\tLoss 0.1795 (0.1861)\tPrec@1 93.750 (93.780)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [197][320/329], lr: 0.00000\tTime 0.104 (0.092)\tData 0.066 (0.009)\tLoss 0.2178 (0.1865)\tPrec@1 91.797 (93.773)\tPrec@5 100.000 (99.847)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 0.4030 (0.4030)\tPrec@1 87.000 (87.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.013 (0.060)\tLoss 0.4931 (0.6112)\tPrec@1 84.000 (83.000)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.023 (0.042)\tLoss 0.6339 (0.6158)\tPrec@1 82.000 (82.762)\tPrec@5 100.000 (98.810)\n",
            "Test: [30/100]\tTime 0.039 (0.037)\tLoss 0.7432 (0.6339)\tPrec@1 77.000 (82.484)\tPrec@5 98.000 (98.710)\n",
            "Test: [40/100]\tTime 0.049 (0.034)\tLoss 0.6663 (0.6388)\tPrec@1 81.000 (82.171)\tPrec@5 98.000 (98.756)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 0.5663 (0.6321)\tPrec@1 87.000 (82.235)\tPrec@5 98.000 (98.784)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 0.5254 (0.6355)\tPrec@1 85.000 (81.689)\tPrec@5 100.000 (98.902)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 0.6654 (0.6297)\tPrec@1 82.000 (81.662)\tPrec@5 100.000 (98.972)\n",
            "Test: [80/100]\tTime 0.039 (0.030)\tLoss 0.5385 (0.6243)\tPrec@1 88.000 (81.852)\tPrec@5 99.000 (99.025)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 0.5249 (0.6328)\tPrec@1 87.000 (81.637)\tPrec@5 100.000 (98.978)\n",
            "val Results: Prec@1 81.570 Prec@5 98.950 Loss 0.63081\n",
            "val Class Accuracy: [0.958,0.978,0.851,0.758,0.860,0.712,0.858,0.742,0.713,0.727]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [198][0/329], lr: 0.00000\tTime 0.685 (0.685)\tData 0.604 (0.604)\tLoss 0.1518 (0.1518)\tPrec@1 92.969 (92.969)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [198][10/329], lr: 0.00000\tTime 0.094 (0.150)\tData 0.004 (0.062)\tLoss 0.1464 (0.1796)\tPrec@1 95.703 (94.034)\tPrec@5 99.609 (99.893)\n",
            "Epoch: [198][20/329], lr: 0.00000\tTime 0.109 (0.125)\tData 0.006 (0.035)\tLoss 0.1910 (0.1807)\tPrec@1 92.969 (93.917)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [198][30/329], lr: 0.00000\tTime 0.102 (0.113)\tData 0.009 (0.027)\tLoss 0.2036 (0.1826)\tPrec@1 92.578 (93.750)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [198][40/329], lr: 0.00000\tTime 0.077 (0.107)\tData 0.004 (0.023)\tLoss 0.1654 (0.1852)\tPrec@1 94.531 (93.750)\tPrec@5 100.000 (99.819)\n",
            "Epoch: [198][50/329], lr: 0.00000\tTime 0.056 (0.103)\tData 0.000 (0.019)\tLoss 0.1593 (0.1814)\tPrec@1 95.312 (93.941)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [198][60/329], lr: 0.00000\tTime 0.086 (0.101)\tData 0.006 (0.017)\tLoss 0.2285 (0.1810)\tPrec@1 91.797 (93.961)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [198][70/329], lr: 0.00000\tTime 0.109 (0.099)\tData 0.008 (0.016)\tLoss 0.2252 (0.1816)\tPrec@1 94.141 (93.970)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [198][80/329], lr: 0.00000\tTime 0.080 (0.097)\tData 0.005 (0.015)\tLoss 0.2488 (0.1841)\tPrec@1 91.797 (93.909)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [198][90/329], lr: 0.00000\tTime 0.092 (0.097)\tData 0.006 (0.014)\tLoss 0.2006 (0.1829)\tPrec@1 94.922 (93.995)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [198][100/329], lr: 0.00000\tTime 0.077 (0.096)\tData 0.005 (0.013)\tLoss 0.2292 (0.1857)\tPrec@1 91.406 (93.851)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [198][110/329], lr: 0.00000\tTime 0.098 (0.096)\tData 0.005 (0.013)\tLoss 0.1748 (0.1860)\tPrec@1 93.750 (93.849)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [198][120/329], lr: 0.00000\tTime 0.093 (0.095)\tData 0.000 (0.012)\tLoss 0.1940 (0.1870)\tPrec@1 94.141 (93.815)\tPrec@5 99.609 (99.829)\n",
            "Epoch: [198][130/329], lr: 0.00000\tTime 0.078 (0.094)\tData 0.000 (0.012)\tLoss 0.1637 (0.1864)\tPrec@1 94.531 (93.819)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [198][140/329], lr: 0.00000\tTime 0.078 (0.094)\tData 0.002 (0.011)\tLoss 0.1872 (0.1861)\tPrec@1 93.750 (93.808)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [198][150/329], lr: 0.00000\tTime 0.092 (0.094)\tData 0.000 (0.011)\tLoss 0.1632 (0.1848)\tPrec@1 94.531 (93.841)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [198][160/329], lr: 0.00000\tTime 0.109 (0.093)\tData 0.002 (0.011)\tLoss 0.1390 (0.1843)\tPrec@1 95.312 (93.849)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [198][170/329], lr: 0.00000\tTime 0.099 (0.093)\tData 0.000 (0.011)\tLoss 0.1402 (0.1841)\tPrec@1 94.922 (93.837)\tPrec@5 100.000 (99.852)\n",
            "Epoch: [198][180/329], lr: 0.00000\tTime 0.093 (0.093)\tData 0.004 (0.010)\tLoss 0.1571 (0.1833)\tPrec@1 94.141 (93.860)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [198][190/329], lr: 0.00000\tTime 0.095 (0.093)\tData 0.006 (0.010)\tLoss 0.2051 (0.1842)\tPrec@1 93.750 (93.791)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [198][200/329], lr: 0.00000\tTime 0.080 (0.092)\tData 0.002 (0.010)\tLoss 0.2208 (0.1839)\tPrec@1 92.188 (93.804)\tPrec@5 100.000 (99.856)\n",
            "Epoch: [198][210/329], lr: 0.00000\tTime 0.085 (0.092)\tData 0.005 (0.010)\tLoss 0.2343 (0.1849)\tPrec@1 92.188 (93.774)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [198][220/329], lr: 0.00000\tTime 0.099 (0.092)\tData 0.010 (0.010)\tLoss 0.2311 (0.1852)\tPrec@1 91.406 (93.754)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [198][230/329], lr: 0.00000\tTime 0.076 (0.092)\tData 0.006 (0.010)\tLoss 0.1413 (0.1846)\tPrec@1 94.141 (93.762)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [198][240/329], lr: 0.00000\tTime 0.085 (0.092)\tData 0.000 (0.010)\tLoss 0.1798 (0.1848)\tPrec@1 92.188 (93.748)\tPrec@5 99.219 (99.849)\n",
            "Epoch: [198][250/329], lr: 0.00000\tTime 0.079 (0.092)\tData 0.000 (0.010)\tLoss 0.1229 (0.1845)\tPrec@1 96.875 (93.764)\tPrec@5 99.219 (99.847)\n",
            "Epoch: [198][260/329], lr: 0.00000\tTime 0.080 (0.092)\tData 0.000 (0.010)\tLoss 0.2348 (0.1844)\tPrec@1 91.016 (93.772)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [198][270/329], lr: 0.00000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 0.1862 (0.1847)\tPrec@1 93.359 (93.773)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [198][280/329], lr: 0.00000\tTime 0.076 (0.091)\tData 0.005 (0.009)\tLoss 0.1989 (0.1845)\tPrec@1 91.797 (93.783)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [198][290/329], lr: 0.00000\tTime 0.081 (0.091)\tData 0.000 (0.009)\tLoss 0.1790 (0.1846)\tPrec@1 92.969 (93.784)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [198][300/329], lr: 0.00000\tTime 0.086 (0.091)\tData 0.003 (0.009)\tLoss 0.2563 (0.1853)\tPrec@1 92.578 (93.760)\tPrec@5 100.000 (99.855)\n",
            "Epoch: [198][310/329], lr: 0.00000\tTime 0.112 (0.091)\tData 0.000 (0.009)\tLoss 0.2361 (0.1856)\tPrec@1 91.797 (93.744)\tPrec@5 100.000 (99.853)\n",
            "Epoch: [198][320/329], lr: 0.00000\tTime 0.110 (0.091)\tData 0.072 (0.009)\tLoss 0.2013 (0.1855)\tPrec@1 93.750 (93.745)\tPrec@5 98.828 (99.850)\n",
            "Test: [0/100]\tTime 0.379 (0.379)\tLoss 0.4512 (0.4512)\tPrec@1 85.000 (85.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.039 (0.058)\tLoss 0.5076 (0.6353)\tPrec@1 84.000 (82.000)\tPrec@5 98.000 (99.273)\n",
            "Test: [20/100]\tTime 0.025 (0.040)\tLoss 0.5877 (0.6371)\tPrec@1 83.000 (81.810)\tPrec@5 100.000 (98.810)\n",
            "Test: [30/100]\tTime 0.022 (0.036)\tLoss 0.7637 (0.6505)\tPrec@1 77.000 (81.452)\tPrec@5 99.000 (98.742)\n",
            "Test: [40/100]\tTime 0.030 (0.034)\tLoss 0.6782 (0.6543)\tPrec@1 77.000 (81.244)\tPrec@5 99.000 (98.756)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 0.6423 (0.6466)\tPrec@1 86.000 (81.471)\tPrec@5 98.000 (98.784)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 0.4817 (0.6500)\tPrec@1 88.000 (80.918)\tPrec@5 100.000 (98.869)\n",
            "Test: [70/100]\tTime 0.015 (0.029)\tLoss 0.7262 (0.6430)\tPrec@1 81.000 (81.042)\tPrec@5 99.000 (98.915)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 0.5656 (0.6377)\tPrec@1 87.000 (81.210)\tPrec@5 99.000 (98.938)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 0.4988 (0.6455)\tPrec@1 88.000 (81.022)\tPrec@5 100.000 (98.912)\n",
            "val Results: Prec@1 81.000 Prec@5 98.890 Loss 0.64358\n",
            "val Class Accuracy: [0.961,0.981,0.846,0.746,0.823,0.782,0.803,0.699,0.748,0.711]\n",
            "Best Prec@1: 81.630\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [199][0/329], lr: 0.00000\tTime 0.670 (0.670)\tData 0.584 (0.584)\tLoss 0.1913 (0.1913)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][10/329], lr: 0.00000\tTime 0.103 (0.146)\tData 0.000 (0.057)\tLoss 0.1822 (0.2066)\tPrec@1 93.750 (92.862)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [199][20/329], lr: 0.00000\tTime 0.082 (0.122)\tData 0.005 (0.033)\tLoss 0.1562 (0.2045)\tPrec@1 94.922 (93.211)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [199][30/329], lr: 0.00000\tTime 0.092 (0.112)\tData 0.010 (0.025)\tLoss 0.2071 (0.1910)\tPrec@1 93.359 (93.662)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [199][40/329], lr: 0.00000\tTime 0.115 (0.109)\tData 0.000 (0.020)\tLoss 0.1247 (0.1909)\tPrec@1 95.312 (93.798)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [199][50/329], lr: 0.00000\tTime 0.093 (0.110)\tData 0.000 (0.017)\tLoss 0.2379 (0.1926)\tPrec@1 91.406 (93.643)\tPrec@5 99.609 (99.816)\n",
            "Epoch: [199][60/329], lr: 0.00000\tTime 0.115 (0.112)\tData 0.011 (0.016)\tLoss 0.2632 (0.1929)\tPrec@1 89.844 (93.609)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [199][70/329], lr: 0.00000\tTime 0.095 (0.111)\tData 0.001 (0.015)\tLoss 0.1852 (0.1909)\tPrec@1 92.578 (93.579)\tPrec@5 99.609 (99.829)\n",
            "Epoch: [199][80/329], lr: 0.00000\tTime 0.100 (0.109)\tData 0.004 (0.014)\tLoss 0.2193 (0.1901)\tPrec@1 92.578 (93.615)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [199][90/329], lr: 0.00000\tTime 0.101 (0.107)\tData 0.004 (0.013)\tLoss 0.2056 (0.1885)\tPrec@1 92.578 (93.656)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [199][100/329], lr: 0.00000\tTime 0.102 (0.106)\tData 0.004 (0.012)\tLoss 0.1570 (0.1899)\tPrec@1 93.359 (93.588)\tPrec@5 99.609 (99.841)\n",
            "Epoch: [199][110/329], lr: 0.00000\tTime 0.082 (0.104)\tData 0.001 (0.011)\tLoss 0.1191 (0.1892)\tPrec@1 96.094 (93.627)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [199][120/329], lr: 0.00000\tTime 0.096 (0.103)\tData 0.007 (0.011)\tLoss 0.1906 (0.1879)\tPrec@1 94.141 (93.673)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [199][130/329], lr: 0.00000\tTime 0.099 (0.102)\tData 0.007 (0.011)\tLoss 0.1786 (0.1877)\tPrec@1 94.922 (93.711)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [199][140/329], lr: 0.00000\tTime 0.074 (0.101)\tData 0.004 (0.010)\tLoss 0.2560 (0.1875)\tPrec@1 94.531 (93.747)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [199][150/329], lr: 0.00000\tTime 0.112 (0.101)\tData 0.006 (0.010)\tLoss 0.1683 (0.1863)\tPrec@1 94.922 (93.810)\tPrec@5 99.609 (99.845)\n",
            "Epoch: [199][160/329], lr: 0.00000\tTime 0.095 (0.100)\tData 0.000 (0.010)\tLoss 0.1271 (0.1864)\tPrec@1 96.094 (93.777)\tPrec@5 99.609 (99.837)\n",
            "Epoch: [199][170/329], lr: 0.00000\tTime 0.082 (0.099)\tData 0.004 (0.010)\tLoss 0.1918 (0.1857)\tPrec@1 93.359 (93.773)\tPrec@5 99.609 (99.842)\n",
            "Epoch: [199][180/329], lr: 0.00000\tTime 0.078 (0.099)\tData 0.000 (0.010)\tLoss 0.1952 (0.1860)\tPrec@1 94.531 (93.767)\tPrec@5 100.000 (99.840)\n",
            "Epoch: [199][190/329], lr: 0.00000\tTime 0.095 (0.098)\tData 0.001 (0.009)\tLoss 0.1692 (0.1861)\tPrec@1 93.359 (93.752)\tPrec@5 100.000 (99.845)\n",
            "Epoch: [199][200/329], lr: 0.00000\tTime 0.076 (0.098)\tData 0.000 (0.009)\tLoss 0.1961 (0.1847)\tPrec@1 94.141 (93.802)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [199][210/329], lr: 0.00000\tTime 0.096 (0.097)\tData 0.007 (0.009)\tLoss 0.1996 (0.1852)\tPrec@1 94.531 (93.796)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [199][220/329], lr: 0.00000\tTime 0.078 (0.097)\tData 0.000 (0.009)\tLoss 0.1576 (0.1852)\tPrec@1 94.922 (93.789)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [199][230/329], lr: 0.00000\tTime 0.096 (0.097)\tData 0.010 (0.009)\tLoss 0.2101 (0.1857)\tPrec@1 93.750 (93.769)\tPrec@5 100.000 (99.844)\n",
            "Epoch: [199][240/329], lr: 0.00000\tTime 0.099 (0.096)\tData 0.006 (0.009)\tLoss 0.2368 (0.1865)\tPrec@1 92.188 (93.745)\tPrec@5 99.609 (99.846)\n",
            "Epoch: [199][250/329], lr: 0.00000\tTime 0.080 (0.096)\tData 0.000 (0.009)\tLoss 0.1771 (0.1866)\tPrec@1 92.969 (93.750)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [199][260/329], lr: 0.00000\tTime 0.081 (0.096)\tData 0.005 (0.009)\tLoss 0.1567 (0.1864)\tPrec@1 94.531 (93.754)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [199][270/329], lr: 0.00000\tTime 0.087 (0.096)\tData 0.004 (0.009)\tLoss 0.1875 (0.1870)\tPrec@1 93.359 (93.730)\tPrec@5 100.000 (99.850)\n",
            "Epoch: [199][280/329], lr: 0.00000\tTime 0.094 (0.096)\tData 0.007 (0.009)\tLoss 0.1640 (0.1867)\tPrec@1 94.922 (93.744)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [199][290/329], lr: 0.00000\tTime 0.097 (0.095)\tData 0.000 (0.009)\tLoss 0.2130 (0.1870)\tPrec@1 93.359 (93.723)\tPrec@5 99.609 (99.850)\n",
            "Epoch: [199][300/329], lr: 0.00000\tTime 0.099 (0.095)\tData 0.005 (0.009)\tLoss 0.2005 (0.1871)\tPrec@1 94.531 (93.720)\tPrec@5 99.219 (99.852)\n",
            "Epoch: [199][310/329], lr: 0.00000\tTime 0.089 (0.095)\tData 0.007 (0.009)\tLoss 0.1679 (0.1872)\tPrec@1 96.094 (93.726)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [199][320/329], lr: 0.00000\tTime 0.113 (0.095)\tData 0.071 (0.009)\tLoss 0.2266 (0.1873)\tPrec@1 92.188 (93.717)\tPrec@5 99.609 (99.845)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 0.4320 (0.4320)\tPrec@1 86.000 (86.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.015 (0.060)\tLoss 0.4981 (0.6271)\tPrec@1 84.000 (82.364)\tPrec@5 98.000 (99.091)\n",
            "Test: [20/100]\tTime 0.030 (0.043)\tLoss 0.6324 (0.6290)\tPrec@1 82.000 (82.429)\tPrec@5 100.000 (98.810)\n",
            "Test: [30/100]\tTime 0.019 (0.037)\tLoss 0.7962 (0.6468)\tPrec@1 77.000 (81.677)\tPrec@5 99.000 (98.742)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 0.6934 (0.6508)\tPrec@1 76.000 (81.390)\tPrec@5 98.000 (98.732)\n",
            "Test: [50/100]\tTime 0.036 (0.031)\tLoss 0.6077 (0.6441)\tPrec@1 85.000 (81.569)\tPrec@5 98.000 (98.765)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 0.5064 (0.6477)\tPrec@1 88.000 (81.164)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 0.6929 (0.6411)\tPrec@1 81.000 (81.268)\tPrec@5 99.000 (98.887)\n",
            "Test: [80/100]\tTime 0.030 (0.030)\tLoss 0.5664 (0.6352)\tPrec@1 86.000 (81.383)\tPrec@5 99.000 (98.938)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 0.5239 (0.6440)\tPrec@1 87.000 (81.143)\tPrec@5 100.000 (98.879)\n",
            "val Results: Prec@1 81.140 Prec@5 98.860 Loss 0.64160\n",
            "val Class Accuracy: [0.950,0.982,0.853,0.729,0.852,0.786,0.839,0.684,0.696,0.743]\n",
            "Best Prec@1: 81.630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test a pretrained checkpoint (on CIFAR10)"
      ],
      "metadata": {
        "id": "25QfLTPNnJC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset cifar10 --resume '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_CE_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' -e"
      ],
      "metadata": {
        "id": "FuOun75gHWJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef71953-c340-4ea4-8b24-7f260e37ef8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating folder: ./checkpoint/cifar10_resnet32_CE_None_exp_0.01_0.01_semi\n",
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Unlabeled est total:\t62030\n",
            "After processing:\t62025,\t[24999, 14984, 8983, 5384, 3228, 1934, 1156, 693, 415, 249]\n",
            "Labeled data extracted:\t12406\n",
            "5000\n",
            "2997\n",
            "1796\n",
            "1077\n",
            "645\n",
            "387\n",
            "232\n",
            "139\n",
            "83\n",
            "50\n",
            "Loading unlabeled data from ./data/ti_80M_selected.pickle\n",
            "tcmalloc: large alloc 1536008192 bytes == 0x66af2000 @  0x7f14d24ec1e7 0x4b2150 0x5ac2ec 0x5e3d6d 0x58ee7f 0x590c9f 0x591039 0x4fb96a 0x4fc108 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x517947 0x5b4a3e 0x4ba80a 0x537e46 0x58ff66 0x51bbc5 0x58f2a7 0x51740e 0x58f2a7 0x51740e 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de\n",
            "tcmalloc: large alloc 1536008192 bytes == 0xc23cc000 @  0x7f14d24ec1e7 0x4b2150 0x5ac2ec 0x4fc11a 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x517947 0x5b4a3e 0x4ba80a 0x537e46 0x58ff66 0x51bbc5 0x58f2a7 0x51740e 0x58f2a7 0x51740e 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f14d20e9c87 0x5b561a\n",
            "Loading pseudo labels from ./data/pseudo_labeled_cifar.pickle\n",
            "Unlabeled data extracted:\t74431\n",
            "29741\n",
            "18034\n",
            "10698\n",
            "6558\n",
            "3279\n",
            "2756\n",
            "1513\n",
            "866\n",
            "604\n",
            "382\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_CE_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/100]\tTime 6.553 (6.553)\tLoss 0.3987 (0.3987)\tPrec@1 88.000 (88.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.618)\tLoss 0.4924 (0.6057)\tPrec@1 83.000 (82.182)\tPrec@5 98.000 (98.909)\n",
            "Test: [20/100]\tTime 0.022 (0.334)\tLoss 0.6248 (0.6065)\tPrec@1 83.000 (82.524)\tPrec@5 100.000 (98.619)\n",
            "Test: [30/100]\tTime 0.026 (0.233)\tLoss 0.7859 (0.6257)\tPrec@1 77.000 (82.161)\tPrec@5 99.000 (98.613)\n",
            "Test: [40/100]\tTime 0.010 (0.182)\tLoss 0.6408 (0.6311)\tPrec@1 77.000 (81.878)\tPrec@5 98.000 (98.659)\n",
            "Test: [50/100]\tTime 0.030 (0.150)\tLoss 0.6033 (0.6242)\tPrec@1 86.000 (82.078)\tPrec@5 99.000 (98.745)\n",
            "Test: [60/100]\tTime 0.028 (0.129)\tLoss 0.4979 (0.6266)\tPrec@1 86.000 (81.639)\tPrec@5 100.000 (98.852)\n",
            "Test: [70/100]\tTime 0.040 (0.115)\tLoss 0.6448 (0.6211)\tPrec@1 82.000 (81.761)\tPrec@5 100.000 (98.887)\n",
            "Test: [80/100]\tTime 0.034 (0.104)\tLoss 0.5455 (0.6159)\tPrec@1 86.000 (81.877)\tPrec@5 99.000 (98.938)\n",
            "Test: [90/100]\tTime 0.027 (0.094)\tLoss 0.5161 (0.6226)\tPrec@1 85.000 (81.659)\tPrec@5 100.000 (98.901)\n",
            "val Results: Prec@1 81.630 Prec@5 98.900 Loss 0.61891\n",
            "val Class Accuracy: [0.932,0.982,0.843,0.771,0.818,0.776,0.862,0.724,0.727,0.728]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function: LDAMLoss**"
      ],
      "metadata": {
        "id": "dd80OKV_fjvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset cifar10 --loss_type LDAM --imb_factor 0.02 --imb_factor_unlabel 0.02 --epochs=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq4ZIIkLfu1Y",
        "outputId": "73192aa8-c3fd-4ed9-e142-e8d08e0ea607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating folder: log/cifar10_resnet32_LDAM_None_exp_0.02_0.02_semi\n",
            "Creating folder: ./checkpoint/cifar10_resnet32_LDAM_None_exp_0.02_0.02_semi\n",
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Unlabeled est total:\t69980\n",
            "After processing:\t69974,\t[24999, 16186, 10477, 6784, 4390, 2843, 1839, 1189, 771, 496]\n",
            "Labeled data extracted:\t13996\n",
            "5000\n",
            "3237\n",
            "2096\n",
            "1357\n",
            "878\n",
            "568\n",
            "368\n",
            "238\n",
            "154\n",
            "100\n",
            "Loading unlabeled data from ./data/ti_80M_selected.pickle\n",
            "tcmalloc: large alloc 1536008192 bytes == 0x67c9a000 @  0x7f106a2191e7 0x4b2590 0x5ad01c 0x5e46ad 0x58f90f 0x59172f 0x591ac9 0x4fc06a 0x4fc808 0x4fe70d 0x5f0318 0x58f62c 0x5105e2 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e\n",
            "tcmalloc: large alloc 1536008192 bytes == 0xc3574000 @  0x7f106a2191e7 0x4b2590 0x5ad01c 0x4fc81a 0x4fe70d 0x5f0318 0x58f62c 0x5105e2 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7f1069e16c87 0x5b636a\n",
            "Loading pseudo labels from ./data/pseudo_labeled_cifar.pickle\n",
            "Unlabeled data extracted:\t83970\n",
            "29936\n",
            "19525\n",
            "12559\n",
            "8356\n",
            "4442\n",
            "3869\n",
            "2242\n",
            "1433\n",
            "965\n",
            "643\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "cls num list:\n",
            "[29936, 19525, 12559, 8356, 4442, 3869, 2242, 1433, 965, 643]\n",
            "/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/losses.py:45: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  output = torch.where(index, x_m, x)\n",
            "Epoch: [0][0/329], lr: 0.00200\tTime 14.122 (14.122)\tData 0.419 (0.419)\tLoss 9.0360 (9.0360)\tPrec@1 29.297 (29.297)\tPrec@5 91.016 (91.016)\n",
            "Epoch: [0][10/329], lr: 0.00200\tTime 0.087 (1.359)\tData 0.010 (0.043)\tLoss 8.0407 (8.6977)\tPrec@1 43.750 (37.500)\tPrec@5 85.938 (81.072)\n",
            "Epoch: [0][20/329], lr: 0.00200\tTime 0.081 (0.755)\tData 0.007 (0.025)\tLoss 6.9397 (8.0838)\tPrec@1 57.031 (43.266)\tPrec@5 90.234 (85.603)\n",
            "Epoch: [0][30/329], lr: 0.00200\tTime 0.081 (0.540)\tData 0.000 (0.019)\tLoss 7.2141 (7.7550)\tPrec@1 52.344 (46.497)\tPrec@5 85.156 (86.744)\n",
            "Epoch: [0][40/329], lr: 0.00200\tTime 0.059 (0.429)\tData 0.005 (0.016)\tLoss 7.2753 (7.4879)\tPrec@1 48.438 (48.666)\tPrec@5 87.500 (87.748)\n",
            "Epoch: [0][50/329], lr: 0.00200\tTime 0.093 (0.363)\tData 0.005 (0.014)\tLoss 6.4009 (7.3359)\tPrec@1 62.500 (50.291)\tPrec@5 93.750 (88.511)\n",
            "Epoch: [0][60/329], lr: 0.00200\tTime 0.117 (0.319)\tData 0.001 (0.013)\tLoss 6.7188 (7.2065)\tPrec@1 55.859 (51.543)\tPrec@5 87.891 (89.062)\n",
            "Epoch: [0][70/329], lr: 0.00200\tTime 0.106 (0.286)\tData 0.001 (0.011)\tLoss 6.0132 (7.0733)\tPrec@1 62.500 (52.778)\tPrec@5 93.750 (89.574)\n",
            "Epoch: [0][80/329], lr: 0.00200\tTime 0.077 (0.263)\tData 0.007 (0.011)\tLoss 6.7468 (6.9365)\tPrec@1 59.766 (54.008)\tPrec@5 88.281 (89.998)\n",
            "Epoch: [0][90/329], lr: 0.00200\tTime 0.096 (0.244)\tData 0.006 (0.010)\tLoss 5.2891 (6.8202)\tPrec@1 64.844 (54.863)\tPrec@5 95.312 (90.428)\n",
            "Epoch: [0][100/329], lr: 0.00200\tTime 0.086 (0.228)\tData 0.000 (0.010)\tLoss 5.2712 (6.7318)\tPrec@1 66.016 (55.670)\tPrec@5 93.750 (90.811)\n",
            "Epoch: [0][110/329], lr: 0.00200\tTime 0.114 (0.217)\tData 0.000 (0.010)\tLoss 5.7782 (6.6438)\tPrec@1 63.281 (56.394)\tPrec@5 93.750 (91.026)\n",
            "Epoch: [0][120/329], lr: 0.00200\tTime 0.102 (0.207)\tData 0.006 (0.009)\tLoss 5.6952 (6.5841)\tPrec@1 65.234 (57.028)\tPrec@5 93.750 (91.209)\n",
            "Epoch: [0][130/329], lr: 0.00200\tTime 0.117 (0.198)\tData 0.001 (0.009)\tLoss 5.4475 (6.5437)\tPrec@1 65.625 (57.380)\tPrec@5 92.969 (91.415)\n",
            "Epoch: [0][140/329], lr: 0.00200\tTime 0.090 (0.191)\tData 0.005 (0.009)\tLoss 5.4671 (6.4862)\tPrec@1 64.453 (57.829)\tPrec@5 94.141 (91.645)\n",
            "Epoch: [0][150/329], lr: 0.00200\tTime 0.073 (0.184)\tData 0.004 (0.008)\tLoss 5.8048 (6.4452)\tPrec@1 63.672 (58.138)\tPrec@5 95.703 (91.828)\n",
            "Epoch: [0][160/329], lr: 0.00200\tTime 0.083 (0.178)\tData 0.005 (0.008)\tLoss 6.3150 (6.3945)\tPrec@1 59.766 (58.553)\tPrec@5 92.969 (92.030)\n",
            "Epoch: [0][170/329], lr: 0.00200\tTime 0.098 (0.173)\tData 0.006 (0.008)\tLoss 5.6193 (6.3405)\tPrec@1 64.844 (58.991)\tPrec@5 95.703 (92.251)\n",
            "Epoch: [0][180/329], lr: 0.00200\tTime 0.119 (0.169)\tData 0.000 (0.008)\tLoss 5.7986 (6.2952)\tPrec@1 63.281 (59.340)\tPrec@5 94.922 (92.403)\n",
            "Epoch: [0][190/329], lr: 0.00200\tTime 0.087 (0.165)\tData 0.007 (0.008)\tLoss 4.9136 (6.2409)\tPrec@1 71.094 (59.788)\tPrec@5 95.703 (92.545)\n",
            "Epoch: [0][200/329], lr: 0.00200\tTime 0.088 (0.161)\tData 0.005 (0.008)\tLoss 5.0015 (6.2000)\tPrec@1 71.875 (60.195)\tPrec@5 94.531 (92.666)\n",
            "Epoch: [0][210/329], lr: 0.00200\tTime 0.086 (0.158)\tData 0.000 (0.008)\tLoss 5.7411 (6.1484)\tPrec@1 65.234 (60.608)\tPrec@5 94.141 (92.806)\n",
            "Epoch: [0][220/329], lr: 0.00200\tTime 0.088 (0.154)\tData 0.002 (0.008)\tLoss 5.9985 (6.1073)\tPrec@1 62.891 (60.950)\tPrec@5 96.094 (92.939)\n",
            "Epoch: [0][230/329], lr: 0.00200\tTime 0.082 (0.151)\tData 0.007 (0.008)\tLoss 5.5475 (6.0697)\tPrec@1 66.016 (61.222)\tPrec@5 94.531 (93.048)\n",
            "Epoch: [0][240/329], lr: 0.00200\tTime 0.104 (0.149)\tData 0.005 (0.008)\tLoss 5.7290 (6.0433)\tPrec@1 63.281 (61.461)\tPrec@5 96.484 (93.147)\n",
            "Epoch: [0][250/329], lr: 0.00200\tTime 0.100 (0.146)\tData 0.007 (0.008)\tLoss 5.1085 (6.0186)\tPrec@1 68.750 (61.647)\tPrec@5 98.438 (93.226)\n",
            "Epoch: [0][260/329], lr: 0.00200\tTime 0.073 (0.144)\tData 0.001 (0.008)\tLoss 5.6476 (5.9834)\tPrec@1 69.531 (61.931)\tPrec@5 92.188 (93.316)\n",
            "Epoch: [0][270/329], lr: 0.00200\tTime 0.072 (0.142)\tData 0.000 (0.008)\tLoss 5.0361 (5.9508)\tPrec@1 71.875 (62.203)\tPrec@5 96.875 (93.423)\n",
            "Epoch: [0][280/329], lr: 0.00200\tTime 0.104 (0.140)\tData 0.006 (0.008)\tLoss 4.8421 (5.9218)\tPrec@1 71.094 (62.474)\tPrec@5 96.094 (93.507)\n",
            "Epoch: [0][290/329], lr: 0.00200\tTime 0.080 (0.138)\tData 0.007 (0.008)\tLoss 5.1701 (5.8875)\tPrec@1 68.750 (62.752)\tPrec@5 96.094 (93.584)\n",
            "Epoch: [0][300/329], lr: 0.00200\tTime 0.096 (0.137)\tData 0.000 (0.007)\tLoss 5.4681 (5.8528)\tPrec@1 66.406 (63.049)\tPrec@5 95.312 (93.655)\n",
            "Epoch: [0][310/329], lr: 0.00200\tTime 0.076 (0.135)\tData 0.000 (0.007)\tLoss 5.0265 (5.8268)\tPrec@1 71.094 (63.289)\tPrec@5 98.047 (93.722)\n",
            "Epoch: [0][320/329], lr: 0.00200\tTime 0.089 (0.134)\tData 0.050 (0.008)\tLoss 4.6842 (5.7972)\tPrec@1 72.656 (63.525)\tPrec@5 95.312 (93.794)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 13.9263 (13.9263)\tPrec@1 26.000 (26.000)\tPrec@5 87.000 (87.000)\n",
            "Test: [10/100]\tTime 0.034 (0.055)\tLoss 10.4728 (12.6699)\tPrec@1 42.000 (32.182)\tPrec@5 89.000 (85.636)\n",
            "Test: [20/100]\tTime 0.031 (0.042)\tLoss 11.3897 (12.7607)\tPrec@1 35.000 (31.429)\tPrec@5 89.000 (86.238)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 11.8191 (12.6996)\tPrec@1 34.000 (31.516)\tPrec@5 84.000 (86.032)\n",
            "Test: [40/100]\tTime 0.033 (0.033)\tLoss 13.2602 (12.7520)\tPrec@1 27.000 (31.220)\tPrec@5 81.000 (85.732)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 12.7909 (12.6710)\tPrec@1 34.000 (31.608)\tPrec@5 84.000 (85.843)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 10.4931 (12.6435)\tPrec@1 38.000 (31.344)\tPrec@5 87.000 (85.639)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 12.5052 (12.5983)\tPrec@1 32.000 (31.549)\tPrec@5 85.000 (85.704)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 11.1430 (12.5581)\tPrec@1 41.000 (31.790)\tPrec@5 84.000 (85.654)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 12.3892 (12.6050)\tPrec@1 33.000 (31.670)\tPrec@5 90.000 (85.758)\n",
            "val Results: Prec@1 31.520 Prec@5 85.690 Loss 12.64578\n",
            "val Class Accuracy: [0.916,0.898,0.525,0.706,0.053,0.001,0.053,0.000,0.000,0.000]\n",
            "Best Prec@1: 31.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [1][0/329], lr: 0.00400\tTime 0.652 (0.652)\tData 0.481 (0.481)\tLoss 4.9451 (4.9451)\tPrec@1 71.875 (71.875)\tPrec@5 96.875 (96.875)\n",
            "Epoch: [1][10/329], lr: 0.00400\tTime 0.149 (0.185)\tData 0.010 (0.071)\tLoss 5.2255 (4.8386)\tPrec@1 68.359 (71.520)\tPrec@5 97.266 (96.733)\n",
            "Epoch: [1][20/329], lr: 0.00400\tTime 0.212 (0.166)\tData 0.143 (0.064)\tLoss 4.5676 (4.8954)\tPrec@1 69.531 (71.168)\tPrec@5 94.922 (95.964)\n",
            "Epoch: [1][30/329], lr: 0.00400\tTime 0.124 (0.154)\tData 0.008 (0.054)\tLoss 4.4838 (5.0135)\tPrec@1 73.438 (70.149)\tPrec@5 95.703 (95.691)\n",
            "Epoch: [1][40/329], lr: 0.00400\tTime 0.101 (0.148)\tData 0.004 (0.048)\tLoss 4.2729 (5.0080)\tPrec@1 75.000 (70.122)\tPrec@5 96.094 (95.675)\n",
            "Epoch: [1][50/329], lr: 0.00400\tTime 0.103 (0.137)\tData 0.015 (0.040)\tLoss 5.5135 (5.0055)\tPrec@1 67.188 (70.259)\tPrec@5 92.969 (95.764)\n",
            "Epoch: [1][60/329], lr: 0.00400\tTime 0.092 (0.129)\tData 0.000 (0.034)\tLoss 5.1758 (5.0121)\tPrec@1 69.922 (70.325)\tPrec@5 93.750 (95.652)\n",
            "Epoch: [1][70/329], lr: 0.00400\tTime 0.088 (0.124)\tData 0.001 (0.030)\tLoss 4.6910 (4.9820)\tPrec@1 72.656 (70.582)\tPrec@5 96.484 (95.731)\n",
            "Epoch: [1][80/329], lr: 0.00400\tTime 0.112 (0.120)\tData 0.009 (0.027)\tLoss 4.5531 (4.9702)\tPrec@1 72.266 (70.650)\tPrec@5 95.312 (95.800)\n",
            "Epoch: [1][90/329], lr: 0.00400\tTime 0.081 (0.116)\tData 0.004 (0.025)\tLoss 4.2740 (4.9425)\tPrec@1 74.609 (70.853)\tPrec@5 97.656 (95.832)\n",
            "Epoch: [1][100/329], lr: 0.00400\tTime 0.065 (0.113)\tData 0.000 (0.023)\tLoss 4.1931 (4.9113)\tPrec@1 75.000 (71.016)\tPrec@5 97.266 (95.893)\n",
            "Epoch: [1][110/329], lr: 0.00400\tTime 0.072 (0.111)\tData 0.002 (0.022)\tLoss 4.3647 (4.8691)\tPrec@1 75.781 (71.305)\tPrec@5 98.438 (95.985)\n",
            "Epoch: [1][120/329], lr: 0.00400\tTime 0.086 (0.110)\tData 0.008 (0.020)\tLoss 3.8203 (4.8286)\tPrec@1 78.906 (71.568)\tPrec@5 97.266 (96.094)\n",
            "Epoch: [1][130/329], lr: 0.00400\tTime 0.089 (0.108)\tData 0.007 (0.019)\tLoss 4.6083 (4.8156)\tPrec@1 73.047 (71.675)\tPrec@5 98.047 (96.106)\n",
            "Epoch: [1][140/329], lr: 0.00400\tTime 0.104 (0.107)\tData 0.000 (0.018)\tLoss 4.3379 (4.7884)\tPrec@1 74.609 (71.867)\tPrec@5 94.141 (96.121)\n",
            "Epoch: [1][150/329], lr: 0.00400\tTime 0.075 (0.106)\tData 0.000 (0.017)\tLoss 4.4517 (4.7557)\tPrec@1 74.609 (72.139)\tPrec@5 98.047 (96.169)\n",
            "Epoch: [1][160/329], lr: 0.00400\tTime 0.090 (0.104)\tData 0.001 (0.017)\tLoss 4.0657 (4.7386)\tPrec@1 77.344 (72.278)\tPrec@5 96.094 (96.215)\n",
            "Epoch: [1][170/329], lr: 0.00400\tTime 0.095 (0.104)\tData 0.000 (0.016)\tLoss 3.7925 (4.7080)\tPrec@1 77.344 (72.487)\tPrec@5 98.047 (96.276)\n",
            "Epoch: [1][180/329], lr: 0.00400\tTime 0.087 (0.103)\tData 0.000 (0.015)\tLoss 4.2044 (4.6878)\tPrec@1 75.000 (72.643)\tPrec@5 98.047 (96.344)\n",
            "Epoch: [1][190/329], lr: 0.00400\tTime 0.076 (0.102)\tData 0.000 (0.015)\tLoss 3.7805 (4.6642)\tPrec@1 81.250 (72.822)\tPrec@5 95.703 (96.360)\n",
            "Epoch: [1][200/329], lr: 0.00400\tTime 0.097 (0.101)\tData 0.005 (0.015)\tLoss 4.1739 (4.6388)\tPrec@1 78.516 (72.994)\tPrec@5 96.484 (96.399)\n",
            "Epoch: [1][210/329], lr: 0.00400\tTime 0.100 (0.101)\tData 0.006 (0.014)\tLoss 4.0145 (4.6089)\tPrec@1 79.688 (73.202)\tPrec@5 96.875 (96.453)\n",
            "Epoch: [1][220/329], lr: 0.00400\tTime 0.109 (0.100)\tData 0.006 (0.014)\tLoss 4.0396 (4.5797)\tPrec@1 78.516 (73.429)\tPrec@5 96.094 (96.509)\n",
            "Epoch: [1][230/329], lr: 0.00400\tTime 0.092 (0.100)\tData 0.006 (0.014)\tLoss 4.2895 (4.5683)\tPrec@1 77.734 (73.547)\tPrec@5 97.656 (96.528)\n",
            "Epoch: [1][240/329], lr: 0.00400\tTime 0.102 (0.099)\tData 0.005 (0.013)\tLoss 3.8129 (4.5527)\tPrec@1 79.297 (73.668)\tPrec@5 98.047 (96.539)\n",
            "Epoch: [1][250/329], lr: 0.00400\tTime 0.073 (0.099)\tData 0.004 (0.013)\tLoss 3.9982 (4.5370)\tPrec@1 78.125 (73.772)\tPrec@5 96.094 (96.584)\n",
            "Epoch: [1][260/329], lr: 0.00400\tTime 0.083 (0.098)\tData 0.000 (0.013)\tLoss 4.1563 (4.5218)\tPrec@1 75.781 (73.885)\tPrec@5 97.266 (96.615)\n",
            "Epoch: [1][270/329], lr: 0.00400\tTime 0.080 (0.098)\tData 0.003 (0.013)\tLoss 4.4152 (4.5039)\tPrec@1 76.172 (74.030)\tPrec@5 97.266 (96.659)\n",
            "Epoch: [1][280/329], lr: 0.00400\tTime 0.097 (0.098)\tData 0.000 (0.012)\tLoss 4.3935 (4.4862)\tPrec@1 78.125 (74.158)\tPrec@5 96.875 (96.697)\n",
            "Epoch: [1][290/329], lr: 0.00400\tTime 0.115 (0.097)\tData 0.000 (0.012)\tLoss 4.2162 (4.4664)\tPrec@1 74.219 (74.319)\tPrec@5 97.266 (96.731)\n",
            "Epoch: [1][300/329], lr: 0.00400\tTime 0.085 (0.097)\tData 0.004 (0.012)\tLoss 4.1322 (4.4448)\tPrec@1 76.562 (74.489)\tPrec@5 95.703 (96.762)\n",
            "Epoch: [1][310/329], lr: 0.00400\tTime 0.080 (0.097)\tData 0.003 (0.012)\tLoss 4.2556 (4.4258)\tPrec@1 79.688 (74.641)\tPrec@5 97.266 (96.787)\n",
            "Epoch: [1][320/329], lr: 0.00400\tTime 0.121 (0.097)\tData 0.084 (0.012)\tLoss 4.5502 (4.4157)\tPrec@1 73.828 (74.709)\tPrec@5 97.656 (96.820)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 15.3423 (15.3423)\tPrec@1 26.000 (26.000)\tPrec@5 88.000 (88.000)\n",
            "Test: [10/100]\tTime 0.026 (0.055)\tLoss 11.7811 (14.2207)\tPrec@1 43.000 (33.545)\tPrec@5 88.000 (85.000)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 13.6848 (14.2649)\tPrec@1 34.000 (33.143)\tPrec@5 81.000 (84.476)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 13.2239 (14.1074)\tPrec@1 37.000 (33.710)\tPrec@5 86.000 (84.323)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 15.1182 (14.1680)\tPrec@1 30.000 (33.707)\tPrec@5 80.000 (83.927)\n",
            "Test: [50/100]\tTime 0.010 (0.032)\tLoss 14.1814 (14.1066)\tPrec@1 37.000 (34.314)\tPrec@5 86.000 (83.980)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 12.0225 (14.1295)\tPrec@1 41.000 (34.082)\tPrec@5 85.000 (83.590)\n",
            "Test: [70/100]\tTime 0.043 (0.030)\tLoss 13.6479 (14.1061)\tPrec@1 30.000 (33.915)\tPrec@5 85.000 (83.507)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 12.7210 (14.0709)\tPrec@1 41.000 (34.099)\tPrec@5 86.000 (83.728)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 13.6091 (14.1288)\tPrec@1 37.000 (33.769)\tPrec@5 80.000 (83.923)\n",
            "val Results: Prec@1 33.780 Prec@5 83.980 Loss 14.15162\n",
            "val Class Accuracy: [0.892,0.895,0.830,0.127,0.513,0.000,0.118,0.003,0.000,0.000]\n",
            "Best Prec@1: 33.780\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [2][0/329], lr: 0.00600\tTime 0.584 (0.584)\tData 0.490 (0.490)\tLoss 3.6380 (3.6380)\tPrec@1 80.078 (80.078)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [2][10/329], lr: 0.00600\tTime 0.085 (0.137)\tData 0.000 (0.050)\tLoss 4.8397 (4.8318)\tPrec@1 71.484 (72.869)\tPrec@5 96.484 (95.916)\n",
            "Epoch: [2][20/329], lr: 0.00600\tTime 0.078 (0.114)\tData 0.005 (0.029)\tLoss 4.3244 (4.6918)\tPrec@1 72.656 (73.158)\tPrec@5 98.828 (96.354)\n",
            "Epoch: [2][30/329], lr: 0.00600\tTime 0.091 (0.108)\tData 0.000 (0.022)\tLoss 4.1916 (4.5009)\tPrec@1 74.609 (74.244)\tPrec@5 98.047 (96.850)\n",
            "Epoch: [2][40/329], lr: 0.00600\tTime 0.081 (0.104)\tData 0.002 (0.017)\tLoss 4.3410 (4.4392)\tPrec@1 77.344 (74.562)\tPrec@5 96.484 (96.818)\n",
            "Epoch: [2][50/329], lr: 0.00600\tTime 0.076 (0.101)\tData 0.007 (0.015)\tLoss 4.5523 (4.3796)\tPrec@1 73.828 (74.939)\tPrec@5 95.703 (97.013)\n",
            "Epoch: [2][60/329], lr: 0.00600\tTime 0.111 (0.099)\tData 0.018 (0.014)\tLoss 4.1971 (4.3168)\tPrec@1 75.781 (75.403)\tPrec@5 98.438 (97.035)\n",
            "Epoch: [2][70/329], lr: 0.00600\tTime 0.089 (0.097)\tData 0.000 (0.013)\tLoss 4.0658 (4.2479)\tPrec@1 76.953 (75.891)\tPrec@5 96.094 (97.062)\n",
            "Epoch: [2][80/329], lr: 0.00600\tTime 0.087 (0.096)\tData 0.000 (0.012)\tLoss 4.2562 (4.2168)\tPrec@1 76.562 (76.196)\tPrec@5 97.266 (97.126)\n",
            "Epoch: [2][90/329], lr: 0.00600\tTime 0.066 (0.096)\tData 0.007 (0.011)\tLoss 3.7217 (4.1615)\tPrec@1 80.078 (76.571)\tPrec@5 95.703 (97.167)\n",
            "Epoch: [2][100/329], lr: 0.00600\tTime 0.120 (0.097)\tData 0.010 (0.011)\tLoss 4.4360 (4.1184)\tPrec@1 74.609 (76.926)\tPrec@5 97.656 (97.269)\n",
            "Epoch: [2][110/329], lr: 0.00600\tTime 0.147 (0.099)\tData 0.000 (0.010)\tLoss 4.0666 (4.0889)\tPrec@1 78.906 (77.189)\tPrec@5 98.047 (97.294)\n",
            "Epoch: [2][120/329], lr: 0.00600\tTime 0.124 (0.101)\tData 0.056 (0.010)\tLoss 3.5118 (4.0603)\tPrec@1 78.906 (77.366)\tPrec@5 98.828 (97.350)\n",
            "Epoch: [2][130/329], lr: 0.00600\tTime 0.067 (0.102)\tData 0.000 (0.010)\tLoss 4.3614 (4.0460)\tPrec@1 74.219 (77.430)\tPrec@5 97.656 (97.373)\n",
            "Epoch: [2][140/329], lr: 0.00600\tTime 0.122 (0.102)\tData 0.035 (0.011)\tLoss 3.0576 (4.0211)\tPrec@1 84.375 (77.640)\tPrec@5 98.828 (97.426)\n",
            "Epoch: [2][150/329], lr: 0.00600\tTime 0.099 (0.101)\tData 0.006 (0.010)\tLoss 4.0827 (4.0072)\tPrec@1 78.125 (77.763)\tPrec@5 96.875 (97.447)\n",
            "Epoch: [2][160/329], lr: 0.00600\tTime 0.113 (0.100)\tData 0.000 (0.010)\tLoss 3.4842 (3.9828)\tPrec@1 79.297 (77.914)\tPrec@5 98.047 (97.469)\n",
            "Epoch: [2][170/329], lr: 0.00600\tTime 0.118 (0.100)\tData 0.000 (0.010)\tLoss 4.1442 (3.9689)\tPrec@1 77.734 (78.006)\tPrec@5 97.656 (97.503)\n",
            "Epoch: [2][180/329], lr: 0.00600\tTime 0.075 (0.099)\tData 0.006 (0.010)\tLoss 3.0417 (3.9385)\tPrec@1 83.984 (78.192)\tPrec@5 98.828 (97.535)\n",
            "Epoch: [2][190/329], lr: 0.00600\tTime 0.074 (0.099)\tData 0.000 (0.010)\tLoss 3.4495 (3.9272)\tPrec@1 80.859 (78.274)\tPrec@5 98.438 (97.562)\n",
            "Epoch: [2][200/329], lr: 0.00600\tTime 0.101 (0.098)\tData 0.000 (0.009)\tLoss 3.2065 (3.9188)\tPrec@1 83.594 (78.370)\tPrec@5 99.609 (97.594)\n",
            "Epoch: [2][210/329], lr: 0.00600\tTime 0.078 (0.098)\tData 0.007 (0.009)\tLoss 3.7044 (3.9032)\tPrec@1 80.859 (78.475)\tPrec@5 97.656 (97.634)\n",
            "Epoch: [2][220/329], lr: 0.00600\tTime 0.092 (0.097)\tData 0.016 (0.009)\tLoss 3.1527 (3.8860)\tPrec@1 82.812 (78.600)\tPrec@5 99.219 (97.679)\n",
            "Epoch: [2][230/329], lr: 0.00600\tTime 0.088 (0.097)\tData 0.006 (0.009)\tLoss 3.5152 (3.8730)\tPrec@1 81.250 (78.710)\tPrec@5 99.609 (97.705)\n",
            "Epoch: [2][240/329], lr: 0.00600\tTime 0.076 (0.097)\tData 0.000 (0.009)\tLoss 3.9247 (3.8681)\tPrec@1 77.734 (78.741)\tPrec@5 100.000 (97.742)\n",
            "Epoch: [2][250/329], lr: 0.00600\tTime 0.098 (0.096)\tData 0.004 (0.009)\tLoss 3.4654 (3.8544)\tPrec@1 82.422 (78.853)\tPrec@5 98.438 (97.759)\n",
            "Epoch: [2][260/329], lr: 0.00600\tTime 0.096 (0.096)\tData 0.001 (0.009)\tLoss 3.0486 (3.8384)\tPrec@1 84.766 (78.969)\tPrec@5 98.828 (97.776)\n",
            "Epoch: [2][270/329], lr: 0.00600\tTime 0.088 (0.096)\tData 0.000 (0.009)\tLoss 3.8313 (3.8231)\tPrec@1 79.688 (79.082)\tPrec@5 98.438 (97.790)\n",
            "Epoch: [2][280/329], lr: 0.00600\tTime 0.092 (0.096)\tData 0.000 (0.009)\tLoss 3.6383 (3.8096)\tPrec@1 78.516 (79.169)\tPrec@5 99.609 (97.811)\n",
            "Epoch: [2][290/329], lr: 0.00600\tTime 0.094 (0.095)\tData 0.005 (0.009)\tLoss 3.8321 (3.7950)\tPrec@1 79.688 (79.247)\tPrec@5 100.000 (97.833)\n",
            "Epoch: [2][300/329], lr: 0.00600\tTime 0.078 (0.095)\tData 0.007 (0.009)\tLoss 3.3459 (3.7791)\tPrec@1 81.250 (79.354)\tPrec@5 98.828 (97.850)\n",
            "Epoch: [2][310/329], lr: 0.00600\tTime 0.070 (0.095)\tData 0.000 (0.009)\tLoss 3.0595 (3.7576)\tPrec@1 84.375 (79.487)\tPrec@5 98.438 (97.863)\n",
            "Epoch: [2][320/329], lr: 0.00600\tTime 0.097 (0.095)\tData 0.048 (0.009)\tLoss 4.2736 (3.7480)\tPrec@1 79.297 (79.563)\tPrec@5 98.047 (97.873)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 10.0342 (10.0342)\tPrec@1 53.000 (53.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.017 (0.053)\tLoss 7.2810 (9.4935)\tPrec@1 66.000 (55.000)\tPrec@5 97.000 (92.818)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 8.1156 (9.5158)\tPrec@1 62.000 (55.143)\tPrec@5 94.000 (92.524)\n",
            "Test: [30/100]\tTime 0.011 (0.032)\tLoss 9.1041 (9.5191)\tPrec@1 56.000 (55.258)\tPrec@5 90.000 (92.710)\n",
            "Test: [40/100]\tTime 0.027 (0.032)\tLoss 10.0854 (9.6376)\tPrec@1 52.000 (54.683)\tPrec@5 90.000 (92.561)\n",
            "Test: [50/100]\tTime 0.017 (0.030)\tLoss 10.0224 (9.5432)\tPrec@1 54.000 (55.098)\tPrec@5 86.000 (92.529)\n",
            "Test: [60/100]\tTime 0.022 (0.029)\tLoss 8.3814 (9.5284)\tPrec@1 58.000 (55.033)\tPrec@5 92.000 (92.361)\n",
            "Test: [70/100]\tTime 0.040 (0.029)\tLoss 9.6800 (9.5034)\tPrec@1 53.000 (55.042)\tPrec@5 92.000 (92.676)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 8.4592 (9.4803)\tPrec@1 60.000 (55.148)\tPrec@5 94.000 (92.741)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 9.6855 (9.5058)\tPrec@1 53.000 (55.077)\tPrec@5 95.000 (92.769)\n",
            "val Results: Prec@1 55.160 Prec@5 92.770 Loss 9.51098\n",
            "val Class Accuracy: [0.960,0.898,0.410,0.694,0.352,0.530,0.668,0.411,0.420,0.173]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [3][0/329], lr: 0.00800\tTime 0.572 (0.572)\tData 0.484 (0.484)\tLoss 3.9424 (3.9424)\tPrec@1 78.906 (78.906)\tPrec@5 96.875 (96.875)\n",
            "Epoch: [3][10/329], lr: 0.00800\tTime 0.090 (0.141)\tData 0.000 (0.049)\tLoss 3.6066 (3.8404)\tPrec@1 82.422 (79.510)\tPrec@5 98.438 (97.479)\n",
            "Epoch: [3][20/329], lr: 0.00800\tTime 0.096 (0.118)\tData 0.004 (0.029)\tLoss 3.6519 (3.7047)\tPrec@1 82.422 (80.841)\tPrec@5 97.266 (97.396)\n",
            "Epoch: [3][30/329], lr: 0.00800\tTime 0.091 (0.108)\tData 0.007 (0.022)\tLoss 4.6187 (3.7417)\tPrec@1 78.125 (80.922)\tPrec@5 96.484 (97.278)\n",
            "Epoch: [3][40/329], lr: 0.00800\tTime 0.072 (0.103)\tData 0.000 (0.018)\tLoss 3.0160 (3.7162)\tPrec@1 84.766 (81.136)\tPrec@5 98.047 (97.294)\n",
            "Epoch: [3][50/329], lr: 0.00800\tTime 0.077 (0.099)\tData 0.004 (0.016)\tLoss 3.8128 (3.6576)\tPrec@1 81.250 (81.480)\tPrec@5 96.875 (97.342)\n",
            "Epoch: [3][60/329], lr: 0.00800\tTime 0.081 (0.098)\tData 0.000 (0.014)\tLoss 2.9550 (3.6245)\tPrec@1 85.938 (81.570)\tPrec@5 98.047 (97.355)\n",
            "Epoch: [3][70/329], lr: 0.00800\tTime 0.099 (0.096)\tData 0.007 (0.014)\tLoss 3.4197 (3.6140)\tPrec@1 82.422 (81.575)\tPrec@5 98.047 (97.414)\n",
            "Epoch: [3][80/329], lr: 0.00800\tTime 0.084 (0.095)\tData 0.007 (0.013)\tLoss 4.0999 (3.5788)\tPrec@1 78.125 (81.655)\tPrec@5 98.828 (97.512)\n",
            "Epoch: [3][90/329], lr: 0.00800\tTime 0.093 (0.094)\tData 0.000 (0.012)\tLoss 3.2035 (3.5397)\tPrec@1 83.594 (81.791)\tPrec@5 98.047 (97.570)\n",
            "Epoch: [3][100/329], lr: 0.00800\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 3.1580 (3.5405)\tPrec@1 84.375 (81.842)\tPrec@5 97.266 (97.598)\n",
            "Epoch: [3][110/329], lr: 0.00800\tTime 0.071 (0.093)\tData 0.000 (0.011)\tLoss 3.6982 (3.5225)\tPrec@1 76.953 (81.876)\tPrec@5 98.438 (97.646)\n",
            "Epoch: [3][120/329], lr: 0.00800\tTime 0.092 (0.093)\tData 0.000 (0.011)\tLoss 2.9147 (3.4910)\tPrec@1 84.375 (81.996)\tPrec@5 99.609 (97.756)\n",
            "Epoch: [3][130/329], lr: 0.00800\tTime 0.095 (0.092)\tData 0.000 (0.010)\tLoss 3.1862 (3.4702)\tPrec@1 83.203 (82.100)\tPrec@5 98.438 (97.826)\n",
            "Epoch: [3][140/329], lr: 0.00800\tTime 0.091 (0.092)\tData 0.007 (0.010)\tLoss 2.7998 (3.4521)\tPrec@1 85.547 (82.164)\tPrec@5 98.828 (97.861)\n",
            "Epoch: [3][150/329], lr: 0.00800\tTime 0.067 (0.092)\tData 0.015 (0.010)\tLoss 3.3918 (3.4395)\tPrec@1 82.031 (82.233)\tPrec@5 97.656 (97.912)\n",
            "Epoch: [3][160/329], lr: 0.00800\tTime 0.089 (0.091)\tData 0.005 (0.009)\tLoss 3.5050 (3.4253)\tPrec@1 79.297 (82.286)\tPrec@5 98.438 (97.964)\n",
            "Epoch: [3][170/329], lr: 0.00800\tTime 0.088 (0.091)\tData 0.001 (0.009)\tLoss 3.0587 (3.4106)\tPrec@1 84.375 (82.353)\tPrec@5 97.656 (97.992)\n",
            "Epoch: [3][180/329], lr: 0.00800\tTime 0.058 (0.091)\tData 0.000 (0.009)\tLoss 3.5146 (3.4051)\tPrec@1 81.641 (82.359)\tPrec@5 97.266 (98.038)\n",
            "Epoch: [3][190/329], lr: 0.00800\tTime 0.075 (0.091)\tData 0.008 (0.009)\tLoss 2.9847 (3.3875)\tPrec@1 85.156 (82.438)\tPrec@5 98.438 (98.053)\n",
            "Epoch: [3][200/329], lr: 0.00800\tTime 0.125 (0.093)\tData 0.000 (0.009)\tLoss 3.5357 (3.3801)\tPrec@1 83.203 (82.478)\tPrec@5 97.656 (98.051)\n",
            "Epoch: [3][210/329], lr: 0.00800\tTime 0.106 (0.094)\tData 0.003 (0.009)\tLoss 2.7385 (3.3532)\tPrec@1 84.375 (82.583)\tPrec@5 100.000 (98.082)\n",
            "Epoch: [3][220/329], lr: 0.00800\tTime 0.082 (0.095)\tData 0.000 (0.010)\tLoss 2.9183 (3.3414)\tPrec@1 85.938 (82.645)\tPrec@5 98.828 (98.107)\n",
            "Epoch: [3][230/329], lr: 0.00800\tTime 0.097 (0.096)\tData 0.001 (0.011)\tLoss 2.7615 (3.3416)\tPrec@1 84.375 (82.652)\tPrec@5 99.609 (98.138)\n",
            "Epoch: [3][240/329], lr: 0.00800\tTime 0.071 (0.096)\tData 0.000 (0.010)\tLoss 3.4194 (3.3387)\tPrec@1 83.203 (82.663)\tPrec@5 99.219 (98.167)\n",
            "Epoch: [3][250/329], lr: 0.00800\tTime 0.081 (0.096)\tData 0.000 (0.010)\tLoss 2.6709 (3.3283)\tPrec@1 84.375 (82.697)\tPrec@5 99.219 (98.182)\n",
            "Epoch: [3][260/329], lr: 0.00800\tTime 0.082 (0.096)\tData 0.004 (0.010)\tLoss 3.7484 (3.3217)\tPrec@1 81.250 (82.738)\tPrec@5 98.828 (98.210)\n",
            "Epoch: [3][270/329], lr: 0.00800\tTime 0.075 (0.095)\tData 0.000 (0.010)\tLoss 3.9245 (3.3208)\tPrec@1 78.906 (82.723)\tPrec@5 98.438 (98.217)\n",
            "Epoch: [3][280/329], lr: 0.00800\tTime 0.096 (0.095)\tData 0.003 (0.010)\tLoss 2.2898 (3.3057)\tPrec@1 88.672 (82.808)\tPrec@5 98.438 (98.233)\n",
            "Epoch: [3][290/329], lr: 0.00800\tTime 0.083 (0.095)\tData 0.004 (0.010)\tLoss 2.9724 (3.2972)\tPrec@1 84.766 (82.849)\tPrec@5 100.000 (98.262)\n",
            "Epoch: [3][300/329], lr: 0.00800\tTime 0.108 (0.095)\tData 0.000 (0.009)\tLoss 2.5566 (3.2880)\tPrec@1 85.156 (82.884)\tPrec@5 100.000 (98.291)\n",
            "Epoch: [3][310/329], lr: 0.00800\tTime 0.080 (0.094)\tData 0.000 (0.009)\tLoss 3.0458 (3.2822)\tPrec@1 83.984 (82.909)\tPrec@5 98.438 (98.304)\n",
            "Epoch: [3][320/329], lr: 0.00800\tTime 0.135 (0.094)\tData 0.095 (0.009)\tLoss 2.8587 (3.2691)\tPrec@1 84.375 (82.982)\tPrec@5 99.219 (98.317)\n",
            "Test: [0/100]\tTime 0.292 (0.292)\tLoss 13.6015 (13.6015)\tPrec@1 34.000 (34.000)\tPrec@5 81.000 (81.000)\n",
            "Test: [10/100]\tTime 0.032 (0.057)\tLoss 10.2447 (12.3153)\tPrec@1 55.000 (41.182)\tPrec@5 85.000 (87.091)\n",
            "Test: [20/100]\tTime 0.029 (0.038)\tLoss 10.6843 (12.3983)\tPrec@1 50.000 (41.476)\tPrec@5 86.000 (86.381)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 11.5987 (12.3426)\tPrec@1 47.000 (41.226)\tPrec@5 88.000 (86.613)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 13.0865 (12.3602)\tPrec@1 44.000 (41.171)\tPrec@5 87.000 (86.610)\n",
            "Test: [50/100]\tTime 0.020 (0.030)\tLoss 11.5043 (12.2546)\tPrec@1 51.000 (41.863)\tPrec@5 85.000 (86.510)\n",
            "Test: [60/100]\tTime 0.027 (0.029)\tLoss 11.1161 (12.2120)\tPrec@1 45.000 (42.098)\tPrec@5 86.000 (86.213)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 12.1770 (12.1957)\tPrec@1 45.000 (42.085)\tPrec@5 90.000 (86.070)\n",
            "Test: [80/100]\tTime 0.029 (0.028)\tLoss 11.3031 (12.1273)\tPrec@1 44.000 (42.235)\tPrec@5 92.000 (86.333)\n",
            "Test: [90/100]\tTime 0.020 (0.027)\tLoss 12.5509 (12.2311)\tPrec@1 36.000 (41.703)\tPrec@5 89.000 (86.121)\n",
            "val Results: Prec@1 41.850 Prec@5 86.310 Loss 12.21984\n",
            "val Class Accuracy: [0.980,0.538,0.314,0.028,0.360,0.592,0.419,0.512,0.015,0.427]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [4][0/329], lr: 0.01000\tTime 0.557 (0.557)\tData 0.483 (0.483)\tLoss 4.7739 (4.7739)\tPrec@1 74.219 (74.219)\tPrec@5 95.312 (95.312)\n",
            "Epoch: [4][10/329], lr: 0.01000\tTime 0.073 (0.138)\tData 0.002 (0.049)\tLoss 4.8252 (6.8989)\tPrec@1 67.578 (59.233)\tPrec@5 94.141 (90.128)\n",
            "Epoch: [4][20/329], lr: 0.01000\tTime 0.092 (0.115)\tData 0.000 (0.028)\tLoss 5.4668 (6.3642)\tPrec@1 64.844 (60.975)\tPrec@5 94.531 (91.574)\n",
            "Epoch: [4][30/329], lr: 0.01000\tTime 0.101 (0.107)\tData 0.005 (0.021)\tLoss 5.0602 (6.0846)\tPrec@1 67.578 (62.286)\tPrec@5 95.312 (92.276)\n",
            "Epoch: [4][40/329], lr: 0.01000\tTime 0.085 (0.102)\tData 0.000 (0.018)\tLoss 4.6500 (5.7858)\tPrec@1 70.312 (64.167)\tPrec@5 96.875 (93.026)\n",
            "Epoch: [4][50/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.007 (0.016)\tLoss 4.9537 (5.5788)\tPrec@1 69.922 (65.587)\tPrec@5 95.703 (93.589)\n",
            "Epoch: [4][60/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.005 (0.015)\tLoss 5.1885 (5.4484)\tPrec@1 71.094 (66.598)\tPrec@5 98.047 (94.128)\n",
            "Epoch: [4][70/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.004 (0.014)\tLoss 4.1001 (5.2979)\tPrec@1 76.953 (67.721)\tPrec@5 98.828 (94.636)\n",
            "Epoch: [4][80/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.005 (0.013)\tLoss 3.9739 (5.1537)\tPrec@1 80.469 (68.996)\tPrec@5 99.219 (95.076)\n",
            "Epoch: [4][90/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.000 (0.012)\tLoss 4.3013 (5.0455)\tPrec@1 76.172 (69.892)\tPrec@5 98.438 (95.355)\n",
            "Epoch: [4][100/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.005 (0.011)\tLoss 4.3749 (4.9422)\tPrec@1 74.219 (70.684)\tPrec@5 98.047 (95.525)\n",
            "Epoch: [4][110/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.010 (0.011)\tLoss 3.8155 (4.8535)\tPrec@1 81.250 (71.330)\tPrec@5 96.875 (95.742)\n",
            "Epoch: [4][120/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.010 (0.011)\tLoss 3.3616 (4.7616)\tPrec@1 82.031 (71.969)\tPrec@5 99.609 (95.929)\n",
            "Epoch: [4][130/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.007 (0.011)\tLoss 3.8149 (4.7026)\tPrec@1 80.078 (72.433)\tPrec@5 98.828 (96.097)\n",
            "Epoch: [4][140/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.017 (0.011)\tLoss 3.9314 (4.6192)\tPrec@1 78.516 (73.041)\tPrec@5 98.438 (96.254)\n",
            "Epoch: [4][150/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.004 (0.010)\tLoss 3.9239 (4.5669)\tPrec@1 78.516 (73.432)\tPrec@5 97.266 (96.352)\n",
            "Epoch: [4][160/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.003 (0.010)\tLoss 3.6115 (4.5093)\tPrec@1 81.641 (73.848)\tPrec@5 99.219 (96.450)\n",
            "Epoch: [4][170/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.000 (0.010)\tLoss 3.2928 (4.4491)\tPrec@1 82.812 (74.308)\tPrec@5 97.656 (96.541)\n",
            "Epoch: [4][180/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.000 (0.009)\tLoss 3.3081 (4.3943)\tPrec@1 80.859 (74.665)\tPrec@5 98.438 (96.627)\n",
            "Epoch: [4][190/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.000 (0.009)\tLoss 3.6205 (4.3419)\tPrec@1 80.469 (75.035)\tPrec@5 98.438 (96.718)\n",
            "Epoch: [4][200/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.000 (0.009)\tLoss 3.6827 (4.2934)\tPrec@1 82.031 (75.406)\tPrec@5 97.266 (96.755)\n",
            "Epoch: [4][210/329], lr: 0.01000\tTime 0.109 (0.091)\tData 0.012 (0.009)\tLoss 2.9037 (4.2440)\tPrec@1 84.766 (75.748)\tPrec@5 98.828 (96.845)\n",
            "Epoch: [4][220/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.005 (0.009)\tLoss 3.4914 (4.2048)\tPrec@1 79.688 (76.002)\tPrec@5 96.094 (96.919)\n",
            "Epoch: [4][230/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.005 (0.009)\tLoss 2.8001 (4.1687)\tPrec@1 83.984 (76.268)\tPrec@5 98.828 (96.975)\n",
            "Epoch: [4][240/329], lr: 0.01000\tTime 0.065 (0.091)\tData 0.003 (0.009)\tLoss 3.7523 (4.1298)\tPrec@1 81.250 (76.525)\tPrec@5 98.047 (97.042)\n",
            "Epoch: [4][250/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.005 (0.009)\tLoss 2.8302 (4.0923)\tPrec@1 84.766 (76.798)\tPrec@5 98.828 (97.098)\n",
            "Epoch: [4][260/329], lr: 0.01000\tTime 0.113 (0.090)\tData 0.008 (0.009)\tLoss 3.5829 (4.0601)\tPrec@1 80.859 (77.011)\tPrec@5 99.219 (97.164)\n",
            "Epoch: [4][270/329], lr: 0.01000\tTime 0.104 (0.090)\tData 0.009 (0.009)\tLoss 3.3277 (4.0335)\tPrec@1 81.250 (77.208)\tPrec@5 98.828 (97.188)\n",
            "Epoch: [4][280/329], lr: 0.01000\tTime 0.131 (0.091)\tData 0.010 (0.009)\tLoss 3.5036 (3.9957)\tPrec@1 80.859 (77.456)\tPrec@5 99.219 (97.239)\n",
            "Epoch: [4][290/329], lr: 0.01000\tTime 0.110 (0.092)\tData 0.000 (0.008)\tLoss 2.7293 (3.9674)\tPrec@1 85.547 (77.662)\tPrec@5 99.219 (97.292)\n",
            "Epoch: [4][300/329], lr: 0.01000\tTime 0.169 (0.093)\tData 0.000 (0.008)\tLoss 3.1246 (3.9377)\tPrec@1 83.203 (77.868)\tPrec@5 98.047 (97.336)\n",
            "Epoch: [4][310/329], lr: 0.01000\tTime 0.127 (0.093)\tData 0.046 (0.009)\tLoss 2.4946 (3.9079)\tPrec@1 86.719 (78.079)\tPrec@5 99.219 (97.369)\n",
            "Epoch: [4][320/329], lr: 0.01000\tTime 0.155 (0.094)\tData 0.081 (0.009)\tLoss 3.2069 (3.8784)\tPrec@1 81.641 (78.259)\tPrec@5 99.219 (97.410)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 16.3344 (16.3344)\tPrec@1 31.000 (31.000)\tPrec@5 85.000 (85.000)\n",
            "Test: [10/100]\tTime 0.032 (0.054)\tLoss 12.3667 (15.9757)\tPrec@1 45.000 (28.000)\tPrec@5 89.000 (87.364)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 16.2366 (16.2093)\tPrec@1 27.000 (27.286)\tPrec@5 89.000 (87.190)\n",
            "Test: [30/100]\tTime 0.033 (0.035)\tLoss 15.8622 (16.3557)\tPrec@1 28.000 (27.000)\tPrec@5 83.000 (86.290)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 15.9694 (16.4614)\tPrec@1 28.000 (26.415)\tPrec@5 90.000 (85.878)\n",
            "Test: [50/100]\tTime 0.040 (0.030)\tLoss 15.5223 (16.3550)\tPrec@1 33.000 (26.882)\tPrec@5 83.000 (85.824)\n",
            "Test: [60/100]\tTime 0.024 (0.029)\tLoss 15.1898 (16.2144)\tPrec@1 25.000 (27.246)\tPrec@5 89.000 (85.885)\n",
            "Test: [70/100]\tTime 0.020 (0.028)\tLoss 17.6840 (16.1952)\tPrec@1 21.000 (27.296)\tPrec@5 80.000 (85.732)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 15.6753 (16.2069)\tPrec@1 29.000 (27.309)\tPrec@5 81.000 (85.654)\n",
            "Test: [90/100]\tTime 0.027 (0.027)\tLoss 16.6715 (16.2273)\tPrec@1 26.000 (27.231)\tPrec@5 87.000 (85.692)\n",
            "val Results: Prec@1 27.260 Prec@5 85.770 Loss 16.25001\n",
            "val Class Accuracy: [0.818,0.064,0.029,0.433,0.236,0.163,0.946,0.034,0.003,0.000]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [5][0/329], lr: 0.01000\tTime 0.539 (0.539)\tData 0.435 (0.435)\tLoss 5.5521 (5.5521)\tPrec@1 70.703 (70.703)\tPrec@5 95.312 (95.312)\n",
            "Epoch: [5][10/329], lr: 0.01000\tTime 0.102 (0.142)\tData 0.002 (0.055)\tLoss 7.3148 (7.9638)\tPrec@1 55.469 (53.977)\tPrec@5 89.844 (86.044)\n",
            "Epoch: [5][20/329], lr: 0.01000\tTime 0.084 (0.118)\tData 0.007 (0.031)\tLoss 6.3102 (7.4089)\tPrec@1 58.594 (55.618)\tPrec@5 95.312 (89.025)\n",
            "Epoch: [5][30/329], lr: 0.01000\tTime 0.083 (0.109)\tData 0.000 (0.022)\tLoss 5.7463 (6.9947)\tPrec@1 66.797 (57.686)\tPrec@5 94.922 (90.814)\n",
            "Epoch: [5][40/329], lr: 0.01000\tTime 0.090 (0.103)\tData 0.006 (0.019)\tLoss 4.7257 (6.6364)\tPrec@1 71.875 (59.994)\tPrec@5 96.484 (91.702)\n",
            "Epoch: [5][50/329], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.016)\tLoss 4.7439 (6.3385)\tPrec@1 72.266 (61.788)\tPrec@5 96.484 (92.624)\n",
            "Epoch: [5][60/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.015)\tLoss 4.8262 (6.1075)\tPrec@1 70.312 (63.339)\tPrec@5 94.531 (93.078)\n",
            "Epoch: [5][70/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.011 (0.014)\tLoss 4.0578 (5.9262)\tPrec@1 76.172 (64.547)\tPrec@5 98.438 (93.557)\n",
            "Epoch: [5][80/329], lr: 0.01000\tTime 0.122 (0.095)\tData 0.007 (0.013)\tLoss 4.3997 (5.7489)\tPrec@1 73.438 (65.683)\tPrec@5 95.703 (93.972)\n",
            "Epoch: [5][90/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.012)\tLoss 4.6381 (5.6053)\tPrec@1 72.266 (66.608)\tPrec@5 95.703 (94.274)\n",
            "Epoch: [5][100/329], lr: 0.01000\tTime 0.070 (0.094)\tData 0.001 (0.012)\tLoss 4.6609 (5.4821)\tPrec@1 73.828 (67.481)\tPrec@5 94.922 (94.605)\n",
            "Epoch: [5][110/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.008 (0.011)\tLoss 4.0342 (5.3647)\tPrec@1 77.734 (68.250)\tPrec@5 96.484 (94.834)\n",
            "Epoch: [5][120/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.011)\tLoss 4.2543 (5.2543)\tPrec@1 76.562 (69.018)\tPrec@5 96.484 (95.045)\n",
            "Epoch: [5][130/329], lr: 0.01000\tTime 0.081 (0.092)\tData 0.000 (0.011)\tLoss 4.5332 (5.1500)\tPrec@1 75.391 (69.731)\tPrec@5 96.484 (95.223)\n",
            "Epoch: [5][140/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.004 (0.010)\tLoss 3.9636 (5.0550)\tPrec@1 78.125 (70.382)\tPrec@5 100.000 (95.415)\n",
            "Epoch: [5][150/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.007 (0.010)\tLoss 3.8555 (4.9784)\tPrec@1 82.031 (70.949)\tPrec@5 96.875 (95.556)\n",
            "Epoch: [5][160/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.007 (0.010)\tLoss 3.1623 (4.8917)\tPrec@1 83.203 (71.557)\tPrec@5 98.438 (95.715)\n",
            "Epoch: [5][170/329], lr: 0.01000\tTime 0.073 (0.092)\tData 0.007 (0.010)\tLoss 3.0443 (4.8127)\tPrec@1 83.594 (72.085)\tPrec@5 98.047 (95.868)\n",
            "Epoch: [5][180/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.000 (0.009)\tLoss 2.9560 (4.7367)\tPrec@1 83.984 (72.594)\tPrec@5 97.656 (95.986)\n",
            "Epoch: [5][190/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 3.2145 (4.6720)\tPrec@1 82.031 (73.010)\tPrec@5 98.438 (96.090)\n",
            "Epoch: [5][200/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.005 (0.009)\tLoss 3.2098 (4.6153)\tPrec@1 81.250 (73.381)\tPrec@5 99.609 (96.175)\n",
            "Epoch: [5][210/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.007 (0.009)\tLoss 3.2974 (4.5559)\tPrec@1 82.031 (73.800)\tPrec@5 99.219 (96.290)\n",
            "Epoch: [5][220/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.005 (0.009)\tLoss 3.5383 (4.5046)\tPrec@1 81.250 (74.171)\tPrec@5 98.047 (96.373)\n",
            "Epoch: [5][230/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.008 (0.009)\tLoss 3.1257 (4.4606)\tPrec@1 82.422 (74.493)\tPrec@5 98.828 (96.454)\n",
            "Epoch: [5][240/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.012 (0.009)\tLoss 3.4269 (4.4136)\tPrec@1 81.250 (74.823)\tPrec@5 98.438 (96.522)\n",
            "Epoch: [5][250/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.000 (0.009)\tLoss 2.7479 (4.3683)\tPrec@1 83.594 (75.117)\tPrec@5 99.219 (96.615)\n",
            "Epoch: [5][260/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.000 (0.009)\tLoss 3.6725 (4.3280)\tPrec@1 78.516 (75.386)\tPrec@5 98.047 (96.670)\n",
            "Epoch: [5][270/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 3.4038 (4.2957)\tPrec@1 82.031 (75.608)\tPrec@5 96.484 (96.722)\n",
            "Epoch: [5][280/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.007 (0.009)\tLoss 3.3475 (4.2568)\tPrec@1 80.859 (75.844)\tPrec@5 99.219 (96.799)\n",
            "Epoch: [5][290/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.000 (0.009)\tLoss 3.1921 (4.2133)\tPrec@1 83.594 (76.133)\tPrec@5 100.000 (96.874)\n",
            "Epoch: [5][300/329], lr: 0.01000\tTime 0.077 (0.090)\tData 0.001 (0.008)\tLoss 3.8375 (4.1745)\tPrec@1 79.297 (76.385)\tPrec@5 98.047 (96.935)\n",
            "Epoch: [5][310/329], lr: 0.01000\tTime 0.084 (0.090)\tData 0.000 (0.008)\tLoss 3.1275 (4.1396)\tPrec@1 83.594 (76.610)\tPrec@5 98.438 (96.993)\n",
            "Epoch: [5][320/329], lr: 0.01000\tTime 0.084 (0.090)\tData 0.046 (0.009)\tLoss 2.8327 (4.1041)\tPrec@1 84.766 (76.840)\tPrec@5 99.219 (97.056)\n",
            "Test: [0/100]\tTime 0.273 (0.273)\tLoss 14.9523 (14.9523)\tPrec@1 29.000 (29.000)\tPrec@5 89.000 (89.000)\n",
            "Test: [10/100]\tTime 0.018 (0.054)\tLoss 11.0163 (12.9522)\tPrec@1 47.000 (41.364)\tPrec@5 87.000 (86.727)\n",
            "Test: [20/100]\tTime 0.033 (0.038)\tLoss 11.2357 (12.9909)\tPrec@1 47.000 (40.524)\tPrec@5 89.000 (87.619)\n",
            "Test: [30/100]\tTime 0.017 (0.033)\tLoss 13.2145 (12.9452)\tPrec@1 33.000 (39.935)\tPrec@5 85.000 (87.581)\n",
            "Test: [40/100]\tTime 0.018 (0.031)\tLoss 14.7149 (13.0729)\tPrec@1 36.000 (39.488)\tPrec@5 84.000 (87.268)\n",
            "Test: [50/100]\tTime 0.018 (0.030)\tLoss 13.2303 (12.9369)\tPrec@1 37.000 (39.980)\tPrec@5 83.000 (87.412)\n",
            "Test: [60/100]\tTime 0.026 (0.029)\tLoss 10.3747 (12.9050)\tPrec@1 53.000 (39.885)\tPrec@5 88.000 (87.033)\n",
            "Test: [70/100]\tTime 0.010 (0.028)\tLoss 13.0530 (12.8478)\tPrec@1 36.000 (39.859)\tPrec@5 92.000 (87.211)\n",
            "Test: [80/100]\tTime 0.026 (0.027)\tLoss 11.7208 (12.8094)\tPrec@1 44.000 (40.049)\tPrec@5 90.000 (87.457)\n",
            "Test: [90/100]\tTime 0.011 (0.027)\tLoss 13.2858 (12.9389)\tPrec@1 37.000 (39.473)\tPrec@5 89.000 (87.253)\n",
            "val Results: Prec@1 39.580 Prec@5 87.400 Loss 12.93955\n",
            "val Class Accuracy: [0.908,0.654,0.714,0.345,0.379,0.538,0.140,0.264,0.009,0.007]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [6][0/329], lr: 0.01000\tTime 0.539 (0.539)\tData 0.448 (0.448)\tLoss 5.6241 (5.6241)\tPrec@1 71.094 (71.094)\tPrec@5 94.922 (94.922)\n",
            "Epoch: [6][10/329], lr: 0.01000\tTime 0.087 (0.133)\tData 0.000 (0.048)\tLoss 5.6656 (6.5770)\tPrec@1 65.234 (62.251)\tPrec@5 92.969 (89.773)\n",
            "Epoch: [6][20/329], lr: 0.01000\tTime 0.101 (0.128)\tData 0.000 (0.032)\tLoss 5.1266 (5.9931)\tPrec@1 71.484 (65.383)\tPrec@5 95.703 (92.690)\n",
            "Epoch: [6][30/329], lr: 0.01000\tTime 0.116 (0.130)\tData 0.005 (0.034)\tLoss 4.7864 (5.6385)\tPrec@1 76.172 (67.918)\tPrec@5 93.359 (93.422)\n",
            "Epoch: [6][40/329], lr: 0.01000\tTime 0.149 (0.133)\tData 0.000 (0.034)\tLoss 4.0917 (5.3594)\tPrec@1 73.828 (69.636)\tPrec@5 97.656 (94.322)\n",
            "Epoch: [6][50/329], lr: 0.01000\tTime 0.086 (0.128)\tData 0.000 (0.031)\tLoss 3.3063 (5.1029)\tPrec@1 84.375 (71.163)\tPrec@5 97.266 (94.907)\n",
            "Epoch: [6][60/329], lr: 0.01000\tTime 0.106 (0.121)\tData 0.007 (0.027)\tLoss 3.4895 (4.8893)\tPrec@1 80.469 (72.618)\tPrec@5 98.828 (95.402)\n",
            "Epoch: [6][70/329], lr: 0.01000\tTime 0.100 (0.117)\tData 0.000 (0.025)\tLoss 3.9858 (4.7475)\tPrec@1 76.562 (73.443)\tPrec@5 97.266 (95.676)\n",
            "Epoch: [6][80/329], lr: 0.01000\tTime 0.061 (0.114)\tData 0.000 (0.022)\tLoss 3.4851 (4.6047)\tPrec@1 79.688 (74.354)\tPrec@5 98.828 (95.997)\n",
            "Epoch: [6][90/329], lr: 0.01000\tTime 0.109 (0.111)\tData 0.005 (0.020)\tLoss 3.4575 (4.4969)\tPrec@1 78.516 (74.961)\tPrec@5 97.266 (96.162)\n",
            "Epoch: [6][100/329], lr: 0.01000\tTime 0.071 (0.109)\tData 0.003 (0.019)\tLoss 3.2029 (4.4048)\tPrec@1 82.031 (75.460)\tPrec@5 98.047 (96.341)\n",
            "Epoch: [6][110/329], lr: 0.01000\tTime 0.116 (0.108)\tData 0.004 (0.018)\tLoss 3.8331 (4.3237)\tPrec@1 78.125 (75.950)\tPrec@5 97.266 (96.516)\n",
            "Epoch: [6][120/329], lr: 0.01000\tTime 0.083 (0.106)\tData 0.000 (0.017)\tLoss 3.3326 (4.2637)\tPrec@1 81.641 (76.330)\tPrec@5 98.828 (96.630)\n",
            "Epoch: [6][130/329], lr: 0.01000\tTime 0.098 (0.105)\tData 0.009 (0.016)\tLoss 3.4102 (4.1882)\tPrec@1 80.469 (76.807)\tPrec@5 97.656 (96.753)\n",
            "Epoch: [6][140/329], lr: 0.01000\tTime 0.082 (0.103)\tData 0.000 (0.015)\tLoss 2.4871 (4.1297)\tPrec@1 86.719 (77.200)\tPrec@5 98.828 (96.847)\n",
            "Epoch: [6][150/329], lr: 0.01000\tTime 0.092 (0.102)\tData 0.009 (0.015)\tLoss 3.5619 (4.0857)\tPrec@1 80.859 (77.476)\tPrec@5 98.438 (96.955)\n",
            "Epoch: [6][160/329], lr: 0.01000\tTime 0.105 (0.101)\tData 0.000 (0.014)\tLoss 3.3554 (4.0319)\tPrec@1 83.203 (77.822)\tPrec@5 98.438 (97.055)\n",
            "Epoch: [6][170/329], lr: 0.01000\tTime 0.073 (0.101)\tData 0.003 (0.014)\tLoss 2.7116 (3.9688)\tPrec@1 85.156 (78.228)\tPrec@5 98.828 (97.115)\n",
            "Epoch: [6][180/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.000 (0.013)\tLoss 2.7576 (3.9198)\tPrec@1 85.547 (78.542)\tPrec@5 98.828 (97.194)\n",
            "Epoch: [6][190/329], lr: 0.01000\tTime 0.076 (0.100)\tData 0.006 (0.013)\tLoss 2.8576 (3.8740)\tPrec@1 85.547 (78.826)\tPrec@5 99.609 (97.264)\n",
            "Epoch: [6][200/329], lr: 0.01000\tTime 0.074 (0.099)\tData 0.000 (0.013)\tLoss 3.5392 (3.8515)\tPrec@1 81.641 (78.959)\tPrec@5 99.219 (97.308)\n",
            "Epoch: [6][210/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.006 (0.012)\tLoss 2.4990 (3.8109)\tPrec@1 87.109 (79.189)\tPrec@5 99.219 (97.373)\n",
            "Epoch: [6][220/329], lr: 0.01000\tTime 0.094 (0.098)\tData 0.008 (0.012)\tLoss 2.6777 (3.7780)\tPrec@1 84.766 (79.385)\tPrec@5 98.047 (97.439)\n",
            "Epoch: [6][230/329], lr: 0.01000\tTime 0.068 (0.098)\tData 0.000 (0.012)\tLoss 3.2621 (3.7445)\tPrec@1 83.594 (79.583)\tPrec@5 97.656 (97.489)\n",
            "Epoch: [6][240/329], lr: 0.01000\tTime 0.113 (0.098)\tData 0.007 (0.012)\tLoss 2.8540 (3.7183)\tPrec@1 83.594 (79.735)\tPrec@5 96.875 (97.520)\n",
            "Epoch: [6][250/329], lr: 0.01000\tTime 0.062 (0.097)\tData 0.000 (0.011)\tLoss 2.5340 (3.6944)\tPrec@1 86.719 (79.852)\tPrec@5 98.047 (97.560)\n",
            "Epoch: [6][260/329], lr: 0.01000\tTime 0.076 (0.097)\tData 0.003 (0.011)\tLoss 2.9970 (3.6679)\tPrec@1 83.594 (80.014)\tPrec@5 98.828 (97.599)\n",
            "Epoch: [6][270/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.003 (0.011)\tLoss 2.8292 (3.6486)\tPrec@1 84.766 (80.127)\tPrec@5 98.438 (97.625)\n",
            "Epoch: [6][280/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.011)\tLoss 2.7941 (3.6250)\tPrec@1 83.594 (80.259)\tPrec@5 99.609 (97.653)\n",
            "Epoch: [6][290/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.005 (0.011)\tLoss 3.6558 (3.6040)\tPrec@1 78.906 (80.361)\tPrec@5 97.656 (97.686)\n",
            "Epoch: [6][300/329], lr: 0.01000\tTime 0.111 (0.096)\tData 0.009 (0.010)\tLoss 3.0084 (3.5819)\tPrec@1 84.375 (80.493)\tPrec@5 98.047 (97.720)\n",
            "Epoch: [6][310/329], lr: 0.01000\tTime 0.067 (0.095)\tData 0.000 (0.010)\tLoss 2.4701 (3.5647)\tPrec@1 85.938 (80.579)\tPrec@5 98.438 (97.743)\n",
            "Epoch: [6][320/329], lr: 0.01000\tTime 0.137 (0.095)\tData 0.092 (0.010)\tLoss 3.0053 (3.5432)\tPrec@1 85.547 (80.733)\tPrec@5 97.656 (97.773)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 16.5154 (16.5154)\tPrec@1 17.000 (17.000)\tPrec@5 84.000 (84.000)\n",
            "Test: [10/100]\tTime 0.028 (0.056)\tLoss 12.9491 (15.3818)\tPrec@1 34.000 (25.545)\tPrec@5 87.000 (82.455)\n",
            "Test: [20/100]\tTime 0.026 (0.037)\tLoss 13.4642 (15.5998)\tPrec@1 33.000 (24.905)\tPrec@5 78.000 (80.762)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 15.6844 (15.4568)\tPrec@1 23.000 (25.613)\tPrec@5 79.000 (81.000)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 16.2065 (15.4960)\tPrec@1 24.000 (25.561)\tPrec@5 74.000 (80.683)\n",
            "Test: [50/100]\tTime 0.017 (0.030)\tLoss 15.0447 (15.4552)\tPrec@1 29.000 (25.549)\tPrec@5 75.000 (81.078)\n",
            "Test: [60/100]\tTime 0.038 (0.030)\tLoss 13.6610 (15.4385)\tPrec@1 31.000 (25.525)\tPrec@5 77.000 (80.590)\n",
            "Test: [70/100]\tTime 0.028 (0.028)\tLoss 15.3894 (15.4021)\tPrec@1 23.000 (25.577)\tPrec@5 86.000 (80.859)\n",
            "Test: [80/100]\tTime 0.037 (0.028)\tLoss 14.5044 (15.3480)\tPrec@1 31.000 (25.938)\tPrec@5 84.000 (80.988)\n",
            "Test: [90/100]\tTime 0.034 (0.028)\tLoss 14.1371 (15.3932)\tPrec@1 34.000 (25.857)\tPrec@5 85.000 (81.066)\n",
            "val Results: Prec@1 26.000 Prec@5 81.210 Loss 15.38515\n",
            "val Class Accuracy: [0.978,0.277,0.493,0.346,0.083,0.072,0.282,0.064,0.003,0.002]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [7][0/329], lr: 0.01000\tTime 0.652 (0.652)\tData 0.573 (0.573)\tLoss 3.7959 (3.7959)\tPrec@1 76.562 (76.562)\tPrec@5 98.047 (98.047)\n",
            "Epoch: [7][10/329], lr: 0.01000\tTime 0.108 (0.143)\tData 0.000 (0.056)\tLoss 7.6282 (7.0816)\tPrec@1 50.000 (55.930)\tPrec@5 89.453 (90.518)\n",
            "Epoch: [7][20/329], lr: 0.01000\tTime 0.118 (0.121)\tData 0.000 (0.031)\tLoss 6.9928 (6.8708)\tPrec@1 57.031 (56.659)\tPrec@5 92.578 (91.388)\n",
            "Epoch: [7][30/329], lr: 0.01000\tTime 0.114 (0.112)\tData 0.007 (0.023)\tLoss 6.3402 (6.6462)\tPrec@1 56.641 (57.661)\tPrec@5 94.141 (92.578)\n",
            "Epoch: [7][40/329], lr: 0.01000\tTime 0.080 (0.108)\tData 0.005 (0.019)\tLoss 5.7532 (6.4489)\tPrec@1 62.891 (58.841)\tPrec@5 94.531 (93.131)\n",
            "Epoch: [7][50/329], lr: 0.01000\tTime 0.086 (0.104)\tData 0.000 (0.017)\tLoss 5.3445 (6.3158)\tPrec@1 69.531 (59.842)\tPrec@5 92.969 (93.390)\n",
            "Epoch: [7][60/329], lr: 0.01000\tTime 0.108 (0.102)\tData 0.007 (0.015)\tLoss 6.1559 (6.2004)\tPrec@1 59.375 (60.835)\tPrec@5 96.094 (93.744)\n",
            "Epoch: [7][70/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.000 (0.014)\tLoss 5.3753 (6.0722)\tPrec@1 67.969 (61.895)\tPrec@5 98.047 (94.047)\n",
            "Epoch: [7][80/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.000 (0.013)\tLoss 5.3120 (5.9797)\tPrec@1 68.359 (62.640)\tPrec@5 97.266 (94.280)\n",
            "Epoch: [7][90/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.005 (0.012)\tLoss 4.5170 (5.8460)\tPrec@1 73.047 (63.607)\tPrec@5 98.047 (94.544)\n",
            "Epoch: [7][100/329], lr: 0.01000\tTime 0.112 (0.099)\tData 0.005 (0.012)\tLoss 4.9896 (5.7216)\tPrec@1 69.141 (64.565)\tPrec@5 97.266 (94.787)\n",
            "Epoch: [7][110/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.000 (0.011)\tLoss 4.3227 (5.6098)\tPrec@1 73.438 (65.351)\tPrec@5 98.438 (94.975)\n",
            "Epoch: [7][120/329], lr: 0.01000\tTime 0.265 (0.103)\tData 0.161 (0.013)\tLoss 4.9313 (5.5232)\tPrec@1 67.578 (66.022)\tPrec@5 95.703 (95.093)\n",
            "Epoch: [7][130/329], lr: 0.01000\tTime 0.101 (0.104)\tData 0.000 (0.014)\tLoss 4.2783 (5.4422)\tPrec@1 75.000 (66.615)\tPrec@5 98.438 (95.301)\n",
            "Epoch: [7][140/329], lr: 0.01000\tTime 0.113 (0.104)\tData 0.005 (0.013)\tLoss 3.5957 (5.3439)\tPrec@1 81.641 (67.356)\tPrec@5 97.656 (95.429)\n",
            "Epoch: [7][150/329], lr: 0.01000\tTime 0.097 (0.103)\tData 0.002 (0.012)\tLoss 4.7048 (5.2527)\tPrec@1 74.219 (68.023)\tPrec@5 98.047 (95.584)\n",
            "Epoch: [7][160/329], lr: 0.01000\tTime 0.125 (0.102)\tData 0.004 (0.012)\tLoss 3.9198 (5.1739)\tPrec@1 82.422 (68.614)\tPrec@5 99.219 (95.727)\n",
            "Epoch: [7][170/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.000 (0.012)\tLoss 4.4443 (5.1101)\tPrec@1 73.047 (69.074)\tPrec@5 99.609 (95.856)\n",
            "Epoch: [7][180/329], lr: 0.01000\tTime 0.102 (0.101)\tData 0.005 (0.011)\tLoss 4.2744 (5.0465)\tPrec@1 75.391 (69.557)\tPrec@5 98.047 (95.964)\n",
            "Epoch: [7][190/329], lr: 0.01000\tTime 0.095 (0.100)\tData 0.000 (0.011)\tLoss 4.1953 (4.9879)\tPrec@1 75.781 (70.016)\tPrec@5 98.438 (96.086)\n",
            "Epoch: [7][200/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.011 (0.011)\tLoss 3.5690 (4.9274)\tPrec@1 78.906 (70.456)\tPrec@5 97.266 (96.171)\n",
            "Epoch: [7][210/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.014 (0.010)\tLoss 3.4134 (4.8700)\tPrec@1 83.203 (70.905)\tPrec@5 99.219 (96.262)\n",
            "Epoch: [7][220/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.000 (0.010)\tLoss 3.8101 (4.8136)\tPrec@1 77.734 (71.299)\tPrec@5 98.047 (96.327)\n",
            "Epoch: [7][230/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.010)\tLoss 4.3649 (4.7693)\tPrec@1 75.000 (71.643)\tPrec@5 96.484 (96.390)\n",
            "Epoch: [7][240/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.013 (0.010)\tLoss 2.6257 (4.7214)\tPrec@1 85.547 (71.964)\tPrec@5 98.828 (96.452)\n",
            "Epoch: [7][250/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.010 (0.010)\tLoss 3.3996 (4.6789)\tPrec@1 78.906 (72.275)\tPrec@5 97.656 (96.528)\n",
            "Epoch: [7][260/329], lr: 0.01000\tTime 0.086 (0.097)\tData 0.004 (0.010)\tLoss 3.5967 (4.6289)\tPrec@1 80.078 (72.629)\tPrec@5 98.828 (96.594)\n",
            "Epoch: [7][270/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.012 (0.010)\tLoss 3.9138 (4.5894)\tPrec@1 77.734 (72.909)\tPrec@5 98.047 (96.653)\n",
            "Epoch: [7][280/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.005 (0.010)\tLoss 3.3222 (4.5410)\tPrec@1 80.859 (73.258)\tPrec@5 98.047 (96.722)\n",
            "Epoch: [7][290/329], lr: 0.01000\tTime 0.105 (0.096)\tData 0.010 (0.009)\tLoss 3.9770 (4.5085)\tPrec@1 77.734 (73.513)\tPrec@5 98.047 (96.792)\n",
            "Epoch: [7][300/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.000 (0.009)\tLoss 3.0261 (4.4687)\tPrec@1 85.547 (73.819)\tPrec@5 97.656 (96.837)\n",
            "Epoch: [7][310/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.009)\tLoss 3.5030 (4.4368)\tPrec@1 80.078 (74.057)\tPrec@5 99.219 (96.895)\n",
            "Epoch: [7][320/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.040 (0.009)\tLoss 3.6640 (4.4086)\tPrec@1 80.859 (74.287)\tPrec@5 99.219 (96.931)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 12.2222 (12.2222)\tPrec@1 42.000 (42.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.035 (0.057)\tLoss 7.3012 (10.9811)\tPrec@1 67.000 (47.364)\tPrec@5 95.000 (92.000)\n",
            "Test: [20/100]\tTime 0.036 (0.042)\tLoss 10.4347 (11.1215)\tPrec@1 48.000 (46.238)\tPrec@5 92.000 (91.857)\n",
            "Test: [30/100]\tTime 0.019 (0.036)\tLoss 10.5730 (11.1461)\tPrec@1 50.000 (45.903)\tPrec@5 93.000 (91.516)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 10.9546 (11.2205)\tPrec@1 45.000 (45.341)\tPrec@5 95.000 (91.415)\n",
            "Test: [50/100]\tTime 0.031 (0.031)\tLoss 11.0744 (11.1185)\tPrec@1 46.000 (45.745)\tPrec@5 90.000 (91.765)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 9.7842 (11.0960)\tPrec@1 54.000 (45.820)\tPrec@5 92.000 (91.525)\n",
            "Test: [70/100]\tTime 0.011 (0.028)\tLoss 11.4300 (11.1059)\tPrec@1 46.000 (45.718)\tPrec@5 91.000 (91.563)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 10.2474 (11.0591)\tPrec@1 46.000 (45.815)\tPrec@5 91.000 (91.630)\n",
            "Test: [90/100]\tTime 0.032 (0.028)\tLoss 11.0154 (11.1222)\tPrec@1 44.000 (45.538)\tPrec@5 92.000 (91.582)\n",
            "val Results: Prec@1 45.560 Prec@5 91.550 Loss 11.11665\n",
            "val Class Accuracy: [0.956,0.496,0.253,0.408,0.600,0.575,0.661,0.554,0.038,0.015]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [8][0/329], lr: 0.01000\tTime 0.607 (0.607)\tData 0.504 (0.504)\tLoss 4.1212 (4.1212)\tPrec@1 76.562 (76.562)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [8][10/329], lr: 0.01000\tTime 0.089 (0.141)\tData 0.005 (0.051)\tLoss 5.0872 (4.7963)\tPrec@1 70.312 (73.011)\tPrec@5 94.531 (95.845)\n",
            "Epoch: [8][20/329], lr: 0.01000\tTime 0.104 (0.118)\tData 0.005 (0.029)\tLoss 4.0678 (4.4972)\tPrec@1 77.734 (75.130)\tPrec@5 97.266 (96.280)\n",
            "Epoch: [8][30/329], lr: 0.01000\tTime 0.095 (0.111)\tData 0.008 (0.021)\tLoss 3.7052 (4.2114)\tPrec@1 79.297 (76.903)\tPrec@5 98.438 (96.850)\n",
            "Epoch: [8][40/329], lr: 0.01000\tTime 0.067 (0.105)\tData 0.004 (0.018)\tLoss 3.5781 (4.0613)\tPrec@1 80.859 (77.792)\tPrec@5 97.266 (97.151)\n",
            "Epoch: [8][50/329], lr: 0.01000\tTime 0.076 (0.102)\tData 0.000 (0.016)\tLoss 3.5378 (3.9231)\tPrec@1 79.297 (78.554)\tPrec@5 97.266 (97.319)\n",
            "Epoch: [8][60/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.000 (0.014)\tLoss 3.4788 (3.8621)\tPrec@1 80.469 (78.977)\tPrec@5 98.047 (97.464)\n",
            "Epoch: [8][70/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.005 (0.013)\tLoss 3.0870 (3.7644)\tPrec@1 83.984 (79.621)\tPrec@5 97.266 (97.634)\n",
            "Epoch: [8][80/329], lr: 0.01000\tTime 0.072 (0.098)\tData 0.007 (0.013)\tLoss 2.8575 (3.7047)\tPrec@1 85.547 (79.967)\tPrec@5 98.828 (97.700)\n",
            "Epoch: [8][90/329], lr: 0.01000\tTime 0.112 (0.098)\tData 0.002 (0.012)\tLoss 2.9629 (3.6700)\tPrec@1 82.812 (80.211)\tPrec@5 99.609 (97.794)\n",
            "Epoch: [8][100/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.007 (0.012)\tLoss 4.1919 (3.6218)\tPrec@1 77.344 (80.511)\tPrec@5 96.875 (97.853)\n",
            "Epoch: [8][110/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.004 (0.011)\tLoss 3.4405 (3.5854)\tPrec@1 80.859 (80.715)\tPrec@5 98.438 (97.906)\n",
            "Epoch: [8][120/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.005 (0.011)\tLoss 3.2385 (3.5363)\tPrec@1 82.031 (80.959)\tPrec@5 98.828 (97.969)\n",
            "Epoch: [8][130/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.005 (0.011)\tLoss 2.7857 (3.4995)\tPrec@1 84.766 (81.169)\tPrec@5 98.438 (98.029)\n",
            "Epoch: [8][140/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.007 (0.010)\tLoss 3.9053 (3.4674)\tPrec@1 76.172 (81.311)\tPrec@5 98.438 (98.080)\n",
            "Epoch: [8][150/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.007 (0.010)\tLoss 3.1213 (3.4485)\tPrec@1 83.203 (81.426)\tPrec@5 98.828 (98.124)\n",
            "Epoch: [8][160/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.005 (0.010)\tLoss 3.0730 (3.4156)\tPrec@1 83.203 (81.619)\tPrec@5 98.828 (98.156)\n",
            "Epoch: [8][170/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.000 (0.010)\tLoss 2.9985 (3.3890)\tPrec@1 83.203 (81.782)\tPrec@5 98.047 (98.170)\n",
            "Epoch: [8][180/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.009 (0.010)\tLoss 2.6781 (3.3638)\tPrec@1 84.375 (81.954)\tPrec@5 99.219 (98.198)\n",
            "Epoch: [8][190/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.010 (0.009)\tLoss 2.9504 (3.3385)\tPrec@1 84.766 (82.082)\tPrec@5 97.656 (98.229)\n",
            "Epoch: [8][200/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.000 (0.009)\tLoss 2.6295 (3.3223)\tPrec@1 86.328 (82.150)\tPrec@5 100.000 (98.263)\n",
            "Epoch: [8][210/329], lr: 0.01000\tTime 0.142 (0.096)\tData 0.011 (0.009)\tLoss 3.6528 (3.3137)\tPrec@1 80.859 (82.189)\tPrec@5 98.438 (98.286)\n",
            "Epoch: [8][220/329], lr: 0.01000\tTime 0.141 (0.098)\tData 0.059 (0.010)\tLoss 3.5121 (3.3033)\tPrec@1 80.859 (82.247)\tPrec@5 98.438 (98.298)\n",
            "Epoch: [8][230/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.000 (0.011)\tLoss 2.2784 (3.2842)\tPrec@1 89.453 (82.380)\tPrec@5 99.219 (98.317)\n",
            "Epoch: [8][240/329], lr: 0.01000\tTime 0.101 (0.099)\tData 0.004 (0.011)\tLoss 2.2551 (3.2757)\tPrec@1 87.891 (82.401)\tPrec@5 99.609 (98.322)\n",
            "Epoch: [8][250/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.012 (0.011)\tLoss 2.1157 (3.2505)\tPrec@1 87.891 (82.548)\tPrec@5 98.438 (98.341)\n",
            "Epoch: [8][260/329], lr: 0.01000\tTime 0.108 (0.099)\tData 0.007 (0.011)\tLoss 2.8647 (3.2358)\tPrec@1 85.938 (82.627)\tPrec@5 97.656 (98.345)\n",
            "Epoch: [8][270/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.007 (0.011)\tLoss 2.6488 (3.2194)\tPrec@1 86.719 (82.742)\tPrec@5 99.609 (98.370)\n",
            "Epoch: [8][280/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.000 (0.011)\tLoss 2.8035 (3.2050)\tPrec@1 84.766 (82.826)\tPrec@5 99.219 (98.394)\n",
            "Epoch: [8][290/329], lr: 0.01000\tTime 0.114 (0.098)\tData 0.011 (0.011)\tLoss 3.0966 (3.1981)\tPrec@1 82.031 (82.877)\tPrec@5 100.000 (98.411)\n",
            "Epoch: [8][300/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.000 (0.011)\tLoss 2.7504 (3.1896)\tPrec@1 86.328 (82.916)\tPrec@5 99.219 (98.430)\n",
            "Epoch: [8][310/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.005 (0.011)\tLoss 2.3717 (3.1764)\tPrec@1 87.109 (82.988)\tPrec@5 99.609 (98.446)\n",
            "Epoch: [8][320/329], lr: 0.01000\tTime 0.129 (0.098)\tData 0.062 (0.011)\tLoss 2.6702 (3.1629)\tPrec@1 85.547 (83.069)\tPrec@5 100.000 (98.469)\n",
            "Test: [0/100]\tTime 0.290 (0.290)\tLoss 12.4562 (12.4562)\tPrec@1 42.000 (42.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.044 (0.058)\tLoss 7.7746 (10.1808)\tPrec@1 65.000 (53.364)\tPrec@5 94.000 (94.273)\n",
            "Test: [20/100]\tTime 0.034 (0.042)\tLoss 8.3075 (10.0150)\tPrec@1 60.000 (53.571)\tPrec@5 99.000 (94.952)\n",
            "Test: [30/100]\tTime 0.035 (0.036)\tLoss 9.2247 (10.0276)\tPrec@1 58.000 (53.452)\tPrec@5 93.000 (94.516)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 11.2208 (10.0675)\tPrec@1 48.000 (53.634)\tPrec@5 92.000 (94.195)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 9.7393 (9.9387)\tPrec@1 51.000 (54.275)\tPrec@5 92.000 (94.137)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 8.1735 (9.9175)\tPrec@1 61.000 (54.557)\tPrec@5 96.000 (93.984)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 10.0325 (9.8738)\tPrec@1 54.000 (54.789)\tPrec@5 95.000 (94.056)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 8.4911 (9.8191)\tPrec@1 66.000 (55.235)\tPrec@5 95.000 (94.185)\n",
            "Test: [90/100]\tTime 0.032 (0.028)\tLoss 9.9853 (9.9014)\tPrec@1 55.000 (54.736)\tPrec@5 97.000 (94.231)\n",
            "val Results: Prec@1 54.810 Prec@5 94.310 Loss 9.89662\n",
            "val Class Accuracy: [0.891,0.963,0.712,0.465,0.566,0.867,0.434,0.349,0.153,0.081]\n",
            "Best Prec@1: 55.160\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [9][0/329], lr: 0.01000\tTime 0.629 (0.629)\tData 0.541 (0.541)\tLoss 2.9732 (2.9732)\tPrec@1 82.031 (82.031)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [9][10/329], lr: 0.01000\tTime 0.125 (0.148)\tData 0.000 (0.056)\tLoss 2.9566 (2.9600)\tPrec@1 86.328 (84.482)\tPrec@5 98.438 (98.793)\n",
            "Epoch: [9][20/329], lr: 0.01000\tTime 0.106 (0.126)\tData 0.005 (0.032)\tLoss 2.7917 (2.9085)\tPrec@1 84.766 (84.673)\tPrec@5 97.656 (98.828)\n",
            "Epoch: [9][30/329], lr: 0.01000\tTime 0.081 (0.115)\tData 0.005 (0.024)\tLoss 2.7767 (2.8891)\tPrec@1 87.500 (84.980)\tPrec@5 98.828 (98.904)\n",
            "Epoch: [9][40/329], lr: 0.01000\tTime 0.087 (0.110)\tData 0.005 (0.020)\tLoss 2.4545 (2.8482)\tPrec@1 86.328 (85.080)\tPrec@5 99.609 (98.866)\n",
            "Epoch: [9][50/329], lr: 0.01000\tTime 0.095 (0.106)\tData 0.009 (0.017)\tLoss 2.6000 (2.8194)\tPrec@1 85.547 (85.195)\tPrec@5 98.828 (98.820)\n",
            "Epoch: [9][60/329], lr: 0.01000\tTime 0.061 (0.103)\tData 0.000 (0.015)\tLoss 2.7842 (2.8094)\tPrec@1 85.547 (85.323)\tPrec@5 98.828 (98.860)\n",
            "Epoch: [9][70/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.001 (0.014)\tLoss 2.8596 (2.8005)\tPrec@1 85.938 (85.393)\tPrec@5 98.438 (98.856)\n",
            "Epoch: [9][80/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.001 (0.013)\tLoss 2.7384 (2.7816)\tPrec@1 84.766 (85.499)\tPrec@5 99.219 (98.896)\n",
            "Epoch: [9][90/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.007 (0.013)\tLoss 2.6805 (2.7835)\tPrec@1 86.328 (85.525)\tPrec@5 99.219 (98.914)\n",
            "Epoch: [9][100/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.009 (0.012)\tLoss 2.5829 (2.7669)\tPrec@1 87.109 (85.589)\tPrec@5 99.219 (98.933)\n",
            "Epoch: [9][110/329], lr: 0.01000\tTime 0.102 (0.098)\tData 0.007 (0.012)\tLoss 2.3829 (2.7453)\tPrec@1 88.281 (85.719)\tPrec@5 98.438 (98.909)\n",
            "Epoch: [9][120/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.009 (0.011)\tLoss 2.4380 (2.7431)\tPrec@1 87.500 (85.763)\tPrec@5 100.000 (98.928)\n",
            "Epoch: [9][130/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.000 (0.011)\tLoss 2.7365 (2.7581)\tPrec@1 85.938 (85.630)\tPrec@5 98.438 (98.897)\n",
            "Epoch: [9][140/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.003 (0.011)\tLoss 2.1741 (2.7622)\tPrec@1 87.891 (85.608)\tPrec@5 98.828 (98.878)\n",
            "Epoch: [9][150/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.010)\tLoss 3.2687 (2.7528)\tPrec@1 82.812 (85.630)\tPrec@5 99.219 (98.888)\n",
            "Epoch: [9][160/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.009 (0.010)\tLoss 2.5945 (2.7404)\tPrec@1 87.891 (85.683)\tPrec@5 99.609 (98.913)\n",
            "Epoch: [9][170/329], lr: 0.01000\tTime 0.101 (0.095)\tData 0.010 (0.010)\tLoss 2.5433 (2.7447)\tPrec@1 85.938 (85.663)\tPrec@5 99.609 (98.906)\n",
            "Epoch: [9][180/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 3.4481 (2.7427)\tPrec@1 80.859 (85.702)\tPrec@5 98.828 (98.914)\n",
            "Epoch: [9][190/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.007 (0.009)\tLoss 2.2647 (2.7252)\tPrec@1 87.109 (85.800)\tPrec@5 98.828 (98.918)\n",
            "Epoch: [9][200/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.004 (0.009)\tLoss 2.4525 (2.7228)\tPrec@1 87.109 (85.821)\tPrec@5 99.609 (98.927)\n",
            "Epoch: [9][210/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.000 (0.009)\tLoss 2.8528 (2.7197)\tPrec@1 84.375 (85.854)\tPrec@5 99.609 (98.947)\n",
            "Epoch: [9][220/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.000 (0.009)\tLoss 2.9953 (2.7212)\tPrec@1 83.203 (85.846)\tPrec@5 99.609 (98.948)\n",
            "Epoch: [9][230/329], lr: 0.01000\tTime 0.071 (0.093)\tData 0.001 (0.009)\tLoss 2.7324 (2.7129)\tPrec@1 84.766 (85.895)\tPrec@5 100.000 (98.962)\n",
            "Epoch: [9][240/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.007 (0.009)\tLoss 3.0045 (2.7094)\tPrec@1 84.766 (85.925)\tPrec@5 98.438 (98.951)\n",
            "Epoch: [9][250/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.005 (0.009)\tLoss 2.9264 (2.7146)\tPrec@1 86.328 (85.895)\tPrec@5 99.219 (98.948)\n",
            "Epoch: [9][260/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.000 (0.009)\tLoss 2.7059 (2.7062)\tPrec@1 87.891 (85.936)\tPrec@5 99.219 (98.943)\n",
            "Epoch: [9][270/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.005 (0.009)\tLoss 1.8658 (2.6941)\tPrec@1 90.234 (86.008)\tPrec@5 99.219 (98.939)\n",
            "Epoch: [9][280/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.005 (0.009)\tLoss 2.7004 (2.6924)\tPrec@1 86.328 (86.001)\tPrec@5 98.438 (98.938)\n",
            "Epoch: [9][290/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.000 (0.009)\tLoss 2.9221 (2.6879)\tPrec@1 83.984 (86.018)\tPrec@5 98.438 (98.940)\n",
            "Epoch: [9][300/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.001 (0.009)\tLoss 2.7466 (2.6880)\tPrec@1 85.547 (86.010)\tPrec@5 97.656 (98.942)\n",
            "Epoch: [9][310/329], lr: 0.01000\tTime 0.110 (0.094)\tData 0.000 (0.009)\tLoss 3.4202 (2.6925)\tPrec@1 78.516 (85.969)\tPrec@5 98.438 (98.939)\n",
            "Epoch: [9][320/329], lr: 0.01000\tTime 0.230 (0.095)\tData 0.131 (0.009)\tLoss 2.3181 (2.6918)\tPrec@1 87.500 (85.969)\tPrec@5 99.609 (98.947)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 9.5894 (9.5894)\tPrec@1 58.000 (58.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.011 (0.060)\tLoss 7.5932 (8.8747)\tPrec@1 65.000 (59.182)\tPrec@5 96.000 (94.636)\n",
            "Test: [20/100]\tTime 0.040 (0.044)\tLoss 8.1889 (8.7058)\tPrec@1 66.000 (60.524)\tPrec@5 96.000 (94.905)\n",
            "Test: [30/100]\tTime 0.020 (0.037)\tLoss 8.4868 (8.7146)\tPrec@1 61.000 (60.548)\tPrec@5 95.000 (94.516)\n",
            "Test: [40/100]\tTime 0.035 (0.035)\tLoss 8.7956 (8.7607)\tPrec@1 58.000 (60.122)\tPrec@5 91.000 (94.220)\n",
            "Test: [50/100]\tTime 0.012 (0.033)\tLoss 9.5899 (8.7025)\tPrec@1 56.000 (60.490)\tPrec@5 91.000 (94.412)\n",
            "Test: [60/100]\tTime 0.043 (0.032)\tLoss 7.7285 (8.7821)\tPrec@1 63.000 (59.803)\tPrec@5 95.000 (94.393)\n",
            "Test: [70/100]\tTime 0.024 (0.031)\tLoss 8.2884 (8.8056)\tPrec@1 62.000 (59.451)\tPrec@5 96.000 (94.437)\n",
            "Test: [80/100]\tTime 0.018 (0.030)\tLoss 7.7726 (8.8143)\tPrec@1 64.000 (59.469)\tPrec@5 93.000 (94.568)\n",
            "Test: [90/100]\tTime 0.020 (0.030)\tLoss 7.7552 (8.8499)\tPrec@1 62.000 (59.396)\tPrec@5 96.000 (94.495)\n",
            "val Results: Prec@1 59.430 Prec@5 94.450 Loss 8.86287\n",
            "val Class Accuracy: [0.733,0.955,0.809,0.432,0.873,0.530,0.358,0.226,0.598,0.429]\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [10][0/329], lr: 0.01000\tTime 0.648 (0.648)\tData 0.535 (0.535)\tLoss 2.5533 (2.5533)\tPrec@1 86.719 (86.719)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [10][10/329], lr: 0.01000\tTime 0.090 (0.150)\tData 0.000 (0.056)\tLoss 3.4549 (3.6085)\tPrec@1 80.078 (79.972)\tPrec@5 99.609 (98.153)\n",
            "Epoch: [10][20/329], lr: 0.01000\tTime 0.078 (0.122)\tData 0.000 (0.031)\tLoss 3.5449 (3.5348)\tPrec@1 80.859 (80.525)\tPrec@5 99.609 (98.177)\n",
            "Epoch: [10][30/329], lr: 0.01000\tTime 0.071 (0.112)\tData 0.000 (0.024)\tLoss 3.5697 (3.4232)\tPrec@1 81.250 (81.363)\tPrec@5 99.219 (98.299)\n",
            "Epoch: [10][40/329], lr: 0.01000\tTime 0.083 (0.105)\tData 0.005 (0.020)\tLoss 3.3821 (3.3125)\tPrec@1 79.688 (82.031)\tPrec@5 100.000 (98.390)\n",
            "Epoch: [10][50/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.000 (0.017)\tLoss 2.9360 (3.1661)\tPrec@1 84.375 (82.835)\tPrec@5 98.828 (98.491)\n",
            "Epoch: [10][60/329], lr: 0.01000\tTime 0.100 (0.102)\tData 0.005 (0.015)\tLoss 2.7707 (3.0894)\tPrec@1 83.594 (83.210)\tPrec@5 98.828 (98.534)\n",
            "Epoch: [10][70/329], lr: 0.01000\tTime 0.095 (0.100)\tData 0.005 (0.014)\tLoss 2.7782 (3.0344)\tPrec@1 85.938 (83.506)\tPrec@5 98.047 (98.592)\n",
            "Epoch: [10][80/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.007 (0.013)\tLoss 2.6548 (2.9847)\tPrec@1 85.156 (83.864)\tPrec@5 98.828 (98.655)\n",
            "Epoch: [10][90/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.012)\tLoss 2.1908 (2.9489)\tPrec@1 90.234 (84.083)\tPrec@5 98.828 (98.652)\n",
            "Epoch: [10][100/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.013 (0.012)\tLoss 2.6159 (2.9123)\tPrec@1 86.328 (84.329)\tPrec@5 98.828 (98.689)\n",
            "Epoch: [10][110/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.000 (0.012)\tLoss 2.9100 (2.8942)\tPrec@1 83.984 (84.431)\tPrec@5 98.438 (98.719)\n",
            "Epoch: [10][120/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.000 (0.011)\tLoss 2.7805 (2.8615)\tPrec@1 85.938 (84.646)\tPrec@5 98.828 (98.754)\n",
            "Epoch: [10][130/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.007 (0.011)\tLoss 2.5240 (2.8447)\tPrec@1 87.891 (84.748)\tPrec@5 98.828 (98.774)\n",
            "Epoch: [10][140/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.005 (0.010)\tLoss 2.5472 (2.8279)\tPrec@1 87.109 (84.835)\tPrec@5 100.000 (98.784)\n",
            "Epoch: [10][150/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.004 (0.010)\tLoss 2.8670 (2.8082)\tPrec@1 85.547 (84.978)\tPrec@5 98.828 (98.784)\n",
            "Epoch: [10][160/329], lr: 0.01000\tTime 0.066 (0.094)\tData 0.005 (0.010)\tLoss 2.5937 (2.7859)\tPrec@1 87.500 (85.120)\tPrec@5 100.000 (98.816)\n",
            "Epoch: [10][170/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.011 (0.010)\tLoss 2.1999 (2.7654)\tPrec@1 88.672 (85.241)\tPrec@5 99.609 (98.840)\n",
            "Epoch: [10][180/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.013 (0.010)\tLoss 3.0924 (2.7666)\tPrec@1 83.594 (85.260)\tPrec@5 99.609 (98.858)\n",
            "Epoch: [10][190/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.010 (0.010)\tLoss 2.7290 (2.7592)\tPrec@1 88.281 (85.340)\tPrec@5 99.609 (98.859)\n",
            "Epoch: [10][200/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.009)\tLoss 2.6890 (2.7459)\tPrec@1 85.156 (85.424)\tPrec@5 99.219 (98.861)\n",
            "Epoch: [10][210/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.000 (0.009)\tLoss 2.2232 (2.7295)\tPrec@1 89.453 (85.562)\tPrec@5 98.828 (98.860)\n",
            "Epoch: [10][220/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.004 (0.009)\tLoss 1.9466 (2.7126)\tPrec@1 89.844 (85.656)\tPrec@5 99.219 (98.883)\n",
            "Epoch: [10][230/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.017 (0.009)\tLoss 2.3886 (2.7021)\tPrec@1 85.547 (85.687)\tPrec@5 100.000 (98.892)\n",
            "Epoch: [10][240/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.000 (0.009)\tLoss 2.7613 (2.7021)\tPrec@1 84.375 (85.690)\tPrec@5 99.609 (98.893)\n",
            "Epoch: [10][250/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.003 (0.009)\tLoss 1.9510 (2.6897)\tPrec@1 91.016 (85.790)\tPrec@5 99.219 (98.904)\n",
            "Epoch: [10][260/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.000 (0.009)\tLoss 2.4408 (2.6802)\tPrec@1 88.672 (85.861)\tPrec@5 100.000 (98.927)\n",
            "Epoch: [10][270/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.008)\tLoss 2.1283 (2.6746)\tPrec@1 88.281 (85.886)\tPrec@5 98.828 (98.926)\n",
            "Epoch: [10][280/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.005 (0.008)\tLoss 2.2098 (2.6679)\tPrec@1 89.844 (85.949)\tPrec@5 99.609 (98.935)\n",
            "Epoch: [10][290/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.007 (0.008)\tLoss 2.4496 (2.6633)\tPrec@1 88.281 (85.964)\tPrec@5 99.609 (98.941)\n",
            "Epoch: [10][300/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.011 (0.008)\tLoss 2.6540 (2.6543)\tPrec@1 87.891 (86.013)\tPrec@5 98.047 (98.938)\n",
            "Epoch: [10][310/329], lr: 0.01000\tTime 0.104 (0.092)\tData 0.007 (0.008)\tLoss 2.2956 (2.6476)\tPrec@1 87.500 (86.053)\tPrec@5 98.047 (98.934)\n",
            "Epoch: [10][320/329], lr: 0.01000\tTime 0.118 (0.092)\tData 0.075 (0.009)\tLoss 2.1046 (2.6431)\tPrec@1 89.453 (86.098)\tPrec@5 99.219 (98.928)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 8.1335 (8.1335)\tPrec@1 66.000 (66.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.054)\tLoss 5.8405 (7.9770)\tPrec@1 74.000 (64.727)\tPrec@5 97.000 (96.273)\n",
            "Test: [20/100]\tTime 0.023 (0.037)\tLoss 7.4236 (7.8324)\tPrec@1 67.000 (65.619)\tPrec@5 97.000 (96.333)\n",
            "Test: [30/100]\tTime 0.028 (0.035)\tLoss 7.9999 (7.8825)\tPrec@1 66.000 (65.419)\tPrec@5 96.000 (96.032)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 8.3799 (7.9382)\tPrec@1 59.000 (65.244)\tPrec@5 94.000 (95.927)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 7.8169 (7.8601)\tPrec@1 69.000 (65.667)\tPrec@5 94.000 (95.902)\n",
            "Test: [60/100]\tTime 0.013 (0.030)\tLoss 6.9761 (7.8854)\tPrec@1 67.000 (65.426)\tPrec@5 96.000 (95.820)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 7.4841 (7.8732)\tPrec@1 67.000 (65.352)\tPrec@5 97.000 (95.944)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 7.1917 (7.8243)\tPrec@1 73.000 (65.667)\tPrec@5 96.000 (96.099)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 7.8718 (7.8900)\tPrec@1 65.000 (65.352)\tPrec@5 99.000 (96.099)\n",
            "val Results: Prec@1 65.360 Prec@5 96.160 Loss 7.89132\n",
            "val Class Accuracy: [0.919,0.977,0.807,0.736,0.733,0.390,0.744,0.450,0.317,0.463]\n",
            "Best Prec@1: 65.360\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [11][0/329], lr: 0.01000\tTime 0.642 (0.642)\tData 0.552 (0.552)\tLoss 2.1958 (2.1958)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [11][10/329], lr: 0.01000\tTime 0.160 (0.150)\tData 0.010 (0.059)\tLoss 2.2436 (2.8208)\tPrec@1 86.719 (85.298)\tPrec@5 99.219 (98.615)\n",
            "Epoch: [11][20/329], lr: 0.01000\tTime 0.114 (0.135)\tData 0.048 (0.036)\tLoss 2.3591 (2.7776)\tPrec@1 88.281 (85.528)\tPrec@5 99.219 (98.549)\n",
            "Epoch: [11][30/329], lr: 0.01000\tTime 0.110 (0.135)\tData 0.005 (0.031)\tLoss 2.3572 (2.6655)\tPrec@1 85.938 (86.139)\tPrec@5 100.000 (98.753)\n",
            "Epoch: [11][40/329], lr: 0.01000\tTime 0.170 (0.137)\tData 0.118 (0.033)\tLoss 2.8065 (2.6151)\tPrec@1 85.547 (86.300)\tPrec@5 99.609 (98.876)\n",
            "Epoch: [11][50/329], lr: 0.01000\tTime 0.121 (0.130)\tData 0.000 (0.028)\tLoss 2.5224 (2.5782)\tPrec@1 86.719 (86.512)\tPrec@5 100.000 (98.874)\n",
            "Epoch: [11][60/329], lr: 0.01000\tTime 0.132 (0.125)\tData 0.072 (0.026)\tLoss 2.0582 (2.5336)\tPrec@1 89.844 (86.770)\tPrec@5 98.828 (98.956)\n",
            "Epoch: [11][70/329], lr: 0.01000\tTime 0.096 (0.122)\tData 0.005 (0.023)\tLoss 2.3519 (2.5184)\tPrec@1 87.109 (86.807)\tPrec@5 99.609 (98.960)\n",
            "Epoch: [11][80/329], lr: 0.01000\tTime 0.084 (0.119)\tData 0.001 (0.021)\tLoss 1.6432 (2.4904)\tPrec@1 92.578 (87.032)\tPrec@5 99.609 (98.963)\n",
            "Epoch: [11][90/329], lr: 0.01000\tTime 0.106 (0.117)\tData 0.007 (0.020)\tLoss 2.0227 (2.4650)\tPrec@1 89.453 (87.169)\tPrec@5 99.609 (98.974)\n",
            "Epoch: [11][100/329], lr: 0.01000\tTime 0.066 (0.115)\tData 0.004 (0.018)\tLoss 1.9684 (2.4402)\tPrec@1 91.016 (87.310)\tPrec@5 98.828 (98.991)\n",
            "Epoch: [11][110/329], lr: 0.01000\tTime 0.087 (0.113)\tData 0.005 (0.017)\tLoss 2.4518 (2.4414)\tPrec@1 86.328 (87.292)\tPrec@5 98.828 (99.018)\n",
            "Epoch: [11][120/329], lr: 0.01000\tTime 0.088 (0.111)\tData 0.000 (0.016)\tLoss 2.6158 (2.4318)\tPrec@1 85.156 (87.342)\tPrec@5 99.219 (99.028)\n",
            "Epoch: [11][130/329], lr: 0.01000\tTime 0.089 (0.110)\tData 0.005 (0.016)\tLoss 2.8425 (2.4516)\tPrec@1 85.547 (87.229)\tPrec@5 99.609 (99.001)\n",
            "Epoch: [11][140/329], lr: 0.01000\tTime 0.089 (0.109)\tData 0.014 (0.015)\tLoss 1.9629 (2.4420)\tPrec@1 90.234 (87.237)\tPrec@5 100.000 (99.025)\n",
            "Epoch: [11][150/329], lr: 0.01000\tTime 0.091 (0.107)\tData 0.007 (0.015)\tLoss 2.3514 (2.4308)\tPrec@1 89.062 (87.306)\tPrec@5 99.219 (99.040)\n",
            "Epoch: [11][160/329], lr: 0.01000\tTime 0.084 (0.106)\tData 0.000 (0.014)\tLoss 2.4698 (2.4361)\tPrec@1 86.719 (87.253)\tPrec@5 98.828 (99.051)\n",
            "Epoch: [11][170/329], lr: 0.01000\tTime 0.116 (0.106)\tData 0.005 (0.014)\tLoss 2.3313 (2.4407)\tPrec@1 87.109 (87.235)\tPrec@5 100.000 (99.050)\n",
            "Epoch: [11][180/329], lr: 0.01000\tTime 0.099 (0.105)\tData 0.005 (0.013)\tLoss 2.2719 (2.4343)\tPrec@1 90.625 (87.286)\tPrec@5 99.609 (99.057)\n",
            "Epoch: [11][190/329], lr: 0.01000\tTime 0.063 (0.104)\tData 0.000 (0.013)\tLoss 1.7509 (2.4372)\tPrec@1 91.406 (87.267)\tPrec@5 100.000 (99.049)\n",
            "Epoch: [11][200/329], lr: 0.01000\tTime 0.106 (0.104)\tData 0.007 (0.013)\tLoss 1.8256 (2.4347)\tPrec@1 90.234 (87.261)\tPrec@5 99.609 (99.054)\n",
            "Epoch: [11][210/329], lr: 0.01000\tTime 0.106 (0.103)\tData 0.016 (0.012)\tLoss 2.0569 (2.4333)\tPrec@1 88.672 (87.235)\tPrec@5 99.609 (99.050)\n",
            "Epoch: [11][220/329], lr: 0.01000\tTime 0.118 (0.102)\tData 0.007 (0.012)\tLoss 2.2488 (2.4299)\tPrec@1 89.453 (87.261)\tPrec@5 98.828 (99.058)\n",
            "Epoch: [11][230/329], lr: 0.01000\tTime 0.085 (0.102)\tData 0.000 (0.012)\tLoss 2.2384 (2.4241)\tPrec@1 88.281 (87.295)\tPrec@5 98.828 (99.072)\n",
            "Epoch: [11][240/329], lr: 0.01000\tTime 0.075 (0.101)\tData 0.000 (0.012)\tLoss 2.8276 (2.4242)\tPrec@1 82.812 (87.297)\tPrec@5 99.609 (99.079)\n",
            "Epoch: [11][250/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.010 (0.012)\tLoss 2.7701 (2.4234)\tPrec@1 87.109 (87.310)\tPrec@5 97.656 (99.072)\n",
            "Epoch: [11][260/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.007 (0.012)\tLoss 1.6916 (2.4186)\tPrec@1 90.625 (87.344)\tPrec@5 99.609 (99.077)\n",
            "Epoch: [11][270/329], lr: 0.01000\tTime 0.111 (0.100)\tData 0.000 (0.011)\tLoss 1.9767 (2.4132)\tPrec@1 89.844 (87.362)\tPrec@5 99.609 (99.076)\n",
            "Epoch: [11][280/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.010 (0.011)\tLoss 2.5229 (2.4070)\tPrec@1 86.719 (87.401)\tPrec@5 98.828 (99.087)\n",
            "Epoch: [11][290/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.005 (0.011)\tLoss 2.3010 (2.4024)\tPrec@1 88.672 (87.418)\tPrec@5 97.266 (99.079)\n",
            "Epoch: [11][300/329], lr: 0.01000\tTime 0.104 (0.099)\tData 0.005 (0.011)\tLoss 2.2918 (2.4031)\tPrec@1 88.281 (87.421)\tPrec@5 98.828 (99.075)\n",
            "Epoch: [11][310/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.007 (0.011)\tLoss 2.7967 (2.4010)\tPrec@1 85.156 (87.436)\tPrec@5 98.828 (99.073)\n",
            "Epoch: [11][320/329], lr: 0.01000\tTime 0.144 (0.098)\tData 0.073 (0.011)\tLoss 3.1930 (2.4071)\tPrec@1 82.031 (87.403)\tPrec@5 98.047 (99.068)\n",
            "Test: [0/100]\tTime 0.350 (0.350)\tLoss 11.0000 (11.0000)\tPrec@1 52.000 (52.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.028 (0.053)\tLoss 7.1891 (9.2505)\tPrec@1 67.000 (58.000)\tPrec@5 94.000 (90.727)\n",
            "Test: [20/100]\tTime 0.027 (0.039)\tLoss 8.7114 (9.2439)\tPrec@1 59.000 (57.905)\tPrec@5 94.000 (90.857)\n",
            "Test: [30/100]\tTime 0.017 (0.033)\tLoss 8.1712 (9.1297)\tPrec@1 60.000 (58.548)\tPrec@5 92.000 (90.387)\n",
            "Test: [40/100]\tTime 0.021 (0.032)\tLoss 8.4366 (9.1160)\tPrec@1 62.000 (58.634)\tPrec@5 93.000 (90.341)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 9.4306 (9.1230)\tPrec@1 60.000 (58.569)\tPrec@5 90.000 (90.216)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 7.5539 (9.1547)\tPrec@1 64.000 (58.426)\tPrec@5 94.000 (90.279)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 8.9056 (9.1654)\tPrec@1 62.000 (58.535)\tPrec@5 93.000 (90.282)\n",
            "Test: [80/100]\tTime 0.028 (0.028)\tLoss 8.1661 (9.1272)\tPrec@1 64.000 (58.679)\tPrec@5 89.000 (90.321)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 8.4145 (9.2116)\tPrec@1 65.000 (58.352)\tPrec@5 91.000 (90.187)\n",
            "val Results: Prec@1 58.370 Prec@5 90.090 Loss 9.21541\n",
            "val Class Accuracy: [0.838,0.915,0.906,0.291,0.741,0.666,0.522,0.526,0.381,0.051]\n",
            "Best Prec@1: 65.360\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [12][0/329], lr: 0.01000\tTime 0.640 (0.640)\tData 0.546 (0.546)\tLoss 2.4804 (2.4804)\tPrec@1 87.109 (87.109)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [12][10/329], lr: 0.01000\tTime 0.107 (0.142)\tData 0.000 (0.054)\tLoss 2.8333 (2.6947)\tPrec@1 83.203 (85.973)\tPrec@5 98.438 (98.544)\n",
            "Epoch: [12][20/329], lr: 0.01000\tTime 0.085 (0.117)\tData 0.005 (0.030)\tLoss 1.9703 (2.6609)\tPrec@1 90.234 (86.031)\tPrec@5 98.828 (98.735)\n",
            "Epoch: [12][30/329], lr: 0.01000\tTime 0.072 (0.107)\tData 0.003 (0.022)\tLoss 2.5072 (2.6206)\tPrec@1 86.328 (86.139)\tPrec@5 100.000 (98.929)\n",
            "Epoch: [12][40/329], lr: 0.01000\tTime 0.114 (0.104)\tData 0.005 (0.018)\tLoss 1.9022 (2.5712)\tPrec@1 90.625 (86.509)\tPrec@5 98.438 (98.923)\n",
            "Epoch: [12][50/329], lr: 0.01000\tTime 0.077 (0.101)\tData 0.005 (0.016)\tLoss 2.1178 (2.5281)\tPrec@1 90.234 (86.849)\tPrec@5 99.609 (98.958)\n",
            "Epoch: [12][60/329], lr: 0.01000\tTime 0.113 (0.099)\tData 0.000 (0.014)\tLoss 2.6569 (2.4756)\tPrec@1 84.766 (87.116)\tPrec@5 99.219 (99.001)\n",
            "Epoch: [12][70/329], lr: 0.01000\tTime 0.100 (0.098)\tData 0.000 (0.014)\tLoss 1.8583 (2.4406)\tPrec@1 88.281 (87.263)\tPrec@5 98.438 (98.988)\n",
            "Epoch: [12][80/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.000 (0.013)\tLoss 2.7428 (2.4426)\tPrec@1 85.547 (87.249)\tPrec@5 99.609 (99.026)\n",
            "Epoch: [12][90/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.001 (0.012)\tLoss 2.0748 (2.4317)\tPrec@1 89.062 (87.260)\tPrec@5 99.609 (99.043)\n",
            "Epoch: [12][100/329], lr: 0.01000\tTime 0.105 (0.100)\tData 0.004 (0.012)\tLoss 2.3708 (2.4266)\tPrec@1 86.719 (87.268)\tPrec@5 98.438 (99.060)\n",
            "Epoch: [12][110/329], lr: 0.01000\tTime 0.108 (0.102)\tData 0.054 (0.013)\tLoss 2.3786 (2.4138)\tPrec@1 88.281 (87.345)\tPrec@5 98.047 (99.067)\n",
            "Epoch: [12][120/329], lr: 0.01000\tTime 0.117 (0.104)\tData 0.059 (0.015)\tLoss 2.6532 (2.3952)\tPrec@1 85.156 (87.471)\tPrec@5 98.828 (99.080)\n",
            "Epoch: [12][130/329], lr: 0.01000\tTime 0.106 (0.103)\tData 0.000 (0.014)\tLoss 2.3781 (2.3964)\tPrec@1 87.500 (87.443)\tPrec@5 99.219 (99.061)\n",
            "Epoch: [12][140/329], lr: 0.01000\tTime 0.079 (0.103)\tData 0.003 (0.013)\tLoss 2.3479 (2.3845)\tPrec@1 86.719 (87.500)\tPrec@5 99.609 (99.080)\n",
            "Epoch: [12][150/329], lr: 0.01000\tTime 0.099 (0.102)\tData 0.005 (0.013)\tLoss 2.1450 (2.3775)\tPrec@1 89.062 (87.567)\tPrec@5 98.828 (99.095)\n",
            "Epoch: [12][160/329], lr: 0.01000\tTime 0.060 (0.102)\tData 0.005 (0.013)\tLoss 2.4467 (2.3807)\tPrec@1 87.500 (87.563)\tPrec@5 98.438 (99.093)\n",
            "Epoch: [12][170/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.004 (0.012)\tLoss 2.8129 (2.3843)\tPrec@1 85.547 (87.548)\tPrec@5 99.219 (99.105)\n",
            "Epoch: [12][180/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.005 (0.012)\tLoss 2.3939 (2.3800)\tPrec@1 87.500 (87.584)\tPrec@5 99.219 (99.104)\n",
            "Epoch: [12][190/329], lr: 0.01000\tTime 0.103 (0.100)\tData 0.002 (0.012)\tLoss 2.5524 (2.3758)\tPrec@1 87.500 (87.612)\tPrec@5 99.609 (99.110)\n",
            "Epoch: [12][200/329], lr: 0.01000\tTime 0.101 (0.099)\tData 0.000 (0.011)\tLoss 2.1550 (2.3692)\tPrec@1 88.672 (87.644)\tPrec@5 98.828 (99.114)\n",
            "Epoch: [12][210/329], lr: 0.01000\tTime 0.070 (0.099)\tData 0.003 (0.011)\tLoss 2.6343 (2.3664)\tPrec@1 85.156 (87.652)\tPrec@5 99.219 (99.110)\n",
            "Epoch: [12][220/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.004 (0.011)\tLoss 2.1248 (2.3632)\tPrec@1 88.281 (87.687)\tPrec@5 99.219 (99.114)\n",
            "Epoch: [12][230/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.009 (0.011)\tLoss 2.3194 (2.3612)\tPrec@1 87.109 (87.700)\tPrec@5 99.609 (99.129)\n",
            "Epoch: [12][240/329], lr: 0.01000\tTime 0.074 (0.098)\tData 0.000 (0.011)\tLoss 2.6247 (2.3666)\tPrec@1 87.109 (87.667)\tPrec@5 98.438 (99.125)\n",
            "Epoch: [12][250/329], lr: 0.01000\tTime 0.069 (0.097)\tData 0.012 (0.011)\tLoss 2.6341 (2.3643)\tPrec@1 85.547 (87.677)\tPrec@5 98.828 (99.119)\n",
            "Epoch: [12][260/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.000 (0.011)\tLoss 2.1180 (2.3555)\tPrec@1 91.406 (87.726)\tPrec@5 99.219 (99.127)\n",
            "Epoch: [12][270/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.007 (0.011)\tLoss 2.5343 (2.3524)\tPrec@1 87.109 (87.741)\tPrec@5 99.219 (99.141)\n",
            "Epoch: [12][280/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.000 (0.010)\tLoss 2.8307 (2.3548)\tPrec@1 83.594 (87.710)\tPrec@5 98.047 (99.138)\n",
            "Epoch: [12][290/329], lr: 0.01000\tTime 0.102 (0.096)\tData 0.000 (0.010)\tLoss 1.4733 (2.3525)\tPrec@1 92.578 (87.709)\tPrec@5 98.828 (99.133)\n",
            "Epoch: [12][300/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.007 (0.010)\tLoss 2.5491 (2.3537)\tPrec@1 86.719 (87.695)\tPrec@5 99.219 (99.133)\n",
            "Epoch: [12][310/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.012 (0.010)\tLoss 2.5730 (2.3533)\tPrec@1 84.766 (87.692)\tPrec@5 100.000 (99.141)\n",
            "Epoch: [12][320/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.077 (0.010)\tLoss 2.2383 (2.3566)\tPrec@1 88.672 (87.674)\tPrec@5 98.828 (99.149)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 11.6784 (11.6784)\tPrec@1 51.000 (51.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.030 (0.057)\tLoss 8.8075 (11.1533)\tPrec@1 61.000 (48.727)\tPrec@5 91.000 (92.727)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 9.2192 (10.6860)\tPrec@1 55.000 (51.143)\tPrec@5 94.000 (93.190)\n",
            "Test: [30/100]\tTime 0.028 (0.035)\tLoss 10.5219 (10.8466)\tPrec@1 51.000 (49.871)\tPrec@5 92.000 (93.032)\n",
            "Test: [40/100]\tTime 0.021 (0.032)\tLoss 10.5339 (10.8086)\tPrec@1 53.000 (50.195)\tPrec@5 92.000 (93.024)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 10.7258 (10.7568)\tPrec@1 49.000 (50.314)\tPrec@5 92.000 (93.020)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 10.2842 (10.8140)\tPrec@1 50.000 (50.066)\tPrec@5 92.000 (92.951)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 8.9338 (10.7856)\tPrec@1 61.000 (50.225)\tPrec@5 95.000 (92.958)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 10.1454 (10.7479)\tPrec@1 57.000 (50.444)\tPrec@5 93.000 (93.025)\n",
            "Test: [90/100]\tTime 0.011 (0.028)\tLoss 12.0835 (10.7936)\tPrec@1 43.000 (50.165)\tPrec@5 91.000 (92.923)\n",
            "val Results: Prec@1 50.400 Prec@5 92.920 Loss 10.76707\n",
            "val Class Accuracy: [0.472,0.794,0.601,0.958,0.513,0.346,0.358,0.368,0.408,0.222]\n",
            "Best Prec@1: 65.360\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [13][0/329], lr: 0.01000\tTime 0.667 (0.667)\tData 0.552 (0.552)\tLoss 2.4196 (2.4196)\tPrec@1 87.891 (87.891)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [13][10/329], lr: 0.01000\tTime 0.092 (0.146)\tData 0.000 (0.056)\tLoss 3.2827 (3.6543)\tPrec@1 83.594 (79.972)\tPrec@5 98.828 (98.153)\n",
            "Epoch: [13][20/329], lr: 0.01000\tTime 0.106 (0.120)\tData 0.004 (0.032)\tLoss 3.4511 (3.4173)\tPrec@1 81.250 (81.269)\tPrec@5 98.047 (98.326)\n",
            "Epoch: [13][30/329], lr: 0.01000\tTime 0.090 (0.111)\tData 0.000 (0.023)\tLoss 3.0585 (3.2856)\tPrec@1 84.375 (82.044)\tPrec@5 99.219 (98.526)\n",
            "Epoch: [13][40/329], lr: 0.01000\tTime 0.077 (0.106)\tData 0.000 (0.019)\tLoss 2.8461 (3.1331)\tPrec@1 85.156 (82.984)\tPrec@5 99.219 (98.685)\n",
            "Epoch: [13][50/329], lr: 0.01000\tTime 0.066 (0.103)\tData 0.000 (0.017)\tLoss 2.6545 (3.0234)\tPrec@1 85.938 (83.678)\tPrec@5 98.438 (98.759)\n",
            "Epoch: [13][60/329], lr: 0.01000\tTime 0.082 (0.101)\tData 0.004 (0.015)\tLoss 1.9940 (2.9011)\tPrec@1 89.062 (84.426)\tPrec@5 99.219 (98.860)\n",
            "Epoch: [13][70/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.008 (0.015)\tLoss 1.8094 (2.8203)\tPrec@1 89.062 (84.898)\tPrec@5 98.828 (98.872)\n",
            "Epoch: [13][80/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.000 (0.014)\tLoss 2.9183 (2.7681)\tPrec@1 83.594 (85.204)\tPrec@5 99.219 (98.910)\n",
            "Epoch: [13][90/329], lr: 0.01000\tTime 0.112 (0.097)\tData 0.000 (0.013)\tLoss 2.9901 (2.7148)\tPrec@1 83.984 (85.538)\tPrec@5 98.047 (98.935)\n",
            "Epoch: [13][100/329], lr: 0.01000\tTime 0.065 (0.097)\tData 0.001 (0.012)\tLoss 2.2980 (2.6763)\tPrec@1 88.672 (85.787)\tPrec@5 99.609 (98.975)\n",
            "Epoch: [13][110/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.005 (0.012)\tLoss 2.3351 (2.6466)\tPrec@1 87.109 (85.955)\tPrec@5 98.438 (98.965)\n",
            "Epoch: [13][120/329], lr: 0.01000\tTime 0.070 (0.095)\tData 0.007 (0.011)\tLoss 2.5659 (2.6397)\tPrec@1 86.328 (86.015)\tPrec@5 98.828 (98.948)\n",
            "Epoch: [13][130/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.011)\tLoss 1.4843 (2.5947)\tPrec@1 93.359 (86.289)\tPrec@5 98.828 (98.974)\n",
            "Epoch: [13][140/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.005 (0.011)\tLoss 2.9112 (2.5781)\tPrec@1 85.547 (86.406)\tPrec@5 98.438 (98.986)\n",
            "Epoch: [13][150/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.000 (0.011)\tLoss 1.8778 (2.5416)\tPrec@1 91.016 (86.620)\tPrec@5 99.219 (99.004)\n",
            "Epoch: [13][160/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.011)\tLoss 2.6321 (2.5165)\tPrec@1 87.500 (86.765)\tPrec@5 98.438 (99.017)\n",
            "Epoch: [13][170/329], lr: 0.01000\tTime 0.126 (0.094)\tData 0.000 (0.010)\tLoss 2.0927 (2.5093)\tPrec@1 88.672 (86.840)\tPrec@5 99.609 (99.038)\n",
            "Epoch: [13][180/329], lr: 0.01000\tTime 0.125 (0.095)\tData 0.006 (0.010)\tLoss 2.1077 (2.4951)\tPrec@1 89.453 (86.922)\tPrec@5 98.828 (99.042)\n",
            "Epoch: [13][190/329], lr: 0.01000\tTime 0.178 (0.097)\tData 0.073 (0.010)\tLoss 2.5238 (2.4890)\tPrec@1 86.328 (86.958)\tPrec@5 98.828 (99.029)\n",
            "Epoch: [13][200/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.029 (0.011)\tLoss 1.9819 (2.4725)\tPrec@1 89.844 (87.028)\tPrec@5 99.609 (99.040)\n",
            "Epoch: [13][210/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.005 (0.011)\tLoss 2.5878 (2.4637)\tPrec@1 85.156 (87.074)\tPrec@5 98.047 (99.037)\n",
            "Epoch: [13][220/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.008 (0.011)\tLoss 2.3641 (2.4584)\tPrec@1 87.500 (87.106)\tPrec@5 97.656 (99.046)\n",
            "Epoch: [13][230/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.000 (0.011)\tLoss 2.3973 (2.4521)\tPrec@1 87.891 (87.135)\tPrec@5 98.438 (99.050)\n",
            "Epoch: [13][240/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.005 (0.011)\tLoss 2.1819 (2.4417)\tPrec@1 88.281 (87.173)\tPrec@5 100.000 (99.052)\n",
            "Epoch: [13][250/329], lr: 0.01000\tTime 0.089 (0.098)\tData 0.007 (0.010)\tLoss 2.2568 (2.4376)\tPrec@1 87.891 (87.173)\tPrec@5 99.609 (99.057)\n",
            "Epoch: [13][260/329], lr: 0.01000\tTime 0.071 (0.098)\tData 0.000 (0.010)\tLoss 1.8044 (2.4309)\tPrec@1 91.016 (87.226)\tPrec@5 99.609 (99.060)\n",
            "Epoch: [13][270/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.007 (0.010)\tLoss 2.3608 (2.4156)\tPrec@1 86.328 (87.297)\tPrec@5 99.609 (99.072)\n",
            "Epoch: [13][280/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.005 (0.010)\tLoss 1.7649 (2.4051)\tPrec@1 90.625 (87.358)\tPrec@5 99.609 (99.081)\n",
            "Epoch: [13][290/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.006 (0.010)\tLoss 2.0827 (2.4003)\tPrec@1 89.062 (87.383)\tPrec@5 100.000 (99.095)\n",
            "Epoch: [13][300/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.002 (0.010)\tLoss 2.0203 (2.3875)\tPrec@1 89.062 (87.452)\tPrec@5 99.609 (99.103)\n",
            "Epoch: [13][310/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.000 (0.010)\tLoss 2.4364 (2.3936)\tPrec@1 86.328 (87.411)\tPrec@5 98.828 (99.092)\n",
            "Epoch: [13][320/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.053 (0.010)\tLoss 1.7452 (2.3932)\tPrec@1 91.016 (87.427)\tPrec@5 100.000 (99.091)\n",
            "Test: [0/100]\tTime 0.294 (0.294)\tLoss 7.0693 (7.0693)\tPrec@1 69.000 (69.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.011 (0.054)\tLoss 6.1902 (7.3952)\tPrec@1 72.000 (66.727)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/100]\tTime 0.011 (0.040)\tLoss 6.3714 (7.3604)\tPrec@1 69.000 (67.143)\tPrec@5 99.000 (97.429)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 7.3461 (7.3773)\tPrec@1 67.000 (66.839)\tPrec@5 98.000 (97.290)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 7.6346 (7.4105)\tPrec@1 68.000 (66.537)\tPrec@5 97.000 (97.122)\n",
            "Test: [50/100]\tTime 0.016 (0.031)\tLoss 7.0770 (7.3217)\tPrec@1 68.000 (66.804)\tPrec@5 96.000 (97.118)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 7.6598 (7.4427)\tPrec@1 65.000 (66.033)\tPrec@5 97.000 (97.082)\n",
            "Test: [70/100]\tTime 0.031 (0.029)\tLoss 7.2115 (7.4001)\tPrec@1 66.000 (66.183)\tPrec@5 96.000 (97.085)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 7.1459 (7.3610)\tPrec@1 70.000 (66.284)\tPrec@5 96.000 (97.086)\n",
            "Test: [90/100]\tTime 0.037 (0.028)\tLoss 7.8145 (7.4408)\tPrec@1 60.000 (65.769)\tPrec@5 98.000 (97.066)\n",
            "val Results: Prec@1 66.090 Prec@5 97.100 Loss 7.39127\n",
            "val Class Accuracy: [0.901,0.940,0.755,0.872,0.363,0.490,0.472,0.520,0.567,0.729]\n",
            "Best Prec@1: 66.090\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [14][0/329], lr: 0.01000\tTime 0.641 (0.641)\tData 0.554 (0.554)\tLoss 2.7833 (2.7833)\tPrec@1 85.547 (85.547)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [14][10/329], lr: 0.01000\tTime 0.101 (0.146)\tData 0.000 (0.056)\tLoss 2.5366 (2.6879)\tPrec@1 87.109 (86.293)\tPrec@5 99.609 (98.864)\n",
            "Epoch: [14][20/329], lr: 0.01000\tTime 0.073 (0.120)\tData 0.000 (0.031)\tLoss 1.7211 (2.5018)\tPrec@1 91.797 (87.147)\tPrec@5 98.828 (98.977)\n",
            "Epoch: [14][30/329], lr: 0.01000\tTime 0.083 (0.111)\tData 0.000 (0.023)\tLoss 1.9133 (2.3797)\tPrec@1 88.672 (87.601)\tPrec@5 99.609 (99.181)\n",
            "Epoch: [14][40/329], lr: 0.01000\tTime 0.104 (0.107)\tData 0.002 (0.019)\tLoss 2.0530 (2.3032)\tPrec@1 89.062 (87.995)\tPrec@5 99.219 (99.190)\n",
            "Epoch: [14][50/329], lr: 0.01000\tTime 0.097 (0.103)\tData 0.006 (0.017)\tLoss 1.7770 (2.2416)\tPrec@1 91.016 (88.358)\tPrec@5 100.000 (99.211)\n",
            "Epoch: [14][60/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.005 (0.015)\tLoss 2.6945 (2.2516)\tPrec@1 85.547 (88.211)\tPrec@5 99.219 (99.270)\n",
            "Epoch: [14][70/329], lr: 0.01000\tTime 0.089 (0.099)\tData 0.006 (0.014)\tLoss 1.7338 (2.2411)\tPrec@1 91.016 (88.259)\tPrec@5 100.000 (99.301)\n",
            "Epoch: [14][80/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.002 (0.013)\tLoss 2.3121 (2.2321)\tPrec@1 87.891 (88.281)\tPrec@5 99.219 (99.330)\n",
            "Epoch: [14][90/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.006 (0.012)\tLoss 1.7234 (2.2109)\tPrec@1 91.797 (88.444)\tPrec@5 98.828 (99.322)\n",
            "Epoch: [14][100/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.005 (0.011)\tLoss 2.4649 (2.2137)\tPrec@1 87.500 (88.448)\tPrec@5 100.000 (99.285)\n",
            "Epoch: [14][110/329], lr: 0.01000\tTime 0.063 (0.096)\tData 0.004 (0.011)\tLoss 2.0456 (2.2174)\tPrec@1 90.625 (88.433)\tPrec@5 99.609 (99.303)\n",
            "Epoch: [14][120/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.007 (0.011)\tLoss 2.0378 (2.2111)\tPrec@1 88.281 (88.478)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [14][130/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.004 (0.011)\tLoss 2.5477 (2.2186)\tPrec@1 88.281 (88.478)\tPrec@5 98.828 (99.266)\n",
            "Epoch: [14][140/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.000 (0.010)\tLoss 1.9706 (2.2100)\tPrec@1 89.844 (88.514)\tPrec@5 98.828 (99.280)\n",
            "Epoch: [14][150/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.000 (0.010)\tLoss 2.4063 (2.2333)\tPrec@1 89.062 (88.421)\tPrec@5 99.219 (99.286)\n",
            "Epoch: [14][160/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.007 (0.010)\tLoss 2.1663 (2.2444)\tPrec@1 87.891 (88.337)\tPrec@5 99.219 (99.267)\n",
            "Epoch: [14][170/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 2.2606 (2.2412)\tPrec@1 87.891 (88.352)\tPrec@5 99.219 (99.264)\n",
            "Epoch: [14][180/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.007 (0.009)\tLoss 2.6186 (2.2432)\tPrec@1 86.719 (88.329)\tPrec@5 99.219 (99.262)\n",
            "Epoch: [14][190/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.006 (0.009)\tLoss 2.1533 (2.2413)\tPrec@1 88.281 (88.328)\tPrec@5 99.609 (99.274)\n",
            "Epoch: [14][200/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.009)\tLoss 2.7032 (2.2358)\tPrec@1 86.328 (88.355)\tPrec@5 98.828 (99.279)\n",
            "Epoch: [14][210/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.004 (0.009)\tLoss 2.2303 (2.2328)\tPrec@1 86.328 (88.355)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [14][220/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.000 (0.009)\tLoss 2.3217 (2.2404)\tPrec@1 87.891 (88.313)\tPrec@5 98.438 (99.268)\n",
            "Epoch: [14][230/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.001 (0.009)\tLoss 2.2151 (2.2435)\tPrec@1 88.672 (88.298)\tPrec@5 98.047 (99.258)\n",
            "Epoch: [14][240/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.005 (0.009)\tLoss 2.0004 (2.2395)\tPrec@1 89.062 (88.307)\tPrec@5 100.000 (99.269)\n",
            "Epoch: [14][250/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.000 (0.009)\tLoss 2.0721 (2.2393)\tPrec@1 88.281 (88.317)\tPrec@5 99.609 (99.262)\n",
            "Epoch: [14][260/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.000 (0.009)\tLoss 2.6497 (2.2393)\tPrec@1 85.547 (88.310)\tPrec@5 100.000 (99.264)\n",
            "Epoch: [14][270/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.003 (0.009)\tLoss 2.4475 (2.2354)\tPrec@1 86.719 (88.326)\tPrec@5 99.609 (99.271)\n",
            "Epoch: [14][280/329], lr: 0.01000\tTime 0.115 (0.096)\tData 0.018 (0.010)\tLoss 1.6733 (2.2317)\tPrec@1 91.016 (88.342)\tPrec@5 100.000 (99.280)\n",
            "Epoch: [14][290/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.003 (0.011)\tLoss 2.3033 (2.2287)\tPrec@1 87.891 (88.366)\tPrec@5 98.828 (99.279)\n",
            "Epoch: [14][300/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.000 (0.011)\tLoss 1.4978 (2.2285)\tPrec@1 90.625 (88.379)\tPrec@5 99.219 (99.275)\n",
            "Epoch: [14][310/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.010)\tLoss 2.2104 (2.2234)\tPrec@1 89.453 (88.429)\tPrec@5 98.828 (99.275)\n",
            "Epoch: [14][320/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.061 (0.010)\tLoss 1.8257 (2.2244)\tPrec@1 89.844 (88.427)\tPrec@5 99.609 (99.275)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 11.1725 (11.1725)\tPrec@1 51.000 (51.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.024 (0.054)\tLoss 9.6909 (11.0142)\tPrec@1 57.000 (50.182)\tPrec@5 90.000 (90.273)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 7.7325 (10.6001)\tPrec@1 63.000 (52.238)\tPrec@5 94.000 (90.714)\n",
            "Test: [30/100]\tTime 0.013 (0.034)\tLoss 10.1215 (10.5606)\tPrec@1 53.000 (52.129)\tPrec@5 94.000 (90.452)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 9.7436 (10.5356)\tPrec@1 59.000 (52.707)\tPrec@5 87.000 (90.024)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 10.8528 (10.5028)\tPrec@1 50.000 (52.627)\tPrec@5 87.000 (90.196)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 10.0874 (10.5337)\tPrec@1 49.000 (52.279)\tPrec@5 91.000 (90.213)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 10.4216 (10.4783)\tPrec@1 51.000 (52.437)\tPrec@5 92.000 (90.197)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 9.4260 (10.4259)\tPrec@1 56.000 (52.704)\tPrec@5 89.000 (90.481)\n",
            "Test: [90/100]\tTime 0.029 (0.028)\tLoss 10.5402 (10.4715)\tPrec@1 53.000 (52.462)\tPrec@5 92.000 (90.440)\n",
            "val Results: Prec@1 52.600 Prec@5 90.520 Loss 10.45666\n",
            "val Class Accuracy: [0.454,0.984,0.831,0.577,0.151,0.798,0.392,0.268,0.730,0.075]\n",
            "Best Prec@1: 66.090\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [15][0/329], lr: 0.01000\tTime 0.653 (0.653)\tData 0.561 (0.561)\tLoss 1.6650 (1.6650)\tPrec@1 91.797 (91.797)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [15][10/329], lr: 0.01000\tTime 0.079 (0.147)\tData 0.006 (0.057)\tLoss 3.9807 (4.2941)\tPrec@1 79.297 (76.776)\tPrec@5 96.484 (96.236)\n",
            "Epoch: [15][20/329], lr: 0.01000\tTime 0.105 (0.120)\tData 0.005 (0.032)\tLoss 3.7228 (4.1721)\tPrec@1 78.125 (77.009)\tPrec@5 98.828 (96.652)\n",
            "Epoch: [15][30/329], lr: 0.01000\tTime 0.079 (0.110)\tData 0.005 (0.023)\tLoss 2.3679 (3.8902)\tPrec@1 87.109 (78.742)\tPrec@5 98.438 (97.203)\n",
            "Epoch: [15][40/329], lr: 0.01000\tTime 0.093 (0.105)\tData 0.005 (0.018)\tLoss 3.0315 (3.7046)\tPrec@1 83.984 (79.830)\tPrec@5 98.438 (97.504)\n",
            "Epoch: [15][50/329], lr: 0.01000\tTime 0.087 (0.102)\tData 0.007 (0.016)\tLoss 2.7751 (3.5222)\tPrec@1 87.109 (80.997)\tPrec@5 98.438 (97.748)\n",
            "Epoch: [15][60/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.005 (0.014)\tLoss 2.4753 (3.3950)\tPrec@1 86.328 (81.653)\tPrec@5 99.219 (97.932)\n",
            "Epoch: [15][70/329], lr: 0.01000\tTime 0.077 (0.098)\tData 0.000 (0.013)\tLoss 2.2088 (3.2729)\tPrec@1 89.844 (82.427)\tPrec@5 99.219 (98.102)\n",
            "Epoch: [15][80/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.000 (0.012)\tLoss 2.4666 (3.1953)\tPrec@1 86.328 (82.841)\tPrec@5 98.828 (98.196)\n",
            "Epoch: [15][90/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.007 (0.012)\tLoss 2.3571 (3.1178)\tPrec@1 87.500 (83.225)\tPrec@5 99.609 (98.304)\n",
            "Epoch: [15][100/329], lr: 0.01000\tTime 0.148 (0.096)\tData 0.008 (0.012)\tLoss 2.3555 (3.0546)\tPrec@1 87.109 (83.532)\tPrec@5 98.828 (98.383)\n",
            "Epoch: [15][110/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.000 (0.011)\tLoss 2.2449 (3.0027)\tPrec@1 90.234 (83.858)\tPrec@5 98.047 (98.448)\n",
            "Epoch: [15][120/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.010)\tLoss 2.3307 (2.9602)\tPrec@1 87.891 (84.133)\tPrec@5 98.828 (98.470)\n",
            "Epoch: [15][130/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.012 (0.010)\tLoss 1.9569 (2.9095)\tPrec@1 91.016 (84.473)\tPrec@5 99.219 (98.524)\n",
            "Epoch: [15][140/329], lr: 0.01000\tTime 0.122 (0.095)\tData 0.007 (0.010)\tLoss 1.8066 (2.8515)\tPrec@1 90.234 (84.813)\tPrec@5 98.828 (98.579)\n",
            "Epoch: [15][150/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.012 (0.010)\tLoss 2.5700 (2.8151)\tPrec@1 87.109 (85.050)\tPrec@5 100.000 (98.629)\n",
            "Epoch: [15][160/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.003 (0.010)\tLoss 2.3710 (2.7885)\tPrec@1 88.281 (85.210)\tPrec@5 99.219 (98.661)\n",
            "Epoch: [15][170/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.000 (0.009)\tLoss 1.9946 (2.7523)\tPrec@1 89.453 (85.428)\tPrec@5 99.219 (98.682)\n",
            "Epoch: [15][180/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.010 (0.009)\tLoss 1.9890 (2.7323)\tPrec@1 87.891 (85.515)\tPrec@5 99.219 (98.705)\n",
            "Epoch: [15][190/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.012 (0.009)\tLoss 2.7809 (2.7198)\tPrec@1 85.156 (85.600)\tPrec@5 99.219 (98.724)\n",
            "Epoch: [15][200/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.006 (0.009)\tLoss 2.5141 (2.6991)\tPrec@1 86.328 (85.720)\tPrec@5 99.609 (98.746)\n",
            "Epoch: [15][210/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.005 (0.009)\tLoss 2.2952 (2.6849)\tPrec@1 87.891 (85.791)\tPrec@5 98.438 (98.774)\n",
            "Epoch: [15][220/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.009)\tLoss 1.8976 (2.6663)\tPrec@1 90.234 (85.877)\tPrec@5 100.000 (98.802)\n",
            "Epoch: [15][230/329], lr: 0.01000\tTime 0.073 (0.092)\tData 0.003 (0.009)\tLoss 2.2105 (2.6472)\tPrec@1 87.891 (85.976)\tPrec@5 99.609 (98.825)\n",
            "Epoch: [15][240/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.004 (0.009)\tLoss 2.0486 (2.6246)\tPrec@1 90.625 (86.121)\tPrec@5 99.219 (98.854)\n",
            "Epoch: [15][250/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.004 (0.009)\tLoss 2.7619 (2.6142)\tPrec@1 84.375 (86.173)\tPrec@5 100.000 (98.876)\n",
            "Epoch: [15][260/329], lr: 0.01000\tTime 0.113 (0.092)\tData 0.006 (0.009)\tLoss 2.2214 (2.6031)\tPrec@1 88.281 (86.235)\tPrec@5 98.828 (98.888)\n",
            "Epoch: [15][270/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.000 (0.009)\tLoss 2.1518 (2.5838)\tPrec@1 89.453 (86.332)\tPrec@5 99.609 (98.909)\n",
            "Epoch: [15][280/329], lr: 0.01000\tTime 0.067 (0.091)\tData 0.000 (0.008)\tLoss 2.3016 (2.5699)\tPrec@1 87.891 (86.400)\tPrec@5 100.000 (98.921)\n",
            "Epoch: [15][290/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.000 (0.008)\tLoss 1.8862 (2.5500)\tPrec@1 90.625 (86.511)\tPrec@5 98.828 (98.926)\n",
            "Epoch: [15][300/329], lr: 0.01000\tTime 0.100 (0.091)\tData 0.005 (0.008)\tLoss 2.2180 (2.5368)\tPrec@1 87.891 (86.581)\tPrec@5 98.828 (98.938)\n",
            "Epoch: [15][310/329], lr: 0.01000\tTime 0.105 (0.091)\tData 0.014 (0.008)\tLoss 2.3404 (2.5299)\tPrec@1 88.672 (86.616)\tPrec@5 98.438 (98.945)\n",
            "Epoch: [15][320/329], lr: 0.01000\tTime 0.146 (0.091)\tData 0.082 (0.008)\tLoss 2.7215 (2.5255)\tPrec@1 85.938 (86.654)\tPrec@5 99.219 (98.957)\n",
            "Test: [0/100]\tTime 0.293 (0.293)\tLoss 8.2657 (8.2657)\tPrec@1 64.000 (64.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.017 (0.054)\tLoss 6.3128 (7.4923)\tPrec@1 70.000 (64.273)\tPrec@5 96.000 (93.818)\n",
            "Test: [20/100]\tTime 0.034 (0.041)\tLoss 7.0306 (7.1801)\tPrec@1 68.000 (66.000)\tPrec@5 93.000 (93.905)\n",
            "Test: [30/100]\tTime 0.046 (0.037)\tLoss 6.9212 (7.1758)\tPrec@1 68.000 (66.258)\tPrec@5 92.000 (93.774)\n",
            "Test: [40/100]\tTime 0.032 (0.036)\tLoss 7.1745 (7.2390)\tPrec@1 69.000 (66.122)\tPrec@5 94.000 (93.878)\n",
            "Test: [50/100]\tTime 0.030 (0.036)\tLoss 7.0187 (7.1589)\tPrec@1 67.000 (66.608)\tPrec@5 96.000 (93.980)\n",
            "Test: [60/100]\tTime 0.021 (0.037)\tLoss 7.3321 (7.2411)\tPrec@1 63.000 (65.869)\tPrec@5 96.000 (93.918)\n",
            "Test: [70/100]\tTime 0.018 (0.037)\tLoss 7.2385 (7.2333)\tPrec@1 64.000 (65.915)\tPrec@5 96.000 (93.972)\n",
            "Test: [80/100]\tTime 0.040 (0.036)\tLoss 7.3484 (7.2022)\tPrec@1 65.000 (66.025)\tPrec@5 95.000 (94.000)\n",
            "Test: [90/100]\tTime 0.020 (0.036)\tLoss 7.3507 (7.1873)\tPrec@1 63.000 (66.055)\tPrec@5 97.000 (94.033)\n",
            "val Results: Prec@1 66.290 Prec@5 93.990 Loss 7.16997\n",
            "val Class Accuracy: [0.815,0.960,0.469,0.571,0.711,0.629,0.697,0.261,0.814,0.702]\n",
            "Best Prec@1: 66.290\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [16][0/329], lr: 0.01000\tTime 0.923 (0.923)\tData 0.778 (0.778)\tLoss 2.7629 (2.7629)\tPrec@1 85.156 (85.156)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [16][10/329], lr: 0.01000\tTime 0.105 (0.182)\tData 0.004 (0.078)\tLoss 3.5945 (3.9774)\tPrec@1 79.688 (78.232)\tPrec@5 96.484 (97.266)\n",
            "Epoch: [16][20/329], lr: 0.01000\tTime 0.083 (0.141)\tData 0.000 (0.043)\tLoss 3.0009 (3.7295)\tPrec@1 82.812 (79.483)\tPrec@5 98.828 (97.526)\n",
            "Epoch: [16][30/329], lr: 0.01000\tTime 0.093 (0.125)\tData 0.005 (0.031)\tLoss 2.6610 (3.4362)\tPrec@1 85.938 (81.300)\tPrec@5 97.656 (97.933)\n",
            "Epoch: [16][40/329], lr: 0.01000\tTime 0.083 (0.118)\tData 0.007 (0.025)\tLoss 2.9263 (3.3066)\tPrec@1 83.984 (82.003)\tPrec@5 98.438 (98.190)\n",
            "Epoch: [16][50/329], lr: 0.01000\tTime 0.081 (0.112)\tData 0.000 (0.021)\tLoss 2.2674 (3.1502)\tPrec@1 86.719 (82.874)\tPrec@5 99.219 (98.346)\n",
            "Epoch: [16][60/329], lr: 0.01000\tTime 0.101 (0.109)\tData 0.007 (0.019)\tLoss 2.7342 (3.0322)\tPrec@1 85.547 (83.530)\tPrec@5 99.219 (98.489)\n",
            "Epoch: [16][70/329], lr: 0.01000\tTime 0.084 (0.107)\tData 0.015 (0.018)\tLoss 1.6688 (2.9150)\tPrec@1 92.578 (84.292)\tPrec@5 99.609 (98.592)\n",
            "Epoch: [16][80/329], lr: 0.01000\tTime 0.092 (0.105)\tData 0.000 (0.016)\tLoss 2.5085 (2.8342)\tPrec@1 87.891 (84.766)\tPrec@5 99.219 (98.679)\n",
            "Epoch: [16][90/329], lr: 0.01000\tTime 0.093 (0.103)\tData 0.000 (0.015)\tLoss 2.1740 (2.7581)\tPrec@1 88.281 (85.182)\tPrec@5 98.438 (98.721)\n",
            "Epoch: [16][100/329], lr: 0.01000\tTime 0.119 (0.102)\tData 0.006 (0.014)\tLoss 2.3536 (2.7157)\tPrec@1 87.500 (85.442)\tPrec@5 100.000 (98.774)\n",
            "Epoch: [16][110/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.000 (0.014)\tLoss 2.2106 (2.6872)\tPrec@1 88.672 (85.624)\tPrec@5 99.219 (98.821)\n",
            "Epoch: [16][120/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.000 (0.013)\tLoss 2.1790 (2.6606)\tPrec@1 88.672 (85.799)\tPrec@5 99.219 (98.860)\n",
            "Epoch: [16][130/329], lr: 0.01000\tTime 0.078 (0.099)\tData 0.004 (0.012)\tLoss 2.4339 (2.6225)\tPrec@1 87.109 (86.036)\tPrec@5 99.219 (98.879)\n",
            "Epoch: [16][140/329], lr: 0.01000\tTime 0.073 (0.098)\tData 0.015 (0.012)\tLoss 2.0334 (2.5907)\tPrec@1 89.062 (86.203)\tPrec@5 99.219 (98.892)\n",
            "Epoch: [16][150/329], lr: 0.01000\tTime 0.099 (0.097)\tData 0.005 (0.012)\tLoss 2.2301 (2.5770)\tPrec@1 87.891 (86.289)\tPrec@5 99.609 (98.913)\n",
            "Epoch: [16][160/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.000 (0.011)\tLoss 2.3945 (2.5592)\tPrec@1 87.500 (86.401)\tPrec@5 99.609 (98.935)\n",
            "Epoch: [16][170/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.011 (0.011)\tLoss 2.2235 (2.5301)\tPrec@1 89.062 (86.554)\tPrec@5 99.609 (98.947)\n",
            "Epoch: [16][180/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.011)\tLoss 1.8108 (2.5121)\tPrec@1 90.625 (86.665)\tPrec@5 98.828 (98.949)\n",
            "Epoch: [16][190/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.005 (0.011)\tLoss 2.8514 (2.5031)\tPrec@1 85.547 (86.733)\tPrec@5 99.219 (98.979)\n",
            "Epoch: [16][200/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.014 (0.011)\tLoss 2.4205 (2.4908)\tPrec@1 88.281 (86.802)\tPrec@5 99.219 (98.978)\n",
            "Epoch: [16][210/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.005 (0.011)\tLoss 2.1236 (2.4773)\tPrec@1 87.891 (86.891)\tPrec@5 99.609 (98.985)\n",
            "Epoch: [16][220/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.010)\tLoss 1.7473 (2.4628)\tPrec@1 91.016 (86.956)\tPrec@5 98.828 (99.007)\n",
            "Epoch: [16][230/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.007 (0.010)\tLoss 2.2777 (2.4589)\tPrec@1 87.891 (86.989)\tPrec@5 99.219 (99.014)\n",
            "Epoch: [16][240/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.000 (0.010)\tLoss 2.1834 (2.4416)\tPrec@1 88.281 (87.088)\tPrec@5 100.000 (99.036)\n",
            "Epoch: [16][250/329], lr: 0.01000\tTime 0.106 (0.094)\tData 0.012 (0.010)\tLoss 2.2529 (2.4349)\tPrec@1 89.062 (87.142)\tPrec@5 99.219 (99.052)\n",
            "Epoch: [16][260/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.000 (0.010)\tLoss 1.4076 (2.4201)\tPrec@1 93.359 (87.228)\tPrec@5 99.609 (99.059)\n",
            "Epoch: [16][270/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.012 (0.010)\tLoss 2.4833 (2.4088)\tPrec@1 85.156 (87.288)\tPrec@5 99.219 (99.065)\n",
            "Epoch: [16][280/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.006 (0.010)\tLoss 2.0319 (2.3967)\tPrec@1 89.062 (87.373)\tPrec@5 99.219 (99.076)\n",
            "Epoch: [16][290/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.000 (0.009)\tLoss 2.0898 (2.3903)\tPrec@1 90.625 (87.421)\tPrec@5 98.828 (99.079)\n",
            "Epoch: [16][300/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.009)\tLoss 2.1315 (2.3913)\tPrec@1 88.281 (87.420)\tPrec@5 100.000 (99.073)\n",
            "Epoch: [16][310/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.008 (0.009)\tLoss 2.5060 (2.3846)\tPrec@1 87.109 (87.460)\tPrec@5 98.438 (99.079)\n",
            "Epoch: [16][320/329], lr: 0.01000\tTime 0.119 (0.093)\tData 0.079 (0.009)\tLoss 2.0864 (2.3786)\tPrec@1 90.234 (87.488)\tPrec@5 99.609 (99.092)\n",
            "Test: [0/100]\tTime 0.310 (0.310)\tLoss 9.6859 (9.6859)\tPrec@1 57.000 (57.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.031 (0.054)\tLoss 6.6604 (8.6939)\tPrec@1 68.000 (59.727)\tPrec@5 97.000 (96.091)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 7.3031 (8.6166)\tPrec@1 64.000 (59.857)\tPrec@5 97.000 (96.143)\n",
            "Test: [30/100]\tTime 0.010 (0.032)\tLoss 8.6676 (8.6570)\tPrec@1 61.000 (59.968)\tPrec@5 95.000 (95.839)\n",
            "Test: [40/100]\tTime 0.023 (0.032)\tLoss 9.3759 (8.6747)\tPrec@1 58.000 (60.073)\tPrec@5 93.000 (95.707)\n",
            "Test: [50/100]\tTime 0.027 (0.030)\tLoss 9.0375 (8.6271)\tPrec@1 58.000 (60.216)\tPrec@5 96.000 (95.725)\n",
            "Test: [60/100]\tTime 0.021 (0.029)\tLoss 7.6617 (8.6127)\tPrec@1 64.000 (60.148)\tPrec@5 97.000 (95.738)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 8.2178 (8.6135)\tPrec@1 64.000 (60.394)\tPrec@5 99.000 (95.746)\n",
            "Test: [80/100]\tTime 0.038 (0.028)\tLoss 8.0332 (8.5875)\tPrec@1 63.000 (60.358)\tPrec@5 94.000 (95.741)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 8.0616 (8.6273)\tPrec@1 63.000 (60.143)\tPrec@5 97.000 (95.626)\n",
            "val Results: Prec@1 60.160 Prec@5 95.630 Loss 8.65071\n",
            "val Class Accuracy: [0.841,0.899,0.831,0.654,0.836,0.412,0.612,0.256,0.315,0.360]\n",
            "Best Prec@1: 66.290\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [17][0/329], lr: 0.01000\tTime 0.618 (0.618)\tData 0.536 (0.536)\tLoss 2.2574 (2.2574)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [17][10/329], lr: 0.01000\tTime 0.111 (0.141)\tData 0.000 (0.055)\tLoss 5.4175 (4.7870)\tPrec@1 67.578 (72.763)\tPrec@5 93.750 (94.744)\n",
            "Epoch: [17][20/329], lr: 0.01000\tTime 0.117 (0.119)\tData 0.000 (0.031)\tLoss 4.3204 (4.7775)\tPrec@1 75.391 (72.712)\tPrec@5 96.094 (95.889)\n",
            "Epoch: [17][30/329], lr: 0.01000\tTime 0.111 (0.114)\tData 0.005 (0.023)\tLoss 3.7038 (4.4626)\tPrec@1 79.688 (74.483)\tPrec@5 98.438 (96.636)\n",
            "Epoch: [17][40/329], lr: 0.01000\tTime 0.072 (0.109)\tData 0.001 (0.019)\tLoss 3.3145 (4.1892)\tPrec@1 82.031 (76.162)\tPrec@5 98.047 (97.008)\n",
            "Epoch: [17][50/329], lr: 0.01000\tTime 0.115 (0.107)\tData 0.005 (0.017)\tLoss 3.6068 (3.9768)\tPrec@1 80.078 (77.466)\tPrec@5 98.438 (97.304)\n",
            "Epoch: [17][60/329], lr: 0.01000\tTime 0.137 (0.107)\tData 0.000 (0.015)\tLoss 2.5280 (3.7904)\tPrec@1 86.719 (78.701)\tPrec@5 98.438 (97.471)\n",
            "Epoch: [17][70/329], lr: 0.01000\tTime 0.129 (0.108)\tData 0.004 (0.014)\tLoss 2.3443 (3.6281)\tPrec@1 88.281 (79.743)\tPrec@5 98.828 (97.673)\n",
            "Epoch: [17][80/329], lr: 0.01000\tTime 0.151 (0.111)\tData 0.066 (0.017)\tLoss 3.2604 (3.5245)\tPrec@1 83.984 (80.421)\tPrec@5 98.828 (97.844)\n",
            "Epoch: [17][90/329], lr: 0.01000\tTime 0.077 (0.113)\tData 0.000 (0.020)\tLoss 2.1378 (3.4409)\tPrec@1 88.281 (80.992)\tPrec@5 98.828 (97.970)\n",
            "Epoch: [17][100/329], lr: 0.01000\tTime 0.084 (0.113)\tData 0.004 (0.019)\tLoss 2.0343 (3.3643)\tPrec@1 88.672 (81.424)\tPrec@5 98.438 (98.043)\n",
            "Epoch: [17][110/329], lr: 0.01000\tTime 0.090 (0.111)\tData 0.005 (0.018)\tLoss 2.6641 (3.3034)\tPrec@1 85.547 (81.803)\tPrec@5 98.828 (98.124)\n",
            "Epoch: [17][120/329], lr: 0.01000\tTime 0.068 (0.109)\tData 0.000 (0.017)\tLoss 2.4901 (3.2378)\tPrec@1 85.938 (82.241)\tPrec@5 97.266 (98.195)\n",
            "Epoch: [17][130/329], lr: 0.01000\tTime 0.091 (0.109)\tData 0.008 (0.016)\tLoss 2.1422 (3.1784)\tPrec@1 88.672 (82.601)\tPrec@5 99.219 (98.259)\n",
            "Epoch: [17][140/329], lr: 0.01000\tTime 0.110 (0.107)\tData 0.001 (0.015)\tLoss 2.8418 (3.1414)\tPrec@1 84.375 (82.799)\tPrec@5 100.000 (98.327)\n",
            "Epoch: [17][150/329], lr: 0.01000\tTime 0.107 (0.106)\tData 0.010 (0.015)\tLoss 2.4225 (3.1050)\tPrec@1 88.672 (83.056)\tPrec@5 99.609 (98.378)\n",
            "Epoch: [17][160/329], lr: 0.01000\tTime 0.088 (0.105)\tData 0.000 (0.014)\tLoss 2.4344 (3.0798)\tPrec@1 88.672 (83.215)\tPrec@5 99.219 (98.416)\n",
            "Epoch: [17][170/329], lr: 0.01000\tTime 0.089 (0.105)\tData 0.000 (0.014)\tLoss 2.6306 (3.0455)\tPrec@1 87.109 (83.443)\tPrec@5 98.438 (98.456)\n",
            "Epoch: [17][180/329], lr: 0.01000\tTime 0.104 (0.104)\tData 0.007 (0.013)\tLoss 2.0879 (3.0020)\tPrec@1 88.672 (83.700)\tPrec@5 99.219 (98.483)\n",
            "Epoch: [17][190/329], lr: 0.01000\tTime 0.091 (0.103)\tData 0.012 (0.013)\tLoss 2.4608 (2.9724)\tPrec@1 87.109 (83.864)\tPrec@5 100.000 (98.517)\n",
            "Epoch: [17][200/329], lr: 0.01000\tTime 0.077 (0.102)\tData 0.006 (0.013)\tLoss 1.7846 (2.9314)\tPrec@1 90.625 (84.111)\tPrec@5 99.609 (98.564)\n",
            "Epoch: [17][210/329], lr: 0.01000\tTime 0.090 (0.102)\tData 0.007 (0.013)\tLoss 2.1537 (2.9049)\tPrec@1 89.062 (84.301)\tPrec@5 98.828 (98.586)\n",
            "Epoch: [17][220/329], lr: 0.01000\tTime 0.083 (0.102)\tData 0.005 (0.012)\tLoss 2.4975 (2.8810)\tPrec@1 86.328 (84.451)\tPrec@5 100.000 (98.627)\n",
            "Epoch: [17][230/329], lr: 0.01000\tTime 0.101 (0.101)\tData 0.000 (0.012)\tLoss 2.0444 (2.8505)\tPrec@1 88.672 (84.620)\tPrec@5 99.219 (98.657)\n",
            "Epoch: [17][240/329], lr: 0.01000\tTime 0.117 (0.101)\tData 0.011 (0.012)\tLoss 2.0201 (2.8255)\tPrec@1 89.453 (84.764)\tPrec@5 98.828 (98.673)\n",
            "Epoch: [17][250/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.000 (0.012)\tLoss 2.3464 (2.8056)\tPrec@1 86.719 (84.895)\tPrec@5 98.828 (98.694)\n",
            "Epoch: [17][260/329], lr: 0.01000\tTime 0.083 (0.100)\tData 0.000 (0.012)\tLoss 2.2666 (2.7889)\tPrec@1 87.891 (85.008)\tPrec@5 99.609 (98.719)\n",
            "Epoch: [17][270/329], lr: 0.01000\tTime 0.107 (0.100)\tData 0.009 (0.011)\tLoss 1.9017 (2.7622)\tPrec@1 91.016 (85.169)\tPrec@5 99.219 (98.742)\n",
            "Epoch: [17][280/329], lr: 0.01000\tTime 0.073 (0.099)\tData 0.002 (0.011)\tLoss 2.2657 (2.7468)\tPrec@1 88.281 (85.262)\tPrec@5 100.000 (98.759)\n",
            "Epoch: [17][290/329], lr: 0.01000\tTime 0.077 (0.099)\tData 0.000 (0.011)\tLoss 2.2240 (2.7233)\tPrec@1 89.062 (85.405)\tPrec@5 100.000 (98.782)\n",
            "Epoch: [17][300/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.000 (0.011)\tLoss 1.7622 (2.7130)\tPrec@1 90.234 (85.469)\tPrec@5 99.219 (98.785)\n",
            "Epoch: [17][310/329], lr: 0.01000\tTime 0.078 (0.099)\tData 0.005 (0.011)\tLoss 2.1029 (2.6953)\tPrec@1 88.672 (85.563)\tPrec@5 99.219 (98.800)\n",
            "Epoch: [17][320/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.057 (0.011)\tLoss 2.2083 (2.6774)\tPrec@1 89.453 (85.680)\tPrec@5 99.609 (98.809)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 6.6367 (6.6367)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.033 (0.056)\tLoss 6.2428 (7.0303)\tPrec@1 70.000 (67.636)\tPrec@5 99.000 (97.727)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 5.7650 (6.6693)\tPrec@1 71.000 (69.000)\tPrec@5 98.000 (97.524)\n",
            "Test: [30/100]\tTime 0.022 (0.034)\tLoss 7.1977 (6.7327)\tPrec@1 63.000 (68.677)\tPrec@5 98.000 (97.452)\n",
            "Test: [40/100]\tTime 0.028 (0.034)\tLoss 7.2741 (6.8188)\tPrec@1 64.000 (68.293)\tPrec@5 95.000 (97.195)\n",
            "Test: [50/100]\tTime 0.036 (0.033)\tLoss 7.2811 (6.6682)\tPrec@1 67.000 (69.059)\tPrec@5 93.000 (97.157)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 7.0358 (6.7928)\tPrec@1 67.000 (68.508)\tPrec@5 96.000 (97.180)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 6.4182 (6.7727)\tPrec@1 68.000 (68.592)\tPrec@5 97.000 (97.169)\n",
            "Test: [80/100]\tTime 0.031 (0.030)\tLoss 8.1841 (6.7676)\tPrec@1 65.000 (68.654)\tPrec@5 95.000 (97.099)\n",
            "Test: [90/100]\tTime 0.017 (0.029)\tLoss 6.5717 (6.7852)\tPrec@1 74.000 (68.835)\tPrec@5 99.000 (96.989)\n",
            "val Results: Prec@1 68.960 Prec@5 97.050 Loss 6.76189\n",
            "val Class Accuracy: [0.806,0.887,0.615,0.907,0.707,0.477,0.554,0.374,0.838,0.731]\n",
            "Best Prec@1: 68.960\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [18][0/329], lr: 0.01000\tTime 0.561 (0.561)\tData 0.470 (0.470)\tLoss 2.0280 (2.0280)\tPrec@1 90.625 (90.625)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [18][10/329], lr: 0.01000\tTime 0.070 (0.141)\tData 0.001 (0.050)\tLoss 2.7540 (2.6645)\tPrec@1 85.938 (86.257)\tPrec@5 98.828 (98.331)\n",
            "Epoch: [18][20/329], lr: 0.01000\tTime 0.091 (0.119)\tData 0.000 (0.029)\tLoss 2.3243 (2.6697)\tPrec@1 87.500 (85.975)\tPrec@5 98.828 (98.512)\n",
            "Epoch: [18][30/329], lr: 0.01000\tTime 0.102 (0.110)\tData 0.000 (0.021)\tLoss 1.7635 (2.6288)\tPrec@1 91.406 (86.227)\tPrec@5 100.000 (98.715)\n",
            "Epoch: [18][40/329], lr: 0.01000\tTime 0.084 (0.107)\tData 0.004 (0.017)\tLoss 2.6769 (2.5606)\tPrec@1 85.156 (86.557)\tPrec@5 98.047 (98.857)\n",
            "Epoch: [18][50/329], lr: 0.01000\tTime 0.109 (0.104)\tData 0.006 (0.016)\tLoss 2.7915 (2.4702)\tPrec@1 86.719 (87.063)\tPrec@5 98.828 (98.974)\n",
            "Epoch: [18][60/329], lr: 0.01000\tTime 0.090 (0.101)\tData 0.006 (0.014)\tLoss 1.6777 (2.4269)\tPrec@1 91.797 (87.372)\tPrec@5 99.609 (98.963)\n",
            "Epoch: [18][70/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.000 (0.013)\tLoss 1.6143 (2.4119)\tPrec@1 92.969 (87.478)\tPrec@5 100.000 (98.993)\n",
            "Epoch: [18][80/329], lr: 0.01000\tTime 0.077 (0.099)\tData 0.001 (0.013)\tLoss 2.1284 (2.3668)\tPrec@1 89.844 (87.703)\tPrec@5 99.609 (99.050)\n",
            "Epoch: [18][90/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.012)\tLoss 2.1126 (2.3444)\tPrec@1 88.672 (87.848)\tPrec@5 99.219 (99.086)\n",
            "Epoch: [18][100/329], lr: 0.01000\tTime 0.089 (0.098)\tData 0.012 (0.012)\tLoss 2.6014 (2.3479)\tPrec@1 87.500 (87.790)\tPrec@5 98.828 (99.087)\n",
            "Epoch: [18][110/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.007 (0.011)\tLoss 2.8262 (2.3278)\tPrec@1 84.766 (87.870)\tPrec@5 99.219 (99.096)\n",
            "Epoch: [18][120/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.000 (0.011)\tLoss 1.6556 (2.2990)\tPrec@1 91.406 (88.042)\tPrec@5 100.000 (99.135)\n",
            "Epoch: [18][130/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.013 (0.011)\tLoss 1.6801 (2.2833)\tPrec@1 92.969 (88.150)\tPrec@5 100.000 (99.144)\n",
            "Epoch: [18][140/329], lr: 0.01000\tTime 0.106 (0.097)\tData 0.000 (0.010)\tLoss 2.2092 (2.2779)\tPrec@1 87.109 (88.184)\tPrec@5 99.609 (99.169)\n",
            "Epoch: [18][150/329], lr: 0.01000\tTime 0.149 (0.099)\tData 0.000 (0.010)\tLoss 2.2062 (2.2663)\tPrec@1 88.281 (88.248)\tPrec@5 100.000 (99.198)\n",
            "Epoch: [18][160/329], lr: 0.01000\tTime 0.135 (0.100)\tData 0.005 (0.011)\tLoss 2.1812 (2.2623)\tPrec@1 90.234 (88.286)\tPrec@5 99.609 (99.202)\n",
            "Epoch: [18][170/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.004 (0.013)\tLoss 1.9299 (2.2583)\tPrec@1 90.234 (88.297)\tPrec@5 98.828 (99.191)\n",
            "Epoch: [18][180/329], lr: 0.01000\tTime 0.112 (0.101)\tData 0.005 (0.013)\tLoss 1.9066 (2.2436)\tPrec@1 91.406 (88.378)\tPrec@5 100.000 (99.195)\n",
            "Epoch: [18][190/329], lr: 0.01000\tTime 0.097 (0.101)\tData 0.010 (0.012)\tLoss 2.1733 (2.2269)\tPrec@1 88.672 (88.480)\tPrec@5 99.609 (99.206)\n",
            "Epoch: [18][200/329], lr: 0.01000\tTime 0.094 (0.101)\tData 0.005 (0.012)\tLoss 2.1219 (2.2203)\tPrec@1 88.672 (88.526)\tPrec@5 99.219 (99.201)\n",
            "Epoch: [18][210/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.015 (0.012)\tLoss 2.2732 (2.2141)\tPrec@1 89.062 (88.577)\tPrec@5 99.219 (99.208)\n",
            "Epoch: [18][220/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.000 (0.012)\tLoss 1.2811 (2.2080)\tPrec@1 93.359 (88.601)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [18][230/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.000 (0.011)\tLoss 2.0738 (2.2067)\tPrec@1 88.672 (88.609)\tPrec@5 98.047 (99.224)\n",
            "Epoch: [18][240/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.008 (0.011)\tLoss 1.4949 (2.1986)\tPrec@1 92.188 (88.656)\tPrec@5 100.000 (99.235)\n",
            "Epoch: [18][250/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.000 (0.011)\tLoss 2.4256 (2.2018)\tPrec@1 85.547 (88.613)\tPrec@5 99.219 (99.237)\n",
            "Epoch: [18][260/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.005 (0.011)\tLoss 1.6224 (2.1934)\tPrec@1 90.625 (88.660)\tPrec@5 99.219 (99.246)\n",
            "Epoch: [18][270/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.011 (0.011)\tLoss 2.6377 (2.1924)\tPrec@1 87.891 (88.659)\tPrec@5 97.656 (99.239)\n",
            "Epoch: [18][280/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.000 (0.011)\tLoss 2.3331 (2.1933)\tPrec@1 86.328 (88.639)\tPrec@5 98.828 (99.244)\n",
            "Epoch: [18][290/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.000 (0.011)\tLoss 2.0456 (2.1898)\tPrec@1 89.453 (88.661)\tPrec@5 100.000 (99.252)\n",
            "Epoch: [18][300/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.000 (0.010)\tLoss 2.8614 (2.1890)\tPrec@1 84.766 (88.672)\tPrec@5 98.438 (99.250)\n",
            "Epoch: [18][310/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.000 (0.010)\tLoss 2.6524 (2.1869)\tPrec@1 85.156 (88.663)\tPrec@5 98.438 (99.246)\n",
            "Epoch: [18][320/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.046 (0.010)\tLoss 2.1021 (2.1906)\tPrec@1 89.062 (88.645)\tPrec@5 100.000 (99.246)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 7.2067 (7.2067)\tPrec@1 66.000 (66.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.022 (0.058)\tLoss 5.0931 (7.4835)\tPrec@1 78.000 (65.727)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 6.5387 (7.3859)\tPrec@1 70.000 (66.381)\tPrec@5 97.000 (96.714)\n",
            "Test: [30/100]\tTime 0.026 (0.035)\tLoss 7.4263 (7.4960)\tPrec@1 69.000 (65.903)\tPrec@5 98.000 (96.355)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 7.7026 (7.5621)\tPrec@1 66.000 (65.537)\tPrec@5 96.000 (96.195)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 8.0899 (7.5184)\tPrec@1 63.000 (65.667)\tPrec@5 94.000 (96.157)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 6.6797 (7.5651)\tPrec@1 68.000 (65.344)\tPrec@5 96.000 (96.197)\n",
            "Test: [70/100]\tTime 0.013 (0.030)\tLoss 7.8723 (7.5454)\tPrec@1 64.000 (65.465)\tPrec@5 96.000 (96.183)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 8.0050 (7.5259)\tPrec@1 63.000 (65.469)\tPrec@5 96.000 (96.136)\n",
            "Test: [90/100]\tTime 0.041 (0.029)\tLoss 7.4197 (7.5591)\tPrec@1 70.000 (65.418)\tPrec@5 98.000 (96.154)\n",
            "val Results: Prec@1 65.680 Prec@5 96.200 Loss 7.52075\n",
            "val Class Accuracy: [0.852,0.808,0.785,0.820,0.487,0.604,0.821,0.482,0.512,0.397]\n",
            "Best Prec@1: 68.960\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [19][0/329], lr: 0.01000\tTime 0.673 (0.673)\tData 0.576 (0.576)\tLoss 1.9976 (1.9976)\tPrec@1 87.891 (87.891)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [19][10/329], lr: 0.01000\tTime 0.109 (0.144)\tData 0.005 (0.058)\tLoss 1.5373 (2.5997)\tPrec@1 92.188 (86.612)\tPrec@5 99.219 (98.544)\n",
            "Epoch: [19][20/329], lr: 0.01000\tTime 0.090 (0.120)\tData 0.000 (0.034)\tLoss 2.7135 (2.4666)\tPrec@1 86.719 (87.147)\tPrec@5 98.438 (98.772)\n",
            "Epoch: [19][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.006 (0.025)\tLoss 2.0332 (2.3450)\tPrec@1 91.016 (87.878)\tPrec@5 99.219 (98.879)\n",
            "Epoch: [19][40/329], lr: 0.01000\tTime 0.094 (0.107)\tData 0.007 (0.021)\tLoss 2.4637 (2.3169)\tPrec@1 87.891 (88.091)\tPrec@5 98.828 (98.933)\n",
            "Epoch: [19][50/329], lr: 0.01000\tTime 0.087 (0.103)\tData 0.005 (0.018)\tLoss 1.9538 (2.2714)\tPrec@1 89.844 (88.235)\tPrec@5 99.609 (99.004)\n",
            "Epoch: [19][60/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.006 (0.016)\tLoss 2.0447 (2.2397)\tPrec@1 88.672 (88.371)\tPrec@5 98.828 (99.014)\n",
            "Epoch: [19][70/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.000 (0.014)\tLoss 2.0142 (2.1893)\tPrec@1 89.844 (88.545)\tPrec@5 99.609 (99.070)\n",
            "Epoch: [19][80/329], lr: 0.01000\tTime 0.074 (0.098)\tData 0.007 (0.014)\tLoss 1.7372 (2.1818)\tPrec@1 90.625 (88.648)\tPrec@5 99.219 (99.103)\n",
            "Epoch: [19][90/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.002 (0.013)\tLoss 2.0890 (2.1582)\tPrec@1 89.062 (88.779)\tPrec@5 100.000 (99.163)\n",
            "Epoch: [19][100/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.006 (0.013)\tLoss 1.8344 (2.1387)\tPrec@1 91.406 (88.923)\tPrec@5 99.609 (99.184)\n",
            "Epoch: [19][110/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.003 (0.012)\tLoss 2.5713 (2.1426)\tPrec@1 85.938 (88.887)\tPrec@5 98.438 (99.177)\n",
            "Epoch: [19][120/329], lr: 0.01000\tTime 0.063 (0.095)\tData 0.012 (0.012)\tLoss 2.3129 (2.1450)\tPrec@1 89.453 (88.866)\tPrec@5 98.828 (99.164)\n",
            "Epoch: [19][130/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.011)\tLoss 2.2096 (2.1455)\tPrec@1 87.891 (88.806)\tPrec@5 99.219 (99.174)\n",
            "Epoch: [19][140/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.007 (0.011)\tLoss 1.7129 (2.1428)\tPrec@1 91.016 (88.830)\tPrec@5 99.609 (99.169)\n",
            "Epoch: [19][150/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.009 (0.011)\tLoss 2.2378 (2.1467)\tPrec@1 87.109 (88.770)\tPrec@5 99.609 (99.164)\n",
            "Epoch: [19][160/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.005 (0.010)\tLoss 2.4702 (2.1368)\tPrec@1 85.156 (88.842)\tPrec@5 99.219 (99.178)\n",
            "Epoch: [19][170/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.010)\tLoss 2.4126 (2.1381)\tPrec@1 86.719 (88.823)\tPrec@5 99.219 (99.178)\n",
            "Epoch: [19][180/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 2.8084 (2.1374)\tPrec@1 85.938 (88.847)\tPrec@5 99.219 (99.184)\n",
            "Epoch: [19][190/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.007 (0.010)\tLoss 2.1566 (2.1265)\tPrec@1 89.453 (88.899)\tPrec@5 99.219 (99.198)\n",
            "Epoch: [19][200/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.000 (0.010)\tLoss 2.7953 (2.1274)\tPrec@1 85.156 (88.911)\tPrec@5 98.047 (99.199)\n",
            "Epoch: [19][210/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.005 (0.010)\tLoss 1.9689 (2.1226)\tPrec@1 90.234 (88.926)\tPrec@5 98.047 (99.204)\n",
            "Epoch: [19][220/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.000 (0.010)\tLoss 2.2348 (2.1246)\tPrec@1 88.672 (88.942)\tPrec@5 98.438 (99.215)\n",
            "Epoch: [19][230/329], lr: 0.01000\tTime 0.111 (0.096)\tData 0.001 (0.010)\tLoss 1.5884 (2.1133)\tPrec@1 91.016 (88.990)\tPrec@5 99.609 (99.220)\n",
            "Epoch: [19][240/329], lr: 0.01000\tTime 0.172 (0.098)\tData 0.077 (0.012)\tLoss 1.8998 (2.1160)\tPrec@1 89.844 (88.972)\tPrec@5 99.219 (99.227)\n",
            "Epoch: [19][250/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.005 (0.011)\tLoss 2.2059 (2.1127)\tPrec@1 89.062 (89.003)\tPrec@5 99.609 (99.225)\n",
            "Epoch: [19][260/329], lr: 0.01000\tTime 0.100 (0.098)\tData 0.006 (0.011)\tLoss 2.0952 (2.1100)\tPrec@1 88.281 (89.027)\tPrec@5 99.609 (99.241)\n",
            "Epoch: [19][270/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.005 (0.011)\tLoss 1.8027 (2.1099)\tPrec@1 91.016 (89.028)\tPrec@5 100.000 (99.248)\n",
            "Epoch: [19][280/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.001 (0.011)\tLoss 2.1345 (2.1053)\tPrec@1 90.234 (89.053)\tPrec@5 98.438 (99.248)\n",
            "Epoch: [19][290/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.004 (0.011)\tLoss 1.8990 (2.1024)\tPrec@1 91.406 (89.068)\tPrec@5 99.219 (99.248)\n",
            "Epoch: [19][300/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.001 (0.010)\tLoss 1.9054 (2.1065)\tPrec@1 91.016 (89.044)\tPrec@5 98.047 (99.250)\n",
            "Epoch: [19][310/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.012 (0.010)\tLoss 1.8549 (2.1039)\tPrec@1 90.234 (89.065)\tPrec@5 99.609 (99.259)\n",
            "Epoch: [19][320/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.056 (0.010)\tLoss 1.9717 (2.0982)\tPrec@1 89.453 (89.087)\tPrec@5 100.000 (99.259)\n",
            "Test: [0/100]\tTime 0.374 (0.374)\tLoss 8.6922 (8.6922)\tPrec@1 56.000 (56.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.025 (0.060)\tLoss 6.6346 (8.3191)\tPrec@1 69.000 (61.636)\tPrec@5 99.000 (96.182)\n",
            "Test: [20/100]\tTime 0.016 (0.042)\tLoss 7.2545 (8.3409)\tPrec@1 64.000 (61.429)\tPrec@5 97.000 (96.524)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 7.5285 (8.2707)\tPrec@1 68.000 (62.129)\tPrec@5 97.000 (96.194)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 8.6516 (8.2471)\tPrec@1 63.000 (62.512)\tPrec@5 93.000 (95.902)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 8.8918 (8.1767)\tPrec@1 59.000 (62.804)\tPrec@5 97.000 (96.118)\n",
            "Test: [60/100]\tTime 0.032 (0.031)\tLoss 7.2366 (8.2017)\tPrec@1 61.000 (62.508)\tPrec@5 98.000 (96.115)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 7.5893 (8.1629)\tPrec@1 65.000 (62.873)\tPrec@5 95.000 (96.113)\n",
            "Test: [80/100]\tTime 0.022 (0.030)\tLoss 7.7156 (8.1259)\tPrec@1 65.000 (63.025)\tPrec@5 96.000 (96.198)\n",
            "Test: [90/100]\tTime 0.035 (0.029)\tLoss 8.1450 (8.1979)\tPrec@1 66.000 (62.714)\tPrec@5 96.000 (96.077)\n",
            "val Results: Prec@1 62.830 Prec@5 96.040 Loss 8.19615\n",
            "val Class Accuracy: [0.952,0.806,0.815,0.675,0.815,0.335,0.628,0.423,0.415,0.419]\n",
            "Best Prec@1: 68.960\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [20][0/329], lr: 0.01000\tTime 0.567 (0.567)\tData 0.482 (0.482)\tLoss 2.9896 (2.9896)\tPrec@1 84.766 (84.766)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [20][10/329], lr: 0.01000\tTime 0.093 (0.143)\tData 0.000 (0.051)\tLoss 3.5159 (3.3548)\tPrec@1 80.859 (81.996)\tPrec@5 99.219 (97.656)\n",
            "Epoch: [20][20/329], lr: 0.01000\tTime 0.092 (0.124)\tData 0.004 (0.029)\tLoss 2.8488 (3.1935)\tPrec@1 83.984 (82.682)\tPrec@5 98.047 (98.140)\n",
            "Epoch: [20][30/329], lr: 0.01000\tTime 0.098 (0.113)\tData 0.012 (0.023)\tLoss 2.2287 (3.0030)\tPrec@1 89.062 (83.972)\tPrec@5 98.828 (98.324)\n",
            "Epoch: [20][40/329], lr: 0.01000\tTime 0.087 (0.108)\tData 0.007 (0.019)\tLoss 2.5554 (2.8750)\tPrec@1 85.938 (84.632)\tPrec@5 98.047 (98.457)\n",
            "Epoch: [20][50/329], lr: 0.01000\tTime 0.084 (0.104)\tData 0.000 (0.016)\tLoss 1.9372 (2.7845)\tPrec@1 89.844 (85.103)\tPrec@5 99.609 (98.606)\n",
            "Epoch: [20][60/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.000 (0.015)\tLoss 1.3936 (2.6982)\tPrec@1 92.188 (85.560)\tPrec@5 99.609 (98.623)\n",
            "Epoch: [20][70/329], lr: 0.01000\tTime 0.072 (0.100)\tData 0.000 (0.013)\tLoss 2.3877 (2.6416)\tPrec@1 88.281 (85.893)\tPrec@5 99.219 (98.729)\n",
            "Epoch: [20][80/329], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.013)\tLoss 2.0727 (2.6021)\tPrec@1 88.281 (86.179)\tPrec@5 100.000 (98.823)\n",
            "Epoch: [20][90/329], lr: 0.01000\tTime 0.110 (0.099)\tData 0.007 (0.012)\tLoss 1.8373 (2.5456)\tPrec@1 90.625 (86.530)\tPrec@5 99.219 (98.897)\n",
            "Epoch: [20][100/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.007 (0.012)\tLoss 2.4297 (2.4953)\tPrec@1 87.500 (86.800)\tPrec@5 99.609 (98.967)\n",
            "Epoch: [20][110/329], lr: 0.01000\tTime 0.067 (0.097)\tData 0.001 (0.011)\tLoss 1.5269 (2.4509)\tPrec@1 91.016 (87.035)\tPrec@5 99.609 (98.986)\n",
            "Epoch: [20][120/329], lr: 0.01000\tTime 0.075 (0.096)\tData 0.012 (0.011)\tLoss 2.2785 (2.4177)\tPrec@1 88.672 (87.222)\tPrec@5 98.828 (99.025)\n",
            "Epoch: [20][130/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.000 (0.011)\tLoss 1.5564 (2.3844)\tPrec@1 92.188 (87.417)\tPrec@5 99.219 (99.034)\n",
            "Epoch: [20][140/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.011)\tLoss 2.0957 (2.3457)\tPrec@1 88.281 (87.603)\tPrec@5 100.000 (99.077)\n",
            "Epoch: [20][150/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.002 (0.011)\tLoss 1.9354 (2.3286)\tPrec@1 90.234 (87.694)\tPrec@5 100.000 (99.115)\n",
            "Epoch: [20][160/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.010)\tLoss 2.1294 (2.3162)\tPrec@1 88.281 (87.740)\tPrec@5 99.609 (99.117)\n",
            "Epoch: [20][170/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.000 (0.010)\tLoss 1.3834 (2.3063)\tPrec@1 91.797 (87.795)\tPrec@5 99.219 (99.123)\n",
            "Epoch: [20][180/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.003 (0.010)\tLoss 2.1547 (2.3070)\tPrec@1 91.016 (87.828)\tPrec@5 98.047 (99.113)\n",
            "Epoch: [20][190/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.001 (0.010)\tLoss 1.7787 (2.2982)\tPrec@1 92.578 (87.901)\tPrec@5 98.828 (99.125)\n",
            "Epoch: [20][200/329], lr: 0.01000\tTime 0.089 (0.093)\tData 0.007 (0.010)\tLoss 2.1212 (2.2870)\tPrec@1 87.891 (87.976)\tPrec@5 98.828 (99.131)\n",
            "Epoch: [20][210/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.002 (0.010)\tLoss 2.1285 (2.2739)\tPrec@1 87.891 (88.057)\tPrec@5 99.609 (99.143)\n",
            "Epoch: [20][220/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.009)\tLoss 2.5069 (2.2586)\tPrec@1 86.719 (88.138)\tPrec@5 98.828 (99.150)\n",
            "Epoch: [20][230/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.012 (0.009)\tLoss 2.3189 (2.2491)\tPrec@1 87.500 (88.207)\tPrec@5 100.000 (99.161)\n",
            "Epoch: [20][240/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.001 (0.009)\tLoss 2.2893 (2.2435)\tPrec@1 89.062 (88.233)\tPrec@5 98.828 (99.164)\n",
            "Epoch: [20][250/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.009)\tLoss 1.3382 (2.2424)\tPrec@1 93.359 (88.242)\tPrec@5 99.219 (99.160)\n",
            "Epoch: [20][260/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 2.0027 (2.2351)\tPrec@1 89.062 (88.283)\tPrec@5 99.219 (99.165)\n",
            "Epoch: [20][270/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.009)\tLoss 2.0387 (2.2263)\tPrec@1 90.234 (88.333)\tPrec@5 99.219 (99.173)\n",
            "Epoch: [20][280/329], lr: 0.01000\tTime 0.158 (0.093)\tData 0.005 (0.009)\tLoss 2.0399 (2.2175)\tPrec@1 89.844 (88.387)\tPrec@5 99.609 (99.178)\n",
            "Epoch: [20][290/329], lr: 0.01000\tTime 0.121 (0.094)\tData 0.000 (0.009)\tLoss 1.8174 (2.2103)\tPrec@1 90.234 (88.422)\tPrec@5 100.000 (99.178)\n",
            "Epoch: [20][300/329], lr: 0.01000\tTime 0.112 (0.095)\tData 0.003 (0.008)\tLoss 2.1368 (2.2028)\tPrec@1 88.281 (88.466)\tPrec@5 99.219 (99.186)\n",
            "Epoch: [20][310/329], lr: 0.01000\tTime 0.120 (0.096)\tData 0.046 (0.009)\tLoss 1.6154 (2.1921)\tPrec@1 91.797 (88.524)\tPrec@5 99.609 (99.201)\n",
            "Epoch: [20][320/329], lr: 0.01000\tTime 0.176 (0.096)\tData 0.109 (0.010)\tLoss 2.4098 (2.1841)\tPrec@1 87.109 (88.570)\tPrec@5 97.656 (99.198)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 7.5730 (7.5730)\tPrec@1 64.000 (64.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.032 (0.056)\tLoss 5.3829 (6.5224)\tPrec@1 74.000 (69.273)\tPrec@5 100.000 (97.727)\n",
            "Test: [20/100]\tTime 0.020 (0.041)\tLoss 5.4698 (6.3917)\tPrec@1 71.000 (70.476)\tPrec@5 100.000 (97.714)\n",
            "Test: [30/100]\tTime 0.038 (0.036)\tLoss 6.2008 (6.3886)\tPrec@1 71.000 (70.452)\tPrec@5 96.000 (97.290)\n",
            "Test: [40/100]\tTime 0.036 (0.033)\tLoss 6.3276 (6.4157)\tPrec@1 71.000 (70.488)\tPrec@5 95.000 (97.195)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 7.2914 (6.4088)\tPrec@1 67.000 (70.510)\tPrec@5 97.000 (97.451)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 5.4530 (6.4915)\tPrec@1 75.000 (69.820)\tPrec@5 98.000 (97.426)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 6.8122 (6.4771)\tPrec@1 68.000 (69.887)\tPrec@5 98.000 (97.437)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 6.2725 (6.4660)\tPrec@1 75.000 (70.062)\tPrec@5 99.000 (97.580)\n",
            "Test: [90/100]\tTime 0.032 (0.029)\tLoss 6.3325 (6.5315)\tPrec@1 70.000 (69.703)\tPrec@5 100.000 (97.571)\n",
            "val Results: Prec@1 69.600 Prec@5 97.620 Loss 6.55449\n",
            "val Class Accuracy: [0.910,0.934,0.894,0.449,0.699,0.785,0.511,0.519,0.763,0.496]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [21][0/329], lr: 0.01000\tTime 0.529 (0.529)\tData 0.440 (0.440)\tLoss 2.0370 (2.0370)\tPrec@1 89.453 (89.453)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [21][10/329], lr: 0.01000\tTime 0.100 (0.137)\tData 0.003 (0.047)\tLoss 2.2410 (2.5561)\tPrec@1 89.453 (86.399)\tPrec@5 99.219 (98.864)\n",
            "Epoch: [21][20/329], lr: 0.01000\tTime 0.098 (0.118)\tData 0.015 (0.027)\tLoss 1.8863 (2.4238)\tPrec@1 90.234 (86.979)\tPrec@5 98.438 (98.921)\n",
            "Epoch: [21][30/329], lr: 0.01000\tTime 0.060 (0.108)\tData 0.003 (0.021)\tLoss 2.1131 (2.3352)\tPrec@1 88.672 (87.525)\tPrec@5 99.609 (99.055)\n",
            "Epoch: [21][40/329], lr: 0.01000\tTime 0.106 (0.105)\tData 0.000 (0.017)\tLoss 2.1398 (2.2283)\tPrec@1 88.672 (88.196)\tPrec@5 98.438 (99.143)\n",
            "Epoch: [21][50/329], lr: 0.01000\tTime 0.113 (0.103)\tData 0.006 (0.015)\tLoss 2.3319 (2.2083)\tPrec@1 87.891 (88.335)\tPrec@5 99.219 (99.142)\n",
            "Epoch: [21][60/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.011 (0.014)\tLoss 2.0765 (2.1838)\tPrec@1 88.281 (88.454)\tPrec@5 100.000 (99.193)\n",
            "Epoch: [21][70/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.000 (0.013)\tLoss 2.4085 (2.1690)\tPrec@1 85.938 (88.589)\tPrec@5 98.828 (99.186)\n",
            "Epoch: [21][80/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.011)\tLoss 2.2076 (2.1469)\tPrec@1 89.062 (88.715)\tPrec@5 98.828 (99.185)\n",
            "Epoch: [21][90/329], lr: 0.01000\tTime 0.117 (0.098)\tData 0.000 (0.011)\tLoss 1.7724 (2.1301)\tPrec@1 91.016 (88.818)\tPrec@5 98.828 (99.232)\n",
            "Epoch: [21][100/329], lr: 0.01000\tTime 0.093 (0.098)\tData 0.004 (0.010)\tLoss 2.1716 (2.1418)\tPrec@1 90.234 (88.765)\tPrec@5 98.438 (99.223)\n",
            "Epoch: [21][110/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.000 (0.010)\tLoss 1.4705 (2.1371)\tPrec@1 92.578 (88.851)\tPrec@5 99.219 (99.222)\n",
            "Epoch: [21][120/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.013 (0.010)\tLoss 1.7567 (2.1301)\tPrec@1 90.625 (88.898)\tPrec@5 99.609 (99.251)\n",
            "Epoch: [21][130/329], lr: 0.01000\tTime 0.062 (0.096)\tData 0.006 (0.010)\tLoss 2.3664 (2.1266)\tPrec@1 88.281 (88.904)\tPrec@5 99.219 (99.237)\n",
            "Epoch: [21][140/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.012 (0.010)\tLoss 2.0542 (2.1105)\tPrec@1 89.844 (89.002)\tPrec@5 98.438 (99.233)\n",
            "Epoch: [21][150/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.003 (0.010)\tLoss 2.2925 (2.0875)\tPrec@1 87.891 (89.099)\tPrec@5 99.609 (99.255)\n",
            "Epoch: [21][160/329], lr: 0.01000\tTime 0.113 (0.095)\tData 0.007 (0.010)\tLoss 1.9851 (2.0755)\tPrec@1 88.281 (89.140)\tPrec@5 98.828 (99.255)\n",
            "Epoch: [21][170/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.011 (0.010)\tLoss 2.1536 (2.0704)\tPrec@1 90.234 (89.190)\tPrec@5 99.609 (99.255)\n",
            "Epoch: [21][180/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.007 (0.010)\tLoss 2.1921 (2.0673)\tPrec@1 87.500 (89.222)\tPrec@5 98.438 (99.249)\n",
            "Epoch: [21][190/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.000 (0.009)\tLoss 2.1337 (2.0644)\tPrec@1 89.453 (89.238)\tPrec@5 99.609 (99.256)\n",
            "Epoch: [21][200/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.009)\tLoss 2.0088 (2.0596)\tPrec@1 89.453 (89.259)\tPrec@5 100.000 (99.256)\n",
            "Epoch: [21][210/329], lr: 0.01000\tTime 0.067 (0.094)\tData 0.010 (0.009)\tLoss 2.3189 (2.0574)\tPrec@1 87.891 (89.264)\tPrec@5 99.609 (99.258)\n",
            "Epoch: [21][220/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.009)\tLoss 2.2212 (2.0605)\tPrec@1 89.453 (89.239)\tPrec@5 98.047 (99.251)\n",
            "Epoch: [21][230/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.005 (0.009)\tLoss 1.8330 (2.0585)\tPrec@1 91.406 (89.235)\tPrec@5 98.828 (99.258)\n",
            "Epoch: [21][240/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.009)\tLoss 1.9632 (2.0607)\tPrec@1 89.844 (89.216)\tPrec@5 98.828 (99.250)\n",
            "Epoch: [21][250/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.009)\tLoss 2.1342 (2.0549)\tPrec@1 87.500 (89.235)\tPrec@5 100.000 (99.253)\n",
            "Epoch: [21][260/329], lr: 0.01000\tTime 0.061 (0.093)\tData 0.000 (0.009)\tLoss 1.7986 (2.0596)\tPrec@1 90.234 (89.211)\tPrec@5 98.828 (99.241)\n",
            "Epoch: [21][270/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.009)\tLoss 2.0699 (2.0607)\tPrec@1 88.281 (89.221)\tPrec@5 99.609 (99.248)\n",
            "Epoch: [21][280/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.012 (0.009)\tLoss 2.0113 (2.0595)\tPrec@1 89.453 (89.235)\tPrec@5 100.000 (99.256)\n",
            "Epoch: [21][290/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.005 (0.009)\tLoss 2.1843 (2.0675)\tPrec@1 88.672 (89.195)\tPrec@5 99.609 (99.258)\n",
            "Epoch: [21][300/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.000 (0.009)\tLoss 1.7552 (2.0637)\tPrec@1 91.406 (89.234)\tPrec@5 98.438 (99.260)\n",
            "Epoch: [21][310/329], lr: 0.01000\tTime 0.097 (0.093)\tData 0.000 (0.009)\tLoss 2.0162 (2.0650)\tPrec@1 89.453 (89.218)\tPrec@5 99.219 (99.264)\n",
            "Epoch: [21][320/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.040 (0.009)\tLoss 1.7338 (2.0622)\tPrec@1 91.406 (89.237)\tPrec@5 99.609 (99.267)\n",
            "Test: [0/100]\tTime 0.306 (0.306)\tLoss 6.9020 (6.9020)\tPrec@1 68.000 (68.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.041 (0.058)\tLoss 5.6567 (6.7736)\tPrec@1 74.000 (69.000)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/100]\tTime 0.028 (0.042)\tLoss 6.0966 (6.6858)\tPrec@1 70.000 (69.381)\tPrec@5 99.000 (97.571)\n",
            "Test: [30/100]\tTime 0.034 (0.036)\tLoss 6.6632 (6.7265)\tPrec@1 67.000 (69.129)\tPrec@5 100.000 (97.516)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 6.9507 (6.6510)\tPrec@1 70.000 (69.585)\tPrec@5 95.000 (97.585)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 6.9421 (6.6560)\tPrec@1 69.000 (69.392)\tPrec@5 95.000 (97.686)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 5.9654 (6.7201)\tPrec@1 73.000 (69.148)\tPrec@5 100.000 (97.803)\n",
            "Test: [70/100]\tTime 0.040 (0.030)\tLoss 6.6277 (6.7346)\tPrec@1 69.000 (68.930)\tPrec@5 98.000 (97.831)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 6.9030 (6.7257)\tPrec@1 70.000 (68.889)\tPrec@5 98.000 (97.901)\n",
            "Test: [90/100]\tTime 0.044 (0.029)\tLoss 6.5688 (6.7629)\tPrec@1 70.000 (68.769)\tPrec@5 100.000 (97.879)\n",
            "val Results: Prec@1 68.910 Prec@5 97.860 Loss 6.74907\n",
            "val Class Accuracy: [0.944,0.878,0.857,0.791,0.735,0.285,0.546,0.593,0.722,0.540]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [22][0/329], lr: 0.01000\tTime 0.884 (0.884)\tData 0.778 (0.778)\tLoss 2.3493 (2.3493)\tPrec@1 87.891 (87.891)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [22][10/329], lr: 0.01000\tTime 0.130 (0.200)\tData 0.008 (0.091)\tLoss 2.2002 (2.1943)\tPrec@1 88.281 (88.814)\tPrec@5 99.609 (99.112)\n",
            "Epoch: [22][20/329], lr: 0.01000\tTime 0.250 (0.179)\tData 0.161 (0.073)\tLoss 2.0358 (2.0388)\tPrec@1 89.062 (89.342)\tPrec@5 100.000 (99.312)\n",
            "Epoch: [22][30/329], lr: 0.01000\tTime 0.105 (0.153)\tData 0.012 (0.052)\tLoss 1.9625 (2.0740)\tPrec@1 90.234 (89.176)\tPrec@5 100.000 (99.294)\n",
            "Epoch: [22][40/329], lr: 0.01000\tTime 0.105 (0.137)\tData 0.006 (0.040)\tLoss 1.7594 (2.0416)\tPrec@1 92.188 (89.291)\tPrec@5 99.219 (99.238)\n",
            "Epoch: [22][50/329], lr: 0.01000\tTime 0.111 (0.129)\tData 0.005 (0.034)\tLoss 2.4280 (2.0476)\tPrec@1 85.938 (89.223)\tPrec@5 99.219 (99.249)\n",
            "Epoch: [22][60/329], lr: 0.01000\tTime 0.099 (0.123)\tData 0.004 (0.029)\tLoss 1.8173 (2.0100)\tPrec@1 92.188 (89.536)\tPrec@5 100.000 (99.302)\n",
            "Epoch: [22][70/329], lr: 0.01000\tTime 0.083 (0.118)\tData 0.000 (0.026)\tLoss 2.2201 (2.0071)\tPrec@1 87.109 (89.497)\tPrec@5 98.828 (99.318)\n",
            "Epoch: [22][80/329], lr: 0.01000\tTime 0.085 (0.115)\tData 0.011 (0.023)\tLoss 2.3550 (2.0180)\tPrec@1 87.109 (89.424)\tPrec@5 99.219 (99.310)\n",
            "Epoch: [22][90/329], lr: 0.01000\tTime 0.087 (0.114)\tData 0.016 (0.022)\tLoss 2.3237 (2.0098)\tPrec@1 89.062 (89.509)\tPrec@5 98.828 (99.296)\n",
            "Epoch: [22][100/329], lr: 0.01000\tTime 0.077 (0.111)\tData 0.000 (0.020)\tLoss 2.2280 (2.0227)\tPrec@1 89.062 (89.472)\tPrec@5 100.000 (99.292)\n",
            "Epoch: [22][110/329], lr: 0.01000\tTime 0.084 (0.109)\tData 0.009 (0.019)\tLoss 2.2787 (2.0329)\tPrec@1 88.672 (89.436)\tPrec@5 99.609 (99.275)\n",
            "Epoch: [22][120/329], lr: 0.01000\tTime 0.064 (0.107)\tData 0.005 (0.018)\tLoss 2.1602 (2.0236)\tPrec@1 89.453 (89.511)\tPrec@5 99.219 (99.287)\n",
            "Epoch: [22][130/329], lr: 0.01000\tTime 0.090 (0.106)\tData 0.000 (0.017)\tLoss 2.0283 (2.0231)\tPrec@1 90.234 (89.519)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [22][140/329], lr: 0.01000\tTime 0.090 (0.106)\tData 0.007 (0.017)\tLoss 2.3820 (2.0259)\tPrec@1 86.719 (89.506)\tPrec@5 98.828 (99.294)\n",
            "Epoch: [22][150/329], lr: 0.01000\tTime 0.088 (0.104)\tData 0.000 (0.016)\tLoss 2.1447 (2.0195)\tPrec@1 89.453 (89.544)\tPrec@5 99.609 (99.325)\n",
            "Epoch: [22][160/329], lr: 0.01000\tTime 0.087 (0.104)\tData 0.004 (0.015)\tLoss 1.4711 (2.0208)\tPrec@1 93.750 (89.540)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [22][170/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.004 (0.015)\tLoss 1.4867 (2.0133)\tPrec@1 92.969 (89.583)\tPrec@5 99.609 (99.317)\n",
            "Epoch: [22][180/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.005 (0.015)\tLoss 1.8743 (2.0024)\tPrec@1 91.406 (89.624)\tPrec@5 99.609 (99.329)\n",
            "Epoch: [22][190/329], lr: 0.01000\tTime 0.096 (0.101)\tData 0.010 (0.014)\tLoss 1.7487 (1.9901)\tPrec@1 91.016 (89.692)\tPrec@5 99.219 (99.335)\n",
            "Epoch: [22][200/329], lr: 0.01000\tTime 0.084 (0.101)\tData 0.009 (0.014)\tLoss 2.0679 (1.9914)\tPrec@1 89.453 (89.673)\tPrec@5 99.609 (99.337)\n",
            "Epoch: [22][210/329], lr: 0.01000\tTime 0.083 (0.100)\tData 0.003 (0.014)\tLoss 3.2879 (2.0000)\tPrec@1 83.203 (89.622)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [22][220/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.010 (0.013)\tLoss 1.9685 (1.9990)\tPrec@1 91.406 (89.628)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [22][230/329], lr: 0.01000\tTime 0.090 (0.100)\tData 0.007 (0.013)\tLoss 1.4105 (1.9985)\tPrec@1 94.141 (89.643)\tPrec@5 99.609 (99.327)\n",
            "Epoch: [22][240/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.007 (0.013)\tLoss 2.2502 (2.0027)\tPrec@1 87.891 (89.610)\tPrec@5 98.828 (99.321)\n",
            "Epoch: [22][250/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.000 (0.013)\tLoss 1.7931 (1.9950)\tPrec@1 91.406 (89.648)\tPrec@5 99.219 (99.317)\n",
            "Epoch: [22][260/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.000 (0.013)\tLoss 2.1093 (1.9950)\tPrec@1 90.234 (89.654)\tPrec@5 98.828 (99.318)\n",
            "Epoch: [22][270/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.006 (0.012)\tLoss 2.6897 (1.9917)\tPrec@1 87.109 (89.677)\tPrec@5 99.219 (99.312)\n",
            "Epoch: [22][280/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.000 (0.012)\tLoss 2.1936 (1.9934)\tPrec@1 87.500 (89.663)\tPrec@5 99.219 (99.320)\n",
            "Epoch: [22][290/329], lr: 0.01000\tTime 0.086 (0.097)\tData 0.006 (0.012)\tLoss 1.6679 (1.9937)\tPrec@1 92.188 (89.669)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [22][300/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.013 (0.012)\tLoss 2.1114 (1.9898)\tPrec@1 88.672 (89.689)\tPrec@5 99.609 (99.326)\n",
            "Epoch: [22][310/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.008 (0.012)\tLoss 1.5758 (1.9886)\tPrec@1 91.406 (89.689)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [22][320/329], lr: 0.01000\tTime 0.105 (0.097)\tData 0.073 (0.012)\tLoss 2.5638 (1.9885)\tPrec@1 87.500 (89.670)\tPrec@5 99.609 (99.328)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 8.5323 (8.5323)\tPrec@1 60.000 (60.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.012 (0.053)\tLoss 5.9576 (8.4994)\tPrec@1 71.000 (60.818)\tPrec@5 97.000 (95.636)\n",
            "Test: [20/100]\tTime 0.018 (0.039)\tLoss 8.1999 (8.1791)\tPrec@1 65.000 (62.286)\tPrec@5 98.000 (95.524)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 8.2056 (8.2495)\tPrec@1 62.000 (62.032)\tPrec@5 96.000 (95.645)\n",
            "Test: [40/100]\tTime 0.012 (0.032)\tLoss 8.5460 (8.2737)\tPrec@1 61.000 (61.878)\tPrec@5 93.000 (95.585)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 9.0130 (8.2788)\tPrec@1 58.000 (61.824)\tPrec@5 93.000 (95.490)\n",
            "Test: [60/100]\tTime 0.035 (0.029)\tLoss 8.4687 (8.3936)\tPrec@1 59.000 (61.246)\tPrec@5 96.000 (95.541)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 8.6875 (8.4141)\tPrec@1 60.000 (61.113)\tPrec@5 95.000 (95.606)\n",
            "Test: [80/100]\tTime 0.021 (0.028)\tLoss 7.8256 (8.3859)\tPrec@1 61.000 (61.099)\tPrec@5 98.000 (95.667)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 7.3668 (8.4457)\tPrec@1 67.000 (60.879)\tPrec@5 99.000 (95.538)\n",
            "val Results: Prec@1 60.970 Prec@5 95.500 Loss 8.43832\n",
            "val Class Accuracy: [0.899,0.909,0.945,0.404,0.470,0.309,0.633,0.264,0.734,0.530]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [23][0/329], lr: 0.01000\tTime 0.653 (0.653)\tData 0.538 (0.538)\tLoss 1.9802 (1.9802)\tPrec@1 89.453 (89.453)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [23][10/329], lr: 0.01000\tTime 0.096 (0.150)\tData 0.011 (0.055)\tLoss 2.4035 (2.1294)\tPrec@1 87.109 (88.849)\tPrec@5 99.609 (99.112)\n",
            "Epoch: [23][20/329], lr: 0.01000\tTime 0.092 (0.122)\tData 0.006 (0.032)\tLoss 2.3237 (2.0880)\tPrec@1 88.281 (89.007)\tPrec@5 99.609 (99.182)\n",
            "Epoch: [23][30/329], lr: 0.01000\tTime 0.100 (0.112)\tData 0.016 (0.024)\tLoss 1.5840 (2.0980)\tPrec@1 91.016 (88.873)\tPrec@5 99.219 (99.206)\n",
            "Epoch: [23][40/329], lr: 0.01000\tTime 0.113 (0.107)\tData 0.008 (0.020)\tLoss 1.6614 (2.0580)\tPrec@1 91.406 (89.129)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [23][50/329], lr: 0.01000\tTime 0.103 (0.103)\tData 0.009 (0.017)\tLoss 1.4060 (2.0062)\tPrec@1 92.578 (89.461)\tPrec@5 98.828 (99.357)\n",
            "Epoch: [23][60/329], lr: 0.01000\tTime 0.100 (0.101)\tData 0.005 (0.016)\tLoss 2.1324 (2.0103)\tPrec@1 87.109 (89.421)\tPrec@5 99.609 (99.347)\n",
            "Epoch: [23][70/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.002 (0.014)\tLoss 1.5806 (2.0203)\tPrec@1 91.797 (89.343)\tPrec@5 99.609 (99.373)\n",
            "Epoch: [23][80/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.000 (0.013)\tLoss 2.0838 (2.0086)\tPrec@1 89.062 (89.424)\tPrec@5 100.000 (99.392)\n",
            "Epoch: [23][90/329], lr: 0.01000\tTime 0.144 (0.100)\tData 0.005 (0.013)\tLoss 2.1635 (2.0013)\tPrec@1 88.672 (89.479)\tPrec@5 100.000 (99.382)\n",
            "Epoch: [23][100/329], lr: 0.01000\tTime 0.130 (0.102)\tData 0.007 (0.012)\tLoss 1.9732 (1.9853)\tPrec@1 88.672 (89.573)\tPrec@5 100.000 (99.389)\n",
            "Epoch: [23][110/329], lr: 0.01000\tTime 0.112 (0.104)\tData 0.000 (0.013)\tLoss 2.1092 (1.9792)\tPrec@1 89.844 (89.622)\tPrec@5 98.438 (99.381)\n",
            "Epoch: [23][120/329], lr: 0.01000\tTime 0.102 (0.107)\tData 0.001 (0.016)\tLoss 1.6824 (1.9812)\tPrec@1 91.797 (89.611)\tPrec@5 99.219 (99.370)\n",
            "Epoch: [23][130/329], lr: 0.01000\tTime 0.087 (0.106)\tData 0.001 (0.016)\tLoss 2.3259 (1.9855)\tPrec@1 87.500 (89.578)\tPrec@5 100.000 (99.371)\n",
            "Epoch: [23][140/329], lr: 0.01000\tTime 0.088 (0.105)\tData 0.009 (0.016)\tLoss 2.2677 (1.9871)\tPrec@1 87.891 (89.600)\tPrec@5 98.828 (99.377)\n",
            "Epoch: [23][150/329], lr: 0.01000\tTime 0.074 (0.104)\tData 0.000 (0.015)\tLoss 1.9476 (1.9772)\tPrec@1 89.453 (89.670)\tPrec@5 99.219 (99.374)\n",
            "Epoch: [23][160/329], lr: 0.01000\tTime 0.088 (0.104)\tData 0.004 (0.015)\tLoss 1.6770 (1.9724)\tPrec@1 91.406 (89.696)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [23][170/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.000 (0.014)\tLoss 2.3590 (1.9768)\tPrec@1 88.672 (89.677)\tPrec@5 100.000 (99.383)\n",
            "Epoch: [23][180/329], lr: 0.01000\tTime 0.081 (0.102)\tData 0.003 (0.014)\tLoss 1.8790 (1.9794)\tPrec@1 91.016 (89.658)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [23][190/329], lr: 0.01000\tTime 0.095 (0.102)\tData 0.004 (0.013)\tLoss 1.9620 (1.9860)\tPrec@1 89.844 (89.639)\tPrec@5 98.828 (99.378)\n",
            "Epoch: [23][200/329], lr: 0.01000\tTime 0.111 (0.101)\tData 0.007 (0.013)\tLoss 1.7750 (1.9867)\tPrec@1 91.406 (89.644)\tPrec@5 100.000 (99.380)\n",
            "Epoch: [23][210/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.007 (0.013)\tLoss 2.2463 (1.9838)\tPrec@1 87.500 (89.668)\tPrec@5 98.828 (99.382)\n",
            "Epoch: [23][220/329], lr: 0.01000\tTime 0.089 (0.100)\tData 0.000 (0.012)\tLoss 2.3384 (1.9864)\tPrec@1 87.500 (89.671)\tPrec@5 99.219 (99.380)\n",
            "Epoch: [23][230/329], lr: 0.01000\tTime 0.083 (0.100)\tData 0.005 (0.012)\tLoss 2.1396 (1.9878)\tPrec@1 88.672 (89.659)\tPrec@5 100.000 (99.383)\n",
            "Epoch: [23][240/329], lr: 0.01000\tTime 0.073 (0.099)\tData 0.000 (0.012)\tLoss 2.6282 (1.9837)\tPrec@1 87.109 (89.685)\tPrec@5 98.438 (99.379)\n",
            "Epoch: [23][250/329], lr: 0.01000\tTime 0.077 (0.099)\tData 0.002 (0.012)\tLoss 1.6516 (1.9844)\tPrec@1 91.406 (89.690)\tPrec@5 99.219 (99.388)\n",
            "Epoch: [23][260/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.000 (0.012)\tLoss 1.9041 (1.9774)\tPrec@1 90.234 (89.717)\tPrec@5 99.219 (99.385)\n",
            "Epoch: [23][270/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.011 (0.011)\tLoss 1.9856 (1.9758)\tPrec@1 90.625 (89.727)\tPrec@5 98.438 (99.385)\n",
            "Epoch: [23][280/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.000 (0.011)\tLoss 1.8814 (1.9766)\tPrec@1 91.016 (89.712)\tPrec@5 98.438 (99.381)\n",
            "Epoch: [23][290/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.010 (0.011)\tLoss 1.9912 (1.9771)\tPrec@1 89.844 (89.710)\tPrec@5 99.609 (99.383)\n",
            "Epoch: [23][300/329], lr: 0.01000\tTime 0.094 (0.098)\tData 0.000 (0.011)\tLoss 1.7918 (1.9750)\tPrec@1 89.844 (89.722)\tPrec@5 100.000 (99.387)\n",
            "Epoch: [23][310/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.000 (0.011)\tLoss 2.0766 (1.9729)\tPrec@1 89.062 (89.724)\tPrec@5 98.828 (99.387)\n",
            "Epoch: [23][320/329], lr: 0.01000\tTime 0.103 (0.097)\tData 0.059 (0.011)\tLoss 1.7030 (1.9704)\tPrec@1 91.016 (89.737)\tPrec@5 100.000 (99.385)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 8.0323 (8.0323)\tPrec@1 66.000 (66.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.032 (0.059)\tLoss 6.8343 (8.0993)\tPrec@1 67.000 (63.455)\tPrec@5 97.000 (96.091)\n",
            "Test: [20/100]\tTime 0.025 (0.043)\tLoss 6.3862 (8.1392)\tPrec@1 72.000 (63.429)\tPrec@5 95.000 (96.048)\n",
            "Test: [30/100]\tTime 0.041 (0.038)\tLoss 7.6910 (8.1299)\tPrec@1 63.000 (63.323)\tPrec@5 94.000 (95.839)\n",
            "Test: [40/100]\tTime 0.031 (0.034)\tLoss 7.9486 (8.2128)\tPrec@1 65.000 (63.073)\tPrec@5 95.000 (95.854)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 7.4572 (8.1239)\tPrec@1 69.000 (63.627)\tPrec@5 95.000 (95.804)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 8.2964 (8.1680)\tPrec@1 59.000 (63.393)\tPrec@5 98.000 (95.885)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 6.7904 (8.1635)\tPrec@1 70.000 (63.296)\tPrec@5 99.000 (95.944)\n",
            "Test: [80/100]\tTime 0.035 (0.030)\tLoss 7.3985 (8.1065)\tPrec@1 64.000 (63.444)\tPrec@5 96.000 (95.988)\n",
            "Test: [90/100]\tTime 0.041 (0.028)\tLoss 9.2437 (8.1615)\tPrec@1 53.000 (63.099)\tPrec@5 96.000 (95.868)\n",
            "val Results: Prec@1 63.120 Prec@5 95.910 Loss 8.15731\n",
            "val Class Accuracy: [0.706,0.967,0.793,0.751,0.486,0.400,0.651,0.679,0.452,0.427]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [24][0/329], lr: 0.01000\tTime 0.713 (0.713)\tData 0.619 (0.619)\tLoss 2.1675 (2.1675)\tPrec@1 86.328 (86.328)\tPrec@5 98.047 (98.047)\n",
            "Epoch: [24][10/329], lr: 0.01000\tTime 0.094 (0.155)\tData 0.000 (0.061)\tLoss 4.4968 (4.6551)\tPrec@1 75.000 (73.793)\tPrec@5 95.703 (94.070)\n",
            "Epoch: [24][20/329], lr: 0.01000\tTime 0.100 (0.125)\tData 0.007 (0.035)\tLoss 3.4997 (4.1608)\tPrec@1 80.859 (76.823)\tPrec@5 97.266 (95.685)\n",
            "Epoch: [24][30/329], lr: 0.01000\tTime 0.105 (0.113)\tData 0.000 (0.025)\tLoss 3.6204 (3.7861)\tPrec@1 80.859 (79.221)\tPrec@5 96.875 (96.522)\n",
            "Epoch: [24][40/329], lr: 0.01000\tTime 0.141 (0.109)\tData 0.004 (0.020)\tLoss 2.6260 (3.5617)\tPrec@1 85.156 (80.440)\tPrec@5 99.219 (97.037)\n",
            "Epoch: [24][50/329], lr: 0.01000\tTime 0.124 (0.106)\tData 0.000 (0.017)\tLoss 2.9690 (3.3390)\tPrec@1 83.203 (81.847)\tPrec@5 99.219 (97.480)\n",
            "Epoch: [24][60/329], lr: 0.01000\tTime 0.069 (0.103)\tData 0.006 (0.015)\tLoss 2.4854 (3.2059)\tPrec@1 87.500 (82.601)\tPrec@5 98.438 (97.707)\n",
            "Epoch: [24][70/329], lr: 0.01000\tTime 0.071 (0.102)\tData 0.006 (0.014)\tLoss 2.5420 (3.1024)\tPrec@1 86.328 (83.181)\tPrec@5 99.219 (97.898)\n",
            "Epoch: [24][80/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.000 (0.013)\tLoss 2.7217 (3.0040)\tPrec@1 87.109 (83.791)\tPrec@5 99.609 (98.076)\n",
            "Epoch: [24][90/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.000 (0.013)\tLoss 1.8060 (2.9236)\tPrec@1 91.797 (84.263)\tPrec@5 99.219 (98.189)\n",
            "Epoch: [24][100/329], lr: 0.01000\tTime 0.077 (0.099)\tData 0.000 (0.012)\tLoss 2.0522 (2.8576)\tPrec@1 89.062 (84.653)\tPrec@5 100.000 (98.294)\n",
            "Epoch: [24][110/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.000 (0.011)\tLoss 2.0717 (2.7927)\tPrec@1 87.891 (85.026)\tPrec@5 100.000 (98.392)\n",
            "Epoch: [24][120/329], lr: 0.01000\tTime 0.068 (0.097)\tData 0.000 (0.011)\tLoss 2.2624 (2.7375)\tPrec@1 88.281 (85.366)\tPrec@5 99.219 (98.447)\n",
            "Epoch: [24][130/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.005 (0.011)\tLoss 2.1489 (2.6836)\tPrec@1 89.453 (85.705)\tPrec@5 99.219 (98.527)\n",
            "Epoch: [24][140/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.000 (0.010)\tLoss 2.6202 (2.6419)\tPrec@1 85.156 (85.940)\tPrec@5 99.219 (98.568)\n",
            "Epoch: [24][150/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.006 (0.010)\tLoss 2.3530 (2.6205)\tPrec@1 89.062 (86.075)\tPrec@5 98.828 (98.590)\n",
            "Epoch: [24][160/329], lr: 0.01000\tTime 0.072 (0.095)\tData 0.009 (0.010)\tLoss 1.9345 (2.6094)\tPrec@1 89.453 (86.173)\tPrec@5 98.828 (98.641)\n",
            "Epoch: [24][170/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.005 (0.010)\tLoss 2.3506 (2.5833)\tPrec@1 88.281 (86.337)\tPrec@5 98.828 (98.671)\n",
            "Epoch: [24][180/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.007 (0.010)\tLoss 2.1083 (2.5637)\tPrec@1 89.453 (86.455)\tPrec@5 99.609 (98.699)\n",
            "Epoch: [24][190/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.000 (0.010)\tLoss 2.2015 (2.5417)\tPrec@1 89.062 (86.582)\tPrec@5 100.000 (98.738)\n",
            "Epoch: [24][200/329], lr: 0.01000\tTime 0.108 (0.097)\tData 0.036 (0.010)\tLoss 2.3624 (2.5161)\tPrec@1 87.891 (86.717)\tPrec@5 98.828 (98.758)\n",
            "Epoch: [24][210/329], lr: 0.01000\tTime 0.173 (0.099)\tData 0.060 (0.011)\tLoss 2.4448 (2.5002)\tPrec@1 85.938 (86.789)\tPrec@5 98.828 (98.787)\n",
            "Epoch: [24][220/329], lr: 0.01000\tTime 0.066 (0.100)\tData 0.003 (0.011)\tLoss 1.9878 (2.4798)\tPrec@1 88.672 (86.880)\tPrec@5 99.219 (98.810)\n",
            "Epoch: [24][230/329], lr: 0.01000\tTime 0.108 (0.100)\tData 0.005 (0.011)\tLoss 3.1421 (2.4723)\tPrec@1 84.766 (86.920)\tPrec@5 99.609 (98.826)\n",
            "Epoch: [24][240/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.004 (0.010)\tLoss 2.4111 (2.4615)\tPrec@1 84.766 (86.951)\tPrec@5 99.219 (98.848)\n",
            "Epoch: [24][250/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.000 (0.010)\tLoss 1.2905 (2.4483)\tPrec@1 93.750 (87.036)\tPrec@5 100.000 (98.869)\n",
            "Epoch: [24][260/329], lr: 0.01000\tTime 0.092 (0.099)\tData 0.000 (0.010)\tLoss 2.4855 (2.4375)\tPrec@1 85.547 (87.088)\tPrec@5 99.609 (98.897)\n",
            "Epoch: [24][270/329], lr: 0.01000\tTime 0.106 (0.099)\tData 0.004 (0.010)\tLoss 2.5912 (2.4248)\tPrec@1 87.500 (87.154)\tPrec@5 99.219 (98.919)\n",
            "Epoch: [24][280/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.005 (0.010)\tLoss 2.0417 (2.4106)\tPrec@1 89.844 (87.255)\tPrec@5 99.219 (98.935)\n",
            "Epoch: [24][290/329], lr: 0.01000\tTime 0.065 (0.098)\tData 0.005 (0.010)\tLoss 2.3871 (2.3959)\tPrec@1 87.891 (87.358)\tPrec@5 98.828 (98.952)\n",
            "Epoch: [24][300/329], lr: 0.01000\tTime 0.079 (0.098)\tData 0.000 (0.010)\tLoss 1.9903 (2.3852)\tPrec@1 89.453 (87.421)\tPrec@5 98.828 (98.959)\n",
            "Epoch: [24][310/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.006 (0.010)\tLoss 1.6299 (2.3809)\tPrec@1 90.625 (87.438)\tPrec@5 98.828 (98.968)\n",
            "Epoch: [24][320/329], lr: 0.01000\tTime 0.120 (0.098)\tData 0.070 (0.010)\tLoss 1.9066 (2.3720)\tPrec@1 89.844 (87.493)\tPrec@5 99.219 (98.979)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 7.2103 (7.2103)\tPrec@1 66.000 (66.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.054)\tLoss 5.7929 (7.0356)\tPrec@1 72.000 (67.182)\tPrec@5 98.000 (97.818)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 6.2459 (7.0801)\tPrec@1 69.000 (67.000)\tPrec@5 99.000 (97.381)\n",
            "Test: [30/100]\tTime 0.017 (0.034)\tLoss 6.8533 (7.0732)\tPrec@1 69.000 (67.097)\tPrec@5 96.000 (97.065)\n",
            "Test: [40/100]\tTime 0.024 (0.032)\tLoss 7.5133 (7.0582)\tPrec@1 61.000 (67.293)\tPrec@5 97.000 (97.195)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 6.5900 (7.0132)\tPrec@1 66.000 (67.529)\tPrec@5 97.000 (97.176)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 7.6424 (7.0959)\tPrec@1 64.000 (67.115)\tPrec@5 96.000 (97.098)\n",
            "Test: [70/100]\tTime 0.013 (0.029)\tLoss 7.1242 (7.1196)\tPrec@1 71.000 (67.141)\tPrec@5 96.000 (97.070)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 5.7375 (7.0537)\tPrec@1 76.000 (67.383)\tPrec@5 96.000 (97.074)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 6.0052 (7.1092)\tPrec@1 73.000 (67.154)\tPrec@5 96.000 (97.044)\n",
            "val Results: Prec@1 67.410 Prec@5 97.110 Loss 7.06491\n",
            "val Class Accuracy: [0.895,0.980,0.910,0.714,0.369,0.504,0.517,0.664,0.502,0.686]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [25][0/329], lr: 0.01000\tTime 0.562 (0.562)\tData 0.481 (0.481)\tLoss 2.4805 (2.4805)\tPrec@1 86.719 (86.719)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [25][10/329], lr: 0.01000\tTime 0.098 (0.135)\tData 0.000 (0.051)\tLoss 2.1101 (3.1211)\tPrec@1 89.453 (83.487)\tPrec@5 98.828 (98.224)\n",
            "Epoch: [25][20/329], lr: 0.01000\tTime 0.112 (0.118)\tData 0.025 (0.031)\tLoss 2.4358 (2.9840)\tPrec@1 88.672 (84.375)\tPrec@5 99.219 (98.214)\n",
            "Epoch: [25][30/329], lr: 0.01000\tTime 0.075 (0.110)\tData 0.003 (0.022)\tLoss 1.9545 (2.7946)\tPrec@1 89.062 (85.459)\tPrec@5 98.438 (98.475)\n",
            "Epoch: [25][40/329], lr: 0.01000\tTime 0.090 (0.105)\tData 0.000 (0.019)\tLoss 2.0985 (2.6518)\tPrec@1 88.672 (86.195)\tPrec@5 99.609 (98.657)\n",
            "Epoch: [25][50/329], lr: 0.01000\tTime 0.099 (0.102)\tData 0.015 (0.016)\tLoss 2.0436 (2.5646)\tPrec@1 88.281 (86.535)\tPrec@5 99.609 (98.775)\n",
            "Epoch: [25][60/329], lr: 0.01000\tTime 0.103 (0.101)\tData 0.007 (0.015)\tLoss 2.1287 (2.4888)\tPrec@1 88.281 (86.872)\tPrec@5 98.828 (98.835)\n",
            "Epoch: [25][70/329], lr: 0.01000\tTime 0.092 (0.099)\tData 0.004 (0.014)\tLoss 2.0641 (2.4472)\tPrec@1 90.625 (87.148)\tPrec@5 100.000 (98.867)\n",
            "Epoch: [25][80/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.010 (0.013)\tLoss 1.9904 (2.3805)\tPrec@1 91.797 (87.524)\tPrec@5 99.219 (98.944)\n",
            "Epoch: [25][90/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.000 (0.012)\tLoss 1.8492 (2.3203)\tPrec@1 91.797 (87.882)\tPrec@5 99.219 (99.000)\n",
            "Epoch: [25][100/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.008 (0.011)\tLoss 2.0902 (2.3011)\tPrec@1 87.891 (88.045)\tPrec@5 99.609 (99.010)\n",
            "Epoch: [25][110/329], lr: 0.01000\tTime 0.106 (0.096)\tData 0.000 (0.011)\tLoss 2.7335 (2.2782)\tPrec@1 85.156 (88.169)\tPrec@5 99.609 (99.036)\n",
            "Epoch: [25][120/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.000 (0.011)\tLoss 2.2255 (2.2524)\tPrec@1 88.672 (88.314)\tPrec@5 99.609 (99.061)\n",
            "Epoch: [25][130/329], lr: 0.01000\tTime 0.075 (0.095)\tData 0.001 (0.010)\tLoss 1.7959 (2.2168)\tPrec@1 90.234 (88.544)\tPrec@5 99.219 (99.067)\n",
            "Epoch: [25][140/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.002 (0.010)\tLoss 1.8549 (2.2043)\tPrec@1 91.016 (88.611)\tPrec@5 99.609 (99.086)\n",
            "Epoch: [25][150/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.000 (0.010)\tLoss 1.5919 (2.1788)\tPrec@1 92.578 (88.760)\tPrec@5 99.219 (99.108)\n",
            "Epoch: [25][160/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.007 (0.010)\tLoss 2.1527 (2.1753)\tPrec@1 89.453 (88.745)\tPrec@5 98.047 (99.122)\n",
            "Epoch: [25][170/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.011 (0.010)\tLoss 1.7689 (2.1619)\tPrec@1 91.406 (88.800)\tPrec@5 99.609 (99.130)\n",
            "Epoch: [25][180/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.000 (0.009)\tLoss 1.8744 (2.1533)\tPrec@1 89.062 (88.845)\tPrec@5 99.609 (99.150)\n",
            "Epoch: [25][190/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.000 (0.009)\tLoss 1.8410 (2.1391)\tPrec@1 90.234 (88.899)\tPrec@5 99.609 (99.161)\n",
            "Epoch: [25][200/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.009)\tLoss 1.4482 (2.1266)\tPrec@1 91.406 (88.983)\tPrec@5 99.609 (99.180)\n",
            "Epoch: [25][210/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.009)\tLoss 2.2749 (2.1206)\tPrec@1 88.281 (89.016)\tPrec@5 98.828 (99.180)\n",
            "Epoch: [25][220/329], lr: 0.01000\tTime 0.070 (0.092)\tData 0.012 (0.009)\tLoss 2.1983 (2.1087)\tPrec@1 88.672 (89.094)\tPrec@5 99.609 (99.198)\n",
            "Epoch: [25][230/329], lr: 0.01000\tTime 0.114 (0.092)\tData 0.009 (0.009)\tLoss 2.5443 (2.1092)\tPrec@1 85.938 (89.101)\tPrec@5 99.609 (99.198)\n",
            "Epoch: [25][240/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.000 (0.009)\tLoss 2.1994 (2.1067)\tPrec@1 88.281 (89.113)\tPrec@5 100.000 (99.203)\n",
            "Epoch: [25][250/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.000 (0.009)\tLoss 2.4272 (2.1040)\tPrec@1 86.719 (89.114)\tPrec@5 98.828 (99.209)\n",
            "Epoch: [25][260/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.006 (0.009)\tLoss 1.7505 (2.0982)\tPrec@1 91.016 (89.149)\tPrec@5 98.828 (99.220)\n",
            "Epoch: [25][270/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.000 (0.008)\tLoss 1.9167 (2.0907)\tPrec@1 89.453 (89.197)\tPrec@5 99.609 (99.227)\n",
            "Epoch: [25][280/329], lr: 0.01000\tTime 0.115 (0.094)\tData 0.000 (0.008)\tLoss 2.1269 (2.0876)\tPrec@1 89.062 (89.213)\tPrec@5 98.828 (99.228)\n",
            "Epoch: [25][290/329], lr: 0.01000\tTime 0.127 (0.095)\tData 0.000 (0.009)\tLoss 1.6021 (2.0849)\tPrec@1 92.188 (89.226)\tPrec@5 99.219 (99.225)\n",
            "Epoch: [25][300/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.000 (0.009)\tLoss 1.8729 (2.0821)\tPrec@1 88.672 (89.227)\tPrec@5 99.219 (99.225)\n",
            "Epoch: [25][310/329], lr: 0.01000\tTime 0.102 (0.096)\tData 0.008 (0.009)\tLoss 1.9715 (2.0802)\tPrec@1 89.844 (89.221)\tPrec@5 98.438 (99.230)\n",
            "Epoch: [25][320/329], lr: 0.01000\tTime 0.138 (0.096)\tData 0.082 (0.009)\tLoss 1.9410 (2.0784)\tPrec@1 89.844 (89.237)\tPrec@5 99.609 (99.230)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 7.5692 (7.5692)\tPrec@1 64.000 (64.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.044 (0.060)\tLoss 6.1141 (6.8845)\tPrec@1 70.000 (68.000)\tPrec@5 100.000 (97.000)\n",
            "Test: [20/100]\tTime 0.025 (0.043)\tLoss 5.4542 (6.6849)\tPrec@1 74.000 (69.190)\tPrec@5 97.000 (96.714)\n",
            "Test: [30/100]\tTime 0.021 (0.038)\tLoss 6.0690 (6.6319)\tPrec@1 72.000 (69.194)\tPrec@5 97.000 (96.806)\n",
            "Test: [40/100]\tTime 0.029 (0.035)\tLoss 6.6032 (6.6171)\tPrec@1 72.000 (69.390)\tPrec@5 94.000 (96.707)\n",
            "Test: [50/100]\tTime 0.030 (0.033)\tLoss 7.8479 (6.6311)\tPrec@1 62.000 (69.392)\tPrec@5 96.000 (96.843)\n",
            "Test: [60/100]\tTime 0.017 (0.032)\tLoss 6.4123 (6.6993)\tPrec@1 69.000 (68.902)\tPrec@5 99.000 (96.934)\n",
            "Test: [70/100]\tTime 0.020 (0.031)\tLoss 5.7852 (6.6965)\tPrec@1 75.000 (68.972)\tPrec@5 98.000 (97.014)\n",
            "Test: [80/100]\tTime 0.026 (0.030)\tLoss 6.4330 (6.6913)\tPrec@1 72.000 (69.062)\tPrec@5 99.000 (97.025)\n",
            "Test: [90/100]\tTime 0.012 (0.029)\tLoss 7.4317 (6.7262)\tPrec@1 62.000 (68.934)\tPrec@5 97.000 (96.945)\n",
            "val Results: Prec@1 69.020 Prec@5 96.970 Loss 6.71364\n",
            "val Class Accuracy: [0.784,0.951,0.847,0.675,0.695,0.755,0.497,0.455,0.862,0.381]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [26][0/329], lr: 0.01000\tTime 0.620 (0.620)\tData 0.535 (0.535)\tLoss 2.0430 (2.0430)\tPrec@1 89.453 (89.453)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [26][10/329], lr: 0.01000\tTime 0.080 (0.145)\tData 0.003 (0.056)\tLoss 2.0637 (2.6205)\tPrec@1 88.672 (86.399)\tPrec@5 99.609 (99.148)\n",
            "Epoch: [26][20/329], lr: 0.01000\tTime 0.080 (0.120)\tData 0.000 (0.032)\tLoss 2.2963 (2.4774)\tPrec@1 87.109 (86.961)\tPrec@5 99.219 (99.051)\n",
            "Epoch: [26][30/329], lr: 0.01000\tTime 0.068 (0.112)\tData 0.000 (0.024)\tLoss 2.2635 (2.4010)\tPrec@1 87.500 (87.487)\tPrec@5 98.438 (99.017)\n",
            "Epoch: [26][40/329], lr: 0.01000\tTime 0.102 (0.106)\tData 0.000 (0.019)\tLoss 2.0445 (2.3381)\tPrec@1 90.234 (87.843)\tPrec@5 99.219 (99.057)\n",
            "Epoch: [26][50/329], lr: 0.01000\tTime 0.080 (0.102)\tData 0.014 (0.016)\tLoss 2.4576 (2.3229)\tPrec@1 85.938 (87.868)\tPrec@5 98.828 (99.050)\n",
            "Epoch: [26][60/329], lr: 0.01000\tTime 0.100 (0.100)\tData 0.000 (0.015)\tLoss 2.1639 (2.2843)\tPrec@1 87.891 (88.089)\tPrec@5 99.609 (99.116)\n",
            "Epoch: [26][70/329], lr: 0.01000\tTime 0.069 (0.098)\tData 0.001 (0.014)\tLoss 2.0454 (2.2306)\tPrec@1 89.062 (88.347)\tPrec@5 99.609 (99.180)\n",
            "Epoch: [26][80/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.010 (0.013)\tLoss 1.8676 (2.2137)\tPrec@1 89.844 (88.416)\tPrec@5 99.219 (99.243)\n",
            "Epoch: [26][90/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.000 (0.012)\tLoss 2.0252 (2.1981)\tPrec@1 88.281 (88.470)\tPrec@5 98.828 (99.253)\n",
            "Epoch: [26][100/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.005 (0.011)\tLoss 1.9919 (2.1693)\tPrec@1 89.844 (88.641)\tPrec@5 99.219 (99.273)\n",
            "Epoch: [26][110/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.005 (0.011)\tLoss 2.4159 (2.1492)\tPrec@1 87.500 (88.735)\tPrec@5 99.219 (99.272)\n",
            "Epoch: [26][120/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.000 (0.011)\tLoss 2.0251 (2.1327)\tPrec@1 90.234 (88.814)\tPrec@5 98.828 (99.280)\n",
            "Epoch: [26][130/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.001 (0.010)\tLoss 2.0082 (2.1182)\tPrec@1 90.625 (88.887)\tPrec@5 99.219 (99.266)\n",
            "Epoch: [26][140/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.011 (0.010)\tLoss 2.2947 (2.1057)\tPrec@1 88.672 (88.960)\tPrec@5 98.828 (99.274)\n",
            "Epoch: [26][150/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.005 (0.010)\tLoss 1.4395 (2.0953)\tPrec@1 93.750 (89.021)\tPrec@5 100.000 (99.283)\n",
            "Epoch: [26][160/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.010)\tLoss 1.6197 (2.0849)\tPrec@1 91.406 (89.084)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [26][170/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.000 (0.010)\tLoss 1.9934 (2.0750)\tPrec@1 90.625 (89.136)\tPrec@5 100.000 (99.310)\n",
            "Epoch: [26][180/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.006 (0.009)\tLoss 1.7397 (2.0593)\tPrec@1 90.234 (89.218)\tPrec@5 100.000 (99.322)\n",
            "Epoch: [26][190/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.007 (0.009)\tLoss 2.1795 (2.0490)\tPrec@1 88.672 (89.259)\tPrec@5 99.219 (99.331)\n",
            "Epoch: [26][200/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.009 (0.009)\tLoss 2.4504 (2.0440)\tPrec@1 86.328 (89.270)\tPrec@5 99.609 (99.331)\n",
            "Epoch: [26][210/329], lr: 0.01000\tTime 0.118 (0.092)\tData 0.007 (0.009)\tLoss 1.9347 (2.0398)\tPrec@1 89.844 (89.305)\tPrec@5 99.609 (99.332)\n",
            "Epoch: [26][220/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.008 (0.009)\tLoss 2.1272 (2.0318)\tPrec@1 89.844 (89.367)\tPrec@5 98.828 (99.330)\n",
            "Epoch: [26][230/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.001 (0.009)\tLoss 1.5454 (2.0279)\tPrec@1 92.188 (89.402)\tPrec@5 100.000 (99.320)\n",
            "Epoch: [26][240/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.002 (0.009)\tLoss 1.5315 (2.0280)\tPrec@1 91.406 (89.392)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [26][250/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.005 (0.009)\tLoss 1.4404 (2.0175)\tPrec@1 93.359 (89.461)\tPrec@5 98.828 (99.325)\n",
            "Epoch: [26][260/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.005 (0.009)\tLoss 2.0820 (2.0132)\tPrec@1 89.062 (89.504)\tPrec@5 98.828 (99.325)\n",
            "Epoch: [26][270/329], lr: 0.01000\tTime 0.104 (0.092)\tData 0.004 (0.009)\tLoss 1.7939 (2.0130)\tPrec@1 90.234 (89.509)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [26][280/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.000 (0.008)\tLoss 2.0151 (2.0146)\tPrec@1 90.625 (89.507)\tPrec@5 99.219 (99.320)\n",
            "Epoch: [26][290/329], lr: 0.01000\tTime 0.109 (0.092)\tData 0.004 (0.008)\tLoss 2.1339 (2.0150)\tPrec@1 86.719 (89.488)\tPrec@5 99.609 (99.321)\n",
            "Epoch: [26][300/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.000 (0.008)\tLoss 1.8437 (2.0194)\tPrec@1 91.406 (89.469)\tPrec@5 100.000 (99.317)\n",
            "Epoch: [26][310/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.007 (0.008)\tLoss 1.8889 (2.0197)\tPrec@1 90.625 (89.464)\tPrec@5 98.438 (99.322)\n",
            "Epoch: [26][320/329], lr: 0.01000\tTime 0.113 (0.092)\tData 0.073 (0.008)\tLoss 1.7129 (2.0162)\tPrec@1 91.016 (89.476)\tPrec@5 99.219 (99.322)\n",
            "Test: [0/100]\tTime 0.387 (0.387)\tLoss 9.3219 (9.3219)\tPrec@1 54.000 (54.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.029 (0.060)\tLoss 7.1058 (8.7557)\tPrec@1 66.000 (58.818)\tPrec@5 90.000 (92.545)\n",
            "Test: [20/100]\tTime 0.018 (0.042)\tLoss 8.5137 (8.5320)\tPrec@1 59.000 (60.095)\tPrec@5 98.000 (93.048)\n",
            "Test: [30/100]\tTime 0.011 (0.036)\tLoss 7.7423 (8.5426)\tPrec@1 68.000 (60.710)\tPrec@5 95.000 (93.129)\n",
            "Test: [40/100]\tTime 0.018 (0.032)\tLoss 8.1822 (8.5768)\tPrec@1 65.000 (60.585)\tPrec@5 95.000 (93.146)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 8.2587 (8.5422)\tPrec@1 59.000 (60.451)\tPrec@5 94.000 (93.255)\n",
            "Test: [60/100]\tTime 0.061 (0.034)\tLoss 7.0001 (8.5829)\tPrec@1 65.000 (60.082)\tPrec@5 93.000 (93.197)\n",
            "Test: [70/100]\tTime 0.039 (0.034)\tLoss 8.1668 (8.6330)\tPrec@1 64.000 (59.831)\tPrec@5 93.000 (93.085)\n",
            "Test: [80/100]\tTime 0.029 (0.035)\tLoss 9.5846 (8.6072)\tPrec@1 57.000 (60.049)\tPrec@5 89.000 (93.062)\n",
            "Test: [90/100]\tTime 0.032 (0.036)\tLoss 9.1923 (8.6901)\tPrec@1 57.000 (59.780)\tPrec@5 94.000 (92.824)\n",
            "val Results: Prec@1 59.990 Prec@5 92.730 Loss 8.69094\n",
            "val Class Accuracy: [0.865,0.596,0.664,0.660,0.927,0.671,0.512,0.464,0.307,0.333]\n",
            "Best Prec@1: 69.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [27][0/329], lr: 0.01000\tTime 0.982 (0.982)\tData 0.808 (0.808)\tLoss 2.3725 (2.3725)\tPrec@1 86.719 (86.719)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [27][10/329], lr: 0.01000\tTime 0.079 (0.201)\tData 0.000 (0.078)\tLoss 4.0004 (4.2927)\tPrec@1 78.125 (75.923)\tPrec@5 97.266 (96.094)\n",
            "Epoch: [27][20/329], lr: 0.01000\tTime 0.099 (0.151)\tData 0.005 (0.044)\tLoss 3.3290 (3.9615)\tPrec@1 81.641 (77.846)\tPrec@5 96.875 (96.856)\n",
            "Epoch: [27][30/329], lr: 0.01000\tTime 0.110 (0.132)\tData 0.000 (0.031)\tLoss 3.2958 (3.6626)\tPrec@1 83.203 (79.902)\tPrec@5 99.219 (97.467)\n",
            "Epoch: [27][40/329], lr: 0.01000\tTime 0.103 (0.123)\tData 0.003 (0.025)\tLoss 1.9174 (3.4857)\tPrec@1 91.406 (80.983)\tPrec@5 98.828 (97.771)\n",
            "Epoch: [27][50/329], lr: 0.01000\tTime 0.086 (0.117)\tData 0.003 (0.021)\tLoss 2.3146 (3.3189)\tPrec@1 87.891 (81.947)\tPrec@5 99.219 (98.085)\n",
            "Epoch: [27][60/329], lr: 0.01000\tTime 0.084 (0.113)\tData 0.000 (0.018)\tLoss 1.6882 (3.1594)\tPrec@1 91.797 (82.877)\tPrec@5 98.828 (98.226)\n",
            "Epoch: [27][70/329], lr: 0.01000\tTime 0.084 (0.111)\tData 0.007 (0.017)\tLoss 2.5892 (3.0439)\tPrec@1 85.156 (83.583)\tPrec@5 98.828 (98.371)\n",
            "Epoch: [27][80/329], lr: 0.01000\tTime 0.105 (0.108)\tData 0.009 (0.016)\tLoss 2.2533 (2.9321)\tPrec@1 87.500 (84.192)\tPrec@5 99.219 (98.505)\n",
            "Epoch: [27][90/329], lr: 0.01000\tTime 0.067 (0.106)\tData 0.000 (0.015)\tLoss 2.5677 (2.8431)\tPrec@1 85.547 (84.710)\tPrec@5 99.219 (98.592)\n",
            "Epoch: [27][100/329], lr: 0.01000\tTime 0.055 (0.104)\tData 0.006 (0.014)\tLoss 2.2438 (2.7850)\tPrec@1 88.281 (85.056)\tPrec@5 99.219 (98.631)\n",
            "Epoch: [27][110/329], lr: 0.01000\tTime 0.124 (0.103)\tData 0.000 (0.014)\tLoss 2.4096 (2.7250)\tPrec@1 87.109 (85.381)\tPrec@5 98.047 (98.680)\n",
            "Epoch: [27][120/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.005 (0.013)\tLoss 1.8606 (2.6657)\tPrec@1 91.406 (85.766)\tPrec@5 99.219 (98.744)\n",
            "Epoch: [27][130/329], lr: 0.01000\tTime 0.103 (0.101)\tData 0.007 (0.013)\tLoss 2.7121 (2.6426)\tPrec@1 85.938 (85.893)\tPrec@5 100.000 (98.766)\n",
            "Epoch: [27][140/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.004 (0.012)\tLoss 1.8204 (2.6141)\tPrec@1 89.844 (86.059)\tPrec@5 99.219 (98.787)\n",
            "Epoch: [27][150/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.005 (0.012)\tLoss 2.0463 (2.5779)\tPrec@1 91.016 (86.261)\tPrec@5 99.219 (98.820)\n",
            "Epoch: [27][160/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.005 (0.012)\tLoss 2.2256 (2.5448)\tPrec@1 87.500 (86.447)\tPrec@5 98.828 (98.857)\n",
            "Epoch: [27][170/329], lr: 0.01000\tTime 0.094 (0.098)\tData 0.007 (0.011)\tLoss 2.1322 (2.5202)\tPrec@1 88.672 (86.573)\tPrec@5 99.219 (98.888)\n",
            "Epoch: [27][180/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.005 (0.011)\tLoss 1.5158 (2.5025)\tPrec@1 93.359 (86.719)\tPrec@5 100.000 (98.895)\n",
            "Epoch: [27][190/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.003 (0.011)\tLoss 2.5191 (2.4757)\tPrec@1 85.547 (86.872)\tPrec@5 98.438 (98.914)\n",
            "Epoch: [27][200/329], lr: 0.01000\tTime 0.108 (0.097)\tData 0.007 (0.011)\tLoss 2.2338 (2.4593)\tPrec@1 89.062 (87.001)\tPrec@5 99.609 (98.941)\n",
            "Epoch: [27][210/329], lr: 0.01000\tTime 0.111 (0.097)\tData 0.003 (0.011)\tLoss 2.0339 (2.4436)\tPrec@1 89.453 (87.076)\tPrec@5 99.609 (98.971)\n",
            "Epoch: [27][220/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.008 (0.011)\tLoss 1.7633 (2.4252)\tPrec@1 92.578 (87.177)\tPrec@5 99.219 (98.985)\n",
            "Epoch: [27][230/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.005 (0.011)\tLoss 2.1460 (2.4098)\tPrec@1 89.062 (87.260)\tPrec@5 99.219 (99.004)\n",
            "Epoch: [27][240/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.005 (0.010)\tLoss 2.0288 (2.3978)\tPrec@1 88.281 (87.299)\tPrec@5 99.609 (99.029)\n",
            "Epoch: [27][250/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.012 (0.010)\tLoss 1.9854 (2.3831)\tPrec@1 89.453 (87.396)\tPrec@5 99.609 (99.041)\n",
            "Epoch: [27][260/329], lr: 0.01000\tTime 0.107 (0.096)\tData 0.000 (0.010)\tLoss 1.8278 (2.3672)\tPrec@1 90.234 (87.493)\tPrec@5 98.828 (99.047)\n",
            "Epoch: [27][270/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.010)\tLoss 2.4321 (2.3582)\tPrec@1 86.719 (87.545)\tPrec@5 98.438 (99.054)\n",
            "Epoch: [27][280/329], lr: 0.01000\tTime 0.108 (0.095)\tData 0.005 (0.010)\tLoss 1.5838 (2.3512)\tPrec@1 93.359 (87.576)\tPrec@5 99.609 (99.063)\n",
            "Epoch: [27][290/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.007 (0.010)\tLoss 1.8943 (2.3377)\tPrec@1 89.062 (87.653)\tPrec@5 99.609 (99.071)\n",
            "Epoch: [27][300/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.012 (0.010)\tLoss 1.7802 (2.3245)\tPrec@1 90.234 (87.731)\tPrec@5 98.828 (99.077)\n",
            "Epoch: [27][310/329], lr: 0.01000\tTime 0.073 (0.095)\tData 0.004 (0.010)\tLoss 2.1681 (2.3138)\tPrec@1 89.062 (87.796)\tPrec@5 99.219 (99.081)\n",
            "Epoch: [27][320/329], lr: 0.01000\tTime 0.117 (0.095)\tData 0.077 (0.010)\tLoss 1.7156 (2.3010)\tPrec@1 91.016 (87.861)\tPrec@5 100.000 (99.093)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 6.5094 (6.5094)\tPrec@1 71.000 (71.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.022 (0.055)\tLoss 5.0621 (6.5765)\tPrec@1 78.000 (71.182)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.026 (0.038)\tLoss 5.3056 (6.5906)\tPrec@1 74.000 (70.810)\tPrec@5 99.000 (97.667)\n",
            "Test: [30/100]\tTime 0.026 (0.035)\tLoss 6.4008 (6.6110)\tPrec@1 71.000 (70.645)\tPrec@5 93.000 (97.323)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 6.6312 (6.5744)\tPrec@1 72.000 (71.000)\tPrec@5 95.000 (97.122)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 6.9662 (6.5169)\tPrec@1 67.000 (71.176)\tPrec@5 97.000 (97.294)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 5.7378 (6.4994)\tPrec@1 77.000 (71.131)\tPrec@5 99.000 (97.377)\n",
            "Test: [70/100]\tTime 0.037 (0.030)\tLoss 6.3576 (6.4880)\tPrec@1 74.000 (71.352)\tPrec@5 95.000 (97.268)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 5.9073 (6.4481)\tPrec@1 74.000 (71.383)\tPrec@5 97.000 (97.321)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 6.7785 (6.5106)\tPrec@1 72.000 (71.099)\tPrec@5 99.000 (97.297)\n",
            "val Results: Prec@1 71.080 Prec@5 97.260 Loss 6.52221\n",
            "val Class Accuracy: [0.961,0.891,0.712,0.757,0.762,0.691,0.771,0.727,0.274,0.562]\n",
            "Best Prec@1: 71.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [28][0/329], lr: 0.01000\tTime 0.534 (0.534)\tData 0.447 (0.447)\tLoss 2.2869 (2.2869)\tPrec@1 87.500 (87.500)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [28][10/329], lr: 0.01000\tTime 0.091 (0.142)\tData 0.004 (0.048)\tLoss 2.4803 (2.8011)\tPrec@1 87.891 (85.724)\tPrec@5 98.828 (98.082)\n",
            "Epoch: [28][20/329], lr: 0.01000\tTime 0.073 (0.121)\tData 0.000 (0.028)\tLoss 2.0135 (2.6732)\tPrec@1 88.281 (85.993)\tPrec@5 99.219 (98.493)\n",
            "Epoch: [28][30/329], lr: 0.01000\tTime 0.094 (0.111)\tData 0.000 (0.020)\tLoss 2.0178 (2.5074)\tPrec@1 90.625 (86.832)\tPrec@5 99.219 (98.690)\n",
            "Epoch: [28][40/329], lr: 0.01000\tTime 0.082 (0.107)\tData 0.006 (0.017)\tLoss 1.9620 (2.4143)\tPrec@1 90.625 (87.414)\tPrec@5 99.609 (98.752)\n",
            "Epoch: [28][50/329], lr: 0.01000\tTime 0.071 (0.103)\tData 0.000 (0.015)\tLoss 2.0936 (2.3249)\tPrec@1 89.062 (87.883)\tPrec@5 99.219 (98.866)\n",
            "Epoch: [28][60/329], lr: 0.01000\tTime 0.101 (0.102)\tData 0.006 (0.014)\tLoss 1.7908 (2.2503)\tPrec@1 92.188 (88.262)\tPrec@5 99.609 (98.956)\n",
            "Epoch: [28][70/329], lr: 0.01000\tTime 0.135 (0.105)\tData 0.015 (0.013)\tLoss 2.0578 (2.2157)\tPrec@1 89.453 (88.479)\tPrec@5 99.219 (98.988)\n",
            "Epoch: [28][80/329], lr: 0.01000\tTime 0.116 (0.106)\tData 0.000 (0.011)\tLoss 1.9326 (2.1698)\tPrec@1 90.625 (88.764)\tPrec@5 99.219 (99.026)\n",
            "Epoch: [28][90/329], lr: 0.01000\tTime 0.119 (0.111)\tData 0.003 (0.015)\tLoss 1.9549 (2.1521)\tPrec@1 90.234 (88.822)\tPrec@5 98.828 (99.077)\n",
            "Epoch: [28][100/329], lr: 0.01000\tTime 0.090 (0.110)\tData 0.005 (0.015)\tLoss 1.9690 (2.1344)\tPrec@1 89.062 (88.923)\tPrec@5 97.656 (99.087)\n",
            "Epoch: [28][110/329], lr: 0.01000\tTime 0.091 (0.108)\tData 0.003 (0.015)\tLoss 2.4530 (2.1078)\tPrec@1 87.500 (89.094)\tPrec@5 99.219 (99.096)\n",
            "Epoch: [28][120/329], lr: 0.01000\tTime 0.130 (0.107)\tData 0.003 (0.014)\tLoss 1.3284 (2.0995)\tPrec@1 93.750 (89.156)\tPrec@5 99.609 (99.103)\n",
            "Epoch: [28][130/329], lr: 0.01000\tTime 0.102 (0.106)\tData 0.000 (0.013)\tLoss 2.4856 (2.0980)\tPrec@1 87.109 (89.161)\tPrec@5 98.438 (99.129)\n",
            "Epoch: [28][140/329], lr: 0.01000\tTime 0.096 (0.106)\tData 0.000 (0.013)\tLoss 1.9405 (2.0856)\tPrec@1 88.672 (89.223)\tPrec@5 99.609 (99.133)\n",
            "Epoch: [28][150/329], lr: 0.01000\tTime 0.089 (0.105)\tData 0.004 (0.013)\tLoss 2.0966 (2.0901)\tPrec@1 89.844 (89.192)\tPrec@5 99.609 (99.133)\n",
            "Epoch: [28][160/329], lr: 0.01000\tTime 0.088 (0.104)\tData 0.005 (0.012)\tLoss 2.1814 (2.0706)\tPrec@1 86.328 (89.278)\tPrec@5 99.219 (99.161)\n",
            "Epoch: [28][170/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.000 (0.012)\tLoss 2.1606 (2.0636)\tPrec@1 88.281 (89.314)\tPrec@5 99.609 (99.175)\n",
            "Epoch: [28][180/329], lr: 0.01000\tTime 0.075 (0.102)\tData 0.000 (0.012)\tLoss 1.9440 (2.0617)\tPrec@1 90.234 (89.337)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [28][190/329], lr: 0.01000\tTime 0.084 (0.101)\tData 0.000 (0.011)\tLoss 2.2244 (2.0543)\tPrec@1 87.891 (89.380)\tPrec@5 99.609 (99.196)\n",
            "Epoch: [28][200/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.012 (0.011)\tLoss 1.8095 (2.0518)\tPrec@1 91.406 (89.422)\tPrec@5 100.000 (99.203)\n",
            "Epoch: [28][210/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.001 (0.011)\tLoss 1.4912 (2.0448)\tPrec@1 92.188 (89.461)\tPrec@5 98.828 (99.209)\n",
            "Epoch: [28][220/329], lr: 0.01000\tTime 0.083 (0.100)\tData 0.006 (0.011)\tLoss 1.7435 (2.0394)\tPrec@1 90.625 (89.490)\tPrec@5 100.000 (99.217)\n",
            "Epoch: [28][230/329], lr: 0.01000\tTime 0.094 (0.100)\tData 0.007 (0.011)\tLoss 2.3999 (2.0440)\tPrec@1 86.328 (89.448)\tPrec@5 98.828 (99.229)\n",
            "Epoch: [28][240/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.013 (0.010)\tLoss 2.3323 (2.0389)\tPrec@1 87.891 (89.482)\tPrec@5 99.219 (99.224)\n",
            "Epoch: [28][250/329], lr: 0.01000\tTime 0.103 (0.099)\tData 0.007 (0.010)\tLoss 2.0199 (2.0340)\tPrec@1 89.453 (89.498)\tPrec@5 99.609 (99.227)\n",
            "Epoch: [28][260/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.007 (0.010)\tLoss 1.8690 (2.0309)\tPrec@1 89.844 (89.522)\tPrec@5 99.609 (99.231)\n",
            "Epoch: [28][270/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.011 (0.010)\tLoss 2.0372 (2.0317)\tPrec@1 89.453 (89.521)\tPrec@5 98.828 (99.226)\n",
            "Epoch: [28][280/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.000 (0.010)\tLoss 2.0758 (2.0291)\tPrec@1 89.062 (89.543)\tPrec@5 99.219 (99.231)\n",
            "Epoch: [28][290/329], lr: 0.01000\tTime 0.116 (0.098)\tData 0.005 (0.010)\tLoss 1.9327 (2.0248)\tPrec@1 89.062 (89.565)\tPrec@5 100.000 (99.232)\n",
            "Epoch: [28][300/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.007 (0.010)\tLoss 2.1267 (2.0248)\tPrec@1 89.062 (89.557)\tPrec@5 100.000 (99.240)\n",
            "Epoch: [28][310/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.004 (0.010)\tLoss 2.2944 (2.0249)\tPrec@1 88.281 (89.554)\tPrec@5 99.609 (99.241)\n",
            "Epoch: [28][320/329], lr: 0.01000\tTime 0.116 (0.097)\tData 0.077 (0.010)\tLoss 2.0512 (2.0237)\tPrec@1 87.109 (89.546)\tPrec@5 99.609 (99.252)\n",
            "Test: [0/100]\tTime 0.374 (0.374)\tLoss 5.2584 (5.2584)\tPrec@1 74.000 (74.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.032 (0.056)\tLoss 3.6466 (5.1497)\tPrec@1 85.000 (76.000)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 3.9591 (5.1172)\tPrec@1 81.000 (76.333)\tPrec@5 98.000 (97.429)\n",
            "Test: [30/100]\tTime 0.033 (0.036)\tLoss 5.4779 (5.1609)\tPrec@1 77.000 (76.032)\tPrec@5 97.000 (97.194)\n",
            "Test: [40/100]\tTime 0.013 (0.031)\tLoss 5.2843 (5.1966)\tPrec@1 75.000 (76.122)\tPrec@5 95.000 (96.927)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 4.9369 (5.1214)\tPrec@1 78.000 (76.333)\tPrec@5 92.000 (96.824)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 5.0925 (5.1896)\tPrec@1 76.000 (75.820)\tPrec@5 96.000 (96.820)\n",
            "Test: [70/100]\tTime 0.039 (0.029)\tLoss 5.2203 (5.1853)\tPrec@1 77.000 (75.873)\tPrec@5 98.000 (96.859)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 4.4704 (5.1544)\tPrec@1 79.000 (75.901)\tPrec@5 99.000 (96.938)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 4.8795 (5.2118)\tPrec@1 75.000 (75.549)\tPrec@5 99.000 (96.901)\n",
            "val Results: Prec@1 75.570 Prec@5 96.870 Loss 5.22671\n",
            "val Class Accuracy: [0.895,0.922,0.828,0.762,0.768,0.508,0.813,0.542,0.649,0.870]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [29][0/329], lr: 0.01000\tTime 0.666 (0.666)\tData 0.562 (0.562)\tLoss 1.4310 (1.4310)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [29][10/329], lr: 0.01000\tTime 0.069 (0.138)\tData 0.000 (0.055)\tLoss 2.6374 (1.9828)\tPrec@1 87.500 (89.773)\tPrec@5 99.609 (99.503)\n",
            "Epoch: [29][20/329], lr: 0.01000\tTime 0.098 (0.117)\tData 0.000 (0.031)\tLoss 1.9890 (2.0197)\tPrec@1 88.281 (89.397)\tPrec@5 99.609 (99.479)\n",
            "Epoch: [29][30/329], lr: 0.01000\tTime 0.085 (0.109)\tData 0.000 (0.024)\tLoss 2.2907 (1.9690)\tPrec@1 89.453 (89.882)\tPrec@5 99.609 (99.446)\n",
            "Epoch: [29][40/329], lr: 0.01000\tTime 0.093 (0.105)\tData 0.000 (0.019)\tLoss 1.7810 (1.9633)\tPrec@1 91.016 (89.882)\tPrec@5 98.047 (99.419)\n",
            "Epoch: [29][50/329], lr: 0.01000\tTime 0.086 (0.103)\tData 0.007 (0.016)\tLoss 2.4491 (1.9718)\tPrec@1 86.719 (89.805)\tPrec@5 99.609 (99.380)\n",
            "Epoch: [29][60/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.009 (0.015)\tLoss 2.1306 (1.9487)\tPrec@1 89.453 (89.850)\tPrec@5 99.219 (99.379)\n",
            "Epoch: [29][70/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.009 (0.014)\tLoss 2.3187 (1.9816)\tPrec@1 87.109 (89.657)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [29][80/329], lr: 0.01000\tTime 0.121 (0.098)\tData 0.006 (0.013)\tLoss 2.0278 (1.9823)\tPrec@1 88.672 (89.694)\tPrec@5 98.828 (99.296)\n",
            "Epoch: [29][90/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.000 (0.013)\tLoss 2.4019 (1.9728)\tPrec@1 87.109 (89.745)\tPrec@5 98.047 (99.317)\n",
            "Epoch: [29][100/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.004 (0.012)\tLoss 1.6194 (1.9560)\tPrec@1 91.797 (89.855)\tPrec@5 99.219 (99.312)\n",
            "Epoch: [29][110/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.007 (0.012)\tLoss 1.9422 (1.9621)\tPrec@1 89.844 (89.837)\tPrec@5 99.609 (99.300)\n",
            "Epoch: [29][120/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.011)\tLoss 1.6527 (1.9510)\tPrec@1 91.406 (89.886)\tPrec@5 100.000 (99.319)\n",
            "Epoch: [29][130/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.000 (0.011)\tLoss 2.3641 (1.9432)\tPrec@1 87.891 (89.936)\tPrec@5 99.609 (99.332)\n",
            "Epoch: [29][140/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.000 (0.010)\tLoss 1.4618 (1.9433)\tPrec@1 92.188 (89.894)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [29][150/329], lr: 0.01000\tTime 0.111 (0.097)\tData 0.003 (0.010)\tLoss 1.9167 (1.9461)\tPrec@1 89.844 (89.872)\tPrec@5 98.828 (99.322)\n",
            "Epoch: [29][160/329], lr: 0.01000\tTime 0.181 (0.099)\tData 0.087 (0.010)\tLoss 1.4365 (1.9369)\tPrec@1 92.188 (89.921)\tPrec@5 100.000 (99.335)\n",
            "Epoch: [29][170/329], lr: 0.01000\tTime 0.141 (0.102)\tData 0.026 (0.013)\tLoss 1.7324 (1.9355)\tPrec@1 91.797 (89.921)\tPrec@5 99.219 (99.328)\n",
            "Epoch: [29][180/329], lr: 0.01000\tTime 0.080 (0.102)\tData 0.000 (0.012)\tLoss 1.8502 (1.9351)\tPrec@1 90.625 (89.917)\tPrec@5 99.609 (99.333)\n",
            "Epoch: [29][190/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.005 (0.012)\tLoss 1.7161 (1.9274)\tPrec@1 91.016 (89.954)\tPrec@5 100.000 (99.339)\n",
            "Epoch: [29][200/329], lr: 0.01000\tTime 0.102 (0.101)\tData 0.004 (0.012)\tLoss 2.2265 (1.9193)\tPrec@1 88.281 (90.009)\tPrec@5 98.047 (99.337)\n",
            "Epoch: [29][210/329], lr: 0.01000\tTime 0.081 (0.101)\tData 0.000 (0.012)\tLoss 1.8396 (1.9165)\tPrec@1 89.844 (90.031)\tPrec@5 99.609 (99.335)\n",
            "Epoch: [29][220/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.000 (0.011)\tLoss 1.5719 (1.9137)\tPrec@1 91.016 (90.033)\tPrec@5 98.438 (99.325)\n",
            "Epoch: [29][230/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.007 (0.011)\tLoss 2.0091 (1.9064)\tPrec@1 90.234 (90.072)\tPrec@5 99.219 (99.332)\n",
            "Epoch: [29][240/329], lr: 0.01000\tTime 0.095 (0.099)\tData 0.007 (0.011)\tLoss 2.0851 (1.9130)\tPrec@1 89.844 (90.045)\tPrec@5 98.828 (99.331)\n",
            "Epoch: [29][250/329], lr: 0.01000\tTime 0.072 (0.099)\tData 0.009 (0.011)\tLoss 2.1631 (1.9103)\tPrec@1 89.062 (90.060)\tPrec@5 99.609 (99.320)\n",
            "Epoch: [29][260/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.000 (0.011)\tLoss 1.6969 (1.9043)\tPrec@1 90.625 (90.094)\tPrec@5 99.219 (99.329)\n",
            "Epoch: [29][270/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.005 (0.011)\tLoss 2.2581 (1.9047)\tPrec@1 88.281 (90.093)\tPrec@5 98.828 (99.327)\n",
            "Epoch: [29][280/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.006 (0.010)\tLoss 1.8793 (1.9040)\tPrec@1 90.234 (90.106)\tPrec@5 100.000 (99.337)\n",
            "Epoch: [29][290/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.004 (0.010)\tLoss 1.5460 (1.9072)\tPrec@1 92.578 (90.080)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [29][300/329], lr: 0.01000\tTime 0.116 (0.097)\tData 0.008 (0.010)\tLoss 2.0144 (1.9088)\tPrec@1 90.625 (90.077)\tPrec@5 98.828 (99.337)\n",
            "Epoch: [29][310/329], lr: 0.01000\tTime 0.104 (0.097)\tData 0.012 (0.010)\tLoss 1.6822 (1.9116)\tPrec@1 91.016 (90.059)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [29][320/329], lr: 0.01000\tTime 0.103 (0.097)\tData 0.060 (0.010)\tLoss 1.9839 (1.9138)\tPrec@1 88.672 (90.060)\tPrec@5 99.219 (99.338)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 6.3752 (6.3752)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.057)\tLoss 5.1438 (6.0443)\tPrec@1 74.000 (72.364)\tPrec@5 99.000 (97.455)\n",
            "Test: [20/100]\tTime 0.011 (0.040)\tLoss 4.6249 (5.7690)\tPrec@1 80.000 (73.952)\tPrec@5 99.000 (97.476)\n",
            "Test: [30/100]\tTime 0.015 (0.035)\tLoss 6.8199 (5.8589)\tPrec@1 68.000 (73.516)\tPrec@5 98.000 (97.226)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 6.1250 (5.8362)\tPrec@1 72.000 (73.366)\tPrec@5 96.000 (97.146)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 5.9857 (5.8064)\tPrec@1 73.000 (73.431)\tPrec@5 95.000 (97.157)\n",
            "Test: [60/100]\tTime 0.045 (0.030)\tLoss 5.1285 (5.8605)\tPrec@1 73.000 (73.115)\tPrec@5 100.000 (97.197)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 6.9093 (5.8674)\tPrec@1 70.000 (73.183)\tPrec@5 98.000 (97.296)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 5.7685 (5.8127)\tPrec@1 76.000 (73.284)\tPrec@5 99.000 (97.383)\n",
            "Test: [90/100]\tTime 0.042 (0.028)\tLoss 5.2651 (5.8978)\tPrec@1 74.000 (72.813)\tPrec@5 99.000 (97.308)\n",
            "val Results: Prec@1 72.860 Prec@5 97.350 Loss 5.89723\n",
            "val Class Accuracy: [0.916,0.884,0.883,0.676,0.688,0.670,0.779,0.515,0.478,0.797]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [30][0/329], lr: 0.01000\tTime 0.625 (0.625)\tData 0.528 (0.528)\tLoss 1.8530 (1.8530)\tPrec@1 89.844 (89.844)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [30][10/329], lr: 0.01000\tTime 0.078 (0.148)\tData 0.005 (0.054)\tLoss 2.2756 (2.2327)\tPrec@1 89.453 (88.352)\tPrec@5 98.047 (99.041)\n",
            "Epoch: [30][20/329], lr: 0.01000\tTime 0.107 (0.124)\tData 0.003 (0.031)\tLoss 1.8299 (2.2141)\tPrec@1 90.625 (88.467)\tPrec@5 99.219 (99.163)\n",
            "Epoch: [30][30/329], lr: 0.01000\tTime 0.080 (0.113)\tData 0.008 (0.023)\tLoss 1.9187 (2.1728)\tPrec@1 91.797 (88.596)\tPrec@5 99.609 (99.257)\n",
            "Epoch: [30][40/329], lr: 0.01000\tTime 0.096 (0.108)\tData 0.011 (0.019)\tLoss 2.1288 (2.1403)\tPrec@1 89.453 (88.796)\tPrec@5 98.047 (99.200)\n",
            "Epoch: [30][50/329], lr: 0.01000\tTime 0.109 (0.105)\tData 0.011 (0.016)\tLoss 1.7343 (2.1089)\tPrec@1 91.016 (88.932)\tPrec@5 98.828 (99.173)\n",
            "Epoch: [30][60/329], lr: 0.01000\tTime 0.100 (0.102)\tData 0.006 (0.015)\tLoss 1.8259 (2.0632)\tPrec@1 89.453 (89.082)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [30][70/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.006 (0.014)\tLoss 2.1405 (2.0529)\tPrec@1 88.672 (89.195)\tPrec@5 99.219 (99.175)\n",
            "Epoch: [30][80/329], lr: 0.01000\tTime 0.089 (0.099)\tData 0.000 (0.013)\tLoss 1.5997 (2.0027)\tPrec@1 91.016 (89.482)\tPrec@5 99.609 (99.204)\n",
            "Epoch: [30][90/329], lr: 0.01000\tTime 0.102 (0.098)\tData 0.007 (0.012)\tLoss 1.9873 (1.9707)\tPrec@1 89.453 (89.681)\tPrec@5 98.828 (99.219)\n",
            "Epoch: [30][100/329], lr: 0.01000\tTime 0.069 (0.097)\tData 0.000 (0.012)\tLoss 2.0257 (1.9459)\tPrec@1 90.625 (89.817)\tPrec@5 98.438 (99.230)\n",
            "Epoch: [30][110/329], lr: 0.01000\tTime 0.068 (0.097)\tData 0.006 (0.011)\tLoss 2.0389 (1.9357)\tPrec@1 88.672 (89.872)\tPrec@5 99.609 (99.222)\n",
            "Epoch: [30][120/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.011)\tLoss 1.9079 (1.9354)\tPrec@1 91.016 (89.889)\tPrec@5 99.609 (99.248)\n",
            "Epoch: [30][130/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.011 (0.011)\tLoss 1.6513 (1.9293)\tPrec@1 91.406 (89.903)\tPrec@5 99.219 (99.252)\n",
            "Epoch: [30][140/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.005 (0.010)\tLoss 2.3471 (1.9263)\tPrec@1 86.328 (89.932)\tPrec@5 99.219 (99.246)\n",
            "Epoch: [30][150/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.007 (0.010)\tLoss 1.3864 (1.9201)\tPrec@1 94.531 (89.971)\tPrec@5 98.828 (99.252)\n",
            "Epoch: [30][160/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.007 (0.010)\tLoss 1.7446 (1.9193)\tPrec@1 91.406 (89.984)\tPrec@5 98.828 (99.248)\n",
            "Epoch: [30][170/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.009 (0.010)\tLoss 2.4163 (1.9267)\tPrec@1 86.328 (89.949)\tPrec@5 100.000 (99.248)\n",
            "Epoch: [30][180/329], lr: 0.01000\tTime 0.120 (0.094)\tData 0.002 (0.010)\tLoss 1.9826 (1.9298)\tPrec@1 89.453 (89.934)\tPrec@5 100.000 (99.255)\n",
            "Epoch: [30][190/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.003 (0.010)\tLoss 1.9604 (1.9293)\tPrec@1 91.016 (89.971)\tPrec@5 99.609 (99.254)\n",
            "Epoch: [30][200/329], lr: 0.01000\tTime 0.105 (0.094)\tData 0.001 (0.009)\tLoss 1.8421 (1.9273)\tPrec@1 91.016 (89.980)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [30][210/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.002 (0.009)\tLoss 1.8228 (1.9306)\tPrec@1 91.797 (89.973)\tPrec@5 98.438 (99.259)\n",
            "Epoch: [30][220/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.002 (0.009)\tLoss 1.6247 (1.9279)\tPrec@1 91.406 (89.983)\tPrec@5 99.609 (99.268)\n",
            "Epoch: [30][230/329], lr: 0.01000\tTime 0.123 (0.093)\tData 0.001 (0.009)\tLoss 2.0320 (1.9262)\tPrec@1 88.672 (89.991)\tPrec@5 99.609 (99.273)\n",
            "Epoch: [30][240/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.000 (0.009)\tLoss 1.6073 (1.9227)\tPrec@1 90.234 (90.014)\tPrec@5 99.219 (99.277)\n",
            "Epoch: [30][250/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.003 (0.009)\tLoss 1.9562 (1.9155)\tPrec@1 91.016 (90.060)\tPrec@5 99.609 (99.284)\n",
            "Epoch: [30][260/329], lr: 0.01000\tTime 0.133 (0.097)\tData 0.000 (0.010)\tLoss 2.1227 (1.9078)\tPrec@1 89.453 (90.098)\tPrec@5 98.828 (99.291)\n",
            "Epoch: [30][270/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.005 (0.010)\tLoss 1.7107 (1.9023)\tPrec@1 91.797 (90.135)\tPrec@5 99.609 (99.295)\n",
            "Epoch: [30][280/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.005 (0.010)\tLoss 2.0513 (1.8994)\tPrec@1 89.844 (90.145)\tPrec@5 98.828 (99.291)\n",
            "Epoch: [30][290/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.007 (0.010)\tLoss 1.6675 (1.8982)\tPrec@1 91.016 (90.142)\tPrec@5 100.000 (99.294)\n",
            "Epoch: [30][300/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.014 (0.010)\tLoss 1.8030 (1.8977)\tPrec@1 90.234 (90.128)\tPrec@5 99.219 (99.290)\n",
            "Epoch: [30][310/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.002 (0.010)\tLoss 2.2508 (1.8971)\tPrec@1 88.281 (90.128)\tPrec@5 99.609 (99.299)\n",
            "Epoch: [30][320/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.046 (0.010)\tLoss 2.6647 (1.9006)\tPrec@1 86.328 (90.115)\tPrec@5 98.438 (99.303)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 4.9454 (4.9454)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.027 (0.055)\tLoss 4.6701 (5.6668)\tPrec@1 78.000 (75.000)\tPrec@5 97.000 (97.909)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 5.3036 (5.6050)\tPrec@1 74.000 (74.190)\tPrec@5 100.000 (97.714)\n",
            "Test: [30/100]\tTime 0.020 (0.033)\tLoss 5.9533 (5.7282)\tPrec@1 72.000 (73.548)\tPrec@5 97.000 (97.387)\n",
            "Test: [40/100]\tTime 0.019 (0.032)\tLoss 4.8287 (5.7551)\tPrec@1 78.000 (73.122)\tPrec@5 98.000 (97.341)\n",
            "Test: [50/100]\tTime 0.031 (0.030)\tLoss 5.2757 (5.7094)\tPrec@1 73.000 (73.196)\tPrec@5 97.000 (97.510)\n",
            "Test: [60/100]\tTime 0.032 (0.029)\tLoss 5.7709 (5.7011)\tPrec@1 67.000 (72.984)\tPrec@5 98.000 (97.590)\n",
            "Test: [70/100]\tTime 0.049 (0.029)\tLoss 4.9400 (5.6941)\tPrec@1 78.000 (73.183)\tPrec@5 97.000 (97.577)\n",
            "Test: [80/100]\tTime 0.021 (0.028)\tLoss 5.1799 (5.6621)\tPrec@1 77.000 (73.272)\tPrec@5 96.000 (97.654)\n",
            "Test: [90/100]\tTime 0.032 (0.028)\tLoss 5.8971 (5.7352)\tPrec@1 71.000 (72.901)\tPrec@5 99.000 (97.516)\n",
            "val Results: Prec@1 72.950 Prec@5 97.480 Loss 5.74657\n",
            "val Class Accuracy: [0.913,0.956,0.758,0.327,0.847,0.639,0.844,0.744,0.662,0.605]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [31][0/329], lr: 0.01000\tTime 0.641 (0.641)\tData 0.543 (0.543)\tLoss 2.2308 (2.2308)\tPrec@1 87.109 (87.109)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [31][10/329], lr: 0.01000\tTime 0.094 (0.144)\tData 0.004 (0.055)\tLoss 2.6431 (2.7287)\tPrec@1 85.938 (84.730)\tPrec@5 97.656 (98.615)\n",
            "Epoch: [31][20/329], lr: 0.01000\tTime 0.094 (0.121)\tData 0.004 (0.031)\tLoss 2.1880 (2.5982)\tPrec@1 89.453 (85.770)\tPrec@5 98.438 (98.810)\n",
            "Epoch: [31][30/329], lr: 0.01000\tTime 0.089 (0.109)\tData 0.000 (0.023)\tLoss 1.7771 (2.4639)\tPrec@1 91.797 (86.769)\tPrec@5 98.438 (98.942)\n",
            "Epoch: [31][40/329], lr: 0.01000\tTime 0.093 (0.106)\tData 0.000 (0.019)\tLoss 2.2847 (2.3503)\tPrec@1 87.891 (87.443)\tPrec@5 100.000 (99.047)\n",
            "Epoch: [31][50/329], lr: 0.01000\tTime 0.103 (0.103)\tData 0.003 (0.016)\tLoss 1.8616 (2.2771)\tPrec@1 90.625 (87.883)\tPrec@5 98.828 (99.104)\n",
            "Epoch: [31][60/329], lr: 0.01000\tTime 0.094 (0.101)\tData 0.013 (0.015)\tLoss 2.0952 (2.1972)\tPrec@1 89.062 (88.435)\tPrec@5 99.219 (99.155)\n",
            "Epoch: [31][70/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.012 (0.014)\tLoss 1.9519 (2.1768)\tPrec@1 89.844 (88.622)\tPrec@5 99.219 (99.158)\n",
            "Epoch: [31][80/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.009 (0.014)\tLoss 2.0866 (2.1597)\tPrec@1 87.891 (88.744)\tPrec@5 99.219 (99.156)\n",
            "Epoch: [31][90/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.007 (0.013)\tLoss 1.5520 (2.1245)\tPrec@1 91.797 (88.878)\tPrec@5 99.609 (99.163)\n",
            "Epoch: [31][100/329], lr: 0.01000\tTime 0.069 (0.097)\tData 0.005 (0.012)\tLoss 1.2869 (2.0845)\tPrec@1 93.750 (89.055)\tPrec@5 100.000 (99.207)\n",
            "Epoch: [31][110/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.005 (0.012)\tLoss 1.8175 (2.0726)\tPrec@1 90.625 (89.136)\tPrec@5 99.609 (99.194)\n",
            "Epoch: [31][120/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.004 (0.012)\tLoss 1.6576 (2.0586)\tPrec@1 91.016 (89.211)\tPrec@5 100.000 (99.232)\n",
            "Epoch: [31][130/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.011)\tLoss 1.7699 (2.0383)\tPrec@1 89.453 (89.319)\tPrec@5 100.000 (99.266)\n",
            "Epoch: [31][140/329], lr: 0.01000\tTime 0.117 (0.096)\tData 0.004 (0.011)\tLoss 1.8301 (2.0193)\tPrec@1 90.625 (89.434)\tPrec@5 99.609 (99.291)\n",
            "Epoch: [31][150/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.000 (0.011)\tLoss 2.0742 (2.0152)\tPrec@1 89.062 (89.461)\tPrec@5 99.219 (99.291)\n",
            "Epoch: [31][160/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.004 (0.010)\tLoss 1.4430 (2.0106)\tPrec@1 92.188 (89.487)\tPrec@5 99.609 (99.292)\n",
            "Epoch: [31][170/329], lr: 0.01000\tTime 0.102 (0.095)\tData 0.017 (0.010)\tLoss 1.9157 (2.0195)\tPrec@1 89.844 (89.428)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [31][180/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.000 (0.010)\tLoss 1.7886 (2.0041)\tPrec@1 91.016 (89.520)\tPrec@5 100.000 (99.318)\n",
            "Epoch: [31][190/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.000 (0.010)\tLoss 1.7485 (1.9851)\tPrec@1 92.188 (89.629)\tPrec@5 100.000 (99.317)\n",
            "Epoch: [31][200/329], lr: 0.01000\tTime 0.073 (0.094)\tData 0.007 (0.010)\tLoss 2.0509 (1.9765)\tPrec@1 89.062 (89.659)\tPrec@5 99.609 (99.326)\n",
            "Epoch: [31][210/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.012 (0.010)\tLoss 1.8569 (1.9715)\tPrec@1 91.016 (89.683)\tPrec@5 99.219 (99.330)\n",
            "Epoch: [31][220/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.000 (0.010)\tLoss 2.7215 (1.9682)\tPrec@1 83.594 (89.690)\tPrec@5 98.047 (99.335)\n",
            "Epoch: [31][230/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.004 (0.009)\tLoss 1.8966 (1.9595)\tPrec@1 91.016 (89.732)\tPrec@5 99.219 (99.335)\n",
            "Epoch: [31][240/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.009)\tLoss 1.6114 (1.9572)\tPrec@1 93.359 (89.758)\tPrec@5 100.000 (99.337)\n",
            "Epoch: [31][250/329], lr: 0.01000\tTime 0.113 (0.093)\tData 0.006 (0.009)\tLoss 2.1299 (1.9560)\tPrec@1 90.234 (89.763)\tPrec@5 100.000 (99.339)\n",
            "Epoch: [31][260/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.002 (0.009)\tLoss 1.6883 (1.9485)\tPrec@1 90.625 (89.797)\tPrec@5 99.609 (99.347)\n",
            "Epoch: [31][270/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.004 (0.009)\tLoss 2.0518 (1.9421)\tPrec@1 89.453 (89.835)\tPrec@5 99.219 (99.348)\n",
            "Epoch: [31][280/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.003 (0.009)\tLoss 1.4570 (1.9411)\tPrec@1 91.016 (89.841)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [31][290/329], lr: 0.01000\tTime 0.105 (0.093)\tData 0.001 (0.009)\tLoss 1.5872 (1.9358)\tPrec@1 92.188 (89.885)\tPrec@5 99.219 (99.369)\n",
            "Epoch: [31][300/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.006 (0.009)\tLoss 2.6225 (1.9393)\tPrec@1 85.156 (89.861)\tPrec@5 98.828 (99.371)\n",
            "Epoch: [31][310/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.007 (0.009)\tLoss 1.7715 (1.9428)\tPrec@1 92.188 (89.853)\tPrec@5 99.219 (99.368)\n",
            "Epoch: [31][320/329], lr: 0.01000\tTime 0.212 (0.094)\tData 0.142 (0.009)\tLoss 2.0105 (1.9379)\tPrec@1 89.453 (89.884)\tPrec@5 99.609 (99.381)\n",
            "Test: [0/100]\tTime 0.418 (0.418)\tLoss 9.9140 (9.9140)\tPrec@1 56.000 (56.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.057 (0.085)\tLoss 7.7101 (9.2618)\tPrec@1 65.000 (57.636)\tPrec@5 96.000 (95.182)\n",
            "Test: [20/100]\tTime 0.038 (0.065)\tLoss 6.9428 (9.1484)\tPrec@1 72.000 (58.381)\tPrec@5 98.000 (95.429)\n",
            "Test: [30/100]\tTime 0.044 (0.055)\tLoss 8.2726 (9.0575)\tPrec@1 62.000 (58.516)\tPrec@5 92.000 (95.323)\n",
            "Test: [40/100]\tTime 0.044 (0.051)\tLoss 9.8235 (9.1113)\tPrec@1 55.000 (58.366)\tPrec@5 94.000 (95.146)\n",
            "Test: [50/100]\tTime 0.050 (0.047)\tLoss 8.9476 (9.0407)\tPrec@1 60.000 (58.765)\tPrec@5 94.000 (95.157)\n",
            "Test: [60/100]\tTime 0.036 (0.043)\tLoss 7.5300 (9.0434)\tPrec@1 64.000 (58.492)\tPrec@5 96.000 (95.230)\n",
            "Test: [70/100]\tTime 0.035 (0.041)\tLoss 8.8494 (9.0301)\tPrec@1 58.000 (58.648)\tPrec@5 95.000 (95.282)\n",
            "Test: [80/100]\tTime 0.029 (0.039)\tLoss 8.5651 (8.9960)\tPrec@1 59.000 (58.667)\tPrec@5 96.000 (95.333)\n",
            "Test: [90/100]\tTime 0.021 (0.037)\tLoss 9.1599 (9.1051)\tPrec@1 57.000 (58.077)\tPrec@5 97.000 (95.110)\n",
            "val Results: Prec@1 58.140 Prec@5 95.080 Loss 9.11199\n",
            "val Class Accuracy: [0.998,0.874,0.465,0.343,0.796,0.444,0.646,0.446,0.387,0.415]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [32][0/329], lr: 0.01000\tTime 0.552 (0.552)\tData 0.457 (0.457)\tLoss 2.0225 (2.0225)\tPrec@1 89.062 (89.062)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [32][10/329], lr: 0.01000\tTime 0.084 (0.139)\tData 0.005 (0.048)\tLoss 2.2159 (3.0730)\tPrec@1 86.719 (83.487)\tPrec@5 98.438 (97.976)\n",
            "Epoch: [32][20/329], lr: 0.01000\tTime 0.118 (0.119)\tData 0.005 (0.028)\tLoss 2.2721 (2.9574)\tPrec@1 88.281 (84.077)\tPrec@5 99.219 (98.363)\n",
            "Epoch: [32][30/329], lr: 0.01000\tTime 0.101 (0.112)\tData 0.000 (0.020)\tLoss 1.9981 (2.7678)\tPrec@1 89.062 (85.219)\tPrec@5 99.609 (98.463)\n",
            "Epoch: [32][40/329], lr: 0.01000\tTime 0.108 (0.108)\tData 0.000 (0.016)\tLoss 2.2648 (2.6567)\tPrec@1 87.891 (85.823)\tPrec@5 98.438 (98.619)\n",
            "Epoch: [32][50/329], lr: 0.01000\tTime 0.094 (0.104)\tData 0.006 (0.014)\tLoss 2.5933 (2.5604)\tPrec@1 86.328 (86.366)\tPrec@5 98.047 (98.698)\n",
            "Epoch: [32][60/329], lr: 0.01000\tTime 0.125 (0.103)\tData 0.007 (0.013)\tLoss 1.8825 (2.4900)\tPrec@1 88.281 (86.738)\tPrec@5 100.000 (98.783)\n",
            "Epoch: [32][70/329], lr: 0.01000\tTime 0.082 (0.101)\tData 0.005 (0.012)\tLoss 1.9762 (2.4096)\tPrec@1 89.844 (87.203)\tPrec@5 100.000 (98.889)\n",
            "Epoch: [32][80/329], lr: 0.01000\tTime 0.110 (0.100)\tData 0.007 (0.011)\tLoss 1.9054 (2.3746)\tPrec@1 89.844 (87.428)\tPrec@5 99.219 (98.915)\n",
            "Epoch: [32][90/329], lr: 0.01000\tTime 0.111 (0.099)\tData 0.000 (0.010)\tLoss 1.6827 (2.3284)\tPrec@1 89.844 (87.655)\tPrec@5 99.609 (98.944)\n",
            "Epoch: [32][100/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.007 (0.010)\tLoss 2.1727 (2.3022)\tPrec@1 89.453 (87.794)\tPrec@5 99.609 (98.967)\n",
            "Epoch: [32][110/329], lr: 0.01000\tTime 0.099 (0.097)\tData 0.000 (0.010)\tLoss 2.1553 (2.2833)\tPrec@1 88.281 (87.929)\tPrec@5 100.000 (99.015)\n",
            "Epoch: [32][120/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.000 (0.010)\tLoss 2.1226 (2.2372)\tPrec@1 88.672 (88.181)\tPrec@5 99.219 (99.041)\n",
            "Epoch: [32][130/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.000 (0.009)\tLoss 1.4931 (2.2027)\tPrec@1 92.188 (88.374)\tPrec@5 100.000 (99.079)\n",
            "Epoch: [32][140/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.007 (0.009)\tLoss 1.9305 (2.1934)\tPrec@1 89.062 (88.434)\tPrec@5 98.828 (99.080)\n",
            "Epoch: [32][150/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.000 (0.009)\tLoss 1.7174 (2.1686)\tPrec@1 91.797 (88.568)\tPrec@5 99.219 (99.100)\n",
            "Epoch: [32][160/329], lr: 0.01000\tTime 0.118 (0.095)\tData 0.005 (0.009)\tLoss 1.8736 (2.1551)\tPrec@1 90.625 (88.652)\tPrec@5 98.828 (99.102)\n",
            "Epoch: [32][170/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.009)\tLoss 2.7217 (2.1535)\tPrec@1 87.891 (88.676)\tPrec@5 99.219 (99.111)\n",
            "Epoch: [32][180/329], lr: 0.01000\tTime 0.061 (0.094)\tData 0.000 (0.008)\tLoss 1.6406 (2.1393)\tPrec@1 91.406 (88.745)\tPrec@5 99.219 (99.122)\n",
            "Epoch: [32][190/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.005 (0.009)\tLoss 1.4979 (2.1214)\tPrec@1 92.188 (88.846)\tPrec@5 98.828 (99.143)\n",
            "Epoch: [32][200/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.012 (0.008)\tLoss 2.4858 (2.1127)\tPrec@1 86.328 (88.880)\tPrec@5 99.219 (99.157)\n",
            "Epoch: [32][210/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.011 (0.008)\tLoss 1.8916 (2.1149)\tPrec@1 92.188 (88.870)\tPrec@5 99.609 (99.171)\n",
            "Epoch: [32][220/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.000 (0.008)\tLoss 1.9061 (2.1064)\tPrec@1 90.625 (88.914)\tPrec@5 100.000 (99.183)\n",
            "Epoch: [32][230/329], lr: 0.01000\tTime 0.118 (0.093)\tData 0.000 (0.008)\tLoss 1.6521 (2.0977)\tPrec@1 91.406 (88.959)\tPrec@5 98.828 (99.187)\n",
            "Epoch: [32][240/329], lr: 0.01000\tTime 0.114 (0.093)\tData 0.012 (0.008)\tLoss 1.4924 (2.0935)\tPrec@1 91.797 (88.991)\tPrec@5 99.219 (99.190)\n",
            "Epoch: [32][250/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.004 (0.008)\tLoss 1.7090 (2.0875)\tPrec@1 91.016 (89.013)\tPrec@5 99.609 (99.197)\n",
            "Epoch: [32][260/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.005 (0.008)\tLoss 2.1191 (2.0825)\tPrec@1 89.453 (89.048)\tPrec@5 100.000 (99.207)\n",
            "Epoch: [32][270/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.002 (0.008)\tLoss 2.1063 (2.0750)\tPrec@1 88.281 (89.093)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [32][280/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.000 (0.008)\tLoss 1.9265 (2.0684)\tPrec@1 91.016 (89.139)\tPrec@5 99.609 (99.223)\n",
            "Epoch: [32][290/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.000 (0.008)\tLoss 2.3443 (2.0645)\tPrec@1 88.281 (89.155)\tPrec@5 98.828 (99.227)\n",
            "Epoch: [32][300/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.004 (0.008)\tLoss 2.1577 (2.0611)\tPrec@1 88.672 (89.159)\tPrec@5 99.609 (99.234)\n",
            "Epoch: [32][310/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.000 (0.008)\tLoss 2.0068 (2.0550)\tPrec@1 87.891 (89.198)\tPrec@5 99.219 (99.243)\n",
            "Epoch: [32][320/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.055 (0.008)\tLoss 2.2898 (2.0490)\tPrec@1 89.062 (89.237)\tPrec@5 99.609 (99.247)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 6.7742 (6.7742)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.031 (0.057)\tLoss 5.8612 (7.3512)\tPrec@1 72.000 (66.000)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.034 (0.042)\tLoss 6.9299 (7.2850)\tPrec@1 65.000 (66.571)\tPrec@5 98.000 (97.571)\n",
            "Test: [30/100]\tTime 0.041 (0.037)\tLoss 7.5172 (7.3762)\tPrec@1 64.000 (66.258)\tPrec@5 97.000 (97.097)\n",
            "Test: [40/100]\tTime 0.029 (0.035)\tLoss 7.3910 (7.4071)\tPrec@1 66.000 (66.341)\tPrec@5 96.000 (97.024)\n",
            "Test: [50/100]\tTime 0.024 (0.033)\tLoss 8.1994 (7.3642)\tPrec@1 64.000 (66.510)\tPrec@5 95.000 (96.922)\n",
            "Test: [60/100]\tTime 0.024 (0.032)\tLoss 7.7820 (7.4123)\tPrec@1 65.000 (66.098)\tPrec@5 97.000 (96.934)\n",
            "Test: [70/100]\tTime 0.023 (0.031)\tLoss 6.4835 (7.3940)\tPrec@1 68.000 (66.000)\tPrec@5 98.000 (96.958)\n",
            "Test: [80/100]\tTime 0.037 (0.030)\tLoss 7.2999 (7.3232)\tPrec@1 64.000 (66.383)\tPrec@5 97.000 (97.000)\n",
            "Test: [90/100]\tTime 0.035 (0.030)\tLoss 7.4157 (7.3373)\tPrec@1 63.000 (66.341)\tPrec@5 98.000 (96.879)\n",
            "val Results: Prec@1 66.560 Prec@5 96.900 Loss 7.30927\n",
            "val Class Accuracy: [0.750,0.984,0.798,0.879,0.351,0.258,0.856,0.548,0.653,0.579]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [33][0/329], lr: 0.01000\tTime 0.676 (0.676)\tData 0.577 (0.577)\tLoss 2.1042 (2.1042)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [33][10/329], lr: 0.01000\tTime 0.094 (0.156)\tData 0.001 (0.059)\tLoss 2.1032 (2.1984)\tPrec@1 89.062 (89.169)\tPrec@5 99.609 (99.290)\n",
            "Epoch: [33][20/329], lr: 0.01000\tTime 0.064 (0.123)\tData 0.002 (0.035)\tLoss 1.5556 (2.0673)\tPrec@1 92.969 (89.769)\tPrec@5 100.000 (99.312)\n",
            "Epoch: [33][30/329], lr: 0.01000\tTime 0.087 (0.114)\tData 0.004 (0.027)\tLoss 1.5497 (2.0370)\tPrec@1 91.406 (89.856)\tPrec@5 100.000 (99.320)\n",
            "Epoch: [33][40/329], lr: 0.01000\tTime 0.089 (0.108)\tData 0.006 (0.022)\tLoss 1.4605 (1.9784)\tPrec@1 92.188 (90.006)\tPrec@5 99.219 (99.362)\n",
            "Epoch: [33][50/329], lr: 0.01000\tTime 0.135 (0.106)\tData 0.000 (0.019)\tLoss 1.6133 (1.9648)\tPrec@1 92.578 (89.966)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [33][60/329], lr: 0.01000\tTime 0.126 (0.107)\tData 0.000 (0.016)\tLoss 2.1364 (1.9403)\tPrec@1 89.453 (90.119)\tPrec@5 99.609 (99.347)\n",
            "Epoch: [33][70/329], lr: 0.01000\tTime 0.235 (0.110)\tData 0.138 (0.019)\tLoss 1.6495 (1.9289)\tPrec@1 90.625 (90.157)\tPrec@5 99.609 (99.389)\n",
            "Epoch: [33][80/329], lr: 0.01000\tTime 0.154 (0.112)\tData 0.086 (0.022)\tLoss 1.6950 (1.9185)\tPrec@1 92.578 (90.210)\tPrec@5 98.828 (99.397)\n",
            "Epoch: [33][90/329], lr: 0.01000\tTime 0.103 (0.113)\tData 0.010 (0.021)\tLoss 1.7644 (1.9248)\tPrec@1 90.234 (90.149)\tPrec@5 99.609 (99.386)\n",
            "Epoch: [33][100/329], lr: 0.01000\tTime 0.100 (0.110)\tData 0.003 (0.020)\tLoss 1.8809 (1.8913)\tPrec@1 90.234 (90.327)\tPrec@5 99.219 (99.401)\n",
            "Epoch: [33][110/329], lr: 0.01000\tTime 0.092 (0.109)\tData 0.000 (0.018)\tLoss 1.7068 (1.8779)\tPrec@1 89.844 (90.347)\tPrec@5 99.609 (99.426)\n",
            "Epoch: [33][120/329], lr: 0.01000\tTime 0.099 (0.108)\tData 0.005 (0.017)\tLoss 2.1172 (1.8723)\tPrec@1 88.672 (90.370)\tPrec@5 99.609 (99.400)\n",
            "Epoch: [33][130/329], lr: 0.01000\tTime 0.079 (0.106)\tData 0.003 (0.017)\tLoss 2.4731 (1.8698)\tPrec@1 88.281 (90.383)\tPrec@5 99.609 (99.401)\n",
            "Epoch: [33][140/329], lr: 0.01000\tTime 0.114 (0.106)\tData 0.000 (0.016)\tLoss 1.9679 (1.8699)\tPrec@1 90.234 (90.376)\tPrec@5 99.219 (99.407)\n",
            "Epoch: [33][150/329], lr: 0.01000\tTime 0.105 (0.104)\tData 0.007 (0.016)\tLoss 1.3389 (1.8740)\tPrec@1 92.578 (90.366)\tPrec@5 99.219 (99.410)\n",
            "Epoch: [33][160/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.006 (0.015)\tLoss 1.8977 (1.8716)\tPrec@1 89.453 (90.361)\tPrec@5 99.219 (99.413)\n",
            "Epoch: [33][170/329], lr: 0.01000\tTime 0.120 (0.103)\tData 0.000 (0.015)\tLoss 1.7455 (1.8754)\tPrec@1 91.016 (90.326)\tPrec@5 99.219 (99.390)\n",
            "Epoch: [33][180/329], lr: 0.01000\tTime 0.079 (0.102)\tData 0.007 (0.015)\tLoss 2.7195 (1.8729)\tPrec@1 85.547 (90.370)\tPrec@5 98.438 (99.396)\n",
            "Epoch: [33][190/329], lr: 0.01000\tTime 0.082 (0.101)\tData 0.001 (0.014)\tLoss 1.5292 (1.8780)\tPrec@1 91.797 (90.347)\tPrec@5 100.000 (99.391)\n",
            "Epoch: [33][200/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.004 (0.014)\tLoss 1.5513 (1.8814)\tPrec@1 92.578 (90.320)\tPrec@5 100.000 (99.392)\n",
            "Epoch: [33][210/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.005 (0.013)\tLoss 1.5531 (1.8813)\tPrec@1 91.797 (90.303)\tPrec@5 99.609 (99.387)\n",
            "Epoch: [33][220/329], lr: 0.01000\tTime 0.108 (0.100)\tData 0.000 (0.013)\tLoss 2.1452 (1.8831)\tPrec@1 89.062 (90.291)\tPrec@5 99.609 (99.394)\n",
            "Epoch: [33][230/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.001 (0.013)\tLoss 1.8452 (1.8843)\tPrec@1 90.625 (90.297)\tPrec@5 100.000 (99.396)\n",
            "Epoch: [33][240/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.005 (0.013)\tLoss 2.2442 (1.8855)\tPrec@1 87.500 (90.293)\tPrec@5 98.828 (99.397)\n",
            "Epoch: [33][250/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.010 (0.012)\tLoss 1.4709 (1.8827)\tPrec@1 91.406 (90.306)\tPrec@5 99.219 (99.399)\n",
            "Epoch: [33][260/329], lr: 0.01000\tTime 0.073 (0.098)\tData 0.010 (0.012)\tLoss 2.3855 (1.8845)\tPrec@1 87.109 (90.290)\tPrec@5 99.219 (99.397)\n",
            "Epoch: [33][270/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.007 (0.012)\tLoss 2.0995 (1.8858)\tPrec@1 90.234 (90.289)\tPrec@5 99.219 (99.399)\n",
            "Epoch: [33][280/329], lr: 0.01000\tTime 0.068 (0.097)\tData 0.000 (0.012)\tLoss 1.9111 (1.8839)\tPrec@1 90.234 (90.305)\tPrec@5 98.828 (99.402)\n",
            "Epoch: [33][290/329], lr: 0.01000\tTime 0.116 (0.097)\tData 0.005 (0.012)\tLoss 1.8901 (1.8834)\tPrec@1 90.625 (90.299)\tPrec@5 99.609 (99.403)\n",
            "Epoch: [33][300/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.006 (0.012)\tLoss 2.0685 (1.8851)\tPrec@1 89.062 (90.284)\tPrec@5 99.609 (99.399)\n",
            "Epoch: [33][310/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.000 (0.012)\tLoss 1.6530 (1.8850)\tPrec@1 91.406 (90.281)\tPrec@5 99.609 (99.397)\n",
            "Epoch: [33][320/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.052 (0.012)\tLoss 2.2312 (1.8878)\tPrec@1 88.281 (90.245)\tPrec@5 98.828 (99.401)\n",
            "Test: [0/100]\tTime 0.370 (0.370)\tLoss 7.0203 (7.0203)\tPrec@1 68.000 (68.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.043 (0.060)\tLoss 5.2062 (6.9284)\tPrec@1 74.000 (68.818)\tPrec@5 100.000 (98.636)\n",
            "Test: [20/100]\tTime 0.017 (0.042)\tLoss 5.3434 (6.7931)\tPrec@1 77.000 (69.714)\tPrec@5 99.000 (98.381)\n",
            "Test: [30/100]\tTime 0.028 (0.036)\tLoss 6.5302 (6.7633)\tPrec@1 70.000 (69.806)\tPrec@5 99.000 (98.065)\n",
            "Test: [40/100]\tTime 0.025 (0.034)\tLoss 6.8567 (6.8482)\tPrec@1 68.000 (69.098)\tPrec@5 96.000 (98.024)\n",
            "Test: [50/100]\tTime 0.025 (0.033)\tLoss 6.8633 (6.8735)\tPrec@1 68.000 (68.882)\tPrec@5 95.000 (97.902)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 6.2805 (6.9085)\tPrec@1 73.000 (68.689)\tPrec@5 100.000 (97.951)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 7.4257 (6.8935)\tPrec@1 66.000 (68.732)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 6.2401 (6.8617)\tPrec@1 71.000 (68.827)\tPrec@5 96.000 (97.926)\n",
            "Test: [90/100]\tTime 0.011 (0.028)\tLoss 6.8126 (6.9356)\tPrec@1 69.000 (68.462)\tPrec@5 100.000 (97.835)\n",
            "val Results: Prec@1 68.370 Prec@5 97.810 Loss 6.94833\n",
            "val Class Accuracy: [0.898,0.972,0.932,0.413,0.662,0.669,0.720,0.514,0.614,0.443]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [34][0/329], lr: 0.01000\tTime 0.632 (0.632)\tData 0.535 (0.535)\tLoss 1.6866 (1.6866)\tPrec@1 90.234 (90.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [34][10/329], lr: 0.01000\tTime 0.088 (0.149)\tData 0.000 (0.054)\tLoss 2.4213 (2.0105)\tPrec@1 87.500 (89.666)\tPrec@5 98.047 (99.503)\n",
            "Epoch: [34][20/329], lr: 0.01000\tTime 0.110 (0.123)\tData 0.005 (0.032)\tLoss 1.2271 (1.8670)\tPrec@1 94.141 (90.346)\tPrec@5 100.000 (99.461)\n",
            "Epoch: [34][30/329], lr: 0.01000\tTime 0.086 (0.111)\tData 0.000 (0.023)\tLoss 1.1440 (1.8195)\tPrec@1 94.922 (90.600)\tPrec@5 100.000 (99.534)\n",
            "Epoch: [34][40/329], lr: 0.01000\tTime 0.093 (0.106)\tData 0.000 (0.019)\tLoss 1.5578 (1.8262)\tPrec@1 91.406 (90.454)\tPrec@5 99.609 (99.543)\n",
            "Epoch: [34][50/329], lr: 0.01000\tTime 0.097 (0.103)\tData 0.001 (0.017)\tLoss 1.6907 (1.8115)\tPrec@1 91.406 (90.548)\tPrec@5 99.609 (99.540)\n",
            "Epoch: [34][60/329], lr: 0.01000\tTime 0.102 (0.103)\tData 0.012 (0.015)\tLoss 2.4299 (1.8234)\tPrec@1 86.719 (90.433)\tPrec@5 99.609 (99.545)\n",
            "Epoch: [34][70/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.000 (0.014)\tLoss 1.7075 (1.8141)\tPrec@1 91.406 (90.493)\tPrec@5 100.000 (99.527)\n",
            "Epoch: [34][80/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.009 (0.013)\tLoss 1.5204 (1.7998)\tPrec@1 92.578 (90.567)\tPrec@5 100.000 (99.542)\n",
            "Epoch: [34][90/329], lr: 0.01000\tTime 0.111 (0.099)\tData 0.007 (0.012)\tLoss 1.6683 (1.7983)\tPrec@1 91.797 (90.595)\tPrec@5 99.609 (99.524)\n",
            "Epoch: [34][100/329], lr: 0.01000\tTime 0.090 (0.098)\tData 0.005 (0.012)\tLoss 1.6001 (1.8110)\tPrec@1 91.797 (90.517)\tPrec@5 98.438 (99.505)\n",
            "Epoch: [34][110/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.005 (0.011)\tLoss 1.9077 (1.8232)\tPrec@1 89.844 (90.467)\tPrec@5 99.219 (99.476)\n",
            "Epoch: [34][120/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.004 (0.011)\tLoss 2.2698 (1.8230)\tPrec@1 88.281 (90.493)\tPrec@5 99.219 (99.496)\n",
            "Epoch: [34][130/329], lr: 0.01000\tTime 0.071 (0.096)\tData 0.000 (0.011)\tLoss 1.5610 (1.8238)\tPrec@1 91.797 (90.500)\tPrec@5 99.609 (99.496)\n",
            "Epoch: [34][140/329], lr: 0.01000\tTime 0.124 (0.098)\tData 0.006 (0.011)\tLoss 1.3356 (1.8137)\tPrec@1 93.359 (90.542)\tPrec@5 99.219 (99.496)\n",
            "Epoch: [34][150/329], lr: 0.01000\tTime 0.111 (0.099)\tData 0.000 (0.011)\tLoss 2.1819 (1.8226)\tPrec@1 89.062 (90.540)\tPrec@5 99.609 (99.490)\n",
            "Epoch: [34][160/329], lr: 0.01000\tTime 0.148 (0.102)\tData 0.000 (0.013)\tLoss 1.6416 (1.8156)\tPrec@1 92.188 (90.581)\tPrec@5 98.828 (99.490)\n",
            "Epoch: [34][170/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.005 (0.012)\tLoss 1.4777 (1.8114)\tPrec@1 91.797 (90.591)\tPrec@5 99.609 (99.488)\n",
            "Epoch: [34][180/329], lr: 0.01000\tTime 0.098 (0.101)\tData 0.005 (0.012)\tLoss 1.7720 (1.8147)\tPrec@1 91.406 (90.584)\tPrec@5 98.828 (99.482)\n",
            "Epoch: [34][190/329], lr: 0.01000\tTime 0.100 (0.101)\tData 0.000 (0.012)\tLoss 1.4772 (1.8041)\tPrec@1 92.578 (90.637)\tPrec@5 99.609 (99.491)\n",
            "Epoch: [34][200/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.017 (0.011)\tLoss 1.9485 (1.8049)\tPrec@1 89.453 (90.641)\tPrec@5 99.609 (99.495)\n",
            "Epoch: [34][210/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.005 (0.011)\tLoss 1.9651 (1.8129)\tPrec@1 89.453 (90.595)\tPrec@5 99.609 (99.502)\n",
            "Epoch: [34][220/329], lr: 0.01000\tTime 0.087 (0.100)\tData 0.004 (0.011)\tLoss 2.4041 (1.8167)\tPrec@1 87.109 (90.567)\tPrec@5 99.219 (99.503)\n",
            "Epoch: [34][230/329], lr: 0.01000\tTime 0.103 (0.100)\tData 0.005 (0.011)\tLoss 1.5026 (1.8189)\tPrec@1 90.625 (90.549)\tPrec@5 99.219 (99.501)\n",
            "Epoch: [34][240/329], lr: 0.01000\tTime 0.102 (0.099)\tData 0.000 (0.011)\tLoss 2.0216 (1.8268)\tPrec@1 89.844 (90.512)\tPrec@5 99.219 (99.506)\n",
            "Epoch: [34][250/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.000 (0.010)\tLoss 1.8578 (1.8233)\tPrec@1 89.844 (90.530)\tPrec@5 99.609 (99.502)\n",
            "Epoch: [34][260/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.000 (0.010)\tLoss 1.4574 (1.8274)\tPrec@1 93.750 (90.508)\tPrec@5 100.000 (99.502)\n",
            "Epoch: [34][270/329], lr: 0.01000\tTime 0.116 (0.098)\tData 0.005 (0.010)\tLoss 1.5672 (1.8196)\tPrec@1 92.188 (90.546)\tPrec@5 100.000 (99.500)\n",
            "Epoch: [34][280/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.010)\tLoss 1.7925 (1.8178)\tPrec@1 91.016 (90.555)\tPrec@5 99.609 (99.501)\n",
            "Epoch: [34][290/329], lr: 0.01000\tTime 0.070 (0.098)\tData 0.005 (0.010)\tLoss 1.7643 (1.8139)\tPrec@1 89.844 (90.561)\tPrec@5 98.828 (99.507)\n",
            "Epoch: [34][300/329], lr: 0.01000\tTime 0.071 (0.098)\tData 0.011 (0.010)\tLoss 1.2588 (1.8134)\tPrec@1 93.359 (90.554)\tPrec@5 100.000 (99.508)\n",
            "Epoch: [34][310/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.005 (0.010)\tLoss 1.6721 (1.8162)\tPrec@1 92.969 (90.550)\tPrec@5 99.609 (99.510)\n",
            "Epoch: [34][320/329], lr: 0.01000\tTime 0.119 (0.097)\tData 0.074 (0.010)\tLoss 1.6782 (1.8195)\tPrec@1 91.016 (90.525)\tPrec@5 99.609 (99.512)\n",
            "Test: [0/100]\tTime 0.293 (0.293)\tLoss 5.3408 (5.3408)\tPrec@1 78.000 (78.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.010 (0.052)\tLoss 4.5594 (5.5949)\tPrec@1 78.000 (74.091)\tPrec@5 98.000 (98.818)\n",
            "Test: [20/100]\tTime 0.015 (0.040)\tLoss 4.3775 (5.5231)\tPrec@1 80.000 (74.381)\tPrec@5 99.000 (98.333)\n",
            "Test: [30/100]\tTime 0.032 (0.035)\tLoss 5.5286 (5.4631)\tPrec@1 75.000 (75.097)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 5.0347 (5.4525)\tPrec@1 77.000 (75.341)\tPrec@5 98.000 (98.122)\n",
            "Test: [50/100]\tTime 0.018 (0.030)\tLoss 6.0627 (5.4252)\tPrec@1 73.000 (75.490)\tPrec@5 94.000 (98.118)\n",
            "Test: [60/100]\tTime 0.037 (0.030)\tLoss 5.0497 (5.4373)\tPrec@1 76.000 (75.262)\tPrec@5 98.000 (98.197)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 5.3860 (5.4229)\tPrec@1 73.000 (75.254)\tPrec@5 99.000 (98.169)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 4.7215 (5.4048)\tPrec@1 78.000 (75.235)\tPrec@5 99.000 (98.259)\n",
            "Test: [90/100]\tTime 0.015 (0.028)\tLoss 4.6762 (5.4658)\tPrec@1 83.000 (74.890)\tPrec@5 99.000 (98.242)\n",
            "val Results: Prec@1 74.880 Prec@5 98.200 Loss 5.47596\n",
            "val Class Accuracy: [0.976,0.949,0.829,0.536,0.797,0.657,0.761,0.760,0.574,0.649]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [35][0/329], lr: 0.01000\tTime 0.619 (0.619)\tData 0.544 (0.544)\tLoss 2.4390 (2.4390)\tPrec@1 88.281 (88.281)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [35][10/329], lr: 0.01000\tTime 0.071 (0.146)\tData 0.014 (0.057)\tLoss 2.2231 (1.9104)\tPrec@1 89.062 (90.554)\tPrec@5 99.219 (99.467)\n",
            "Epoch: [35][20/329], lr: 0.01000\tTime 0.090 (0.121)\tData 0.004 (0.033)\tLoss 1.2364 (1.8274)\tPrec@1 92.188 (90.551)\tPrec@5 99.609 (99.554)\n",
            "Epoch: [35][30/329], lr: 0.01000\tTime 0.099 (0.111)\tData 0.004 (0.025)\tLoss 1.9701 (1.7823)\tPrec@1 89.844 (90.990)\tPrec@5 99.609 (99.534)\n",
            "Epoch: [35][40/329], lr: 0.01000\tTime 0.077 (0.106)\tData 0.000 (0.021)\tLoss 1.5397 (1.7748)\tPrec@1 91.406 (90.987)\tPrec@5 100.000 (99.524)\n",
            "Epoch: [35][50/329], lr: 0.01000\tTime 0.074 (0.103)\tData 0.000 (0.018)\tLoss 1.4416 (1.7778)\tPrec@1 92.188 (90.924)\tPrec@5 99.609 (99.502)\n",
            "Epoch: [35][60/329], lr: 0.01000\tTime 0.112 (0.101)\tData 0.014 (0.016)\tLoss 2.1230 (1.8095)\tPrec@1 89.062 (90.747)\tPrec@5 99.219 (99.494)\n",
            "Epoch: [35][70/329], lr: 0.01000\tTime 0.093 (0.100)\tData 0.000 (0.015)\tLoss 1.5081 (1.8143)\tPrec@1 91.406 (90.691)\tPrec@5 100.000 (99.494)\n",
            "Epoch: [35][80/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.007 (0.014)\tLoss 2.1141 (1.8351)\tPrec@1 90.234 (90.524)\tPrec@5 100.000 (99.489)\n",
            "Epoch: [35][90/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.000 (0.013)\tLoss 1.7544 (1.8199)\tPrec@1 90.625 (90.552)\tPrec@5 99.609 (99.481)\n",
            "Epoch: [35][100/329], lr: 0.01000\tTime 0.073 (0.097)\tData 0.001 (0.013)\tLoss 1.5683 (1.8226)\tPrec@1 92.969 (90.555)\tPrec@5 99.219 (99.451)\n",
            "Epoch: [35][110/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.013 (0.013)\tLoss 2.0144 (1.8301)\tPrec@1 89.844 (90.534)\tPrec@5 99.609 (99.462)\n",
            "Epoch: [35][120/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.012)\tLoss 1.7148 (1.8290)\tPrec@1 89.844 (90.522)\tPrec@5 99.609 (99.461)\n",
            "Epoch: [35][130/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.007 (0.012)\tLoss 1.9803 (1.8348)\tPrec@1 89.062 (90.488)\tPrec@5 99.609 (99.466)\n",
            "Epoch: [35][140/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.012 (0.011)\tLoss 2.0009 (1.8412)\tPrec@1 91.016 (90.467)\tPrec@5 99.219 (99.454)\n",
            "Epoch: [35][150/329], lr: 0.01000\tTime 0.117 (0.095)\tData 0.005 (0.011)\tLoss 1.9696 (1.8506)\tPrec@1 89.844 (90.431)\tPrec@5 100.000 (99.454)\n",
            "Epoch: [35][160/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.000 (0.011)\tLoss 2.2052 (1.8498)\tPrec@1 89.453 (90.404)\tPrec@5 98.828 (99.452)\n",
            "Epoch: [35][170/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.005 (0.011)\tLoss 1.6257 (1.8477)\tPrec@1 91.406 (90.438)\tPrec@5 99.609 (99.436)\n",
            "Epoch: [35][180/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.010)\tLoss 2.0632 (1.8472)\tPrec@1 89.453 (90.426)\tPrec@5 99.219 (99.448)\n",
            "Epoch: [35][190/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.005 (0.010)\tLoss 1.6621 (1.8457)\tPrec@1 91.797 (90.435)\tPrec@5 99.609 (99.460)\n",
            "Epoch: [35][200/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.004 (0.010)\tLoss 1.7424 (1.8443)\tPrec@1 91.016 (90.438)\tPrec@5 98.828 (99.456)\n",
            "Epoch: [35][210/329], lr: 0.01000\tTime 0.128 (0.094)\tData 0.005 (0.010)\tLoss 1.9132 (1.8459)\tPrec@1 89.844 (90.438)\tPrec@5 99.219 (99.450)\n",
            "Epoch: [35][220/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.000 (0.010)\tLoss 1.2650 (1.8383)\tPrec@1 93.750 (90.469)\tPrec@5 99.609 (99.452)\n",
            "Epoch: [35][230/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.005 (0.010)\tLoss 1.9461 (1.8484)\tPrec@1 89.062 (90.398)\tPrec@5 98.438 (99.439)\n",
            "Epoch: [35][240/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.028 (0.011)\tLoss 2.0770 (1.8448)\tPrec@1 89.453 (90.422)\tPrec@5 98.828 (99.434)\n",
            "Epoch: [35][250/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.004 (0.012)\tLoss 1.8125 (1.8473)\tPrec@1 89.844 (90.399)\tPrec@5 99.219 (99.437)\n",
            "Epoch: [35][260/329], lr: 0.01000\tTime 0.100 (0.098)\tData 0.000 (0.012)\tLoss 2.2781 (1.8498)\tPrec@1 87.891 (90.384)\tPrec@5 99.219 (99.433)\n",
            "Epoch: [35][270/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.009 (0.012)\tLoss 1.4963 (1.8517)\tPrec@1 92.578 (90.376)\tPrec@5 100.000 (99.439)\n",
            "Epoch: [35][280/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.000 (0.011)\tLoss 1.9371 (1.8492)\tPrec@1 89.844 (90.389)\tPrec@5 99.609 (99.444)\n",
            "Epoch: [35][290/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.005 (0.011)\tLoss 2.2628 (1.8520)\tPrec@1 89.453 (90.378)\tPrec@5 100.000 (99.444)\n",
            "Epoch: [35][300/329], lr: 0.01000\tTime 0.104 (0.098)\tData 0.005 (0.011)\tLoss 1.5664 (1.8440)\tPrec@1 92.578 (90.429)\tPrec@5 99.609 (99.443)\n",
            "Epoch: [35][310/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.000 (0.011)\tLoss 1.7817 (1.8425)\tPrec@1 90.234 (90.450)\tPrec@5 99.609 (99.451)\n",
            "Epoch: [35][320/329], lr: 0.01000\tTime 0.114 (0.097)\tData 0.079 (0.011)\tLoss 2.2294 (1.8422)\tPrec@1 88.281 (90.451)\tPrec@5 98.438 (99.439)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 6.3283 (6.3283)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.023 (0.057)\tLoss 5.6137 (6.8574)\tPrec@1 75.000 (68.818)\tPrec@5 95.000 (94.364)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 6.1390 (6.7832)\tPrec@1 69.000 (69.000)\tPrec@5 97.000 (95.190)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 7.0832 (6.8686)\tPrec@1 65.000 (68.516)\tPrec@5 97.000 (94.903)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 5.8940 (6.8779)\tPrec@1 73.000 (68.683)\tPrec@5 98.000 (94.829)\n",
            "Test: [50/100]\tTime 0.035 (0.031)\tLoss 7.2715 (6.8345)\tPrec@1 68.000 (69.039)\tPrec@5 94.000 (94.686)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 6.9395 (6.9020)\tPrec@1 69.000 (68.656)\tPrec@5 96.000 (94.689)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 6.0117 (6.9103)\tPrec@1 71.000 (68.521)\tPrec@5 97.000 (94.620)\n",
            "Test: [80/100]\tTime 0.018 (0.028)\tLoss 6.9721 (6.8862)\tPrec@1 71.000 (68.605)\tPrec@5 95.000 (94.741)\n",
            "Test: [90/100]\tTime 0.032 (0.028)\tLoss 8.5454 (6.9548)\tPrec@1 59.000 (68.253)\tPrec@5 93.000 (94.648)\n",
            "val Results: Prec@1 68.210 Prec@5 94.610 Loss 6.97306\n",
            "val Class Accuracy: [0.751,0.721,0.497,0.876,0.736,0.751,0.605,0.620,0.656,0.608]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [36][0/329], lr: 0.01000\tTime 0.524 (0.524)\tData 0.433 (0.433)\tLoss 2.0856 (2.0856)\tPrec@1 88.281 (88.281)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [36][10/329], lr: 0.01000\tTime 0.093 (0.141)\tData 0.005 (0.052)\tLoss 2.3401 (2.7278)\tPrec@1 88.672 (85.795)\tPrec@5 98.438 (98.402)\n",
            "Epoch: [36][20/329], lr: 0.01000\tTime 0.089 (0.120)\tData 0.000 (0.033)\tLoss 2.8810 (2.5849)\tPrec@1 83.594 (86.551)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [36][30/329], lr: 0.01000\tTime 0.095 (0.111)\tData 0.012 (0.025)\tLoss 2.3352 (2.5054)\tPrec@1 88.281 (86.933)\tPrec@5 99.219 (98.639)\n",
            "Epoch: [36][40/329], lr: 0.01000\tTime 0.108 (0.107)\tData 0.006 (0.020)\tLoss 1.8175 (2.3473)\tPrec@1 89.844 (87.748)\tPrec@5 99.219 (98.790)\n",
            "Epoch: [36][50/329], lr: 0.01000\tTime 0.096 (0.103)\tData 0.000 (0.017)\tLoss 1.8937 (2.2228)\tPrec@1 90.625 (88.457)\tPrec@5 98.438 (98.874)\n",
            "Epoch: [36][60/329], lr: 0.01000\tTime 0.094 (0.101)\tData 0.004 (0.015)\tLoss 2.3045 (2.1609)\tPrec@1 86.719 (88.794)\tPrec@5 99.609 (98.950)\n",
            "Epoch: [36][70/329], lr: 0.01000\tTime 0.117 (0.100)\tData 0.007 (0.014)\tLoss 2.0291 (2.1135)\tPrec@1 89.844 (89.013)\tPrec@5 100.000 (99.021)\n",
            "Epoch: [36][80/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.009 (0.013)\tLoss 1.8076 (2.0655)\tPrec@1 90.625 (89.280)\tPrec@5 99.219 (99.084)\n",
            "Epoch: [36][90/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.006 (0.013)\tLoss 1.4439 (2.0485)\tPrec@1 92.188 (89.359)\tPrec@5 100.000 (99.129)\n",
            "Epoch: [36][100/329], lr: 0.01000\tTime 0.094 (0.098)\tData 0.005 (0.012)\tLoss 1.4850 (2.0234)\tPrec@1 92.188 (89.430)\tPrec@5 100.000 (99.161)\n",
            "Epoch: [36][110/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.005 (0.012)\tLoss 2.0301 (2.0184)\tPrec@1 89.453 (89.471)\tPrec@5 99.609 (99.162)\n",
            "Epoch: [36][120/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.005 (0.012)\tLoss 2.3238 (2.0118)\tPrec@1 86.719 (89.521)\tPrec@5 98.828 (99.196)\n",
            "Epoch: [36][130/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.005 (0.011)\tLoss 1.7251 (1.9994)\tPrec@1 89.844 (89.578)\tPrec@5 100.000 (99.216)\n",
            "Epoch: [36][140/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.004 (0.011)\tLoss 1.9381 (1.9892)\tPrec@1 88.281 (89.647)\tPrec@5 100.000 (99.224)\n",
            "Epoch: [36][150/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.007 (0.011)\tLoss 2.5569 (1.9897)\tPrec@1 86.328 (89.652)\tPrec@5 98.047 (99.211)\n",
            "Epoch: [36][160/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.000 (0.011)\tLoss 1.8144 (1.9865)\tPrec@1 90.234 (89.652)\tPrec@5 99.219 (99.209)\n",
            "Epoch: [36][170/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.011 (0.011)\tLoss 1.9323 (1.9913)\tPrec@1 89.844 (89.624)\tPrec@5 100.000 (99.212)\n",
            "Epoch: [36][180/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.011 (0.010)\tLoss 2.2638 (1.9903)\tPrec@1 89.844 (89.634)\tPrec@5 97.656 (99.212)\n",
            "Epoch: [36][190/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.000 (0.010)\tLoss 2.0740 (1.9751)\tPrec@1 89.453 (89.690)\tPrec@5 100.000 (99.223)\n",
            "Epoch: [36][200/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.005 (0.010)\tLoss 2.2366 (1.9759)\tPrec@1 88.672 (89.677)\tPrec@5 99.609 (99.232)\n",
            "Epoch: [36][210/329], lr: 0.01000\tTime 0.111 (0.095)\tData 0.000 (0.010)\tLoss 1.6153 (1.9739)\tPrec@1 91.406 (89.694)\tPrec@5 99.219 (99.239)\n",
            "Epoch: [36][220/329], lr: 0.01000\tTime 0.068 (0.094)\tData 0.000 (0.010)\tLoss 2.2495 (1.9765)\tPrec@1 88.672 (89.690)\tPrec@5 98.828 (99.247)\n",
            "Epoch: [36][230/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.005 (0.010)\tLoss 1.8409 (1.9706)\tPrec@1 90.234 (89.719)\tPrec@5 98.438 (99.251)\n",
            "Epoch: [36][240/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.006 (0.009)\tLoss 1.5472 (1.9598)\tPrec@1 91.797 (89.769)\tPrec@5 100.000 (99.259)\n",
            "Epoch: [36][250/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.005 (0.009)\tLoss 2.3032 (1.9539)\tPrec@1 89.453 (89.813)\tPrec@5 98.438 (99.262)\n",
            "Epoch: [36][260/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.009 (0.009)\tLoss 1.5154 (1.9504)\tPrec@1 91.797 (89.827)\tPrec@5 100.000 (99.264)\n",
            "Epoch: [36][270/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.000 (0.009)\tLoss 1.6858 (1.9419)\tPrec@1 91.406 (89.878)\tPrec@5 99.219 (99.266)\n",
            "Epoch: [36][280/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.006 (0.009)\tLoss 1.6026 (1.9335)\tPrec@1 92.188 (89.923)\tPrec@5 99.609 (99.277)\n",
            "Epoch: [36][290/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.024 (0.009)\tLoss 1.6863 (1.9234)\tPrec@1 91.406 (89.989)\tPrec@5 100.000 (99.290)\n",
            "Epoch: [36][300/329], lr: 0.01000\tTime 0.113 (0.094)\tData 0.001 (0.009)\tLoss 1.9525 (1.9257)\tPrec@1 91.016 (89.985)\tPrec@5 99.609 (99.282)\n",
            "Epoch: [36][310/329], lr: 0.01000\tTime 0.164 (0.095)\tData 0.098 (0.010)\tLoss 2.1552 (1.9262)\tPrec@1 87.891 (89.974)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [36][320/329], lr: 0.01000\tTime 0.244 (0.097)\tData 0.148 (0.011)\tLoss 2.4462 (1.9263)\tPrec@1 86.328 (89.984)\tPrec@5 99.219 (99.284)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 5.9673 (5.9673)\tPrec@1 75.000 (75.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.027 (0.058)\tLoss 5.7176 (6.1812)\tPrec@1 73.000 (72.000)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 5.1351 (6.0308)\tPrec@1 78.000 (72.762)\tPrec@5 97.000 (96.429)\n",
            "Test: [30/100]\tTime 0.033 (0.036)\tLoss 7.0021 (6.1435)\tPrec@1 68.000 (72.516)\tPrec@5 96.000 (96.516)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 5.8451 (6.0769)\tPrec@1 74.000 (72.878)\tPrec@5 94.000 (96.488)\n",
            "Test: [50/100]\tTime 0.026 (0.033)\tLoss 5.8354 (6.0533)\tPrec@1 74.000 (72.843)\tPrec@5 99.000 (96.569)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 5.8051 (6.1051)\tPrec@1 76.000 (72.557)\tPrec@5 97.000 (96.541)\n",
            "Test: [70/100]\tTime 0.011 (0.030)\tLoss 6.5670 (6.1274)\tPrec@1 72.000 (72.493)\tPrec@5 96.000 (96.479)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 5.5678 (6.0998)\tPrec@1 76.000 (72.543)\tPrec@5 97.000 (96.568)\n",
            "Test: [90/100]\tTime 0.033 (0.029)\tLoss 6.6489 (6.1728)\tPrec@1 72.000 (72.253)\tPrec@5 97.000 (96.418)\n",
            "val Results: Prec@1 72.230 Prec@5 96.410 Loss 6.18746\n",
            "val Class Accuracy: [0.914,0.963,0.636,0.727,0.614,0.837,0.821,0.570,0.427,0.714]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [37][0/329], lr: 0.01000\tTime 0.663 (0.663)\tData 0.576 (0.576)\tLoss 2.3888 (2.3888)\tPrec@1 85.547 (85.547)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [37][10/329], lr: 0.01000\tTime 0.087 (0.151)\tData 0.000 (0.059)\tLoss 2.6551 (1.8836)\tPrec@1 85.547 (90.057)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [37][20/329], lr: 0.01000\tTime 0.064 (0.122)\tData 0.000 (0.034)\tLoss 1.8257 (1.8220)\tPrec@1 91.406 (90.606)\tPrec@5 100.000 (99.368)\n",
            "Epoch: [37][30/329], lr: 0.01000\tTime 0.107 (0.114)\tData 0.006 (0.025)\tLoss 1.6181 (1.7902)\tPrec@1 92.969 (90.713)\tPrec@5 100.000 (99.408)\n",
            "Epoch: [37][40/329], lr: 0.01000\tTime 0.105 (0.108)\tData 0.000 (0.021)\tLoss 1.5695 (1.8127)\tPrec@1 91.797 (90.530)\tPrec@5 99.219 (99.428)\n",
            "Epoch: [37][50/329], lr: 0.01000\tTime 0.096 (0.104)\tData 0.002 (0.018)\tLoss 2.0455 (1.8353)\tPrec@1 89.453 (90.411)\tPrec@5 99.609 (99.479)\n",
            "Epoch: [37][60/329], lr: 0.01000\tTime 0.102 (0.103)\tData 0.004 (0.016)\tLoss 2.0073 (1.8346)\tPrec@1 89.062 (90.330)\tPrec@5 99.219 (99.443)\n",
            "Epoch: [37][70/329], lr: 0.01000\tTime 0.101 (0.102)\tData 0.008 (0.015)\tLoss 2.1026 (1.8294)\tPrec@1 88.281 (90.355)\tPrec@5 98.438 (99.439)\n",
            "Epoch: [37][80/329], lr: 0.01000\tTime 0.095 (0.100)\tData 0.005 (0.014)\tLoss 1.9805 (1.8132)\tPrec@1 89.844 (90.432)\tPrec@5 98.828 (99.421)\n",
            "Epoch: [37][90/329], lr: 0.01000\tTime 0.072 (0.099)\tData 0.000 (0.013)\tLoss 1.4613 (1.8103)\tPrec@1 92.969 (90.488)\tPrec@5 99.609 (99.433)\n",
            "Epoch: [37][100/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.001 (0.013)\tLoss 1.5874 (1.8118)\tPrec@1 91.797 (90.497)\tPrec@5 99.609 (99.443)\n",
            "Epoch: [37][110/329], lr: 0.01000\tTime 0.066 (0.098)\tData 0.000 (0.012)\tLoss 1.9489 (1.8299)\tPrec@1 89.453 (90.410)\tPrec@5 99.219 (99.447)\n",
            "Epoch: [37][120/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.000 (0.012)\tLoss 2.4396 (1.8240)\tPrec@1 87.891 (90.454)\tPrec@5 98.438 (99.441)\n",
            "Epoch: [37][130/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.007 (0.011)\tLoss 1.4092 (1.8219)\tPrec@1 92.969 (90.449)\tPrec@5 100.000 (99.433)\n",
            "Epoch: [37][140/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.004 (0.011)\tLoss 1.7790 (1.8219)\tPrec@1 90.625 (90.498)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [37][150/329], lr: 0.01000\tTime 0.118 (0.096)\tData 0.007 (0.011)\tLoss 1.8288 (1.8156)\tPrec@1 90.625 (90.506)\tPrec@5 100.000 (99.457)\n",
            "Epoch: [37][160/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.005 (0.011)\tLoss 1.5583 (1.8197)\tPrec@1 91.797 (90.482)\tPrec@5 99.609 (99.461)\n",
            "Epoch: [37][170/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.003 (0.010)\tLoss 1.6033 (1.8139)\tPrec@1 89.844 (90.520)\tPrec@5 100.000 (99.472)\n",
            "Epoch: [37][180/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.010)\tLoss 1.5023 (1.8116)\tPrec@1 92.188 (90.528)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [37][190/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.000 (0.010)\tLoss 1.8807 (1.8164)\tPrec@1 89.062 (90.500)\tPrec@5 100.000 (99.468)\n",
            "Epoch: [37][200/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.010)\tLoss 1.8299 (1.8228)\tPrec@1 90.234 (90.458)\tPrec@5 99.219 (99.462)\n",
            "Epoch: [37][210/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.008 (0.009)\tLoss 1.6244 (1.8254)\tPrec@1 91.797 (90.416)\tPrec@5 99.609 (99.445)\n",
            "Epoch: [37][220/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.000 (0.009)\tLoss 1.7296 (1.8208)\tPrec@1 91.797 (90.452)\tPrec@5 99.609 (99.450)\n",
            "Epoch: [37][230/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.007 (0.009)\tLoss 1.4251 (1.8250)\tPrec@1 92.578 (90.434)\tPrec@5 99.609 (99.452)\n",
            "Epoch: [37][240/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.004 (0.009)\tLoss 2.5847 (1.8310)\tPrec@1 87.109 (90.405)\tPrec@5 99.609 (99.447)\n",
            "Epoch: [37][250/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.012 (0.009)\tLoss 1.9490 (1.8330)\tPrec@1 89.844 (90.390)\tPrec@5 99.609 (99.448)\n",
            "Epoch: [37][260/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.004 (0.009)\tLoss 1.2636 (1.8368)\tPrec@1 94.922 (90.374)\tPrec@5 100.000 (99.443)\n",
            "Epoch: [37][270/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.007 (0.009)\tLoss 1.9386 (1.8330)\tPrec@1 90.234 (90.404)\tPrec@5 99.219 (99.448)\n",
            "Epoch: [37][280/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.004 (0.009)\tLoss 2.0508 (1.8362)\tPrec@1 90.234 (90.394)\tPrec@5 99.219 (99.444)\n",
            "Epoch: [37][290/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.005 (0.009)\tLoss 1.3594 (1.8328)\tPrec@1 93.359 (90.416)\tPrec@5 99.609 (99.450)\n",
            "Epoch: [37][300/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.009)\tLoss 2.0098 (1.8345)\tPrec@1 88.672 (90.406)\tPrec@5 98.828 (99.446)\n",
            "Epoch: [37][310/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.004 (0.009)\tLoss 1.5374 (1.8290)\tPrec@1 93.359 (90.445)\tPrec@5 98.438 (99.441)\n",
            "Epoch: [37][320/329], lr: 0.01000\tTime 0.112 (0.092)\tData 0.073 (0.009)\tLoss 1.6638 (1.8285)\tPrec@1 91.016 (90.442)\tPrec@5 99.219 (99.435)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 6.9400 (6.9400)\tPrec@1 69.000 (69.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.019 (0.054)\tLoss 5.2197 (7.1902)\tPrec@1 74.000 (66.455)\tPrec@5 96.000 (94.818)\n",
            "Test: [20/100]\tTime 0.020 (0.041)\tLoss 6.0220 (7.0648)\tPrec@1 72.000 (67.667)\tPrec@5 98.000 (94.905)\n",
            "Test: [30/100]\tTime 0.042 (0.035)\tLoss 6.5677 (7.2558)\tPrec@1 70.000 (66.613)\tPrec@5 95.000 (94.871)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 6.6990 (7.2964)\tPrec@1 69.000 (66.610)\tPrec@5 97.000 (94.829)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 7.4391 (7.2587)\tPrec@1 67.000 (66.961)\tPrec@5 95.000 (94.902)\n",
            "Test: [60/100]\tTime 0.011 (0.030)\tLoss 6.5966 (7.2889)\tPrec@1 71.000 (66.787)\tPrec@5 95.000 (94.984)\n",
            "Test: [70/100]\tTime 0.030 (0.029)\tLoss 7.5311 (7.3051)\tPrec@1 65.000 (66.634)\tPrec@5 97.000 (94.887)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 7.5394 (7.3055)\tPrec@1 65.000 (66.593)\tPrec@5 94.000 (94.963)\n",
            "Test: [90/100]\tTime 0.037 (0.028)\tLoss 7.9988 (7.3880)\tPrec@1 65.000 (66.165)\tPrec@5 93.000 (94.857)\n",
            "val Results: Prec@1 66.060 Prec@5 94.860 Loss 7.41916\n",
            "val Class Accuracy: [0.870,0.850,0.738,0.571,0.672,0.612,0.956,0.598,0.315,0.424]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [38][0/329], lr: 0.01000\tTime 0.531 (0.531)\tData 0.443 (0.443)\tLoss 2.0618 (2.0618)\tPrec@1 89.453 (89.453)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [38][10/329], lr: 0.01000\tTime 0.152 (0.159)\tData 0.000 (0.047)\tLoss 3.8472 (3.7629)\tPrec@1 80.078 (79.190)\tPrec@5 98.438 (96.733)\n",
            "Epoch: [38][20/329], lr: 0.01000\tTime 0.115 (0.137)\tData 0.066 (0.033)\tLoss 2.9561 (3.6010)\tPrec@1 83.203 (80.171)\tPrec@5 98.438 (96.856)\n",
            "Epoch: [38][30/329], lr: 0.01000\tTime 0.110 (0.143)\tData 0.000 (0.035)\tLoss 2.9677 (3.3793)\tPrec@1 84.766 (81.704)\tPrec@5 99.219 (97.480)\n",
            "Epoch: [38][40/329], lr: 0.01000\tTime 0.097 (0.138)\tData 0.004 (0.033)\tLoss 3.6643 (3.1522)\tPrec@1 81.250 (83.070)\tPrec@5 97.656 (97.742)\n",
            "Epoch: [38][50/329], lr: 0.01000\tTime 0.090 (0.129)\tData 0.008 (0.028)\tLoss 2.2255 (2.9241)\tPrec@1 88.281 (84.360)\tPrec@5 98.828 (98.062)\n",
            "Epoch: [38][60/329], lr: 0.01000\tTime 0.088 (0.123)\tData 0.001 (0.024)\tLoss 1.7749 (2.7937)\tPrec@1 91.016 (85.022)\tPrec@5 99.219 (98.252)\n",
            "Epoch: [38][70/329], lr: 0.01000\tTime 0.096 (0.120)\tData 0.004 (0.022)\tLoss 2.0577 (2.7196)\tPrec@1 90.625 (85.404)\tPrec@5 99.219 (98.388)\n",
            "Epoch: [38][80/329], lr: 0.01000\tTime 0.071 (0.116)\tData 0.004 (0.020)\tLoss 2.1647 (2.6533)\tPrec@1 89.062 (85.827)\tPrec@5 98.438 (98.481)\n",
            "Epoch: [38][90/329], lr: 0.01000\tTime 0.111 (0.114)\tData 0.000 (0.019)\tLoss 2.1985 (2.5981)\tPrec@1 89.062 (86.135)\tPrec@5 99.219 (98.562)\n",
            "Epoch: [38][100/329], lr: 0.01000\tTime 0.082 (0.111)\tData 0.004 (0.018)\tLoss 1.5725 (2.5166)\tPrec@1 91.797 (86.607)\tPrec@5 99.609 (98.646)\n",
            "Epoch: [38][110/329], lr: 0.01000\tTime 0.108 (0.109)\tData 0.012 (0.017)\tLoss 1.7741 (2.4754)\tPrec@1 91.016 (86.852)\tPrec@5 100.000 (98.716)\n",
            "Epoch: [38][120/329], lr: 0.01000\tTime 0.061 (0.108)\tData 0.000 (0.016)\tLoss 1.3959 (2.4235)\tPrec@1 92.969 (87.187)\tPrec@5 100.000 (98.767)\n",
            "Epoch: [38][130/329], lr: 0.01000\tTime 0.078 (0.106)\tData 0.000 (0.015)\tLoss 2.1279 (2.3869)\tPrec@1 89.062 (87.399)\tPrec@5 99.609 (98.810)\n",
            "Epoch: [38][140/329], lr: 0.01000\tTime 0.108 (0.105)\tData 0.002 (0.015)\tLoss 1.8927 (2.3578)\tPrec@1 91.016 (87.544)\tPrec@5 99.609 (98.853)\n",
            "Epoch: [38][150/329], lr: 0.01000\tTime 0.073 (0.104)\tData 0.000 (0.014)\tLoss 2.0758 (2.3275)\tPrec@1 89.062 (87.720)\tPrec@5 98.828 (98.893)\n",
            "Epoch: [38][160/329], lr: 0.01000\tTime 0.104 (0.103)\tData 0.005 (0.013)\tLoss 1.9583 (2.2978)\tPrec@1 90.234 (87.903)\tPrec@5 98.438 (98.913)\n",
            "Epoch: [38][170/329], lr: 0.01000\tTime 0.062 (0.102)\tData 0.006 (0.013)\tLoss 1.7813 (2.2603)\tPrec@1 89.453 (88.108)\tPrec@5 99.219 (98.954)\n",
            "Epoch: [38][180/329], lr: 0.01000\tTime 0.077 (0.101)\tData 0.005 (0.013)\tLoss 1.8983 (2.2392)\tPrec@1 90.625 (88.234)\tPrec@5 98.828 (98.958)\n",
            "Epoch: [38][190/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.000 (0.012)\tLoss 1.6845 (2.2296)\tPrec@1 91.797 (88.287)\tPrec@5 99.609 (98.979)\n",
            "Epoch: [38][200/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.005 (0.012)\tLoss 1.5873 (2.2108)\tPrec@1 92.578 (88.400)\tPrec@5 99.609 (98.999)\n",
            "Epoch: [38][210/329], lr: 0.01000\tTime 0.103 (0.100)\tData 0.005 (0.012)\tLoss 1.8884 (2.2024)\tPrec@1 88.672 (88.439)\tPrec@5 98.828 (99.002)\n",
            "Epoch: [38][220/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.007 (0.011)\tLoss 1.7400 (2.1847)\tPrec@1 90.625 (88.553)\tPrec@5 99.219 (99.024)\n",
            "Epoch: [38][230/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.005 (0.011)\tLoss 1.6955 (2.1738)\tPrec@1 90.625 (88.611)\tPrec@5 99.219 (99.036)\n",
            "Epoch: [38][240/329], lr: 0.01000\tTime 0.115 (0.099)\tData 0.000 (0.011)\tLoss 1.3307 (2.1585)\tPrec@1 93.359 (88.699)\tPrec@5 99.609 (99.057)\n",
            "Epoch: [38][250/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.000 (0.011)\tLoss 1.9460 (2.1415)\tPrec@1 90.234 (88.789)\tPrec@5 100.000 (99.077)\n",
            "Epoch: [38][260/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.005 (0.011)\tLoss 2.0187 (2.1342)\tPrec@1 89.453 (88.819)\tPrec@5 99.609 (99.084)\n",
            "Epoch: [38][270/329], lr: 0.01000\tTime 0.110 (0.098)\tData 0.000 (0.011)\tLoss 1.5487 (2.1275)\tPrec@1 91.406 (88.856)\tPrec@5 99.219 (99.089)\n",
            "Epoch: [38][280/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.005 (0.010)\tLoss 1.9902 (2.1195)\tPrec@1 89.844 (88.898)\tPrec@5 99.609 (99.106)\n",
            "Epoch: [38][290/329], lr: 0.01000\tTime 0.086 (0.097)\tData 0.004 (0.010)\tLoss 1.6747 (2.1109)\tPrec@1 91.797 (88.935)\tPrec@5 100.000 (99.122)\n",
            "Epoch: [38][300/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.000 (0.010)\tLoss 1.9042 (2.1044)\tPrec@1 91.406 (88.974)\tPrec@5 98.438 (99.129)\n",
            "Epoch: [38][310/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.009 (0.010)\tLoss 1.8857 (2.0977)\tPrec@1 90.234 (89.010)\tPrec@5 99.219 (99.128)\n",
            "Epoch: [38][320/329], lr: 0.01000\tTime 0.122 (0.096)\tData 0.063 (0.010)\tLoss 2.2653 (2.0925)\tPrec@1 89.062 (89.053)\tPrec@5 100.000 (99.131)\n",
            "Test: [0/100]\tTime 0.380 (0.380)\tLoss 8.2913 (8.2913)\tPrec@1 64.000 (64.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.011 (0.056)\tLoss 7.3631 (7.9234)\tPrec@1 67.000 (63.455)\tPrec@5 94.000 (96.455)\n",
            "Test: [20/100]\tTime 0.010 (0.041)\tLoss 6.7392 (8.0138)\tPrec@1 67.000 (62.571)\tPrec@5 99.000 (96.810)\n",
            "Test: [30/100]\tTime 0.028 (0.034)\tLoss 7.7056 (7.9335)\tPrec@1 67.000 (63.419)\tPrec@5 95.000 (96.516)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 6.9978 (7.8374)\tPrec@1 66.000 (63.927)\tPrec@5 97.000 (96.610)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 7.7952 (7.8106)\tPrec@1 64.000 (64.078)\tPrec@5 96.000 (96.706)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 6.9070 (7.8515)\tPrec@1 66.000 (63.869)\tPrec@5 98.000 (96.803)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 8.2528 (7.8684)\tPrec@1 61.000 (63.873)\tPrec@5 96.000 (96.789)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 7.2773 (7.8483)\tPrec@1 66.000 (63.790)\tPrec@5 97.000 (96.877)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 8.4051 (7.9394)\tPrec@1 62.000 (63.429)\tPrec@5 100.000 (96.901)\n",
            "val Results: Prec@1 63.440 Prec@5 96.780 Loss 7.95385\n",
            "val Class Accuracy: [0.976,0.884,0.794,0.638,0.678,0.538,0.404,0.800,0.268,0.364]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [39][0/329], lr: 0.01000\tTime 0.614 (0.614)\tData 0.526 (0.526)\tLoss 2.1532 (2.1532)\tPrec@1 88.281 (88.281)\tPrec@5 98.047 (98.047)\n",
            "Epoch: [39][10/329], lr: 0.01000\tTime 0.098 (0.145)\tData 0.000 (0.053)\tLoss 4.7816 (4.4391)\tPrec@1 71.875 (74.893)\tPrec@5 97.656 (96.875)\n",
            "Epoch: [39][20/329], lr: 0.01000\tTime 0.106 (0.121)\tData 0.000 (0.031)\tLoss 3.3646 (4.3130)\tPrec@1 80.859 (75.707)\tPrec@5 99.609 (97.321)\n",
            "Epoch: [39][30/329], lr: 0.01000\tTime 0.075 (0.111)\tData 0.005 (0.022)\tLoss 3.0659 (3.9900)\tPrec@1 83.594 (77.621)\tPrec@5 98.828 (97.618)\n",
            "Epoch: [39][40/329], lr: 0.01000\tTime 0.064 (0.106)\tData 0.003 (0.018)\tLoss 2.8171 (3.7545)\tPrec@1 84.375 (79.040)\tPrec@5 99.219 (97.866)\n",
            "Epoch: [39][50/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.015 (0.016)\tLoss 2.4021 (3.5370)\tPrec@1 88.672 (80.568)\tPrec@5 98.438 (98.100)\n",
            "Epoch: [39][60/329], lr: 0.01000\tTime 0.102 (0.101)\tData 0.007 (0.015)\tLoss 2.6846 (3.3660)\tPrec@1 85.156 (81.564)\tPrec@5 99.609 (98.233)\n",
            "Epoch: [39][70/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.000 (0.013)\tLoss 2.6075 (3.2469)\tPrec@1 87.109 (82.279)\tPrec@5 98.828 (98.305)\n",
            "Epoch: [39][80/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.004 (0.013)\tLoss 2.1073 (3.1311)\tPrec@1 88.281 (83.010)\tPrec@5 99.609 (98.418)\n",
            "Epoch: [39][90/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.000 (0.012)\tLoss 3.2021 (3.0543)\tPrec@1 82.422 (83.465)\tPrec@5 99.219 (98.493)\n",
            "Epoch: [39][100/329], lr: 0.01000\tTime 0.122 (0.100)\tData 0.000 (0.011)\tLoss 2.5503 (2.9909)\tPrec@1 86.719 (83.864)\tPrec@5 99.609 (98.581)\n",
            "Epoch: [39][110/329], lr: 0.01000\tTime 0.077 (0.101)\tData 0.012 (0.011)\tLoss 2.4417 (2.9339)\tPrec@1 84.766 (84.227)\tPrec@5 97.656 (98.613)\n",
            "Epoch: [39][120/329], lr: 0.01000\tTime 0.130 (0.103)\tData 0.005 (0.012)\tLoss 1.5970 (2.8725)\tPrec@1 92.188 (84.575)\tPrec@5 99.219 (98.676)\n",
            "Epoch: [39][130/329], lr: 0.01000\tTime 0.108 (0.105)\tData 0.009 (0.014)\tLoss 2.3333 (2.8133)\tPrec@1 87.891 (84.921)\tPrec@5 98.828 (98.712)\n",
            "Epoch: [39][140/329], lr: 0.01000\tTime 0.103 (0.105)\tData 0.006 (0.014)\tLoss 1.9882 (2.7684)\tPrec@1 89.844 (85.176)\tPrec@5 98.047 (98.742)\n",
            "Epoch: [39][150/329], lr: 0.01000\tTime 0.099 (0.104)\tData 0.006 (0.013)\tLoss 2.3741 (2.7322)\tPrec@1 87.891 (85.374)\tPrec@5 99.609 (98.779)\n",
            "Epoch: [39][160/329], lr: 0.01000\tTime 0.087 (0.103)\tData 0.007 (0.013)\tLoss 1.1669 (2.6820)\tPrec@1 94.141 (85.668)\tPrec@5 100.000 (98.831)\n",
            "Epoch: [39][170/329], lr: 0.01000\tTime 0.117 (0.103)\tData 0.005 (0.012)\tLoss 1.6419 (2.6396)\tPrec@1 91.797 (85.894)\tPrec@5 100.000 (98.872)\n",
            "Epoch: [39][180/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.009 (0.012)\tLoss 1.9472 (2.6030)\tPrec@1 89.844 (86.089)\tPrec@5 100.000 (98.902)\n",
            "Epoch: [39][190/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.007 (0.012)\tLoss 2.2477 (2.5793)\tPrec@1 88.281 (86.228)\tPrec@5 98.438 (98.902)\n",
            "Epoch: [39][200/329], lr: 0.01000\tTime 0.075 (0.101)\tData 0.005 (0.012)\tLoss 2.2337 (2.5537)\tPrec@1 89.062 (86.383)\tPrec@5 98.047 (98.914)\n",
            "Epoch: [39][210/329], lr: 0.01000\tTime 0.114 (0.100)\tData 0.000 (0.012)\tLoss 2.3413 (2.5288)\tPrec@1 88.281 (86.530)\tPrec@5 98.828 (98.939)\n",
            "Epoch: [39][220/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.000 (0.011)\tLoss 1.5955 (2.5026)\tPrec@1 91.797 (86.680)\tPrec@5 99.219 (98.959)\n",
            "Epoch: [39][230/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.005 (0.011)\tLoss 2.1059 (2.4847)\tPrec@1 89.453 (86.780)\tPrec@5 98.828 (98.975)\n",
            "Epoch: [39][240/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.003 (0.011)\tLoss 2.0271 (2.4667)\tPrec@1 88.672 (86.873)\tPrec@5 99.219 (98.995)\n",
            "Epoch: [39][250/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.005 (0.011)\tLoss 2.2172 (2.4500)\tPrec@1 88.281 (86.972)\tPrec@5 98.047 (98.992)\n",
            "Epoch: [39][260/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.004 (0.011)\tLoss 1.5271 (2.4293)\tPrec@1 92.969 (87.117)\tPrec@5 98.828 (98.997)\n",
            "Epoch: [39][270/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.006 (0.011)\tLoss 2.2783 (2.4082)\tPrec@1 87.109 (87.233)\tPrec@5 100.000 (99.013)\n",
            "Epoch: [39][280/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.005 (0.011)\tLoss 2.2450 (2.3967)\tPrec@1 87.891 (87.280)\tPrec@5 99.609 (99.023)\n",
            "Epoch: [39][290/329], lr: 0.01000\tTime 0.114 (0.098)\tData 0.003 (0.010)\tLoss 1.9771 (2.3771)\tPrec@1 91.406 (87.393)\tPrec@5 98.828 (99.035)\n",
            "Epoch: [39][300/329], lr: 0.01000\tTime 0.075 (0.097)\tData 0.007 (0.010)\tLoss 1.8451 (2.3618)\tPrec@1 91.406 (87.486)\tPrec@5 99.219 (99.037)\n",
            "Epoch: [39][310/329], lr: 0.01000\tTime 0.071 (0.097)\tData 0.000 (0.010)\tLoss 1.8379 (2.3421)\tPrec@1 90.234 (87.597)\tPrec@5 99.219 (99.055)\n",
            "Epoch: [39][320/329], lr: 0.01000\tTime 0.110 (0.097)\tData 0.077 (0.010)\tLoss 1.8972 (2.3309)\tPrec@1 89.844 (87.665)\tPrec@5 98.828 (99.064)\n",
            "Test: [0/100]\tTime 0.290 (0.290)\tLoss 5.1868 (5.1868)\tPrec@1 77.000 (77.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.020 (0.055)\tLoss 5.3044 (5.9060)\tPrec@1 72.000 (72.636)\tPrec@5 99.000 (97.636)\n",
            "Test: [20/100]\tTime 0.030 (0.041)\tLoss 5.5453 (5.7451)\tPrec@1 73.000 (73.286)\tPrec@5 98.000 (97.286)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 6.7936 (5.9015)\tPrec@1 72.000 (72.516)\tPrec@5 97.000 (97.226)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 5.3953 (5.8789)\tPrec@1 75.000 (72.829)\tPrec@5 95.000 (97.268)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 5.3607 (5.8047)\tPrec@1 75.000 (73.196)\tPrec@5 94.000 (97.314)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 6.6790 (5.8939)\tPrec@1 70.000 (72.705)\tPrec@5 98.000 (97.410)\n",
            "Test: [70/100]\tTime 0.038 (0.029)\tLoss 6.1358 (5.9178)\tPrec@1 70.000 (72.479)\tPrec@5 99.000 (97.423)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 5.7502 (5.9292)\tPrec@1 72.000 (72.370)\tPrec@5 98.000 (97.481)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 5.7061 (5.9686)\tPrec@1 76.000 (72.132)\tPrec@5 100.000 (97.429)\n",
            "val Results: Prec@1 72.270 Prec@5 97.340 Loss 5.96376\n",
            "val Class Accuracy: [0.862,0.883,0.565,0.452,0.946,0.635,0.871,0.433,0.823,0.757]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [40][0/329], lr: 0.01000\tTime 0.585 (0.585)\tData 0.513 (0.513)\tLoss 2.3908 (2.3908)\tPrec@1 88.672 (88.672)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [40][10/329], lr: 0.01000\tTime 0.083 (0.145)\tData 0.005 (0.052)\tLoss 2.2472 (2.3309)\tPrec@1 88.672 (88.317)\tPrec@5 98.438 (98.899)\n",
            "Epoch: [40][20/329], lr: 0.01000\tTime 0.080 (0.120)\tData 0.000 (0.030)\tLoss 2.5681 (2.2518)\tPrec@1 85.156 (88.653)\tPrec@5 99.609 (99.033)\n",
            "Epoch: [40][30/329], lr: 0.01000\tTime 0.072 (0.113)\tData 0.000 (0.022)\tLoss 1.6502 (2.1789)\tPrec@1 91.406 (88.785)\tPrec@5 99.609 (99.042)\n",
            "Epoch: [40][40/329], lr: 0.01000\tTime 0.101 (0.109)\tData 0.005 (0.019)\tLoss 1.6933 (2.1679)\tPrec@1 90.625 (88.700)\tPrec@5 100.000 (99.181)\n",
            "Epoch: [40][50/329], lr: 0.01000\tTime 0.087 (0.106)\tData 0.000 (0.016)\tLoss 2.2073 (2.1438)\tPrec@1 87.891 (88.779)\tPrec@5 98.047 (99.165)\n",
            "Epoch: [40][60/329], lr: 0.01000\tTime 0.089 (0.103)\tData 0.007 (0.015)\tLoss 2.1181 (2.1069)\tPrec@1 88.281 (88.934)\tPrec@5 100.000 (99.212)\n",
            "Epoch: [40][70/329], lr: 0.01000\tTime 0.091 (0.102)\tData 0.002 (0.014)\tLoss 1.7378 (2.0795)\tPrec@1 91.016 (89.107)\tPrec@5 99.609 (99.230)\n",
            "Epoch: [40][80/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.007 (0.013)\tLoss 1.7228 (2.0685)\tPrec@1 91.406 (89.159)\tPrec@5 100.000 (99.277)\n",
            "Epoch: [40][90/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.005 (0.013)\tLoss 1.2238 (2.0529)\tPrec@1 93.750 (89.260)\tPrec@5 100.000 (99.283)\n",
            "Epoch: [40][100/329], lr: 0.01000\tTime 0.067 (0.098)\tData 0.000 (0.012)\tLoss 2.1557 (2.0306)\tPrec@1 89.062 (89.399)\tPrec@5 98.438 (99.281)\n",
            "Epoch: [40][110/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.000 (0.012)\tLoss 1.4309 (2.0215)\tPrec@1 92.578 (89.460)\tPrec@5 100.000 (99.286)\n",
            "Epoch: [40][120/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.000 (0.012)\tLoss 1.8233 (2.0047)\tPrec@1 90.234 (89.524)\tPrec@5 98.828 (99.283)\n",
            "Epoch: [40][130/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.002 (0.011)\tLoss 2.0380 (1.9951)\tPrec@1 89.453 (89.584)\tPrec@5 99.609 (99.299)\n",
            "Epoch: [40][140/329], lr: 0.01000\tTime 0.132 (0.097)\tData 0.010 (0.011)\tLoss 2.1450 (1.9858)\tPrec@1 90.234 (89.653)\tPrec@5 98.438 (99.302)\n",
            "Epoch: [40][150/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.007 (0.011)\tLoss 1.4862 (1.9677)\tPrec@1 93.359 (89.761)\tPrec@5 100.000 (99.314)\n",
            "Epoch: [40][160/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.004 (0.010)\tLoss 2.0774 (1.9621)\tPrec@1 87.500 (89.776)\tPrec@5 99.219 (99.306)\n",
            "Epoch: [40][170/329], lr: 0.01000\tTime 0.117 (0.096)\tData 0.002 (0.010)\tLoss 1.5110 (1.9547)\tPrec@1 90.625 (89.821)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [40][180/329], lr: 0.01000\tTime 0.111 (0.096)\tData 0.007 (0.010)\tLoss 1.3643 (1.9451)\tPrec@1 92.578 (89.863)\tPrec@5 99.609 (99.325)\n",
            "Epoch: [40][190/329], lr: 0.01000\tTime 0.110 (0.097)\tData 0.005 (0.010)\tLoss 2.0314 (1.9463)\tPrec@1 89.844 (89.866)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [40][200/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.000 (0.010)\tLoss 2.7710 (1.9374)\tPrec@1 84.375 (89.937)\tPrec@5 99.219 (99.343)\n",
            "Epoch: [40][210/329], lr: 0.01000\tTime 0.137 (0.100)\tData 0.000 (0.011)\tLoss 2.4437 (1.9397)\tPrec@1 87.500 (89.927)\tPrec@5 99.609 (99.346)\n",
            "Epoch: [40][220/329], lr: 0.01000\tTime 0.107 (0.100)\tData 0.000 (0.011)\tLoss 1.9231 (1.9368)\tPrec@1 90.625 (89.953)\tPrec@5 98.438 (99.337)\n",
            "Epoch: [40][230/329], lr: 0.01000\tTime 0.101 (0.100)\tData 0.005 (0.011)\tLoss 2.2983 (1.9355)\tPrec@1 88.281 (89.979)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [40][240/329], lr: 0.01000\tTime 0.106 (0.100)\tData 0.000 (0.011)\tLoss 1.3517 (1.9301)\tPrec@1 92.969 (90.014)\tPrec@5 100.000 (99.342)\n",
            "Epoch: [40][250/329], lr: 0.01000\tTime 0.081 (0.100)\tData 0.011 (0.010)\tLoss 2.3847 (1.9288)\tPrec@1 87.891 (90.007)\tPrec@5 98.438 (99.349)\n",
            "Epoch: [40][260/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.007 (0.010)\tLoss 1.5807 (1.9264)\tPrec@1 92.578 (90.014)\tPrec@5 99.219 (99.340)\n",
            "Epoch: [40][270/329], lr: 0.01000\tTime 0.112 (0.099)\tData 0.006 (0.010)\tLoss 2.0130 (1.9239)\tPrec@1 88.281 (90.028)\tPrec@5 98.828 (99.346)\n",
            "Epoch: [40][280/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.010)\tLoss 1.6299 (1.9207)\tPrec@1 93.359 (90.052)\tPrec@5 100.000 (99.349)\n",
            "Epoch: [40][290/329], lr: 0.01000\tTime 0.069 (0.099)\tData 0.008 (0.010)\tLoss 2.3482 (1.9244)\tPrec@1 86.328 (90.025)\tPrec@5 99.219 (99.356)\n",
            "Epoch: [40][300/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.000 (0.010)\tLoss 2.0474 (1.9257)\tPrec@1 89.062 (90.024)\tPrec@5 100.000 (99.364)\n",
            "Epoch: [40][310/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.012 (0.010)\tLoss 1.9906 (1.9254)\tPrec@1 90.625 (90.030)\tPrec@5 99.609 (99.366)\n",
            "Epoch: [40][320/329], lr: 0.01000\tTime 0.133 (0.098)\tData 0.093 (0.010)\tLoss 1.7182 (1.9243)\tPrec@1 91.016 (90.038)\tPrec@5 98.438 (99.368)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 5.2196 (5.2196)\tPrec@1 76.000 (76.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.058)\tLoss 4.7409 (6.0547)\tPrec@1 76.000 (72.727)\tPrec@5 100.000 (98.273)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 4.7451 (5.7899)\tPrec@1 77.000 (73.810)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.020 (0.034)\tLoss 6.5601 (5.8189)\tPrec@1 68.000 (73.774)\tPrec@5 97.000 (97.645)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 5.7515 (5.8842)\tPrec@1 73.000 (73.390)\tPrec@5 96.000 (97.488)\n",
            "Test: [50/100]\tTime 0.040 (0.032)\tLoss 6.1110 (5.8457)\tPrec@1 71.000 (73.235)\tPrec@5 96.000 (97.529)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 5.6654 (5.9178)\tPrec@1 76.000 (72.885)\tPrec@5 97.000 (97.557)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 5.5349 (5.9333)\tPrec@1 74.000 (72.803)\tPrec@5 98.000 (97.549)\n",
            "Test: [80/100]\tTime 0.016 (0.030)\tLoss 5.1436 (5.8787)\tPrec@1 78.000 (73.025)\tPrec@5 96.000 (97.543)\n",
            "Test: [90/100]\tTime 0.035 (0.029)\tLoss 6.3076 (5.9558)\tPrec@1 71.000 (72.681)\tPrec@5 99.000 (97.473)\n",
            "val Results: Prec@1 72.620 Prec@5 97.430 Loss 5.97237\n",
            "val Class Accuracy: [0.839,0.962,0.865,0.766,0.588,0.601,0.805,0.615,0.611,0.610]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [41][0/329], lr: 0.01000\tTime 0.578 (0.578)\tData 0.454 (0.454)\tLoss 2.0076 (2.0076)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [41][10/329], lr: 0.01000\tTime 0.105 (0.143)\tData 0.024 (0.052)\tLoss 2.0294 (2.2922)\tPrec@1 91.016 (88.494)\tPrec@5 98.828 (99.148)\n",
            "Epoch: [41][20/329], lr: 0.01000\tTime 0.096 (0.120)\tData 0.001 (0.034)\tLoss 2.0648 (2.2216)\tPrec@1 88.281 (88.728)\tPrec@5 98.828 (99.163)\n",
            "Epoch: [41][30/329], lr: 0.01000\tTime 0.102 (0.112)\tData 0.005 (0.027)\tLoss 1.9709 (2.0905)\tPrec@1 89.453 (89.214)\tPrec@5 99.219 (99.194)\n",
            "Epoch: [41][40/329], lr: 0.01000\tTime 0.092 (0.108)\tData 0.000 (0.022)\tLoss 2.4364 (2.0480)\tPrec@1 87.109 (89.444)\tPrec@5 99.609 (99.276)\n",
            "Epoch: [41][50/329], lr: 0.01000\tTime 0.115 (0.105)\tData 0.007 (0.019)\tLoss 2.0995 (2.0113)\tPrec@1 90.234 (89.652)\tPrec@5 99.609 (99.280)\n",
            "Epoch: [41][60/329], lr: 0.01000\tTime 0.106 (0.103)\tData 0.000 (0.017)\tLoss 1.7592 (1.9588)\tPrec@1 91.406 (89.914)\tPrec@5 100.000 (99.328)\n",
            "Epoch: [41][70/329], lr: 0.01000\tTime 0.103 (0.101)\tData 0.006 (0.015)\tLoss 2.0203 (1.9400)\tPrec@1 89.453 (90.014)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [41][80/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.005 (0.014)\tLoss 2.2564 (1.9075)\tPrec@1 89.062 (90.210)\tPrec@5 99.219 (99.402)\n",
            "Epoch: [41][90/329], lr: 0.01000\tTime 0.127 (0.099)\tData 0.002 (0.013)\tLoss 2.1007 (1.8880)\tPrec@1 89.062 (90.303)\tPrec@5 100.000 (99.425)\n",
            "Epoch: [41][100/329], lr: 0.01000\tTime 0.089 (0.098)\tData 0.009 (0.013)\tLoss 1.8310 (1.8736)\tPrec@1 91.406 (90.350)\tPrec@5 99.219 (99.420)\n",
            "Epoch: [41][110/329], lr: 0.01000\tTime 0.080 (0.097)\tData 0.004 (0.012)\tLoss 1.5125 (1.8760)\tPrec@1 92.188 (90.333)\tPrec@5 99.219 (99.416)\n",
            "Epoch: [41][120/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.005 (0.012)\tLoss 2.1288 (1.8811)\tPrec@1 88.281 (90.276)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [41][130/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.005 (0.011)\tLoss 2.0287 (1.8841)\tPrec@1 89.062 (90.273)\tPrec@5 99.609 (99.451)\n",
            "Epoch: [41][140/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.000 (0.011)\tLoss 1.6961 (1.8774)\tPrec@1 92.578 (90.317)\tPrec@5 100.000 (99.454)\n",
            "Epoch: [41][150/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.005 (0.010)\tLoss 1.9953 (1.8746)\tPrec@1 89.844 (90.340)\tPrec@5 98.438 (99.439)\n",
            "Epoch: [41][160/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.000 (0.010)\tLoss 1.5388 (1.8594)\tPrec@1 92.578 (90.411)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [41][170/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.005 (0.010)\tLoss 2.4906 (1.8630)\tPrec@1 88.281 (90.392)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [41][180/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.000 (0.010)\tLoss 1.8066 (1.8604)\tPrec@1 90.234 (90.416)\tPrec@5 99.609 (99.415)\n",
            "Epoch: [41][190/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.010)\tLoss 1.4904 (1.8562)\tPrec@1 92.969 (90.429)\tPrec@5 99.219 (99.415)\n",
            "Epoch: [41][200/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.007 (0.009)\tLoss 1.4817 (1.8509)\tPrec@1 92.578 (90.454)\tPrec@5 99.609 (99.411)\n",
            "Epoch: [41][210/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.003 (0.009)\tLoss 1.4017 (1.8384)\tPrec@1 94.531 (90.523)\tPrec@5 99.219 (99.419)\n",
            "Epoch: [41][220/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.007 (0.009)\tLoss 2.1991 (1.8411)\tPrec@1 87.891 (90.492)\tPrec@5 99.219 (99.426)\n",
            "Epoch: [41][230/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.009 (0.009)\tLoss 2.2612 (1.8483)\tPrec@1 87.891 (90.449)\tPrec@5 99.609 (99.423)\n",
            "Epoch: [41][240/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.005 (0.009)\tLoss 1.4726 (1.8436)\tPrec@1 92.578 (90.476)\tPrec@5 99.219 (99.425)\n",
            "Epoch: [41][250/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.001 (0.009)\tLoss 1.7000 (1.8438)\tPrec@1 92.578 (90.479)\tPrec@5 99.219 (99.435)\n",
            "Epoch: [41][260/329], lr: 0.01000\tTime 0.107 (0.094)\tData 0.000 (0.009)\tLoss 1.8774 (1.8411)\tPrec@1 90.625 (90.492)\tPrec@5 99.219 (99.430)\n",
            "Epoch: [41][270/329], lr: 0.01000\tTime 0.121 (0.095)\tData 0.010 (0.009)\tLoss 1.8162 (1.8443)\tPrec@1 90.625 (90.456)\tPrec@5 99.219 (99.439)\n",
            "Epoch: [41][280/329], lr: 0.01000\tTime 0.137 (0.096)\tData 0.002 (0.009)\tLoss 2.1745 (1.8448)\tPrec@1 88.281 (90.454)\tPrec@5 98.828 (99.424)\n",
            "Epoch: [41][290/329], lr: 0.01000\tTime 0.123 (0.097)\tData 0.044 (0.009)\tLoss 1.3519 (1.8434)\tPrec@1 92.578 (90.445)\tPrec@5 99.219 (99.424)\n",
            "Epoch: [41][300/329], lr: 0.01000\tTime 0.103 (0.097)\tData 0.007 (0.009)\tLoss 2.3882 (1.8471)\tPrec@1 86.328 (90.412)\tPrec@5 99.219 (99.426)\n",
            "Epoch: [41][310/329], lr: 0.01000\tTime 0.106 (0.097)\tData 0.005 (0.009)\tLoss 1.7986 (1.8468)\tPrec@1 91.406 (90.420)\tPrec@5 99.609 (99.422)\n",
            "Epoch: [41][320/329], lr: 0.01000\tTime 0.190 (0.097)\tData 0.097 (0.009)\tLoss 1.9209 (1.8501)\tPrec@1 90.234 (90.408)\tPrec@5 99.219 (99.418)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 13.9501 (13.9501)\tPrec@1 37.000 (37.000)\tPrec@5 88.000 (88.000)\n",
            "Test: [10/100]\tTime 0.022 (0.057)\tLoss 10.8051 (12.7496)\tPrec@1 51.000 (43.182)\tPrec@5 93.000 (89.545)\n",
            "Test: [20/100]\tTime 0.014 (0.042)\tLoss 10.5782 (12.9733)\tPrec@1 49.000 (41.238)\tPrec@5 92.000 (89.667)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 11.8598 (12.9053)\tPrec@1 44.000 (41.548)\tPrec@5 89.000 (89.903)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 13.2515 (12.9572)\tPrec@1 37.000 (41.244)\tPrec@5 87.000 (89.707)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 13.4434 (12.9364)\tPrec@1 40.000 (41.471)\tPrec@5 84.000 (89.863)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 11.0977 (12.9446)\tPrec@1 49.000 (41.311)\tPrec@5 93.000 (89.918)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 12.2366 (12.8835)\tPrec@1 47.000 (41.549)\tPrec@5 90.000 (90.042)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 12.1673 (12.8324)\tPrec@1 45.000 (41.605)\tPrec@5 92.000 (90.111)\n",
            "Test: [90/100]\tTime 0.042 (0.029)\tLoss 12.4932 (12.9103)\tPrec@1 43.000 (41.352)\tPrec@5 96.000 (90.055)\n",
            "val Results: Prec@1 41.400 Prec@5 90.090 Loss 12.92769\n",
            "val Class Accuracy: [0.990,0.909,0.730,0.123,0.187,0.124,0.338,0.376,0.320,0.043]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [42][0/329], lr: 0.01000\tTime 0.604 (0.604)\tData 0.482 (0.482)\tLoss 1.8193 (1.8193)\tPrec@1 90.234 (90.234)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [42][10/329], lr: 0.01000\tTime 0.090 (0.145)\tData 0.005 (0.053)\tLoss 3.8606 (4.2928)\tPrec@1 78.516 (75.817)\tPrec@5 96.875 (96.094)\n",
            "Epoch: [42][20/329], lr: 0.01000\tTime 0.097 (0.120)\tData 0.004 (0.031)\tLoss 4.0074 (4.0973)\tPrec@1 80.078 (76.786)\tPrec@5 98.047 (97.005)\n",
            "Epoch: [42][30/329], lr: 0.01000\tTime 0.093 (0.110)\tData 0.005 (0.023)\tLoss 3.2089 (3.8317)\tPrec@1 82.031 (78.591)\tPrec@5 97.656 (97.203)\n",
            "Epoch: [42][40/329], lr: 0.01000\tTime 0.087 (0.105)\tData 0.004 (0.018)\tLoss 2.9454 (3.5736)\tPrec@1 85.156 (80.316)\tPrec@5 97.656 (97.609)\n",
            "Epoch: [42][50/329], lr: 0.01000\tTime 0.090 (0.103)\tData 0.007 (0.016)\tLoss 2.2256 (3.3565)\tPrec@1 88.672 (81.595)\tPrec@5 99.609 (97.901)\n",
            "Epoch: [42][60/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.000 (0.015)\tLoss 2.1268 (3.2311)\tPrec@1 90.234 (82.339)\tPrec@5 98.438 (98.015)\n",
            "Epoch: [42][70/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.000 (0.014)\tLoss 2.8371 (3.1537)\tPrec@1 84.375 (82.713)\tPrec@5 98.438 (98.118)\n",
            "Epoch: [42][80/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.000 (0.013)\tLoss 2.5434 (3.0426)\tPrec@1 86.328 (83.377)\tPrec@5 99.609 (98.283)\n",
            "Epoch: [42][90/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.005 (0.012)\tLoss 1.8504 (2.9522)\tPrec@1 89.844 (83.933)\tPrec@5 99.609 (98.365)\n",
            "Epoch: [42][100/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.012 (0.012)\tLoss 2.1607 (2.8913)\tPrec@1 89.062 (84.259)\tPrec@5 99.219 (98.441)\n",
            "Epoch: [42][110/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.000 (0.011)\tLoss 2.2398 (2.8240)\tPrec@1 87.109 (84.667)\tPrec@5 98.828 (98.490)\n",
            "Epoch: [42][120/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.008 (0.011)\tLoss 2.1964 (2.7883)\tPrec@1 87.500 (84.879)\tPrec@5 99.219 (98.531)\n",
            "Epoch: [42][130/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.010)\tLoss 2.5434 (2.7314)\tPrec@1 87.500 (85.225)\tPrec@5 98.828 (98.575)\n",
            "Epoch: [42][140/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.006 (0.010)\tLoss 1.9541 (2.6956)\tPrec@1 90.234 (85.433)\tPrec@5 100.000 (98.634)\n",
            "Epoch: [42][150/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.000 (0.010)\tLoss 2.3977 (2.6575)\tPrec@1 86.719 (85.668)\tPrec@5 99.609 (98.683)\n",
            "Epoch: [42][160/329], lr: 0.01000\tTime 0.116 (0.094)\tData 0.010 (0.010)\tLoss 1.7255 (2.6161)\tPrec@1 91.406 (85.906)\tPrec@5 99.609 (98.719)\n",
            "Epoch: [42][170/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.000 (0.009)\tLoss 1.7064 (2.5831)\tPrec@1 91.797 (86.095)\tPrec@5 100.000 (98.757)\n",
            "Epoch: [42][180/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.005 (0.009)\tLoss 1.0133 (2.5445)\tPrec@1 95.312 (86.335)\tPrec@5 99.219 (98.783)\n",
            "Epoch: [42][190/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.000 (0.009)\tLoss 2.0024 (2.5280)\tPrec@1 89.453 (86.398)\tPrec@5 98.438 (98.795)\n",
            "Epoch: [42][200/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.001 (0.009)\tLoss 2.0200 (2.5154)\tPrec@1 89.453 (86.487)\tPrec@5 99.609 (98.809)\n",
            "Epoch: [42][210/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.004 (0.009)\tLoss 1.9792 (2.4988)\tPrec@1 91.406 (86.606)\tPrec@5 98.828 (98.823)\n",
            "Epoch: [42][220/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.004 (0.009)\tLoss 2.0622 (2.4785)\tPrec@1 89.453 (86.731)\tPrec@5 98.828 (98.840)\n",
            "Epoch: [42][230/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.005 (0.008)\tLoss 2.1238 (2.4546)\tPrec@1 89.453 (86.890)\tPrec@5 98.438 (98.867)\n",
            "Epoch: [42][240/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.015 (0.008)\tLoss 2.1879 (2.4365)\tPrec@1 88.672 (86.965)\tPrec@5 98.828 (98.883)\n",
            "Epoch: [42][250/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.005 (0.008)\tLoss 2.0251 (2.4182)\tPrec@1 88.672 (87.069)\tPrec@5 99.609 (98.897)\n",
            "Epoch: [42][260/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.007 (0.008)\tLoss 1.8241 (2.4004)\tPrec@1 91.016 (87.177)\tPrec@5 98.828 (98.910)\n",
            "Epoch: [42][270/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.004 (0.008)\tLoss 2.6984 (2.3870)\tPrec@1 85.547 (87.256)\tPrec@5 98.828 (98.932)\n",
            "Epoch: [42][280/329], lr: 0.01000\tTime 0.073 (0.093)\tData 0.007 (0.008)\tLoss 2.0385 (2.3675)\tPrec@1 89.062 (87.372)\tPrec@5 99.219 (98.952)\n",
            "Epoch: [42][290/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.000 (0.008)\tLoss 1.1875 (2.3529)\tPrec@1 94.141 (87.457)\tPrec@5 99.609 (98.957)\n",
            "Epoch: [42][300/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.000 (0.008)\tLoss 2.4568 (2.3445)\tPrec@1 88.281 (87.512)\tPrec@5 98.828 (98.966)\n",
            "Epoch: [42][310/329], lr: 0.01000\tTime 0.097 (0.093)\tData 0.004 (0.008)\tLoss 2.1969 (2.3382)\tPrec@1 89.062 (87.557)\tPrec@5 99.219 (98.981)\n",
            "Epoch: [42][320/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.065 (0.008)\tLoss 1.8831 (2.3275)\tPrec@1 90.234 (87.617)\tPrec@5 99.609 (98.998)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 7.0904 (7.0904)\tPrec@1 67.000 (67.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.044 (0.058)\tLoss 6.5103 (6.7166)\tPrec@1 66.000 (68.818)\tPrec@5 94.000 (96.636)\n",
            "Test: [20/100]\tTime 0.042 (0.046)\tLoss 5.1260 (6.6201)\tPrec@1 77.000 (69.429)\tPrec@5 99.000 (96.810)\n",
            "Test: [30/100]\tTime 0.011 (0.042)\tLoss 7.6514 (6.6536)\tPrec@1 62.000 (69.194)\tPrec@5 95.000 (96.774)\n",
            "Test: [40/100]\tTime 0.034 (0.041)\tLoss 5.9433 (6.5998)\tPrec@1 72.000 (69.415)\tPrec@5 98.000 (96.829)\n",
            "Test: [50/100]\tTime 0.044 (0.041)\tLoss 7.0524 (6.5593)\tPrec@1 69.000 (69.549)\tPrec@5 97.000 (96.922)\n",
            "Test: [60/100]\tTime 0.013 (0.040)\tLoss 5.5244 (6.5841)\tPrec@1 74.000 (69.377)\tPrec@5 95.000 (97.000)\n",
            "Test: [70/100]\tTime 0.035 (0.040)\tLoss 5.9857 (6.6243)\tPrec@1 73.000 (69.070)\tPrec@5 98.000 (96.930)\n",
            "Test: [80/100]\tTime 0.053 (0.040)\tLoss 4.9569 (6.5651)\tPrec@1 79.000 (69.235)\tPrec@5 97.000 (96.926)\n",
            "Test: [90/100]\tTime 0.019 (0.040)\tLoss 5.7209 (6.6408)\tPrec@1 74.000 (68.967)\tPrec@5 99.000 (96.835)\n",
            "val Results: Prec@1 68.880 Prec@5 96.820 Loss 6.65364\n",
            "val Class Accuracy: [0.925,0.852,0.869,0.593,0.591,0.833,0.351,0.664,0.418,0.792]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [43][0/329], lr: 0.01000\tTime 0.874 (0.874)\tData 0.779 (0.779)\tLoss 2.3723 (2.3723)\tPrec@1 88.281 (88.281)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [43][10/329], lr: 0.01000\tTime 0.095 (0.165)\tData 0.005 (0.078)\tLoss 2.2483 (2.5525)\tPrec@1 87.500 (86.683)\tPrec@5 97.266 (98.295)\n",
            "Epoch: [43][20/329], lr: 0.01000\tTime 0.080 (0.132)\tData 0.005 (0.044)\tLoss 2.6471 (2.4416)\tPrec@1 85.547 (87.202)\tPrec@5 99.609 (98.512)\n",
            "Epoch: [43][30/329], lr: 0.01000\tTime 0.093 (0.120)\tData 0.010 (0.032)\tLoss 1.7933 (2.3479)\tPrec@1 92.578 (87.790)\tPrec@5 99.609 (98.702)\n",
            "Epoch: [43][40/329], lr: 0.01000\tTime 0.091 (0.113)\tData 0.000 (0.026)\tLoss 2.2629 (2.2939)\tPrec@1 88.672 (88.024)\tPrec@5 99.609 (98.857)\n",
            "Epoch: [43][50/329], lr: 0.01000\tTime 0.099 (0.109)\tData 0.002 (0.022)\tLoss 2.3718 (2.2576)\tPrec@1 88.281 (88.289)\tPrec@5 99.609 (98.974)\n",
            "Epoch: [43][60/329], lr: 0.01000\tTime 0.084 (0.106)\tData 0.004 (0.020)\tLoss 2.0104 (2.1822)\tPrec@1 89.062 (88.697)\tPrec@5 99.219 (99.046)\n",
            "Epoch: [43][70/329], lr: 0.01000\tTime 0.085 (0.103)\tData 0.005 (0.018)\tLoss 2.2811 (2.1538)\tPrec@1 88.281 (88.859)\tPrec@5 99.609 (99.109)\n",
            "Epoch: [43][80/329], lr: 0.01000\tTime 0.077 (0.102)\tData 0.007 (0.016)\tLoss 1.8444 (2.1103)\tPrec@1 91.016 (89.140)\tPrec@5 99.219 (99.156)\n",
            "Epoch: [43][90/329], lr: 0.01000\tTime 0.101 (0.101)\tData 0.012 (0.016)\tLoss 2.1063 (2.1054)\tPrec@1 89.453 (89.101)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [43][100/329], lr: 0.01000\tTime 0.118 (0.100)\tData 0.007 (0.015)\tLoss 2.4120 (2.0843)\tPrec@1 86.719 (89.198)\tPrec@5 99.609 (99.184)\n",
            "Epoch: [43][110/329], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.014)\tLoss 1.5681 (2.0394)\tPrec@1 92.578 (89.481)\tPrec@5 99.609 (99.208)\n",
            "Epoch: [43][120/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.014 (0.013)\tLoss 1.6191 (2.0198)\tPrec@1 92.188 (89.556)\tPrec@5 99.609 (99.228)\n",
            "Epoch: [43][130/329], lr: 0.01000\tTime 0.077 (0.098)\tData 0.000 (0.013)\tLoss 1.6919 (2.0072)\tPrec@1 90.625 (89.629)\tPrec@5 99.219 (99.231)\n",
            "Epoch: [43][140/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.004 (0.012)\tLoss 2.1629 (2.0055)\tPrec@1 88.281 (89.622)\tPrec@5 99.609 (99.222)\n",
            "Epoch: [43][150/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.000 (0.012)\tLoss 1.7849 (2.0041)\tPrec@1 91.406 (89.614)\tPrec@5 100.000 (99.224)\n",
            "Epoch: [43][160/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.005 (0.012)\tLoss 1.2665 (1.9928)\tPrec@1 92.969 (89.701)\tPrec@5 99.219 (99.224)\n",
            "Epoch: [43][170/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.005 (0.011)\tLoss 1.9765 (1.9899)\tPrec@1 89.062 (89.698)\tPrec@5 99.609 (99.242)\n",
            "Epoch: [43][180/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.000 (0.011)\tLoss 1.9661 (1.9862)\tPrec@1 88.672 (89.712)\tPrec@5 98.047 (99.240)\n",
            "Epoch: [43][190/329], lr: 0.01000\tTime 0.105 (0.096)\tData 0.000 (0.011)\tLoss 1.5135 (1.9799)\tPrec@1 92.969 (89.729)\tPrec@5 98.828 (99.243)\n",
            "Epoch: [43][200/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.010)\tLoss 1.9534 (1.9769)\tPrec@1 89.453 (89.741)\tPrec@5 100.000 (99.250)\n",
            "Epoch: [43][210/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.010)\tLoss 1.2696 (1.9744)\tPrec@1 94.531 (89.747)\tPrec@5 99.609 (99.256)\n",
            "Epoch: [43][220/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.013 (0.010)\tLoss 1.3085 (1.9658)\tPrec@1 95.312 (89.835)\tPrec@5 100.000 (99.263)\n",
            "Epoch: [43][230/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.003 (0.010)\tLoss 2.2038 (1.9689)\tPrec@1 88.672 (89.800)\tPrec@5 99.609 (99.269)\n",
            "Epoch: [43][240/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.006 (0.010)\tLoss 2.0352 (1.9639)\tPrec@1 87.891 (89.818)\tPrec@5 99.219 (99.272)\n",
            "Epoch: [43][250/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.000 (0.010)\tLoss 1.8875 (1.9583)\tPrec@1 88.281 (89.852)\tPrec@5 100.000 (99.281)\n",
            "Epoch: [43][260/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.009)\tLoss 2.3619 (1.9550)\tPrec@1 87.891 (89.875)\tPrec@5 99.219 (99.282)\n",
            "Epoch: [43][270/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.009 (0.009)\tLoss 2.3255 (1.9592)\tPrec@1 88.672 (89.857)\tPrec@5 100.000 (99.284)\n",
            "Epoch: [43][280/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.007 (0.009)\tLoss 1.1407 (1.9499)\tPrec@1 94.141 (89.919)\tPrec@5 99.219 (99.298)\n",
            "Epoch: [43][290/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.007 (0.009)\tLoss 1.9157 (1.9486)\tPrec@1 91.016 (89.914)\tPrec@5 99.609 (99.306)\n",
            "Epoch: [43][300/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.001 (0.009)\tLoss 1.7874 (1.9458)\tPrec@1 91.406 (89.920)\tPrec@5 99.609 (99.316)\n",
            "Epoch: [43][310/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.000 (0.009)\tLoss 1.9555 (1.9390)\tPrec@1 89.453 (89.948)\tPrec@5 99.609 (99.328)\n",
            "Epoch: [43][320/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.050 (0.009)\tLoss 1.6302 (1.9371)\tPrec@1 91.016 (89.954)\tPrec@5 99.609 (99.332)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 6.8353 (6.8353)\tPrec@1 67.000 (67.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.021 (0.055)\tLoss 5.3163 (6.9902)\tPrec@1 75.000 (69.364)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/100]\tTime 0.029 (0.042)\tLoss 4.3709 (6.8060)\tPrec@1 82.000 (69.476)\tPrec@5 96.000 (97.000)\n",
            "Test: [30/100]\tTime 0.029 (0.036)\tLoss 6.5670 (6.8010)\tPrec@1 72.000 (69.645)\tPrec@5 96.000 (96.645)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 6.3949 (6.7902)\tPrec@1 73.000 (69.659)\tPrec@5 94.000 (96.585)\n",
            "Test: [50/100]\tTime 0.032 (0.032)\tLoss 6.8387 (6.7806)\tPrec@1 67.000 (69.549)\tPrec@5 95.000 (96.686)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 6.3519 (6.8228)\tPrec@1 71.000 (69.230)\tPrec@5 95.000 (96.738)\n",
            "Test: [70/100]\tTime 0.025 (0.030)\tLoss 6.9922 (6.7906)\tPrec@1 66.000 (69.394)\tPrec@5 97.000 (96.831)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 6.6343 (6.7592)\tPrec@1 72.000 (69.605)\tPrec@5 96.000 (96.852)\n",
            "Test: [90/100]\tTime 0.013 (0.029)\tLoss 6.8710 (6.8283)\tPrec@1 68.000 (69.319)\tPrec@5 99.000 (96.824)\n",
            "val Results: Prec@1 69.180 Prec@5 96.740 Loss 6.85481\n",
            "val Class Accuracy: [0.974,0.985,0.702,0.651,0.805,0.532,0.778,0.545,0.675,0.271]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [44][0/329], lr: 0.01000\tTime 0.637 (0.637)\tData 0.550 (0.550)\tLoss 2.2625 (2.2625)\tPrec@1 89.062 (89.062)\tPrec@5 98.047 (98.047)\n",
            "Epoch: [44][10/329], lr: 0.01000\tTime 0.108 (0.142)\tData 0.001 (0.057)\tLoss 2.7342 (2.7644)\tPrec@1 87.500 (85.689)\tPrec@5 98.438 (98.473)\n",
            "Epoch: [44][20/329], lr: 0.01000\tTime 0.089 (0.118)\tData 0.004 (0.032)\tLoss 2.4709 (2.7241)\tPrec@1 85.938 (85.324)\tPrec@5 98.438 (98.605)\n",
            "Epoch: [44][30/329], lr: 0.01000\tTime 0.088 (0.113)\tData 0.006 (0.024)\tLoss 2.3356 (2.5499)\tPrec@1 89.062 (86.366)\tPrec@5 98.828 (98.702)\n",
            "Epoch: [44][40/329], lr: 0.01000\tTime 0.089 (0.108)\tData 0.000 (0.020)\tLoss 2.5137 (2.4566)\tPrec@1 87.109 (86.871)\tPrec@5 98.047 (98.771)\n",
            "Epoch: [44][50/329], lr: 0.01000\tTime 0.128 (0.106)\tData 0.012 (0.017)\tLoss 1.8444 (2.3778)\tPrec@1 90.234 (87.286)\tPrec@5 98.828 (98.882)\n",
            "Epoch: [44][60/329], lr: 0.01000\tTime 0.115 (0.108)\tData 0.002 (0.015)\tLoss 2.4947 (2.3497)\tPrec@1 85.547 (87.487)\tPrec@5 98.438 (98.918)\n",
            "Epoch: [44][70/329], lr: 0.01000\tTime 0.092 (0.108)\tData 0.038 (0.015)\tLoss 1.5087 (2.2628)\tPrec@1 92.969 (88.012)\tPrec@5 99.219 (98.999)\n",
            "Epoch: [44][80/329], lr: 0.01000\tTime 0.118 (0.112)\tData 0.050 (0.018)\tLoss 1.9446 (2.2176)\tPrec@1 89.453 (88.276)\tPrec@5 98.828 (99.045)\n",
            "Epoch: [44][90/329], lr: 0.01000\tTime 0.101 (0.113)\tData 0.003 (0.019)\tLoss 2.2546 (2.1856)\tPrec@1 88.672 (88.483)\tPrec@5 99.219 (99.094)\n",
            "Epoch: [44][100/329], lr: 0.01000\tTime 0.087 (0.112)\tData 0.001 (0.018)\tLoss 1.6111 (2.1484)\tPrec@1 92.188 (88.676)\tPrec@5 99.219 (99.099)\n",
            "Epoch: [44][110/329], lr: 0.01000\tTime 0.097 (0.110)\tData 0.009 (0.017)\tLoss 1.8514 (2.1303)\tPrec@1 90.234 (88.795)\tPrec@5 98.828 (99.089)\n",
            "Epoch: [44][120/329], lr: 0.01000\tTime 0.103 (0.109)\tData 0.004 (0.016)\tLoss 1.4988 (2.1102)\tPrec@1 92.578 (88.908)\tPrec@5 98.828 (99.132)\n",
            "Epoch: [44][130/329], lr: 0.01000\tTime 0.104 (0.108)\tData 0.008 (0.015)\tLoss 1.8319 (2.0834)\tPrec@1 91.797 (89.071)\tPrec@5 99.219 (99.144)\n",
            "Epoch: [44][140/329], lr: 0.01000\tTime 0.075 (0.107)\tData 0.006 (0.015)\tLoss 2.1996 (2.0726)\tPrec@1 88.281 (89.121)\tPrec@5 99.609 (99.149)\n",
            "Epoch: [44][150/329], lr: 0.01000\tTime 0.106 (0.106)\tData 0.014 (0.014)\tLoss 1.6507 (2.0521)\tPrec@1 91.016 (89.249)\tPrec@5 100.000 (99.162)\n",
            "Epoch: [44][160/329], lr: 0.01000\tTime 0.082 (0.105)\tData 0.000 (0.014)\tLoss 1.6840 (2.0325)\tPrec@1 91.016 (89.373)\tPrec@5 99.219 (99.175)\n",
            "Epoch: [44][170/329], lr: 0.01000\tTime 0.087 (0.104)\tData 0.005 (0.014)\tLoss 1.8962 (2.0206)\tPrec@1 90.234 (89.442)\tPrec@5 99.609 (99.196)\n",
            "Epoch: [44][180/329], lr: 0.01000\tTime 0.078 (0.103)\tData 0.002 (0.013)\tLoss 2.0741 (2.0092)\tPrec@1 89.453 (89.507)\tPrec@5 98.828 (99.199)\n",
            "Epoch: [44][190/329], lr: 0.01000\tTime 0.072 (0.103)\tData 0.010 (0.013)\tLoss 1.8920 (2.0001)\tPrec@1 90.625 (89.545)\tPrec@5 99.219 (99.209)\n",
            "Epoch: [44][200/329], lr: 0.01000\tTime 0.085 (0.102)\tData 0.005 (0.013)\tLoss 2.1236 (1.9912)\tPrec@1 89.453 (89.611)\tPrec@5 98.438 (99.217)\n",
            "Epoch: [44][210/329], lr: 0.01000\tTime 0.084 (0.102)\tData 0.012 (0.013)\tLoss 2.0679 (1.9870)\tPrec@1 89.062 (89.635)\tPrec@5 98.828 (99.226)\n",
            "Epoch: [44][220/329], lr: 0.01000\tTime 0.112 (0.101)\tData 0.007 (0.012)\tLoss 2.3624 (1.9861)\tPrec@1 88.281 (89.626)\tPrec@5 99.609 (99.240)\n",
            "Epoch: [44][230/329], lr: 0.01000\tTime 0.103 (0.101)\tData 0.012 (0.012)\tLoss 1.7086 (1.9772)\tPrec@1 91.016 (89.680)\tPrec@5 100.000 (99.246)\n",
            "Epoch: [44][240/329], lr: 0.01000\tTime 0.110 (0.100)\tData 0.007 (0.012)\tLoss 1.9186 (1.9713)\tPrec@1 91.016 (89.734)\tPrec@5 100.000 (99.259)\n",
            "Epoch: [44][250/329], lr: 0.01000\tTime 0.102 (0.100)\tData 0.012 (0.012)\tLoss 1.6329 (1.9658)\tPrec@1 91.797 (89.774)\tPrec@5 99.219 (99.269)\n",
            "Epoch: [44][260/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.011 (0.012)\tLoss 2.0646 (1.9694)\tPrec@1 89.062 (89.751)\tPrec@5 99.609 (99.282)\n",
            "Epoch: [44][270/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.000 (0.011)\tLoss 2.2465 (1.9657)\tPrec@1 89.062 (89.779)\tPrec@5 99.609 (99.297)\n",
            "Epoch: [44][280/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.006 (0.011)\tLoss 1.9347 (1.9632)\tPrec@1 89.453 (89.794)\tPrec@5 100.000 (99.299)\n",
            "Epoch: [44][290/329], lr: 0.01000\tTime 0.069 (0.098)\tData 0.000 (0.011)\tLoss 1.5397 (1.9581)\tPrec@1 92.969 (89.829)\tPrec@5 99.609 (99.306)\n",
            "Epoch: [44][300/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.007 (0.011)\tLoss 1.9798 (1.9527)\tPrec@1 91.406 (89.855)\tPrec@5 98.828 (99.312)\n",
            "Epoch: [44][310/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.011)\tLoss 1.8359 (1.9537)\tPrec@1 90.234 (89.845)\tPrec@5 99.219 (99.310)\n",
            "Epoch: [44][320/329], lr: 0.01000\tTime 0.134 (0.098)\tData 0.075 (0.011)\tLoss 1.6454 (1.9550)\tPrec@1 90.625 (89.836)\tPrec@5 99.609 (99.315)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 7.7923 (7.7923)\tPrec@1 65.000 (65.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.028 (0.056)\tLoss 8.0104 (8.0822)\tPrec@1 60.000 (61.909)\tPrec@5 94.000 (90.909)\n",
            "Test: [20/100]\tTime 0.031 (0.040)\tLoss 7.3534 (7.8359)\tPrec@1 64.000 (63.000)\tPrec@5 91.000 (91.667)\n",
            "Test: [30/100]\tTime 0.025 (0.035)\tLoss 7.0378 (7.8022)\tPrec@1 69.000 (63.226)\tPrec@5 93.000 (91.613)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 6.3345 (7.8234)\tPrec@1 71.000 (63.146)\tPrec@5 96.000 (91.585)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 7.6156 (7.7800)\tPrec@1 66.000 (63.118)\tPrec@5 92.000 (91.471)\n",
            "Test: [60/100]\tTime 0.016 (0.030)\tLoss 7.2240 (7.7654)\tPrec@1 66.000 (63.049)\tPrec@5 93.000 (91.803)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 7.6176 (7.8200)\tPrec@1 65.000 (62.831)\tPrec@5 95.000 (91.761)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 7.0903 (7.8034)\tPrec@1 64.000 (62.877)\tPrec@5 92.000 (91.753)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 7.2562 (7.8708)\tPrec@1 62.000 (62.527)\tPrec@5 93.000 (91.538)\n",
            "val Results: Prec@1 62.570 Prec@5 91.660 Loss 7.87835\n",
            "val Class Accuracy: [0.613,0.524,0.655,0.326,0.800,0.930,0.529,0.574,0.522,0.784]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [45][0/329], lr: 0.01000\tTime 0.597 (0.597)\tData 0.486 (0.486)\tLoss 1.5632 (1.5632)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [45][10/329], lr: 0.01000\tTime 0.126 (0.142)\tData 0.003 (0.049)\tLoss 4.1871 (4.5799)\tPrec@1 76.953 (74.148)\tPrec@5 98.047 (95.277)\n",
            "Epoch: [45][20/329], lr: 0.01000\tTime 0.127 (0.117)\tData 0.056 (0.031)\tLoss 3.7865 (4.2051)\tPrec@1 80.078 (76.414)\tPrec@5 98.047 (96.633)\n",
            "Epoch: [45][30/329], lr: 0.01000\tTime 0.081 (0.108)\tData 0.005 (0.025)\tLoss 2.9561 (3.8418)\tPrec@1 82.812 (78.654)\tPrec@5 98.828 (97.228)\n",
            "Epoch: [45][40/329], lr: 0.01000\tTime 0.086 (0.105)\tData 0.001 (0.021)\tLoss 2.5952 (3.5477)\tPrec@1 85.156 (80.459)\tPrec@5 99.609 (97.628)\n",
            "Epoch: [45][50/329], lr: 0.01000\tTime 0.073 (0.102)\tData 0.005 (0.018)\tLoss 2.4020 (3.3412)\tPrec@1 86.719 (81.733)\tPrec@5 99.219 (97.909)\n",
            "Epoch: [45][60/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.003 (0.016)\tLoss 2.3728 (3.1592)\tPrec@1 87.500 (82.819)\tPrec@5 98.828 (98.104)\n",
            "Epoch: [45][70/329], lr: 0.01000\tTime 0.072 (0.099)\tData 0.001 (0.015)\tLoss 2.1822 (3.0025)\tPrec@1 88.672 (83.737)\tPrec@5 100.000 (98.283)\n",
            "Epoch: [45][80/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.014)\tLoss 2.8367 (2.9019)\tPrec@1 83.984 (84.279)\tPrec@5 98.438 (98.389)\n",
            "Epoch: [45][90/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.006 (0.014)\tLoss 1.5570 (2.8145)\tPrec@1 91.016 (84.787)\tPrec@5 99.219 (98.480)\n",
            "Epoch: [45][100/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.005 (0.013)\tLoss 2.3574 (2.7554)\tPrec@1 88.281 (85.160)\tPrec@5 99.219 (98.538)\n",
            "Epoch: [45][110/329], lr: 0.01000\tTime 0.065 (0.096)\tData 0.000 (0.013)\tLoss 2.1068 (2.7007)\tPrec@1 89.844 (85.515)\tPrec@5 99.219 (98.596)\n",
            "Epoch: [45][120/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.007 (0.012)\tLoss 2.3816 (2.6501)\tPrec@1 87.500 (85.799)\tPrec@5 98.047 (98.628)\n",
            "Epoch: [45][130/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.007 (0.012)\tLoss 2.0020 (2.6143)\tPrec@1 89.844 (86.012)\tPrec@5 99.609 (98.679)\n",
            "Epoch: [45][140/329], lr: 0.01000\tTime 0.138 (0.097)\tData 0.005 (0.012)\tLoss 1.9908 (2.5693)\tPrec@1 88.672 (86.292)\tPrec@5 99.219 (98.720)\n",
            "Epoch: [45][150/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.034 (0.011)\tLoss 2.1638 (2.5325)\tPrec@1 89.062 (86.504)\tPrec@5 100.000 (98.779)\n",
            "Epoch: [45][160/329], lr: 0.01000\tTime 0.113 (0.101)\tData 0.000 (0.014)\tLoss 1.5687 (2.4952)\tPrec@1 92.969 (86.716)\tPrec@5 99.609 (98.814)\n",
            "Epoch: [45][170/329], lr: 0.01000\tTime 0.095 (0.102)\tData 0.006 (0.013)\tLoss 1.5213 (2.4550)\tPrec@1 91.016 (86.947)\tPrec@5 100.000 (98.846)\n",
            "Epoch: [45][180/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.000 (0.013)\tLoss 1.8021 (2.4190)\tPrec@1 89.844 (87.165)\tPrec@5 99.219 (98.876)\n",
            "Epoch: [45][190/329], lr: 0.01000\tTime 0.106 (0.101)\tData 0.005 (0.013)\tLoss 1.6942 (2.3859)\tPrec@1 91.797 (87.359)\tPrec@5 99.609 (98.914)\n",
            "Epoch: [45][200/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.000 (0.012)\tLoss 2.1887 (2.3652)\tPrec@1 90.234 (87.477)\tPrec@5 99.219 (98.939)\n",
            "Epoch: [45][210/329], lr: 0.01000\tTime 0.094 (0.100)\tData 0.000 (0.012)\tLoss 2.3247 (2.3443)\tPrec@1 88.672 (87.602)\tPrec@5 99.219 (98.961)\n",
            "Epoch: [45][220/329], lr: 0.01000\tTime 0.090 (0.100)\tData 0.012 (0.012)\tLoss 1.6769 (2.3240)\tPrec@1 92.969 (87.726)\tPrec@5 100.000 (98.994)\n",
            "Epoch: [45][230/329], lr: 0.01000\tTime 0.108 (0.099)\tData 0.012 (0.012)\tLoss 1.5981 (2.2984)\tPrec@1 91.797 (87.862)\tPrec@5 99.609 (99.018)\n",
            "Epoch: [45][240/329], lr: 0.01000\tTime 0.112 (0.099)\tData 0.007 (0.012)\tLoss 1.8245 (2.2847)\tPrec@1 91.016 (87.944)\tPrec@5 98.828 (99.042)\n",
            "Epoch: [45][250/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.008 (0.011)\tLoss 1.8779 (2.2779)\tPrec@1 91.016 (88.007)\tPrec@5 99.219 (99.052)\n",
            "Epoch: [45][260/329], lr: 0.01000\tTime 0.102 (0.098)\tData 0.005 (0.011)\tLoss 1.7519 (2.2527)\tPrec@1 91.016 (88.147)\tPrec@5 99.219 (99.065)\n",
            "Epoch: [45][270/329], lr: 0.01000\tTime 0.110 (0.098)\tData 0.005 (0.011)\tLoss 2.3083 (2.2378)\tPrec@1 87.109 (88.221)\tPrec@5 99.219 (99.080)\n",
            "Epoch: [45][280/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.007 (0.011)\tLoss 2.4512 (2.2281)\tPrec@1 88.672 (88.292)\tPrec@5 99.219 (99.088)\n",
            "Epoch: [45][290/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.005 (0.011)\tLoss 2.4876 (2.2166)\tPrec@1 85.547 (88.355)\tPrec@5 99.219 (99.099)\n",
            "Epoch: [45][300/329], lr: 0.01000\tTime 0.067 (0.097)\tData 0.000 (0.010)\tLoss 1.9541 (2.2119)\tPrec@1 89.062 (88.376)\tPrec@5 99.609 (99.102)\n",
            "Epoch: [45][310/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.000 (0.010)\tLoss 1.8346 (2.2025)\tPrec@1 90.234 (88.434)\tPrec@5 98.828 (99.097)\n",
            "Epoch: [45][320/329], lr: 0.01000\tTime 0.126 (0.097)\tData 0.073 (0.010)\tLoss 1.3663 (2.1915)\tPrec@1 92.969 (88.505)\tPrec@5 100.000 (99.109)\n",
            "Test: [0/100]\tTime 0.371 (0.371)\tLoss 10.7147 (10.7147)\tPrec@1 48.000 (48.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.027 (0.056)\tLoss 8.4657 (10.4945)\tPrec@1 60.000 (52.091)\tPrec@5 93.000 (93.364)\n",
            "Test: [20/100]\tTime 0.029 (0.040)\tLoss 10.4064 (10.6595)\tPrec@1 51.000 (51.095)\tPrec@5 93.000 (93.286)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 10.6466 (10.7662)\tPrec@1 51.000 (50.548)\tPrec@5 91.000 (92.871)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 10.7169 (10.7706)\tPrec@1 49.000 (50.585)\tPrec@5 94.000 (92.829)\n",
            "Test: [50/100]\tTime 0.012 (0.032)\tLoss 10.0931 (10.7437)\tPrec@1 55.000 (50.804)\tPrec@5 94.000 (92.667)\n",
            "Test: [60/100]\tTime 0.035 (0.031)\tLoss 10.6501 (10.6673)\tPrec@1 43.000 (50.918)\tPrec@5 93.000 (92.754)\n",
            "Test: [70/100]\tTime 0.046 (0.030)\tLoss 11.1237 (10.6615)\tPrec@1 49.000 (50.944)\tPrec@5 94.000 (92.775)\n",
            "Test: [80/100]\tTime 0.022 (0.030)\tLoss 9.6660 (10.6331)\tPrec@1 56.000 (50.988)\tPrec@5 93.000 (92.963)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 12.1674 (10.7011)\tPrec@1 45.000 (50.769)\tPrec@5 92.000 (93.000)\n",
            "val Results: Prec@1 50.790 Prec@5 92.940 Loss 10.69925\n",
            "val Class Accuracy: [0.975,0.987,0.162,0.302,0.605,0.204,0.873,0.643,0.160,0.168]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [46][0/329], lr: 0.01000\tTime 0.635 (0.635)\tData 0.565 (0.565)\tLoss 2.0447 (2.0447)\tPrec@1 90.234 (90.234)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [46][10/329], lr: 0.01000\tTime 0.118 (0.148)\tData 0.006 (0.059)\tLoss 5.3809 (5.3281)\tPrec@1 69.141 (68.537)\tPrec@5 94.922 (94.673)\n",
            "Epoch: [46][20/329], lr: 0.01000\tTime 0.107 (0.122)\tData 0.012 (0.034)\tLoss 4.4926 (5.0754)\tPrec@1 74.609 (70.350)\tPrec@5 97.656 (95.275)\n",
            "Epoch: [46][30/329], lr: 0.01000\tTime 0.066 (0.111)\tData 0.000 (0.025)\tLoss 3.9498 (4.8093)\tPrec@1 76.953 (72.077)\tPrec@5 98.047 (95.917)\n",
            "Epoch: [46][40/329], lr: 0.01000\tTime 0.078 (0.106)\tData 0.005 (0.020)\tLoss 2.7824 (4.5529)\tPrec@1 84.766 (73.866)\tPrec@5 98.828 (96.465)\n",
            "Epoch: [46][50/329], lr: 0.01000\tTime 0.091 (0.103)\tData 0.003 (0.017)\tLoss 3.2833 (4.3699)\tPrec@1 82.812 (75.191)\tPrec@5 98.828 (96.783)\n",
            "Epoch: [46][60/329], lr: 0.01000\tTime 0.082 (0.101)\tData 0.007 (0.016)\tLoss 2.5754 (4.1508)\tPrec@1 86.328 (76.575)\tPrec@5 98.828 (97.106)\n",
            "Epoch: [46][70/329], lr: 0.01000\tTime 0.099 (0.100)\tData 0.012 (0.015)\tLoss 2.7987 (3.9437)\tPrec@1 86.328 (77.921)\tPrec@5 99.219 (97.376)\n",
            "Epoch: [46][80/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.000 (0.014)\tLoss 2.7716 (3.7708)\tPrec@1 83.984 (78.906)\tPrec@5 99.219 (97.545)\n",
            "Epoch: [46][90/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.000 (0.013)\tLoss 2.5980 (3.6428)\tPrec@1 85.547 (79.709)\tPrec@5 99.609 (97.699)\n",
            "Epoch: [46][100/329], lr: 0.01000\tTime 0.069 (0.096)\tData 0.004 (0.013)\tLoss 2.3889 (3.5335)\tPrec@1 87.891 (80.415)\tPrec@5 98.828 (97.869)\n",
            "Epoch: [46][110/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.006 (0.012)\tLoss 2.5164 (3.4432)\tPrec@1 88.281 (80.968)\tPrec@5 98.828 (97.991)\n",
            "Epoch: [46][120/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.003 (0.012)\tLoss 2.5167 (3.3657)\tPrec@1 87.500 (81.457)\tPrec@5 98.828 (98.079)\n",
            "Epoch: [46][130/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.014 (0.012)\tLoss 2.5671 (3.2948)\tPrec@1 86.719 (81.894)\tPrec@5 99.609 (98.175)\n",
            "Epoch: [46][140/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.005 (0.012)\tLoss 2.3675 (3.2303)\tPrec@1 88.281 (82.264)\tPrec@5 99.219 (98.235)\n",
            "Epoch: [46][150/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.012 (0.011)\tLoss 2.3996 (3.1734)\tPrec@1 87.891 (82.580)\tPrec@5 98.828 (98.311)\n",
            "Epoch: [46][160/329], lr: 0.01000\tTime 0.110 (0.095)\tData 0.008 (0.011)\tLoss 2.7743 (3.1323)\tPrec@1 85.547 (82.832)\tPrec@5 98.828 (98.362)\n",
            "Epoch: [46][170/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.000 (0.011)\tLoss 2.2207 (3.0808)\tPrec@1 89.453 (83.141)\tPrec@5 98.828 (98.399)\n",
            "Epoch: [46][180/329], lr: 0.01000\tTime 0.094 (0.094)\tData 0.003 (0.011)\tLoss 2.6468 (3.0363)\tPrec@1 85.547 (83.430)\tPrec@5 98.438 (98.440)\n",
            "Epoch: [46][190/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.011 (0.011)\tLoss 2.5985 (3.0023)\tPrec@1 86.719 (83.622)\tPrec@5 99.609 (98.499)\n",
            "Epoch: [46][200/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.007 (0.010)\tLoss 1.9573 (2.9600)\tPrec@1 89.062 (83.866)\tPrec@5 99.219 (98.539)\n",
            "Epoch: [46][210/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.010 (0.010)\tLoss 1.7073 (2.9205)\tPrec@1 91.406 (84.097)\tPrec@5 99.219 (98.587)\n",
            "Epoch: [46][220/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.010 (0.010)\tLoss 2.1310 (2.8902)\tPrec@1 89.062 (84.292)\tPrec@5 99.219 (98.616)\n",
            "Epoch: [46][230/329], lr: 0.01000\tTime 0.124 (0.093)\tData 0.007 (0.010)\tLoss 2.0796 (2.8648)\tPrec@1 88.281 (84.431)\tPrec@5 99.609 (98.639)\n",
            "Epoch: [46][240/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.005 (0.010)\tLoss 2.0050 (2.8353)\tPrec@1 90.234 (84.625)\tPrec@5 98.828 (98.676)\n",
            "Epoch: [46][250/329], lr: 0.01000\tTime 0.115 (0.094)\tData 0.000 (0.009)\tLoss 2.0444 (2.8102)\tPrec@1 91.797 (84.759)\tPrec@5 98.047 (98.699)\n",
            "Epoch: [46][260/329], lr: 0.01000\tTime 0.102 (0.096)\tData 0.000 (0.011)\tLoss 1.9045 (2.7865)\tPrec@1 89.844 (84.899)\tPrec@5 98.828 (98.725)\n",
            "Epoch: [46][270/329], lr: 0.01000\tTime 0.105 (0.097)\tData 0.000 (0.012)\tLoss 2.3380 (2.7646)\tPrec@1 90.234 (85.039)\tPrec@5 99.609 (98.747)\n",
            "Epoch: [46][280/329], lr: 0.01000\tTime 0.102 (0.097)\tData 0.005 (0.012)\tLoss 2.0431 (2.7449)\tPrec@1 89.062 (85.149)\tPrec@5 99.609 (98.756)\n",
            "Epoch: [46][290/329], lr: 0.01000\tTime 0.080 (0.097)\tData 0.005 (0.012)\tLoss 2.1482 (2.7247)\tPrec@1 88.281 (85.270)\tPrec@5 98.438 (98.772)\n",
            "Epoch: [46][300/329], lr: 0.01000\tTime 0.067 (0.097)\tData 0.000 (0.012)\tLoss 2.0687 (2.6995)\tPrec@1 89.062 (85.430)\tPrec@5 98.828 (98.788)\n",
            "Epoch: [46][310/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.007 (0.011)\tLoss 1.9230 (2.6824)\tPrec@1 90.234 (85.519)\tPrec@5 99.609 (98.807)\n",
            "Epoch: [46][320/329], lr: 0.01000\tTime 0.168 (0.097)\tData 0.101 (0.012)\tLoss 2.5157 (2.6588)\tPrec@1 86.719 (85.658)\tPrec@5 99.609 (98.827)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 7.5343 (7.5343)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.021 (0.059)\tLoss 5.5707 (7.3138)\tPrec@1 75.000 (67.727)\tPrec@5 97.000 (96.909)\n",
            "Test: [20/100]\tTime 0.021 (0.041)\tLoss 5.7531 (7.2456)\tPrec@1 74.000 (67.905)\tPrec@5 98.000 (96.714)\n",
            "Test: [30/100]\tTime 0.022 (0.036)\tLoss 7.5639 (7.2844)\tPrec@1 65.000 (67.581)\tPrec@5 96.000 (96.452)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 7.2377 (7.2620)\tPrec@1 66.000 (67.707)\tPrec@5 95.000 (96.390)\n",
            "Test: [50/100]\tTime 0.024 (0.030)\tLoss 7.0501 (7.2696)\tPrec@1 71.000 (67.588)\tPrec@5 98.000 (96.588)\n",
            "Test: [60/100]\tTime 0.020 (0.030)\tLoss 6.3581 (7.2758)\tPrec@1 71.000 (67.410)\tPrec@5 97.000 (96.590)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 7.8063 (7.2788)\tPrec@1 66.000 (67.507)\tPrec@5 98.000 (96.493)\n",
            "Test: [80/100]\tTime 0.016 (0.028)\tLoss 6.3384 (7.2515)\tPrec@1 72.000 (67.593)\tPrec@5 96.000 (96.519)\n",
            "Test: [90/100]\tTime 0.050 (0.028)\tLoss 8.1747 (7.3452)\tPrec@1 65.000 (67.165)\tPrec@5 98.000 (96.516)\n",
            "val Results: Prec@1 67.170 Prec@5 96.550 Loss 7.35859\n",
            "val Class Accuracy: [0.964,0.979,0.794,0.647,0.632,0.625,0.790,0.476,0.479,0.331]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [47][0/329], lr: 0.01000\tTime 0.548 (0.548)\tData 0.465 (0.465)\tLoss 1.9587 (1.9587)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [47][10/329], lr: 0.01000\tTime 0.100 (0.143)\tData 0.000 (0.050)\tLoss 2.0892 (2.3176)\tPrec@1 88.281 (87.784)\tPrec@5 99.219 (98.580)\n",
            "Epoch: [47][20/329], lr: 0.01000\tTime 0.099 (0.119)\tData 0.000 (0.029)\tLoss 1.9706 (2.3185)\tPrec@1 89.844 (87.965)\tPrec@5 99.609 (98.735)\n",
            "Epoch: [47][30/329], lr: 0.01000\tTime 0.107 (0.111)\tData 0.005 (0.021)\tLoss 1.7661 (2.2566)\tPrec@1 90.625 (88.395)\tPrec@5 98.047 (98.765)\n",
            "Epoch: [47][40/329], lr: 0.01000\tTime 0.106 (0.108)\tData 0.006 (0.017)\tLoss 1.9247 (2.1986)\tPrec@1 90.234 (88.643)\tPrec@5 98.438 (98.857)\n",
            "Epoch: [47][50/329], lr: 0.01000\tTime 0.105 (0.104)\tData 0.007 (0.015)\tLoss 1.9780 (2.1988)\tPrec@1 90.234 (88.611)\tPrec@5 99.609 (98.843)\n",
            "Epoch: [47][60/329], lr: 0.01000\tTime 0.078 (0.102)\tData 0.000 (0.014)\tLoss 1.8188 (2.1728)\tPrec@1 91.406 (88.749)\tPrec@5 100.000 (98.956)\n",
            "Epoch: [47][70/329], lr: 0.01000\tTime 0.072 (0.101)\tData 0.000 (0.013)\tLoss 2.3506 (2.1689)\tPrec@1 87.500 (88.732)\tPrec@5 98.828 (98.988)\n",
            "Epoch: [47][80/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.001 (0.012)\tLoss 1.8670 (2.1529)\tPrec@1 89.844 (88.845)\tPrec@5 98.828 (99.021)\n",
            "Epoch: [47][90/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.002 (0.011)\tLoss 1.7639 (2.1346)\tPrec@1 91.016 (88.887)\tPrec@5 99.219 (99.060)\n",
            "Epoch: [47][100/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.004 (0.011)\tLoss 2.3741 (2.1291)\tPrec@1 84.375 (88.885)\tPrec@5 100.000 (99.114)\n",
            "Epoch: [47][110/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.007 (0.010)\tLoss 1.9045 (2.1063)\tPrec@1 89.844 (89.003)\tPrec@5 100.000 (99.155)\n",
            "Epoch: [47][120/329], lr: 0.01000\tTime 0.057 (0.096)\tData 0.000 (0.010)\tLoss 2.0323 (2.1005)\tPrec@1 90.625 (89.069)\tPrec@5 100.000 (99.206)\n",
            "Epoch: [47][130/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.012 (0.010)\tLoss 2.5194 (2.1010)\tPrec@1 86.328 (89.060)\tPrec@5 100.000 (99.240)\n",
            "Epoch: [47][140/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.012 (0.010)\tLoss 1.8357 (2.0919)\tPrec@1 91.016 (89.118)\tPrec@5 99.219 (99.238)\n",
            "Epoch: [47][150/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.005 (0.010)\tLoss 2.3478 (2.0856)\tPrec@1 87.500 (89.150)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [47][160/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.005 (0.010)\tLoss 1.4002 (2.0729)\tPrec@1 92.969 (89.211)\tPrec@5 98.438 (99.262)\n",
            "Epoch: [47][170/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.000 (0.010)\tLoss 2.0324 (2.0639)\tPrec@1 89.062 (89.289)\tPrec@5 99.609 (99.278)\n",
            "Epoch: [47][180/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.009 (0.010)\tLoss 1.8217 (2.0579)\tPrec@1 92.188 (89.300)\tPrec@5 98.438 (99.288)\n",
            "Epoch: [47][190/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.008 (0.010)\tLoss 2.1234 (2.0536)\tPrec@1 89.062 (89.324)\tPrec@5 99.219 (99.290)\n",
            "Epoch: [47][200/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.006 (0.009)\tLoss 2.3991 (2.0530)\tPrec@1 86.328 (89.315)\tPrec@5 100.000 (99.295)\n",
            "Epoch: [47][210/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.009)\tLoss 1.5299 (2.0506)\tPrec@1 93.359 (89.316)\tPrec@5 99.609 (99.289)\n",
            "Epoch: [47][220/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.005 (0.009)\tLoss 1.8296 (2.0416)\tPrec@1 91.406 (89.356)\tPrec@5 100.000 (99.295)\n",
            "Epoch: [47][230/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.006 (0.009)\tLoss 2.1068 (2.0312)\tPrec@1 87.109 (89.407)\tPrec@5 98.047 (99.295)\n",
            "Epoch: [47][240/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.009)\tLoss 1.9289 (2.0287)\tPrec@1 89.453 (89.437)\tPrec@5 100.000 (99.306)\n",
            "Epoch: [47][250/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.010 (0.009)\tLoss 1.7727 (2.0220)\tPrec@1 90.625 (89.464)\tPrec@5 99.219 (99.315)\n",
            "Epoch: [47][260/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.000 (0.009)\tLoss 1.5448 (2.0167)\tPrec@1 90.625 (89.480)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [47][270/329], lr: 0.01000\tTime 0.118 (0.093)\tData 0.007 (0.009)\tLoss 1.9887 (2.0191)\tPrec@1 91.016 (89.456)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [47][280/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 1.9977 (2.0139)\tPrec@1 90.625 (89.485)\tPrec@5 99.219 (99.305)\n",
            "Epoch: [47][290/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.009)\tLoss 2.3109 (2.0153)\tPrec@1 88.281 (89.476)\tPrec@5 99.609 (99.309)\n",
            "Epoch: [47][300/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.001 (0.009)\tLoss 1.8151 (2.0121)\tPrec@1 91.016 (89.484)\tPrec@5 98.828 (99.306)\n",
            "Epoch: [47][310/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.009)\tLoss 2.0657 (2.0096)\tPrec@1 88.281 (89.491)\tPrec@5 98.828 (99.312)\n",
            "Epoch: [47][320/329], lr: 0.01000\tTime 0.127 (0.093)\tData 0.081 (0.009)\tLoss 2.3988 (2.0109)\tPrec@1 86.719 (89.493)\tPrec@5 99.609 (99.303)\n",
            "Test: [0/100]\tTime 0.519 (0.519)\tLoss 5.3992 (5.3992)\tPrec@1 73.000 (73.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.045 (0.089)\tLoss 5.1181 (6.6387)\tPrec@1 78.000 (70.091)\tPrec@5 99.000 (97.182)\n",
            "Test: [20/100]\tTime 0.048 (0.066)\tLoss 5.5171 (6.5323)\tPrec@1 74.000 (70.762)\tPrec@5 99.000 (96.810)\n",
            "Test: [30/100]\tTime 0.034 (0.058)\tLoss 7.3762 (6.7126)\tPrec@1 65.000 (69.774)\tPrec@5 95.000 (96.581)\n",
            "Test: [40/100]\tTime 0.039 (0.054)\tLoss 7.2337 (6.7496)\tPrec@1 66.000 (69.512)\tPrec@5 93.000 (96.439)\n",
            "Test: [50/100]\tTime 0.024 (0.050)\tLoss 7.2921 (6.6627)\tPrec@1 62.000 (69.765)\tPrec@5 95.000 (96.549)\n",
            "Test: [60/100]\tTime 0.013 (0.047)\tLoss 6.6365 (6.7670)\tPrec@1 68.000 (69.066)\tPrec@5 98.000 (96.590)\n",
            "Test: [70/100]\tTime 0.018 (0.044)\tLoss 7.3420 (6.7532)\tPrec@1 68.000 (69.254)\tPrec@5 96.000 (96.479)\n",
            "Test: [80/100]\tTime 0.024 (0.042)\tLoss 6.7201 (6.7383)\tPrec@1 70.000 (69.346)\tPrec@5 95.000 (96.568)\n",
            "Test: [90/100]\tTime 0.034 (0.040)\tLoss 6.7657 (6.7820)\tPrec@1 70.000 (69.143)\tPrec@5 97.000 (96.429)\n",
            "val Results: Prec@1 69.290 Prec@5 96.460 Loss 6.77374\n",
            "val Class Accuracy: [0.932,0.885,0.730,0.849,0.411,0.537,0.863,0.548,0.552,0.622]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [48][0/329], lr: 0.01000\tTime 0.628 (0.628)\tData 0.535 (0.535)\tLoss 2.0812 (2.0812)\tPrec@1 89.062 (89.062)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [48][10/329], lr: 0.01000\tTime 0.089 (0.149)\tData 0.003 (0.056)\tLoss 3.0029 (3.5631)\tPrec@1 83.984 (80.753)\tPrec@5 96.875 (97.017)\n",
            "Epoch: [48][20/329], lr: 0.01000\tTime 0.091 (0.124)\tData 0.000 (0.033)\tLoss 3.0849 (3.3767)\tPrec@1 82.422 (81.789)\tPrec@5 97.266 (97.749)\n",
            "Epoch: [48][30/329], lr: 0.01000\tTime 0.128 (0.115)\tData 0.000 (0.024)\tLoss 2.7443 (3.0998)\tPrec@1 87.891 (83.493)\tPrec@5 99.219 (98.160)\n",
            "Epoch: [48][40/329], lr: 0.01000\tTime 0.114 (0.110)\tData 0.000 (0.020)\tLoss 2.0842 (2.9070)\tPrec@1 88.672 (84.594)\tPrec@5 99.219 (98.399)\n",
            "Epoch: [48][50/329], lr: 0.01000\tTime 0.106 (0.106)\tData 0.009 (0.017)\tLoss 2.3781 (2.8073)\tPrec@1 89.453 (85.110)\tPrec@5 99.219 (98.606)\n",
            "Epoch: [48][60/329], lr: 0.01000\tTime 0.081 (0.103)\tData 0.000 (0.015)\tLoss 2.0205 (2.7136)\tPrec@1 89.844 (85.637)\tPrec@5 100.000 (98.726)\n",
            "Epoch: [48][70/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.007 (0.014)\tLoss 2.3984 (2.6275)\tPrec@1 87.109 (86.114)\tPrec@5 100.000 (98.839)\n",
            "Epoch: [48][80/329], lr: 0.01000\tTime 0.066 (0.100)\tData 0.007 (0.013)\tLoss 1.8998 (2.5821)\tPrec@1 91.016 (86.381)\tPrec@5 99.219 (98.881)\n",
            "Epoch: [48][90/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.012)\tLoss 1.8835 (2.5025)\tPrec@1 90.234 (86.813)\tPrec@5 99.609 (98.923)\n",
            "Epoch: [48][100/329], lr: 0.01000\tTime 0.117 (0.098)\tData 0.006 (0.012)\tLoss 2.6893 (2.4673)\tPrec@1 85.547 (87.032)\tPrec@5 100.000 (98.952)\n",
            "Epoch: [48][110/329], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.011)\tLoss 2.0970 (2.4406)\tPrec@1 87.891 (87.169)\tPrec@5 100.000 (98.972)\n",
            "Epoch: [48][120/329], lr: 0.01000\tTime 0.112 (0.096)\tData 0.005 (0.011)\tLoss 2.7230 (2.4070)\tPrec@1 85.547 (87.368)\tPrec@5 99.219 (99.009)\n",
            "Epoch: [48][130/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.005 (0.011)\tLoss 1.2800 (2.3518)\tPrec@1 91.797 (87.655)\tPrec@5 100.000 (99.055)\n",
            "Epoch: [48][140/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.002 (0.010)\tLoss 2.6625 (2.3285)\tPrec@1 85.547 (87.771)\tPrec@5 99.219 (99.089)\n",
            "Epoch: [48][150/329], lr: 0.01000\tTime 0.113 (0.095)\tData 0.018 (0.010)\tLoss 1.6698 (2.3090)\tPrec@1 90.625 (87.875)\tPrec@5 100.000 (99.113)\n",
            "Epoch: [48][160/329], lr: 0.01000\tTime 0.070 (0.094)\tData 0.000 (0.010)\tLoss 1.8972 (2.2852)\tPrec@1 91.016 (88.012)\tPrec@5 99.609 (99.131)\n",
            "Epoch: [48][170/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.005 (0.010)\tLoss 2.0862 (2.2659)\tPrec@1 89.453 (88.133)\tPrec@5 100.000 (99.134)\n",
            "Epoch: [48][180/329], lr: 0.01000\tTime 0.078 (0.094)\tData 0.005 (0.010)\tLoss 1.7697 (2.2522)\tPrec@1 91.016 (88.210)\tPrec@5 98.438 (99.143)\n",
            "Epoch: [48][190/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 2.2531 (2.2421)\tPrec@1 88.672 (88.265)\tPrec@5 99.219 (99.145)\n",
            "Epoch: [48][200/329], lr: 0.01000\tTime 0.111 (0.093)\tData 0.005 (0.009)\tLoss 1.8152 (2.2287)\tPrec@1 90.625 (88.341)\tPrec@5 100.000 (99.159)\n",
            "Epoch: [48][210/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.001 (0.009)\tLoss 2.1635 (2.2106)\tPrec@1 89.844 (88.476)\tPrec@5 98.047 (99.156)\n",
            "Epoch: [48][220/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.005 (0.009)\tLoss 1.6398 (2.1944)\tPrec@1 92.188 (88.568)\tPrec@5 98.438 (99.157)\n",
            "Epoch: [48][230/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.005 (0.009)\tLoss 1.1407 (2.1846)\tPrec@1 94.141 (88.618)\tPrec@5 100.000 (99.163)\n",
            "Epoch: [48][240/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.009 (0.009)\tLoss 2.2168 (2.1723)\tPrec@1 87.891 (88.677)\tPrec@5 99.609 (99.181)\n",
            "Epoch: [48][250/329], lr: 0.01000\tTime 0.066 (0.092)\tData 0.009 (0.009)\tLoss 1.4693 (2.1597)\tPrec@1 92.578 (88.740)\tPrec@5 100.000 (99.197)\n",
            "Epoch: [48][260/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.002 (0.009)\tLoss 1.8824 (2.1518)\tPrec@1 90.625 (88.790)\tPrec@5 99.609 (99.198)\n",
            "Epoch: [48][270/329], lr: 0.01000\tTime 0.080 (0.092)\tData 0.004 (0.009)\tLoss 1.6056 (2.1407)\tPrec@1 91.016 (88.848)\tPrec@5 99.609 (99.209)\n",
            "Epoch: [48][280/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.007 (0.009)\tLoss 1.8971 (2.1376)\tPrec@1 90.234 (88.869)\tPrec@5 99.219 (99.212)\n",
            "Epoch: [48][290/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.000 (0.009)\tLoss 1.3624 (2.1241)\tPrec@1 94.141 (88.954)\tPrec@5 99.609 (99.224)\n",
            "Epoch: [48][300/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.009 (0.009)\tLoss 2.4380 (2.1174)\tPrec@1 89.453 (89.014)\tPrec@5 98.047 (99.227)\n",
            "Epoch: [48][310/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.002 (0.009)\tLoss 2.1450 (2.1157)\tPrec@1 88.672 (89.019)\tPrec@5 98.828 (99.223)\n",
            "Epoch: [48][320/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.038 (0.009)\tLoss 2.1107 (2.1090)\tPrec@1 88.672 (89.059)\tPrec@5 99.609 (99.231)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 9.0064 (9.0064)\tPrec@1 59.000 (59.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.040 (0.056)\tLoss 8.7061 (9.1886)\tPrec@1 56.000 (57.364)\tPrec@5 92.000 (93.182)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 8.7493 (8.9875)\tPrec@1 58.000 (57.810)\tPrec@5 93.000 (94.143)\n",
            "Test: [30/100]\tTime 0.030 (0.036)\tLoss 9.3811 (8.9470)\tPrec@1 52.000 (57.581)\tPrec@5 92.000 (93.968)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 8.7736 (8.9163)\tPrec@1 61.000 (57.878)\tPrec@5 93.000 (94.098)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 9.6225 (8.8343)\tPrec@1 54.000 (58.373)\tPrec@5 94.000 (94.020)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 8.3669 (8.9209)\tPrec@1 56.000 (57.754)\tPrec@5 95.000 (94.082)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 9.8097 (9.0017)\tPrec@1 54.000 (57.408)\tPrec@5 92.000 (93.901)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 8.3774 (8.9688)\tPrec@1 58.000 (57.568)\tPrec@5 92.000 (93.790)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 8.6397 (9.0880)\tPrec@1 60.000 (57.132)\tPrec@5 97.000 (93.571)\n",
            "val Results: Prec@1 57.250 Prec@5 93.540 Loss 9.07570\n",
            "val Class Accuracy: [0.832,0.564,0.552,0.747,0.922,0.433,0.164,0.554,0.350,0.607]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [49][0/329], lr: 0.01000\tTime 0.620 (0.620)\tData 0.532 (0.532)\tLoss 3.0020 (3.0020)\tPrec@1 84.766 (84.766)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [49][10/329], lr: 0.01000\tTime 0.091 (0.147)\tData 0.000 (0.056)\tLoss 6.3567 (6.4579)\tPrec@1 59.766 (60.582)\tPrec@5 93.359 (89.560)\n",
            "Epoch: [49][20/329], lr: 0.01000\tTime 0.089 (0.121)\tData 0.005 (0.034)\tLoss 4.7891 (6.2225)\tPrec@1 72.266 (62.333)\tPrec@5 96.875 (91.313)\n",
            "Epoch: [49][30/329], lr: 0.01000\tTime 0.074 (0.111)\tData 0.001 (0.025)\tLoss 4.4995 (5.8093)\tPrec@1 75.391 (65.499)\tPrec@5 96.094 (92.553)\n",
            "Epoch: [49][40/329], lr: 0.01000\tTime 0.064 (0.105)\tData 0.012 (0.020)\tLoss 4.4440 (5.4186)\tPrec@1 75.391 (68.093)\tPrec@5 96.875 (93.540)\n",
            "Epoch: [49][50/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.000 (0.017)\tLoss 3.0406 (5.0855)\tPrec@1 82.812 (70.297)\tPrec@5 98.047 (94.225)\n",
            "Epoch: [49][60/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.015 (0.015)\tLoss 3.5866 (4.7909)\tPrec@1 81.250 (72.195)\tPrec@5 98.828 (94.877)\n",
            "Epoch: [49][70/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.002 (0.014)\tLoss 3.0650 (4.5882)\tPrec@1 84.375 (73.603)\tPrec@5 98.828 (95.401)\n",
            "Epoch: [49][80/329], lr: 0.01000\tTime 0.115 (0.098)\tData 0.005 (0.013)\tLoss 3.0974 (4.4134)\tPrec@1 83.594 (74.744)\tPrec@5 98.047 (95.809)\n",
            "Epoch: [49][90/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.000 (0.012)\tLoss 2.5589 (4.2495)\tPrec@1 86.328 (75.824)\tPrec@5 98.438 (96.115)\n",
            "Epoch: [49][100/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.000 (0.012)\tLoss 2.6906 (4.1052)\tPrec@1 86.328 (76.733)\tPrec@5 98.438 (96.361)\n",
            "Epoch: [49][110/329], lr: 0.01000\tTime 0.124 (0.096)\tData 0.007 (0.011)\tLoss 2.1570 (3.9869)\tPrec@1 89.453 (77.477)\tPrec@5 99.219 (96.586)\n",
            "Epoch: [49][120/329], lr: 0.01000\tTime 0.141 (0.096)\tData 0.000 (0.011)\tLoss 2.8242 (3.8716)\tPrec@1 84.375 (78.219)\tPrec@5 99.219 (96.749)\n",
            "Epoch: [49][130/329], lr: 0.01000\tTime 0.114 (0.097)\tData 0.000 (0.010)\tLoss 2.2692 (3.7739)\tPrec@1 87.891 (78.847)\tPrec@5 98.438 (96.908)\n",
            "Epoch: [49][140/329], lr: 0.01000\tTime 0.129 (0.099)\tData 0.066 (0.011)\tLoss 2.1666 (3.6847)\tPrec@1 88.281 (79.419)\tPrec@5 98.047 (97.058)\n",
            "Epoch: [49][150/329], lr: 0.01000\tTime 0.113 (0.101)\tData 0.000 (0.012)\tLoss 2.3214 (3.5990)\tPrec@1 87.500 (79.946)\tPrec@5 100.000 (97.201)\n",
            "Epoch: [49][160/329], lr: 0.01000\tTime 0.101 (0.103)\tData 0.008 (0.012)\tLoss 3.1361 (3.5355)\tPrec@1 83.594 (80.347)\tPrec@5 98.438 (97.321)\n",
            "Epoch: [49][170/329], lr: 0.01000\tTime 0.101 (0.102)\tData 0.003 (0.012)\tLoss 2.5698 (3.4597)\tPrec@1 86.328 (80.805)\tPrec@5 97.656 (97.428)\n",
            "Epoch: [49][180/329], lr: 0.01000\tTime 0.075 (0.102)\tData 0.014 (0.012)\tLoss 2.8772 (3.4027)\tPrec@1 84.375 (81.149)\tPrec@5 99.219 (97.535)\n",
            "Epoch: [49][190/329], lr: 0.01000\tTime 0.099 (0.101)\tData 0.000 (0.012)\tLoss 2.3811 (3.3380)\tPrec@1 86.719 (81.551)\tPrec@5 98.828 (97.628)\n",
            "Epoch: [49][200/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.003 (0.011)\tLoss 1.7239 (3.2836)\tPrec@1 91.016 (81.889)\tPrec@5 99.219 (97.701)\n",
            "Epoch: [49][210/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.000 (0.011)\tLoss 1.9756 (3.2346)\tPrec@1 89.844 (82.203)\tPrec@5 99.609 (97.767)\n",
            "Epoch: [49][220/329], lr: 0.01000\tTime 0.110 (0.100)\tData 0.000 (0.011)\tLoss 2.1731 (3.1933)\tPrec@1 87.891 (82.434)\tPrec@5 99.219 (97.819)\n",
            "Epoch: [49][230/329], lr: 0.01000\tTime 0.057 (0.099)\tData 0.005 (0.010)\tLoss 1.7179 (3.1510)\tPrec@1 92.578 (82.686)\tPrec@5 99.609 (97.869)\n",
            "Epoch: [49][240/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.000 (0.010)\tLoss 2.3177 (3.1121)\tPrec@1 89.453 (82.931)\tPrec@5 100.000 (97.935)\n",
            "Epoch: [49][250/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.009 (0.010)\tLoss 2.2706 (3.0836)\tPrec@1 87.891 (83.122)\tPrec@5 99.219 (97.991)\n",
            "Epoch: [49][260/329], lr: 0.01000\tTime 0.093 (0.098)\tData 0.000 (0.010)\tLoss 1.9892 (3.0516)\tPrec@1 89.062 (83.335)\tPrec@5 100.000 (98.041)\n",
            "Epoch: [49][270/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.000 (0.010)\tLoss 2.1245 (3.0144)\tPrec@1 88.281 (83.551)\tPrec@5 99.609 (98.084)\n",
            "Epoch: [49][280/329], lr: 0.01000\tTime 0.116 (0.097)\tData 0.011 (0.010)\tLoss 1.8559 (2.9871)\tPrec@1 89.062 (83.705)\tPrec@5 100.000 (98.122)\n",
            "Epoch: [49][290/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.009 (0.010)\tLoss 1.8739 (2.9579)\tPrec@1 91.406 (83.884)\tPrec@5 99.219 (98.164)\n",
            "Epoch: [49][300/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.000 (0.010)\tLoss 1.7063 (2.9284)\tPrec@1 91.406 (84.054)\tPrec@5 99.609 (98.199)\n",
            "Epoch: [49][310/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.005 (0.010)\tLoss 2.3814 (2.9092)\tPrec@1 85.938 (84.159)\tPrec@5 99.609 (98.230)\n",
            "Epoch: [49][320/329], lr: 0.01000\tTime 0.118 (0.097)\tData 0.062 (0.010)\tLoss 1.9971 (2.8868)\tPrec@1 87.891 (84.296)\tPrec@5 98.828 (98.262)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 7.8969 (7.8969)\tPrec@1 63.000 (63.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.027 (0.054)\tLoss 5.6697 (7.0502)\tPrec@1 76.000 (67.909)\tPrec@5 96.000 (97.455)\n",
            "Test: [20/100]\tTime 0.042 (0.041)\tLoss 5.8368 (6.9232)\tPrec@1 73.000 (68.190)\tPrec@5 99.000 (97.238)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 6.5859 (6.8945)\tPrec@1 67.000 (68.387)\tPrec@5 93.000 (97.000)\n",
            "Test: [40/100]\tTime 0.016 (0.033)\tLoss 7.1651 (6.9107)\tPrec@1 67.000 (68.220)\tPrec@5 95.000 (96.951)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 7.8653 (6.8864)\tPrec@1 60.000 (68.216)\tPrec@5 94.000 (96.843)\n",
            "Test: [60/100]\tTime 0.017 (0.029)\tLoss 6.0614 (6.9267)\tPrec@1 74.000 (67.885)\tPrec@5 97.000 (96.902)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 6.9053 (6.9617)\tPrec@1 69.000 (67.803)\tPrec@5 97.000 (96.901)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 5.9902 (6.9229)\tPrec@1 75.000 (67.963)\tPrec@5 96.000 (96.901)\n",
            "Test: [90/100]\tTime 0.015 (0.028)\tLoss 6.9273 (7.0091)\tPrec@1 68.000 (67.615)\tPrec@5 100.000 (96.857)\n",
            "val Results: Prec@1 67.690 Prec@5 96.880 Loss 7.00755\n",
            "val Class Accuracy: [0.933,0.988,0.825,0.574,0.774,0.536,0.518,0.598,0.524,0.499]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [50][0/329], lr: 0.01000\tTime 0.567 (0.567)\tData 0.466 (0.466)\tLoss 2.6300 (2.6300)\tPrec@1 84.766 (84.766)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [50][10/329], lr: 0.01000\tTime 0.094 (0.141)\tData 0.002 (0.047)\tLoss 1.6961 (2.1609)\tPrec@1 90.625 (88.636)\tPrec@5 98.438 (99.112)\n",
            "Epoch: [50][20/329], lr: 0.01000\tTime 0.116 (0.118)\tData 0.000 (0.026)\tLoss 1.8912 (2.0688)\tPrec@1 91.406 (89.025)\tPrec@5 100.000 (99.293)\n",
            "Epoch: [50][30/329], lr: 0.01000\tTime 0.109 (0.109)\tData 0.008 (0.020)\tLoss 1.7896 (2.0237)\tPrec@1 90.625 (89.378)\tPrec@5 100.000 (99.370)\n",
            "Epoch: [50][40/329], lr: 0.01000\tTime 0.080 (0.104)\tData 0.005 (0.017)\tLoss 1.9010 (2.0165)\tPrec@1 91.406 (89.444)\tPrec@5 100.000 (99.390)\n",
            "Epoch: [50][50/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.007 (0.015)\tLoss 1.7168 (1.9934)\tPrec@1 91.016 (89.499)\tPrec@5 99.219 (99.403)\n",
            "Epoch: [50][60/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.006 (0.013)\tLoss 2.1608 (1.9772)\tPrec@1 89.062 (89.613)\tPrec@5 99.219 (99.398)\n",
            "Epoch: [50][70/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.008 (0.012)\tLoss 1.5324 (1.9701)\tPrec@1 92.188 (89.706)\tPrec@5 99.609 (99.389)\n",
            "Epoch: [50][80/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.004 (0.011)\tLoss 1.5139 (1.9670)\tPrec@1 92.188 (89.699)\tPrec@5 100.000 (99.383)\n",
            "Epoch: [50][90/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.003 (0.011)\tLoss 2.4358 (1.9746)\tPrec@1 87.500 (89.766)\tPrec@5 99.609 (99.360)\n",
            "Epoch: [50][100/329], lr: 0.01000\tTime 0.115 (0.096)\tData 0.005 (0.010)\tLoss 1.7409 (1.9729)\tPrec@1 90.234 (89.743)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [50][110/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.006 (0.010)\tLoss 2.4166 (1.9711)\tPrec@1 87.891 (89.798)\tPrec@5 98.828 (99.381)\n",
            "Epoch: [50][120/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.000 (0.010)\tLoss 1.9821 (1.9679)\tPrec@1 89.844 (89.811)\tPrec@5 100.000 (99.370)\n",
            "Epoch: [50][130/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.007 (0.009)\tLoss 2.2001 (1.9793)\tPrec@1 87.891 (89.760)\tPrec@5 98.438 (99.371)\n",
            "Epoch: [50][140/329], lr: 0.01000\tTime 0.090 (0.094)\tData 0.008 (0.009)\tLoss 2.5927 (1.9956)\tPrec@1 87.500 (89.669)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [50][150/329], lr: 0.01000\tTime 0.109 (0.094)\tData 0.007 (0.009)\tLoss 2.1347 (1.9956)\tPrec@1 89.453 (89.645)\tPrec@5 99.609 (99.371)\n",
            "Epoch: [50][160/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.000 (0.009)\tLoss 1.6053 (1.9952)\tPrec@1 90.234 (89.633)\tPrec@5 100.000 (99.372)\n",
            "Epoch: [50][170/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.006 (0.009)\tLoss 1.5148 (1.9871)\tPrec@1 92.578 (89.647)\tPrec@5 99.219 (99.372)\n",
            "Epoch: [50][180/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.008)\tLoss 2.2396 (1.9875)\tPrec@1 89.062 (89.650)\tPrec@5 98.047 (99.366)\n",
            "Epoch: [50][190/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.000 (0.008)\tLoss 2.0014 (1.9838)\tPrec@1 88.281 (89.637)\tPrec@5 99.609 (99.366)\n",
            "Epoch: [50][200/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.000 (0.008)\tLoss 1.4225 (1.9721)\tPrec@1 92.188 (89.673)\tPrec@5 99.609 (99.372)\n",
            "Epoch: [50][210/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.013 (0.008)\tLoss 2.0376 (1.9670)\tPrec@1 89.844 (89.712)\tPrec@5 98.828 (99.371)\n",
            "Epoch: [50][220/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.000 (0.008)\tLoss 2.2476 (1.9729)\tPrec@1 89.062 (89.694)\tPrec@5 100.000 (99.376)\n",
            "Epoch: [50][230/329], lr: 0.01000\tTime 0.110 (0.094)\tData 0.004 (0.008)\tLoss 1.4252 (1.9721)\tPrec@1 92.188 (89.692)\tPrec@5 99.609 (99.379)\n",
            "Epoch: [50][240/329], lr: 0.01000\tTime 0.115 (0.096)\tData 0.000 (0.009)\tLoss 1.3646 (1.9724)\tPrec@1 93.359 (89.682)\tPrec@5 99.609 (99.376)\n",
            "Epoch: [50][250/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.012 (0.010)\tLoss 1.7003 (1.9747)\tPrec@1 92.578 (89.677)\tPrec@5 99.219 (99.362)\n",
            "Epoch: [50][260/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.009)\tLoss 1.6639 (1.9724)\tPrec@1 91.797 (89.691)\tPrec@5 99.609 (99.365)\n",
            "Epoch: [50][270/329], lr: 0.01000\tTime 0.104 (0.097)\tData 0.000 (0.009)\tLoss 1.8209 (1.9688)\tPrec@1 92.969 (89.714)\tPrec@5 99.219 (99.363)\n",
            "Epoch: [50][280/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.002 (0.009)\tLoss 2.0465 (1.9699)\tPrec@1 88.672 (89.705)\tPrec@5 99.609 (99.361)\n",
            "Epoch: [50][290/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.000 (0.009)\tLoss 2.3241 (1.9715)\tPrec@1 88.281 (89.692)\tPrec@5 99.609 (99.364)\n",
            "Epoch: [50][300/329], lr: 0.01000\tTime 0.071 (0.096)\tData 0.000 (0.009)\tLoss 1.7882 (1.9721)\tPrec@1 89.844 (89.696)\tPrec@5 99.609 (99.372)\n",
            "Epoch: [50][310/329], lr: 0.01000\tTime 0.070 (0.096)\tData 0.000 (0.009)\tLoss 2.5443 (1.9717)\tPrec@1 87.500 (89.704)\tPrec@5 100.000 (99.376)\n",
            "Epoch: [50][320/329], lr: 0.01000\tTime 0.121 (0.096)\tData 0.079 (0.009)\tLoss 2.2238 (1.9769)\tPrec@1 88.672 (89.673)\tPrec@5 99.219 (99.378)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 5.5690 (5.5690)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.035 (0.051)\tLoss 4.8569 (5.9052)\tPrec@1 75.000 (73.000)\tPrec@5 99.000 (98.091)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 5.1010 (5.8942)\tPrec@1 75.000 (72.619)\tPrec@5 100.000 (98.095)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 6.1383 (5.9367)\tPrec@1 71.000 (72.355)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 5.1590 (5.9629)\tPrec@1 76.000 (72.415)\tPrec@5 96.000 (97.585)\n",
            "Test: [50/100]\tTime 0.012 (0.030)\tLoss 6.3529 (5.9789)\tPrec@1 69.000 (72.235)\tPrec@5 98.000 (97.529)\n",
            "Test: [60/100]\tTime 0.028 (0.029)\tLoss 4.9620 (5.9487)\tPrec@1 80.000 (72.361)\tPrec@5 98.000 (97.639)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 6.4215 (5.9479)\tPrec@1 71.000 (72.465)\tPrec@5 98.000 (97.563)\n",
            "Test: [80/100]\tTime 0.013 (0.028)\tLoss 4.1276 (5.8987)\tPrec@1 84.000 (72.679)\tPrec@5 97.000 (97.531)\n",
            "Test: [90/100]\tTime 0.040 (0.028)\tLoss 5.5247 (5.9575)\tPrec@1 73.000 (72.407)\tPrec@5 99.000 (97.505)\n",
            "val Results: Prec@1 72.430 Prec@5 97.470 Loss 5.96443\n",
            "val Class Accuracy: [0.939,0.925,0.856,0.509,0.569,0.710,0.843,0.778,0.537,0.577]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [51][0/329], lr: 0.01000\tTime 0.503 (0.503)\tData 0.406 (0.406)\tLoss 2.2461 (2.2461)\tPrec@1 88.672 (88.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [51][10/329], lr: 0.01000\tTime 0.074 (0.137)\tData 0.005 (0.045)\tLoss 3.3886 (2.9316)\tPrec@1 81.250 (83.310)\tPrec@5 98.828 (98.651)\n",
            "Epoch: [51][20/329], lr: 0.01000\tTime 0.072 (0.118)\tData 0.000 (0.026)\tLoss 2.7138 (2.9654)\tPrec@1 85.938 (83.668)\tPrec@5 98.047 (98.531)\n",
            "Epoch: [51][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.014 (0.020)\tLoss 2.1494 (2.7757)\tPrec@1 88.281 (84.728)\tPrec@5 99.219 (98.664)\n",
            "Epoch: [51][40/329], lr: 0.01000\tTime 0.121 (0.106)\tData 0.000 (0.016)\tLoss 2.3947 (2.6360)\tPrec@1 86.719 (85.690)\tPrec@5 98.828 (98.790)\n",
            "Epoch: [51][50/329], lr: 0.01000\tTime 0.122 (0.103)\tData 0.006 (0.014)\tLoss 2.0737 (2.5556)\tPrec@1 87.500 (86.152)\tPrec@5 99.609 (98.820)\n",
            "Epoch: [51][60/329], lr: 0.01000\tTime 0.078 (0.101)\tData 0.000 (0.013)\tLoss 1.6054 (2.4741)\tPrec@1 92.188 (86.668)\tPrec@5 99.609 (98.937)\n",
            "Epoch: [51][70/329], lr: 0.01000\tTime 0.101 (0.099)\tData 0.000 (0.012)\tLoss 1.7815 (2.4179)\tPrec@1 90.234 (86.994)\tPrec@5 100.000 (99.010)\n",
            "Epoch: [51][80/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.012 (0.012)\tLoss 1.8092 (2.3562)\tPrec@1 90.234 (87.322)\tPrec@5 99.609 (99.050)\n",
            "Epoch: [51][90/329], lr: 0.01000\tTime 0.073 (0.097)\tData 0.000 (0.011)\tLoss 1.8896 (2.3109)\tPrec@1 88.672 (87.620)\tPrec@5 99.609 (99.090)\n",
            "Epoch: [51][100/329], lr: 0.01000\tTime 0.120 (0.096)\tData 0.006 (0.011)\tLoss 1.9324 (2.2966)\tPrec@1 90.625 (87.751)\tPrec@5 100.000 (99.110)\n",
            "Epoch: [51][110/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.004 (0.011)\tLoss 1.9629 (2.2701)\tPrec@1 89.062 (87.912)\tPrec@5 99.219 (99.120)\n",
            "Epoch: [51][120/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.010 (0.010)\tLoss 1.6982 (2.2333)\tPrec@1 91.016 (88.120)\tPrec@5 99.609 (99.144)\n",
            "Epoch: [51][130/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.000 (0.010)\tLoss 1.4861 (2.2063)\tPrec@1 91.406 (88.275)\tPrec@5 100.000 (99.150)\n",
            "Epoch: [51][140/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.005 (0.010)\tLoss 1.8181 (2.1884)\tPrec@1 90.625 (88.389)\tPrec@5 100.000 (99.155)\n",
            "Epoch: [51][150/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.005 (0.010)\tLoss 1.8650 (2.1711)\tPrec@1 91.406 (88.532)\tPrec@5 100.000 (99.180)\n",
            "Epoch: [51][160/329], lr: 0.01000\tTime 0.074 (0.093)\tData 0.000 (0.009)\tLoss 2.2757 (2.1630)\tPrec@1 87.500 (88.594)\tPrec@5 100.000 (99.199)\n",
            "Epoch: [51][170/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.011 (0.009)\tLoss 1.5372 (2.1503)\tPrec@1 92.188 (88.686)\tPrec@5 99.219 (99.203)\n",
            "Epoch: [51][180/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.000 (0.009)\tLoss 2.1999 (2.1359)\tPrec@1 88.672 (88.773)\tPrec@5 99.609 (99.201)\n",
            "Epoch: [51][190/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.014 (0.009)\tLoss 2.0281 (2.1255)\tPrec@1 89.844 (88.856)\tPrec@5 99.609 (99.209)\n",
            "Epoch: [51][200/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.007 (0.009)\tLoss 1.8966 (2.1101)\tPrec@1 90.234 (88.940)\tPrec@5 98.828 (99.215)\n",
            "Epoch: [51][210/329], lr: 0.01000\tTime 0.110 (0.093)\tData 0.003 (0.009)\tLoss 1.9183 (2.1113)\tPrec@1 90.234 (88.927)\tPrec@5 99.219 (99.222)\n",
            "Epoch: [51][220/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.007 (0.009)\tLoss 2.2915 (2.1016)\tPrec@1 88.672 (88.992)\tPrec@5 98.438 (99.226)\n",
            "Epoch: [51][230/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.006 (0.009)\tLoss 2.0079 (2.1045)\tPrec@1 89.062 (88.963)\tPrec@5 99.609 (99.234)\n",
            "Epoch: [51][240/329], lr: 0.01000\tTime 0.113 (0.092)\tData 0.007 (0.009)\tLoss 1.5916 (2.0957)\tPrec@1 90.625 (89.017)\tPrec@5 100.000 (99.235)\n",
            "Epoch: [51][250/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.009)\tLoss 1.9127 (2.0876)\tPrec@1 89.453 (89.089)\tPrec@5 99.609 (99.245)\n",
            "Epoch: [51][260/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.000 (0.009)\tLoss 2.1203 (2.0724)\tPrec@1 87.891 (89.167)\tPrec@5 100.000 (99.250)\n",
            "Epoch: [51][270/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.007 (0.008)\tLoss 1.4948 (2.0559)\tPrec@1 93.359 (89.259)\tPrec@5 99.609 (99.265)\n",
            "Epoch: [51][280/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.008)\tLoss 1.9981 (2.0472)\tPrec@1 91.016 (89.311)\tPrec@5 99.219 (99.270)\n",
            "Epoch: [51][290/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.000 (0.008)\tLoss 2.0785 (2.0467)\tPrec@1 89.453 (89.335)\tPrec@5 99.219 (99.268)\n",
            "Epoch: [51][300/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.008)\tLoss 2.2308 (2.0412)\tPrec@1 89.844 (89.375)\tPrec@5 98.828 (99.268)\n",
            "Epoch: [51][310/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.000 (0.008)\tLoss 1.7946 (2.0369)\tPrec@1 91.016 (89.403)\tPrec@5 99.219 (99.269)\n",
            "Epoch: [51][320/329], lr: 0.01000\tTime 0.324 (0.094)\tData 0.184 (0.009)\tLoss 2.5800 (2.0333)\tPrec@1 85.547 (89.425)\tPrec@5 99.609 (99.283)\n",
            "Test: [0/100]\tTime 0.376 (0.376)\tLoss 6.9217 (6.9217)\tPrec@1 69.000 (69.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 5.8919 (6.7564)\tPrec@1 73.000 (70.000)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/100]\tTime 0.030 (0.041)\tLoss 5.7748 (6.7446)\tPrec@1 72.000 (69.571)\tPrec@5 98.000 (97.429)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 7.0214 (6.7920)\tPrec@1 65.000 (69.097)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 6.8970 (6.8656)\tPrec@1 68.000 (68.732)\tPrec@5 95.000 (97.537)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 7.5123 (6.8441)\tPrec@1 67.000 (68.784)\tPrec@5 97.000 (97.569)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 5.5521 (6.8275)\tPrec@1 72.000 (68.705)\tPrec@5 99.000 (97.541)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 6.8075 (6.8218)\tPrec@1 71.000 (68.634)\tPrec@5 97.000 (97.634)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 6.6190 (6.8351)\tPrec@1 70.000 (68.481)\tPrec@5 98.000 (97.704)\n",
            "Test: [90/100]\tTime 0.024 (0.028)\tLoss 6.4005 (6.9168)\tPrec@1 70.000 (68.044)\tPrec@5 99.000 (97.615)\n",
            "val Results: Prec@1 68.150 Prec@5 97.540 Loss 6.91278\n",
            "val Class Accuracy: [0.977,0.941,0.697,0.542,0.699,0.811,0.564,0.714,0.516,0.354]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [52][0/329], lr: 0.01000\tTime 0.567 (0.567)\tData 0.473 (0.473)\tLoss 2.3303 (2.3303)\tPrec@1 87.109 (87.109)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [52][10/329], lr: 0.01000\tTime 0.101 (0.144)\tData 0.000 (0.059)\tLoss 1.9724 (2.2355)\tPrec@1 91.016 (88.778)\tPrec@5 99.219 (98.899)\n",
            "Epoch: [52][20/329], lr: 0.01000\tTime 0.106 (0.120)\tData 0.004 (0.034)\tLoss 2.2127 (2.1521)\tPrec@1 88.281 (88.951)\tPrec@5 100.000 (99.089)\n",
            "Epoch: [52][30/329], lr: 0.01000\tTime 0.089 (0.109)\tData 0.003 (0.024)\tLoss 1.9071 (2.0520)\tPrec@1 89.844 (89.302)\tPrec@5 99.609 (99.206)\n",
            "Epoch: [52][40/329], lr: 0.01000\tTime 0.063 (0.104)\tData 0.003 (0.020)\tLoss 2.2210 (2.0269)\tPrec@1 87.891 (89.472)\tPrec@5 99.219 (99.276)\n",
            "Epoch: [52][50/329], lr: 0.01000\tTime 0.088 (0.102)\tData 0.001 (0.017)\tLoss 2.1638 (1.9790)\tPrec@1 89.844 (89.737)\tPrec@5 99.219 (99.303)\n",
            "Epoch: [52][60/329], lr: 0.01000\tTime 0.067 (0.100)\tData 0.004 (0.015)\tLoss 1.8753 (1.9891)\tPrec@1 91.016 (89.677)\tPrec@5 99.609 (99.328)\n",
            "Epoch: [52][70/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.007 (0.014)\tLoss 1.5479 (1.9637)\tPrec@1 92.578 (89.838)\tPrec@5 100.000 (99.367)\n",
            "Epoch: [52][80/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.000 (0.013)\tLoss 1.7386 (1.9448)\tPrec@1 92.188 (89.935)\tPrec@5 99.609 (99.402)\n",
            "Epoch: [52][90/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.000 (0.012)\tLoss 1.9806 (1.9542)\tPrec@1 89.453 (89.921)\tPrec@5 99.219 (99.399)\n",
            "Epoch: [52][100/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.004 (0.012)\tLoss 1.4452 (1.9501)\tPrec@1 94.141 (89.937)\tPrec@5 98.828 (99.389)\n",
            "Epoch: [52][110/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.008 (0.011)\tLoss 1.6727 (1.9478)\tPrec@1 89.453 (89.935)\tPrec@5 98.438 (99.360)\n",
            "Epoch: [52][120/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 2.4610 (1.9533)\tPrec@1 87.500 (89.915)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [52][130/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.005 (0.011)\tLoss 1.4163 (1.9386)\tPrec@1 93.359 (89.993)\tPrec@5 99.609 (99.386)\n",
            "Epoch: [52][140/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.002 (0.010)\tLoss 2.2178 (1.9294)\tPrec@1 89.062 (90.052)\tPrec@5 99.609 (99.385)\n",
            "Epoch: [52][150/329], lr: 0.01000\tTime 0.110 (0.093)\tData 0.008 (0.010)\tLoss 1.8305 (1.9334)\tPrec@1 89.844 (90.009)\tPrec@5 99.219 (99.382)\n",
            "Epoch: [52][160/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.000 (0.010)\tLoss 1.5034 (1.9241)\tPrec@1 92.969 (90.062)\tPrec@5 98.828 (99.362)\n",
            "Epoch: [52][170/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.004 (0.010)\tLoss 1.7791 (1.9244)\tPrec@1 91.406 (90.024)\tPrec@5 99.219 (99.360)\n",
            "Epoch: [52][180/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.007 (0.010)\tLoss 1.9339 (1.9199)\tPrec@1 90.625 (90.049)\tPrec@5 99.609 (99.366)\n",
            "Epoch: [52][190/329], lr: 0.01000\tTime 0.121 (0.092)\tData 0.004 (0.009)\tLoss 1.5111 (1.9098)\tPrec@1 92.578 (90.097)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [52][200/329], lr: 0.01000\tTime 0.104 (0.092)\tData 0.012 (0.009)\tLoss 1.9071 (1.8975)\tPrec@1 89.453 (90.166)\tPrec@5 99.609 (99.384)\n",
            "Epoch: [52][210/329], lr: 0.01000\tTime 0.106 (0.092)\tData 0.004 (0.009)\tLoss 2.1299 (1.9013)\tPrec@1 88.281 (90.120)\tPrec@5 99.219 (99.382)\n",
            "Epoch: [52][220/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.002 (0.009)\tLoss 2.0226 (1.9010)\tPrec@1 91.016 (90.139)\tPrec@5 98.828 (99.381)\n",
            "Epoch: [52][230/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.000 (0.009)\tLoss 1.8777 (1.9053)\tPrec@1 89.844 (90.102)\tPrec@5 99.609 (99.379)\n",
            "Epoch: [52][240/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.000 (0.009)\tLoss 1.8406 (1.9013)\tPrec@1 90.234 (90.131)\tPrec@5 99.609 (99.378)\n",
            "Epoch: [52][250/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.005 (0.009)\tLoss 1.6086 (1.8946)\tPrec@1 91.797 (90.172)\tPrec@5 99.219 (99.381)\n",
            "Epoch: [52][260/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.001 (0.009)\tLoss 1.4462 (1.8912)\tPrec@1 93.359 (90.195)\tPrec@5 99.609 (99.386)\n",
            "Epoch: [52][270/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.002 (0.009)\tLoss 1.9718 (1.8842)\tPrec@1 90.234 (90.230)\tPrec@5 99.219 (99.393)\n",
            "Epoch: [52][280/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.005 (0.008)\tLoss 1.4750 (1.8726)\tPrec@1 91.406 (90.287)\tPrec@5 100.000 (99.413)\n",
            "Epoch: [52][290/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.000 (0.008)\tLoss 2.6786 (1.8733)\tPrec@1 83.203 (90.275)\tPrec@5 100.000 (99.417)\n",
            "Epoch: [52][300/329], lr: 0.01000\tTime 0.088 (0.091)\tData 0.000 (0.008)\tLoss 1.6441 (1.8720)\tPrec@1 91.016 (90.284)\tPrec@5 99.609 (99.420)\n",
            "Epoch: [52][310/329], lr: 0.01000\tTime 0.113 (0.091)\tData 0.002 (0.008)\tLoss 1.9322 (1.8714)\tPrec@1 89.062 (90.276)\tPrec@5 99.609 (99.421)\n",
            "Epoch: [52][320/329], lr: 0.01000\tTime 0.110 (0.091)\tData 0.073 (0.008)\tLoss 1.7371 (1.8692)\tPrec@1 91.797 (90.278)\tPrec@5 99.609 (99.424)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 6.6688 (6.6688)\tPrec@1 67.000 (67.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.037 (0.055)\tLoss 5.7539 (6.3595)\tPrec@1 70.000 (71.364)\tPrec@5 98.000 (98.545)\n",
            "Test: [20/100]\tTime 0.029 (0.040)\tLoss 5.6474 (6.2904)\tPrec@1 74.000 (71.048)\tPrec@5 99.000 (97.952)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 5.6103 (6.2821)\tPrec@1 76.000 (71.000)\tPrec@5 99.000 (97.935)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 5.3445 (6.1829)\tPrec@1 74.000 (71.341)\tPrec@5 97.000 (97.805)\n",
            "Test: [50/100]\tTime 0.020 (0.030)\tLoss 6.9748 (6.1146)\tPrec@1 66.000 (71.549)\tPrec@5 97.000 (97.882)\n",
            "Test: [60/100]\tTime 0.014 (0.030)\tLoss 6.4874 (6.2179)\tPrec@1 69.000 (70.787)\tPrec@5 97.000 (97.967)\n",
            "Test: [70/100]\tTime 0.040 (0.029)\tLoss 6.2918 (6.2537)\tPrec@1 71.000 (70.789)\tPrec@5 99.000 (97.986)\n",
            "Test: [80/100]\tTime 0.011 (0.028)\tLoss 5.1628 (6.1904)\tPrec@1 74.000 (71.049)\tPrec@5 100.000 (98.099)\n",
            "Test: [90/100]\tTime 0.036 (0.028)\tLoss 6.4690 (6.2578)\tPrec@1 70.000 (70.824)\tPrec@5 99.000 (97.989)\n",
            "val Results: Prec@1 70.930 Prec@5 97.990 Loss 6.24917\n",
            "val Class Accuracy: [0.926,0.958,0.604,0.845,0.807,0.473,0.271,0.800,0.638,0.771]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [53][0/329], lr: 0.01000\tTime 0.614 (0.614)\tData 0.522 (0.522)\tLoss 2.1713 (2.1713)\tPrec@1 88.672 (88.672)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [53][10/329], lr: 0.01000\tTime 0.084 (0.141)\tData 0.000 (0.053)\tLoss 2.4036 (2.2579)\tPrec@1 87.109 (88.352)\tPrec@5 98.438 (99.077)\n",
            "Epoch: [53][20/329], lr: 0.01000\tTime 0.079 (0.121)\tData 0.002 (0.031)\tLoss 1.8906 (2.1890)\tPrec@1 88.281 (88.635)\tPrec@5 98.828 (99.089)\n",
            "Epoch: [53][30/329], lr: 0.01000\tTime 0.123 (0.120)\tData 0.014 (0.024)\tLoss 1.6129 (2.1040)\tPrec@1 93.359 (89.138)\tPrec@5 99.219 (99.156)\n",
            "Epoch: [53][40/329], lr: 0.01000\tTime 0.119 (0.120)\tData 0.003 (0.022)\tLoss 1.8562 (2.0673)\tPrec@1 89.062 (89.186)\tPrec@5 99.609 (99.209)\n",
            "Epoch: [53][50/329], lr: 0.01000\tTime 0.140 (0.120)\tData 0.076 (0.023)\tLoss 1.4647 (2.0223)\tPrec@1 92.578 (89.468)\tPrec@5 98.828 (99.242)\n",
            "Epoch: [53][60/329], lr: 0.01000\tTime 0.097 (0.121)\tData 0.004 (0.022)\tLoss 1.5606 (1.9943)\tPrec@1 91.797 (89.639)\tPrec@5 99.609 (99.232)\n",
            "Epoch: [53][70/329], lr: 0.01000\tTime 0.109 (0.118)\tData 0.045 (0.021)\tLoss 1.5359 (1.9632)\tPrec@1 90.625 (89.811)\tPrec@5 99.609 (99.279)\n",
            "Epoch: [53][80/329], lr: 0.01000\tTime 0.093 (0.115)\tData 0.000 (0.019)\tLoss 1.8141 (1.9797)\tPrec@1 90.625 (89.742)\tPrec@5 98.828 (99.243)\n",
            "Epoch: [53][90/329], lr: 0.01000\tTime 0.076 (0.112)\tData 0.000 (0.018)\tLoss 1.8559 (1.9641)\tPrec@1 89.844 (89.839)\tPrec@5 98.828 (99.270)\n",
            "Epoch: [53][100/329], lr: 0.01000\tTime 0.108 (0.110)\tData 0.005 (0.017)\tLoss 1.7923 (1.9483)\tPrec@1 90.625 (89.913)\tPrec@5 99.609 (99.308)\n",
            "Epoch: [53][110/329], lr: 0.01000\tTime 0.114 (0.109)\tData 0.000 (0.016)\tLoss 2.0748 (1.9416)\tPrec@1 89.453 (89.935)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [53][120/329], lr: 0.01000\tTime 0.083 (0.107)\tData 0.007 (0.015)\tLoss 2.1578 (1.9319)\tPrec@1 89.453 (89.992)\tPrec@5 98.828 (99.329)\n",
            "Epoch: [53][130/329], lr: 0.01000\tTime 0.075 (0.106)\tData 0.005 (0.014)\tLoss 2.1320 (1.9202)\tPrec@1 88.281 (90.038)\tPrec@5 100.000 (99.359)\n",
            "Epoch: [53][140/329], lr: 0.01000\tTime 0.091 (0.105)\tData 0.004 (0.014)\tLoss 1.5710 (1.9098)\tPrec@1 91.406 (90.063)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [53][150/329], lr: 0.01000\tTime 0.086 (0.104)\tData 0.000 (0.013)\tLoss 2.0111 (1.9131)\tPrec@1 90.234 (90.079)\tPrec@5 99.609 (99.361)\n",
            "Epoch: [53][160/329], lr: 0.01000\tTime 0.093 (0.103)\tData 0.000 (0.013)\tLoss 1.5758 (1.9120)\tPrec@1 91.406 (90.079)\tPrec@5 99.609 (99.362)\n",
            "Epoch: [53][170/329], lr: 0.01000\tTime 0.093 (0.102)\tData 0.000 (0.012)\tLoss 1.8640 (1.9075)\tPrec@1 89.453 (90.102)\tPrec@5 100.000 (99.356)\n",
            "Epoch: [53][180/329], lr: 0.01000\tTime 0.084 (0.101)\tData 0.005 (0.012)\tLoss 1.7561 (1.9084)\tPrec@1 91.797 (90.118)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [53][190/329], lr: 0.01000\tTime 0.071 (0.101)\tData 0.000 (0.012)\tLoss 1.9243 (1.9031)\tPrec@1 90.625 (90.142)\tPrec@5 99.219 (99.348)\n",
            "Epoch: [53][200/329], lr: 0.01000\tTime 0.090 (0.100)\tData 0.005 (0.012)\tLoss 1.4469 (1.8995)\tPrec@1 91.797 (90.149)\tPrec@5 99.609 (99.355)\n",
            "Epoch: [53][210/329], lr: 0.01000\tTime 0.086 (0.100)\tData 0.012 (0.012)\tLoss 1.4761 (1.8916)\tPrec@1 92.188 (90.190)\tPrec@5 100.000 (99.363)\n",
            "Epoch: [53][220/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.007 (0.011)\tLoss 1.6076 (1.8853)\tPrec@1 90.234 (90.218)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [53][230/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.007 (0.011)\tLoss 1.5862 (1.8791)\tPrec@1 92.188 (90.250)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [53][240/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.010 (0.011)\tLoss 2.4085 (1.8789)\tPrec@1 86.328 (90.251)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [53][250/329], lr: 0.01000\tTime 0.092 (0.098)\tData 0.000 (0.011)\tLoss 1.3783 (1.8757)\tPrec@1 93.359 (90.255)\tPrec@5 100.000 (99.382)\n",
            "Epoch: [53][260/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.000 (0.011)\tLoss 1.5913 (1.8722)\tPrec@1 92.578 (90.294)\tPrec@5 99.609 (99.388)\n",
            "Epoch: [53][270/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.008 (0.011)\tLoss 2.0161 (1.8730)\tPrec@1 89.453 (90.298)\tPrec@5 98.438 (99.387)\n",
            "Epoch: [53][280/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.008 (0.011)\tLoss 1.8312 (1.8756)\tPrec@1 90.625 (90.293)\tPrec@5 98.828 (99.394)\n",
            "Epoch: [53][290/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.000 (0.011)\tLoss 1.8033 (1.8740)\tPrec@1 91.016 (90.310)\tPrec@5 99.219 (99.400)\n",
            "Epoch: [53][300/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.005 (0.011)\tLoss 1.4947 (1.8707)\tPrec@1 93.359 (90.327)\tPrec@5 99.609 (99.408)\n",
            "Epoch: [53][310/329], lr: 0.01000\tTime 0.061 (0.096)\tData 0.000 (0.010)\tLoss 2.0166 (1.8676)\tPrec@1 89.453 (90.340)\tPrec@5 100.000 (99.411)\n",
            "Epoch: [53][320/329], lr: 0.01000\tTime 0.130 (0.096)\tData 0.073 (0.010)\tLoss 1.7569 (1.8661)\tPrec@1 91.797 (90.354)\tPrec@5 100.000 (99.413)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 6.2674 (6.2674)\tPrec@1 69.000 (69.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.019 (0.054)\tLoss 5.7335 (6.7151)\tPrec@1 72.000 (68.455)\tPrec@5 97.000 (95.636)\n",
            "Test: [20/100]\tTime 0.026 (0.041)\tLoss 6.0642 (6.8189)\tPrec@1 67.000 (68.143)\tPrec@5 98.000 (95.476)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 6.5731 (6.7791)\tPrec@1 68.000 (68.355)\tPrec@5 96.000 (95.097)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 6.8876 (6.7490)\tPrec@1 70.000 (68.829)\tPrec@5 93.000 (95.146)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 6.9187 (6.7358)\tPrec@1 67.000 (68.824)\tPrec@5 95.000 (95.333)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 5.9569 (6.7981)\tPrec@1 71.000 (68.426)\tPrec@5 97.000 (95.295)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 6.8321 (6.7883)\tPrec@1 67.000 (68.507)\tPrec@5 98.000 (95.239)\n",
            "Test: [80/100]\tTime 0.027 (0.028)\tLoss 5.8714 (6.7764)\tPrec@1 78.000 (68.457)\tPrec@5 96.000 (95.432)\n",
            "Test: [90/100]\tTime 0.010 (0.027)\tLoss 7.1231 (6.8300)\tPrec@1 67.000 (68.176)\tPrec@5 97.000 (95.418)\n",
            "val Results: Prec@1 68.240 Prec@5 95.350 Loss 6.83325\n",
            "val Class Accuracy: [0.969,0.955,0.862,0.467,0.727,0.468,0.635,0.583,0.613,0.545]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [54][0/329], lr: 0.01000\tTime 0.601 (0.601)\tData 0.530 (0.530)\tLoss 2.1623 (2.1623)\tPrec@1 88.672 (88.672)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [54][10/329], lr: 0.01000\tTime 0.083 (0.137)\tData 0.000 (0.054)\tLoss 2.2200 (2.5085)\tPrec@1 89.062 (86.790)\tPrec@5 98.828 (98.438)\n",
            "Epoch: [54][20/329], lr: 0.01000\tTime 0.090 (0.117)\tData 0.001 (0.031)\tLoss 2.4308 (2.4297)\tPrec@1 87.500 (87.407)\tPrec@5 98.828 (98.698)\n",
            "Epoch: [54][30/329], lr: 0.01000\tTime 0.069 (0.109)\tData 0.000 (0.023)\tLoss 1.8147 (2.2787)\tPrec@1 89.844 (88.206)\tPrec@5 99.609 (98.954)\n",
            "Epoch: [54][40/329], lr: 0.01000\tTime 0.108 (0.104)\tData 0.007 (0.019)\tLoss 2.2526 (2.2466)\tPrec@1 89.062 (88.415)\tPrec@5 99.609 (99.066)\n",
            "Epoch: [54][50/329], lr: 0.01000\tTime 0.093 (0.100)\tData 0.000 (0.016)\tLoss 1.7394 (2.1664)\tPrec@1 90.234 (88.886)\tPrec@5 99.219 (99.089)\n",
            "Epoch: [54][60/329], lr: 0.01000\tTime 0.116 (0.099)\tData 0.000 (0.015)\tLoss 1.7931 (2.1006)\tPrec@1 89.453 (89.248)\tPrec@5 99.609 (99.129)\n",
            "Epoch: [54][70/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.005 (0.013)\tLoss 1.9670 (2.0749)\tPrec@1 89.453 (89.426)\tPrec@5 99.219 (99.136)\n",
            "Epoch: [54][80/329], lr: 0.01000\tTime 0.113 (0.097)\tData 0.004 (0.012)\tLoss 2.1206 (2.0354)\tPrec@1 88.281 (89.598)\tPrec@5 100.000 (99.171)\n",
            "Epoch: [54][90/329], lr: 0.01000\tTime 0.105 (0.096)\tData 0.007 (0.012)\tLoss 2.1593 (2.0044)\tPrec@1 89.844 (89.801)\tPrec@5 98.438 (99.214)\n",
            "Epoch: [54][100/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.001 (0.012)\tLoss 1.9173 (1.9827)\tPrec@1 91.016 (89.910)\tPrec@5 99.609 (99.254)\n",
            "Epoch: [54][110/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.004 (0.011)\tLoss 1.9484 (1.9809)\tPrec@1 89.453 (89.875)\tPrec@5 99.609 (99.279)\n",
            "Epoch: [54][120/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.005 (0.010)\tLoss 2.0955 (1.9815)\tPrec@1 88.672 (89.821)\tPrec@5 99.219 (99.283)\n",
            "Epoch: [54][130/329], lr: 0.01000\tTime 0.171 (0.098)\tData 0.000 (0.010)\tLoss 1.9444 (1.9614)\tPrec@1 89.844 (89.924)\tPrec@5 98.828 (99.269)\n",
            "Epoch: [54][140/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.000 (0.012)\tLoss 1.6758 (1.9537)\tPrec@1 91.406 (89.982)\tPrec@5 99.609 (99.285)\n",
            "Epoch: [54][150/329], lr: 0.01000\tTime 0.105 (0.101)\tData 0.005 (0.014)\tLoss 1.8949 (1.9510)\tPrec@1 90.625 (90.012)\tPrec@5 99.609 (99.289)\n",
            "Epoch: [54][160/329], lr: 0.01000\tTime 0.073 (0.101)\tData 0.011 (0.013)\tLoss 1.7787 (1.9383)\tPrec@1 91.016 (90.072)\tPrec@5 99.219 (99.309)\n",
            "Epoch: [54][170/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.003 (0.013)\tLoss 1.5020 (1.9278)\tPrec@1 90.234 (90.102)\tPrec@5 99.219 (99.322)\n",
            "Epoch: [54][180/329], lr: 0.01000\tTime 0.108 (0.100)\tData 0.000 (0.013)\tLoss 1.9082 (1.9233)\tPrec@1 90.234 (90.120)\tPrec@5 100.000 (99.333)\n",
            "Epoch: [54][190/329], lr: 0.01000\tTime 0.093 (0.100)\tData 0.000 (0.012)\tLoss 1.3939 (1.9125)\tPrec@1 92.578 (90.189)\tPrec@5 99.219 (99.337)\n",
            "Epoch: [54][200/329], lr: 0.01000\tTime 0.095 (0.100)\tData 0.000 (0.012)\tLoss 1.4880 (1.9030)\tPrec@1 92.188 (90.244)\tPrec@5 100.000 (99.345)\n",
            "Epoch: [54][210/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.000 (0.012)\tLoss 1.9341 (1.8982)\tPrec@1 90.234 (90.249)\tPrec@5 98.828 (99.341)\n",
            "Epoch: [54][220/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.010 (0.012)\tLoss 1.3216 (1.8948)\tPrec@1 93.359 (90.249)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [54][230/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.004 (0.011)\tLoss 2.4633 (1.8976)\tPrec@1 87.109 (90.229)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [54][240/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.000 (0.011)\tLoss 1.7456 (1.8895)\tPrec@1 91.016 (90.285)\tPrec@5 100.000 (99.358)\n",
            "Epoch: [54][250/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.000 (0.011)\tLoss 1.4257 (1.8834)\tPrec@1 93.359 (90.311)\tPrec@5 99.609 (99.360)\n",
            "Epoch: [54][260/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.000 (0.011)\tLoss 2.0573 (1.8833)\tPrec@1 88.672 (90.302)\tPrec@5 99.219 (99.362)\n",
            "Epoch: [54][270/329], lr: 0.01000\tTime 0.069 (0.097)\tData 0.000 (0.011)\tLoss 1.7119 (1.8856)\tPrec@1 91.406 (90.276)\tPrec@5 99.609 (99.359)\n",
            "Epoch: [54][280/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.007 (0.010)\tLoss 1.5959 (1.8882)\tPrec@1 92.969 (90.269)\tPrec@5 99.609 (99.358)\n",
            "Epoch: [54][290/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.001 (0.010)\tLoss 1.3875 (1.8913)\tPrec@1 92.969 (90.265)\tPrec@5 99.609 (99.354)\n",
            "Epoch: [54][300/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.005 (0.010)\tLoss 1.8836 (1.8935)\tPrec@1 90.234 (90.253)\tPrec@5 100.000 (99.358)\n",
            "Epoch: [54][310/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.000 (0.010)\tLoss 1.4253 (1.8857)\tPrec@1 92.188 (90.287)\tPrec@5 99.609 (99.352)\n",
            "Epoch: [54][320/329], lr: 0.01000\tTime 0.121 (0.096)\tData 0.072 (0.010)\tLoss 1.6709 (1.8854)\tPrec@1 92.188 (90.276)\tPrec@5 100.000 (99.355)\n",
            "Test: [0/100]\tTime 0.359 (0.359)\tLoss 4.5718 (4.5718)\tPrec@1 80.000 (80.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.017 (0.055)\tLoss 4.8615 (5.6573)\tPrec@1 77.000 (74.909)\tPrec@5 98.000 (97.091)\n",
            "Test: [20/100]\tTime 0.031 (0.041)\tLoss 5.2506 (5.5314)\tPrec@1 73.000 (75.048)\tPrec@5 99.000 (96.810)\n",
            "Test: [30/100]\tTime 0.023 (0.034)\tLoss 5.9158 (5.6356)\tPrec@1 71.000 (74.774)\tPrec@5 96.000 (96.677)\n",
            "Test: [40/100]\tTime 0.009 (0.031)\tLoss 6.4745 (5.7061)\tPrec@1 71.000 (74.341)\tPrec@5 94.000 (96.415)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 5.6092 (5.6774)\tPrec@1 72.000 (74.137)\tPrec@5 93.000 (96.569)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 5.9273 (5.7237)\tPrec@1 69.000 (73.705)\tPrec@5 98.000 (96.639)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 5.3341 (5.7116)\tPrec@1 77.000 (73.676)\tPrec@5 97.000 (96.690)\n",
            "Test: [80/100]\tTime 0.019 (0.028)\tLoss 5.0574 (5.6841)\tPrec@1 80.000 (73.827)\tPrec@5 95.000 (96.778)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 5.1190 (5.7173)\tPrec@1 76.000 (73.670)\tPrec@5 99.000 (96.758)\n",
            "val Results: Prec@1 73.750 Prec@5 96.760 Loss 5.72580\n",
            "val Class Accuracy: [0.894,0.969,0.771,0.733,0.829,0.477,0.832,0.525,0.767,0.578]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [55][0/329], lr: 0.01000\tTime 0.628 (0.628)\tData 0.543 (0.543)\tLoss 2.3309 (2.3309)\tPrec@1 88.281 (88.281)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [55][10/329], lr: 0.01000\tTime 0.070 (0.139)\tData 0.005 (0.057)\tLoss 1.7900 (2.1278)\tPrec@1 90.625 (88.459)\tPrec@5 99.219 (99.006)\n",
            "Epoch: [55][20/329], lr: 0.01000\tTime 0.081 (0.117)\tData 0.005 (0.033)\tLoss 2.0716 (1.9807)\tPrec@1 90.625 (89.602)\tPrec@5 99.609 (99.070)\n",
            "Epoch: [55][30/329], lr: 0.01000\tTime 0.081 (0.109)\tData 0.000 (0.024)\tLoss 1.6399 (1.8526)\tPrec@1 91.797 (90.323)\tPrec@5 98.828 (99.131)\n",
            "Epoch: [55][40/329], lr: 0.01000\tTime 0.094 (0.105)\tData 0.004 (0.020)\tLoss 1.2984 (1.8349)\tPrec@1 93.750 (90.377)\tPrec@5 100.000 (99.152)\n",
            "Epoch: [55][50/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.000 (0.017)\tLoss 1.7588 (1.8422)\tPrec@1 91.406 (90.395)\tPrec@5 99.609 (99.165)\n",
            "Epoch: [55][60/329], lr: 0.01000\tTime 0.072 (0.100)\tData 0.000 (0.015)\tLoss 1.8404 (1.8402)\tPrec@1 91.797 (90.465)\tPrec@5 100.000 (99.212)\n",
            "Epoch: [55][70/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.000 (0.014)\tLoss 1.4901 (1.8358)\tPrec@1 91.406 (90.454)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [55][80/329], lr: 0.01000\tTime 0.119 (0.099)\tData 0.012 (0.014)\tLoss 2.3288 (1.8275)\tPrec@1 87.109 (90.471)\tPrec@5 98.438 (99.267)\n",
            "Epoch: [55][90/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.014 (0.013)\tLoss 1.9004 (1.8223)\tPrec@1 88.672 (90.470)\tPrec@5 99.609 (99.296)\n",
            "Epoch: [55][100/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.005 (0.012)\tLoss 1.6984 (1.8184)\tPrec@1 90.234 (90.443)\tPrec@5 99.609 (99.308)\n",
            "Epoch: [55][110/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.012)\tLoss 1.5534 (1.8062)\tPrec@1 91.797 (90.509)\tPrec@5 100.000 (99.331)\n",
            "Epoch: [55][120/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.012)\tLoss 2.6417 (1.7991)\tPrec@1 87.109 (90.564)\tPrec@5 99.219 (99.335)\n",
            "Epoch: [55][130/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.007 (0.011)\tLoss 1.8459 (1.8013)\tPrec@1 90.234 (90.521)\tPrec@5 99.609 (99.344)\n",
            "Epoch: [55][140/329], lr: 0.01000\tTime 0.070 (0.094)\tData 0.005 (0.011)\tLoss 2.1004 (1.8052)\tPrec@1 88.672 (90.531)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [55][150/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.004 (0.010)\tLoss 2.4067 (1.8142)\tPrec@1 85.938 (90.457)\tPrec@5 99.219 (99.356)\n",
            "Epoch: [55][160/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 2.3024 (1.8163)\tPrec@1 87.891 (90.465)\tPrec@5 100.000 (99.376)\n",
            "Epoch: [55][170/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.007 (0.010)\tLoss 1.6775 (1.8255)\tPrec@1 91.016 (90.415)\tPrec@5 99.609 (99.379)\n",
            "Epoch: [55][180/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.005 (0.010)\tLoss 1.3795 (1.8259)\tPrec@1 92.969 (90.396)\tPrec@5 99.219 (99.376)\n",
            "Epoch: [55][190/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.006 (0.010)\tLoss 1.7105 (1.8183)\tPrec@1 91.797 (90.455)\tPrec@5 98.828 (99.384)\n",
            "Epoch: [55][200/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.007 (0.009)\tLoss 2.1916 (1.8100)\tPrec@1 87.500 (90.493)\tPrec@5 99.219 (99.388)\n",
            "Epoch: [55][210/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.007 (0.009)\tLoss 1.6629 (1.8015)\tPrec@1 90.234 (90.549)\tPrec@5 99.609 (99.411)\n",
            "Epoch: [55][220/329], lr: 0.01000\tTime 0.118 (0.094)\tData 0.008 (0.009)\tLoss 1.2030 (1.7981)\tPrec@1 93.359 (90.584)\tPrec@5 100.000 (99.418)\n",
            "Epoch: [55][230/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.008 (0.010)\tLoss 2.1193 (1.8016)\tPrec@1 89.062 (90.574)\tPrec@5 100.000 (99.422)\n",
            "Epoch: [55][240/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.009 (0.012)\tLoss 1.8320 (1.8038)\tPrec@1 90.625 (90.560)\tPrec@5 98.047 (99.407)\n",
            "Epoch: [55][250/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.005 (0.012)\tLoss 1.8920 (1.8052)\tPrec@1 89.062 (90.538)\tPrec@5 99.219 (99.404)\n",
            "Epoch: [55][260/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.010 (0.012)\tLoss 2.0493 (1.8045)\tPrec@1 89.844 (90.555)\tPrec@5 99.219 (99.407)\n",
            "Epoch: [55][270/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.000 (0.012)\tLoss 1.5691 (1.8074)\tPrec@1 92.188 (90.551)\tPrec@5 99.219 (99.403)\n",
            "Epoch: [55][280/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.012 (0.011)\tLoss 1.9319 (1.8106)\tPrec@1 89.844 (90.542)\tPrec@5 98.828 (99.399)\n",
            "Epoch: [55][290/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.006 (0.011)\tLoss 1.8283 (1.8141)\tPrec@1 90.625 (90.532)\tPrec@5 98.828 (99.389)\n",
            "Epoch: [55][300/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.007 (0.011)\tLoss 2.0040 (1.8088)\tPrec@1 89.844 (90.564)\tPrec@5 98.438 (99.398)\n",
            "Epoch: [55][310/329], lr: 0.01000\tTime 0.092 (0.096)\tData 0.008 (0.011)\tLoss 1.3733 (1.8105)\tPrec@1 92.578 (90.548)\tPrec@5 99.219 (99.405)\n",
            "Epoch: [55][320/329], lr: 0.01000\tTime 0.105 (0.096)\tData 0.060 (0.011)\tLoss 1.6936 (1.8120)\tPrec@1 91.016 (90.543)\tPrec@5 99.609 (99.404)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 7.9565 (7.9565)\tPrec@1 66.000 (66.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 7.8078 (8.8130)\tPrec@1 64.000 (60.091)\tPrec@5 92.000 (92.364)\n",
            "Test: [20/100]\tTime 0.039 (0.040)\tLoss 7.4760 (8.4468)\tPrec@1 64.000 (62.048)\tPrec@5 96.000 (93.238)\n",
            "Test: [30/100]\tTime 0.036 (0.035)\tLoss 9.1482 (8.5041)\tPrec@1 58.000 (61.516)\tPrec@5 92.000 (92.903)\n",
            "Test: [40/100]\tTime 0.035 (0.033)\tLoss 8.5412 (8.5556)\tPrec@1 61.000 (61.317)\tPrec@5 93.000 (92.683)\n",
            "Test: [50/100]\tTime 0.013 (0.030)\tLoss 8.5659 (8.4847)\tPrec@1 63.000 (61.706)\tPrec@5 94.000 (92.824)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 7.5115 (8.4692)\tPrec@1 68.000 (61.852)\tPrec@5 93.000 (92.902)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 6.9401 (8.4584)\tPrec@1 72.000 (61.972)\tPrec@5 95.000 (92.901)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 7.6483 (8.4309)\tPrec@1 68.000 (62.025)\tPrec@5 89.000 (92.975)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 9.3931 (8.5004)\tPrec@1 55.000 (61.769)\tPrec@5 96.000 (92.703)\n",
            "val Results: Prec@1 61.980 Prec@5 92.650 Loss 8.47738\n",
            "val Class Accuracy: [0.812,0.885,0.751,0.900,0.753,0.531,0.449,0.482,0.305,0.330]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [56][0/329], lr: 0.01000\tTime 0.657 (0.657)\tData 0.583 (0.583)\tLoss 1.2394 (1.2394)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [56][10/329], lr: 0.01000\tTime 0.091 (0.145)\tData 0.006 (0.058)\tLoss 1.7515 (2.2781)\tPrec@1 91.797 (87.749)\tPrec@5 99.609 (98.899)\n",
            "Epoch: [56][20/329], lr: 0.01000\tTime 0.117 (0.121)\tData 0.005 (0.033)\tLoss 2.2605 (2.1531)\tPrec@1 88.281 (88.635)\tPrec@5 98.438 (98.958)\n",
            "Epoch: [56][30/329], lr: 0.01000\tTime 0.085 (0.110)\tData 0.005 (0.024)\tLoss 1.7426 (2.0736)\tPrec@1 91.406 (89.062)\tPrec@5 98.828 (98.992)\n",
            "Epoch: [56][40/329], lr: 0.01000\tTime 0.083 (0.106)\tData 0.002 (0.020)\tLoss 1.9860 (2.0369)\tPrec@1 88.672 (89.320)\tPrec@5 99.219 (99.057)\n",
            "Epoch: [56][50/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.013 (0.018)\tLoss 2.2357 (1.9883)\tPrec@1 89.062 (89.568)\tPrec@5 99.219 (99.142)\n",
            "Epoch: [56][60/329], lr: 0.01000\tTime 0.107 (0.100)\tData 0.000 (0.016)\tLoss 1.5996 (1.9790)\tPrec@1 92.188 (89.709)\tPrec@5 99.609 (99.187)\n",
            "Epoch: [56][70/329], lr: 0.01000\tTime 0.085 (0.099)\tData 0.009 (0.014)\tLoss 1.4903 (1.9513)\tPrec@1 91.797 (89.855)\tPrec@5 99.219 (99.252)\n",
            "Epoch: [56][80/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.006 (0.013)\tLoss 1.1683 (1.9044)\tPrec@1 94.922 (90.114)\tPrec@5 99.219 (99.296)\n",
            "Epoch: [56][90/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.000 (0.013)\tLoss 1.8770 (1.9044)\tPrec@1 90.234 (90.118)\tPrec@5 99.609 (99.309)\n",
            "Epoch: [56][100/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.006 (0.012)\tLoss 2.4103 (1.9177)\tPrec@1 87.500 (90.026)\tPrec@5 98.438 (99.327)\n",
            "Epoch: [56][110/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.000 (0.012)\tLoss 1.7908 (1.9094)\tPrec@1 90.234 (90.069)\tPrec@5 99.609 (99.338)\n",
            "Epoch: [56][120/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.007 (0.011)\tLoss 1.8024 (1.8989)\tPrec@1 90.234 (90.134)\tPrec@5 98.828 (99.348)\n",
            "Epoch: [56][130/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.006 (0.011)\tLoss 1.7336 (1.8809)\tPrec@1 91.016 (90.243)\tPrec@5 100.000 (99.365)\n",
            "Epoch: [56][140/329], lr: 0.01000\tTime 0.098 (0.093)\tData 0.000 (0.011)\tLoss 2.4307 (1.8837)\tPrec@1 87.891 (90.237)\tPrec@5 98.438 (99.352)\n",
            "Epoch: [56][150/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.006 (0.010)\tLoss 1.1949 (1.8825)\tPrec@1 92.969 (90.240)\tPrec@5 100.000 (99.353)\n",
            "Epoch: [56][160/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.006 (0.010)\tLoss 1.6389 (1.8848)\tPrec@1 91.406 (90.222)\tPrec@5 98.828 (99.335)\n",
            "Epoch: [56][170/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.007 (0.010)\tLoss 1.5177 (1.8739)\tPrec@1 91.797 (90.280)\tPrec@5 98.438 (99.340)\n",
            "Epoch: [56][180/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.003 (0.010)\tLoss 1.4266 (1.8700)\tPrec@1 92.578 (90.295)\tPrec@5 99.609 (99.346)\n",
            "Epoch: [56][190/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.005 (0.010)\tLoss 1.8716 (1.8673)\tPrec@1 89.453 (90.302)\tPrec@5 98.828 (99.344)\n",
            "Epoch: [56][200/329], lr: 0.01000\tTime 0.087 (0.092)\tData 0.006 (0.010)\tLoss 2.4169 (1.8761)\tPrec@1 86.328 (90.246)\tPrec@5 100.000 (99.345)\n",
            "Epoch: [56][210/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.009 (0.010)\tLoss 1.8629 (1.8749)\tPrec@1 90.234 (90.260)\tPrec@5 99.609 (99.348)\n",
            "Epoch: [56][220/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.000 (0.009)\tLoss 1.5318 (1.8789)\tPrec@1 92.578 (90.247)\tPrec@5 99.609 (99.342)\n",
            "Epoch: [56][230/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.011 (0.009)\tLoss 2.1595 (1.8753)\tPrec@1 89.062 (90.280)\tPrec@5 99.609 (99.342)\n",
            "Epoch: [56][240/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.004 (0.009)\tLoss 1.6371 (1.8724)\tPrec@1 91.797 (90.304)\tPrec@5 98.828 (99.339)\n",
            "Epoch: [56][250/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.009)\tLoss 1.4457 (1.8621)\tPrec@1 91.797 (90.371)\tPrec@5 99.609 (99.351)\n",
            "Epoch: [56][260/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.012 (0.009)\tLoss 1.6307 (1.8599)\tPrec@1 91.406 (90.378)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [56][270/329], lr: 0.01000\tTime 0.055 (0.092)\tData 0.008 (0.009)\tLoss 1.8128 (1.8645)\tPrec@1 89.844 (90.348)\tPrec@5 99.219 (99.363)\n",
            "Epoch: [56][280/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.007 (0.009)\tLoss 1.6069 (1.8651)\tPrec@1 91.797 (90.355)\tPrec@5 99.219 (99.366)\n",
            "Epoch: [56][290/329], lr: 0.01000\tTime 0.076 (0.091)\tData 0.007 (0.009)\tLoss 1.7505 (1.8575)\tPrec@1 91.016 (90.404)\tPrec@5 100.000 (99.373)\n",
            "Epoch: [56][300/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.007 (0.009)\tLoss 2.1009 (1.8611)\tPrec@1 88.672 (90.373)\tPrec@5 99.609 (99.378)\n",
            "Epoch: [56][310/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.005 (0.009)\tLoss 1.5333 (1.8572)\tPrec@1 91.016 (90.400)\tPrec@5 99.609 (99.383)\n",
            "Epoch: [56][320/329], lr: 0.01000\tTime 0.191 (0.092)\tData 0.116 (0.009)\tLoss 1.3510 (1.8500)\tPrec@1 93.359 (90.441)\tPrec@5 100.000 (99.388)\n",
            "Test: [0/100]\tTime 0.444 (0.444)\tLoss 7.4019 (7.4019)\tPrec@1 69.000 (69.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.055 (0.084)\tLoss 5.5039 (7.1223)\tPrec@1 77.000 (69.182)\tPrec@5 95.000 (95.727)\n",
            "Test: [20/100]\tTime 0.035 (0.061)\tLoss 5.1251 (6.9845)\tPrec@1 73.000 (69.619)\tPrec@5 99.000 (95.762)\n",
            "Test: [30/100]\tTime 0.021 (0.053)\tLoss 7.1340 (7.0058)\tPrec@1 64.000 (69.032)\tPrec@5 97.000 (95.613)\n",
            "Test: [40/100]\tTime 0.048 (0.049)\tLoss 7.1210 (7.0331)\tPrec@1 70.000 (68.780)\tPrec@5 92.000 (95.561)\n",
            "Test: [50/100]\tTime 0.020 (0.045)\tLoss 6.8456 (7.0192)\tPrec@1 67.000 (68.647)\tPrec@5 95.000 (95.588)\n",
            "Test: [60/100]\tTime 0.025 (0.042)\tLoss 5.2689 (6.9897)\tPrec@1 78.000 (68.656)\tPrec@5 96.000 (95.639)\n",
            "Test: [70/100]\tTime 0.016 (0.039)\tLoss 7.5189 (7.0303)\tPrec@1 65.000 (68.521)\tPrec@5 98.000 (95.648)\n",
            "Test: [80/100]\tTime 0.010 (0.037)\tLoss 6.5011 (6.9331)\tPrec@1 74.000 (69.099)\tPrec@5 96.000 (95.790)\n",
            "Test: [90/100]\tTime 0.029 (0.036)\tLoss 7.3409 (6.9960)\tPrec@1 66.000 (68.846)\tPrec@5 98.000 (95.703)\n",
            "val Results: Prec@1 68.820 Prec@5 95.650 Loss 7.00689\n",
            "val Class Accuracy: [0.838,0.942,0.868,0.755,0.709,0.688,0.791,0.532,0.329,0.430]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [57][0/329], lr: 0.01000\tTime 0.620 (0.620)\tData 0.532 (0.532)\tLoss 1.6926 (1.6926)\tPrec@1 91.797 (91.797)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [57][10/329], lr: 0.01000\tTime 0.095 (0.140)\tData 0.004 (0.053)\tLoss 2.4907 (2.3118)\tPrec@1 86.328 (88.139)\tPrec@5 98.828 (98.899)\n",
            "Epoch: [57][20/329], lr: 0.01000\tTime 0.113 (0.120)\tData 0.033 (0.037)\tLoss 1.8864 (2.2557)\tPrec@1 89.062 (88.244)\tPrec@5 99.219 (98.958)\n",
            "Epoch: [57][30/329], lr: 0.01000\tTime 0.082 (0.111)\tData 0.006 (0.029)\tLoss 1.8433 (2.2036)\tPrec@1 91.797 (88.584)\tPrec@5 99.609 (98.992)\n",
            "Epoch: [57][40/329], lr: 0.01000\tTime 0.104 (0.107)\tData 0.005 (0.024)\tLoss 1.7161 (2.1672)\tPrec@1 91.406 (88.805)\tPrec@5 99.609 (99.047)\n",
            "Epoch: [57][50/329], lr: 0.01000\tTime 0.072 (0.103)\tData 0.000 (0.021)\tLoss 1.3645 (2.1494)\tPrec@1 93.359 (88.863)\tPrec@5 100.000 (99.027)\n",
            "Epoch: [57][60/329], lr: 0.01000\tTime 0.088 (0.101)\tData 0.000 (0.018)\tLoss 2.1051 (2.1263)\tPrec@1 87.891 (89.005)\tPrec@5 99.219 (99.052)\n",
            "Epoch: [57][70/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.007 (0.017)\tLoss 1.6528 (2.0684)\tPrec@1 90.625 (89.327)\tPrec@5 99.219 (99.070)\n",
            "Epoch: [57][80/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.007 (0.016)\tLoss 1.5528 (2.0149)\tPrec@1 92.578 (89.603)\tPrec@5 99.609 (99.084)\n",
            "Epoch: [57][90/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.000 (0.014)\tLoss 1.7097 (1.9894)\tPrec@1 91.406 (89.749)\tPrec@5 99.219 (99.133)\n",
            "Epoch: [57][100/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.005 (0.014)\tLoss 2.0527 (1.9683)\tPrec@1 89.844 (89.848)\tPrec@5 98.828 (99.165)\n",
            "Epoch: [57][110/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.013)\tLoss 1.4831 (1.9542)\tPrec@1 92.969 (89.911)\tPrec@5 100.000 (99.166)\n",
            "Epoch: [57][120/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.013)\tLoss 1.1279 (1.9341)\tPrec@1 93.750 (90.005)\tPrec@5 100.000 (99.209)\n",
            "Epoch: [57][130/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.007 (0.012)\tLoss 2.1482 (1.9317)\tPrec@1 88.281 (90.008)\tPrec@5 99.609 (99.216)\n",
            "Epoch: [57][140/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.005 (0.012)\tLoss 1.6598 (1.9237)\tPrec@1 91.406 (90.063)\tPrec@5 99.609 (99.241)\n",
            "Epoch: [57][150/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.007 (0.012)\tLoss 1.7608 (1.9082)\tPrec@1 90.625 (90.139)\tPrec@5 98.438 (99.247)\n",
            "Epoch: [57][160/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.005 (0.011)\tLoss 2.0493 (1.9098)\tPrec@1 90.625 (90.118)\tPrec@5 99.609 (99.245)\n",
            "Epoch: [57][170/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.012 (0.011)\tLoss 1.8086 (1.9065)\tPrec@1 91.406 (90.138)\tPrec@5 98.047 (99.251)\n",
            "Epoch: [57][180/329], lr: 0.01000\tTime 0.068 (0.092)\tData 0.001 (0.011)\tLoss 1.5842 (1.8930)\tPrec@1 92.188 (90.206)\tPrec@5 99.609 (99.268)\n",
            "Epoch: [57][190/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.001 (0.010)\tLoss 1.2739 (1.8773)\tPrec@1 93.359 (90.273)\tPrec@5 100.000 (99.282)\n",
            "Epoch: [57][200/329], lr: 0.01000\tTime 0.069 (0.092)\tData 0.000 (0.010)\tLoss 1.5219 (1.8788)\tPrec@1 92.969 (90.252)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [57][210/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.005 (0.010)\tLoss 1.6879 (1.8787)\tPrec@1 91.797 (90.233)\tPrec@5 100.000 (99.293)\n",
            "Epoch: [57][220/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.010)\tLoss 2.1203 (1.8771)\tPrec@1 88.672 (90.238)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [57][230/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.005 (0.010)\tLoss 1.5605 (1.8814)\tPrec@1 93.750 (90.236)\tPrec@5 99.219 (99.303)\n",
            "Epoch: [57][240/329], lr: 0.01000\tTime 0.049 (0.092)\tData 0.000 (0.010)\tLoss 1.5788 (1.8757)\tPrec@1 92.578 (90.273)\tPrec@5 99.219 (99.308)\n",
            "Epoch: [57][250/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.002 (0.010)\tLoss 1.9257 (1.8731)\tPrec@1 89.453 (90.289)\tPrec@5 99.219 (99.306)\n",
            "Epoch: [57][260/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.000 (0.010)\tLoss 1.6368 (1.8721)\tPrec@1 91.406 (90.290)\tPrec@5 100.000 (99.310)\n",
            "Epoch: [57][270/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.007 (0.010)\tLoss 1.4638 (1.8631)\tPrec@1 92.578 (90.341)\tPrec@5 99.609 (99.317)\n",
            "Epoch: [57][280/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.011 (0.009)\tLoss 2.1777 (1.8595)\tPrec@1 87.500 (90.353)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [57][290/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.004 (0.009)\tLoss 2.0856 (1.8585)\tPrec@1 90.234 (90.371)\tPrec@5 99.609 (99.329)\n",
            "Epoch: [57][300/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.006 (0.009)\tLoss 2.0660 (1.8611)\tPrec@1 89.062 (90.349)\tPrec@5 100.000 (99.333)\n",
            "Epoch: [57][310/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.006 (0.009)\tLoss 2.3903 (1.8667)\tPrec@1 87.500 (90.315)\tPrec@5 98.828 (99.333)\n",
            "Epoch: [57][320/329], lr: 0.01000\tTime 0.110 (0.091)\tData 0.067 (0.009)\tLoss 2.1347 (1.8679)\tPrec@1 89.453 (90.307)\tPrec@5 98.828 (99.344)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 6.4680 (6.4680)\tPrec@1 71.000 (71.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.026 (0.057)\tLoss 5.0505 (6.4659)\tPrec@1 76.000 (70.909)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.033 (0.042)\tLoss 6.1925 (6.5896)\tPrec@1 69.000 (69.952)\tPrec@5 98.000 (97.429)\n",
            "Test: [30/100]\tTime 0.019 (0.038)\tLoss 6.1607 (6.6031)\tPrec@1 71.000 (69.774)\tPrec@5 96.000 (96.742)\n",
            "Test: [40/100]\tTime 0.040 (0.035)\tLoss 5.9294 (6.5575)\tPrec@1 73.000 (70.073)\tPrec@5 98.000 (96.756)\n",
            "Test: [50/100]\tTime 0.021 (0.033)\tLoss 7.5244 (6.5686)\tPrec@1 67.000 (70.176)\tPrec@5 97.000 (96.824)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 5.8126 (6.5449)\tPrec@1 74.000 (70.311)\tPrec@5 99.000 (96.951)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 6.9362 (6.5575)\tPrec@1 68.000 (70.225)\tPrec@5 96.000 (96.887)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 5.9526 (6.5413)\tPrec@1 75.000 (70.333)\tPrec@5 97.000 (96.914)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 7.2264 (6.5981)\tPrec@1 66.000 (70.154)\tPrec@5 99.000 (96.934)\n",
            "val Results: Prec@1 70.060 Prec@5 96.960 Loss 6.60798\n",
            "val Class Accuracy: [0.952,0.917,0.595,0.817,0.746,0.630,0.425,0.856,0.620,0.448]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [58][0/329], lr: 0.01000\tTime 0.665 (0.665)\tData 0.568 (0.568)\tLoss 1.5266 (1.5266)\tPrec@1 93.359 (93.359)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [58][10/329], lr: 0.01000\tTime 0.082 (0.151)\tData 0.006 (0.058)\tLoss 2.2140 (2.3934)\tPrec@1 88.672 (87.891)\tPrec@5 99.219 (98.793)\n",
            "Epoch: [58][20/329], lr: 0.01000\tTime 0.094 (0.122)\tData 0.012 (0.034)\tLoss 2.3851 (2.2939)\tPrec@1 87.109 (88.356)\tPrec@5 98.438 (98.977)\n",
            "Epoch: [58][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.000 (0.025)\tLoss 1.8517 (2.1997)\tPrec@1 89.844 (88.735)\tPrec@5 99.219 (99.030)\n",
            "Epoch: [58][40/329], lr: 0.01000\tTime 0.124 (0.110)\tData 0.000 (0.021)\tLoss 2.4073 (2.1353)\tPrec@1 86.719 (89.043)\tPrec@5 99.609 (99.085)\n",
            "Epoch: [58][50/329], lr: 0.01000\tTime 0.124 (0.111)\tData 0.001 (0.018)\tLoss 1.6773 (2.0605)\tPrec@1 91.406 (89.430)\tPrec@5 99.609 (99.104)\n",
            "Epoch: [58][60/329], lr: 0.01000\tTime 0.118 (0.112)\tData 0.013 (0.016)\tLoss 1.4021 (2.0060)\tPrec@1 92.188 (89.696)\tPrec@5 99.219 (99.135)\n",
            "Epoch: [58][70/329], lr: 0.01000\tTime 0.102 (0.115)\tData 0.004 (0.020)\tLoss 1.7081 (1.9911)\tPrec@1 91.016 (89.783)\tPrec@5 99.219 (99.147)\n",
            "Epoch: [58][80/329], lr: 0.01000\tTime 0.108 (0.112)\tData 0.005 (0.018)\tLoss 2.1734 (1.9600)\tPrec@1 88.281 (89.897)\tPrec@5 99.219 (99.175)\n",
            "Epoch: [58][90/329], lr: 0.01000\tTime 0.110 (0.110)\tData 0.000 (0.017)\tLoss 1.4359 (1.9439)\tPrec@1 92.188 (90.011)\tPrec@5 99.609 (99.202)\n",
            "Epoch: [58][100/329], lr: 0.01000\tTime 0.110 (0.109)\tData 0.000 (0.016)\tLoss 1.9221 (1.9257)\tPrec@1 90.625 (90.122)\tPrec@5 98.047 (99.219)\n",
            "Epoch: [58][110/329], lr: 0.01000\tTime 0.111 (0.107)\tData 0.004 (0.015)\tLoss 1.8600 (1.9237)\tPrec@1 89.453 (90.108)\tPrec@5 99.609 (99.229)\n",
            "Epoch: [58][120/329], lr: 0.01000\tTime 0.059 (0.106)\tData 0.000 (0.014)\tLoss 1.8844 (1.9228)\tPrec@1 91.406 (90.128)\tPrec@5 99.609 (99.245)\n",
            "Epoch: [58][130/329], lr: 0.01000\tTime 0.094 (0.105)\tData 0.004 (0.013)\tLoss 1.3553 (1.9070)\tPrec@1 92.578 (90.193)\tPrec@5 99.609 (99.258)\n",
            "Epoch: [58][140/329], lr: 0.01000\tTime 0.119 (0.104)\tData 0.000 (0.012)\tLoss 1.8227 (1.8968)\tPrec@1 91.016 (90.240)\tPrec@5 99.609 (99.285)\n",
            "Epoch: [58][150/329], lr: 0.01000\tTime 0.102 (0.103)\tData 0.005 (0.012)\tLoss 2.5543 (1.8958)\tPrec@1 87.109 (90.255)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [58][160/329], lr: 0.01000\tTime 0.116 (0.102)\tData 0.014 (0.012)\tLoss 1.6620 (1.8905)\tPrec@1 91.016 (90.285)\tPrec@5 99.609 (99.306)\n",
            "Epoch: [58][170/329], lr: 0.01000\tTime 0.132 (0.101)\tData 0.007 (0.011)\tLoss 1.7651 (1.8901)\tPrec@1 91.797 (90.296)\tPrec@5 99.609 (99.310)\n",
            "Epoch: [58][180/329], lr: 0.01000\tTime 0.083 (0.101)\tData 0.000 (0.011)\tLoss 1.6592 (1.8775)\tPrec@1 91.797 (90.366)\tPrec@5 99.609 (99.322)\n",
            "Epoch: [58][190/329], lr: 0.01000\tTime 0.110 (0.100)\tData 0.006 (0.011)\tLoss 2.2626 (1.8787)\tPrec@1 87.891 (90.324)\tPrec@5 99.609 (99.327)\n",
            "Epoch: [58][200/329], lr: 0.01000\tTime 0.107 (0.099)\tData 0.012 (0.010)\tLoss 2.6317 (1.8764)\tPrec@1 85.547 (90.330)\tPrec@5 99.219 (99.320)\n",
            "Epoch: [58][210/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.000 (0.010)\tLoss 1.8434 (1.8729)\tPrec@1 89.844 (90.351)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [58][220/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.007 (0.010)\tLoss 1.9017 (1.8713)\tPrec@1 91.406 (90.360)\tPrec@5 99.219 (99.327)\n",
            "Epoch: [58][230/329], lr: 0.01000\tTime 0.089 (0.098)\tData 0.000 (0.010)\tLoss 1.4409 (1.8730)\tPrec@1 91.797 (90.339)\tPrec@5 99.609 (99.330)\n",
            "Epoch: [58][240/329], lr: 0.01000\tTime 0.095 (0.098)\tData 0.004 (0.010)\tLoss 1.6616 (1.8755)\tPrec@1 92.969 (90.332)\tPrec@5 99.609 (99.329)\n",
            "Epoch: [58][250/329], lr: 0.01000\tTime 0.122 (0.097)\tData 0.005 (0.010)\tLoss 1.8855 (1.8687)\tPrec@1 90.625 (90.365)\tPrec@5 99.609 (99.332)\n",
            "Epoch: [58][260/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.003 (0.009)\tLoss 1.5683 (1.8626)\tPrec@1 91.406 (90.405)\tPrec@5 99.219 (99.331)\n",
            "Epoch: [58][270/329], lr: 0.01000\tTime 0.099 (0.097)\tData 0.000 (0.009)\tLoss 1.8498 (1.8594)\tPrec@1 89.453 (90.407)\tPrec@5 99.609 (99.336)\n",
            "Epoch: [58][280/329], lr: 0.01000\tTime 0.073 (0.096)\tData 0.006 (0.009)\tLoss 1.7664 (1.8537)\tPrec@1 91.797 (90.425)\tPrec@5 99.609 (99.345)\n",
            "Epoch: [58][290/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.007 (0.009)\tLoss 1.5099 (1.8473)\tPrec@1 92.578 (90.468)\tPrec@5 98.828 (99.353)\n",
            "Epoch: [58][300/329], lr: 0.01000\tTime 0.077 (0.096)\tData 0.000 (0.009)\tLoss 2.2360 (1.8496)\tPrec@1 89.453 (90.441)\tPrec@5 99.219 (99.363)\n",
            "Epoch: [58][310/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.000 (0.009)\tLoss 1.9879 (1.8485)\tPrec@1 89.844 (90.455)\tPrec@5 98.438 (99.366)\n",
            "Epoch: [58][320/329], lr: 0.01000\tTime 0.125 (0.096)\tData 0.074 (0.009)\tLoss 1.8161 (1.8482)\tPrec@1 91.797 (90.463)\tPrec@5 99.609 (99.360)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 6.1787 (6.1787)\tPrec@1 72.000 (72.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.026 (0.052)\tLoss 4.8842 (5.7494)\tPrec@1 79.000 (73.545)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/100]\tTime 0.019 (0.039)\tLoss 4.9266 (5.4202)\tPrec@1 77.000 (75.238)\tPrec@5 98.000 (96.952)\n",
            "Test: [30/100]\tTime 0.023 (0.034)\tLoss 6.6098 (5.5928)\tPrec@1 70.000 (74.387)\tPrec@5 97.000 (96.677)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 5.7662 (5.6029)\tPrec@1 74.000 (74.268)\tPrec@5 95.000 (96.683)\n",
            "Test: [50/100]\tTime 0.019 (0.029)\tLoss 5.1298 (5.5296)\tPrec@1 76.000 (74.431)\tPrec@5 97.000 (96.863)\n",
            "Test: [60/100]\tTime 0.037 (0.029)\tLoss 5.7502 (5.5701)\tPrec@1 72.000 (74.082)\tPrec@5 97.000 (96.902)\n",
            "Test: [70/100]\tTime 0.036 (0.029)\tLoss 4.8711 (5.5554)\tPrec@1 79.000 (74.239)\tPrec@5 98.000 (96.986)\n",
            "Test: [80/100]\tTime 0.010 (0.027)\tLoss 5.4489 (5.5373)\tPrec@1 77.000 (74.358)\tPrec@5 96.000 (97.049)\n",
            "Test: [90/100]\tTime 0.023 (0.027)\tLoss 5.5023 (5.5524)\tPrec@1 76.000 (74.286)\tPrec@5 97.000 (97.011)\n",
            "val Results: Prec@1 74.270 Prec@5 96.940 Loss 5.56222\n",
            "val Class Accuracy: [0.904,0.980,0.775,0.548,0.783,0.705,0.822,0.519,0.694,0.697]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [59][0/329], lr: 0.01000\tTime 0.643 (0.643)\tData 0.568 (0.568)\tLoss 2.2708 (2.2708)\tPrec@1 87.109 (87.109)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [59][10/329], lr: 0.01000\tTime 0.082 (0.143)\tData 0.000 (0.059)\tLoss 1.6914 (2.3261)\tPrec@1 90.625 (87.891)\tPrec@5 99.219 (98.544)\n",
            "Epoch: [59][20/329], lr: 0.01000\tTime 0.097 (0.120)\tData 0.000 (0.034)\tLoss 2.1007 (2.2466)\tPrec@1 89.062 (88.356)\tPrec@5 99.609 (98.661)\n",
            "Epoch: [59][30/329], lr: 0.01000\tTime 0.062 (0.109)\tData 0.000 (0.026)\tLoss 1.8209 (2.1217)\tPrec@1 90.625 (89.050)\tPrec@5 98.828 (98.765)\n",
            "Epoch: [59][40/329], lr: 0.01000\tTime 0.080 (0.103)\tData 0.000 (0.021)\tLoss 1.5205 (2.0886)\tPrec@1 91.406 (89.234)\tPrec@5 99.609 (98.857)\n",
            "Epoch: [59][50/329], lr: 0.01000\tTime 0.096 (0.101)\tData 0.004 (0.018)\tLoss 1.9411 (2.0683)\tPrec@1 89.844 (89.361)\tPrec@5 100.000 (98.943)\n",
            "Epoch: [59][60/329], lr: 0.01000\tTime 0.114 (0.098)\tData 0.005 (0.016)\tLoss 1.8977 (2.0258)\tPrec@1 90.234 (89.562)\tPrec@5 100.000 (99.014)\n",
            "Epoch: [59][70/329], lr: 0.01000\tTime 0.091 (0.097)\tData 0.000 (0.014)\tLoss 2.1840 (2.0111)\tPrec@1 90.625 (89.657)\tPrec@5 100.000 (99.065)\n",
            "Epoch: [59][80/329], lr: 0.01000\tTime 0.078 (0.096)\tData 0.000 (0.013)\tLoss 1.5691 (1.9715)\tPrec@1 92.188 (89.800)\tPrec@5 99.219 (99.122)\n",
            "Epoch: [59][90/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.005 (0.012)\tLoss 1.8930 (1.9430)\tPrec@1 89.844 (89.912)\tPrec@5 99.609 (99.172)\n",
            "Epoch: [59][100/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.007 (0.011)\tLoss 1.4881 (1.9125)\tPrec@1 92.188 (90.064)\tPrec@5 99.609 (99.180)\n",
            "Epoch: [59][110/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.011)\tLoss 1.8991 (1.8965)\tPrec@1 89.844 (90.125)\tPrec@5 99.219 (99.212)\n",
            "Epoch: [59][120/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.004 (0.011)\tLoss 1.8116 (1.8992)\tPrec@1 90.625 (90.128)\tPrec@5 98.438 (99.219)\n",
            "Epoch: [59][130/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.012 (0.010)\tLoss 1.5639 (1.8920)\tPrec@1 92.188 (90.175)\tPrec@5 99.219 (99.234)\n",
            "Epoch: [59][140/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.000 (0.010)\tLoss 1.5878 (1.8830)\tPrec@1 91.797 (90.248)\tPrec@5 100.000 (99.246)\n",
            "Epoch: [59][150/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.000 (0.010)\tLoss 1.7770 (1.8748)\tPrec@1 91.406 (90.284)\tPrec@5 100.000 (99.270)\n",
            "Epoch: [59][160/329], lr: 0.01000\tTime 0.147 (0.098)\tData 0.000 (0.009)\tLoss 1.5779 (1.8717)\tPrec@1 92.188 (90.322)\tPrec@5 98.828 (99.289)\n",
            "Epoch: [59][170/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.021 (0.010)\tLoss 1.9267 (1.8643)\tPrec@1 89.062 (90.346)\tPrec@5 99.219 (99.290)\n",
            "Epoch: [59][180/329], lr: 0.01000\tTime 0.107 (0.098)\tData 0.000 (0.010)\tLoss 1.2534 (1.8602)\tPrec@1 94.531 (90.394)\tPrec@5 100.000 (99.312)\n",
            "Epoch: [59][190/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.000 (0.009)\tLoss 1.6696 (1.8568)\tPrec@1 91.016 (90.423)\tPrec@5 98.828 (99.313)\n",
            "Epoch: [59][200/329], lr: 0.01000\tTime 0.129 (0.098)\tData 0.001 (0.009)\tLoss 1.6762 (1.8543)\tPrec@1 91.406 (90.417)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [59][210/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.000 (0.009)\tLoss 1.4671 (1.8521)\tPrec@1 92.188 (90.412)\tPrec@5 99.609 (99.332)\n",
            "Epoch: [59][220/329], lr: 0.01000\tTime 0.105 (0.097)\tData 0.006 (0.009)\tLoss 1.8001 (1.8495)\tPrec@1 90.625 (90.422)\tPrec@5 100.000 (99.341)\n",
            "Epoch: [59][230/329], lr: 0.01000\tTime 0.066 (0.097)\tData 0.005 (0.009)\tLoss 1.4314 (1.8451)\tPrec@1 93.359 (90.466)\tPrec@5 99.219 (99.344)\n",
            "Epoch: [59][240/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.010 (0.009)\tLoss 1.9828 (1.8426)\tPrec@1 89.453 (90.484)\tPrec@5 99.609 (99.352)\n",
            "Epoch: [59][250/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.000 (0.008)\tLoss 1.7636 (1.8398)\tPrec@1 91.797 (90.505)\tPrec@5 98.438 (99.346)\n",
            "Epoch: [59][260/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.007 (0.008)\tLoss 2.1592 (1.8424)\tPrec@1 88.672 (90.498)\tPrec@5 99.609 (99.355)\n",
            "Epoch: [59][270/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.008)\tLoss 2.1333 (1.8432)\tPrec@1 89.062 (90.491)\tPrec@5 98.828 (99.360)\n",
            "Epoch: [59][280/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.001 (0.008)\tLoss 1.5896 (1.8387)\tPrec@1 91.016 (90.508)\tPrec@5 100.000 (99.358)\n",
            "Epoch: [59][290/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.007 (0.008)\tLoss 1.9914 (1.8398)\tPrec@1 90.234 (90.504)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [59][300/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.000 (0.008)\tLoss 1.8557 (1.8387)\tPrec@1 89.844 (90.511)\tPrec@5 98.828 (99.351)\n",
            "Epoch: [59][310/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.008)\tLoss 2.1288 (1.8394)\tPrec@1 88.281 (90.509)\tPrec@5 98.828 (99.351)\n",
            "Epoch: [59][320/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.057 (0.008)\tLoss 1.2948 (1.8401)\tPrec@1 94.141 (90.507)\tPrec@5 100.000 (99.364)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 7.5280 (7.5280)\tPrec@1 67.000 (67.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.015 (0.053)\tLoss 7.1109 (7.3547)\tPrec@1 66.000 (66.636)\tPrec@5 96.000 (97.182)\n",
            "Test: [20/100]\tTime 0.017 (0.039)\tLoss 5.4464 (7.0827)\tPrec@1 75.000 (67.619)\tPrec@5 99.000 (97.000)\n",
            "Test: [30/100]\tTime 0.017 (0.033)\tLoss 6.8468 (7.0709)\tPrec@1 68.000 (67.645)\tPrec@5 96.000 (96.968)\n",
            "Test: [40/100]\tTime 0.035 (0.032)\tLoss 6.6423 (7.0648)\tPrec@1 69.000 (67.732)\tPrec@5 97.000 (96.927)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 7.1333 (7.0985)\tPrec@1 65.000 (67.392)\tPrec@5 98.000 (97.098)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 6.1410 (7.0831)\tPrec@1 72.000 (67.557)\tPrec@5 98.000 (97.033)\n",
            "Test: [70/100]\tTime 0.031 (0.029)\tLoss 6.9572 (7.1230)\tPrec@1 64.000 (67.225)\tPrec@5 99.000 (97.042)\n",
            "Test: [80/100]\tTime 0.022 (0.028)\tLoss 5.7332 (7.0883)\tPrec@1 74.000 (67.259)\tPrec@5 97.000 (97.111)\n",
            "Test: [90/100]\tTime 0.034 (0.028)\tLoss 6.4217 (7.1738)\tPrec@1 74.000 (66.901)\tPrec@5 97.000 (97.000)\n",
            "val Results: Prec@1 67.010 Prec@5 96.940 Loss 7.17423\n",
            "val Class Accuracy: [0.894,0.969,0.874,0.567,0.828,0.621,0.391,0.768,0.444,0.345]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [60][0/329], lr: 0.01000\tTime 0.657 (0.657)\tData 0.578 (0.578)\tLoss 2.1644 (2.1644)\tPrec@1 89.062 (89.062)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [60][10/329], lr: 0.01000\tTime 0.082 (0.144)\tData 0.000 (0.057)\tLoss 3.3417 (3.6005)\tPrec@1 80.078 (80.078)\tPrec@5 98.047 (96.449)\n",
            "Epoch: [60][20/329], lr: 0.01000\tTime 0.093 (0.122)\tData 0.000 (0.032)\tLoss 2.7846 (3.3642)\tPrec@1 83.984 (81.250)\tPrec@5 99.219 (97.656)\n",
            "Epoch: [60][30/329], lr: 0.01000\tTime 0.111 (0.111)\tData 0.007 (0.024)\tLoss 2.5528 (3.0883)\tPrec@1 85.547 (82.976)\tPrec@5 98.438 (98.034)\n",
            "Epoch: [60][40/329], lr: 0.01000\tTime 0.077 (0.106)\tData 0.001 (0.019)\tLoss 2.3613 (2.9335)\tPrec@1 87.891 (83.965)\tPrec@5 98.828 (98.237)\n",
            "Epoch: [60][50/329], lr: 0.01000\tTime 0.089 (0.102)\tData 0.004 (0.017)\tLoss 2.5757 (2.8307)\tPrec@1 87.109 (84.658)\tPrec@5 99.609 (98.407)\n",
            "Epoch: [60][60/329], lr: 0.01000\tTime 0.097 (0.100)\tData 0.004 (0.015)\tLoss 1.7704 (2.7031)\tPrec@1 90.625 (85.496)\tPrec@5 99.219 (98.572)\n",
            "Epoch: [60][70/329], lr: 0.01000\tTime 0.114 (0.099)\tData 0.005 (0.014)\tLoss 2.0723 (2.6205)\tPrec@1 89.453 (85.982)\tPrec@5 99.609 (98.691)\n",
            "Epoch: [60][80/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.009 (0.013)\tLoss 2.1795 (2.5363)\tPrec@1 87.891 (86.410)\tPrec@5 99.219 (98.785)\n",
            "Epoch: [60][90/329], lr: 0.01000\tTime 0.070 (0.096)\tData 0.007 (0.013)\tLoss 1.9923 (2.4666)\tPrec@1 89.844 (86.805)\tPrec@5 99.609 (98.841)\n",
            "Epoch: [60][100/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.006 (0.012)\tLoss 1.7703 (2.3997)\tPrec@1 90.234 (87.241)\tPrec@5 99.609 (98.913)\n",
            "Epoch: [60][110/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.008 (0.012)\tLoss 1.8258 (2.3585)\tPrec@1 89.453 (87.444)\tPrec@5 100.000 (98.955)\n",
            "Epoch: [60][120/329], lr: 0.01000\tTime 0.069 (0.094)\tData 0.000 (0.011)\tLoss 2.1238 (2.3244)\tPrec@1 89.453 (87.626)\tPrec@5 99.219 (98.977)\n",
            "Epoch: [60][130/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.005 (0.011)\tLoss 2.1873 (2.3010)\tPrec@1 89.453 (87.780)\tPrec@5 98.438 (99.007)\n",
            "Epoch: [60][140/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.005 (0.011)\tLoss 2.0350 (2.2745)\tPrec@1 89.453 (87.904)\tPrec@5 99.609 (99.036)\n",
            "Epoch: [60][150/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.011)\tLoss 2.0285 (2.2483)\tPrec@1 89.453 (88.059)\tPrec@5 99.609 (99.040)\n",
            "Epoch: [60][160/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.004 (0.010)\tLoss 1.7678 (2.2244)\tPrec@1 89.062 (88.218)\tPrec@5 100.000 (99.071)\n",
            "Epoch: [60][170/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.009 (0.010)\tLoss 1.5083 (2.2080)\tPrec@1 93.750 (88.343)\tPrec@5 99.609 (99.095)\n",
            "Epoch: [60][180/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.000 (0.010)\tLoss 1.4850 (2.1910)\tPrec@1 91.406 (88.480)\tPrec@5 98.828 (99.100)\n",
            "Epoch: [60][190/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.011 (0.010)\tLoss 1.8734 (2.1729)\tPrec@1 89.844 (88.553)\tPrec@5 98.828 (99.108)\n",
            "Epoch: [60][200/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.003 (0.010)\tLoss 1.9256 (2.1600)\tPrec@1 89.062 (88.625)\tPrec@5 98.828 (99.125)\n",
            "Epoch: [60][210/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.000 (0.009)\tLoss 1.8729 (2.1452)\tPrec@1 90.625 (88.714)\tPrec@5 99.609 (99.143)\n",
            "Epoch: [60][220/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 1.4960 (2.1351)\tPrec@1 93.359 (88.774)\tPrec@5 99.609 (99.153)\n",
            "Epoch: [60][230/329], lr: 0.01000\tTime 0.117 (0.092)\tData 0.007 (0.009)\tLoss 1.9792 (2.1285)\tPrec@1 89.844 (88.807)\tPrec@5 98.438 (99.156)\n",
            "Epoch: [60][240/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.000 (0.009)\tLoss 1.3562 (2.1113)\tPrec@1 94.531 (88.912)\tPrec@5 100.000 (99.170)\n",
            "Epoch: [60][250/329], lr: 0.01000\tTime 0.149 (0.094)\tData 0.042 (0.009)\tLoss 1.3463 (2.0970)\tPrec@1 92.969 (88.992)\tPrec@5 100.000 (99.185)\n",
            "Epoch: [60][260/329], lr: 0.01000\tTime 0.117 (0.095)\tData 0.001 (0.010)\tLoss 1.8970 (2.0858)\tPrec@1 91.016 (89.064)\tPrec@5 99.609 (99.201)\n",
            "Epoch: [60][270/329], lr: 0.01000\tTime 0.067 (0.095)\tData 0.003 (0.010)\tLoss 1.5282 (2.0778)\tPrec@1 92.969 (89.107)\tPrec@5 99.219 (99.209)\n",
            "Epoch: [60][280/329], lr: 0.01000\tTime 0.111 (0.095)\tData 0.001 (0.010)\tLoss 2.4065 (2.0698)\tPrec@1 87.109 (89.142)\tPrec@5 99.609 (99.220)\n",
            "Epoch: [60][290/329], lr: 0.01000\tTime 0.069 (0.095)\tData 0.000 (0.010)\tLoss 1.8884 (2.0632)\tPrec@1 88.281 (89.182)\tPrec@5 99.219 (99.224)\n",
            "Epoch: [60][300/329], lr: 0.01000\tTime 0.073 (0.095)\tData 0.009 (0.010)\tLoss 2.2783 (2.0597)\tPrec@1 87.891 (89.194)\tPrec@5 100.000 (99.234)\n",
            "Epoch: [60][310/329], lr: 0.01000\tTime 0.124 (0.095)\tData 0.005 (0.010)\tLoss 2.1422 (2.0611)\tPrec@1 87.891 (89.199)\tPrec@5 98.438 (99.235)\n",
            "Epoch: [60][320/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.055 (0.010)\tLoss 2.1492 (2.0547)\tPrec@1 89.453 (89.243)\tPrec@5 99.219 (99.242)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 6.7994 (6.7994)\tPrec@1 69.000 (69.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.017 (0.055)\tLoss 5.4252 (6.4688)\tPrec@1 73.000 (70.455)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 4.7591 (6.5365)\tPrec@1 78.000 (69.905)\tPrec@5 100.000 (97.524)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 7.2541 (6.5581)\tPrec@1 65.000 (69.871)\tPrec@5 100.000 (97.484)\n",
            "Test: [40/100]\tTime 0.017 (0.032)\tLoss 6.7912 (6.4698)\tPrec@1 68.000 (70.122)\tPrec@5 98.000 (97.512)\n",
            "Test: [50/100]\tTime 0.026 (0.030)\tLoss 6.1199 (6.4273)\tPrec@1 72.000 (70.137)\tPrec@5 97.000 (97.451)\n",
            "Test: [60/100]\tTime 0.034 (0.029)\tLoss 5.4369 (6.4315)\tPrec@1 72.000 (70.164)\tPrec@5 97.000 (97.443)\n",
            "Test: [70/100]\tTime 0.028 (0.029)\tLoss 6.5304 (6.4708)\tPrec@1 68.000 (70.042)\tPrec@5 97.000 (97.507)\n",
            "Test: [80/100]\tTime 0.048 (0.029)\tLoss 5.5669 (6.3761)\tPrec@1 74.000 (70.395)\tPrec@5 95.000 (97.481)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 5.3609 (6.4332)\tPrec@1 75.000 (70.143)\tPrec@5 99.000 (97.418)\n",
            "val Results: Prec@1 70.050 Prec@5 97.440 Loss 6.46209\n",
            "val Class Accuracy: [0.911,0.878,0.915,0.663,0.599,0.649,0.702,0.573,0.396,0.719]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [61][0/329], lr: 0.01000\tTime 0.599 (0.599)\tData 0.495 (0.495)\tLoss 2.3015 (2.3015)\tPrec@1 88.672 (88.672)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [61][10/329], lr: 0.01000\tTime 0.105 (0.139)\tData 0.003 (0.049)\tLoss 2.5877 (2.8625)\tPrec@1 87.109 (84.837)\tPrec@5 98.047 (97.869)\n",
            "Epoch: [61][20/329], lr: 0.01000\tTime 0.096 (0.118)\tData 0.000 (0.028)\tLoss 2.1365 (2.6380)\tPrec@1 89.453 (86.049)\tPrec@5 98.828 (98.438)\n",
            "Epoch: [61][30/329], lr: 0.01000\tTime 0.098 (0.109)\tData 0.007 (0.021)\tLoss 2.5005 (2.5267)\tPrec@1 87.500 (86.757)\tPrec@5 99.609 (98.702)\n",
            "Epoch: [61][40/329], lr: 0.01000\tTime 0.072 (0.103)\tData 0.000 (0.017)\tLoss 2.1279 (2.4232)\tPrec@1 88.281 (87.357)\tPrec@5 99.609 (98.876)\n",
            "Epoch: [61][50/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.004 (0.015)\tLoss 2.8759 (2.3487)\tPrec@1 83.984 (87.714)\tPrec@5 98.047 (98.912)\n",
            "Epoch: [61][60/329], lr: 0.01000\tTime 0.086 (0.099)\tData 0.007 (0.014)\tLoss 2.0540 (2.3094)\tPrec@1 91.406 (87.948)\tPrec@5 99.219 (98.937)\n",
            "Epoch: [61][70/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.005 (0.013)\tLoss 1.8682 (2.2564)\tPrec@1 90.625 (88.287)\tPrec@5 100.000 (99.026)\n",
            "Epoch: [61][80/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.003 (0.012)\tLoss 1.5010 (2.2138)\tPrec@1 91.797 (88.522)\tPrec@5 100.000 (99.084)\n",
            "Epoch: [61][90/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.004 (0.012)\tLoss 2.1851 (2.1806)\tPrec@1 89.844 (88.706)\tPrec@5 98.828 (99.099)\n",
            "Epoch: [61][100/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.003 (0.011)\tLoss 2.4849 (2.1563)\tPrec@1 86.328 (88.807)\tPrec@5 99.219 (99.118)\n",
            "Epoch: [61][110/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.006 (0.011)\tLoss 2.3829 (2.1437)\tPrec@1 87.500 (88.894)\tPrec@5 98.828 (99.113)\n",
            "Epoch: [61][120/329], lr: 0.01000\tTime 0.069 (0.095)\tData 0.000 (0.011)\tLoss 1.7607 (2.1218)\tPrec@1 89.844 (89.033)\tPrec@5 100.000 (99.135)\n",
            "Epoch: [61][130/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.005 (0.010)\tLoss 1.1375 (2.1068)\tPrec@1 93.750 (89.113)\tPrec@5 100.000 (99.153)\n",
            "Epoch: [61][140/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.010)\tLoss 1.8067 (2.0932)\tPrec@1 91.797 (89.184)\tPrec@5 99.609 (99.163)\n",
            "Epoch: [61][150/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.006 (0.010)\tLoss 2.1162 (2.0730)\tPrec@1 89.844 (89.280)\tPrec@5 98.828 (99.170)\n",
            "Epoch: [61][160/329], lr: 0.01000\tTime 0.119 (0.093)\tData 0.007 (0.010)\tLoss 1.9364 (2.0618)\tPrec@1 88.672 (89.346)\tPrec@5 99.219 (99.187)\n",
            "Epoch: [61][170/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.009 (0.010)\tLoss 2.0847 (2.0530)\tPrec@1 89.844 (89.396)\tPrec@5 98.828 (99.187)\n",
            "Epoch: [61][180/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.007 (0.010)\tLoss 2.4594 (2.0419)\tPrec@1 85.938 (89.449)\tPrec@5 100.000 (99.201)\n",
            "Epoch: [61][190/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.004 (0.010)\tLoss 1.2290 (2.0269)\tPrec@1 92.969 (89.519)\tPrec@5 99.609 (99.225)\n",
            "Epoch: [61][200/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.005 (0.010)\tLoss 2.0262 (2.0209)\tPrec@1 87.891 (89.535)\tPrec@5 100.000 (99.236)\n",
            "Epoch: [61][210/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 1.8514 (2.0155)\tPrec@1 91.406 (89.551)\tPrec@5 99.609 (99.243)\n",
            "Epoch: [61][220/329], lr: 0.01000\tTime 0.118 (0.093)\tData 0.006 (0.009)\tLoss 1.5462 (2.0012)\tPrec@1 93.359 (89.660)\tPrec@5 100.000 (99.259)\n",
            "Epoch: [61][230/329], lr: 0.01000\tTime 0.096 (0.093)\tData 0.012 (0.009)\tLoss 2.0112 (1.9963)\tPrec@1 89.453 (89.676)\tPrec@5 99.219 (99.259)\n",
            "Epoch: [61][240/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.009 (0.009)\tLoss 1.8016 (1.9941)\tPrec@1 90.625 (89.693)\tPrec@5 99.609 (99.272)\n",
            "Epoch: [61][250/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.000 (0.009)\tLoss 2.3155 (1.9853)\tPrec@1 87.891 (89.744)\tPrec@5 99.609 (99.275)\n",
            "Epoch: [61][260/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.006 (0.009)\tLoss 1.5782 (1.9721)\tPrec@1 91.797 (89.817)\tPrec@5 99.609 (99.283)\n",
            "Epoch: [61][270/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.000 (0.009)\tLoss 2.1910 (1.9615)\tPrec@1 89.844 (89.881)\tPrec@5 97.656 (99.285)\n",
            "Epoch: [61][280/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.009)\tLoss 1.8790 (1.9530)\tPrec@1 90.234 (89.927)\tPrec@5 99.219 (99.287)\n",
            "Epoch: [61][290/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.007 (0.009)\tLoss 1.4960 (1.9470)\tPrec@1 91.797 (89.969)\tPrec@5 99.609 (99.286)\n",
            "Epoch: [61][300/329], lr: 0.01000\tTime 0.114 (0.093)\tData 0.007 (0.009)\tLoss 1.6986 (1.9456)\tPrec@1 91.406 (89.971)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [61][310/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.000 (0.009)\tLoss 1.8669 (1.9452)\tPrec@1 90.625 (89.976)\tPrec@5 99.219 (99.285)\n",
            "Epoch: [61][320/329], lr: 0.01000\tTime 0.249 (0.093)\tData 0.163 (0.009)\tLoss 1.5687 (1.9439)\tPrec@1 92.188 (89.980)\tPrec@5 100.000 (99.289)\n",
            "Test: [0/100]\tTime 0.480 (0.480)\tLoss 5.5376 (5.5376)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.052 (0.083)\tLoss 3.9415 (5.0913)\tPrec@1 82.000 (76.182)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/100]\tTime 0.027 (0.062)\tLoss 4.8006 (5.0391)\tPrec@1 75.000 (76.476)\tPrec@5 97.000 (97.952)\n",
            "Test: [30/100]\tTime 0.026 (0.055)\tLoss 6.5217 (5.1789)\tPrec@1 70.000 (75.935)\tPrec@5 97.000 (97.710)\n",
            "Test: [40/100]\tTime 0.048 (0.050)\tLoss 4.9924 (5.1217)\tPrec@1 75.000 (76.024)\tPrec@5 97.000 (97.683)\n",
            "Test: [50/100]\tTime 0.041 (0.046)\tLoss 4.5691 (5.1180)\tPrec@1 79.000 (75.980)\tPrec@5 98.000 (97.765)\n",
            "Test: [60/100]\tTime 0.030 (0.043)\tLoss 6.1406 (5.1963)\tPrec@1 72.000 (75.639)\tPrec@5 99.000 (97.803)\n",
            "Test: [70/100]\tTime 0.023 (0.040)\tLoss 5.8516 (5.2351)\tPrec@1 72.000 (75.451)\tPrec@5 96.000 (97.789)\n",
            "Test: [80/100]\tTime 0.041 (0.038)\tLoss 4.3541 (5.1807)\tPrec@1 80.000 (75.519)\tPrec@5 98.000 (97.815)\n",
            "Test: [90/100]\tTime 0.036 (0.037)\tLoss 5.5025 (5.2663)\tPrec@1 73.000 (75.077)\tPrec@5 99.000 (97.615)\n",
            "val Results: Prec@1 75.010 Prec@5 97.560 Loss 5.28047\n",
            "val Class Accuracy: [0.896,0.909,0.817,0.518,0.919,0.626,0.683,0.627,0.653,0.853]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [62][0/329], lr: 0.01000\tTime 0.682 (0.682)\tData 0.599 (0.599)\tLoss 1.6899 (1.6899)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [62][10/329], lr: 0.01000\tTime 0.115 (0.153)\tData 0.007 (0.063)\tLoss 2.6963 (2.8104)\tPrec@1 86.719 (85.405)\tPrec@5 99.219 (98.438)\n",
            "Epoch: [62][20/329], lr: 0.01000\tTime 0.091 (0.124)\tData 0.004 (0.036)\tLoss 2.1662 (2.5543)\tPrec@1 89.844 (87.091)\tPrec@5 98.828 (98.605)\n",
            "Epoch: [62][30/329], lr: 0.01000\tTime 0.086 (0.114)\tData 0.000 (0.026)\tLoss 2.4482 (2.4321)\tPrec@1 87.500 (87.601)\tPrec@5 98.438 (98.664)\n",
            "Epoch: [62][40/329], lr: 0.01000\tTime 0.104 (0.109)\tData 0.000 (0.021)\tLoss 1.8422 (2.3484)\tPrec@1 89.453 (88.024)\tPrec@5 98.438 (98.695)\n",
            "Epoch: [62][50/329], lr: 0.01000\tTime 0.074 (0.105)\tData 0.005 (0.019)\tLoss 2.2307 (2.3012)\tPrec@1 89.062 (88.235)\tPrec@5 100.000 (98.874)\n",
            "Epoch: [62][60/329], lr: 0.01000\tTime 0.104 (0.103)\tData 0.002 (0.017)\tLoss 1.5238 (2.2099)\tPrec@1 92.188 (88.749)\tPrec@5 99.219 (98.995)\n",
            "Epoch: [62][70/329], lr: 0.01000\tTime 0.061 (0.101)\tData 0.000 (0.015)\tLoss 1.8916 (2.1644)\tPrec@1 90.234 (88.952)\tPrec@5 100.000 (99.037)\n",
            "Epoch: [62][80/329], lr: 0.01000\tTime 0.103 (0.100)\tData 0.000 (0.014)\tLoss 1.4486 (2.1188)\tPrec@1 92.188 (89.207)\tPrec@5 100.000 (99.074)\n",
            "Epoch: [62][90/329], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.013)\tLoss 1.6539 (2.0948)\tPrec@1 90.625 (89.247)\tPrec@5 100.000 (99.124)\n",
            "Epoch: [62][100/329], lr: 0.01000\tTime 0.068 (0.098)\tData 0.003 (0.013)\tLoss 1.8064 (2.0538)\tPrec@1 91.016 (89.457)\tPrec@5 100.000 (99.157)\n",
            "Epoch: [62][110/329], lr: 0.01000\tTime 0.075 (0.097)\tData 0.000 (0.012)\tLoss 2.1550 (2.0243)\tPrec@1 88.281 (89.615)\tPrec@5 99.609 (99.201)\n",
            "Epoch: [62][120/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.012 (0.012)\tLoss 2.1097 (2.0174)\tPrec@1 89.453 (89.634)\tPrec@5 100.000 (99.232)\n",
            "Epoch: [62][130/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.012 (0.012)\tLoss 1.6505 (1.9979)\tPrec@1 90.234 (89.689)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [62][140/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.007 (0.011)\tLoss 1.6321 (1.9964)\tPrec@1 92.969 (89.689)\tPrec@5 98.828 (99.263)\n",
            "Epoch: [62][150/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.014 (0.011)\tLoss 1.3303 (1.9759)\tPrec@1 93.359 (89.810)\tPrec@5 99.609 (99.281)\n",
            "Epoch: [62][160/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.005 (0.011)\tLoss 1.2632 (1.9560)\tPrec@1 94.141 (89.924)\tPrec@5 98.828 (99.287)\n",
            "Epoch: [62][170/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.007 (0.011)\tLoss 1.7888 (1.9424)\tPrec@1 89.844 (89.985)\tPrec@5 98.828 (99.292)\n",
            "Epoch: [62][180/329], lr: 0.01000\tTime 0.089 (0.095)\tData 0.009 (0.011)\tLoss 1.4435 (1.9360)\tPrec@1 92.578 (90.008)\tPrec@5 99.609 (99.316)\n",
            "Epoch: [62][190/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.007 (0.010)\tLoss 1.7371 (1.9323)\tPrec@1 91.797 (90.022)\tPrec@5 100.000 (99.325)\n",
            "Epoch: [62][200/329], lr: 0.01000\tTime 0.096 (0.094)\tData 0.005 (0.010)\tLoss 1.5915 (1.9192)\tPrec@1 91.016 (90.089)\tPrec@5 100.000 (99.335)\n",
            "Epoch: [62][210/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.007 (0.010)\tLoss 1.8940 (1.9137)\tPrec@1 87.891 (90.086)\tPrec@5 99.609 (99.335)\n",
            "Epoch: [62][220/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.000 (0.010)\tLoss 1.4705 (1.9013)\tPrec@1 92.969 (90.171)\tPrec@5 98.828 (99.342)\n",
            "Epoch: [62][230/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.005 (0.010)\tLoss 1.8187 (1.8947)\tPrec@1 89.844 (90.211)\tPrec@5 99.219 (99.342)\n",
            "Epoch: [62][240/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 1.8331 (1.8879)\tPrec@1 90.234 (90.234)\tPrec@5 98.828 (99.344)\n",
            "Epoch: [62][250/329], lr: 0.01000\tTime 0.106 (0.093)\tData 0.012 (0.009)\tLoss 1.8016 (1.8853)\tPrec@1 90.625 (90.222)\tPrec@5 99.609 (99.348)\n",
            "Epoch: [62][260/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.009)\tLoss 1.5809 (1.8766)\tPrec@1 91.016 (90.266)\tPrec@5 99.219 (99.344)\n",
            "Epoch: [62][270/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.010 (0.009)\tLoss 2.0023 (1.8730)\tPrec@1 89.844 (90.291)\tPrec@5 100.000 (99.351)\n",
            "Epoch: [62][280/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.000 (0.009)\tLoss 2.0683 (1.8719)\tPrec@1 90.234 (90.301)\tPrec@5 99.609 (99.361)\n",
            "Epoch: [62][290/329], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.009)\tLoss 1.4289 (1.8679)\tPrec@1 92.969 (90.334)\tPrec@5 99.609 (99.365)\n",
            "Epoch: [62][300/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.009)\tLoss 1.8196 (1.8635)\tPrec@1 89.453 (90.355)\tPrec@5 99.219 (99.364)\n",
            "Epoch: [62][310/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.000 (0.009)\tLoss 1.5423 (1.8596)\tPrec@1 93.359 (90.394)\tPrec@5 99.609 (99.368)\n",
            "Epoch: [62][320/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.040 (0.009)\tLoss 1.7229 (1.8652)\tPrec@1 91.797 (90.360)\tPrec@5 99.219 (99.368)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 5.9406 (5.9406)\tPrec@1 75.000 (75.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.030 (0.056)\tLoss 5.0231 (5.8214)\tPrec@1 76.000 (74.727)\tPrec@5 99.000 (96.727)\n",
            "Test: [20/100]\tTime 0.035 (0.041)\tLoss 5.0585 (5.6837)\tPrec@1 75.000 (74.190)\tPrec@5 99.000 (97.048)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 5.8037 (5.7713)\tPrec@1 73.000 (73.645)\tPrec@5 97.000 (96.968)\n",
            "Test: [40/100]\tTime 0.014 (0.032)\tLoss 5.3751 (5.7591)\tPrec@1 79.000 (74.049)\tPrec@5 98.000 (96.951)\n",
            "Test: [50/100]\tTime 0.044 (0.031)\tLoss 5.9641 (5.7318)\tPrec@1 73.000 (74.157)\tPrec@5 93.000 (96.980)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 4.7530 (5.7751)\tPrec@1 78.000 (73.836)\tPrec@5 98.000 (97.115)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 5.6844 (5.7833)\tPrec@1 76.000 (73.761)\tPrec@5 97.000 (97.056)\n",
            "Test: [80/100]\tTime 0.040 (0.029)\tLoss 5.9199 (5.7379)\tPrec@1 72.000 (74.049)\tPrec@5 96.000 (97.136)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 6.1632 (5.7941)\tPrec@1 74.000 (73.747)\tPrec@5 100.000 (97.154)\n",
            "val Results: Prec@1 73.920 Prec@5 97.130 Loss 5.79034\n",
            "val Class Accuracy: [0.748,0.947,0.833,0.713,0.659,0.845,0.764,0.656,0.607,0.620]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [63][0/329], lr: 0.01000\tTime 0.625 (0.625)\tData 0.557 (0.557)\tLoss 1.9216 (1.9216)\tPrec@1 90.625 (90.625)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [63][10/329], lr: 0.01000\tTime 0.109 (0.152)\tData 0.002 (0.055)\tLoss 2.4315 (2.3071)\tPrec@1 87.109 (88.281)\tPrec@5 99.609 (99.183)\n",
            "Epoch: [63][20/329], lr: 0.01000\tTime 0.096 (0.124)\tData 0.007 (0.032)\tLoss 2.2386 (2.1526)\tPrec@1 86.328 (88.746)\tPrec@5 99.219 (99.107)\n",
            "Epoch: [63][30/329], lr: 0.01000\tTime 0.089 (0.113)\tData 0.000 (0.024)\tLoss 1.9989 (2.0924)\tPrec@1 89.453 (89.075)\tPrec@5 99.219 (99.093)\n",
            "Epoch: [63][40/329], lr: 0.01000\tTime 0.104 (0.115)\tData 0.000 (0.020)\tLoss 1.8132 (2.0335)\tPrec@1 90.625 (89.415)\tPrec@5 99.609 (99.181)\n",
            "Epoch: [63][50/329], lr: 0.01000\tTime 0.121 (0.116)\tData 0.000 (0.017)\tLoss 1.8189 (2.0230)\tPrec@1 89.844 (89.476)\tPrec@5 99.609 (99.188)\n",
            "Epoch: [63][60/329], lr: 0.01000\tTime 0.116 (0.118)\tData 0.010 (0.015)\tLoss 1.4451 (1.9934)\tPrec@1 92.188 (89.652)\tPrec@5 98.828 (99.180)\n",
            "Epoch: [63][70/329], lr: 0.01000\tTime 0.085 (0.118)\tData 0.000 (0.015)\tLoss 1.7734 (1.9819)\tPrec@1 90.625 (89.728)\tPrec@5 98.828 (99.197)\n",
            "Epoch: [63][80/329], lr: 0.01000\tTime 0.088 (0.115)\tData 0.000 (0.014)\tLoss 1.9072 (1.9687)\tPrec@1 90.234 (89.791)\tPrec@5 99.219 (99.248)\n",
            "Epoch: [63][90/329], lr: 0.01000\tTime 0.092 (0.113)\tData 0.005 (0.013)\tLoss 1.4130 (1.9320)\tPrec@1 92.578 (89.981)\tPrec@5 98.828 (99.275)\n",
            "Epoch: [63][100/329], lr: 0.01000\tTime 0.082 (0.111)\tData 0.000 (0.012)\tLoss 1.9530 (1.9137)\tPrec@1 89.453 (90.103)\tPrec@5 98.828 (99.288)\n",
            "Epoch: [63][110/329], lr: 0.01000\tTime 0.077 (0.109)\tData 0.000 (0.012)\tLoss 2.1851 (1.9196)\tPrec@1 89.062 (90.094)\tPrec@5 98.828 (99.303)\n",
            "Epoch: [63][120/329], lr: 0.01000\tTime 0.104 (0.108)\tData 0.005 (0.011)\tLoss 1.4056 (1.9066)\tPrec@1 92.969 (90.189)\tPrec@5 99.609 (99.319)\n",
            "Epoch: [63][130/329], lr: 0.01000\tTime 0.072 (0.107)\tData 0.000 (0.011)\tLoss 1.4141 (1.8799)\tPrec@1 93.359 (90.336)\tPrec@5 99.609 (99.338)\n",
            "Epoch: [63][140/329], lr: 0.01000\tTime 0.086 (0.106)\tData 0.005 (0.011)\tLoss 2.0132 (1.8937)\tPrec@1 89.844 (90.259)\tPrec@5 99.609 (99.330)\n",
            "Epoch: [63][150/329], lr: 0.01000\tTime 0.088 (0.105)\tData 0.011 (0.010)\tLoss 1.9603 (1.8792)\tPrec@1 91.016 (90.328)\tPrec@5 99.219 (99.351)\n",
            "Epoch: [63][160/329], lr: 0.01000\tTime 0.077 (0.104)\tData 0.012 (0.010)\tLoss 2.1111 (1.8695)\tPrec@1 88.281 (90.370)\tPrec@5 99.219 (99.357)\n",
            "Epoch: [63][170/329], lr: 0.01000\tTime 0.083 (0.103)\tData 0.005 (0.010)\tLoss 1.9088 (1.8608)\tPrec@1 90.625 (90.406)\tPrec@5 99.219 (99.356)\n",
            "Epoch: [63][180/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.000 (0.010)\tLoss 2.1065 (1.8585)\tPrec@1 89.062 (90.416)\tPrec@5 99.219 (99.355)\n",
            "Epoch: [63][190/329], lr: 0.01000\tTime 0.088 (0.102)\tData 0.011 (0.010)\tLoss 1.8784 (1.8573)\tPrec@1 90.234 (90.418)\tPrec@5 99.219 (99.358)\n",
            "Epoch: [63][200/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.004 (0.010)\tLoss 1.6636 (1.8507)\tPrec@1 90.234 (90.446)\tPrec@5 99.609 (99.366)\n",
            "Epoch: [63][210/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.007 (0.010)\tLoss 1.7343 (1.8476)\tPrec@1 91.016 (90.464)\tPrec@5 100.000 (99.367)\n",
            "Epoch: [63][220/329], lr: 0.01000\tTime 0.058 (0.100)\tData 0.001 (0.009)\tLoss 2.1502 (1.8410)\tPrec@1 87.500 (90.512)\tPrec@5 98.828 (99.364)\n",
            "Epoch: [63][230/329], lr: 0.01000\tTime 0.074 (0.100)\tData 0.004 (0.009)\tLoss 1.7219 (1.8296)\tPrec@1 90.625 (90.573)\tPrec@5 99.609 (99.369)\n",
            "Epoch: [63][240/329], lr: 0.01000\tTime 0.111 (0.099)\tData 0.007 (0.009)\tLoss 2.5784 (1.8263)\tPrec@1 85.938 (90.583)\tPrec@5 99.609 (99.378)\n",
            "Epoch: [63][250/329], lr: 0.01000\tTime 0.098 (0.099)\tData 0.006 (0.009)\tLoss 1.9443 (1.8305)\tPrec@1 90.625 (90.563)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [63][260/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.011 (0.009)\tLoss 1.9449 (1.8348)\tPrec@1 90.625 (90.547)\tPrec@5 99.609 (99.380)\n",
            "Epoch: [63][270/329], lr: 0.01000\tTime 0.070 (0.098)\tData 0.009 (0.009)\tLoss 1.9031 (1.8303)\tPrec@1 90.234 (90.577)\tPrec@5 99.219 (99.380)\n",
            "Epoch: [63][280/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.016 (0.009)\tLoss 1.4760 (1.8253)\tPrec@1 92.188 (90.601)\tPrec@5 99.219 (99.379)\n",
            "Epoch: [63][290/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.009 (0.009)\tLoss 1.7587 (1.8213)\tPrec@1 91.016 (90.613)\tPrec@5 99.609 (99.384)\n",
            "Epoch: [63][300/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.008 (0.009)\tLoss 1.6636 (1.8202)\tPrec@1 91.406 (90.616)\tPrec@5 99.609 (99.389)\n",
            "Epoch: [63][310/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.005 (0.009)\tLoss 2.2274 (1.8256)\tPrec@1 88.281 (90.572)\tPrec@5 99.219 (99.392)\n",
            "Epoch: [63][320/329], lr: 0.01000\tTime 0.107 (0.097)\tData 0.070 (0.009)\tLoss 1.7430 (1.8261)\tPrec@1 91.797 (90.576)\tPrec@5 99.219 (99.388)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 7.3641 (7.3641)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.021 (0.053)\tLoss 6.7007 (7.7483)\tPrec@1 70.000 (65.273)\tPrec@5 92.000 (95.364)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 6.2381 (7.6265)\tPrec@1 71.000 (65.857)\tPrec@5 98.000 (96.476)\n",
            "Test: [30/100]\tTime 0.020 (0.035)\tLoss 8.3240 (7.7417)\tPrec@1 63.000 (65.419)\tPrec@5 95.000 (96.161)\n",
            "Test: [40/100]\tTime 0.036 (0.032)\tLoss 7.5815 (7.7313)\tPrec@1 64.000 (65.561)\tPrec@5 97.000 (96.098)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 8.2333 (7.6330)\tPrec@1 67.000 (66.059)\tPrec@5 95.000 (96.235)\n",
            "Test: [60/100]\tTime 0.052 (0.030)\tLoss 6.4853 (7.6904)\tPrec@1 71.000 (65.820)\tPrec@5 96.000 (96.246)\n",
            "Test: [70/100]\tTime 0.015 (0.029)\tLoss 7.3833 (7.6823)\tPrec@1 63.000 (65.859)\tPrec@5 100.000 (96.169)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 6.7287 (7.6203)\tPrec@1 73.000 (66.074)\tPrec@5 96.000 (96.185)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 8.7612 (7.7187)\tPrec@1 61.000 (65.626)\tPrec@5 96.000 (96.121)\n",
            "val Results: Prec@1 65.770 Prec@5 96.060 Loss 7.70310\n",
            "val Class Accuracy: [0.832,0.923,0.747,0.877,0.524,0.657,0.339,0.612,0.564,0.502]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [64][0/329], lr: 0.01000\tTime 0.628 (0.628)\tData 0.534 (0.534)\tLoss 2.2451 (2.2451)\tPrec@1 88.281 (88.281)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [64][10/329], lr: 0.01000\tTime 0.102 (0.145)\tData 0.009 (0.054)\tLoss 2.4337 (2.5854)\tPrec@1 87.891 (85.938)\tPrec@5 98.438 (98.722)\n",
            "Epoch: [64][20/329], lr: 0.01000\tTime 0.096 (0.120)\tData 0.004 (0.029)\tLoss 2.2932 (2.5358)\tPrec@1 87.891 (86.421)\tPrec@5 98.438 (98.828)\n",
            "Epoch: [64][30/329], lr: 0.01000\tTime 0.089 (0.110)\tData 0.000 (0.022)\tLoss 1.4082 (2.3862)\tPrec@1 93.750 (87.437)\tPrec@5 99.609 (98.954)\n",
            "Epoch: [64][40/329], lr: 0.01000\tTime 0.103 (0.104)\tData 0.015 (0.019)\tLoss 1.6207 (2.2907)\tPrec@1 91.016 (87.872)\tPrec@5 99.609 (98.990)\n",
            "Epoch: [64][50/329], lr: 0.01000\tTime 0.110 (0.101)\tData 0.009 (0.016)\tLoss 1.9950 (2.2130)\tPrec@1 89.844 (88.335)\tPrec@5 99.219 (99.081)\n",
            "Epoch: [64][60/329], lr: 0.01000\tTime 0.104 (0.099)\tData 0.012 (0.015)\tLoss 1.9005 (2.1568)\tPrec@1 91.016 (88.659)\tPrec@5 99.219 (99.116)\n",
            "Epoch: [64][70/329], lr: 0.01000\tTime 0.078 (0.097)\tData 0.008 (0.014)\tLoss 2.3770 (2.1435)\tPrec@1 87.891 (88.771)\tPrec@5 98.828 (99.147)\n",
            "Epoch: [64][80/329], lr: 0.01000\tTime 0.070 (0.095)\tData 0.000 (0.013)\tLoss 1.9064 (2.1084)\tPrec@1 91.797 (89.009)\tPrec@5 99.609 (99.195)\n",
            "Epoch: [64][90/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.005 (0.012)\tLoss 2.2684 (2.0976)\tPrec@1 89.453 (89.093)\tPrec@5 99.609 (99.202)\n",
            "Epoch: [64][100/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.007 (0.012)\tLoss 2.2763 (2.0902)\tPrec@1 89.844 (89.124)\tPrec@5 98.828 (99.226)\n",
            "Epoch: [64][110/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.001 (0.012)\tLoss 1.6725 (2.0547)\tPrec@1 90.234 (89.323)\tPrec@5 99.219 (99.272)\n",
            "Epoch: [64][120/329], lr: 0.01000\tTime 0.130 (0.094)\tData 0.009 (0.011)\tLoss 1.2478 (2.0232)\tPrec@1 92.578 (89.492)\tPrec@5 99.609 (99.280)\n",
            "Epoch: [64][130/329], lr: 0.01000\tTime 0.120 (0.096)\tData 0.000 (0.011)\tLoss 1.5504 (2.0076)\tPrec@1 92.188 (89.563)\tPrec@5 100.000 (99.293)\n",
            "Epoch: [64][140/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.000 (0.010)\tLoss 1.4298 (1.9834)\tPrec@1 93.359 (89.672)\tPrec@5 100.000 (99.316)\n",
            "Epoch: [64][150/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.034 (0.011)\tLoss 1.7083 (1.9702)\tPrec@1 90.234 (89.730)\tPrec@5 99.219 (99.312)\n",
            "Epoch: [64][160/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.004 (0.012)\tLoss 1.9799 (1.9623)\tPrec@1 90.625 (89.769)\tPrec@5 99.609 (99.333)\n",
            "Epoch: [64][170/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.005 (0.012)\tLoss 2.1592 (1.9608)\tPrec@1 88.672 (89.757)\tPrec@5 100.000 (99.349)\n",
            "Epoch: [64][180/329], lr: 0.01000\tTime 0.112 (0.099)\tData 0.003 (0.012)\tLoss 1.6560 (1.9515)\tPrec@1 92.188 (89.807)\tPrec@5 99.219 (99.344)\n",
            "Epoch: [64][190/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.000 (0.011)\tLoss 2.1533 (1.9459)\tPrec@1 89.062 (89.840)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [64][200/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.004 (0.011)\tLoss 2.1561 (1.9390)\tPrec@1 90.625 (89.890)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [64][210/329], lr: 0.01000\tTime 0.072 (0.098)\tData 0.000 (0.011)\tLoss 1.3977 (1.9259)\tPrec@1 92.578 (89.959)\tPrec@5 98.438 (99.345)\n",
            "Epoch: [64][220/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.000 (0.011)\tLoss 1.7958 (1.9257)\tPrec@1 91.797 (89.971)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [64][230/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.000 (0.010)\tLoss 2.1757 (1.9228)\tPrec@1 89.062 (90.001)\tPrec@5 99.219 (99.337)\n",
            "Epoch: [64][240/329], lr: 0.01000\tTime 0.073 (0.097)\tData 0.000 (0.010)\tLoss 2.1169 (1.9176)\tPrec@1 89.453 (90.046)\tPrec@5 99.609 (99.345)\n",
            "Epoch: [64][250/329], lr: 0.01000\tTime 0.112 (0.097)\tData 0.006 (0.010)\tLoss 2.2121 (1.9152)\tPrec@1 88.672 (90.051)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [64][260/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.012 (0.010)\tLoss 1.9583 (1.9039)\tPrec@1 90.625 (90.127)\tPrec@5 99.219 (99.346)\n",
            "Epoch: [64][270/329], lr: 0.01000\tTime 0.097 (0.096)\tData 0.003 (0.010)\tLoss 1.5269 (1.8981)\tPrec@1 93.359 (90.171)\tPrec@5 99.219 (99.350)\n",
            "Epoch: [64][280/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.011 (0.010)\tLoss 1.6367 (1.8953)\tPrec@1 92.188 (90.180)\tPrec@5 99.219 (99.345)\n",
            "Epoch: [64][290/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.010)\tLoss 1.7383 (1.9009)\tPrec@1 92.578 (90.157)\tPrec@5 100.000 (99.348)\n",
            "Epoch: [64][300/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.010)\tLoss 1.8119 (1.8986)\tPrec@1 92.188 (90.167)\tPrec@5 99.219 (99.337)\n",
            "Epoch: [64][310/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.000 (0.009)\tLoss 1.9116 (1.8951)\tPrec@1 89.844 (90.189)\tPrec@5 100.000 (99.343)\n",
            "Epoch: [64][320/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.035 (0.010)\tLoss 1.8748 (1.8958)\tPrec@1 89.844 (90.194)\tPrec@5 99.609 (99.340)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 6.2085 (6.2085)\tPrec@1 73.000 (73.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.016 (0.053)\tLoss 4.9621 (6.2442)\tPrec@1 77.000 (72.273)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 4.8593 (6.2368)\tPrec@1 77.000 (71.810)\tPrec@5 96.000 (96.476)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 6.1709 (6.3189)\tPrec@1 70.000 (71.774)\tPrec@5 92.000 (96.226)\n",
            "Test: [40/100]\tTime 0.026 (0.032)\tLoss 6.4265 (6.3158)\tPrec@1 72.000 (71.610)\tPrec@5 93.000 (96.463)\n",
            "Test: [50/100]\tTime 0.033 (0.030)\tLoss 5.7499 (6.2332)\tPrec@1 73.000 (71.882)\tPrec@5 92.000 (96.412)\n",
            "Test: [60/100]\tTime 0.037 (0.029)\tLoss 5.2590 (6.2450)\tPrec@1 77.000 (71.836)\tPrec@5 97.000 (96.328)\n",
            "Test: [70/100]\tTime 0.037 (0.028)\tLoss 5.6527 (6.2364)\tPrec@1 71.000 (71.718)\tPrec@5 97.000 (96.380)\n",
            "Test: [80/100]\tTime 0.032 (0.028)\tLoss 5.4995 (6.1821)\tPrec@1 74.000 (71.914)\tPrec@5 97.000 (96.469)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 6.9432 (6.2506)\tPrec@1 67.000 (71.615)\tPrec@5 100.000 (96.418)\n",
            "val Results: Prec@1 71.570 Prec@5 96.420 Loss 6.28490\n",
            "val Class Accuracy: [0.964,0.997,0.675,0.700,0.786,0.566,0.774,0.514,0.606,0.575]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [65][0/329], lr: 0.01000\tTime 0.569 (0.569)\tData 0.506 (0.506)\tLoss 2.2462 (2.2462)\tPrec@1 87.500 (87.500)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [65][10/329], lr: 0.01000\tTime 0.099 (0.136)\tData 0.004 (0.052)\tLoss 2.2075 (2.5939)\tPrec@1 88.672 (86.754)\tPrec@5 99.609 (98.509)\n",
            "Epoch: [65][20/329], lr: 0.01000\tTime 0.100 (0.116)\tData 0.004 (0.029)\tLoss 2.0022 (2.4650)\tPrec@1 90.625 (87.109)\tPrec@5 98.438 (98.475)\n",
            "Epoch: [65][30/329], lr: 0.01000\tTime 0.127 (0.109)\tData 0.006 (0.022)\tLoss 2.9847 (2.3772)\tPrec@1 85.547 (87.639)\tPrec@5 96.875 (98.614)\n",
            "Epoch: [65][40/329], lr: 0.01000\tTime 0.084 (0.104)\tData 0.007 (0.019)\tLoss 1.8139 (2.2348)\tPrec@1 89.844 (88.300)\tPrec@5 99.219 (98.790)\n",
            "Epoch: [65][50/329], lr: 0.01000\tTime 0.105 (0.102)\tData 0.004 (0.016)\tLoss 1.8956 (2.1534)\tPrec@1 90.625 (88.710)\tPrec@5 99.219 (98.905)\n",
            "Epoch: [65][60/329], lr: 0.01000\tTime 0.068 (0.099)\tData 0.000 (0.014)\tLoss 1.5943 (2.0736)\tPrec@1 91.797 (89.146)\tPrec@5 99.219 (99.001)\n",
            "Epoch: [65][70/329], lr: 0.01000\tTime 0.109 (0.098)\tData 0.000 (0.013)\tLoss 1.9718 (2.0208)\tPrec@1 89.844 (89.426)\tPrec@5 98.828 (99.054)\n",
            "Epoch: [65][80/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.012 (0.013)\tLoss 1.2849 (1.9891)\tPrec@1 92.969 (89.603)\tPrec@5 99.609 (99.113)\n",
            "Epoch: [65][90/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.000 (0.012)\tLoss 2.0090 (1.9765)\tPrec@1 90.234 (89.689)\tPrec@5 98.438 (99.133)\n",
            "Epoch: [65][100/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.007 (0.011)\tLoss 1.9478 (1.9657)\tPrec@1 90.625 (89.751)\tPrec@5 98.828 (99.157)\n",
            "Epoch: [65][110/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.009 (0.011)\tLoss 1.4393 (1.9390)\tPrec@1 92.188 (89.907)\tPrec@5 98.828 (99.159)\n",
            "Epoch: [65][120/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.004 (0.010)\tLoss 1.4452 (1.9320)\tPrec@1 91.797 (89.960)\tPrec@5 99.219 (99.193)\n",
            "Epoch: [65][130/329], lr: 0.01000\tTime 0.133 (0.094)\tData 0.004 (0.010)\tLoss 2.0285 (1.9140)\tPrec@1 88.672 (90.041)\tPrec@5 99.609 (99.210)\n",
            "Epoch: [65][140/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.003 (0.010)\tLoss 2.0725 (1.9036)\tPrec@1 87.891 (90.076)\tPrec@5 99.219 (99.230)\n",
            "Epoch: [65][150/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.007 (0.009)\tLoss 1.8595 (1.8953)\tPrec@1 91.016 (90.136)\tPrec@5 100.000 (99.237)\n",
            "Epoch: [65][160/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.006 (0.009)\tLoss 1.6812 (1.8930)\tPrec@1 91.016 (90.164)\tPrec@5 100.000 (99.253)\n",
            "Epoch: [65][170/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.012 (0.009)\tLoss 1.4393 (1.8818)\tPrec@1 93.359 (90.234)\tPrec@5 100.000 (99.262)\n",
            "Epoch: [65][180/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.001 (0.009)\tLoss 1.9052 (1.8655)\tPrec@1 90.625 (90.319)\tPrec@5 100.000 (99.275)\n",
            "Epoch: [65][190/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.009)\tLoss 1.7827 (1.8690)\tPrec@1 91.406 (90.312)\tPrec@5 100.000 (99.292)\n",
            "Epoch: [65][200/329], lr: 0.01000\tTime 0.086 (0.092)\tData 0.006 (0.009)\tLoss 1.7025 (1.8687)\tPrec@1 91.016 (90.308)\tPrec@5 100.000 (99.300)\n",
            "Epoch: [65][210/329], lr: 0.01000\tTime 0.110 (0.092)\tData 0.002 (0.009)\tLoss 1.4097 (1.8630)\tPrec@1 92.969 (90.349)\tPrec@5 99.609 (99.311)\n",
            "Epoch: [65][220/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.009 (0.008)\tLoss 1.7561 (1.8555)\tPrec@1 90.234 (90.390)\tPrec@5 98.828 (99.325)\n",
            "Epoch: [65][230/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.000 (0.008)\tLoss 2.1069 (1.8590)\tPrec@1 89.453 (90.373)\tPrec@5 98.828 (99.319)\n",
            "Epoch: [65][240/329], lr: 0.01000\tTime 0.139 (0.094)\tData 0.000 (0.008)\tLoss 1.5504 (1.8598)\tPrec@1 92.969 (90.383)\tPrec@5 99.609 (99.322)\n",
            "Epoch: [65][250/329], lr: 0.01000\tTime 0.120 (0.095)\tData 0.014 (0.009)\tLoss 1.7080 (1.8533)\tPrec@1 91.797 (90.434)\tPrec@5 100.000 (99.329)\n",
            "Epoch: [65][260/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.005 (0.009)\tLoss 1.5135 (1.8491)\tPrec@1 92.578 (90.456)\tPrec@5 98.828 (99.335)\n",
            "Epoch: [65][270/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.005 (0.009)\tLoss 2.0213 (1.8459)\tPrec@1 90.234 (90.469)\tPrec@5 98.828 (99.338)\n",
            "Epoch: [65][280/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.002 (0.009)\tLoss 1.6891 (1.8426)\tPrec@1 91.016 (90.479)\tPrec@5 100.000 (99.344)\n",
            "Epoch: [65][290/329], lr: 0.01000\tTime 0.109 (0.096)\tData 0.002 (0.009)\tLoss 2.0803 (1.8470)\tPrec@1 88.281 (90.468)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [65][300/329], lr: 0.01000\tTime 0.073 (0.096)\tData 0.005 (0.009)\tLoss 2.2148 (1.8409)\tPrec@1 88.672 (90.499)\tPrec@5 99.609 (99.362)\n",
            "Epoch: [65][310/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.006 (0.009)\tLoss 1.8729 (1.8386)\tPrec@1 89.844 (90.521)\tPrec@5 100.000 (99.367)\n",
            "Epoch: [65][320/329], lr: 0.01000\tTime 0.110 (0.096)\tData 0.067 (0.009)\tLoss 1.6137 (1.8340)\tPrec@1 92.578 (90.556)\tPrec@5 99.219 (99.371)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 6.1827 (6.1827)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.022 (0.055)\tLoss 4.8150 (6.3125)\tPrec@1 78.000 (72.727)\tPrec@5 97.000 (97.000)\n",
            "Test: [20/100]\tTime 0.026 (0.040)\tLoss 5.5086 (6.2366)\tPrec@1 74.000 (72.524)\tPrec@5 97.000 (96.619)\n",
            "Test: [30/100]\tTime 0.020 (0.034)\tLoss 5.8895 (6.3276)\tPrec@1 75.000 (72.355)\tPrec@5 96.000 (96.516)\n",
            "Test: [40/100]\tTime 0.018 (0.032)\tLoss 6.8237 (6.4388)\tPrec@1 72.000 (71.756)\tPrec@5 94.000 (96.439)\n",
            "Test: [50/100]\tTime 0.025 (0.030)\tLoss 6.5200 (6.4001)\tPrec@1 72.000 (71.784)\tPrec@5 94.000 (96.451)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 5.9783 (6.4222)\tPrec@1 72.000 (71.574)\tPrec@5 97.000 (96.443)\n",
            "Test: [70/100]\tTime 0.028 (0.028)\tLoss 6.6849 (6.4349)\tPrec@1 70.000 (71.423)\tPrec@5 96.000 (96.394)\n",
            "Test: [80/100]\tTime 0.027 (0.028)\tLoss 6.3413 (6.4115)\tPrec@1 73.000 (71.494)\tPrec@5 97.000 (96.407)\n",
            "Test: [90/100]\tTime 0.021 (0.027)\tLoss 7.1794 (6.4483)\tPrec@1 65.000 (71.264)\tPrec@5 97.000 (96.308)\n",
            "val Results: Prec@1 71.200 Prec@5 96.260 Loss 6.47031\n",
            "val Class Accuracy: [0.966,0.939,0.719,0.744,0.819,0.311,0.879,0.604,0.802,0.337]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [66][0/329], lr: 0.01000\tTime 0.559 (0.559)\tData 0.472 (0.472)\tLoss 1.8600 (1.8600)\tPrec@1 92.188 (92.188)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [66][10/329], lr: 0.01000\tTime 0.086 (0.141)\tData 0.005 (0.048)\tLoss 2.0674 (1.9949)\tPrec@1 89.844 (89.986)\tPrec@5 99.219 (99.254)\n",
            "Epoch: [66][20/329], lr: 0.01000\tTime 0.103 (0.117)\tData 0.009 (0.028)\tLoss 1.4795 (2.0345)\tPrec@1 91.406 (89.453)\tPrec@5 98.828 (99.219)\n",
            "Epoch: [66][30/329], lr: 0.01000\tTime 0.092 (0.108)\tData 0.005 (0.021)\tLoss 2.2044 (1.9306)\tPrec@1 89.844 (90.008)\tPrec@5 99.219 (99.383)\n",
            "Epoch: [66][40/329], lr: 0.01000\tTime 0.088 (0.103)\tData 0.007 (0.017)\tLoss 1.5846 (1.9242)\tPrec@1 91.016 (89.987)\tPrec@5 99.219 (99.362)\n",
            "Epoch: [66][50/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.017 (0.015)\tLoss 1.4891 (1.9323)\tPrec@1 92.578 (89.959)\tPrec@5 98.828 (99.349)\n",
            "Epoch: [66][60/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.000 (0.013)\tLoss 1.7119 (1.9096)\tPrec@1 92.578 (90.036)\tPrec@5 98.438 (99.360)\n",
            "Epoch: [66][70/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.007 (0.012)\tLoss 1.9270 (1.8948)\tPrec@1 89.844 (90.102)\tPrec@5 98.828 (99.373)\n",
            "Epoch: [66][80/329], lr: 0.01000\tTime 0.073 (0.095)\tData 0.000 (0.011)\tLoss 1.7372 (1.8826)\tPrec@1 90.625 (90.225)\tPrec@5 98.438 (99.368)\n",
            "Epoch: [66][90/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.000 (0.011)\tLoss 1.5564 (1.8486)\tPrec@1 91.016 (90.402)\tPrec@5 99.609 (99.390)\n",
            "Epoch: [66][100/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.004 (0.010)\tLoss 1.5225 (1.8387)\tPrec@1 91.797 (90.416)\tPrec@5 100.000 (99.420)\n",
            "Epoch: [66][110/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.005 (0.010)\tLoss 1.6397 (1.8270)\tPrec@1 91.797 (90.495)\tPrec@5 100.000 (99.430)\n",
            "Epoch: [66][120/329], lr: 0.01000\tTime 0.105 (0.093)\tData 0.000 (0.010)\tLoss 1.3113 (1.8247)\tPrec@1 92.969 (90.493)\tPrec@5 100.000 (99.441)\n",
            "Epoch: [66][130/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.005 (0.009)\tLoss 2.0758 (1.8400)\tPrec@1 89.062 (90.413)\tPrec@5 98.828 (99.439)\n",
            "Epoch: [66][140/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.001 (0.009)\tLoss 1.8540 (1.8404)\tPrec@1 90.234 (90.434)\tPrec@5 99.609 (99.443)\n",
            "Epoch: [66][150/329], lr: 0.01000\tTime 0.064 (0.092)\tData 0.000 (0.009)\tLoss 1.9747 (1.8466)\tPrec@1 90.625 (90.400)\tPrec@5 99.219 (99.426)\n",
            "Epoch: [66][160/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.008 (0.009)\tLoss 2.0687 (1.8541)\tPrec@1 89.453 (90.341)\tPrec@5 98.438 (99.423)\n",
            "Epoch: [66][170/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.005 (0.009)\tLoss 2.5395 (1.8623)\tPrec@1 85.938 (90.323)\tPrec@5 99.219 (99.427)\n",
            "Epoch: [66][180/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.000 (0.009)\tLoss 1.5227 (1.8592)\tPrec@1 91.797 (90.355)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [66][190/329], lr: 0.01000\tTime 0.063 (0.091)\tData 0.000 (0.009)\tLoss 2.3058 (1.8582)\tPrec@1 88.672 (90.380)\tPrec@5 98.828 (99.431)\n",
            "Epoch: [66][200/329], lr: 0.01000\tTime 0.101 (0.091)\tData 0.000 (0.009)\tLoss 1.9939 (1.8578)\tPrec@1 88.281 (90.380)\tPrec@5 100.000 (99.438)\n",
            "Epoch: [66][210/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.007 (0.008)\tLoss 1.6957 (1.8531)\tPrec@1 91.406 (90.403)\tPrec@5 100.000 (99.437)\n",
            "Epoch: [66][220/329], lr: 0.01000\tTime 0.074 (0.091)\tData 0.006 (0.008)\tLoss 1.9710 (1.8528)\tPrec@1 89.453 (90.404)\tPrec@5 98.438 (99.434)\n",
            "Epoch: [66][230/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.006 (0.008)\tLoss 1.6905 (1.8485)\tPrec@1 92.188 (90.425)\tPrec@5 99.609 (99.442)\n",
            "Epoch: [66][240/329], lr: 0.01000\tTime 0.074 (0.090)\tData 0.000 (0.008)\tLoss 1.3142 (1.8454)\tPrec@1 94.531 (90.439)\tPrec@5 98.828 (99.436)\n",
            "Epoch: [66][250/329], lr: 0.01000\tTime 0.106 (0.090)\tData 0.000 (0.008)\tLoss 1.7105 (1.8369)\tPrec@1 93.359 (90.480)\tPrec@5 99.219 (99.448)\n",
            "Epoch: [66][260/329], lr: 0.01000\tTime 0.077 (0.090)\tData 0.007 (0.008)\tLoss 1.7416 (1.8275)\tPrec@1 89.844 (90.531)\tPrec@5 98.438 (99.443)\n",
            "Epoch: [66][270/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.000 (0.008)\tLoss 1.6940 (1.8195)\tPrec@1 91.406 (90.577)\tPrec@5 99.609 (99.446)\n",
            "Epoch: [66][280/329], lr: 0.01000\tTime 0.080 (0.090)\tData 0.000 (0.008)\tLoss 1.6016 (1.8238)\tPrec@1 91.016 (90.557)\tPrec@5 99.219 (99.441)\n",
            "Epoch: [66][290/329], lr: 0.01000\tTime 0.077 (0.090)\tData 0.002 (0.008)\tLoss 1.6351 (1.8189)\tPrec@1 91.016 (90.581)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [66][300/329], lr: 0.01000\tTime 0.084 (0.090)\tData 0.007 (0.008)\tLoss 1.5121 (1.8202)\tPrec@1 92.969 (90.578)\tPrec@5 99.219 (99.439)\n",
            "Epoch: [66][310/329], lr: 0.01000\tTime 0.105 (0.090)\tData 0.007 (0.008)\tLoss 1.7498 (1.8194)\tPrec@1 91.797 (90.592)\tPrec@5 99.219 (99.440)\n",
            "Epoch: [66][320/329], lr: 0.01000\tTime 0.107 (0.090)\tData 0.061 (0.008)\tLoss 2.1179 (1.8186)\tPrec@1 89.062 (90.593)\tPrec@5 98.828 (99.437)\n",
            "Test: [0/100]\tTime 0.350 (0.350)\tLoss 7.9185 (7.9185)\tPrec@1 63.000 (63.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.038 (0.064)\tLoss 6.4533 (7.7896)\tPrec@1 69.000 (63.455)\tPrec@5 97.000 (96.000)\n",
            "Test: [20/100]\tTime 0.042 (0.052)\tLoss 7.4118 (7.8723)\tPrec@1 65.000 (63.190)\tPrec@5 95.000 (95.095)\n",
            "Test: [30/100]\tTime 0.033 (0.048)\tLoss 7.5889 (7.8868)\tPrec@1 65.000 (63.323)\tPrec@5 94.000 (95.194)\n",
            "Test: [40/100]\tTime 0.047 (0.046)\tLoss 8.2864 (7.8612)\tPrec@1 60.000 (63.512)\tPrec@5 95.000 (95.171)\n",
            "Test: [50/100]\tTime 0.030 (0.045)\tLoss 7.3105 (7.7788)\tPrec@1 66.000 (64.078)\tPrec@5 93.000 (95.059)\n",
            "Test: [60/100]\tTime 0.043 (0.043)\tLoss 7.2135 (7.7696)\tPrec@1 65.000 (64.098)\tPrec@5 94.000 (94.869)\n",
            "Test: [70/100]\tTime 0.035 (0.043)\tLoss 7.1126 (7.7979)\tPrec@1 69.000 (63.930)\tPrec@5 94.000 (94.775)\n",
            "Test: [80/100]\tTime 0.041 (0.043)\tLoss 5.7326 (7.7326)\tPrec@1 75.000 (64.136)\tPrec@5 94.000 (94.864)\n",
            "Test: [90/100]\tTime 0.046 (0.042)\tLoss 7.0818 (7.7702)\tPrec@1 68.000 (63.978)\tPrec@5 92.000 (94.703)\n",
            "val Results: Prec@1 64.110 Prec@5 94.650 Loss 7.76010\n",
            "val Class Accuracy: [0.896,0.965,0.703,0.718,0.494,0.296,0.746,0.818,0.145,0.630]\n",
            "Best Prec@1: 75.570\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [67][0/329], lr: 0.01000\tTime 0.642 (0.642)\tData 0.555 (0.555)\tLoss 1.9618 (1.9618)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [67][10/329], lr: 0.01000\tTime 0.089 (0.151)\tData 0.007 (0.059)\tLoss 4.7211 (4.6705)\tPrec@1 71.875 (73.224)\tPrec@5 98.828 (94.709)\n",
            "Epoch: [67][20/329], lr: 0.01000\tTime 0.071 (0.125)\tData 0.008 (0.035)\tLoss 3.5123 (4.4819)\tPrec@1 82.031 (74.907)\tPrec@5 98.047 (95.852)\n",
            "Epoch: [67][30/329], lr: 0.01000\tTime 0.096 (0.114)\tData 0.000 (0.026)\tLoss 3.4822 (4.1571)\tPrec@1 79.688 (76.802)\tPrec@5 98.047 (96.459)\n",
            "Epoch: [67][40/329], lr: 0.01000\tTime 0.094 (0.108)\tData 0.000 (0.022)\tLoss 2.9984 (3.8737)\tPrec@1 84.375 (78.449)\tPrec@5 98.828 (97.037)\n",
            "Epoch: [67][50/329], lr: 0.01000\tTime 0.070 (0.104)\tData 0.007 (0.019)\tLoss 2.6055 (3.6310)\tPrec@1 85.938 (80.025)\tPrec@5 98.828 (97.396)\n",
            "Epoch: [67][60/329], lr: 0.01000\tTime 0.100 (0.102)\tData 0.008 (0.017)\tLoss 2.5495 (3.4423)\tPrec@1 84.766 (81.167)\tPrec@5 99.609 (97.682)\n",
            "Epoch: [67][70/329], lr: 0.01000\tTime 0.094 (0.100)\tData 0.011 (0.016)\tLoss 2.6307 (3.2949)\tPrec@1 86.328 (82.053)\tPrec@5 98.828 (97.909)\n",
            "Epoch: [67][80/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.007 (0.015)\tLoss 2.5203 (3.1856)\tPrec@1 86.719 (82.740)\tPrec@5 99.609 (98.008)\n",
            "Epoch: [67][90/329], lr: 0.01000\tTime 0.089 (0.098)\tData 0.007 (0.014)\tLoss 1.8825 (3.0804)\tPrec@1 88.281 (83.302)\tPrec@5 99.219 (98.124)\n",
            "Epoch: [67][100/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.000 (0.013)\tLoss 2.2944 (2.9985)\tPrec@1 85.938 (83.779)\tPrec@5 99.609 (98.252)\n",
            "Epoch: [67][110/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.003 (0.013)\tLoss 2.3306 (2.9112)\tPrec@1 89.062 (84.273)\tPrec@5 99.219 (98.346)\n",
            "Epoch: [67][120/329], lr: 0.01000\tTime 0.071 (0.096)\tData 0.000 (0.012)\tLoss 1.9101 (2.8510)\tPrec@1 90.234 (84.595)\tPrec@5 99.219 (98.425)\n",
            "Epoch: [67][130/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.015 (0.012)\tLoss 2.2158 (2.7986)\tPrec@1 89.453 (84.894)\tPrec@5 99.219 (98.467)\n",
            "Epoch: [67][140/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.011)\tLoss 1.2780 (2.7501)\tPrec@1 94.922 (85.181)\tPrec@5 100.000 (98.537)\n",
            "Epoch: [67][150/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.011)\tLoss 2.0924 (2.6999)\tPrec@1 90.234 (85.474)\tPrec@5 99.609 (98.588)\n",
            "Epoch: [67][160/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.007 (0.011)\tLoss 2.0325 (2.6636)\tPrec@1 91.016 (85.690)\tPrec@5 99.219 (98.629)\n",
            "Epoch: [67][170/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.004 (0.011)\tLoss 2.2350 (2.6245)\tPrec@1 87.109 (85.915)\tPrec@5 100.000 (98.675)\n",
            "Epoch: [67][180/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.009 (0.010)\tLoss 2.5290 (2.5908)\tPrec@1 87.109 (86.112)\tPrec@5 100.000 (98.712)\n",
            "Epoch: [67][190/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.005 (0.010)\tLoss 2.0057 (2.5586)\tPrec@1 89.844 (86.297)\tPrec@5 99.609 (98.752)\n",
            "Epoch: [67][200/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.003 (0.010)\tLoss 1.9756 (2.5288)\tPrec@1 91.016 (86.505)\tPrec@5 98.828 (98.781)\n",
            "Epoch: [67][210/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.007 (0.010)\tLoss 2.1552 (2.5029)\tPrec@1 88.281 (86.637)\tPrec@5 98.828 (98.810)\n",
            "Epoch: [67][220/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.010)\tLoss 2.1952 (2.4823)\tPrec@1 88.672 (86.777)\tPrec@5 100.000 (98.844)\n",
            "Epoch: [67][230/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.009 (0.010)\tLoss 2.1561 (2.4606)\tPrec@1 90.234 (86.893)\tPrec@5 99.219 (98.869)\n",
            "Epoch: [67][240/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.010)\tLoss 2.2565 (2.4537)\tPrec@1 86.719 (86.923)\tPrec@5 99.609 (98.872)\n",
            "Epoch: [67][250/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.007 (0.009)\tLoss 1.6220 (2.4336)\tPrec@1 92.188 (87.038)\tPrec@5 99.609 (98.892)\n",
            "Epoch: [67][260/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.007 (0.009)\tLoss 2.4214 (2.4191)\tPrec@1 88.281 (87.124)\tPrec@5 99.609 (98.906)\n",
            "Epoch: [67][270/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.006 (0.009)\tLoss 2.1111 (2.3951)\tPrec@1 89.062 (87.256)\tPrec@5 100.000 (98.932)\n",
            "Epoch: [67][280/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.002 (0.009)\tLoss 1.7062 (2.3814)\tPrec@1 90.625 (87.329)\tPrec@5 99.219 (98.942)\n",
            "Epoch: [67][290/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 1.7245 (2.3640)\tPrec@1 91.406 (87.437)\tPrec@5 99.609 (98.962)\n",
            "Epoch: [67][300/329], lr: 0.01000\tTime 0.070 (0.091)\tData 0.011 (0.009)\tLoss 1.9751 (2.3458)\tPrec@1 89.453 (87.555)\tPrec@5 99.609 (98.981)\n",
            "Epoch: [67][310/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.007 (0.009)\tLoss 1.6933 (2.3296)\tPrec@1 91.406 (87.652)\tPrec@5 99.219 (98.996)\n",
            "Epoch: [67][320/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.039 (0.009)\tLoss 2.3365 (2.3220)\tPrec@1 88.672 (87.698)\tPrec@5 99.219 (99.011)\n",
            "Test: [0/100]\tTime 0.290 (0.290)\tLoss 4.8396 (4.8396)\tPrec@1 80.000 (80.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.027 (0.055)\tLoss 4.6004 (4.7478)\tPrec@1 78.000 (78.364)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 4.2536 (4.7744)\tPrec@1 80.000 (77.762)\tPrec@5 99.000 (98.000)\n",
            "Test: [30/100]\tTime 0.012 (0.036)\tLoss 6.1281 (4.9760)\tPrec@1 69.000 (76.677)\tPrec@5 98.000 (97.935)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 4.6749 (4.9901)\tPrec@1 79.000 (76.463)\tPrec@5 98.000 (97.927)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 4.4823 (4.9617)\tPrec@1 80.000 (76.706)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.012 (0.030)\tLoss 4.9889 (5.0117)\tPrec@1 77.000 (76.426)\tPrec@5 99.000 (98.066)\n",
            "Test: [70/100]\tTime 0.070 (0.030)\tLoss 5.4230 (4.9998)\tPrec@1 76.000 (76.648)\tPrec@5 99.000 (98.099)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 3.7394 (4.9603)\tPrec@1 82.000 (76.728)\tPrec@5 98.000 (98.148)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 4.7392 (5.0235)\tPrec@1 77.000 (76.363)\tPrec@5 100.000 (98.143)\n",
            "val Results: Prec@1 76.380 Prec@5 98.100 Loss 5.02752\n",
            "val Class Accuracy: [0.962,0.921,0.682,0.634,0.820,0.754,0.853,0.673,0.521,0.818]\n",
            "Best Prec@1: 76.380\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [68][0/329], lr: 0.01000\tTime 0.637 (0.637)\tData 0.549 (0.549)\tLoss 2.3203 (2.3203)\tPrec@1 87.109 (87.109)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [68][10/329], lr: 0.01000\tTime 0.085 (0.147)\tData 0.000 (0.055)\tLoss 2.3479 (2.1590)\tPrec@1 88.672 (88.885)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [68][20/329], lr: 0.01000\tTime 0.092 (0.122)\tData 0.000 (0.032)\tLoss 2.2553 (2.1319)\tPrec@1 87.500 (88.802)\tPrec@5 99.219 (99.144)\n",
            "Epoch: [68][30/329], lr: 0.01000\tTime 0.082 (0.111)\tData 0.000 (0.023)\tLoss 2.0302 (2.0914)\tPrec@1 89.062 (89.126)\tPrec@5 100.000 (99.143)\n",
            "Epoch: [68][40/329], lr: 0.01000\tTime 0.075 (0.106)\tData 0.015 (0.019)\tLoss 2.2545 (2.0847)\tPrec@1 88.281 (89.186)\tPrec@5 98.828 (99.200)\n",
            "Epoch: [68][50/329], lr: 0.01000\tTime 0.117 (0.104)\tData 0.017 (0.017)\tLoss 1.2808 (2.0225)\tPrec@1 94.531 (89.514)\tPrec@5 100.000 (99.280)\n",
            "Epoch: [68][60/329], lr: 0.01000\tTime 0.102 (0.105)\tData 0.001 (0.015)\tLoss 1.6864 (1.9798)\tPrec@1 90.234 (89.684)\tPrec@5 99.609 (99.321)\n",
            "Epoch: [68][70/329], lr: 0.01000\tTime 0.106 (0.107)\tData 0.005 (0.016)\tLoss 2.7291 (1.9701)\tPrec@1 86.328 (89.712)\tPrec@5 100.000 (99.373)\n",
            "Epoch: [68][80/329], lr: 0.01000\tTime 0.113 (0.109)\tData 0.032 (0.018)\tLoss 1.4760 (1.9545)\tPrec@1 92.969 (89.810)\tPrec@5 100.000 (99.407)\n",
            "Epoch: [68][90/329], lr: 0.01000\tTime 0.084 (0.109)\tData 0.000 (0.017)\tLoss 2.0037 (1.9556)\tPrec@1 88.672 (89.818)\tPrec@5 99.609 (99.421)\n",
            "Epoch: [68][100/329], lr: 0.01000\tTime 0.091 (0.107)\tData 0.000 (0.015)\tLoss 1.8251 (1.9445)\tPrec@1 92.578 (89.851)\tPrec@5 99.609 (99.408)\n",
            "Epoch: [68][110/329], lr: 0.01000\tTime 0.101 (0.106)\tData 0.000 (0.014)\tLoss 1.9196 (1.9475)\tPrec@1 89.844 (89.833)\tPrec@5 99.219 (99.402)\n",
            "Epoch: [68][120/329], lr: 0.01000\tTime 0.101 (0.105)\tData 0.003 (0.014)\tLoss 1.6868 (1.9302)\tPrec@1 91.797 (89.950)\tPrec@5 100.000 (99.406)\n",
            "Epoch: [68][130/329], lr: 0.01000\tTime 0.106 (0.104)\tData 0.000 (0.013)\tLoss 1.8222 (1.9287)\tPrec@1 89.453 (89.951)\tPrec@5 99.609 (99.407)\n",
            "Epoch: [68][140/329], lr: 0.01000\tTime 0.107 (0.103)\tData 0.006 (0.013)\tLoss 1.9082 (1.9218)\tPrec@1 91.406 (90.010)\tPrec@5 99.609 (99.410)\n",
            "Epoch: [68][150/329], lr: 0.01000\tTime 0.108 (0.102)\tData 0.008 (0.012)\tLoss 2.0396 (1.9200)\tPrec@1 90.234 (90.030)\tPrec@5 99.219 (99.418)\n",
            "Epoch: [68][160/329], lr: 0.01000\tTime 0.080 (0.101)\tData 0.000 (0.012)\tLoss 1.5351 (1.9139)\tPrec@1 92.969 (90.072)\tPrec@5 99.609 (99.425)\n",
            "Epoch: [68][170/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.007 (0.011)\tLoss 1.4234 (1.9109)\tPrec@1 92.969 (90.077)\tPrec@5 99.219 (99.429)\n",
            "Epoch: [68][180/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.000 (0.011)\tLoss 1.6006 (1.9034)\tPrec@1 92.578 (90.137)\tPrec@5 99.609 (99.424)\n",
            "Epoch: [68][190/329], lr: 0.01000\tTime 0.073 (0.099)\tData 0.003 (0.011)\tLoss 1.6571 (1.8973)\tPrec@1 90.625 (90.177)\tPrec@5 99.219 (99.431)\n",
            "Epoch: [68][200/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.006 (0.011)\tLoss 2.4946 (1.8933)\tPrec@1 89.453 (90.213)\tPrec@5 99.609 (99.434)\n",
            "Epoch: [68][210/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.008 (0.010)\tLoss 1.8319 (1.9018)\tPrec@1 89.844 (90.173)\tPrec@5 98.438 (99.430)\n",
            "Epoch: [68][220/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.001 (0.010)\tLoss 1.8493 (1.8945)\tPrec@1 90.234 (90.229)\tPrec@5 99.609 (99.410)\n",
            "Epoch: [68][230/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.000 (0.010)\tLoss 2.0932 (1.8922)\tPrec@1 88.672 (90.231)\tPrec@5 100.000 (99.400)\n",
            "Epoch: [68][240/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.006 (0.010)\tLoss 1.6237 (1.8888)\tPrec@1 92.969 (90.252)\tPrec@5 99.219 (99.397)\n",
            "Epoch: [68][250/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.006 (0.010)\tLoss 2.0080 (1.8866)\tPrec@1 89.844 (90.272)\tPrec@5 99.609 (99.399)\n",
            "Epoch: [68][260/329], lr: 0.01000\tTime 0.117 (0.096)\tData 0.000 (0.010)\tLoss 1.3889 (1.8792)\tPrec@1 92.969 (90.311)\tPrec@5 98.828 (99.401)\n",
            "Epoch: [68][270/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.007 (0.010)\tLoss 1.6722 (1.8766)\tPrec@1 92.188 (90.324)\tPrec@5 99.219 (99.402)\n",
            "Epoch: [68][280/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.007 (0.009)\tLoss 1.9661 (1.8730)\tPrec@1 89.844 (90.346)\tPrec@5 99.219 (99.412)\n",
            "Epoch: [68][290/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.006 (0.009)\tLoss 1.7617 (1.8724)\tPrec@1 89.844 (90.346)\tPrec@5 99.609 (99.412)\n",
            "Epoch: [68][300/329], lr: 0.01000\tTime 0.118 (0.095)\tData 0.006 (0.009)\tLoss 2.0657 (1.8709)\tPrec@1 90.234 (90.349)\tPrec@5 99.609 (99.419)\n",
            "Epoch: [68][310/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.005 (0.009)\tLoss 1.3871 (1.8692)\tPrec@1 92.188 (90.354)\tPrec@5 100.000 (99.423)\n",
            "Epoch: [68][320/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.073 (0.009)\tLoss 1.9611 (1.8651)\tPrec@1 88.672 (90.365)\tPrec@5 99.609 (99.426)\n",
            "Test: [0/100]\tTime 0.286 (0.286)\tLoss 5.3587 (5.3587)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.017 (0.053)\tLoss 4.3738 (5.2576)\tPrec@1 80.000 (75.909)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/100]\tTime 0.012 (0.039)\tLoss 5.5449 (5.1528)\tPrec@1 75.000 (77.000)\tPrec@5 97.000 (97.429)\n",
            "Test: [30/100]\tTime 0.020 (0.033)\tLoss 5.4358 (5.1856)\tPrec@1 75.000 (76.871)\tPrec@5 96.000 (97.258)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 4.9926 (5.1684)\tPrec@1 76.000 (76.659)\tPrec@5 95.000 (97.341)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 4.7938 (5.1393)\tPrec@1 76.000 (76.412)\tPrec@5 96.000 (97.314)\n",
            "Test: [60/100]\tTime 0.024 (0.029)\tLoss 4.9079 (5.1845)\tPrec@1 77.000 (76.180)\tPrec@5 98.000 (97.328)\n",
            "Test: [70/100]\tTime 0.012 (0.028)\tLoss 4.4621 (5.2292)\tPrec@1 77.000 (75.972)\tPrec@5 98.000 (97.296)\n",
            "Test: [80/100]\tTime 0.033 (0.028)\tLoss 4.4309 (5.1778)\tPrec@1 81.000 (76.086)\tPrec@5 96.000 (97.333)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 5.4880 (5.2407)\tPrec@1 75.000 (75.769)\tPrec@5 97.000 (97.176)\n",
            "val Results: Prec@1 75.700 Prec@5 97.180 Loss 5.24915\n",
            "val Class Accuracy: [0.824,0.955,0.839,0.512,0.772,0.736,0.758,0.813,0.584,0.777]\n",
            "Best Prec@1: 76.380\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [69][0/329], lr: 0.01000\tTime 0.599 (0.599)\tData 0.513 (0.513)\tLoss 1.3095 (1.3095)\tPrec@1 94.141 (94.141)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [69][10/329], lr: 0.01000\tTime 0.099 (0.141)\tData 0.000 (0.052)\tLoss 2.2658 (2.6695)\tPrec@1 88.672 (85.866)\tPrec@5 99.219 (97.869)\n",
            "Epoch: [69][20/329], lr: 0.01000\tTime 0.082 (0.117)\tData 0.005 (0.029)\tLoss 2.3334 (2.6308)\tPrec@1 87.891 (86.328)\tPrec@5 99.219 (98.196)\n",
            "Epoch: [69][30/329], lr: 0.01000\tTime 0.087 (0.108)\tData 0.000 (0.022)\tLoss 2.6052 (2.4817)\tPrec@1 87.109 (87.172)\tPrec@5 98.438 (98.337)\n",
            "Epoch: [69][40/329], lr: 0.01000\tTime 0.115 (0.104)\tData 0.000 (0.018)\tLoss 2.1200 (2.3563)\tPrec@1 88.672 (87.786)\tPrec@5 99.609 (98.561)\n",
            "Epoch: [69][50/329], lr: 0.01000\tTime 0.099 (0.101)\tData 0.008 (0.015)\tLoss 1.4309 (2.2592)\tPrec@1 93.750 (88.327)\tPrec@5 99.609 (98.744)\n",
            "Epoch: [69][60/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.004 (0.013)\tLoss 2.1763 (2.2421)\tPrec@1 89.062 (88.429)\tPrec@5 98.828 (98.770)\n",
            "Epoch: [69][70/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.000 (0.013)\tLoss 1.6638 (2.2002)\tPrec@1 91.406 (88.666)\tPrec@5 99.219 (98.834)\n",
            "Epoch: [69][80/329], lr: 0.01000\tTime 0.097 (0.096)\tData 0.001 (0.012)\tLoss 2.1088 (2.1690)\tPrec@1 89.844 (88.845)\tPrec@5 99.609 (98.929)\n",
            "Epoch: [69][90/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.003 (0.011)\tLoss 2.3051 (2.1308)\tPrec@1 89.453 (89.028)\tPrec@5 98.047 (98.953)\n",
            "Epoch: [69][100/329], lr: 0.01000\tTime 0.069 (0.095)\tData 0.008 (0.011)\tLoss 1.1060 (2.0900)\tPrec@1 95.312 (89.248)\tPrec@5 99.609 (98.963)\n",
            "Epoch: [69][110/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.012 (0.011)\tLoss 1.4558 (2.0669)\tPrec@1 91.797 (89.355)\tPrec@5 99.609 (98.997)\n",
            "Epoch: [69][120/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.005 (0.011)\tLoss 1.5322 (2.0509)\tPrec@1 91.016 (89.443)\tPrec@5 99.609 (99.032)\n",
            "Epoch: [69][130/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.006 (0.010)\tLoss 2.1151 (2.0333)\tPrec@1 88.672 (89.534)\tPrec@5 99.219 (99.061)\n",
            "Epoch: [69][140/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.012 (0.010)\tLoss 1.2180 (2.0248)\tPrec@1 93.750 (89.561)\tPrec@5 98.828 (99.061)\n",
            "Epoch: [69][150/329], lr: 0.01000\tTime 0.111 (0.095)\tData 0.000 (0.010)\tLoss 1.9995 (2.0010)\tPrec@1 89.062 (89.691)\tPrec@5 100.000 (99.100)\n",
            "Epoch: [69][160/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.000 (0.010)\tLoss 1.4441 (1.9880)\tPrec@1 94.141 (89.764)\tPrec@5 99.609 (99.117)\n",
            "Epoch: [69][170/329], lr: 0.01000\tTime 0.171 (0.098)\tData 0.092 (0.012)\tLoss 1.7384 (1.9756)\tPrec@1 91.016 (89.819)\tPrec@5 99.219 (99.143)\n",
            "Epoch: [69][180/329], lr: 0.01000\tTime 0.111 (0.099)\tData 0.000 (0.012)\tLoss 2.0589 (1.9708)\tPrec@1 89.453 (89.850)\tPrec@5 99.609 (99.150)\n",
            "Epoch: [69][190/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.004 (0.012)\tLoss 1.8087 (1.9647)\tPrec@1 90.625 (89.862)\tPrec@5 100.000 (99.174)\n",
            "Epoch: [69][200/329], lr: 0.01000\tTime 0.105 (0.099)\tData 0.000 (0.011)\tLoss 2.5116 (1.9526)\tPrec@1 85.938 (89.935)\tPrec@5 99.219 (99.188)\n",
            "Epoch: [69][210/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.005 (0.011)\tLoss 0.9318 (1.9434)\tPrec@1 95.312 (89.984)\tPrec@5 99.609 (99.193)\n",
            "Epoch: [69][220/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.003 (0.011)\tLoss 1.5845 (1.9374)\tPrec@1 92.578 (90.017)\tPrec@5 100.000 (99.212)\n",
            "Epoch: [69][230/329], lr: 0.01000\tTime 0.110 (0.098)\tData 0.000 (0.011)\tLoss 1.8163 (1.9255)\tPrec@1 90.234 (90.069)\tPrec@5 100.000 (99.229)\n",
            "Epoch: [69][240/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.000 (0.010)\tLoss 1.4683 (1.9138)\tPrec@1 91.797 (90.124)\tPrec@5 99.609 (99.248)\n",
            "Epoch: [69][250/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.002 (0.010)\tLoss 1.5847 (1.9070)\tPrec@1 92.578 (90.153)\tPrec@5 98.828 (99.256)\n",
            "Epoch: [69][260/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.000 (0.010)\tLoss 1.9292 (1.9075)\tPrec@1 90.625 (90.145)\tPrec@5 98.438 (99.250)\n",
            "Epoch: [69][270/329], lr: 0.01000\tTime 0.094 (0.096)\tData 0.006 (0.010)\tLoss 1.4480 (1.9064)\tPrec@1 92.188 (90.148)\tPrec@5 100.000 (99.259)\n",
            "Epoch: [69][280/329], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.010)\tLoss 1.9594 (1.9050)\tPrec@1 90.234 (90.154)\tPrec@5 99.609 (99.260)\n",
            "Epoch: [69][290/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.006 (0.010)\tLoss 1.5000 (1.8973)\tPrec@1 92.578 (90.193)\tPrec@5 100.000 (99.275)\n",
            "Epoch: [69][300/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.000 (0.009)\tLoss 2.4977 (1.9012)\tPrec@1 88.281 (90.173)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [69][310/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.007 (0.009)\tLoss 1.9138 (1.8989)\tPrec@1 91.016 (90.193)\tPrec@5 100.000 (99.289)\n",
            "Epoch: [69][320/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.057 (0.009)\tLoss 2.2632 (1.9021)\tPrec@1 89.453 (90.181)\tPrec@5 98.828 (99.288)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 7.4344 (7.4344)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.030 (0.055)\tLoss 6.4184 (7.4559)\tPrec@1 73.000 (65.818)\tPrec@5 95.000 (96.727)\n",
            "Test: [20/100]\tTime 0.026 (0.040)\tLoss 5.9719 (7.4179)\tPrec@1 72.000 (66.190)\tPrec@5 97.000 (96.333)\n",
            "Test: [30/100]\tTime 0.026 (0.033)\tLoss 6.9331 (7.3942)\tPrec@1 70.000 (66.355)\tPrec@5 90.000 (96.097)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 8.0794 (7.4068)\tPrec@1 66.000 (66.537)\tPrec@5 95.000 (96.122)\n",
            "Test: [50/100]\tTime 0.034 (0.030)\tLoss 7.2712 (7.3485)\tPrec@1 66.000 (66.725)\tPrec@5 92.000 (95.882)\n",
            "Test: [60/100]\tTime 0.022 (0.029)\tLoss 6.4825 (7.4352)\tPrec@1 68.000 (66.180)\tPrec@5 96.000 (95.918)\n",
            "Test: [70/100]\tTime 0.024 (0.028)\tLoss 7.7685 (7.4485)\tPrec@1 63.000 (66.056)\tPrec@5 97.000 (96.070)\n",
            "Test: [80/100]\tTime 0.025 (0.028)\tLoss 5.7816 (7.3701)\tPrec@1 75.000 (66.494)\tPrec@5 96.000 (96.062)\n",
            "Test: [90/100]\tTime 0.023 (0.027)\tLoss 7.6463 (7.4594)\tPrec@1 62.000 (66.121)\tPrec@5 99.000 (96.033)\n",
            "val Results: Prec@1 66.150 Prec@5 95.940 Loss 7.46085\n",
            "val Class Accuracy: [0.945,0.993,0.851,0.573,0.472,0.645,0.662,0.554,0.368,0.552]\n",
            "Best Prec@1: 76.380\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [70][0/329], lr: 0.01000\tTime 0.643 (0.643)\tData 0.537 (0.537)\tLoss 1.5508 (1.5508)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [70][10/329], lr: 0.01000\tTime 0.092 (0.147)\tData 0.004 (0.054)\tLoss 1.8952 (2.1462)\tPrec@1 89.453 (88.743)\tPrec@5 98.828 (98.935)\n",
            "Epoch: [70][20/329], lr: 0.01000\tTime 0.082 (0.121)\tData 0.006 (0.031)\tLoss 1.8750 (1.9867)\tPrec@1 91.016 (89.583)\tPrec@5 99.219 (99.070)\n",
            "Epoch: [70][30/329], lr: 0.01000\tTime 0.094 (0.110)\tData 0.000 (0.023)\tLoss 2.2042 (1.9770)\tPrec@1 88.672 (89.617)\tPrec@5 98.828 (99.042)\n",
            "Epoch: [70][40/329], lr: 0.01000\tTime 0.092 (0.104)\tData 0.003 (0.019)\tLoss 1.7181 (1.9305)\tPrec@1 91.406 (90.006)\tPrec@5 99.609 (99.143)\n",
            "Epoch: [70][50/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.012 (0.016)\tLoss 1.6552 (1.9127)\tPrec@1 90.625 (90.081)\tPrec@5 99.609 (99.188)\n",
            "Epoch: [70][60/329], lr: 0.01000\tTime 0.081 (0.098)\tData 0.004 (0.014)\tLoss 1.9465 (1.9081)\tPrec@1 90.234 (90.138)\tPrec@5 99.219 (99.206)\n",
            "Epoch: [70][70/329], lr: 0.01000\tTime 0.096 (0.097)\tData 0.000 (0.013)\tLoss 1.9242 (1.8710)\tPrec@1 90.234 (90.377)\tPrec@5 98.047 (99.230)\n",
            "Epoch: [70][80/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.006 (0.012)\tLoss 2.0684 (1.8598)\tPrec@1 88.281 (90.422)\tPrec@5 98.828 (99.238)\n",
            "Epoch: [70][90/329], lr: 0.01000\tTime 0.103 (0.095)\tData 0.004 (0.012)\tLoss 2.0686 (1.8801)\tPrec@1 88.281 (90.325)\tPrec@5 99.609 (99.245)\n",
            "Epoch: [70][100/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.000 (0.011)\tLoss 1.8156 (1.8687)\tPrec@1 91.406 (90.397)\tPrec@5 99.219 (99.250)\n",
            "Epoch: [70][110/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.007 (0.011)\tLoss 1.6961 (1.8680)\tPrec@1 90.234 (90.407)\tPrec@5 99.609 (99.261)\n",
            "Epoch: [70][120/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.014 (0.011)\tLoss 1.5251 (1.8546)\tPrec@1 91.016 (90.480)\tPrec@5 98.828 (99.274)\n",
            "Epoch: [70][130/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.005 (0.010)\tLoss 1.6426 (1.8424)\tPrec@1 92.969 (90.577)\tPrec@5 99.609 (99.269)\n",
            "Epoch: [70][140/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.006 (0.010)\tLoss 2.0067 (1.8362)\tPrec@1 89.453 (90.619)\tPrec@5 99.609 (99.288)\n",
            "Epoch: [70][150/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 2.1464 (1.8339)\tPrec@1 88.672 (90.625)\tPrec@5 99.219 (99.289)\n",
            "Epoch: [70][160/329], lr: 0.01000\tTime 0.128 (0.092)\tData 0.000 (0.010)\tLoss 1.8685 (1.8282)\tPrec@1 90.625 (90.674)\tPrec@5 100.000 (99.301)\n",
            "Epoch: [70][170/329], lr: 0.01000\tTime 0.095 (0.092)\tData 0.010 (0.010)\tLoss 2.1635 (1.8251)\tPrec@1 87.891 (90.684)\tPrec@5 99.609 (99.303)\n",
            "Epoch: [70][180/329], lr: 0.01000\tTime 0.070 (0.091)\tData 0.004 (0.010)\tLoss 1.3325 (1.8243)\tPrec@1 94.141 (90.672)\tPrec@5 100.000 (99.303)\n",
            "Epoch: [70][190/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.009)\tLoss 1.9679 (1.8317)\tPrec@1 91.016 (90.633)\tPrec@5 99.219 (99.309)\n",
            "Epoch: [70][200/329], lr: 0.01000\tTime 0.114 (0.091)\tData 0.000 (0.009)\tLoss 1.3077 (1.8214)\tPrec@1 93.359 (90.677)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [70][210/329], lr: 0.01000\tTime 0.069 (0.091)\tData 0.000 (0.009)\tLoss 1.6470 (1.8204)\tPrec@1 92.969 (90.666)\tPrec@5 99.219 (99.328)\n",
            "Epoch: [70][220/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.015 (0.009)\tLoss 1.7904 (1.8179)\tPrec@1 90.625 (90.664)\tPrec@5 98.828 (99.325)\n",
            "Epoch: [70][230/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.005 (0.009)\tLoss 1.6506 (1.8160)\tPrec@1 92.188 (90.674)\tPrec@5 100.000 (99.337)\n",
            "Epoch: [70][240/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.000 (0.009)\tLoss 1.7014 (1.8142)\tPrec@1 91.016 (90.674)\tPrec@5 99.609 (99.342)\n",
            "Epoch: [70][250/329], lr: 0.01000\tTime 0.119 (0.092)\tData 0.000 (0.009)\tLoss 1.5484 (1.8151)\tPrec@1 92.188 (90.676)\tPrec@5 100.000 (99.353)\n",
            "Epoch: [70][260/329], lr: 0.01000\tTime 0.108 (0.093)\tData 0.000 (0.009)\tLoss 1.9617 (1.8178)\tPrec@1 90.625 (90.665)\tPrec@5 98.047 (99.352)\n",
            "Epoch: [70][270/329], lr: 0.01000\tTime 0.115 (0.094)\tData 0.009 (0.008)\tLoss 1.8502 (1.8210)\tPrec@1 90.625 (90.644)\tPrec@5 98.438 (99.340)\n",
            "Epoch: [70][280/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.000 (0.009)\tLoss 1.5011 (1.8244)\tPrec@1 93.359 (90.617)\tPrec@5 99.609 (99.337)\n",
            "Epoch: [70][290/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.009)\tLoss 1.8167 (1.8210)\tPrec@1 91.016 (90.632)\tPrec@5 99.219 (99.337)\n",
            "Epoch: [70][300/329], lr: 0.01000\tTime 0.079 (0.095)\tData 0.000 (0.009)\tLoss 1.5658 (1.8220)\tPrec@1 92.578 (90.628)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [70][310/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.005 (0.009)\tLoss 2.0678 (1.8249)\tPrec@1 87.891 (90.602)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [70][320/329], lr: 0.01000\tTime 0.119 (0.095)\tData 0.075 (0.009)\tLoss 1.6043 (1.8205)\tPrec@1 91.797 (90.631)\tPrec@5 99.609 (99.347)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 4.8076 (4.8076)\tPrec@1 78.000 (78.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.021 (0.052)\tLoss 4.5186 (5.2643)\tPrec@1 78.000 (75.273)\tPrec@5 95.000 (97.364)\n",
            "Test: [20/100]\tTime 0.022 (0.038)\tLoss 5.0949 (5.0762)\tPrec@1 75.000 (76.238)\tPrec@5 99.000 (97.571)\n",
            "Test: [30/100]\tTime 0.041 (0.034)\tLoss 4.8536 (5.1625)\tPrec@1 78.000 (75.613)\tPrec@5 95.000 (97.290)\n",
            "Test: [40/100]\tTime 0.027 (0.031)\tLoss 4.9459 (5.1922)\tPrec@1 79.000 (75.415)\tPrec@5 97.000 (97.244)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 5.3475 (5.2376)\tPrec@1 75.000 (75.157)\tPrec@5 96.000 (97.216)\n",
            "Test: [60/100]\tTime 0.017 (0.028)\tLoss 5.2619 (5.3120)\tPrec@1 76.000 (74.852)\tPrec@5 98.000 (97.311)\n",
            "Test: [70/100]\tTime 0.012 (0.028)\tLoss 4.5496 (5.3324)\tPrec@1 78.000 (74.732)\tPrec@5 98.000 (97.394)\n",
            "Test: [80/100]\tTime 0.042 (0.027)\tLoss 5.0101 (5.2916)\tPrec@1 80.000 (74.938)\tPrec@5 97.000 (97.457)\n",
            "Test: [90/100]\tTime 0.031 (0.027)\tLoss 4.1636 (5.3221)\tPrec@1 85.000 (74.868)\tPrec@5 99.000 (97.484)\n",
            "val Results: Prec@1 74.810 Prec@5 97.430 Loss 5.35202\n",
            "val Class Accuracy: [0.791,0.886,0.866,0.749,0.811,0.517,0.691,0.664,0.801,0.705]\n",
            "Best Prec@1: 76.380\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [71][0/329], lr: 0.01000\tTime 0.616 (0.616)\tData 0.513 (0.513)\tLoss 1.7337 (1.7337)\tPrec@1 90.234 (90.234)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [71][10/329], lr: 0.01000\tTime 0.085 (0.139)\tData 0.000 (0.053)\tLoss 2.6172 (3.1779)\tPrec@1 86.719 (82.351)\tPrec@5 98.438 (97.550)\n",
            "Epoch: [71][20/329], lr: 0.01000\tTime 0.079 (0.116)\tData 0.000 (0.029)\tLoss 2.8874 (3.0577)\tPrec@1 85.156 (83.519)\tPrec@5 99.219 (97.712)\n",
            "Epoch: [71][30/329], lr: 0.01000\tTime 0.123 (0.109)\tData 0.013 (0.023)\tLoss 2.5323 (2.8576)\tPrec@1 86.328 (84.728)\tPrec@5 98.828 (98.034)\n",
            "Epoch: [71][40/329], lr: 0.01000\tTime 0.083 (0.104)\tData 0.000 (0.018)\tLoss 2.3119 (2.7195)\tPrec@1 88.672 (85.509)\tPrec@5 99.219 (98.323)\n",
            "Epoch: [71][50/329], lr: 0.01000\tTime 0.118 (0.101)\tData 0.000 (0.016)\tLoss 1.8310 (2.6145)\tPrec@1 90.234 (86.060)\tPrec@5 99.609 (98.575)\n",
            "Epoch: [71][60/329], lr: 0.01000\tTime 0.115 (0.100)\tData 0.007 (0.014)\tLoss 2.7350 (2.5503)\tPrec@1 86.328 (86.431)\tPrec@5 98.047 (98.655)\n",
            "Epoch: [71][70/329], lr: 0.01000\tTime 0.061 (0.098)\tData 0.000 (0.013)\tLoss 1.6318 (2.4676)\tPrec@1 91.016 (86.950)\tPrec@5 100.000 (98.751)\n",
            "Epoch: [71][80/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.000 (0.013)\tLoss 1.3590 (2.3896)\tPrec@1 92.188 (87.384)\tPrec@5 100.000 (98.828)\n",
            "Epoch: [71][90/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.004 (0.012)\tLoss 1.7721 (2.3387)\tPrec@1 91.797 (87.680)\tPrec@5 99.219 (98.875)\n",
            "Epoch: [71][100/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.007 (0.012)\tLoss 1.7250 (2.2999)\tPrec@1 91.016 (87.879)\tPrec@5 99.609 (98.913)\n",
            "Epoch: [71][110/329], lr: 0.01000\tTime 0.081 (0.094)\tData 0.000 (0.011)\tLoss 2.2796 (2.2550)\tPrec@1 88.672 (88.137)\tPrec@5 98.438 (98.951)\n",
            "Epoch: [71][120/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.000 (0.011)\tLoss 1.6533 (2.2244)\tPrec@1 90.625 (88.317)\tPrec@5 99.609 (98.980)\n",
            "Epoch: [71][130/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.007 (0.011)\tLoss 2.0085 (2.1959)\tPrec@1 89.844 (88.454)\tPrec@5 99.219 (99.025)\n",
            "Epoch: [71][140/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.005 (0.010)\tLoss 1.9746 (2.1781)\tPrec@1 89.844 (88.567)\tPrec@5 99.219 (99.050)\n",
            "Epoch: [71][150/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.006 (0.010)\tLoss 1.5198 (2.1476)\tPrec@1 91.797 (88.721)\tPrec@5 100.000 (99.066)\n",
            "Epoch: [71][160/329], lr: 0.01000\tTime 0.075 (0.092)\tData 0.001 (0.010)\tLoss 1.6731 (2.1284)\tPrec@1 91.797 (88.830)\tPrec@5 99.609 (99.100)\n",
            "Epoch: [71][170/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.007 (0.010)\tLoss 1.8696 (2.1040)\tPrec@1 91.016 (88.996)\tPrec@5 99.609 (99.114)\n",
            "Epoch: [71][180/329], lr: 0.01000\tTime 0.109 (0.092)\tData 0.007 (0.010)\tLoss 1.9093 (2.0914)\tPrec@1 89.062 (89.082)\tPrec@5 99.219 (99.117)\n",
            "Epoch: [71][190/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.004 (0.009)\tLoss 1.8797 (2.0793)\tPrec@1 90.625 (89.142)\tPrec@5 99.609 (99.131)\n",
            "Epoch: [71][200/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 2.4113 (2.0692)\tPrec@1 85.938 (89.183)\tPrec@5 98.828 (99.155)\n",
            "Epoch: [71][210/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.007 (0.009)\tLoss 2.3006 (2.0608)\tPrec@1 87.500 (89.238)\tPrec@5 98.438 (99.165)\n",
            "Epoch: [71][220/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.006 (0.009)\tLoss 1.6985 (2.0442)\tPrec@1 92.188 (89.336)\tPrec@5 99.219 (99.157)\n",
            "Epoch: [71][230/329], lr: 0.01000\tTime 0.119 (0.091)\tData 0.006 (0.009)\tLoss 1.7938 (2.0352)\tPrec@1 91.016 (89.391)\tPrec@5 99.609 (99.168)\n",
            "Epoch: [71][240/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.013 (0.009)\tLoss 1.6609 (2.0193)\tPrec@1 92.578 (89.458)\tPrec@5 98.828 (99.181)\n",
            "Epoch: [71][250/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.002 (0.009)\tLoss 1.6865 (2.0088)\tPrec@1 91.016 (89.529)\tPrec@5 100.000 (99.199)\n",
            "Epoch: [71][260/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.000 (0.009)\tLoss 1.4806 (2.0010)\tPrec@1 91.797 (89.574)\tPrec@5 99.609 (99.208)\n",
            "Epoch: [71][270/329], lr: 0.01000\tTime 0.088 (0.090)\tData 0.000 (0.009)\tLoss 2.2605 (2.0024)\tPrec@1 87.891 (89.561)\tPrec@5 99.609 (99.220)\n",
            "Epoch: [71][280/329], lr: 0.01000\tTime 0.108 (0.090)\tData 0.000 (0.009)\tLoss 1.8093 (1.9963)\tPrec@1 91.406 (89.587)\tPrec@5 99.609 (99.226)\n",
            "Epoch: [71][290/329], lr: 0.01000\tTime 0.098 (0.090)\tData 0.004 (0.009)\tLoss 1.7044 (1.9910)\tPrec@1 91.016 (89.605)\tPrec@5 99.609 (99.224)\n",
            "Epoch: [71][300/329], lr: 0.01000\tTime 0.100 (0.090)\tData 0.005 (0.008)\tLoss 1.7845 (1.9878)\tPrec@1 90.234 (89.623)\tPrec@5 100.000 (99.232)\n",
            "Epoch: [71][310/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.000 (0.008)\tLoss 1.4001 (1.9771)\tPrec@1 91.797 (89.682)\tPrec@5 100.000 (99.233)\n",
            "Epoch: [71][320/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.045 (0.009)\tLoss 1.8703 (1.9776)\tPrec@1 89.062 (89.677)\tPrec@5 98.828 (99.241)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 4.6964 (4.6964)\tPrec@1 79.000 (79.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.015 (0.054)\tLoss 4.0942 (4.9275)\tPrec@1 79.000 (77.000)\tPrec@5 98.000 (98.091)\n",
            "Test: [20/100]\tTime 0.029 (0.038)\tLoss 4.7592 (4.8016)\tPrec@1 78.000 (77.714)\tPrec@5 98.000 (98.095)\n",
            "Test: [30/100]\tTime 0.033 (0.035)\tLoss 5.1722 (4.9120)\tPrec@1 79.000 (77.484)\tPrec@5 99.000 (97.677)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 4.0861 (4.8914)\tPrec@1 79.000 (77.463)\tPrec@5 99.000 (97.561)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 4.7433 (4.8691)\tPrec@1 77.000 (77.706)\tPrec@5 96.000 (97.686)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 4.3096 (4.8941)\tPrec@1 81.000 (77.607)\tPrec@5 97.000 (97.721)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 4.5570 (4.9124)\tPrec@1 79.000 (77.577)\tPrec@5 98.000 (97.662)\n",
            "Test: [80/100]\tTime 0.032 (0.028)\tLoss 4.6887 (4.8473)\tPrec@1 80.000 (77.840)\tPrec@5 97.000 (97.691)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 4.3989 (4.9132)\tPrec@1 81.000 (77.484)\tPrec@5 100.000 (97.637)\n",
            "val Results: Prec@1 77.230 Prec@5 97.660 Loss 4.96280\n",
            "val Class Accuracy: [0.924,0.923,0.828,0.799,0.841,0.595,0.838,0.694,0.582,0.699]\n",
            "Best Prec@1: 77.230\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [72][0/329], lr: 0.01000\tTime 0.855 (0.855)\tData 0.758 (0.758)\tLoss 1.3063 (1.3063)\tPrec@1 93.750 (93.750)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [72][10/329], lr: 0.01000\tTime 0.113 (0.197)\tData 0.008 (0.100)\tLoss 2.7893 (1.9661)\tPrec@1 85.547 (89.702)\tPrec@5 98.438 (99.112)\n",
            "Epoch: [72][20/329], lr: 0.01000\tTime 0.226 (0.170)\tData 0.115 (0.069)\tLoss 1.6054 (1.8566)\tPrec@1 91.406 (90.346)\tPrec@5 99.609 (99.219)\n",
            "Epoch: [72][30/329], lr: 0.01000\tTime 0.095 (0.145)\tData 0.000 (0.050)\tLoss 1.6475 (1.8269)\tPrec@1 92.578 (90.537)\tPrec@5 100.000 (99.206)\n",
            "Epoch: [72][40/329], lr: 0.01000\tTime 0.106 (0.132)\tData 0.005 (0.039)\tLoss 1.7577 (1.8187)\tPrec@1 91.797 (90.549)\tPrec@5 99.609 (99.209)\n",
            "Epoch: [72][50/329], lr: 0.01000\tTime 0.101 (0.125)\tData 0.003 (0.032)\tLoss 1.5131 (1.8060)\tPrec@1 93.750 (90.640)\tPrec@5 99.609 (99.280)\n",
            "Epoch: [72][60/329], lr: 0.01000\tTime 0.099 (0.120)\tData 0.005 (0.028)\tLoss 1.8659 (1.8218)\tPrec@1 89.844 (90.516)\tPrec@5 100.000 (99.302)\n",
            "Epoch: [72][70/329], lr: 0.01000\tTime 0.093 (0.116)\tData 0.000 (0.025)\tLoss 1.6809 (1.8192)\tPrec@1 90.625 (90.592)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [72][80/329], lr: 0.01000\tTime 0.072 (0.112)\tData 0.013 (0.023)\tLoss 2.1360 (1.8138)\tPrec@1 90.234 (90.615)\tPrec@5 99.609 (99.325)\n",
            "Epoch: [72][90/329], lr: 0.01000\tTime 0.081 (0.110)\tData 0.001 (0.021)\tLoss 1.6082 (1.8129)\tPrec@1 92.188 (90.659)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [72][100/329], lr: 0.01000\tTime 0.091 (0.107)\tData 0.005 (0.019)\tLoss 1.4262 (1.7937)\tPrec@1 93.359 (90.799)\tPrec@5 99.219 (99.343)\n",
            "Epoch: [72][110/329], lr: 0.01000\tTime 0.077 (0.106)\tData 0.000 (0.018)\tLoss 1.8674 (1.7887)\tPrec@1 90.234 (90.819)\tPrec@5 98.828 (99.338)\n",
            "Epoch: [72][120/329], lr: 0.01000\tTime 0.094 (0.105)\tData 0.006 (0.017)\tLoss 2.1119 (1.8082)\tPrec@1 89.062 (90.709)\tPrec@5 99.609 (99.338)\n",
            "Epoch: [72][130/329], lr: 0.01000\tTime 0.107 (0.104)\tData 0.004 (0.017)\tLoss 2.3562 (1.8047)\tPrec@1 87.500 (90.697)\tPrec@5 99.609 (99.329)\n",
            "Epoch: [72][140/329], lr: 0.01000\tTime 0.090 (0.103)\tData 0.000 (0.016)\tLoss 2.0313 (1.8065)\tPrec@1 89.453 (90.697)\tPrec@5 99.219 (99.327)\n",
            "Epoch: [72][150/329], lr: 0.01000\tTime 0.073 (0.102)\tData 0.000 (0.015)\tLoss 1.9831 (1.8024)\tPrec@1 89.453 (90.705)\tPrec@5 100.000 (99.327)\n",
            "Epoch: [72][160/329], lr: 0.01000\tTime 0.074 (0.101)\tData 0.000 (0.015)\tLoss 2.3444 (1.8037)\tPrec@1 88.281 (90.705)\tPrec@5 97.266 (99.301)\n",
            "Epoch: [72][170/329], lr: 0.01000\tTime 0.080 (0.100)\tData 0.000 (0.014)\tLoss 1.5699 (1.8016)\tPrec@1 91.406 (90.691)\tPrec@5 99.219 (99.308)\n",
            "Epoch: [72][180/329], lr: 0.01000\tTime 0.080 (0.099)\tData 0.000 (0.014)\tLoss 1.8787 (1.8025)\tPrec@1 89.844 (90.666)\tPrec@5 99.219 (99.309)\n",
            "Epoch: [72][190/329], lr: 0.01000\tTime 0.082 (0.099)\tData 0.002 (0.014)\tLoss 1.5362 (1.8008)\tPrec@1 92.578 (90.676)\tPrec@5 99.609 (99.315)\n",
            "Epoch: [72][200/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.000 (0.013)\tLoss 0.9807 (1.7965)\tPrec@1 95.703 (90.712)\tPrec@5 100.000 (99.314)\n",
            "Epoch: [72][210/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.007 (0.013)\tLoss 1.7241 (1.7991)\tPrec@1 91.016 (90.684)\tPrec@5 99.609 (99.308)\n",
            "Epoch: [72][220/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.007 (0.013)\tLoss 1.8967 (1.7973)\tPrec@1 90.625 (90.687)\tPrec@5 99.219 (99.304)\n",
            "Epoch: [72][230/329], lr: 0.01000\tTime 0.090 (0.097)\tData 0.000 (0.012)\tLoss 1.4601 (1.8009)\tPrec@1 92.188 (90.664)\tPrec@5 99.219 (99.298)\n",
            "Epoch: [72][240/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.000 (0.012)\tLoss 1.3041 (1.8004)\tPrec@1 92.578 (90.662)\tPrec@5 99.609 (99.314)\n",
            "Epoch: [72][250/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.000 (0.012)\tLoss 1.8332 (1.7970)\tPrec@1 90.625 (90.686)\tPrec@5 97.266 (99.320)\n",
            "Epoch: [72][260/329], lr: 0.01000\tTime 0.099 (0.096)\tData 0.005 (0.012)\tLoss 1.6233 (1.7952)\tPrec@1 91.797 (90.691)\tPrec@5 99.219 (99.329)\n",
            "Epoch: [72][270/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.000 (0.012)\tLoss 1.6732 (1.7904)\tPrec@1 91.016 (90.733)\tPrec@5 99.609 (99.333)\n",
            "Epoch: [72][280/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.003 (0.011)\tLoss 1.8416 (1.7898)\tPrec@1 87.891 (90.729)\tPrec@5 99.609 (99.337)\n",
            "Epoch: [72][290/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.011)\tLoss 1.4619 (1.7815)\tPrec@1 91.797 (90.777)\tPrec@5 99.609 (99.340)\n",
            "Epoch: [72][300/329], lr: 0.01000\tTime 0.079 (0.094)\tData 0.000 (0.011)\tLoss 2.2341 (1.7819)\tPrec@1 88.672 (90.778)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [72][310/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.006 (0.011)\tLoss 1.5423 (1.7783)\tPrec@1 91.016 (90.805)\tPrec@5 99.609 (99.346)\n",
            "Epoch: [72][320/329], lr: 0.01000\tTime 0.119 (0.094)\tData 0.083 (0.011)\tLoss 1.6693 (1.7798)\tPrec@1 91.797 (90.789)\tPrec@5 99.609 (99.349)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 6.4046 (6.4046)\tPrec@1 69.000 (69.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.031 (0.055)\tLoss 5.4578 (5.7801)\tPrec@1 71.000 (72.455)\tPrec@5 95.000 (96.636)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 4.8458 (5.6752)\tPrec@1 75.000 (73.190)\tPrec@5 98.000 (96.762)\n",
            "Test: [30/100]\tTime 0.025 (0.033)\tLoss 7.1102 (5.6520)\tPrec@1 66.000 (73.129)\tPrec@5 98.000 (96.871)\n",
            "Test: [40/100]\tTime 0.021 (0.031)\tLoss 4.8418 (5.6186)\tPrec@1 78.000 (73.463)\tPrec@5 97.000 (96.854)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 4.6895 (5.5923)\tPrec@1 75.000 (73.510)\tPrec@5 99.000 (96.980)\n",
            "Test: [60/100]\tTime 0.032 (0.029)\tLoss 5.0515 (5.6572)\tPrec@1 77.000 (73.148)\tPrec@5 96.000 (97.049)\n",
            "Test: [70/100]\tTime 0.018 (0.028)\tLoss 4.4362 (5.6932)\tPrec@1 78.000 (73.099)\tPrec@5 98.000 (97.014)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 5.8791 (5.6966)\tPrec@1 74.000 (73.123)\tPrec@5 96.000 (97.099)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 6.1034 (5.7552)\tPrec@1 71.000 (72.813)\tPrec@5 97.000 (97.022)\n",
            "val Results: Prec@1 72.760 Prec@5 97.030 Loss 5.77159\n",
            "val Class Accuracy: [0.835,0.755,0.550,0.568,0.793,0.845,0.698,0.754,0.528,0.950]\n",
            "Best Prec@1: 77.230\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [73][0/329], lr: 0.01000\tTime 0.555 (0.555)\tData 0.452 (0.452)\tLoss 2.7016 (2.7016)\tPrec@1 86.719 (86.719)\tPrec@5 98.047 (98.047)\n",
            "Epoch: [73][10/329], lr: 0.01000\tTime 0.088 (0.137)\tData 0.000 (0.045)\tLoss 3.1779 (3.2991)\tPrec@1 81.641 (81.712)\tPrec@5 99.219 (97.940)\n",
            "Epoch: [73][20/329], lr: 0.01000\tTime 0.098 (0.117)\tData 0.003 (0.025)\tLoss 2.5347 (2.9133)\tPrec@1 86.719 (84.375)\tPrec@5 99.609 (98.326)\n",
            "Epoch: [73][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.000 (0.019)\tLoss 2.1546 (2.6553)\tPrec@1 89.062 (85.874)\tPrec@5 98.438 (98.488)\n",
            "Epoch: [73][40/329], lr: 0.01000\tTime 0.076 (0.105)\tData 0.000 (0.016)\tLoss 2.3248 (2.5213)\tPrec@1 86.719 (86.490)\tPrec@5 99.609 (98.714)\n",
            "Epoch: [73][50/329], lr: 0.01000\tTime 0.100 (0.102)\tData 0.000 (0.015)\tLoss 1.7514 (2.4062)\tPrec@1 91.016 (87.240)\tPrec@5 100.000 (98.828)\n",
            "Epoch: [73][60/329], lr: 0.01000\tTime 0.067 (0.099)\tData 0.000 (0.013)\tLoss 1.6018 (2.3395)\tPrec@1 91.406 (87.583)\tPrec@5 99.219 (98.860)\n",
            "Epoch: [73][70/329], lr: 0.01000\tTime 0.108 (0.098)\tData 0.007 (0.012)\tLoss 1.4561 (2.2664)\tPrec@1 93.359 (87.935)\tPrec@5 100.000 (98.988)\n",
            "Epoch: [73][80/329], lr: 0.01000\tTime 0.089 (0.097)\tData 0.006 (0.012)\tLoss 1.9261 (2.2088)\tPrec@1 90.625 (88.305)\tPrec@5 99.609 (99.069)\n",
            "Epoch: [73][90/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.002 (0.011)\tLoss 1.7493 (2.1632)\tPrec@1 90.234 (88.595)\tPrec@5 98.828 (99.073)\n",
            "Epoch: [73][100/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.000 (0.010)\tLoss 1.9409 (2.1029)\tPrec@1 89.844 (88.935)\tPrec@5 100.000 (99.122)\n",
            "Epoch: [73][110/329], lr: 0.01000\tTime 0.164 (0.099)\tData 0.086 (0.010)\tLoss 1.8086 (2.0808)\tPrec@1 91.016 (89.126)\tPrec@5 100.000 (99.145)\n",
            "Epoch: [73][120/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.032 (0.012)\tLoss 1.4773 (2.0430)\tPrec@1 92.188 (89.337)\tPrec@5 99.609 (99.164)\n",
            "Epoch: [73][130/329], lr: 0.01000\tTime 0.102 (0.102)\tData 0.001 (0.014)\tLoss 1.7872 (2.0202)\tPrec@1 89.844 (89.435)\tPrec@5 99.609 (99.186)\n",
            "Epoch: [73][140/329], lr: 0.01000\tTime 0.081 (0.102)\tData 0.000 (0.014)\tLoss 1.6237 (2.0026)\tPrec@1 92.188 (89.564)\tPrec@5 98.828 (99.199)\n",
            "Epoch: [73][150/329], lr: 0.01000\tTime 0.105 (0.101)\tData 0.000 (0.013)\tLoss 1.8881 (1.9874)\tPrec@1 91.016 (89.657)\tPrec@5 98.438 (99.206)\n",
            "Epoch: [73][160/329], lr: 0.01000\tTime 0.083 (0.101)\tData 0.009 (0.013)\tLoss 1.8315 (1.9839)\tPrec@1 91.016 (89.667)\tPrec@5 99.219 (99.216)\n",
            "Epoch: [73][170/329], lr: 0.01000\tTime 0.083 (0.100)\tData 0.006 (0.012)\tLoss 1.6189 (1.9738)\tPrec@1 93.359 (89.716)\tPrec@5 100.000 (99.239)\n",
            "Epoch: [73][180/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.010 (0.012)\tLoss 1.7178 (1.9655)\tPrec@1 92.578 (89.783)\tPrec@5 98.828 (99.245)\n",
            "Epoch: [73][190/329], lr: 0.01000\tTime 0.112 (0.099)\tData 0.007 (0.012)\tLoss 1.6713 (1.9565)\tPrec@1 91.797 (89.827)\tPrec@5 100.000 (99.249)\n",
            "Epoch: [73][200/329], lr: 0.01000\tTime 0.073 (0.098)\tData 0.007 (0.012)\tLoss 2.0382 (1.9468)\tPrec@1 88.672 (89.861)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [73][210/329], lr: 0.01000\tTime 0.103 (0.098)\tData 0.000 (0.011)\tLoss 1.6786 (1.9312)\tPrec@1 91.797 (89.947)\tPrec@5 98.828 (99.265)\n",
            "Epoch: [73][220/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.000 (0.011)\tLoss 2.1749 (1.9277)\tPrec@1 87.109 (89.955)\tPrec@5 99.219 (99.266)\n",
            "Epoch: [73][230/329], lr: 0.01000\tTime 0.080 (0.097)\tData 0.000 (0.011)\tLoss 1.3307 (1.9197)\tPrec@1 92.188 (89.979)\tPrec@5 100.000 (99.280)\n",
            "Epoch: [73][240/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.005 (0.011)\tLoss 1.4995 (1.9156)\tPrec@1 92.578 (90.001)\tPrec@5 100.000 (99.292)\n",
            "Epoch: [73][250/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.000 (0.010)\tLoss 2.0565 (1.9195)\tPrec@1 88.672 (89.979)\tPrec@5 99.609 (99.300)\n",
            "Epoch: [73][260/329], lr: 0.01000\tTime 0.083 (0.096)\tData 0.006 (0.010)\tLoss 1.9801 (1.9158)\tPrec@1 89.453 (90.004)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [73][270/329], lr: 0.01000\tTime 0.109 (0.095)\tData 0.011 (0.010)\tLoss 1.7704 (1.9118)\tPrec@1 91.016 (90.033)\tPrec@5 99.219 (99.302)\n",
            "Epoch: [73][280/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.003 (0.010)\tLoss 1.5388 (1.9053)\tPrec@1 92.188 (90.075)\tPrec@5 99.609 (99.313)\n",
            "Epoch: [73][290/329], lr: 0.01000\tTime 0.075 (0.095)\tData 0.002 (0.010)\tLoss 2.0099 (1.9033)\tPrec@1 89.062 (90.080)\tPrec@5 99.609 (99.319)\n",
            "Epoch: [73][300/329], lr: 0.01000\tTime 0.101 (0.094)\tData 0.000 (0.010)\tLoss 1.6618 (1.9003)\tPrec@1 91.406 (90.105)\tPrec@5 100.000 (99.320)\n",
            "Epoch: [73][310/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.000 (0.010)\tLoss 1.8220 (1.8986)\tPrec@1 91.406 (90.115)\tPrec@5 98.828 (99.322)\n",
            "Epoch: [73][320/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.064 (0.010)\tLoss 1.6338 (1.8960)\tPrec@1 91.016 (90.137)\tPrec@5 99.219 (99.315)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 6.3673 (6.3673)\tPrec@1 70.000 (70.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.050)\tLoss 5.9552 (6.6998)\tPrec@1 71.000 (69.364)\tPrec@5 99.000 (97.091)\n",
            "Test: [20/100]\tTime 0.025 (0.037)\tLoss 4.2562 (6.7654)\tPrec@1 79.000 (69.190)\tPrec@5 99.000 (96.810)\n",
            "Test: [30/100]\tTime 0.020 (0.033)\tLoss 8.0080 (6.9203)\tPrec@1 60.000 (68.484)\tPrec@5 96.000 (96.226)\n",
            "Test: [40/100]\tTime 0.026 (0.031)\tLoss 7.4588 (6.9684)\tPrec@1 70.000 (68.439)\tPrec@5 96.000 (96.244)\n",
            "Test: [50/100]\tTime 0.040 (0.029)\tLoss 6.4908 (6.9308)\tPrec@1 70.000 (68.373)\tPrec@5 95.000 (96.510)\n",
            "Test: [60/100]\tTime 0.023 (0.028)\tLoss 6.9798 (6.9706)\tPrec@1 65.000 (67.951)\tPrec@5 97.000 (96.459)\n",
            "Test: [70/100]\tTime 0.026 (0.027)\tLoss 7.1571 (7.0000)\tPrec@1 68.000 (67.873)\tPrec@5 98.000 (96.324)\n",
            "Test: [80/100]\tTime 0.028 (0.027)\tLoss 6.2730 (6.9631)\tPrec@1 71.000 (67.914)\tPrec@5 98.000 (96.370)\n",
            "Test: [90/100]\tTime 0.038 (0.027)\tLoss 6.8162 (7.0254)\tPrec@1 69.000 (67.582)\tPrec@5 97.000 (96.385)\n",
            "val Results: Prec@1 67.630 Prec@5 96.380 Loss 7.02809\n",
            "val Class Accuracy: [0.990,0.837,0.656,0.679,0.452,0.601,0.741,0.684,0.470,0.653]\n",
            "Best Prec@1: 77.230\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [74][0/329], lr: 0.01000\tTime 0.501 (0.501)\tData 0.417 (0.417)\tLoss 1.4642 (1.4642)\tPrec@1 92.969 (92.969)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [74][10/329], lr: 0.01000\tTime 0.087 (0.144)\tData 0.000 (0.053)\tLoss 2.0733 (2.3242)\tPrec@1 88.672 (87.749)\tPrec@5 98.438 (98.544)\n",
            "Epoch: [74][20/329], lr: 0.01000\tTime 0.123 (0.119)\tData 0.000 (0.031)\tLoss 2.8941 (2.2752)\tPrec@1 86.328 (88.170)\tPrec@5 98.438 (98.735)\n",
            "Epoch: [74][30/329], lr: 0.01000\tTime 0.086 (0.108)\tData 0.000 (0.023)\tLoss 2.2400 (2.1750)\tPrec@1 88.281 (88.785)\tPrec@5 98.047 (98.841)\n",
            "Epoch: [74][40/329], lr: 0.01000\tTime 0.079 (0.103)\tData 0.000 (0.019)\tLoss 1.7906 (2.0774)\tPrec@1 90.234 (89.291)\tPrec@5 99.219 (98.923)\n",
            "Epoch: [74][50/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.010 (0.017)\tLoss 2.0834 (2.0487)\tPrec@1 89.453 (89.476)\tPrec@5 99.219 (99.027)\n",
            "Epoch: [74][60/329], lr: 0.01000\tTime 0.108 (0.098)\tData 0.012 (0.015)\tLoss 1.9131 (1.9985)\tPrec@1 88.281 (89.709)\tPrec@5 99.219 (99.084)\n",
            "Epoch: [74][70/329], lr: 0.01000\tTime 0.073 (0.096)\tData 0.000 (0.014)\tLoss 2.4774 (1.9680)\tPrec@1 87.500 (89.899)\tPrec@5 99.219 (99.076)\n",
            "Epoch: [74][80/329], lr: 0.01000\tTime 0.084 (0.096)\tData 0.000 (0.013)\tLoss 2.3455 (1.9334)\tPrec@1 87.500 (90.075)\tPrec@5 98.828 (99.122)\n",
            "Epoch: [74][90/329], lr: 0.01000\tTime 0.118 (0.095)\tData 0.007 (0.012)\tLoss 1.5927 (1.9162)\tPrec@1 92.188 (90.174)\tPrec@5 99.609 (99.141)\n",
            "Epoch: [74][100/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.004 (0.012)\tLoss 2.0342 (1.9033)\tPrec@1 88.672 (90.238)\tPrec@5 98.828 (99.157)\n",
            "Epoch: [74][110/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.000 (0.011)\tLoss 1.5535 (1.8867)\tPrec@1 92.578 (90.326)\tPrec@5 99.609 (99.169)\n",
            "Epoch: [74][120/329], lr: 0.01000\tTime 0.068 (0.093)\tData 0.000 (0.011)\tLoss 1.9912 (1.8806)\tPrec@1 90.234 (90.376)\tPrec@5 99.609 (99.180)\n",
            "Epoch: [74][130/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.006 (0.011)\tLoss 1.8768 (1.8637)\tPrec@1 91.016 (90.482)\tPrec@5 100.000 (99.201)\n",
            "Epoch: [74][140/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 1.4072 (1.8612)\tPrec@1 92.969 (90.522)\tPrec@5 100.000 (99.205)\n",
            "Epoch: [74][150/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.008 (0.010)\tLoss 1.5961 (1.8503)\tPrec@1 93.359 (90.584)\tPrec@5 99.609 (99.224)\n",
            "Epoch: [74][160/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.001 (0.010)\tLoss 2.0004 (1.8456)\tPrec@1 89.844 (90.591)\tPrec@5 99.219 (99.228)\n",
            "Epoch: [74][170/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.004 (0.010)\tLoss 1.6704 (1.8386)\tPrec@1 91.016 (90.614)\tPrec@5 99.219 (99.239)\n",
            "Epoch: [74][180/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.007 (0.010)\tLoss 2.3540 (1.8424)\tPrec@1 88.281 (90.586)\tPrec@5 99.219 (99.232)\n",
            "Epoch: [74][190/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.006 (0.010)\tLoss 1.4060 (1.8375)\tPrec@1 93.750 (90.607)\tPrec@5 100.000 (99.237)\n",
            "Epoch: [74][200/329], lr: 0.01000\tTime 0.128 (0.091)\tData 0.000 (0.009)\tLoss 1.8439 (1.8311)\tPrec@1 90.234 (90.646)\tPrec@5 99.219 (99.248)\n",
            "Epoch: [74][210/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.000 (0.009)\tLoss 1.7762 (1.8239)\tPrec@1 91.016 (90.690)\tPrec@5 98.828 (99.258)\n",
            "Epoch: [74][220/329], lr: 0.01000\tTime 0.107 (0.094)\tData 0.000 (0.009)\tLoss 1.7075 (1.8203)\tPrec@1 91.406 (90.706)\tPrec@5 100.000 (99.270)\n",
            "Epoch: [74][230/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.012 (0.009)\tLoss 2.0566 (1.8156)\tPrec@1 89.844 (90.733)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [74][240/329], lr: 0.01000\tTime 0.102 (0.095)\tData 0.000 (0.010)\tLoss 1.2940 (1.8121)\tPrec@1 94.531 (90.751)\tPrec@5 98.828 (99.274)\n",
            "Epoch: [74][250/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.000 (0.010)\tLoss 1.6725 (1.8016)\tPrec@1 90.234 (90.792)\tPrec@5 98.828 (99.289)\n",
            "Epoch: [74][260/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.003 (0.010)\tLoss 2.5398 (1.8055)\tPrec@1 87.891 (90.773)\tPrec@5 99.609 (99.289)\n",
            "Epoch: [74][270/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.004 (0.010)\tLoss 1.3638 (1.8030)\tPrec@1 93.359 (90.789)\tPrec@5 100.000 (99.294)\n",
            "Epoch: [74][280/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.003 (0.010)\tLoss 1.5879 (1.8027)\tPrec@1 91.406 (90.775)\tPrec@5 99.219 (99.308)\n",
            "Epoch: [74][290/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.009)\tLoss 1.4982 (1.8043)\tPrec@1 92.188 (90.763)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [74][300/329], lr: 0.01000\tTime 0.095 (0.095)\tData 0.000 (0.009)\tLoss 1.9241 (1.8065)\tPrec@1 90.625 (90.756)\tPrec@5 98.828 (99.299)\n",
            "Epoch: [74][310/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.008 (0.009)\tLoss 2.1176 (1.8091)\tPrec@1 89.453 (90.751)\tPrec@5 99.219 (99.299)\n",
            "Epoch: [74][320/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.063 (0.009)\tLoss 1.4165 (1.8048)\tPrec@1 92.188 (90.782)\tPrec@5 100.000 (99.309)\n",
            "Test: [0/100]\tTime 0.310 (0.310)\tLoss 5.1337 (5.1337)\tPrec@1 79.000 (79.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.055)\tLoss 4.6737 (5.0571)\tPrec@1 79.000 (78.727)\tPrec@5 100.000 (98.455)\n",
            "Test: [20/100]\tTime 0.028 (0.036)\tLoss 4.2230 (4.9546)\tPrec@1 79.000 (78.048)\tPrec@5 100.000 (98.333)\n",
            "Test: [30/100]\tTime 0.029 (0.034)\tLoss 5.4212 (5.0539)\tPrec@1 73.000 (77.290)\tPrec@5 98.000 (98.226)\n",
            "Test: [40/100]\tTime 0.029 (0.030)\tLoss 4.8682 (5.0303)\tPrec@1 79.000 (77.537)\tPrec@5 99.000 (98.220)\n",
            "Test: [50/100]\tTime 0.033 (0.030)\tLoss 4.7136 (4.9717)\tPrec@1 79.000 (77.686)\tPrec@5 99.000 (98.451)\n",
            "Test: [60/100]\tTime 0.016 (0.029)\tLoss 4.8206 (4.9930)\tPrec@1 79.000 (77.689)\tPrec@5 100.000 (98.492)\n",
            "Test: [70/100]\tTime 0.021 (0.028)\tLoss 3.9841 (4.9971)\tPrec@1 83.000 (77.620)\tPrec@5 96.000 (98.408)\n",
            "Test: [80/100]\tTime 0.024 (0.027)\tLoss 4.1344 (4.9411)\tPrec@1 80.000 (77.802)\tPrec@5 98.000 (98.383)\n",
            "Test: [90/100]\tTime 0.023 (0.027)\tLoss 4.4199 (5.0078)\tPrec@1 82.000 (77.527)\tPrec@5 99.000 (98.308)\n",
            "val Results: Prec@1 77.370 Prec@5 98.320 Loss 5.03266\n",
            "val Class Accuracy: [0.959,0.965,0.756,0.660,0.862,0.789,0.759,0.740,0.515,0.732]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [75][0/329], lr: 0.01000\tTime 0.469 (0.469)\tData 0.386 (0.386)\tLoss 1.6170 (1.6170)\tPrec@1 91.016 (91.016)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [75][10/329], lr: 0.01000\tTime 0.092 (0.136)\tData 0.000 (0.047)\tLoss 1.9365 (1.8590)\tPrec@1 90.234 (90.696)\tPrec@5 100.000 (99.609)\n",
            "Epoch: [75][20/329], lr: 0.01000\tTime 0.082 (0.113)\tData 0.006 (0.026)\tLoss 1.6092 (1.7578)\tPrec@1 91.016 (91.239)\tPrec@5 99.219 (99.554)\n",
            "Epoch: [75][30/329], lr: 0.01000\tTime 0.115 (0.110)\tData 0.013 (0.020)\tLoss 1.5889 (1.7524)\tPrec@1 91.406 (91.217)\tPrec@5 99.609 (99.408)\n",
            "Epoch: [75][40/329], lr: 0.01000\tTime 0.093 (0.104)\tData 0.007 (0.017)\tLoss 1.6221 (1.7887)\tPrec@1 91.406 (91.025)\tPrec@5 99.219 (99.352)\n",
            "Epoch: [75][50/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.007 (0.015)\tLoss 1.8331 (1.7924)\tPrec@1 88.672 (90.862)\tPrec@5 100.000 (99.341)\n",
            "Epoch: [75][60/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.000 (0.013)\tLoss 1.6947 (1.7757)\tPrec@1 91.406 (90.881)\tPrec@5 99.219 (99.353)\n",
            "Epoch: [75][70/329], lr: 0.01000\tTime 0.111 (0.097)\tData 0.004 (0.012)\tLoss 0.9736 (1.7567)\tPrec@1 94.922 (91.005)\tPrec@5 99.219 (99.378)\n",
            "Epoch: [75][80/329], lr: 0.01000\tTime 0.098 (0.096)\tData 0.007 (0.011)\tLoss 2.1057 (1.7554)\tPrec@1 88.281 (90.924)\tPrec@5 99.219 (99.388)\n",
            "Epoch: [75][90/329], lr: 0.01000\tTime 0.070 (0.095)\tData 0.000 (0.011)\tLoss 1.2953 (1.7462)\tPrec@1 92.969 (91.003)\tPrec@5 99.609 (99.403)\n",
            "Epoch: [75][100/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.007 (0.010)\tLoss 1.4384 (1.7347)\tPrec@1 92.188 (91.019)\tPrec@5 99.609 (99.404)\n",
            "Epoch: [75][110/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 1.6933 (1.7238)\tPrec@1 91.406 (91.100)\tPrec@5 99.219 (99.419)\n",
            "Epoch: [75][120/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.009)\tLoss 1.7186 (1.7306)\tPrec@1 92.969 (91.080)\tPrec@5 98.828 (99.406)\n",
            "Epoch: [75][130/329], lr: 0.01000\tTime 0.104 (0.093)\tData 0.006 (0.009)\tLoss 1.7506 (1.7334)\tPrec@1 90.625 (91.063)\tPrec@5 99.609 (99.389)\n",
            "Epoch: [75][140/329], lr: 0.01000\tTime 0.071 (0.092)\tData 0.000 (0.009)\tLoss 1.4275 (1.7324)\tPrec@1 92.188 (91.054)\tPrec@5 100.000 (99.415)\n",
            "Epoch: [75][150/329], lr: 0.01000\tTime 0.111 (0.092)\tData 0.006 (0.009)\tLoss 1.9110 (1.7363)\tPrec@1 90.234 (91.062)\tPrec@5 100.000 (99.415)\n",
            "Epoch: [75][160/329], lr: 0.01000\tTime 0.068 (0.092)\tData 0.000 (0.009)\tLoss 1.2149 (1.7335)\tPrec@1 93.359 (91.067)\tPrec@5 99.219 (99.420)\n",
            "Epoch: [75][170/329], lr: 0.01000\tTime 0.070 (0.091)\tData 0.000 (0.009)\tLoss 1.7247 (1.7423)\tPrec@1 91.797 (91.032)\tPrec@5 99.219 (99.422)\n",
            "Epoch: [75][180/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 1.8738 (1.7401)\tPrec@1 89.453 (91.037)\tPrec@5 99.219 (99.428)\n",
            "Epoch: [75][190/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.001 (0.008)\tLoss 1.2814 (1.7351)\tPrec@1 92.578 (91.065)\tPrec@5 100.000 (99.425)\n",
            "Epoch: [75][200/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.007 (0.008)\tLoss 1.7065 (1.7351)\tPrec@1 92.578 (91.072)\tPrec@5 99.609 (99.429)\n",
            "Epoch: [75][210/329], lr: 0.01000\tTime 0.074 (0.091)\tData 0.000 (0.008)\tLoss 1.4940 (1.7360)\tPrec@1 91.406 (91.067)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [75][220/329], lr: 0.01000\tTime 0.106 (0.091)\tData 0.007 (0.008)\tLoss 1.3812 (1.7392)\tPrec@1 92.188 (91.051)\tPrec@5 100.000 (99.436)\n",
            "Epoch: [75][230/329], lr: 0.01000\tTime 0.080 (0.090)\tData 0.007 (0.008)\tLoss 1.6554 (1.7363)\tPrec@1 92.188 (91.056)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [75][240/329], lr: 0.01000\tTime 0.072 (0.090)\tData 0.004 (0.008)\tLoss 1.8093 (1.7363)\tPrec@1 91.016 (91.063)\tPrec@5 98.828 (99.436)\n",
            "Epoch: [75][250/329], lr: 0.01000\tTime 0.087 (0.090)\tData 0.006 (0.008)\tLoss 1.5686 (1.7384)\tPrec@1 92.578 (91.039)\tPrec@5 99.219 (99.440)\n",
            "Epoch: [75][260/329], lr: 0.01000\tTime 0.091 (0.090)\tData 0.007 (0.008)\tLoss 1.6303 (1.7396)\tPrec@1 91.406 (91.034)\tPrec@5 99.219 (99.427)\n",
            "Epoch: [75][270/329], lr: 0.01000\tTime 0.087 (0.090)\tData 0.006 (0.008)\tLoss 1.7496 (1.7501)\tPrec@1 89.844 (90.971)\tPrec@5 99.219 (99.410)\n",
            "Epoch: [75][280/329], lr: 0.01000\tTime 0.070 (0.090)\tData 0.000 (0.008)\tLoss 1.4869 (1.7541)\tPrec@1 91.406 (90.946)\tPrec@5 99.609 (99.398)\n",
            "Epoch: [75][290/329], lr: 0.01000\tTime 0.086 (0.090)\tData 0.005 (0.008)\tLoss 1.8787 (1.7550)\tPrec@1 91.406 (90.963)\tPrec@5 99.609 (99.404)\n",
            "Epoch: [75][300/329], lr: 0.01000\tTime 0.090 (0.090)\tData 0.004 (0.008)\tLoss 1.3864 (1.7544)\tPrec@1 92.188 (90.959)\tPrec@5 100.000 (99.415)\n",
            "Epoch: [75][310/329], lr: 0.01000\tTime 0.089 (0.090)\tData 0.000 (0.008)\tLoss 2.0336 (1.7508)\tPrec@1 90.625 (90.991)\tPrec@5 99.609 (99.425)\n",
            "Epoch: [75][320/329], lr: 0.01000\tTime 0.200 (0.090)\tData 0.109 (0.008)\tLoss 1.7689 (1.7476)\tPrec@1 91.016 (91.002)\tPrec@5 99.609 (99.429)\n",
            "Test: [0/100]\tTime 0.467 (0.467)\tLoss 4.5383 (4.5383)\tPrec@1 77.000 (77.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.035 (0.085)\tLoss 4.0553 (5.1407)\tPrec@1 81.000 (75.909)\tPrec@5 98.000 (98.818)\n",
            "Test: [20/100]\tTime 0.027 (0.063)\tLoss 4.6098 (4.9624)\tPrec@1 78.000 (76.524)\tPrec@5 96.000 (98.381)\n",
            "Test: [30/100]\tTime 0.033 (0.055)\tLoss 4.8394 (5.0456)\tPrec@1 77.000 (76.452)\tPrec@5 99.000 (98.065)\n",
            "Test: [40/100]\tTime 0.031 (0.050)\tLoss 5.1410 (5.1462)\tPrec@1 76.000 (76.171)\tPrec@5 97.000 (97.829)\n",
            "Test: [50/100]\tTime 0.044 (0.047)\tLoss 5.4910 (5.1573)\tPrec@1 74.000 (76.059)\tPrec@5 96.000 (97.922)\n",
            "Test: [60/100]\tTime 0.016 (0.042)\tLoss 5.3028 (5.2454)\tPrec@1 75.000 (75.475)\tPrec@5 99.000 (98.000)\n",
            "Test: [70/100]\tTime 0.028 (0.040)\tLoss 3.7478 (5.2583)\tPrec@1 82.000 (75.366)\tPrec@5 98.000 (98.000)\n",
            "Test: [80/100]\tTime 0.043 (0.038)\tLoss 4.3825 (5.2111)\tPrec@1 80.000 (75.580)\tPrec@5 100.000 (98.025)\n",
            "Test: [90/100]\tTime 0.023 (0.037)\tLoss 4.2726 (5.2960)\tPrec@1 84.000 (75.187)\tPrec@5 100.000 (98.022)\n",
            "val Results: Prec@1 75.040 Prec@5 98.000 Loss 5.32707\n",
            "val Class Accuracy: [0.930,0.929,0.852,0.566,0.612,0.567,0.844,0.782,0.716,0.706]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [76][0/329], lr: 0.01000\tTime 0.629 (0.629)\tData 0.545 (0.545)\tLoss 1.6582 (1.6582)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [76][10/329], lr: 0.01000\tTime 0.092 (0.150)\tData 0.002 (0.056)\tLoss 2.6875 (2.7089)\tPrec@1 86.328 (85.938)\tPrec@5 98.438 (98.899)\n",
            "Epoch: [76][20/329], lr: 0.01000\tTime 0.069 (0.122)\tData 0.000 (0.032)\tLoss 1.7840 (2.5239)\tPrec@1 91.406 (86.830)\tPrec@5 99.219 (98.698)\n",
            "Epoch: [76][30/329], lr: 0.01000\tTime 0.090 (0.114)\tData 0.006 (0.024)\tLoss 1.8794 (2.3411)\tPrec@1 91.406 (87.840)\tPrec@5 99.219 (98.904)\n",
            "Epoch: [76][40/329], lr: 0.01000\tTime 0.083 (0.107)\tData 0.000 (0.020)\tLoss 2.4126 (2.2763)\tPrec@1 89.062 (88.205)\tPrec@5 99.219 (99.000)\n",
            "Epoch: [76][50/329], lr: 0.01000\tTime 0.071 (0.103)\tData 0.000 (0.018)\tLoss 1.8357 (2.1849)\tPrec@1 89.453 (88.680)\tPrec@5 99.609 (99.066)\n",
            "Epoch: [76][60/329], lr: 0.01000\tTime 0.106 (0.101)\tData 0.005 (0.016)\tLoss 1.6845 (2.1246)\tPrec@1 91.016 (89.005)\tPrec@5 99.609 (99.135)\n",
            "Epoch: [76][70/329], lr: 0.01000\tTime 0.083 (0.099)\tData 0.000 (0.014)\tLoss 1.1322 (2.0795)\tPrec@1 93.359 (89.288)\tPrec@5 98.828 (99.186)\n",
            "Epoch: [76][80/329], lr: 0.01000\tTime 0.078 (0.098)\tData 0.005 (0.014)\tLoss 1.6760 (2.0397)\tPrec@1 90.234 (89.482)\tPrec@5 99.219 (99.214)\n",
            "Epoch: [76][90/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.000 (0.013)\tLoss 1.7103 (2.0295)\tPrec@1 91.016 (89.548)\tPrec@5 100.000 (99.262)\n",
            "Epoch: [76][100/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.006 (0.012)\tLoss 2.0382 (2.0077)\tPrec@1 89.062 (89.635)\tPrec@5 99.219 (99.254)\n",
            "Epoch: [76][110/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.011 (0.012)\tLoss 1.3142 (1.9814)\tPrec@1 92.578 (89.738)\tPrec@5 98.828 (99.268)\n",
            "Epoch: [76][120/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.000 (0.011)\tLoss 2.8481 (1.9728)\tPrec@1 84.766 (89.769)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [76][130/329], lr: 0.01000\tTime 0.078 (0.094)\tData 0.000 (0.011)\tLoss 1.4299 (1.9462)\tPrec@1 93.359 (89.918)\tPrec@5 99.219 (99.311)\n",
            "Epoch: [76][140/329], lr: 0.01000\tTime 0.078 (0.094)\tData 0.000 (0.011)\tLoss 2.0876 (1.9429)\tPrec@1 89.844 (89.941)\tPrec@5 99.609 (99.321)\n",
            "Epoch: [76][150/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 2.1637 (1.9343)\tPrec@1 89.062 (89.999)\tPrec@5 98.047 (99.304)\n",
            "Epoch: [76][160/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.012 (0.010)\tLoss 1.3756 (1.9208)\tPrec@1 92.969 (90.045)\tPrec@5 100.000 (99.311)\n",
            "Epoch: [76][170/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.006 (0.010)\tLoss 1.3592 (1.9036)\tPrec@1 92.578 (90.154)\tPrec@5 100.000 (99.335)\n",
            "Epoch: [76][180/329], lr: 0.01000\tTime 0.100 (0.093)\tData 0.003 (0.010)\tLoss 1.8493 (1.9013)\tPrec@1 91.016 (90.178)\tPrec@5 100.000 (99.337)\n",
            "Epoch: [76][190/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.010)\tLoss 1.6773 (1.9054)\tPrec@1 92.578 (90.161)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [76][200/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.005 (0.010)\tLoss 1.6504 (1.8962)\tPrec@1 91.797 (90.232)\tPrec@5 99.219 (99.353)\n",
            "Epoch: [76][210/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.008 (0.010)\tLoss 1.9939 (1.8857)\tPrec@1 89.844 (90.283)\tPrec@5 98.047 (99.365)\n",
            "Epoch: [76][220/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.004 (0.009)\tLoss 2.0255 (1.8775)\tPrec@1 88.281 (90.307)\tPrec@5 98.828 (99.364)\n",
            "Epoch: [76][230/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.005 (0.009)\tLoss 1.5963 (1.8681)\tPrec@1 91.016 (90.358)\tPrec@5 99.609 (99.371)\n",
            "Epoch: [76][240/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.000 (0.009)\tLoss 1.3201 (1.8584)\tPrec@1 92.969 (90.401)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [76][250/329], lr: 0.01000\tTime 0.116 (0.092)\tData 0.003 (0.009)\tLoss 1.7868 (1.8541)\tPrec@1 90.625 (90.435)\tPrec@5 99.609 (99.371)\n",
            "Epoch: [76][260/329], lr: 0.01000\tTime 0.116 (0.092)\tData 0.001 (0.009)\tLoss 1.8130 (1.8526)\tPrec@1 89.453 (90.438)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [76][270/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.006 (0.009)\tLoss 1.5036 (1.8514)\tPrec@1 93.750 (90.461)\tPrec@5 99.219 (99.380)\n",
            "Epoch: [76][280/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.000 (0.009)\tLoss 2.0738 (1.8509)\tPrec@1 89.844 (90.483)\tPrec@5 99.609 (99.370)\n",
            "Epoch: [76][290/329], lr: 0.01000\tTime 0.069 (0.091)\tData 0.000 (0.009)\tLoss 1.5308 (1.8461)\tPrec@1 92.969 (90.508)\tPrec@5 99.609 (99.374)\n",
            "Epoch: [76][300/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.009 (0.009)\tLoss 1.5024 (1.8426)\tPrec@1 92.188 (90.522)\tPrec@5 98.828 (99.376)\n",
            "Epoch: [76][310/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 1.8232 (1.8387)\tPrec@1 90.625 (90.531)\tPrec@5 99.609 (99.380)\n",
            "Epoch: [76][320/329], lr: 0.01000\tTime 0.076 (0.091)\tData 0.034 (0.009)\tLoss 1.9007 (1.8457)\tPrec@1 91.016 (90.508)\tPrec@5 100.000 (99.383)\n",
            "Test: [0/100]\tTime 0.369 (0.369)\tLoss 6.9580 (6.9580)\tPrec@1 69.000 (69.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.019 (0.061)\tLoss 5.3125 (6.5263)\tPrec@1 76.000 (70.182)\tPrec@5 96.000 (96.636)\n",
            "Test: [20/100]\tTime 0.035 (0.043)\tLoss 5.4679 (6.4461)\tPrec@1 78.000 (71.000)\tPrec@5 98.000 (96.429)\n",
            "Test: [30/100]\tTime 0.032 (0.035)\tLoss 6.3295 (6.4276)\tPrec@1 69.000 (70.419)\tPrec@5 98.000 (96.581)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 6.8702 (6.3930)\tPrec@1 67.000 (70.610)\tPrec@5 95.000 (96.537)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 5.4592 (6.3711)\tPrec@1 75.000 (70.706)\tPrec@5 97.000 (96.667)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 6.0329 (6.4619)\tPrec@1 68.000 (70.213)\tPrec@5 98.000 (96.721)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 6.7517 (6.4897)\tPrec@1 69.000 (70.155)\tPrec@5 98.000 (96.676)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 5.6306 (6.4395)\tPrec@1 73.000 (70.284)\tPrec@5 97.000 (96.716)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 6.0857 (6.4885)\tPrec@1 74.000 (70.033)\tPrec@5 98.000 (96.637)\n",
            "val Results: Prec@1 70.000 Prec@5 96.540 Loss 6.51889\n",
            "val Class Accuracy: [0.983,0.903,0.782,0.538,0.744,0.699,0.659,0.486,0.505,0.701]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [77][0/329], lr: 0.01000\tTime 0.630 (0.630)\tData 0.558 (0.558)\tLoss 1.6371 (1.6371)\tPrec@1 92.188 (92.188)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [77][10/329], lr: 0.01000\tTime 0.085 (0.140)\tData 0.003 (0.057)\tLoss 2.7852 (3.0020)\tPrec@1 86.719 (83.878)\tPrec@5 98.438 (98.082)\n",
            "Epoch: [77][20/329], lr: 0.01000\tTime 0.101 (0.118)\tData 0.007 (0.032)\tLoss 2.0055 (2.7594)\tPrec@1 89.844 (85.454)\tPrec@5 99.609 (98.084)\n",
            "Epoch: [77][30/329], lr: 0.01000\tTime 0.068 (0.107)\tData 0.007 (0.024)\tLoss 3.1668 (2.6376)\tPrec@1 83.203 (86.076)\tPrec@5 98.438 (98.425)\n",
            "Epoch: [77][40/329], lr: 0.01000\tTime 0.096 (0.103)\tData 0.010 (0.020)\tLoss 1.8266 (2.5175)\tPrec@1 90.625 (86.738)\tPrec@5 99.609 (98.571)\n",
            "Epoch: [77][50/329], lr: 0.01000\tTime 0.066 (0.101)\tData 0.000 (0.017)\tLoss 1.3526 (2.3850)\tPrec@1 94.141 (87.508)\tPrec@5 99.609 (98.759)\n",
            "Epoch: [77][60/329], lr: 0.01000\tTime 0.117 (0.100)\tData 0.000 (0.015)\tLoss 1.3254 (2.2594)\tPrec@1 91.797 (88.185)\tPrec@5 99.219 (98.879)\n",
            "Epoch: [77][70/329], lr: 0.01000\tTime 0.106 (0.101)\tData 0.000 (0.014)\tLoss 1.7440 (2.1912)\tPrec@1 90.625 (88.567)\tPrec@5 98.828 (98.944)\n",
            "Epoch: [77][80/329], lr: 0.01000\tTime 0.162 (0.103)\tData 0.008 (0.013)\tLoss 1.6767 (2.1533)\tPrec@1 92.188 (88.788)\tPrec@5 99.609 (98.978)\n",
            "Epoch: [77][90/329], lr: 0.01000\tTime 0.115 (0.105)\tData 0.000 (0.014)\tLoss 2.1096 (2.1164)\tPrec@1 88.281 (88.990)\tPrec@5 98.438 (99.030)\n",
            "Epoch: [77][100/329], lr: 0.01000\tTime 0.103 (0.105)\tData 0.005 (0.014)\tLoss 1.9245 (2.0858)\tPrec@1 90.234 (89.155)\tPrec@5 99.219 (99.072)\n",
            "Epoch: [77][110/329], lr: 0.01000\tTime 0.075 (0.104)\tData 0.002 (0.014)\tLoss 1.7375 (2.0632)\tPrec@1 91.016 (89.302)\tPrec@5 99.609 (99.106)\n",
            "Epoch: [77][120/329], lr: 0.01000\tTime 0.078 (0.103)\tData 0.000 (0.013)\tLoss 1.9598 (2.0458)\tPrec@1 90.234 (89.395)\tPrec@5 99.609 (99.132)\n",
            "Epoch: [77][130/329], lr: 0.01000\tTime 0.096 (0.102)\tData 0.013 (0.012)\tLoss 1.5172 (2.0286)\tPrec@1 90.625 (89.480)\tPrec@5 99.609 (99.138)\n",
            "Epoch: [77][140/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.006 (0.012)\tLoss 2.2836 (2.0141)\tPrec@1 88.281 (89.578)\tPrec@5 98.047 (99.133)\n",
            "Epoch: [77][150/329], lr: 0.01000\tTime 0.070 (0.100)\tData 0.000 (0.012)\tLoss 1.9641 (1.9964)\tPrec@1 91.016 (89.689)\tPrec@5 98.828 (99.146)\n",
            "Epoch: [77][160/329], lr: 0.01000\tTime 0.097 (0.099)\tData 0.005 (0.011)\tLoss 1.6828 (1.9802)\tPrec@1 91.797 (89.769)\tPrec@5 100.000 (99.173)\n",
            "Epoch: [77][170/329], lr: 0.01000\tTime 0.069 (0.098)\tData 0.000 (0.011)\tLoss 1.5561 (1.9702)\tPrec@1 92.578 (89.803)\tPrec@5 99.609 (99.194)\n",
            "Epoch: [77][180/329], lr: 0.01000\tTime 0.063 (0.097)\tData 0.000 (0.011)\tLoss 2.0070 (1.9633)\tPrec@1 88.672 (89.842)\tPrec@5 99.609 (99.210)\n",
            "Epoch: [77][190/329], lr: 0.01000\tTime 0.085 (0.097)\tData 0.000 (0.011)\tLoss 2.1367 (1.9528)\tPrec@1 88.672 (89.901)\tPrec@5 98.828 (99.227)\n",
            "Epoch: [77][200/329], lr: 0.01000\tTime 0.095 (0.096)\tData 0.006 (0.011)\tLoss 1.5789 (1.9353)\tPrec@1 91.016 (89.968)\tPrec@5 98.828 (99.232)\n",
            "Epoch: [77][210/329], lr: 0.01000\tTime 0.077 (0.096)\tData 0.005 (0.010)\tLoss 1.6218 (1.9266)\tPrec@1 91.797 (90.031)\tPrec@5 99.219 (99.256)\n",
            "Epoch: [77][220/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.007 (0.010)\tLoss 2.0303 (1.9239)\tPrec@1 90.234 (90.051)\tPrec@5 99.609 (99.265)\n",
            "Epoch: [77][230/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.004 (0.010)\tLoss 1.9017 (1.9152)\tPrec@1 90.625 (90.099)\tPrec@5 99.609 (99.278)\n",
            "Epoch: [77][240/329], lr: 0.01000\tTime 0.075 (0.095)\tData 0.014 (0.010)\tLoss 1.5099 (1.9115)\tPrec@1 91.797 (90.095)\tPrec@5 99.609 (99.280)\n",
            "Epoch: [77][250/329], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.010)\tLoss 2.0146 (1.9065)\tPrec@1 91.016 (90.129)\tPrec@5 98.047 (99.286)\n",
            "Epoch: [77][260/329], lr: 0.01000\tTime 0.095 (0.094)\tData 0.007 (0.010)\tLoss 1.7104 (1.9020)\tPrec@1 91.406 (90.146)\tPrec@5 99.609 (99.295)\n",
            "Epoch: [77][270/329], lr: 0.01000\tTime 0.099 (0.094)\tData 0.009 (0.010)\tLoss 2.1001 (1.9050)\tPrec@1 88.281 (90.121)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [77][280/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.000 (0.010)\tLoss 1.5207 (1.8947)\tPrec@1 93.359 (90.177)\tPrec@5 99.609 (99.305)\n",
            "Epoch: [77][290/329], lr: 0.01000\tTime 0.088 (0.093)\tData 0.007 (0.010)\tLoss 1.5519 (1.8882)\tPrec@1 92.188 (90.218)\tPrec@5 99.219 (99.317)\n",
            "Epoch: [77][300/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 1.6691 (1.8835)\tPrec@1 91.016 (90.232)\tPrec@5 99.609 (99.329)\n",
            "Epoch: [77][310/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.005 (0.010)\tLoss 1.4861 (1.8785)\tPrec@1 93.359 (90.268)\tPrec@5 99.609 (99.336)\n",
            "Epoch: [77][320/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.057 (0.010)\tLoss 2.1415 (1.8763)\tPrec@1 89.453 (90.289)\tPrec@5 98.828 (99.345)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 6.1214 (6.1214)\tPrec@1 71.000 (71.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.018 (0.059)\tLoss 5.3191 (5.8168)\tPrec@1 77.000 (73.000)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/100]\tTime 0.022 (0.043)\tLoss 5.6080 (5.6877)\tPrec@1 71.000 (73.429)\tPrec@5 99.000 (97.286)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 6.3854 (5.6887)\tPrec@1 71.000 (73.419)\tPrec@5 96.000 (97.226)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 4.9311 (5.5817)\tPrec@1 77.000 (73.854)\tPrec@5 99.000 (97.268)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 6.2615 (5.5527)\tPrec@1 70.000 (73.882)\tPrec@5 95.000 (97.333)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 5.8992 (5.6836)\tPrec@1 76.000 (73.361)\tPrec@5 99.000 (97.344)\n",
            "Test: [70/100]\tTime 0.009 (0.029)\tLoss 5.3175 (5.7063)\tPrec@1 75.000 (73.338)\tPrec@5 99.000 (97.423)\n",
            "Test: [80/100]\tTime 0.014 (0.027)\tLoss 4.5017 (5.6764)\tPrec@1 78.000 (73.519)\tPrec@5 99.000 (97.481)\n",
            "Test: [90/100]\tTime 0.035 (0.028)\tLoss 4.8308 (5.7320)\tPrec@1 76.000 (73.264)\tPrec@5 99.000 (97.451)\n",
            "val Results: Prec@1 73.380 Prec@5 97.460 Loss 5.72787\n",
            "val Class Accuracy: [0.852,0.940,0.853,0.689,0.910,0.574,0.372,0.609,0.709,0.830]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [78][0/329], lr: 0.01000\tTime 0.454 (0.454)\tData 0.381 (0.381)\tLoss 1.5796 (1.5796)\tPrec@1 92.188 (92.188)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [78][10/329], lr: 0.01000\tTime 0.095 (0.140)\tData 0.000 (0.052)\tLoss 1.7102 (1.7898)\tPrec@1 92.188 (90.945)\tPrec@5 98.828 (99.396)\n",
            "Epoch: [78][20/329], lr: 0.01000\tTime 0.105 (0.117)\tData 0.000 (0.030)\tLoss 1.9036 (1.7746)\tPrec@1 91.797 (91.276)\tPrec@5 99.219 (99.405)\n",
            "Epoch: [78][30/329], lr: 0.01000\tTime 0.083 (0.107)\tData 0.010 (0.024)\tLoss 1.9187 (1.7375)\tPrec@1 91.016 (91.318)\tPrec@5 99.609 (99.395)\n",
            "Epoch: [78][40/329], lr: 0.01000\tTime 0.081 (0.102)\tData 0.002 (0.019)\tLoss 2.3025 (1.7566)\tPrec@1 88.672 (91.225)\tPrec@5 99.609 (99.447)\n",
            "Epoch: [78][50/329], lr: 0.01000\tTime 0.091 (0.099)\tData 0.007 (0.017)\tLoss 1.8775 (1.7599)\tPrec@1 90.625 (91.092)\tPrec@5 99.609 (99.456)\n",
            "Epoch: [78][60/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.007 (0.016)\tLoss 1.7245 (1.7398)\tPrec@1 92.578 (91.144)\tPrec@5 99.609 (99.468)\n",
            "Epoch: [78][70/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.007 (0.014)\tLoss 1.8505 (1.7500)\tPrec@1 91.016 (91.109)\tPrec@5 100.000 (99.472)\n",
            "Epoch: [78][80/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.004 (0.014)\tLoss 2.1426 (1.7523)\tPrec@1 88.281 (91.078)\tPrec@5 98.828 (99.465)\n",
            "Epoch: [78][90/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.004 (0.013)\tLoss 1.6582 (1.7483)\tPrec@1 91.797 (91.067)\tPrec@5 99.609 (99.459)\n",
            "Epoch: [78][100/329], lr: 0.01000\tTime 0.109 (0.093)\tData 0.006 (0.012)\tLoss 1.6963 (1.7413)\tPrec@1 90.625 (91.070)\tPrec@5 99.609 (99.486)\n",
            "Epoch: [78][110/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.008 (0.012)\tLoss 1.6896 (1.7493)\tPrec@1 91.406 (91.040)\tPrec@5 99.609 (99.476)\n",
            "Epoch: [78][120/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.003 (0.011)\tLoss 1.9209 (1.7567)\tPrec@1 90.625 (90.983)\tPrec@5 99.609 (99.487)\n",
            "Epoch: [78][130/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.006 (0.011)\tLoss 2.0535 (1.7590)\tPrec@1 88.281 (90.959)\tPrec@5 99.219 (99.490)\n",
            "Epoch: [78][140/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.006 (0.011)\tLoss 1.1114 (1.7477)\tPrec@1 94.922 (91.029)\tPrec@5 100.000 (99.485)\n",
            "Epoch: [78][150/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.006 (0.011)\tLoss 1.7261 (1.7459)\tPrec@1 91.406 (91.036)\tPrec@5 99.609 (99.493)\n",
            "Epoch: [78][160/329], lr: 0.01000\tTime 0.093 (0.091)\tData 0.004 (0.010)\tLoss 1.1452 (1.7386)\tPrec@1 93.359 (91.054)\tPrec@5 99.219 (99.483)\n",
            "Epoch: [78][170/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.000 (0.010)\tLoss 1.6632 (1.7359)\tPrec@1 91.797 (91.100)\tPrec@5 99.609 (99.484)\n",
            "Epoch: [78][180/329], lr: 0.01000\tTime 0.143 (0.092)\tData 0.010 (0.010)\tLoss 1.3891 (1.7330)\tPrec@1 92.969 (91.093)\tPrec@5 99.609 (99.486)\n",
            "Epoch: [78][190/329], lr: 0.01000\tTime 0.090 (0.093)\tData 0.008 (0.010)\tLoss 1.3695 (1.7253)\tPrec@1 93.359 (91.142)\tPrec@5 98.828 (99.483)\n",
            "Epoch: [78][200/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.044 (0.011)\tLoss 2.0817 (1.7329)\tPrec@1 89.844 (91.088)\tPrec@5 98.828 (99.473)\n",
            "Epoch: [78][210/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.005 (0.011)\tLoss 1.7634 (1.7442)\tPrec@1 89.844 (90.997)\tPrec@5 99.219 (99.472)\n",
            "Epoch: [78][220/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.003 (0.010)\tLoss 1.5410 (1.7405)\tPrec@1 91.016 (91.014)\tPrec@5 99.219 (99.472)\n",
            "Epoch: [78][230/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.006 (0.010)\tLoss 1.4828 (1.7323)\tPrec@1 92.188 (91.056)\tPrec@5 99.609 (99.477)\n",
            "Epoch: [78][240/329], lr: 0.01000\tTime 0.117 (0.095)\tData 0.000 (0.010)\tLoss 1.6179 (1.7312)\tPrec@1 91.797 (91.053)\tPrec@5 99.219 (99.476)\n",
            "Epoch: [78][250/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.000 (0.010)\tLoss 1.8986 (1.7312)\tPrec@1 89.844 (91.064)\tPrec@5 99.609 (99.486)\n",
            "Epoch: [78][260/329], lr: 0.01000\tTime 0.074 (0.094)\tData 0.010 (0.010)\tLoss 1.6088 (1.7314)\tPrec@1 91.406 (91.083)\tPrec@5 99.609 (99.484)\n",
            "Epoch: [78][270/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.007 (0.010)\tLoss 1.2632 (1.7294)\tPrec@1 94.531 (91.102)\tPrec@5 100.000 (99.484)\n",
            "Epoch: [78][280/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.000 (0.010)\tLoss 1.8545 (1.7346)\tPrec@1 91.797 (91.080)\tPrec@5 99.219 (99.473)\n",
            "Epoch: [78][290/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.006 (0.010)\tLoss 1.7267 (1.7327)\tPrec@1 91.016 (91.077)\tPrec@5 99.609 (99.475)\n",
            "Epoch: [78][300/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.012 (0.010)\tLoss 1.4665 (1.7331)\tPrec@1 92.969 (91.077)\tPrec@5 99.609 (99.465)\n",
            "Epoch: [78][310/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.010)\tLoss 1.8623 (1.7357)\tPrec@1 89.844 (91.063)\tPrec@5 99.609 (99.452)\n",
            "Epoch: [78][320/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.038 (0.010)\tLoss 1.9478 (1.7308)\tPrec@1 89.844 (91.100)\tPrec@5 99.219 (99.457)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 5.0497 (5.0497)\tPrec@1 78.000 (78.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.026 (0.053)\tLoss 4.4884 (5.5813)\tPrec@1 77.000 (75.636)\tPrec@5 98.000 (97.091)\n",
            "Test: [20/100]\tTime 0.030 (0.039)\tLoss 4.4614 (5.3370)\tPrec@1 81.000 (76.524)\tPrec@5 99.000 (97.238)\n",
            "Test: [30/100]\tTime 0.025 (0.034)\tLoss 6.4293 (5.5538)\tPrec@1 71.000 (75.452)\tPrec@5 99.000 (97.258)\n",
            "Test: [40/100]\tTime 0.025 (0.031)\tLoss 6.0630 (5.6617)\tPrec@1 73.000 (74.927)\tPrec@5 95.000 (97.073)\n",
            "Test: [50/100]\tTime 0.034 (0.030)\tLoss 6.4382 (5.6038)\tPrec@1 73.000 (75.059)\tPrec@5 94.000 (96.941)\n",
            "Test: [60/100]\tTime 0.037 (0.029)\tLoss 4.9325 (5.6727)\tPrec@1 77.000 (74.607)\tPrec@5 99.000 (97.115)\n",
            "Test: [70/100]\tTime 0.024 (0.028)\tLoss 5.5372 (5.6215)\tPrec@1 73.000 (74.732)\tPrec@5 97.000 (97.155)\n",
            "Test: [80/100]\tTime 0.021 (0.027)\tLoss 4.7292 (5.5759)\tPrec@1 81.000 (74.938)\tPrec@5 97.000 (97.136)\n",
            "Test: [90/100]\tTime 0.030 (0.027)\tLoss 4.7997 (5.6109)\tPrec@1 79.000 (74.681)\tPrec@5 99.000 (97.088)\n",
            "val Results: Prec@1 74.570 Prec@5 97.090 Loss 5.64399\n",
            "val Class Accuracy: [0.914,0.921,0.882,0.683,0.663,0.724,0.894,0.399,0.688,0.689]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [79][0/329], lr: 0.01000\tTime 0.621 (0.621)\tData 0.541 (0.541)\tLoss 1.6940 (1.6940)\tPrec@1 91.797 (91.797)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [79][10/329], lr: 0.01000\tTime 0.076 (0.142)\tData 0.000 (0.056)\tLoss 2.0968 (2.0405)\tPrec@1 89.453 (89.347)\tPrec@5 98.438 (98.935)\n",
            "Epoch: [79][20/329], lr: 0.01000\tTime 0.080 (0.119)\tData 0.000 (0.032)\tLoss 1.8848 (2.0439)\tPrec@1 90.234 (89.472)\tPrec@5 98.828 (99.051)\n",
            "Epoch: [79][30/329], lr: 0.01000\tTime 0.088 (0.109)\tData 0.006 (0.024)\tLoss 1.7150 (2.0301)\tPrec@1 92.188 (89.604)\tPrec@5 99.609 (99.206)\n",
            "Epoch: [79][40/329], lr: 0.01000\tTime 0.096 (0.103)\tData 0.000 (0.020)\tLoss 1.6207 (1.9729)\tPrec@1 91.406 (89.910)\tPrec@5 98.828 (99.209)\n",
            "Epoch: [79][50/329], lr: 0.01000\tTime 0.085 (0.100)\tData 0.001 (0.017)\tLoss 1.9839 (1.9702)\tPrec@1 90.234 (89.867)\tPrec@5 99.609 (99.265)\n",
            "Epoch: [79][60/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.000 (0.015)\tLoss 1.6722 (1.9306)\tPrec@1 91.797 (90.087)\tPrec@5 99.609 (99.296)\n",
            "Epoch: [79][70/329], lr: 0.01000\tTime 0.093 (0.096)\tData 0.000 (0.014)\tLoss 1.6905 (1.8981)\tPrec@1 92.188 (90.322)\tPrec@5 98.828 (99.345)\n",
            "Epoch: [79][80/329], lr: 0.01000\tTime 0.102 (0.094)\tData 0.004 (0.013)\tLoss 1.3949 (1.8879)\tPrec@1 92.969 (90.355)\tPrec@5 99.219 (99.349)\n",
            "Epoch: [79][90/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.005 (0.012)\tLoss 2.0335 (1.8722)\tPrec@1 90.625 (90.389)\tPrec@5 100.000 (99.369)\n",
            "Epoch: [79][100/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.007 (0.012)\tLoss 1.3259 (1.8587)\tPrec@1 92.969 (90.439)\tPrec@5 99.609 (99.373)\n",
            "Epoch: [79][110/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.000 (0.011)\tLoss 1.6494 (1.8642)\tPrec@1 92.578 (90.400)\tPrec@5 99.219 (99.384)\n",
            "Epoch: [79][120/329], lr: 0.01000\tTime 0.092 (0.093)\tData 0.007 (0.011)\tLoss 1.9433 (1.8382)\tPrec@1 90.625 (90.551)\tPrec@5 100.000 (99.393)\n",
            "Epoch: [79][130/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.005 (0.010)\tLoss 1.8693 (1.8246)\tPrec@1 89.453 (90.613)\tPrec@5 99.219 (99.410)\n",
            "Epoch: [79][140/329], lr: 0.01000\tTime 0.097 (0.092)\tData 0.007 (0.010)\tLoss 2.6737 (1.8240)\tPrec@1 86.328 (90.595)\tPrec@5 99.219 (99.421)\n",
            "Epoch: [79][150/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.005 (0.010)\tLoss 1.2661 (1.8167)\tPrec@1 93.359 (90.620)\tPrec@5 100.000 (99.421)\n",
            "Epoch: [79][160/329], lr: 0.01000\tTime 0.084 (0.091)\tData 0.001 (0.010)\tLoss 1.3087 (1.8046)\tPrec@1 92.578 (90.691)\tPrec@5 98.438 (99.423)\n",
            "Epoch: [79][170/329], lr: 0.01000\tTime 0.071 (0.091)\tData 0.000 (0.010)\tLoss 1.5374 (1.7962)\tPrec@1 92.578 (90.748)\tPrec@5 100.000 (99.422)\n",
            "Epoch: [79][180/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.000 (0.009)\tLoss 1.2697 (1.7894)\tPrec@1 92.578 (90.767)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [79][190/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.000 (0.009)\tLoss 1.2434 (1.7798)\tPrec@1 92.578 (90.789)\tPrec@5 99.609 (99.431)\n",
            "Epoch: [79][200/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.001 (0.009)\tLoss 1.4399 (1.7726)\tPrec@1 92.188 (90.839)\tPrec@5 99.609 (99.429)\n",
            "Epoch: [79][210/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.007 (0.009)\tLoss 2.1173 (1.7672)\tPrec@1 88.672 (90.868)\tPrec@5 100.000 (99.437)\n",
            "Epoch: [79][220/329], lr: 0.01000\tTime 0.097 (0.091)\tData 0.000 (0.009)\tLoss 1.5873 (1.7604)\tPrec@1 91.797 (90.903)\tPrec@5 99.609 (99.434)\n",
            "Epoch: [79][230/329], lr: 0.01000\tTime 0.110 (0.090)\tData 0.009 (0.009)\tLoss 1.9232 (1.7517)\tPrec@1 90.625 (90.963)\tPrec@5 98.828 (99.434)\n",
            "Epoch: [79][240/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.007 (0.009)\tLoss 2.3577 (1.7568)\tPrec@1 87.891 (90.941)\tPrec@5 99.609 (99.436)\n",
            "Epoch: [79][250/329], lr: 0.01000\tTime 0.077 (0.090)\tData 0.006 (0.009)\tLoss 1.7487 (1.7601)\tPrec@1 91.406 (90.950)\tPrec@5 100.000 (99.435)\n",
            "Epoch: [79][260/329], lr: 0.01000\tTime 0.082 (0.090)\tData 0.000 (0.009)\tLoss 1.8419 (1.7622)\tPrec@1 90.625 (90.929)\tPrec@5 99.219 (99.439)\n",
            "Epoch: [79][270/329], lr: 0.01000\tTime 0.115 (0.090)\tData 0.014 (0.009)\tLoss 1.9151 (1.7649)\tPrec@1 90.234 (90.925)\tPrec@5 99.219 (99.434)\n",
            "Epoch: [79][280/329], lr: 0.01000\tTime 0.112 (0.090)\tData 0.009 (0.008)\tLoss 2.2768 (1.7677)\tPrec@1 87.500 (90.899)\tPrec@5 98.438 (99.424)\n",
            "Epoch: [79][290/329], lr: 0.01000\tTime 0.108 (0.090)\tData 0.010 (0.008)\tLoss 1.8275 (1.7647)\tPrec@1 90.234 (90.904)\tPrec@5 99.609 (99.420)\n",
            "Epoch: [79][300/329], lr: 0.01000\tTime 0.120 (0.090)\tData 0.005 (0.008)\tLoss 2.1469 (1.7668)\tPrec@1 89.062 (90.900)\tPrec@5 98.828 (99.426)\n",
            "Epoch: [79][310/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.000 (0.008)\tLoss 1.6021 (1.7751)\tPrec@1 91.797 (90.855)\tPrec@5 99.219 (99.412)\n",
            "Epoch: [79][320/329], lr: 0.01000\tTime 0.279 (0.092)\tData 0.180 (0.009)\tLoss 1.8154 (1.7709)\tPrec@1 91.016 (90.881)\tPrec@5 98.828 (99.417)\n",
            "Test: [0/100]\tTime 0.451 (0.451)\tLoss 6.4470 (6.4470)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.066)\tLoss 6.4335 (6.7701)\tPrec@1 70.000 (68.545)\tPrec@5 94.000 (96.182)\n",
            "Test: [20/100]\tTime 0.030 (0.047)\tLoss 4.9397 (6.5492)\tPrec@1 76.000 (70.095)\tPrec@5 98.000 (96.476)\n",
            "Test: [30/100]\tTime 0.023 (0.038)\tLoss 6.0406 (6.5712)\tPrec@1 71.000 (69.839)\tPrec@5 98.000 (96.484)\n",
            "Test: [40/100]\tTime 0.026 (0.036)\tLoss 5.3143 (6.5070)\tPrec@1 77.000 (70.268)\tPrec@5 95.000 (96.366)\n",
            "Test: [50/100]\tTime 0.021 (0.033)\tLoss 6.8860 (6.4950)\tPrec@1 66.000 (70.373)\tPrec@5 97.000 (96.412)\n",
            "Test: [60/100]\tTime 0.023 (0.032)\tLoss 5.8390 (6.4860)\tPrec@1 73.000 (70.459)\tPrec@5 99.000 (96.590)\n",
            "Test: [70/100]\tTime 0.015 (0.031)\tLoss 5.6028 (6.5061)\tPrec@1 74.000 (70.155)\tPrec@5 98.000 (96.592)\n",
            "Test: [80/100]\tTime 0.013 (0.030)\tLoss 4.4274 (6.4430)\tPrec@1 79.000 (70.395)\tPrec@5 99.000 (96.642)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 5.3547 (6.4949)\tPrec@1 73.000 (70.165)\tPrec@5 99.000 (96.571)\n",
            "val Results: Prec@1 70.210 Prec@5 96.520 Loss 6.50628\n",
            "val Class Accuracy: [0.733,0.995,0.864,0.372,0.671,0.728,0.609,0.791,0.759,0.499]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [80][0/329], lr: 0.01000\tTime 0.635 (0.635)\tData 0.531 (0.531)\tLoss 1.6872 (1.6872)\tPrec@1 91.406 (91.406)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [80][10/329], lr: 0.01000\tTime 0.082 (0.142)\tData 0.000 (0.051)\tLoss 3.1782 (3.2031)\tPrec@1 83.203 (83.558)\tPrec@5 98.438 (97.443)\n",
            "Epoch: [80][20/329], lr: 0.01000\tTime 0.103 (0.120)\tData 0.000 (0.032)\tLoss 1.9985 (2.8875)\tPrec@1 89.453 (85.324)\tPrec@5 99.219 (98.103)\n",
            "Epoch: [80][30/329], lr: 0.01000\tTime 0.109 (0.110)\tData 0.007 (0.024)\tLoss 2.7130 (2.6623)\tPrec@1 84.766 (86.303)\tPrec@5 97.656 (98.299)\n",
            "Epoch: [80][40/329], lr: 0.01000\tTime 0.089 (0.104)\tData 0.005 (0.020)\tLoss 1.6779 (2.5461)\tPrec@1 91.406 (86.995)\tPrec@5 99.609 (98.476)\n",
            "Epoch: [80][50/329], lr: 0.01000\tTime 0.103 (0.102)\tData 0.005 (0.017)\tLoss 1.9984 (2.4182)\tPrec@1 90.234 (87.646)\tPrec@5 100.000 (98.683)\n",
            "Epoch: [80][60/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.006 (0.015)\tLoss 1.7907 (2.3260)\tPrec@1 91.406 (88.134)\tPrec@5 100.000 (98.783)\n",
            "Epoch: [80][70/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.006 (0.014)\tLoss 2.1831 (2.2616)\tPrec@1 87.891 (88.457)\tPrec@5 98.047 (98.867)\n",
            "Epoch: [80][80/329], lr: 0.01000\tTime 0.113 (0.098)\tData 0.012 (0.013)\tLoss 1.7007 (2.1964)\tPrec@1 91.406 (88.759)\tPrec@5 99.219 (98.934)\n",
            "Epoch: [80][90/329], lr: 0.01000\tTime 0.070 (0.097)\tData 0.007 (0.012)\tLoss 1.7229 (2.1612)\tPrec@1 91.797 (88.964)\tPrec@5 98.047 (98.957)\n",
            "Epoch: [80][100/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.007 (0.012)\tLoss 1.2887 (2.1266)\tPrec@1 94.531 (89.140)\tPrec@5 98.828 (98.991)\n",
            "Epoch: [80][110/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.002 (0.011)\tLoss 1.5073 (2.0885)\tPrec@1 92.578 (89.319)\tPrec@5 99.609 (99.057)\n",
            "Epoch: [80][120/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.001 (0.011)\tLoss 1.5209 (2.0672)\tPrec@1 92.969 (89.447)\tPrec@5 99.219 (99.067)\n",
            "Epoch: [80][130/329], lr: 0.01000\tTime 0.103 (0.094)\tData 0.009 (0.011)\tLoss 1.8695 (2.0346)\tPrec@1 91.797 (89.617)\tPrec@5 99.609 (99.105)\n",
            "Epoch: [80][140/329], lr: 0.01000\tTime 0.072 (0.093)\tData 0.000 (0.010)\tLoss 1.6994 (2.0237)\tPrec@1 91.797 (89.639)\tPrec@5 98.828 (99.102)\n",
            "Epoch: [80][150/329], lr: 0.01000\tTime 0.063 (0.093)\tData 0.002 (0.010)\tLoss 1.8041 (1.9993)\tPrec@1 91.016 (89.771)\tPrec@5 99.609 (99.118)\n",
            "Epoch: [80][160/329], lr: 0.01000\tTime 0.099 (0.093)\tData 0.002 (0.010)\tLoss 1.2852 (1.9826)\tPrec@1 92.578 (89.841)\tPrec@5 99.609 (99.139)\n",
            "Epoch: [80][170/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.000 (0.009)\tLoss 1.6110 (1.9652)\tPrec@1 92.578 (89.928)\tPrec@5 99.609 (99.155)\n",
            "Epoch: [80][180/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.000 (0.009)\tLoss 1.4447 (1.9491)\tPrec@1 92.969 (90.008)\tPrec@5 99.219 (99.169)\n",
            "Epoch: [80][190/329], lr: 0.01000\tTime 0.073 (0.092)\tData 0.005 (0.009)\tLoss 1.4109 (1.9395)\tPrec@1 92.188 (90.030)\tPrec@5 99.219 (99.184)\n",
            "Epoch: [80][200/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.002 (0.009)\tLoss 1.6993 (1.9281)\tPrec@1 91.016 (90.094)\tPrec@5 99.219 (99.184)\n",
            "Epoch: [80][210/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.009 (0.009)\tLoss 1.6740 (1.9226)\tPrec@1 91.016 (90.120)\tPrec@5 99.609 (99.197)\n",
            "Epoch: [80][220/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.000 (0.009)\tLoss 2.0209 (1.9189)\tPrec@1 89.453 (90.144)\tPrec@5 99.609 (99.221)\n",
            "Epoch: [80][230/329], lr: 0.01000\tTime 0.076 (0.091)\tData 0.011 (0.009)\tLoss 1.9126 (1.9165)\tPrec@1 91.406 (90.150)\tPrec@5 98.828 (99.227)\n",
            "Epoch: [80][240/329], lr: 0.01000\tTime 0.086 (0.090)\tData 0.000 (0.009)\tLoss 1.6199 (1.9066)\tPrec@1 92.188 (90.205)\tPrec@5 99.219 (99.232)\n",
            "Epoch: [80][250/329], lr: 0.01000\tTime 0.098 (0.091)\tData 0.005 (0.009)\tLoss 2.0383 (1.9047)\tPrec@1 89.453 (90.220)\tPrec@5 99.219 (99.237)\n",
            "Epoch: [80][260/329], lr: 0.01000\tTime 0.089 (0.090)\tData 0.002 (0.009)\tLoss 1.3413 (1.8995)\tPrec@1 93.359 (90.267)\tPrec@5 99.609 (99.249)\n",
            "Epoch: [80][270/329], lr: 0.01000\tTime 0.085 (0.090)\tData 0.010 (0.009)\tLoss 1.4555 (1.8971)\tPrec@1 92.578 (90.279)\tPrec@5 100.000 (99.256)\n",
            "Epoch: [80][280/329], lr: 0.01000\tTime 0.074 (0.090)\tData 0.006 (0.009)\tLoss 1.9412 (1.8984)\tPrec@1 89.844 (90.276)\tPrec@5 99.219 (99.252)\n",
            "Epoch: [80][290/329], lr: 0.01000\tTime 0.088 (0.090)\tData 0.006 (0.009)\tLoss 1.5822 (1.8876)\tPrec@1 91.016 (90.320)\tPrec@5 98.047 (99.251)\n",
            "Epoch: [80][300/329], lr: 0.01000\tTime 0.073 (0.090)\tData 0.004 (0.009)\tLoss 1.7826 (1.8822)\tPrec@1 90.234 (90.349)\tPrec@5 99.609 (99.262)\n",
            "Epoch: [80][310/329], lr: 0.01000\tTime 0.070 (0.090)\tData 0.000 (0.009)\tLoss 1.9700 (1.8765)\tPrec@1 89.062 (90.380)\tPrec@5 99.609 (99.270)\n",
            "Epoch: [80][320/329], lr: 0.01000\tTime 0.107 (0.090)\tData 0.064 (0.009)\tLoss 1.3680 (1.8728)\tPrec@1 93.750 (90.404)\tPrec@5 100.000 (99.282)\n",
            "Test: [0/100]\tTime 0.293 (0.293)\tLoss 8.0311 (8.0311)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.049 (0.057)\tLoss 5.8087 (7.0962)\tPrec@1 74.000 (69.364)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/100]\tTime 0.026 (0.040)\tLoss 6.4070 (7.1752)\tPrec@1 72.000 (68.762)\tPrec@5 98.000 (96.810)\n",
            "Test: [30/100]\tTime 0.022 (0.036)\tLoss 6.8053 (7.2037)\tPrec@1 69.000 (68.742)\tPrec@5 97.000 (96.677)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 7.6534 (7.2350)\tPrec@1 69.000 (68.341)\tPrec@5 93.000 (96.707)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 6.3679 (7.1540)\tPrec@1 76.000 (68.725)\tPrec@5 96.000 (96.863)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 6.2570 (7.2125)\tPrec@1 71.000 (68.180)\tPrec@5 97.000 (96.902)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 7.3562 (7.2278)\tPrec@1 65.000 (68.113)\tPrec@5 97.000 (96.915)\n",
            "Test: [80/100]\tTime 0.022 (0.028)\tLoss 6.7072 (7.1840)\tPrec@1 72.000 (68.123)\tPrec@5 98.000 (97.074)\n",
            "Test: [90/100]\tTime 0.016 (0.028)\tLoss 7.4836 (7.2360)\tPrec@1 66.000 (67.824)\tPrec@5 99.000 (97.055)\n",
            "val Results: Prec@1 67.790 Prec@5 97.050 Loss 7.25288\n",
            "val Class Accuracy: [0.986,0.909,0.771,0.592,0.840,0.655,0.712,0.481,0.327,0.506]\n",
            "Best Prec@1: 77.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [81][0/329], lr: 0.01000\tTime 0.585 (0.585)\tData 0.491 (0.491)\tLoss 1.5694 (1.5694)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][10/329], lr: 0.01000\tTime 0.114 (0.143)\tData 0.002 (0.048)\tLoss 2.3868 (2.4611)\tPrec@1 88.281 (87.287)\tPrec@5 98.047 (99.006)\n",
            "Epoch: [81][20/329], lr: 0.01000\tTime 0.107 (0.119)\tData 0.000 (0.027)\tLoss 1.6697 (2.2692)\tPrec@1 91.016 (88.002)\tPrec@5 99.609 (99.275)\n",
            "Epoch: [81][30/329], lr: 0.01000\tTime 0.084 (0.110)\tData 0.014 (0.020)\tLoss 1.8229 (2.1604)\tPrec@1 90.234 (88.722)\tPrec@5 98.828 (99.257)\n",
            "Epoch: [81][40/329], lr: 0.01000\tTime 0.121 (0.105)\tData 0.000 (0.017)\tLoss 1.7335 (2.0491)\tPrec@1 89.453 (89.272)\tPrec@5 99.609 (99.304)\n",
            "Epoch: [81][50/329], lr: 0.01000\tTime 0.127 (0.107)\tData 0.009 (0.015)\tLoss 1.3518 (1.9821)\tPrec@1 92.969 (89.714)\tPrec@5 99.609 (99.288)\n",
            "Epoch: [81][60/329], lr: 0.01000\tTime 0.102 (0.108)\tData 0.032 (0.014)\tLoss 1.7809 (1.9418)\tPrec@1 91.016 (90.010)\tPrec@5 99.609 (99.321)\n",
            "Epoch: [81][70/329], lr: 0.01000\tTime 0.099 (0.111)\tData 0.003 (0.016)\tLoss 1.4690 (1.9033)\tPrec@1 91.797 (90.201)\tPrec@5 99.609 (99.334)\n",
            "Epoch: [81][80/329], lr: 0.01000\tTime 0.109 (0.110)\tData 0.000 (0.016)\tLoss 1.5266 (1.8983)\tPrec@1 92.578 (90.230)\tPrec@5 100.000 (99.349)\n",
            "Epoch: [81][90/329], lr: 0.01000\tTime 0.106 (0.108)\tData 0.005 (0.014)\tLoss 2.2735 (1.9171)\tPrec@1 88.281 (90.161)\tPrec@5 98.438 (99.330)\n",
            "Epoch: [81][100/329], lr: 0.01000\tTime 0.098 (0.107)\tData 0.004 (0.013)\tLoss 1.9597 (1.9061)\tPrec@1 90.234 (90.223)\tPrec@5 99.609 (99.323)\n",
            "Epoch: [81][110/329], lr: 0.01000\tTime 0.092 (0.106)\tData 0.007 (0.013)\tLoss 1.6342 (1.8780)\tPrec@1 91.797 (90.379)\tPrec@5 99.219 (99.345)\n",
            "Epoch: [81][120/329], lr: 0.01000\tTime 0.086 (0.105)\tData 0.001 (0.012)\tLoss 2.0574 (1.8712)\tPrec@1 89.844 (90.376)\tPrec@5 99.219 (99.370)\n",
            "Epoch: [81][130/329], lr: 0.01000\tTime 0.097 (0.104)\tData 0.004 (0.012)\tLoss 1.8869 (1.8771)\tPrec@1 90.625 (90.342)\tPrec@5 98.828 (99.353)\n",
            "Epoch: [81][140/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.003 (0.011)\tLoss 1.8667 (1.8772)\tPrec@1 91.016 (90.345)\tPrec@5 99.219 (99.349)\n",
            "Epoch: [81][150/329], lr: 0.01000\tTime 0.083 (0.101)\tData 0.000 (0.011)\tLoss 1.6209 (1.8638)\tPrec@1 91.016 (90.413)\tPrec@5 99.219 (99.351)\n",
            "Epoch: [81][160/329], lr: 0.01000\tTime 0.078 (0.100)\tData 0.005 (0.011)\tLoss 1.5272 (1.8538)\tPrec@1 91.406 (90.467)\tPrec@5 99.219 (99.359)\n",
            "Epoch: [81][170/329], lr: 0.01000\tTime 0.089 (0.100)\tData 0.003 (0.011)\tLoss 1.7830 (1.8520)\tPrec@1 91.016 (90.479)\tPrec@5 98.438 (99.374)\n",
            "Epoch: [81][180/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.005 (0.011)\tLoss 2.3649 (1.8566)\tPrec@1 87.500 (90.433)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [81][190/329], lr: 0.01000\tTime 0.079 (0.099)\tData 0.006 (0.010)\tLoss 1.9609 (1.8539)\tPrec@1 89.062 (90.453)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [81][200/329], lr: 0.01000\tTime 0.073 (0.098)\tData 0.005 (0.010)\tLoss 1.5833 (1.8378)\tPrec@1 91.406 (90.530)\tPrec@5 99.219 (99.380)\n",
            "Epoch: [81][210/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.005 (0.010)\tLoss 2.0848 (1.8375)\tPrec@1 88.281 (90.523)\tPrec@5 100.000 (99.380)\n",
            "Epoch: [81][220/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.007 (0.010)\tLoss 1.6720 (1.8381)\tPrec@1 91.406 (90.530)\tPrec@5 100.000 (99.385)\n",
            "Epoch: [81][230/329], lr: 0.01000\tTime 0.107 (0.097)\tData 0.000 (0.010)\tLoss 1.5101 (1.8220)\tPrec@1 92.969 (90.610)\tPrec@5 100.000 (99.403)\n",
            "Epoch: [81][240/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.004 (0.010)\tLoss 1.7024 (1.8224)\tPrec@1 91.406 (90.609)\tPrec@5 99.609 (99.407)\n",
            "Epoch: [81][250/329], lr: 0.01000\tTime 0.067 (0.096)\tData 0.000 (0.010)\tLoss 1.4958 (1.8186)\tPrec@1 92.578 (90.630)\tPrec@5 99.219 (99.402)\n",
            "Epoch: [81][260/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.006 (0.010)\tLoss 1.4177 (1.8129)\tPrec@1 92.969 (90.656)\tPrec@5 99.609 (99.412)\n",
            "Epoch: [81][270/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.000 (0.009)\tLoss 1.4898 (1.8125)\tPrec@1 91.797 (90.658)\tPrec@5 100.000 (99.413)\n",
            "Epoch: [81][280/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.007 (0.009)\tLoss 1.4702 (1.8054)\tPrec@1 92.188 (90.700)\tPrec@5 100.000 (99.419)\n",
            "Epoch: [81][290/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.000 (0.009)\tLoss 1.6352 (1.7993)\tPrec@1 91.797 (90.724)\tPrec@5 99.609 (99.423)\n",
            "Epoch: [81][300/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.000 (0.009)\tLoss 2.1250 (1.7990)\tPrec@1 89.844 (90.738)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [81][310/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.007 (0.009)\tLoss 1.7265 (1.7969)\tPrec@1 91.406 (90.749)\tPrec@5 100.000 (99.426)\n",
            "Epoch: [81][320/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.061 (0.009)\tLoss 1.6168 (1.7975)\tPrec@1 91.797 (90.744)\tPrec@5 99.609 (99.426)\n",
            "Test: [0/100]\tTime 0.360 (0.360)\tLoss 4.2283 (4.2283)\tPrec@1 81.000 (81.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.052)\tLoss 3.7681 (4.9267)\tPrec@1 83.000 (76.455)\tPrec@5 99.000 (97.455)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 3.8417 (4.5994)\tPrec@1 82.000 (78.619)\tPrec@5 98.000 (97.524)\n",
            "Test: [30/100]\tTime 0.030 (0.034)\tLoss 5.0361 (4.6561)\tPrec@1 77.000 (78.452)\tPrec@5 97.000 (97.226)\n",
            "Test: [40/100]\tTime 0.035 (0.031)\tLoss 3.8920 (4.6803)\tPrec@1 85.000 (78.293)\tPrec@5 96.000 (97.171)\n",
            "Test: [50/100]\tTime 0.032 (0.030)\tLoss 4.9704 (4.6782)\tPrec@1 75.000 (78.333)\tPrec@5 96.000 (97.235)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 4.6645 (4.7364)\tPrec@1 82.000 (78.033)\tPrec@5 98.000 (97.377)\n",
            "Test: [70/100]\tTime 0.018 (0.028)\tLoss 4.2884 (4.6853)\tPrec@1 78.000 (78.282)\tPrec@5 98.000 (97.352)\n",
            "Test: [80/100]\tTime 0.022 (0.028)\tLoss 4.1111 (4.6537)\tPrec@1 81.000 (78.370)\tPrec@5 96.000 (97.420)\n",
            "Test: [90/100]\tTime 0.017 (0.027)\tLoss 4.6101 (4.6893)\tPrec@1 78.000 (78.176)\tPrec@5 100.000 (97.363)\n",
            "val Results: Prec@1 78.150 Prec@5 97.380 Loss 4.69888\n",
            "val Class Accuracy: [0.822,0.942,0.651,0.616,0.858,0.825,0.901,0.670,0.766,0.764]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [82][0/329], lr: 0.01000\tTime 0.558 (0.558)\tData 0.476 (0.476)\tLoss 1.6098 (1.6098)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][10/329], lr: 0.01000\tTime 0.105 (0.142)\tData 0.006 (0.048)\tLoss 1.5289 (2.0087)\tPrec@1 92.969 (89.773)\tPrec@5 99.609 (99.219)\n",
            "Epoch: [82][20/329], lr: 0.01000\tTime 0.111 (0.118)\tData 0.002 (0.027)\tLoss 1.3443 (1.9310)\tPrec@1 93.750 (89.937)\tPrec@5 99.609 (99.293)\n",
            "Epoch: [82][30/329], lr: 0.01000\tTime 0.080 (0.108)\tData 0.000 (0.020)\tLoss 2.0842 (1.8914)\tPrec@1 88.672 (90.285)\tPrec@5 99.609 (99.370)\n",
            "Epoch: [82][40/329], lr: 0.01000\tTime 0.072 (0.103)\tData 0.011 (0.017)\tLoss 1.5506 (1.8962)\tPrec@1 91.406 (90.272)\tPrec@5 99.219 (99.324)\n",
            "Epoch: [82][50/329], lr: 0.01000\tTime 0.095 (0.101)\tData 0.007 (0.015)\tLoss 2.0791 (1.8747)\tPrec@1 89.453 (90.418)\tPrec@5 98.438 (99.318)\n",
            "Epoch: [82][60/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.007 (0.014)\tLoss 2.6348 (1.8574)\tPrec@1 87.109 (90.439)\tPrec@5 98.047 (99.296)\n",
            "Epoch: [82][70/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.000 (0.013)\tLoss 2.0123 (1.8533)\tPrec@1 87.500 (90.421)\tPrec@5 100.000 (99.285)\n",
            "Epoch: [82][80/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.000 (0.012)\tLoss 1.5518 (1.8284)\tPrec@1 93.359 (90.606)\tPrec@5 99.219 (99.296)\n",
            "Epoch: [82][90/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.012)\tLoss 1.7928 (1.8266)\tPrec@1 89.062 (90.573)\tPrec@5 99.219 (99.317)\n",
            "Epoch: [82][100/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.009 (0.011)\tLoss 1.4064 (1.8091)\tPrec@1 92.969 (90.671)\tPrec@5 99.219 (99.319)\n",
            "Epoch: [82][110/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.012 (0.011)\tLoss 1.6965 (1.7923)\tPrec@1 91.797 (90.759)\tPrec@5 99.609 (99.345)\n",
            "Epoch: [82][120/329], lr: 0.01000\tTime 0.094 (0.093)\tData 0.005 (0.010)\tLoss 1.5829 (1.7774)\tPrec@1 92.578 (90.886)\tPrec@5 99.609 (99.358)\n",
            "Epoch: [82][130/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.010)\tLoss 1.3966 (1.7782)\tPrec@1 93.750 (90.896)\tPrec@5 100.000 (99.362)\n",
            "Epoch: [82][140/329], lr: 0.01000\tTime 0.107 (0.093)\tData 0.006 (0.010)\tLoss 1.7564 (1.7804)\tPrec@1 91.797 (90.872)\tPrec@5 99.219 (99.363)\n",
            "Epoch: [82][150/329], lr: 0.01000\tTime 0.111 (0.094)\tData 0.007 (0.010)\tLoss 2.2475 (1.7797)\tPrec@1 87.891 (90.866)\tPrec@5 99.219 (99.374)\n",
            "Epoch: [82][160/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.010)\tLoss 2.0611 (1.7800)\tPrec@1 88.672 (90.851)\tPrec@5 99.219 (99.374)\n",
            "Epoch: [82][170/329], lr: 0.01000\tTime 0.115 (0.096)\tData 0.045 (0.010)\tLoss 1.8646 (1.7784)\tPrec@1 90.234 (90.835)\tPrec@5 99.219 (99.388)\n",
            "Epoch: [82][180/329], lr: 0.01000\tTime 0.080 (0.098)\tData 0.011 (0.011)\tLoss 1.5448 (1.7767)\tPrec@1 91.406 (90.847)\tPrec@5 98.828 (99.378)\n",
            "Epoch: [82][190/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.001 (0.011)\tLoss 1.8967 (1.7729)\tPrec@1 90.625 (90.881)\tPrec@5 99.609 (99.386)\n",
            "Epoch: [82][200/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.000 (0.010)\tLoss 1.8127 (1.7670)\tPrec@1 89.844 (90.911)\tPrec@5 100.000 (99.401)\n",
            "Epoch: [82][210/329], lr: 0.01000\tTime 0.109 (0.097)\tData 0.000 (0.010)\tLoss 1.4721 (1.7633)\tPrec@1 92.188 (90.927)\tPrec@5 99.609 (99.406)\n",
            "Epoch: [82][220/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.000 (0.010)\tLoss 1.7385 (1.7678)\tPrec@1 91.016 (90.917)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [82][230/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.005 (0.010)\tLoss 1.6154 (1.7578)\tPrec@1 91.406 (90.978)\tPrec@5 99.609 (99.425)\n",
            "Epoch: [82][240/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.002 (0.009)\tLoss 1.6443 (1.7556)\tPrec@1 91.797 (90.988)\tPrec@5 99.609 (99.425)\n",
            "Epoch: [82][250/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.009)\tLoss 1.0977 (1.7479)\tPrec@1 93.750 (91.027)\tPrec@5 99.219 (99.438)\n",
            "Epoch: [82][260/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.006 (0.009)\tLoss 1.7040 (1.7486)\tPrec@1 89.062 (91.017)\tPrec@5 99.219 (99.440)\n",
            "Epoch: [82][270/329], lr: 0.01000\tTime 0.090 (0.095)\tData 0.012 (0.009)\tLoss 1.6604 (1.7542)\tPrec@1 91.406 (90.995)\tPrec@5 100.000 (99.439)\n",
            "Epoch: [82][280/329], lr: 0.01000\tTime 0.068 (0.095)\tData 0.000 (0.009)\tLoss 1.8041 (1.7575)\tPrec@1 91.406 (90.985)\tPrec@5 100.000 (99.441)\n",
            "Epoch: [82][290/329], lr: 0.01000\tTime 0.084 (0.095)\tData 0.008 (0.009)\tLoss 1.3839 (1.7569)\tPrec@1 92.578 (90.995)\tPrec@5 99.219 (99.443)\n",
            "Epoch: [82][300/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.000 (0.009)\tLoss 2.2031 (1.7627)\tPrec@1 87.891 (90.959)\tPrec@5 99.219 (99.439)\n",
            "Epoch: [82][310/329], lr: 0.01000\tTime 0.075 (0.094)\tData 0.000 (0.009)\tLoss 1.6487 (1.7627)\tPrec@1 92.188 (90.955)\tPrec@5 99.609 (99.442)\n",
            "Epoch: [82][320/329], lr: 0.01000\tTime 0.093 (0.094)\tData 0.043 (0.009)\tLoss 1.7616 (1.7559)\tPrec@1 91.016 (90.986)\tPrec@5 99.609 (99.441)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 5.5308 (5.5308)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.056)\tLoss 3.7261 (5.3356)\tPrec@1 82.000 (75.273)\tPrec@5 98.000 (97.455)\n",
            "Test: [20/100]\tTime 0.030 (0.040)\tLoss 4.2040 (5.0846)\tPrec@1 82.000 (76.810)\tPrec@5 99.000 (97.762)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 5.3415 (5.1795)\tPrec@1 76.000 (76.290)\tPrec@5 96.000 (97.355)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 4.5443 (5.1833)\tPrec@1 79.000 (76.244)\tPrec@5 97.000 (97.244)\n",
            "Test: [50/100]\tTime 0.025 (0.030)\tLoss 4.9633 (5.0952)\tPrec@1 76.000 (76.745)\tPrec@5 98.000 (97.294)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 5.0566 (5.1307)\tPrec@1 78.000 (76.590)\tPrec@5 99.000 (97.443)\n",
            "Test: [70/100]\tTime 0.016 (0.028)\tLoss 5.0661 (5.1374)\tPrec@1 77.000 (76.606)\tPrec@5 97.000 (97.394)\n",
            "Test: [80/100]\tTime 0.029 (0.028)\tLoss 4.6532 (5.1025)\tPrec@1 79.000 (76.716)\tPrec@5 97.000 (97.506)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 5.0016 (5.1374)\tPrec@1 76.000 (76.560)\tPrec@5 99.000 (97.549)\n",
            "val Results: Prec@1 76.520 Prec@5 97.640 Loss 5.14485\n",
            "val Class Accuracy: [0.804,0.969,0.825,0.860,0.727,0.630,0.763,0.756,0.706,0.612]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [83][0/329], lr: 0.01000\tTime 0.651 (0.651)\tData 0.591 (0.591)\tLoss 1.7222 (1.7222)\tPrec@1 91.016 (91.016)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [83][10/329], lr: 0.01000\tTime 0.077 (0.147)\tData 0.005 (0.061)\tLoss 1.2335 (1.7722)\tPrec@1 92.969 (91.193)\tPrec@5 100.000 (99.503)\n",
            "Epoch: [83][20/329], lr: 0.01000\tTime 0.086 (0.119)\tData 0.000 (0.035)\tLoss 1.1791 (1.7978)\tPrec@1 93.750 (90.923)\tPrec@5 100.000 (99.535)\n",
            "Epoch: [83][30/329], lr: 0.01000\tTime 0.099 (0.110)\tData 0.009 (0.027)\tLoss 1.5469 (1.8024)\tPrec@1 92.188 (90.902)\tPrec@5 99.219 (99.458)\n",
            "Epoch: [83][40/329], lr: 0.01000\tTime 0.076 (0.104)\tData 0.005 (0.021)\tLoss 1.5182 (1.7476)\tPrec@1 91.797 (91.120)\tPrec@5 99.609 (99.486)\n",
            "Epoch: [83][50/329], lr: 0.01000\tTime 0.112 (0.102)\tData 0.005 (0.019)\tLoss 2.1341 (1.7218)\tPrec@1 88.281 (91.230)\tPrec@5 99.219 (99.464)\n",
            "Epoch: [83][60/329], lr: 0.01000\tTime 0.094 (0.099)\tData 0.003 (0.017)\tLoss 1.8532 (1.6800)\tPrec@1 90.625 (91.502)\tPrec@5 100.000 (99.481)\n",
            "Epoch: [83][70/329], lr: 0.01000\tTime 0.078 (0.097)\tData 0.005 (0.015)\tLoss 1.7384 (1.6811)\tPrec@1 92.578 (91.500)\tPrec@5 98.047 (99.477)\n",
            "Epoch: [83][80/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.014 (0.015)\tLoss 1.6490 (1.6784)\tPrec@1 92.578 (91.483)\tPrec@5 99.219 (99.465)\n",
            "Epoch: [83][90/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.000 (0.014)\tLoss 1.5961 (1.6858)\tPrec@1 91.797 (91.411)\tPrec@5 99.609 (99.498)\n",
            "Epoch: [83][100/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.005 (0.013)\tLoss 1.3739 (1.6906)\tPrec@1 93.359 (91.379)\tPrec@5 100.000 (99.493)\n",
            "Epoch: [83][110/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.004 (0.012)\tLoss 1.3760 (1.6975)\tPrec@1 92.188 (91.346)\tPrec@5 99.609 (99.490)\n",
            "Epoch: [83][120/329], lr: 0.01000\tTime 0.079 (0.093)\tData 0.000 (0.012)\tLoss 1.8138 (1.7001)\tPrec@1 90.234 (91.338)\tPrec@5 98.828 (99.474)\n",
            "Epoch: [83][130/329], lr: 0.01000\tTime 0.102 (0.093)\tData 0.006 (0.012)\tLoss 1.9706 (1.6931)\tPrec@1 89.062 (91.373)\tPrec@5 99.219 (99.472)\n",
            "Epoch: [83][140/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.000 (0.011)\tLoss 1.4036 (1.7011)\tPrec@1 92.969 (91.318)\tPrec@5 98.438 (99.474)\n",
            "Epoch: [83][150/329], lr: 0.01000\tTime 0.093 (0.093)\tData 0.005 (0.011)\tLoss 1.7758 (1.7024)\tPrec@1 90.625 (91.311)\tPrec@5 99.609 (99.467)\n",
            "Epoch: [83][160/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.008 (0.011)\tLoss 1.6944 (1.7017)\tPrec@1 90.625 (91.312)\tPrec@5 99.609 (99.474)\n",
            "Epoch: [83][170/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.006 (0.010)\tLoss 2.0283 (1.7038)\tPrec@1 90.234 (91.310)\tPrec@5 99.219 (99.468)\n",
            "Epoch: [83][180/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.000 (0.010)\tLoss 1.9416 (1.7088)\tPrec@1 89.844 (91.264)\tPrec@5 100.000 (99.473)\n",
            "Epoch: [83][190/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.000 (0.010)\tLoss 2.0350 (1.7168)\tPrec@1 88.281 (91.210)\tPrec@5 98.828 (99.468)\n",
            "Epoch: [83][200/329], lr: 0.01000\tTime 0.093 (0.092)\tData 0.007 (0.010)\tLoss 1.7501 (1.7203)\tPrec@1 91.797 (91.181)\tPrec@5 100.000 (99.475)\n",
            "Epoch: [83][210/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.012 (0.010)\tLoss 1.9621 (1.7174)\tPrec@1 90.625 (91.193)\tPrec@5 99.219 (99.482)\n",
            "Epoch: [83][220/329], lr: 0.01000\tTime 0.106 (0.091)\tData 0.008 (0.010)\tLoss 1.4420 (1.7218)\tPrec@1 93.359 (91.168)\tPrec@5 99.609 (99.475)\n",
            "Epoch: [83][230/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.007 (0.010)\tLoss 1.6656 (1.7191)\tPrec@1 91.797 (91.171)\tPrec@5 100.000 (99.486)\n",
            "Epoch: [83][240/329], lr: 0.01000\tTime 0.077 (0.091)\tData 0.000 (0.010)\tLoss 0.9997 (1.7202)\tPrec@1 95.703 (91.144)\tPrec@5 100.000 (99.485)\n",
            "Epoch: [83][250/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.000 (0.010)\tLoss 1.5565 (1.7131)\tPrec@1 92.188 (91.188)\tPrec@5 99.609 (99.483)\n",
            "Epoch: [83][260/329], lr: 0.01000\tTime 0.146 (0.092)\tData 0.000 (0.009)\tLoss 2.2666 (1.7183)\tPrec@1 89.062 (91.161)\tPrec@5 99.609 (99.476)\n",
            "Epoch: [83][270/329], lr: 0.01000\tTime 0.119 (0.093)\tData 0.000 (0.009)\tLoss 1.8922 (1.7171)\tPrec@1 89.844 (91.161)\tPrec@5 99.219 (99.480)\n",
            "Epoch: [83][280/329], lr: 0.01000\tTime 0.124 (0.094)\tData 0.000 (0.009)\tLoss 1.2909 (1.7178)\tPrec@1 92.969 (91.164)\tPrec@5 99.609 (99.481)\n",
            "Epoch: [83][290/329], lr: 0.01000\tTime 0.080 (0.095)\tData 0.000 (0.010)\tLoss 1.4801 (1.7288)\tPrec@1 92.969 (91.107)\tPrec@5 100.000 (99.474)\n",
            "Epoch: [83][300/329], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.010)\tLoss 1.2512 (1.7278)\tPrec@1 93.750 (91.114)\tPrec@5 99.219 (99.477)\n",
            "Epoch: [83][310/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.010)\tLoss 1.6538 (1.7253)\tPrec@1 90.625 (91.116)\tPrec@5 100.000 (99.481)\n",
            "Epoch: [83][320/329], lr: 0.01000\tTime 0.148 (0.095)\tData 0.092 (0.010)\tLoss 1.6006 (1.7277)\tPrec@1 92.969 (91.106)\tPrec@5 100.000 (99.485)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 4.9440 (4.9440)\tPrec@1 74.000 (74.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.056)\tLoss 4.7754 (5.5814)\tPrec@1 77.000 (72.727)\tPrec@5 98.000 (97.818)\n",
            "Test: [20/100]\tTime 0.013 (0.039)\tLoss 4.7473 (5.5451)\tPrec@1 79.000 (73.905)\tPrec@5 98.000 (97.857)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 5.3432 (5.6142)\tPrec@1 73.000 (73.774)\tPrec@5 98.000 (97.548)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 5.3678 (5.6012)\tPrec@1 77.000 (73.854)\tPrec@5 96.000 (97.463)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 6.3772 (5.6075)\tPrec@1 72.000 (73.804)\tPrec@5 97.000 (97.588)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 5.0598 (5.6189)\tPrec@1 75.000 (73.672)\tPrec@5 100.000 (97.607)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 6.0384 (5.6328)\tPrec@1 73.000 (73.648)\tPrec@5 96.000 (97.592)\n",
            "Test: [80/100]\tTime 0.013 (0.028)\tLoss 4.3363 (5.5812)\tPrec@1 80.000 (73.938)\tPrec@5 98.000 (97.519)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 5.9121 (5.6433)\tPrec@1 72.000 (73.604)\tPrec@5 100.000 (97.604)\n",
            "val Results: Prec@1 73.620 Prec@5 97.550 Loss 5.64748\n",
            "val Class Accuracy: [0.943,0.901,0.722,0.773,0.628,0.530,0.828,0.734,0.666,0.637]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [84][0/329], lr: 0.01000\tTime 0.636 (0.636)\tData 0.542 (0.542)\tLoss 1.7881 (1.7881)\tPrec@1 92.969 (92.969)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [84][10/329], lr: 0.01000\tTime 0.078 (0.148)\tData 0.014 (0.056)\tLoss 2.6263 (2.9528)\tPrec@1 85.938 (83.381)\tPrec@5 100.000 (98.864)\n",
            "Epoch: [84][20/329], lr: 0.01000\tTime 0.101 (0.121)\tData 0.004 (0.033)\tLoss 2.5779 (2.8052)\tPrec@1 87.109 (84.542)\tPrec@5 98.047 (98.717)\n",
            "Epoch: [84][30/329], lr: 0.01000\tTime 0.079 (0.111)\tData 0.001 (0.024)\tLoss 2.0589 (2.6881)\tPrec@1 87.891 (85.345)\tPrec@5 100.000 (98.866)\n",
            "Epoch: [84][40/329], lr: 0.01000\tTime 0.102 (0.106)\tData 0.001 (0.020)\tLoss 1.6134 (2.5518)\tPrec@1 92.578 (86.128)\tPrec@5 99.609 (98.990)\n",
            "Epoch: [84][50/329], lr: 0.01000\tTime 0.089 (0.102)\tData 0.000 (0.018)\tLoss 2.1632 (2.4516)\tPrec@1 87.891 (86.780)\tPrec@5 98.828 (99.012)\n",
            "Epoch: [84][60/329], lr: 0.01000\tTime 0.076 (0.099)\tData 0.004 (0.016)\tLoss 2.5543 (2.3831)\tPrec@1 86.719 (87.173)\tPrec@5 99.609 (99.065)\n",
            "Epoch: [84][70/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.007 (0.015)\tLoss 1.9108 (2.3196)\tPrec@1 89.453 (87.544)\tPrec@5 99.219 (99.158)\n",
            "Epoch: [84][80/329], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.014)\tLoss 1.5369 (2.2718)\tPrec@1 91.797 (87.857)\tPrec@5 99.609 (99.214)\n",
            "Epoch: [84][90/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.005 (0.013)\tLoss 1.5693 (2.2128)\tPrec@1 92.188 (88.217)\tPrec@5 99.609 (99.236)\n",
            "Epoch: [84][100/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.005 (0.012)\tLoss 2.0711 (2.1621)\tPrec@1 89.453 (88.537)\tPrec@5 98.828 (99.250)\n",
            "Epoch: [84][110/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.000 (0.012)\tLoss 2.3847 (2.1391)\tPrec@1 87.500 (88.665)\tPrec@5 99.609 (99.250)\n",
            "Epoch: [84][120/329], lr: 0.01000\tTime 0.091 (0.094)\tData 0.002 (0.012)\tLoss 1.4916 (2.1012)\tPrec@1 92.578 (88.872)\tPrec@5 99.219 (99.264)\n",
            "Epoch: [84][130/329], lr: 0.01000\tTime 0.112 (0.093)\tData 0.006 (0.011)\tLoss 2.6136 (2.0845)\tPrec@1 85.547 (88.964)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [84][140/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.003 (0.011)\tLoss 1.8895 (2.0579)\tPrec@1 89.453 (89.126)\tPrec@5 99.609 (99.296)\n",
            "Epoch: [84][150/329], lr: 0.01000\tTime 0.069 (0.092)\tData 0.004 (0.010)\tLoss 1.4672 (2.0450)\tPrec@1 92.969 (89.174)\tPrec@5 99.219 (99.286)\n",
            "Epoch: [84][160/329], lr: 0.01000\tTime 0.096 (0.092)\tData 0.007 (0.010)\tLoss 2.0724 (2.0249)\tPrec@1 88.672 (89.305)\tPrec@5 100.000 (99.292)\n",
            "Epoch: [84][170/329], lr: 0.01000\tTime 0.103 (0.092)\tData 0.006 (0.010)\tLoss 1.7271 (2.0070)\tPrec@1 91.797 (89.407)\tPrec@5 100.000 (99.312)\n",
            "Epoch: [84][180/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.005 (0.010)\tLoss 1.9311 (2.0032)\tPrec@1 88.672 (89.410)\tPrec@5 99.609 (99.301)\n",
            "Epoch: [84][190/329], lr: 0.01000\tTime 0.103 (0.091)\tData 0.006 (0.010)\tLoss 1.2982 (1.9875)\tPrec@1 92.969 (89.496)\tPrec@5 100.000 (99.319)\n",
            "Epoch: [84][200/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.004 (0.010)\tLoss 1.5255 (1.9826)\tPrec@1 91.797 (89.509)\tPrec@5 100.000 (99.326)\n",
            "Epoch: [84][210/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.000 (0.010)\tLoss 1.8169 (1.9742)\tPrec@1 91.016 (89.577)\tPrec@5 99.219 (99.324)\n",
            "Epoch: [84][220/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.000 (0.010)\tLoss 2.4278 (1.9743)\tPrec@1 85.938 (89.598)\tPrec@5 100.000 (99.328)\n",
            "Epoch: [84][230/329], lr: 0.01000\tTime 0.083 (0.091)\tData 0.005 (0.009)\tLoss 2.2905 (1.9743)\tPrec@1 88.672 (89.600)\tPrec@5 99.609 (99.327)\n",
            "Epoch: [84][240/329], lr: 0.01000\tTime 0.096 (0.090)\tData 0.006 (0.009)\tLoss 1.7994 (1.9715)\tPrec@1 89.062 (89.627)\tPrec@5 99.609 (99.324)\n",
            "Epoch: [84][250/329], lr: 0.01000\tTime 0.078 (0.090)\tData 0.007 (0.009)\tLoss 1.6578 (1.9618)\tPrec@1 91.797 (89.680)\tPrec@5 99.219 (99.329)\n",
            "Epoch: [84][260/329], lr: 0.01000\tTime 0.095 (0.090)\tData 0.006 (0.009)\tLoss 1.6079 (1.9508)\tPrec@1 91.797 (89.731)\tPrec@5 98.438 (99.334)\n",
            "Epoch: [84][270/329], lr: 0.01000\tTime 0.071 (0.090)\tData 0.000 (0.009)\tLoss 1.6845 (1.9478)\tPrec@1 92.578 (89.759)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [84][280/329], lr: 0.01000\tTime 0.102 (0.090)\tData 0.000 (0.009)\tLoss 2.2556 (1.9483)\tPrec@1 88.672 (89.755)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [84][290/329], lr: 0.01000\tTime 0.083 (0.090)\tData 0.007 (0.009)\tLoss 2.1880 (1.9432)\tPrec@1 89.062 (89.798)\tPrec@5 99.609 (99.345)\n",
            "Epoch: [84][300/329], lr: 0.01000\tTime 0.108 (0.090)\tData 0.000 (0.009)\tLoss 1.5484 (1.9301)\tPrec@1 91.406 (89.872)\tPrec@5 100.000 (99.354)\n",
            "Epoch: [84][310/329], lr: 0.01000\tTime 0.080 (0.090)\tData 0.000 (0.009)\tLoss 2.0125 (1.9213)\tPrec@1 89.453 (89.924)\tPrec@5 99.609 (99.363)\n",
            "Epoch: [84][320/329], lr: 0.01000\tTime 0.109 (0.090)\tData 0.070 (0.009)\tLoss 1.3767 (1.9098)\tPrec@1 94.141 (89.996)\tPrec@5 100.000 (99.367)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 8.5557 (8.5557)\tPrec@1 64.000 (64.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.010 (0.051)\tLoss 6.2947 (7.6749)\tPrec@1 69.000 (66.727)\tPrec@5 96.000 (95.818)\n",
            "Test: [20/100]\tTime 0.035 (0.040)\tLoss 6.5331 (7.4121)\tPrec@1 69.000 (67.714)\tPrec@5 97.000 (95.619)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 7.7022 (7.4549)\tPrec@1 67.000 (67.387)\tPrec@5 95.000 (95.452)\n",
            "Test: [40/100]\tTime 0.030 (0.032)\tLoss 8.5326 (7.4542)\tPrec@1 61.000 (67.244)\tPrec@5 95.000 (95.561)\n",
            "Test: [50/100]\tTime 0.011 (0.030)\tLoss 7.3034 (7.3948)\tPrec@1 68.000 (67.627)\tPrec@5 95.000 (95.686)\n",
            "Test: [60/100]\tTime 0.020 (0.029)\tLoss 6.0369 (7.3726)\tPrec@1 73.000 (67.705)\tPrec@5 97.000 (95.721)\n",
            "Test: [70/100]\tTime 0.040 (0.029)\tLoss 7.5917 (7.3765)\tPrec@1 66.000 (67.521)\tPrec@5 96.000 (95.746)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 7.1184 (7.3286)\tPrec@1 69.000 (67.716)\tPrec@5 94.000 (95.815)\n",
            "Test: [90/100]\tTime 0.047 (0.029)\tLoss 7.0440 (7.3642)\tPrec@1 69.000 (67.626)\tPrec@5 99.000 (95.780)\n",
            "val Results: Prec@1 67.580 Prec@5 95.780 Loss 7.38617\n",
            "val Class Accuracy: [0.914,0.996,0.822,0.479,0.743,0.868,0.735,0.270,0.586,0.345]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [85][0/329], lr: 0.01000\tTime 0.559 (0.559)\tData 0.469 (0.469)\tLoss 1.5743 (1.5743)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][10/329], lr: 0.01000\tTime 0.093 (0.178)\tData 0.009 (0.080)\tLoss 1.4661 (2.1253)\tPrec@1 93.750 (90.234)\tPrec@5 99.219 (99.183)\n",
            "Epoch: [85][20/329], lr: 0.01000\tTime 0.110 (0.150)\tData 0.000 (0.053)\tLoss 1.4553 (2.0126)\tPrec@1 93.359 (90.402)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [85][30/329], lr: 0.01000\tTime 0.084 (0.146)\tData 0.003 (0.048)\tLoss 1.9436 (1.9475)\tPrec@1 91.406 (90.537)\tPrec@5 97.656 (99.231)\n",
            "Epoch: [85][40/329], lr: 0.01000\tTime 0.109 (0.137)\tData 0.002 (0.041)\tLoss 1.5977 (1.9434)\tPrec@1 92.188 (90.425)\tPrec@5 100.000 (99.190)\n",
            "Epoch: [85][50/329], lr: 0.01000\tTime 0.100 (0.129)\tData 0.004 (0.034)\tLoss 2.1479 (1.9047)\tPrec@1 88.281 (90.479)\tPrec@5 99.609 (99.203)\n",
            "Epoch: [85][60/329], lr: 0.01000\tTime 0.100 (0.125)\tData 0.000 (0.029)\tLoss 1.6390 (1.9002)\tPrec@1 91.406 (90.484)\tPrec@5 99.609 (99.276)\n",
            "Epoch: [85][70/329], lr: 0.01000\tTime 0.100 (0.121)\tData 0.005 (0.026)\tLoss 1.8471 (1.8740)\tPrec@1 90.625 (90.548)\tPrec@5 98.438 (99.274)\n",
            "Epoch: [85][80/329], lr: 0.01000\tTime 0.093 (0.117)\tData 0.004 (0.023)\tLoss 1.9722 (1.8544)\tPrec@1 90.234 (90.654)\tPrec@5 100.000 (99.272)\n",
            "Epoch: [85][90/329], lr: 0.01000\tTime 0.100 (0.115)\tData 0.007 (0.022)\tLoss 1.2973 (1.8447)\tPrec@1 94.922 (90.741)\tPrec@5 99.609 (99.287)\n",
            "Epoch: [85][100/329], lr: 0.01000\tTime 0.081 (0.112)\tData 0.000 (0.020)\tLoss 2.5331 (1.8552)\tPrec@1 86.719 (90.683)\tPrec@5 98.828 (99.288)\n",
            "Epoch: [85][110/329], lr: 0.01000\tTime 0.099 (0.110)\tData 0.007 (0.019)\tLoss 2.0224 (1.8613)\tPrec@1 89.844 (90.604)\tPrec@5 99.609 (99.296)\n",
            "Epoch: [85][120/329], lr: 0.01000\tTime 0.089 (0.108)\tData 0.000 (0.017)\tLoss 1.8516 (1.8459)\tPrec@1 89.844 (90.673)\tPrec@5 98.047 (99.280)\n",
            "Epoch: [85][130/329], lr: 0.01000\tTime 0.087 (0.107)\tData 0.003 (0.017)\tLoss 1.3220 (1.8446)\tPrec@1 91.406 (90.640)\tPrec@5 100.000 (99.287)\n",
            "Epoch: [85][140/329], lr: 0.01000\tTime 0.091 (0.106)\tData 0.006 (0.016)\tLoss 1.6429 (1.8332)\tPrec@1 91.797 (90.711)\tPrec@5 99.219 (99.280)\n",
            "Epoch: [85][150/329], lr: 0.01000\tTime 0.079 (0.105)\tData 0.000 (0.015)\tLoss 1.3858 (1.8079)\tPrec@1 93.359 (90.847)\tPrec@5 99.219 (99.294)\n",
            "Epoch: [85][160/329], lr: 0.01000\tTime 0.114 (0.104)\tData 0.005 (0.015)\tLoss 1.6243 (1.8079)\tPrec@1 91.797 (90.870)\tPrec@5 99.609 (99.289)\n",
            "Epoch: [85][170/329], lr: 0.01000\tTime 0.114 (0.103)\tData 0.000 (0.014)\tLoss 1.5388 (1.8075)\tPrec@1 92.969 (90.888)\tPrec@5 100.000 (99.285)\n",
            "Epoch: [85][180/329], lr: 0.01000\tTime 0.103 (0.103)\tData 0.005 (0.014)\tLoss 1.6882 (1.8069)\tPrec@1 91.016 (90.880)\tPrec@5 99.609 (99.281)\n",
            "Epoch: [85][190/329], lr: 0.01000\tTime 0.090 (0.102)\tData 0.005 (0.013)\tLoss 1.7832 (1.8151)\tPrec@1 91.406 (90.815)\tPrec@5 98.438 (99.264)\n",
            "Epoch: [85][200/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.000 (0.013)\tLoss 1.5027 (1.8202)\tPrec@1 93.359 (90.794)\tPrec@5 99.609 (99.273)\n",
            "Epoch: [85][210/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.000 (0.013)\tLoss 1.9361 (1.8203)\tPrec@1 89.844 (90.775)\tPrec@5 99.609 (99.280)\n",
            "Epoch: [85][220/329], lr: 0.01000\tTime 0.107 (0.100)\tData 0.000 (0.012)\tLoss 2.0523 (1.8168)\tPrec@1 88.281 (90.786)\tPrec@5 99.219 (99.272)\n",
            "Epoch: [85][230/329], lr: 0.01000\tTime 0.102 (0.100)\tData 0.007 (0.012)\tLoss 1.4179 (1.8053)\tPrec@1 92.578 (90.841)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [85][240/329], lr: 0.01000\tTime 0.106 (0.099)\tData 0.005 (0.012)\tLoss 1.7175 (1.8001)\tPrec@1 91.016 (90.860)\tPrec@5 99.219 (99.284)\n",
            "Epoch: [85][250/329], lr: 0.01000\tTime 0.099 (0.099)\tData 0.005 (0.012)\tLoss 2.7781 (1.8061)\tPrec@1 86.719 (90.835)\tPrec@5 98.828 (99.284)\n",
            "Epoch: [85][260/329], lr: 0.01000\tTime 0.070 (0.098)\tData 0.003 (0.012)\tLoss 1.5921 (1.8009)\tPrec@1 93.359 (90.855)\tPrec@5 99.609 (99.297)\n",
            "Epoch: [85][270/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.000 (0.011)\tLoss 1.8375 (1.8002)\tPrec@1 89.062 (90.841)\tPrec@5 99.219 (99.302)\n",
            "Epoch: [85][280/329], lr: 0.01000\tTime 0.099 (0.098)\tData 0.012 (0.011)\tLoss 1.7041 (1.7919)\tPrec@1 90.234 (90.874)\tPrec@5 99.609 (99.308)\n",
            "Epoch: [85][290/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.000 (0.011)\tLoss 1.5493 (1.7895)\tPrec@1 91.797 (90.873)\tPrec@5 99.219 (99.303)\n",
            "Epoch: [85][300/329], lr: 0.01000\tTime 0.074 (0.097)\tData 0.005 (0.011)\tLoss 1.6310 (1.7853)\tPrec@1 92.188 (90.894)\tPrec@5 100.000 (99.310)\n",
            "Epoch: [85][310/329], lr: 0.01000\tTime 0.100 (0.097)\tData 0.006 (0.011)\tLoss 1.8155 (1.7830)\tPrec@1 91.016 (90.900)\tPrec@5 98.828 (99.310)\n",
            "Epoch: [85][320/329], lr: 0.01000\tTime 0.101 (0.097)\tData 0.061 (0.011)\tLoss 1.7926 (1.7806)\tPrec@1 91.016 (90.923)\tPrec@5 99.219 (99.319)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 5.5625 (5.5625)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.033 (0.054)\tLoss 4.4891 (5.2711)\tPrec@1 76.000 (75.727)\tPrec@5 99.000 (97.091)\n",
            "Test: [20/100]\tTime 0.015 (0.039)\tLoss 3.7793 (5.1457)\tPrec@1 83.000 (76.143)\tPrec@5 99.000 (97.000)\n",
            "Test: [30/100]\tTime 0.015 (0.035)\tLoss 6.5519 (5.2637)\tPrec@1 69.000 (75.742)\tPrec@5 97.000 (96.806)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 5.1448 (5.3261)\tPrec@1 76.000 (75.512)\tPrec@5 94.000 (96.756)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 4.9333 (5.2069)\tPrec@1 77.000 (76.078)\tPrec@5 93.000 (96.627)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 5.5206 (5.2868)\tPrec@1 74.000 (75.705)\tPrec@5 96.000 (96.705)\n",
            "Test: [70/100]\tTime 0.016 (0.030)\tLoss 5.0960 (5.2896)\tPrec@1 76.000 (75.704)\tPrec@5 96.000 (96.789)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 5.5798 (5.2599)\tPrec@1 72.000 (75.679)\tPrec@5 99.000 (96.914)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 5.1133 (5.3012)\tPrec@1 77.000 (75.495)\tPrec@5 99.000 (96.978)\n",
            "val Results: Prec@1 75.580 Prec@5 96.910 Loss 5.32630\n",
            "val Class Accuracy: [0.893,0.930,0.748,0.794,0.656,0.698,0.855,0.617,0.572,0.795]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [86][0/329], lr: 0.01000\tTime 0.639 (0.639)\tData 0.567 (0.567)\tLoss 2.1386 (2.1386)\tPrec@1 88.672 (88.672)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [86][10/329], lr: 0.01000\tTime 0.072 (0.144)\tData 0.000 (0.057)\tLoss 2.5220 (3.1908)\tPrec@1 87.109 (82.777)\tPrec@5 99.219 (97.940)\n",
            "Epoch: [86][20/329], lr: 0.01000\tTime 0.085 (0.122)\tData 0.006 (0.033)\tLoss 3.0556 (2.9396)\tPrec@1 83.594 (84.189)\tPrec@5 98.047 (98.270)\n",
            "Epoch: [86][30/329], lr: 0.01000\tTime 0.083 (0.111)\tData 0.005 (0.024)\tLoss 2.0970 (2.7743)\tPrec@1 86.719 (85.144)\tPrec@5 99.219 (98.337)\n",
            "Epoch: [86][40/329], lr: 0.01000\tTime 0.064 (0.107)\tData 0.000 (0.020)\tLoss 2.0465 (2.6434)\tPrec@1 89.062 (86.004)\tPrec@5 99.219 (98.561)\n",
            "Epoch: [86][50/329], lr: 0.01000\tTime 0.078 (0.103)\tData 0.000 (0.017)\tLoss 1.7658 (2.5443)\tPrec@1 91.016 (86.581)\tPrec@5 99.219 (98.683)\n",
            "Epoch: [86][60/329], lr: 0.01000\tTime 0.067 (0.101)\tData 0.003 (0.016)\tLoss 1.8179 (2.4361)\tPrec@1 91.797 (87.218)\tPrec@5 99.609 (98.777)\n",
            "Epoch: [86][70/329], lr: 0.01000\tTime 0.084 (0.100)\tData 0.000 (0.014)\tLoss 1.4997 (2.3361)\tPrec@1 92.578 (87.731)\tPrec@5 100.000 (98.845)\n",
            "Epoch: [86][80/329], lr: 0.01000\tTime 0.086 (0.099)\tData 0.000 (0.013)\tLoss 1.6703 (2.2799)\tPrec@1 91.406 (88.030)\tPrec@5 100.000 (98.867)\n",
            "Epoch: [86][90/329], lr: 0.01000\tTime 0.070 (0.098)\tData 0.000 (0.012)\tLoss 2.1344 (2.2250)\tPrec@1 90.234 (88.384)\tPrec@5 99.219 (98.910)\n",
            "Epoch: [86][100/329], lr: 0.01000\tTime 0.135 (0.099)\tData 0.010 (0.012)\tLoss 1.5324 (2.1903)\tPrec@1 92.188 (88.579)\tPrec@5 98.438 (98.933)\n",
            "Epoch: [86][110/329], lr: 0.01000\tTime 0.109 (0.100)\tData 0.009 (0.011)\tLoss 1.4635 (2.1548)\tPrec@1 94.141 (88.820)\tPrec@5 99.219 (98.962)\n",
            "Epoch: [86][120/329], lr: 0.01000\tTime 0.183 (0.103)\tData 0.114 (0.014)\tLoss 1.6113 (2.1172)\tPrec@1 92.969 (89.004)\tPrec@5 99.609 (99.009)\n",
            "Epoch: [86][130/329], lr: 0.01000\tTime 0.103 (0.104)\tData 0.003 (0.015)\tLoss 1.7718 (2.0889)\tPrec@1 91.016 (89.173)\tPrec@5 99.609 (99.037)\n",
            "Epoch: [86][140/329], lr: 0.01000\tTime 0.085 (0.103)\tData 0.000 (0.014)\tLoss 1.4602 (2.0752)\tPrec@1 92.188 (89.243)\tPrec@5 98.828 (99.075)\n",
            "Epoch: [86][150/329], lr: 0.01000\tTime 0.093 (0.103)\tData 0.003 (0.013)\tLoss 2.0379 (2.0707)\tPrec@1 90.234 (89.303)\tPrec@5 99.609 (99.089)\n",
            "Epoch: [86][160/329], lr: 0.01000\tTime 0.109 (0.102)\tData 0.001 (0.013)\tLoss 1.6195 (2.0470)\tPrec@1 91.406 (89.412)\tPrec@5 100.000 (99.119)\n",
            "Epoch: [86][170/329], lr: 0.01000\tTime 0.096 (0.101)\tData 0.005 (0.012)\tLoss 1.6107 (2.0337)\tPrec@1 91.406 (89.474)\tPrec@5 99.609 (99.137)\n",
            "Epoch: [86][180/329], lr: 0.01000\tTime 0.103 (0.101)\tData 0.000 (0.012)\tLoss 2.2092 (2.0185)\tPrec@1 87.891 (89.555)\tPrec@5 99.219 (99.158)\n",
            "Epoch: [86][190/329], lr: 0.01000\tTime 0.088 (0.100)\tData 0.005 (0.012)\tLoss 1.7739 (1.9990)\tPrec@1 91.406 (89.649)\tPrec@5 100.000 (99.174)\n",
            "Epoch: [86][200/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.000 (0.011)\tLoss 1.5777 (1.9833)\tPrec@1 92.578 (89.739)\tPrec@5 100.000 (99.192)\n",
            "Epoch: [86][210/329], lr: 0.01000\tTime 0.090 (0.099)\tData 0.000 (0.011)\tLoss 1.9297 (1.9726)\tPrec@1 89.453 (89.792)\tPrec@5 99.219 (99.195)\n",
            "Epoch: [86][220/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.000 (0.011)\tLoss 1.2646 (1.9615)\tPrec@1 93.750 (89.853)\tPrec@5 99.609 (99.208)\n",
            "Epoch: [86][230/329], lr: 0.01000\tTime 0.086 (0.098)\tData 0.006 (0.011)\tLoss 1.4990 (1.9493)\tPrec@1 91.797 (89.908)\tPrec@5 98.828 (99.214)\n",
            "Epoch: [86][240/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.005 (0.011)\tLoss 1.6427 (1.9456)\tPrec@1 91.797 (89.935)\tPrec@5 99.609 (99.228)\n",
            "Epoch: [86][250/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.000 (0.010)\tLoss 2.0867 (1.9344)\tPrec@1 90.625 (89.978)\tPrec@5 98.828 (99.237)\n",
            "Epoch: [86][260/329], lr: 0.01000\tTime 0.079 (0.097)\tData 0.006 (0.010)\tLoss 1.9522 (1.9243)\tPrec@1 91.797 (90.029)\tPrec@5 98.438 (99.243)\n",
            "Epoch: [86][270/329], lr: 0.01000\tTime 0.054 (0.096)\tData 0.002 (0.010)\tLoss 1.4663 (1.9105)\tPrec@1 92.969 (90.103)\tPrec@5 100.000 (99.256)\n",
            "Epoch: [86][280/329], lr: 0.01000\tTime 0.070 (0.096)\tData 0.006 (0.010)\tLoss 1.1395 (1.9014)\tPrec@1 94.531 (90.157)\tPrec@5 100.000 (99.263)\n",
            "Epoch: [86][290/329], lr: 0.01000\tTime 0.103 (0.096)\tData 0.009 (0.010)\tLoss 1.4922 (1.8979)\tPrec@1 92.578 (90.171)\tPrec@5 98.828 (99.252)\n",
            "Epoch: [86][300/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.007 (0.010)\tLoss 1.6080 (1.8927)\tPrec@1 91.016 (90.201)\tPrec@5 99.609 (99.260)\n",
            "Epoch: [86][310/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.005 (0.010)\tLoss 1.7928 (1.8885)\tPrec@1 91.016 (90.241)\tPrec@5 98.828 (99.253)\n",
            "Epoch: [86][320/329], lr: 0.01000\tTime 0.111 (0.095)\tData 0.073 (0.010)\tLoss 1.8057 (1.8877)\tPrec@1 90.234 (90.240)\tPrec@5 99.609 (99.254)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 5.1963 (5.1963)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.052)\tLoss 4.4078 (5.7124)\tPrec@1 78.000 (73.909)\tPrec@5 97.000 (97.636)\n",
            "Test: [20/100]\tTime 0.036 (0.039)\tLoss 4.8770 (5.4935)\tPrec@1 76.000 (74.762)\tPrec@5 98.000 (97.333)\n",
            "Test: [30/100]\tTime 0.025 (0.035)\tLoss 4.9220 (5.4408)\tPrec@1 77.000 (75.194)\tPrec@5 98.000 (97.258)\n",
            "Test: [40/100]\tTime 0.020 (0.032)\tLoss 5.1745 (5.4900)\tPrec@1 77.000 (74.756)\tPrec@5 95.000 (97.098)\n",
            "Test: [50/100]\tTime 0.021 (0.030)\tLoss 5.3419 (5.4788)\tPrec@1 74.000 (74.647)\tPrec@5 98.000 (97.176)\n",
            "Test: [60/100]\tTime 0.012 (0.029)\tLoss 5.4045 (5.5257)\tPrec@1 74.000 (74.328)\tPrec@5 99.000 (97.246)\n",
            "Test: [70/100]\tTime 0.012 (0.028)\tLoss 5.2010 (5.5132)\tPrec@1 75.000 (74.380)\tPrec@5 98.000 (97.324)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 4.9503 (5.5037)\tPrec@1 79.000 (74.481)\tPrec@5 97.000 (97.346)\n",
            "Test: [90/100]\tTime 0.038 (0.028)\tLoss 5.1862 (5.5246)\tPrec@1 75.000 (74.308)\tPrec@5 100.000 (97.319)\n",
            "val Results: Prec@1 74.390 Prec@5 97.260 Loss 5.53188\n",
            "val Class Accuracy: [0.854,0.980,0.841,0.652,0.751,0.399,0.885,0.589,0.888,0.600]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [87][0/329], lr: 0.01000\tTime 0.623 (0.623)\tData 0.538 (0.538)\tLoss 2.3290 (2.3290)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [87][10/329], lr: 0.01000\tTime 0.084 (0.146)\tData 0.005 (0.055)\tLoss 1.8172 (2.2499)\tPrec@1 91.797 (88.317)\tPrec@5 98.828 (98.899)\n",
            "Epoch: [87][20/329], lr: 0.01000\tTime 0.089 (0.120)\tData 0.007 (0.033)\tLoss 1.7420 (2.0723)\tPrec@1 89.844 (89.342)\tPrec@5 98.828 (99.070)\n",
            "Epoch: [87][30/329], lr: 0.01000\tTime 0.090 (0.110)\tData 0.000 (0.024)\tLoss 1.8516 (1.9711)\tPrec@1 89.844 (89.856)\tPrec@5 98.047 (99.156)\n",
            "Epoch: [87][40/329], lr: 0.01000\tTime 0.081 (0.104)\tData 0.007 (0.020)\tLoss 1.7806 (1.9048)\tPrec@1 90.625 (90.149)\tPrec@5 98.438 (99.238)\n",
            "Epoch: [87][50/329], lr: 0.01000\tTime 0.107 (0.101)\tData 0.006 (0.018)\tLoss 1.3212 (1.8792)\tPrec@1 94.141 (90.273)\tPrec@5 100.000 (99.265)\n",
            "Epoch: [87][60/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.000 (0.016)\tLoss 1.8491 (1.8554)\tPrec@1 91.797 (90.439)\tPrec@5 99.219 (99.302)\n",
            "Epoch: [87][70/329], lr: 0.01000\tTime 0.093 (0.097)\tData 0.004 (0.015)\tLoss 1.5033 (1.8314)\tPrec@1 92.188 (90.631)\tPrec@5 99.219 (99.323)\n",
            "Epoch: [87][80/329], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.014)\tLoss 2.2630 (1.8249)\tPrec@1 88.281 (90.649)\tPrec@5 99.219 (99.339)\n",
            "Epoch: [87][90/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.013)\tLoss 1.5960 (1.8253)\tPrec@1 90.234 (90.616)\tPrec@5 99.219 (99.326)\n",
            "Epoch: [87][100/329], lr: 0.01000\tTime 0.112 (0.094)\tData 0.000 (0.012)\tLoss 1.7634 (1.8277)\tPrec@1 91.797 (90.617)\tPrec@5 98.828 (99.346)\n",
            "Epoch: [87][110/329], lr: 0.01000\tTime 0.063 (0.094)\tData 0.001 (0.012)\tLoss 1.2429 (1.8126)\tPrec@1 94.141 (90.688)\tPrec@5 100.000 (99.388)\n",
            "Epoch: [87][120/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.000 (0.011)\tLoss 1.5690 (1.7795)\tPrec@1 92.578 (90.877)\tPrec@5 99.609 (99.416)\n",
            "Epoch: [87][130/329], lr: 0.01000\tTime 0.086 (0.093)\tData 0.000 (0.011)\tLoss 1.7439 (1.7828)\tPrec@1 90.234 (90.887)\tPrec@5 100.000 (99.416)\n",
            "Epoch: [87][140/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.000 (0.010)\tLoss 2.1092 (1.7827)\tPrec@1 89.844 (90.933)\tPrec@5 98.047 (99.407)\n",
            "Epoch: [87][150/329], lr: 0.01000\tTime 0.097 (0.093)\tData 0.000 (0.010)\tLoss 1.4647 (1.7732)\tPrec@1 92.188 (90.992)\tPrec@5 99.219 (99.408)\n",
            "Epoch: [87][160/329], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.010)\tLoss 1.6617 (1.7719)\tPrec@1 90.625 (90.972)\tPrec@5 99.609 (99.418)\n",
            "Epoch: [87][170/329], lr: 0.01000\tTime 0.079 (0.092)\tData 0.004 (0.010)\tLoss 1.8391 (1.7712)\tPrec@1 91.016 (90.972)\tPrec@5 99.219 (99.413)\n",
            "Epoch: [87][180/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.010)\tLoss 1.6392 (1.7588)\tPrec@1 91.016 (91.048)\tPrec@5 99.609 (99.424)\n",
            "Epoch: [87][190/329], lr: 0.01000\tTime 0.108 (0.092)\tData 0.005 (0.010)\tLoss 2.0862 (1.7648)\tPrec@1 87.891 (91.001)\tPrec@5 99.609 (99.433)\n",
            "Epoch: [87][200/329], lr: 0.01000\tTime 0.128 (0.092)\tData 0.009 (0.009)\tLoss 1.9451 (1.7640)\tPrec@1 90.234 (90.994)\tPrec@5 99.219 (99.431)\n",
            "Epoch: [87][210/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.004 (0.009)\tLoss 2.2317 (1.7581)\tPrec@1 89.062 (91.027)\tPrec@5 98.828 (99.430)\n",
            "Epoch: [87][220/329], lr: 0.01000\tTime 0.130 (0.093)\tData 0.010 (0.009)\tLoss 1.3814 (1.7512)\tPrec@1 93.359 (91.056)\tPrec@5 99.609 (99.438)\n",
            "Epoch: [87][230/329], lr: 0.01000\tTime 0.113 (0.095)\tData 0.000 (0.011)\tLoss 1.9734 (1.7594)\tPrec@1 88.281 (91.004)\tPrec@5 99.609 (99.432)\n",
            "Epoch: [87][240/329], lr: 0.01000\tTime 0.089 (0.096)\tData 0.005 (0.011)\tLoss 1.3104 (1.7542)\tPrec@1 93.750 (91.030)\tPrec@5 98.828 (99.429)\n",
            "Epoch: [87][250/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.000 (0.011)\tLoss 1.6719 (1.7547)\tPrec@1 91.406 (91.033)\tPrec@5 100.000 (99.434)\n",
            "Epoch: [87][260/329], lr: 0.01000\tTime 0.096 (0.095)\tData 0.007 (0.011)\tLoss 1.5220 (1.7550)\tPrec@1 91.406 (91.013)\tPrec@5 100.000 (99.440)\n",
            "Epoch: [87][270/329], lr: 0.01000\tTime 0.105 (0.095)\tData 0.000 (0.010)\tLoss 1.9472 (1.7509)\tPrec@1 90.234 (91.049)\tPrec@5 99.219 (99.434)\n",
            "Epoch: [87][280/329], lr: 0.01000\tTime 0.108 (0.095)\tData 0.010 (0.010)\tLoss 2.5480 (1.7563)\tPrec@1 87.109 (91.016)\tPrec@5 99.609 (99.426)\n",
            "Epoch: [87][290/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.000 (0.010)\tLoss 1.3763 (1.7466)\tPrec@1 92.969 (91.059)\tPrec@5 99.609 (99.427)\n",
            "Epoch: [87][300/329], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.010)\tLoss 0.8470 (1.7506)\tPrec@1 95.703 (91.043)\tPrec@5 99.219 (99.421)\n",
            "Epoch: [87][310/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.006 (0.010)\tLoss 1.9687 (1.7514)\tPrec@1 87.891 (91.042)\tPrec@5 99.219 (99.413)\n",
            "Epoch: [87][320/329], lr: 0.01000\tTime 0.139 (0.094)\tData 0.069 (0.010)\tLoss 1.7815 (1.7520)\tPrec@1 90.234 (91.033)\tPrec@5 99.609 (99.422)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 5.4778 (5.4778)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.028 (0.053)\tLoss 5.4251 (6.2309)\tPrec@1 75.000 (73.182)\tPrec@5 97.000 (96.182)\n",
            "Test: [20/100]\tTime 0.022 (0.038)\tLoss 4.4892 (6.0221)\tPrec@1 80.000 (74.429)\tPrec@5 97.000 (96.524)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 6.3324 (6.0662)\tPrec@1 73.000 (74.290)\tPrec@5 96.000 (96.161)\n",
            "Test: [40/100]\tTime 0.030 (0.032)\tLoss 5.7618 (6.0466)\tPrec@1 75.000 (74.073)\tPrec@5 99.000 (96.098)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 5.7529 (6.0985)\tPrec@1 75.000 (73.686)\tPrec@5 96.000 (96.294)\n",
            "Test: [60/100]\tTime 0.017 (0.029)\tLoss 4.8229 (6.0568)\tPrec@1 79.000 (73.836)\tPrec@5 98.000 (96.459)\n",
            "Test: [70/100]\tTime 0.027 (0.028)\tLoss 6.0558 (6.0666)\tPrec@1 72.000 (73.761)\tPrec@5 96.000 (96.268)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 5.1336 (6.0078)\tPrec@1 78.000 (74.136)\tPrec@5 97.000 (96.469)\n",
            "Test: [90/100]\tTime 0.029 (0.027)\tLoss 6.1373 (6.0697)\tPrec@1 76.000 (73.813)\tPrec@5 98.000 (96.473)\n",
            "val Results: Prec@1 73.600 Prec@5 96.400 Loss 6.11489\n",
            "val Class Accuracy: [0.925,0.978,0.779,0.617,0.810,0.816,0.839,0.719,0.537,0.340]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [88][0/329], lr: 0.01000\tTime 0.644 (0.644)\tData 0.552 (0.552)\tLoss 2.0888 (2.0888)\tPrec@1 88.281 (88.281)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [88][10/329], lr: 0.01000\tTime 0.070 (0.146)\tData 0.000 (0.057)\tLoss 3.1240 (2.6159)\tPrec@1 83.984 (85.973)\tPrec@5 100.000 (98.828)\n",
            "Epoch: [88][20/329], lr: 0.01000\tTime 0.077 (0.119)\tData 0.002 (0.034)\tLoss 2.0335 (2.4070)\tPrec@1 89.062 (87.370)\tPrec@5 99.219 (98.977)\n",
            "Epoch: [88][30/329], lr: 0.01000\tTime 0.079 (0.108)\tData 0.006 (0.025)\tLoss 1.9466 (2.3426)\tPrec@1 88.281 (87.639)\tPrec@5 99.609 (98.979)\n",
            "Epoch: [88][40/329], lr: 0.01000\tTime 0.086 (0.103)\tData 0.007 (0.021)\tLoss 1.7402 (2.2175)\tPrec@1 91.797 (88.443)\tPrec@5 99.609 (99.066)\n",
            "Epoch: [88][50/329], lr: 0.01000\tTime 0.092 (0.100)\tData 0.014 (0.018)\tLoss 1.3479 (2.1488)\tPrec@1 93.750 (88.825)\tPrec@5 99.219 (99.127)\n",
            "Epoch: [88][60/329], lr: 0.01000\tTime 0.090 (0.098)\tData 0.006 (0.017)\tLoss 1.2935 (2.0834)\tPrec@1 92.578 (89.229)\tPrec@5 99.609 (99.187)\n",
            "Epoch: [88][70/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.010 (0.016)\tLoss 1.9402 (2.0357)\tPrec@1 90.625 (89.475)\tPrec@5 98.828 (99.208)\n",
            "Epoch: [88][80/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.006 (0.015)\tLoss 1.5932 (1.9989)\tPrec@1 91.406 (89.656)\tPrec@5 99.609 (99.214)\n",
            "Epoch: [88][90/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.006 (0.014)\tLoss 1.6574 (1.9706)\tPrec@1 91.016 (89.758)\tPrec@5 98.828 (99.227)\n",
            "Epoch: [88][100/329], lr: 0.01000\tTime 0.072 (0.094)\tData 0.000 (0.013)\tLoss 1.8153 (1.9450)\tPrec@1 91.797 (89.902)\tPrec@5 98.828 (99.234)\n",
            "Epoch: [88][110/329], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.013)\tLoss 1.6247 (1.9191)\tPrec@1 91.797 (90.023)\tPrec@5 99.609 (99.250)\n",
            "Epoch: [88][120/329], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.012)\tLoss 1.6720 (1.8958)\tPrec@1 90.234 (90.160)\tPrec@5 99.609 (99.270)\n",
            "Epoch: [88][130/329], lr: 0.01000\tTime 0.097 (0.094)\tData 0.000 (0.012)\tLoss 2.0039 (1.8874)\tPrec@1 89.844 (90.219)\tPrec@5 98.828 (99.293)\n",
            "Epoch: [88][140/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.007 (0.011)\tLoss 1.4177 (1.8726)\tPrec@1 93.750 (90.304)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [88][150/329], lr: 0.01000\tTime 0.076 (0.093)\tData 0.003 (0.011)\tLoss 1.8552 (1.8703)\tPrec@1 90.625 (90.307)\tPrec@5 99.219 (99.325)\n",
            "Epoch: [88][160/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.008 (0.011)\tLoss 1.6069 (1.8679)\tPrec@1 91.797 (90.353)\tPrec@5 99.219 (99.330)\n",
            "Epoch: [88][170/329], lr: 0.01000\tTime 0.067 (0.092)\tData 0.000 (0.011)\tLoss 1.3192 (1.8640)\tPrec@1 93.750 (90.381)\tPrec@5 100.000 (99.340)\n",
            "Epoch: [88][180/329], lr: 0.01000\tTime 0.105 (0.092)\tData 0.004 (0.011)\tLoss 1.4251 (1.8543)\tPrec@1 91.406 (90.426)\tPrec@5 99.609 (99.355)\n",
            "Epoch: [88][190/329], lr: 0.01000\tTime 0.100 (0.092)\tData 0.000 (0.010)\tLoss 1.8812 (1.8461)\tPrec@1 90.234 (90.476)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [88][200/329], lr: 0.01000\tTime 0.076 (0.092)\tData 0.000 (0.010)\tLoss 1.6147 (1.8507)\tPrec@1 91.016 (90.438)\tPrec@5 99.609 (99.357)\n",
            "Epoch: [88][210/329], lr: 0.01000\tTime 0.091 (0.092)\tData 0.010 (0.010)\tLoss 1.5462 (1.8380)\tPrec@1 92.188 (90.495)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [88][220/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.005 (0.010)\tLoss 1.9490 (1.8281)\tPrec@1 90.625 (90.570)\tPrec@5 99.219 (99.364)\n",
            "Epoch: [88][230/329], lr: 0.01000\tTime 0.082 (0.092)\tData 0.000 (0.009)\tLoss 2.1666 (1.8253)\tPrec@1 88.281 (90.578)\tPrec@5 99.219 (99.369)\n",
            "Epoch: [88][240/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.012 (0.009)\tLoss 2.4264 (1.8187)\tPrec@1 85.547 (90.609)\tPrec@5 99.219 (99.373)\n",
            "Epoch: [88][250/329], lr: 0.01000\tTime 0.071 (0.091)\tData 0.000 (0.009)\tLoss 1.2782 (1.8153)\tPrec@1 93.359 (90.631)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [88][260/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.000 (0.009)\tLoss 1.6083 (1.8103)\tPrec@1 91.016 (90.661)\tPrec@5 99.219 (99.389)\n",
            "Epoch: [88][270/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.000 (0.009)\tLoss 1.4767 (1.8014)\tPrec@1 92.578 (90.711)\tPrec@5 99.609 (99.393)\n",
            "Epoch: [88][280/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.009)\tLoss 1.7168 (1.8050)\tPrec@1 91.016 (90.690)\tPrec@5 100.000 (99.398)\n",
            "Epoch: [88][290/329], lr: 0.01000\tTime 0.094 (0.091)\tData 0.004 (0.009)\tLoss 1.8397 (1.8061)\tPrec@1 91.406 (90.673)\tPrec@5 99.219 (99.389)\n",
            "Epoch: [88][300/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.005 (0.009)\tLoss 1.2370 (1.8048)\tPrec@1 93.750 (90.670)\tPrec@5 99.609 (99.391)\n",
            "Epoch: [88][310/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.007 (0.009)\tLoss 1.7982 (1.7985)\tPrec@1 90.234 (90.694)\tPrec@5 100.000 (99.397)\n",
            "Epoch: [88][320/329], lr: 0.01000\tTime 0.263 (0.092)\tData 0.174 (0.009)\tLoss 2.0283 (1.8004)\tPrec@1 89.062 (90.671)\tPrec@5 100.000 (99.398)\n",
            "Test: [0/100]\tTime 0.473 (0.473)\tLoss 5.1980 (5.1980)\tPrec@1 75.000 (75.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.054 (0.086)\tLoss 4.3796 (5.0606)\tPrec@1 79.000 (77.000)\tPrec@5 98.000 (97.455)\n",
            "Test: [20/100]\tTime 0.034 (0.063)\tLoss 4.5008 (4.8385)\tPrec@1 78.000 (77.857)\tPrec@5 98.000 (97.571)\n",
            "Test: [30/100]\tTime 0.029 (0.052)\tLoss 5.4084 (4.9541)\tPrec@1 78.000 (77.516)\tPrec@5 96.000 (97.161)\n",
            "Test: [40/100]\tTime 0.023 (0.045)\tLoss 4.8188 (5.0005)\tPrec@1 78.000 (77.585)\tPrec@5 96.000 (97.171)\n",
            "Test: [50/100]\tTime 0.037 (0.040)\tLoss 4.8704 (4.9600)\tPrec@1 77.000 (77.667)\tPrec@5 96.000 (97.275)\n",
            "Test: [60/100]\tTime 0.022 (0.038)\tLoss 5.0023 (5.0491)\tPrec@1 79.000 (77.180)\tPrec@5 97.000 (97.311)\n",
            "Test: [70/100]\tTime 0.017 (0.036)\tLoss 4.4602 (5.0464)\tPrec@1 77.000 (77.155)\tPrec@5 98.000 (97.352)\n",
            "Test: [80/100]\tTime 0.030 (0.035)\tLoss 4.7006 (5.0057)\tPrec@1 82.000 (77.284)\tPrec@5 97.000 (97.346)\n",
            "Test: [90/100]\tTime 0.012 (0.034)\tLoss 4.8777 (5.0239)\tPrec@1 76.000 (77.220)\tPrec@5 99.000 (97.297)\n",
            "val Results: Prec@1 77.330 Prec@5 97.300 Loss 5.02965\n",
            "val Class Accuracy: [0.836,0.961,0.767,0.828,0.871,0.720,0.698,0.721,0.660,0.671]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [89][0/329], lr: 0.01000\tTime 0.724 (0.724)\tData 0.622 (0.622)\tLoss 1.7023 (1.7023)\tPrec@1 91.016 (91.016)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [89][10/329], lr: 0.01000\tTime 0.093 (0.155)\tData 0.007 (0.062)\tLoss 1.7404 (1.5205)\tPrec@1 91.016 (92.401)\tPrec@5 99.609 (99.680)\n",
            "Epoch: [89][20/329], lr: 0.01000\tTime 0.052 (0.124)\tData 0.000 (0.037)\tLoss 2.4916 (1.6364)\tPrec@1 87.891 (91.741)\tPrec@5 99.219 (99.647)\n",
            "Epoch: [89][30/329], lr: 0.01000\tTime 0.071 (0.114)\tData 0.005 (0.028)\tLoss 2.7062 (1.6856)\tPrec@1 87.891 (91.469)\tPrec@5 98.828 (99.597)\n",
            "Epoch: [89][40/329], lr: 0.01000\tTime 0.085 (0.109)\tData 0.000 (0.023)\tLoss 1.4668 (1.7403)\tPrec@1 92.969 (91.178)\tPrec@5 99.219 (99.533)\n",
            "Epoch: [89][50/329], lr: 0.01000\tTime 0.087 (0.104)\tData 0.000 (0.019)\tLoss 1.7798 (1.7346)\tPrec@1 90.625 (91.215)\tPrec@5 99.219 (99.487)\n",
            "Epoch: [89][60/329], lr: 0.01000\tTime 0.072 (0.101)\tData 0.004 (0.017)\tLoss 1.5076 (1.7569)\tPrec@1 91.406 (91.067)\tPrec@5 99.609 (99.481)\n",
            "Epoch: [89][70/329], lr: 0.01000\tTime 0.084 (0.100)\tData 0.010 (0.016)\tLoss 1.5703 (1.7527)\tPrec@1 92.188 (91.148)\tPrec@5 99.219 (99.444)\n",
            "Epoch: [89][80/329], lr: 0.01000\tTime 0.098 (0.098)\tData 0.000 (0.014)\tLoss 1.7753 (1.7628)\tPrec@1 91.797 (91.064)\tPrec@5 99.219 (99.460)\n",
            "Epoch: [89][90/329], lr: 0.01000\tTime 0.072 (0.097)\tData 0.005 (0.013)\tLoss 1.4365 (1.7543)\tPrec@1 92.578 (91.097)\tPrec@5 98.438 (99.442)\n",
            "Epoch: [89][100/329], lr: 0.01000\tTime 0.113 (0.096)\tData 0.011 (0.013)\tLoss 1.6054 (1.7394)\tPrec@1 91.016 (91.159)\tPrec@5 100.000 (99.455)\n",
            "Epoch: [89][110/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.012)\tLoss 1.5379 (1.7376)\tPrec@1 93.359 (91.146)\tPrec@5 100.000 (99.465)\n",
            "Epoch: [89][120/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.006 (0.012)\tLoss 1.4515 (1.7396)\tPrec@1 92.969 (91.100)\tPrec@5 99.219 (99.454)\n",
            "Epoch: [89][130/329], lr: 0.01000\tTime 0.077 (0.094)\tData 0.003 (0.011)\tLoss 1.3774 (1.7260)\tPrec@1 93.750 (91.171)\tPrec@5 99.609 (99.445)\n",
            "Epoch: [89][140/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.007 (0.011)\tLoss 1.3723 (1.7185)\tPrec@1 93.359 (91.204)\tPrec@5 99.609 (99.451)\n",
            "Epoch: [89][150/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.005 (0.011)\tLoss 1.6166 (1.7189)\tPrec@1 92.188 (91.220)\tPrec@5 99.609 (99.444)\n",
            "Epoch: [89][160/329], lr: 0.01000\tTime 0.110 (0.093)\tData 0.006 (0.010)\tLoss 1.7060 (1.7188)\tPrec@1 91.406 (91.193)\tPrec@5 100.000 (99.440)\n",
            "Epoch: [89][170/329], lr: 0.01000\tTime 0.103 (0.093)\tData 0.000 (0.010)\tLoss 1.8894 (1.7228)\tPrec@1 91.797 (91.185)\tPrec@5 99.219 (99.440)\n",
            "Epoch: [89][180/329], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.010)\tLoss 1.7855 (1.7163)\tPrec@1 90.625 (91.201)\tPrec@5 99.219 (99.454)\n",
            "Epoch: [89][190/329], lr: 0.01000\tTime 0.098 (0.092)\tData 0.006 (0.010)\tLoss 2.3378 (1.7129)\tPrec@1 89.062 (91.230)\tPrec@5 99.219 (99.468)\n",
            "Epoch: [89][200/329], lr: 0.01000\tTime 0.067 (0.092)\tData 0.001 (0.009)\tLoss 1.0862 (1.7048)\tPrec@1 93.750 (91.276)\tPrec@5 100.000 (99.462)\n",
            "Epoch: [89][210/329], lr: 0.01000\tTime 0.077 (0.092)\tData 0.000 (0.009)\tLoss 1.9480 (1.7081)\tPrec@1 90.625 (91.254)\tPrec@5 99.219 (99.458)\n",
            "Epoch: [89][220/329], lr: 0.01000\tTime 0.102 (0.092)\tData 0.004 (0.009)\tLoss 2.0783 (1.7037)\tPrec@1 89.453 (91.265)\tPrec@5 99.219 (99.454)\n",
            "Epoch: [89][230/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.000 (0.009)\tLoss 1.3442 (1.7055)\tPrec@1 92.578 (91.259)\tPrec@5 99.609 (99.452)\n",
            "Epoch: [89][240/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.006 (0.009)\tLoss 1.4458 (1.7029)\tPrec@1 92.969 (91.290)\tPrec@5 99.219 (99.447)\n",
            "Epoch: [89][250/329], lr: 0.01000\tTime 0.108 (0.091)\tData 0.011 (0.009)\tLoss 1.9866 (1.7113)\tPrec@1 89.453 (91.248)\tPrec@5 99.219 (99.448)\n",
            "Epoch: [89][260/329], lr: 0.01000\tTime 0.078 (0.091)\tData 0.000 (0.009)\tLoss 1.8204 (1.7140)\tPrec@1 91.797 (91.240)\tPrec@5 100.000 (99.457)\n",
            "Epoch: [89][270/329], lr: 0.01000\tTime 0.099 (0.092)\tData 0.006 (0.009)\tLoss 1.2693 (1.7141)\tPrec@1 94.141 (91.243)\tPrec@5 99.609 (99.458)\n",
            "Epoch: [89][280/329], lr: 0.01000\tTime 0.072 (0.091)\tData 0.002 (0.009)\tLoss 1.3840 (1.7150)\tPrec@1 93.359 (91.235)\tPrec@5 99.219 (99.451)\n",
            "Epoch: [89][290/329], lr: 0.01000\tTime 0.095 (0.091)\tData 0.004 (0.009)\tLoss 2.0061 (1.7137)\tPrec@1 88.672 (91.236)\tPrec@5 100.000 (99.455)\n",
            "Epoch: [89][300/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.003 (0.008)\tLoss 1.9395 (1.7211)\tPrec@1 89.453 (91.196)\tPrec@5 99.219 (99.454)\n",
            "Epoch: [89][310/329], lr: 0.01000\tTime 0.100 (0.091)\tData 0.000 (0.008)\tLoss 1.6598 (1.7229)\tPrec@1 90.625 (91.171)\tPrec@5 99.219 (99.457)\n",
            "Epoch: [89][320/329], lr: 0.01000\tTime 0.138 (0.091)\tData 0.097 (0.009)\tLoss 1.2434 (1.7232)\tPrec@1 93.750 (91.168)\tPrec@5 100.000 (99.466)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 5.9703 (5.9703)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.050)\tLoss 4.7988 (5.7310)\tPrec@1 77.000 (74.727)\tPrec@5 97.000 (97.636)\n",
            "Test: [20/100]\tTime 0.046 (0.038)\tLoss 4.7365 (5.6807)\tPrec@1 78.000 (74.952)\tPrec@5 98.000 (97.857)\n",
            "Test: [30/100]\tTime 0.029 (0.034)\tLoss 6.3852 (5.7033)\tPrec@1 72.000 (74.839)\tPrec@5 96.000 (97.645)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 6.1504 (5.7111)\tPrec@1 72.000 (74.512)\tPrec@5 98.000 (97.537)\n",
            "Test: [50/100]\tTime 0.029 (0.030)\tLoss 5.8045 (5.6891)\tPrec@1 74.000 (74.431)\tPrec@5 98.000 (97.667)\n",
            "Test: [60/100]\tTime 0.020 (0.029)\tLoss 5.4572 (5.7100)\tPrec@1 75.000 (74.262)\tPrec@5 98.000 (97.803)\n",
            "Test: [70/100]\tTime 0.028 (0.028)\tLoss 6.2283 (5.7371)\tPrec@1 68.000 (74.056)\tPrec@5 98.000 (97.803)\n",
            "Test: [80/100]\tTime 0.022 (0.028)\tLoss 4.4828 (5.6814)\tPrec@1 81.000 (74.173)\tPrec@5 98.000 (97.827)\n",
            "Test: [90/100]\tTime 0.019 (0.027)\tLoss 5.6662 (5.7392)\tPrec@1 77.000 (73.945)\tPrec@5 98.000 (97.780)\n",
            "val Results: Prec@1 73.860 Prec@5 97.720 Loss 5.76231\n",
            "val Class Accuracy: [0.938,0.969,0.871,0.698,0.797,0.709,0.710,0.603,0.424,0.667]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [90][0/329], lr: 0.01000\tTime 0.623 (0.623)\tData 0.535 (0.535)\tLoss 2.1918 (2.1918)\tPrec@1 86.328 (86.328)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [90][10/329], lr: 0.01000\tTime 0.072 (0.142)\tData 0.000 (0.053)\tLoss 2.0655 (2.1923)\tPrec@1 88.281 (87.891)\tPrec@5 100.000 (98.899)\n",
            "Epoch: [90][20/329], lr: 0.01000\tTime 0.110 (0.120)\tData 0.005 (0.031)\tLoss 2.0703 (2.0518)\tPrec@1 89.062 (88.988)\tPrec@5 98.828 (99.051)\n",
            "Epoch: [90][30/329], lr: 0.01000\tTime 0.096 (0.109)\tData 0.000 (0.022)\tLoss 2.7268 (1.9837)\tPrec@1 86.719 (89.667)\tPrec@5 99.219 (99.231)\n",
            "Epoch: [90][40/329], lr: 0.01000\tTime 0.091 (0.105)\tData 0.007 (0.019)\tLoss 1.6121 (1.9149)\tPrec@1 91.016 (90.025)\tPrec@5 99.219 (99.304)\n",
            "Epoch: [90][50/329], lr: 0.01000\tTime 0.119 (0.102)\tData 0.000 (0.016)\tLoss 1.5895 (1.8942)\tPrec@1 90.625 (90.089)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [90][60/329], lr: 0.01000\tTime 0.108 (0.104)\tData 0.005 (0.015)\tLoss 2.1698 (1.8483)\tPrec@1 89.453 (90.375)\tPrec@5 99.609 (99.372)\n",
            "Epoch: [90][70/329], lr: 0.01000\tTime 0.085 (0.106)\tData 0.028 (0.017)\tLoss 2.1599 (1.8248)\tPrec@1 88.672 (90.482)\tPrec@5 99.609 (99.340)\n",
            "Epoch: [90][80/329], lr: 0.01000\tTime 0.097 (0.110)\tData 0.025 (0.021)\tLoss 1.5484 (1.8161)\tPrec@1 92.188 (90.504)\tPrec@5 98.828 (99.354)\n",
            "Epoch: [90][90/329], lr: 0.01000\tTime 0.118 (0.108)\tData 0.003 (0.020)\tLoss 1.7955 (1.8149)\tPrec@1 91.016 (90.535)\tPrec@5 100.000 (99.360)\n",
            "Epoch: [90][100/329], lr: 0.01000\tTime 0.086 (0.107)\tData 0.000 (0.018)\tLoss 1.6261 (1.7969)\tPrec@1 91.406 (90.675)\tPrec@5 99.609 (99.381)\n",
            "Epoch: [90][110/329], lr: 0.01000\tTime 0.095 (0.105)\tData 0.005 (0.017)\tLoss 2.0972 (1.7951)\tPrec@1 89.453 (90.681)\tPrec@5 99.609 (99.409)\n",
            "Epoch: [90][120/329], lr: 0.01000\tTime 0.079 (0.104)\tData 0.001 (0.016)\tLoss 1.6211 (1.7876)\tPrec@1 91.016 (90.719)\tPrec@5 100.000 (99.425)\n",
            "Epoch: [90][130/329], lr: 0.01000\tTime 0.087 (0.103)\tData 0.012 (0.016)\tLoss 1.3651 (1.7809)\tPrec@1 92.969 (90.759)\tPrec@5 100.000 (99.436)\n",
            "Epoch: [90][140/329], lr: 0.01000\tTime 0.076 (0.103)\tData 0.005 (0.015)\tLoss 1.6236 (1.7710)\tPrec@1 91.406 (90.794)\tPrec@5 100.000 (99.435)\n",
            "Epoch: [90][150/329], lr: 0.01000\tTime 0.086 (0.102)\tData 0.000 (0.015)\tLoss 1.4184 (1.7715)\tPrec@1 93.359 (90.806)\tPrec@5 99.609 (99.436)\n",
            "Epoch: [90][160/329], lr: 0.01000\tTime 0.092 (0.101)\tData 0.009 (0.014)\tLoss 1.9096 (1.7719)\tPrec@1 90.234 (90.836)\tPrec@5 100.000 (99.440)\n",
            "Epoch: [90][170/329], lr: 0.01000\tTime 0.072 (0.100)\tData 0.014 (0.014)\tLoss 2.2250 (1.7738)\tPrec@1 88.672 (90.801)\tPrec@5 99.609 (99.452)\n",
            "Epoch: [90][180/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.007 (0.014)\tLoss 1.3923 (1.7788)\tPrec@1 94.141 (90.800)\tPrec@5 99.609 (99.445)\n",
            "Epoch: [90][190/329], lr: 0.01000\tTime 0.096 (0.099)\tData 0.005 (0.013)\tLoss 1.4223 (1.7704)\tPrec@1 92.969 (90.846)\tPrec@5 100.000 (99.452)\n",
            "Epoch: [90][200/329], lr: 0.01000\tTime 0.075 (0.098)\tData 0.000 (0.013)\tLoss 0.9486 (1.7660)\tPrec@1 95.312 (90.895)\tPrec@5 100.000 (99.450)\n",
            "Epoch: [90][210/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.009 (0.013)\tLoss 2.0038 (1.7613)\tPrec@1 88.281 (90.918)\tPrec@5 99.219 (99.437)\n",
            "Epoch: [90][220/329], lr: 0.01000\tTime 0.084 (0.098)\tData 0.000 (0.013)\tLoss 1.2560 (1.7536)\tPrec@1 93.750 (90.961)\tPrec@5 100.000 (99.449)\n",
            "Epoch: [90][230/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.000 (0.012)\tLoss 1.4218 (1.7477)\tPrec@1 93.750 (91.005)\tPrec@5 100.000 (99.447)\n",
            "Epoch: [90][240/329], lr: 0.01000\tTime 0.081 (0.097)\tData 0.000 (0.012)\tLoss 1.9258 (1.7498)\tPrec@1 89.062 (90.985)\tPrec@5 100.000 (99.444)\n",
            "Epoch: [90][250/329], lr: 0.01000\tTime 0.086 (0.097)\tData 0.007 (0.012)\tLoss 1.4922 (1.7524)\tPrec@1 91.406 (90.967)\tPrec@5 100.000 (99.441)\n",
            "Epoch: [90][260/329], lr: 0.01000\tTime 0.088 (0.096)\tData 0.007 (0.012)\tLoss 1.8006 (1.7570)\tPrec@1 91.406 (90.938)\tPrec@5 99.219 (99.437)\n",
            "Epoch: [90][270/329], lr: 0.01000\tTime 0.087 (0.096)\tData 0.008 (0.012)\tLoss 1.0363 (1.7558)\tPrec@1 94.531 (90.945)\tPrec@5 100.000 (99.446)\n",
            "Epoch: [90][280/329], lr: 0.01000\tTime 0.080 (0.096)\tData 0.000 (0.011)\tLoss 2.2289 (1.7551)\tPrec@1 89.062 (90.943)\tPrec@5 98.828 (99.447)\n",
            "Epoch: [90][290/329], lr: 0.01000\tTime 0.097 (0.096)\tData 0.006 (0.011)\tLoss 2.1060 (1.7571)\tPrec@1 89.453 (90.938)\tPrec@5 98.828 (99.454)\n",
            "Epoch: [90][300/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.005 (0.011)\tLoss 1.5443 (1.7521)\tPrec@1 92.188 (90.969)\tPrec@5 99.219 (99.456)\n",
            "Epoch: [90][310/329], lr: 0.01000\tTime 0.077 (0.095)\tData 0.003 (0.011)\tLoss 1.8279 (1.7506)\tPrec@1 90.625 (90.973)\tPrec@5 99.219 (99.466)\n",
            "Epoch: [90][320/329], lr: 0.01000\tTime 0.114 (0.095)\tData 0.072 (0.011)\tLoss 1.6936 (1.7565)\tPrec@1 91.406 (90.939)\tPrec@5 99.609 (99.467)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 7.1055 (7.1055)\tPrec@1 67.000 (67.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.022 (0.053)\tLoss 6.0372 (7.4838)\tPrec@1 75.000 (66.636)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 5.2985 (7.3835)\tPrec@1 74.000 (67.000)\tPrec@5 96.000 (96.524)\n",
            "Test: [30/100]\tTime 0.016 (0.033)\tLoss 8.1910 (7.5047)\tPrec@1 60.000 (66.323)\tPrec@5 94.000 (96.290)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 7.5809 (7.5182)\tPrec@1 65.000 (66.220)\tPrec@5 95.000 (96.317)\n",
            "Test: [50/100]\tTime 0.012 (0.030)\tLoss 7.3044 (7.3979)\tPrec@1 69.000 (66.961)\tPrec@5 95.000 (96.255)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 6.0432 (7.4107)\tPrec@1 70.000 (66.754)\tPrec@5 99.000 (96.393)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 8.0419 (7.3975)\tPrec@1 63.000 (66.831)\tPrec@5 97.000 (96.437)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 7.1213 (7.3479)\tPrec@1 69.000 (67.074)\tPrec@5 97.000 (96.370)\n",
            "Test: [90/100]\tTime 0.026 (0.028)\tLoss 7.4679 (7.4047)\tPrec@1 69.000 (66.846)\tPrec@5 100.000 (96.341)\n",
            "val Results: Prec@1 66.880 Prec@5 96.220 Loss 7.40154\n",
            "val Class Accuracy: [0.983,0.951,0.613,0.872,0.596,0.629,0.721,0.512,0.359,0.452]\n",
            "Best Prec@1: 78.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [91][0/329], lr: 0.01000\tTime 0.540 (0.540)\tData 0.462 (0.462)\tLoss 1.6760 (1.6760)\tPrec@1 91.797 (91.797)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [91][10/329], lr: 0.01000\tTime 0.088 (0.134)\tData 0.000 (0.052)\tLoss 2.1563 (2.2888)\tPrec@1 88.672 (87.820)\tPrec@5 99.219 (98.899)\n",
            "Epoch: [91][20/329], lr: 0.01000\tTime 0.093 (0.114)\tData 0.005 (0.029)\tLoss 1.8063 (2.1263)\tPrec@1 91.406 (88.932)\tPrec@5 98.828 (99.256)\n",
            "Epoch: [91][30/329], lr: 0.01000\tTime 0.079 (0.107)\tData 0.000 (0.021)\tLoss 1.7371 (2.0098)\tPrec@1 91.797 (89.504)\tPrec@5 99.609 (99.345)\n",
            "Epoch: [91][40/329], lr: 0.01000\tTime 0.084 (0.104)\tData 0.000 (0.017)\tLoss 2.2321 (1.9584)\tPrec@1 89.453 (89.949)\tPrec@5 99.609 (99.343)\n",
            "Epoch: [91][50/329], lr: 0.01000\tTime 0.103 (0.102)\tData 0.005 (0.015)\tLoss 1.7911 (1.8784)\tPrec@1 91.016 (90.342)\tPrec@5 98.828 (99.341)\n",
            "Epoch: [91][60/329], lr: 0.01000\tTime 0.079 (0.100)\tData 0.006 (0.014)\tLoss 1.9597 (1.8578)\tPrec@1 89.453 (90.362)\tPrec@5 99.609 (99.328)\n",
            "Epoch: [91][70/329], lr: 0.01000\tTime 0.072 (0.098)\tData 0.000 (0.013)\tLoss 1.8408 (1.8376)\tPrec@1 89.062 (90.438)\tPrec@5 99.609 (99.373)\n",
            "Epoch: [91][80/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.001 (0.012)\tLoss 2.0121 (1.8369)\tPrec@1 91.016 (90.408)\tPrec@5 98.828 (99.388)\n",
            "Epoch: [91][90/329], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.011)\tLoss 1.4387 (1.8312)\tPrec@1 91.406 (90.406)\tPrec@5 99.609 (99.399)\n",
            "Epoch: [91][100/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.012 (0.011)\tLoss 1.9518 (1.8224)\tPrec@1 91.406 (90.455)\tPrec@5 100.000 (99.412)\n",
            "Epoch: [91][110/329], lr: 0.01000\tTime 0.068 (0.095)\tData 0.000 (0.011)\tLoss 1.8395 (1.8150)\tPrec@1 90.625 (90.519)\tPrec@5 100.000 (99.437)\n",
            "Epoch: [91][120/329], lr: 0.01000\tTime 0.088 (0.095)\tData 0.001 (0.011)\tLoss 1.6661 (1.8088)\tPrec@1 90.625 (90.554)\tPrec@5 100.000 (99.435)\n",
            "Epoch: [91][130/329], lr: 0.01000\tTime 0.100 (0.094)\tData 0.000 (0.010)\tLoss 1.5716 (1.7968)\tPrec@1 92.578 (90.637)\tPrec@5 98.828 (99.448)\n",
            "Epoch: [91][140/329], lr: 0.01000\tTime 0.068 (0.094)\tData 0.000 (0.010)\tLoss 1.2816 (1.7779)\tPrec@1 91.797 (90.728)\tPrec@5 100.000 (99.474)\n",
            "Epoch: [91][150/329], lr: 0.01000\tTime 0.114 (0.095)\tData 0.012 (0.010)\tLoss 1.5712 (1.7663)\tPrec@1 91.797 (90.809)\tPrec@5 98.828 (99.465)\n",
            "Epoch: [91][160/329], lr: 0.01000\tTime 0.125 (0.096)\tData 0.006 (0.010)\tLoss 2.3666 (1.7706)\tPrec@1 88.672 (90.766)\tPrec@5 99.219 (99.471)\n",
            "Epoch: [91][170/329], lr: 0.01000\tTime 0.111 (0.097)\tData 0.000 (0.010)\tLoss 1.2398 (1.7607)\tPrec@1 93.750 (90.833)\tPrec@5 99.609 (99.465)\n",
            "Epoch: [91][180/329], lr: 0.01000\tTime 0.101 (0.099)\tData 0.005 (0.011)\tLoss 1.5572 (1.7639)\tPrec@1 91.797 (90.808)\tPrec@5 99.609 (99.463)\n",
            "Epoch: [91][190/329], lr: 0.01000\tTime 0.109 (0.099)\tData 0.000 (0.011)\tLoss 1.9752 (1.7566)\tPrec@1 89.844 (90.862)\tPrec@5 99.609 (99.468)\n",
            "Epoch: [91][200/329], lr: 0.01000\tTime 0.100 (0.099)\tData 0.005 (0.010)\tLoss 1.9005 (1.7493)\tPrec@1 89.844 (90.915)\tPrec@5 99.609 (99.477)\n",
            "Epoch: [91][210/329], lr: 0.01000\tTime 0.088 (0.099)\tData 0.004 (0.010)\tLoss 1.5562 (1.7502)\tPrec@1 93.750 (90.916)\tPrec@5 99.219 (99.469)\n",
            "Epoch: [91][220/329], lr: 0.01000\tTime 0.073 (0.099)\tData 0.001 (0.010)\tLoss 1.7973 (1.7460)\tPrec@1 91.016 (90.952)\tPrec@5 99.609 (99.468)\n",
            "Epoch: [91][230/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.005 (0.010)\tLoss 2.0025 (1.7537)\tPrec@1 89.453 (90.907)\tPrec@5 99.609 (99.464)\n",
            "Epoch: [91][240/329], lr: 0.01000\tTime 0.082 (0.098)\tData 0.005 (0.010)\tLoss 2.4172 (1.7546)\tPrec@1 87.891 (90.912)\tPrec@5 99.219 (99.455)\n",
            "Epoch: [91][250/329], lr: 0.01000\tTime 0.078 (0.097)\tData 0.001 (0.010)\tLoss 1.5476 (1.7566)\tPrec@1 92.188 (90.910)\tPrec@5 98.828 (99.454)\n",
            "Epoch: [91][260/329], lr: 0.01000\tTime 0.077 (0.097)\tData 0.006 (0.010)\tLoss 1.3915 (1.7563)\tPrec@1 92.578 (90.897)\tPrec@5 100.000 (99.460)\n",
            "Epoch: [91][270/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.006 (0.010)\tLoss 1.6718 (1.7564)\tPrec@1 91.406 (90.906)\tPrec@5 99.609 (99.454)\n",
            "Epoch: [91][280/329], lr: 0.01000\tTime 0.076 (0.096)\tData 0.001 (0.009)\tLoss 1.8608 (1.7523)\tPrec@1 90.625 (90.925)\tPrec@5 99.219 (99.455)\n",
            "Epoch: [91][290/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.006 (0.009)\tLoss 2.0846 (1.7539)\tPrec@1 89.844 (90.916)\tPrec@5 98.828 (99.455)\n",
            "Epoch: [91][300/329], lr: 0.01000\tTime 0.091 (0.096)\tData 0.005 (0.009)\tLoss 1.5440 (1.7522)\tPrec@1 92.578 (90.925)\tPrec@5 100.000 (99.460)\n",
            "Epoch: [91][310/329], lr: 0.01000\tTime 0.078 (0.095)\tData 0.000 (0.009)\tLoss 2.6962 (1.7524)\tPrec@1 85.938 (90.938)\tPrec@5 99.219 (99.462)\n",
            "Epoch: [91][320/329], lr: 0.01000\tTime 0.121 (0.095)\tData 0.081 (0.009)\tLoss 1.7476 (1.7524)\tPrec@1 90.234 (90.941)\tPrec@5 99.609 (99.467)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 4.7660 (4.7660)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.052)\tLoss 3.6759 (4.5879)\tPrec@1 83.000 (79.545)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.025 (0.039)\tLoss 3.7189 (4.5209)\tPrec@1 80.000 (79.381)\tPrec@5 99.000 (98.476)\n",
            "Test: [30/100]\tTime 0.018 (0.033)\tLoss 4.6138 (4.6106)\tPrec@1 80.000 (78.839)\tPrec@5 96.000 (98.097)\n",
            "Test: [40/100]\tTime 0.039 (0.031)\tLoss 4.5306 (4.6690)\tPrec@1 81.000 (78.634)\tPrec@5 99.000 (97.976)\n",
            "Test: [50/100]\tTime 0.027 (0.030)\tLoss 6.0684 (4.6220)\tPrec@1 74.000 (78.882)\tPrec@5 96.000 (98.020)\n",
            "Test: [60/100]\tTime 0.024 (0.029)\tLoss 4.7548 (4.7036)\tPrec@1 77.000 (78.377)\tPrec@5 100.000 (98.131)\n",
            "Test: [70/100]\tTime 0.011 (0.028)\tLoss 4.3579 (4.7006)\tPrec@1 77.000 (78.282)\tPrec@5 98.000 (98.155)\n",
            "Test: [80/100]\tTime 0.023 (0.027)\tLoss 3.5675 (4.6977)\tPrec@1 84.000 (78.321)\tPrec@5 100.000 (98.185)\n",
            "Test: [90/100]\tTime 0.018 (0.027)\tLoss 3.6522 (4.7383)\tPrec@1 83.000 (78.176)\tPrec@5 100.000 (98.187)\n",
            "val Results: Prec@1 78.330 Prec@5 98.170 Loss 4.73296\n",
            "val Class Accuracy: [0.939,0.969,0.857,0.737,0.748,0.668,0.681,0.741,0.753,0.740]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [92][0/329], lr: 0.01000\tTime 0.650 (0.650)\tData 0.568 (0.568)\tLoss 1.6713 (1.6713)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [92][10/329], lr: 0.01000\tTime 0.087 (0.141)\tData 0.000 (0.054)\tLoss 1.4587 (1.6132)\tPrec@1 92.969 (91.690)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [92][20/329], lr: 0.01000\tTime 0.077 (0.117)\tData 0.000 (0.030)\tLoss 2.3769 (1.6907)\tPrec@1 88.672 (91.369)\tPrec@5 99.609 (99.591)\n",
            "Epoch: [92][30/329], lr: 0.01000\tTime 0.084 (0.108)\tData 0.000 (0.022)\tLoss 1.5421 (1.6901)\tPrec@1 92.188 (91.179)\tPrec@5 99.609 (99.483)\n",
            "Epoch: [92][40/329], lr: 0.01000\tTime 0.074 (0.104)\tData 0.005 (0.018)\tLoss 1.5775 (1.6924)\tPrec@1 92.188 (91.225)\tPrec@5 99.219 (99.428)\n",
            "Epoch: [92][50/329], lr: 0.01000\tTime 0.083 (0.102)\tData 0.000 (0.015)\tLoss 1.5124 (1.6823)\tPrec@1 92.578 (91.291)\tPrec@5 98.828 (99.433)\n",
            "Epoch: [92][60/329], lr: 0.01000\tTime 0.096 (0.100)\tData 0.011 (0.014)\tLoss 2.3446 (1.6802)\tPrec@1 86.328 (91.285)\tPrec@5 99.609 (99.449)\n",
            "Epoch: [92][70/329], lr: 0.01000\tTime 0.087 (0.099)\tData 0.005 (0.013)\tLoss 1.9802 (1.6950)\tPrec@1 89.844 (91.175)\tPrec@5 99.609 (99.483)\n",
            "Epoch: [92][80/329], lr: 0.01000\tTime 0.087 (0.098)\tData 0.000 (0.012)\tLoss 2.1018 (1.6994)\tPrec@1 89.453 (91.189)\tPrec@5 100.000 (99.503)\n",
            "Epoch: [92][90/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.001 (0.011)\tLoss 1.6795 (1.7197)\tPrec@1 92.969 (91.089)\tPrec@5 98.828 (99.468)\n",
            "Epoch: [92][100/329], lr: 0.01000\tTime 0.100 (0.096)\tData 0.005 (0.011)\tLoss 1.8835 (1.7237)\tPrec@1 89.844 (91.105)\tPrec@5 99.219 (99.459)\n",
            "Epoch: [92][110/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.003 (0.010)\tLoss 2.1593 (1.7246)\tPrec@1 87.891 (91.058)\tPrec@5 99.219 (99.465)\n",
            "Epoch: [92][120/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.000 (0.010)\tLoss 1.3691 (1.7215)\tPrec@1 92.578 (91.071)\tPrec@5 99.609 (99.464)\n",
            "Epoch: [92][130/329], lr: 0.01000\tTime 0.107 (0.095)\tData 0.000 (0.010)\tLoss 1.4572 (1.7210)\tPrec@1 94.141 (91.105)\tPrec@5 99.609 (99.469)\n",
            "Epoch: [92][140/329], lr: 0.01000\tTime 0.066 (0.095)\tData 0.000 (0.009)\tLoss 2.1677 (1.7157)\tPrec@1 89.844 (91.162)\tPrec@5 99.219 (99.479)\n",
            "Epoch: [92][150/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.007 (0.009)\tLoss 1.2287 (1.7079)\tPrec@1 92.969 (91.228)\tPrec@5 99.609 (99.480)\n",
            "Epoch: [92][160/329], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.009)\tLoss 1.9042 (1.6981)\tPrec@1 89.062 (91.297)\tPrec@5 99.219 (99.478)\n",
            "Epoch: [92][170/329], lr: 0.01000\tTime 0.104 (0.094)\tData 0.000 (0.009)\tLoss 1.5177 (1.6934)\tPrec@1 92.188 (91.310)\tPrec@5 100.000 (99.470)\n",
            "Epoch: [92][180/329], lr: 0.01000\tTime 0.075 (0.093)\tData 0.011 (0.009)\tLoss 1.8194 (1.6947)\tPrec@1 90.625 (91.316)\tPrec@5 99.609 (99.469)\n",
            "Epoch: [92][190/329], lr: 0.01000\tTime 0.077 (0.093)\tData 0.005 (0.009)\tLoss 1.5000 (1.6956)\tPrec@1 92.188 (91.320)\tPrec@5 99.609 (99.464)\n",
            "Epoch: [92][200/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.000 (0.009)\tLoss 2.0793 (1.6954)\tPrec@1 89.453 (91.330)\tPrec@5 99.609 (99.468)\n",
            "Epoch: [92][210/329], lr: 0.01000\tTime 0.082 (0.093)\tData 0.009 (0.009)\tLoss 1.7024 (1.6992)\tPrec@1 91.406 (91.304)\tPrec@5 99.219 (99.469)\n",
            "Epoch: [92][220/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.008)\tLoss 2.1517 (1.6970)\tPrec@1 88.672 (91.304)\tPrec@5 99.609 (99.472)\n",
            "Epoch: [92][230/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.000 (0.008)\tLoss 1.8838 (1.6985)\tPrec@1 90.234 (91.285)\tPrec@5 99.219 (99.474)\n",
            "Epoch: [92][240/329], lr: 0.01000\tTime 0.072 (0.092)\tData 0.007 (0.008)\tLoss 1.7435 (1.7018)\tPrec@1 90.625 (91.252)\tPrec@5 99.609 (99.462)\n",
            "Epoch: [92][250/329], lr: 0.01000\tTime 0.124 (0.092)\tData 0.007 (0.008)\tLoss 1.4026 (1.7044)\tPrec@1 92.578 (91.221)\tPrec@5 99.609 (99.460)\n",
            "Epoch: [92][260/329], lr: 0.01000\tTime 0.123 (0.093)\tData 0.010 (0.008)\tLoss 1.3423 (1.7101)\tPrec@1 92.969 (91.173)\tPrec@5 100.000 (99.461)\n",
            "Epoch: [92][270/329], lr: 0.01000\tTime 0.128 (0.094)\tData 0.010 (0.008)\tLoss 1.6524 (1.7036)\tPrec@1 91.406 (91.209)\tPrec@5 99.609 (99.472)\n",
            "Epoch: [92][280/329], lr: 0.01000\tTime 0.158 (0.095)\tData 0.073 (0.009)\tLoss 1.5500 (1.7030)\tPrec@1 92.578 (91.213)\tPrec@5 98.828 (99.476)\n",
            "Epoch: [92][290/329], lr: 0.01000\tTime 0.098 (0.095)\tData 0.000 (0.010)\tLoss 1.9349 (1.6994)\tPrec@1 89.453 (91.236)\tPrec@5 99.219 (99.475)\n",
            "Epoch: [92][300/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.009)\tLoss 1.5433 (1.7004)\tPrec@1 92.578 (91.228)\tPrec@5 99.609 (99.477)\n",
            "Epoch: [92][310/329], lr: 0.01000\tTime 0.086 (0.095)\tData 0.000 (0.009)\tLoss 2.4169 (1.6987)\tPrec@1 86.719 (91.230)\tPrec@5 98.438 (99.470)\n",
            "Epoch: [92][320/329], lr: 0.01000\tTime 0.123 (0.095)\tData 0.071 (0.009)\tLoss 1.7703 (1.6975)\tPrec@1 90.234 (91.242)\tPrec@5 99.609 (99.457)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 5.6720 (5.6720)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.046 (0.057)\tLoss 4.4090 (5.1881)\tPrec@1 80.000 (76.727)\tPrec@5 96.000 (97.636)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 4.5983 (5.4306)\tPrec@1 78.000 (75.333)\tPrec@5 100.000 (97.571)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 6.6587 (5.5101)\tPrec@1 70.000 (74.871)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.033 (0.032)\tLoss 5.7375 (5.5198)\tPrec@1 72.000 (74.756)\tPrec@5 97.000 (97.561)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 5.3720 (5.4339)\tPrec@1 74.000 (75.216)\tPrec@5 96.000 (97.588)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 4.8994 (5.4738)\tPrec@1 79.000 (75.000)\tPrec@5 96.000 (97.607)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 5.2924 (5.4876)\tPrec@1 73.000 (74.831)\tPrec@5 99.000 (97.704)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 4.3501 (5.4264)\tPrec@1 82.000 (75.222)\tPrec@5 98.000 (97.667)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 5.3756 (5.4872)\tPrec@1 77.000 (75.011)\tPrec@5 99.000 (97.626)\n",
            "val Results: Prec@1 75.060 Prec@5 97.660 Loss 5.47920\n",
            "val Class Accuracy: [0.971,0.960,0.743,0.739,0.794,0.674,0.717,0.682,0.400,0.826]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [93][0/329], lr: 0.01000\tTime 0.638 (0.638)\tData 0.572 (0.572)\tLoss 1.1693 (1.1693)\tPrec@1 94.141 (94.141)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [93][10/329], lr: 0.01000\tTime 0.085 (0.144)\tData 0.004 (0.057)\tLoss 2.0543 (2.0829)\tPrec@1 88.281 (89.098)\tPrec@5 99.609 (99.183)\n",
            "Epoch: [93][20/329], lr: 0.01000\tTime 0.072 (0.118)\tData 0.000 (0.033)\tLoss 1.9328 (2.1283)\tPrec@1 91.406 (89.156)\tPrec@5 98.438 (99.089)\n",
            "Epoch: [93][30/329], lr: 0.01000\tTime 0.085 (0.109)\tData 0.000 (0.025)\tLoss 1.7614 (2.0223)\tPrec@1 89.453 (89.642)\tPrec@5 99.219 (99.156)\n",
            "Epoch: [93][40/329], lr: 0.01000\tTime 0.086 (0.103)\tData 0.000 (0.020)\tLoss 1.1924 (1.9509)\tPrec@1 94.141 (90.044)\tPrec@5 100.000 (99.171)\n",
            "Epoch: [93][50/329], lr: 0.01000\tTime 0.094 (0.100)\tData 0.005 (0.017)\tLoss 1.9486 (1.9224)\tPrec@1 87.891 (90.165)\tPrec@5 98.828 (99.157)\n",
            "Epoch: [93][60/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.000 (0.015)\tLoss 2.3353 (1.9012)\tPrec@1 87.109 (90.151)\tPrec@5 98.828 (99.219)\n",
            "Epoch: [93][70/329], lr: 0.01000\tTime 0.092 (0.097)\tData 0.007 (0.014)\tLoss 1.8857 (1.8789)\tPrec@1 89.062 (90.245)\tPrec@5 99.219 (99.230)\n",
            "Epoch: [93][80/329], lr: 0.01000\tTime 0.096 (0.096)\tData 0.000 (0.013)\tLoss 2.0707 (1.8740)\tPrec@1 89.062 (90.230)\tPrec@5 98.828 (99.233)\n",
            "Epoch: [93][90/329], lr: 0.01000\tTime 0.099 (0.095)\tData 0.000 (0.012)\tLoss 2.3329 (1.8619)\tPrec@1 88.281 (90.290)\tPrec@5 98.828 (99.253)\n",
            "Epoch: [93][100/329], lr: 0.01000\tTime 0.063 (0.094)\tData 0.004 (0.011)\tLoss 1.6472 (1.8475)\tPrec@1 91.016 (90.362)\tPrec@5 100.000 (99.261)\n",
            "Epoch: [93][110/329], lr: 0.01000\tTime 0.110 (0.094)\tData 0.005 (0.011)\tLoss 1.5699 (1.8291)\tPrec@1 90.625 (90.467)\tPrec@5 100.000 (99.265)\n",
            "Epoch: [93][120/329], lr: 0.01000\tTime 0.080 (0.094)\tData 0.002 (0.011)\tLoss 1.7533 (1.8278)\tPrec@1 89.844 (90.476)\tPrec@5 98.438 (99.264)\n",
            "Epoch: [93][130/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.010)\tLoss 2.2730 (1.8094)\tPrec@1 88.672 (90.592)\tPrec@5 98.047 (99.255)\n",
            "Epoch: [93][140/329], lr: 0.01000\tTime 0.116 (0.093)\tData 0.012 (0.010)\tLoss 1.2478 (1.7928)\tPrec@1 93.359 (90.700)\tPrec@5 99.219 (99.271)\n",
            "Epoch: [93][150/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.010)\tLoss 1.8030 (1.7905)\tPrec@1 89.453 (90.708)\tPrec@5 99.219 (99.281)\n",
            "Epoch: [93][160/329], lr: 0.01000\tTime 0.083 (0.093)\tData 0.000 (0.010)\tLoss 1.8514 (1.7875)\tPrec@1 90.234 (90.756)\tPrec@5 99.219 (99.299)\n",
            "Epoch: [93][170/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.007 (0.010)\tLoss 1.6443 (1.7765)\tPrec@1 92.969 (90.824)\tPrec@5 99.219 (99.312)\n",
            "Epoch: [93][180/329], lr: 0.01000\tTime 0.078 (0.092)\tData 0.004 (0.009)\tLoss 2.3068 (1.7712)\tPrec@1 87.891 (90.854)\tPrec@5 99.219 (99.329)\n",
            "Epoch: [93][190/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.005 (0.009)\tLoss 1.2062 (1.7580)\tPrec@1 94.141 (90.922)\tPrec@5 100.000 (99.337)\n",
            "Epoch: [93][200/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.011 (0.009)\tLoss 2.3188 (1.7631)\tPrec@1 89.453 (90.917)\tPrec@5 99.219 (99.328)\n",
            "Epoch: [93][210/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.003 (0.009)\tLoss 1.6109 (1.7589)\tPrec@1 91.406 (90.929)\tPrec@5 100.000 (99.341)\n",
            "Epoch: [93][220/329], lr: 0.01000\tTime 0.099 (0.091)\tData 0.016 (0.009)\tLoss 1.7714 (1.7629)\tPrec@1 90.234 (90.903)\tPrec@5 99.609 (99.364)\n",
            "Epoch: [93][230/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.000 (0.009)\tLoss 1.8442 (1.7601)\tPrec@1 90.625 (90.912)\tPrec@5 100.000 (99.378)\n",
            "Epoch: [93][240/329], lr: 0.01000\tTime 0.086 (0.091)\tData 0.001 (0.009)\tLoss 1.4127 (1.7631)\tPrec@1 93.359 (90.896)\tPrec@5 99.609 (99.387)\n",
            "Epoch: [93][250/329], lr: 0.01000\tTime 0.082 (0.091)\tData 0.006 (0.009)\tLoss 1.9747 (1.7596)\tPrec@1 89.453 (90.922)\tPrec@5 100.000 (99.392)\n",
            "Epoch: [93][260/329], lr: 0.01000\tTime 0.068 (0.091)\tData 0.000 (0.009)\tLoss 2.2049 (1.7601)\tPrec@1 88.672 (90.923)\tPrec@5 99.219 (99.392)\n",
            "Epoch: [93][270/329], lr: 0.01000\tTime 0.092 (0.091)\tData 0.005 (0.009)\tLoss 1.7196 (1.7593)\tPrec@1 91.406 (90.923)\tPrec@5 99.219 (99.400)\n",
            "Epoch: [93][280/329], lr: 0.01000\tTime 0.104 (0.091)\tData 0.007 (0.009)\tLoss 1.4483 (1.7569)\tPrec@1 92.578 (90.931)\tPrec@5 100.000 (99.412)\n",
            "Epoch: [93][290/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.007 (0.009)\tLoss 1.5254 (1.7529)\tPrec@1 92.188 (90.949)\tPrec@5 99.609 (99.413)\n",
            "Epoch: [93][300/329], lr: 0.01000\tTime 0.075 (0.091)\tData 0.004 (0.009)\tLoss 1.6191 (1.7530)\tPrec@1 90.625 (90.948)\tPrec@5 100.000 (99.412)\n",
            "Epoch: [93][310/329], lr: 0.01000\tTime 0.090 (0.091)\tData 0.000 (0.008)\tLoss 1.5943 (1.7468)\tPrec@1 92.188 (90.979)\tPrec@5 99.609 (99.418)\n",
            "Epoch: [93][320/329], lr: 0.01000\tTime 0.102 (0.091)\tData 0.066 (0.009)\tLoss 1.5006 (1.7471)\tPrec@1 92.188 (90.977)\tPrec@5 99.609 (99.416)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 5.8684 (5.8684)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.051)\tLoss 4.4320 (5.3498)\tPrec@1 79.000 (75.091)\tPrec@5 98.000 (97.455)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 4.5627 (5.3869)\tPrec@1 77.000 (75.095)\tPrec@5 97.000 (97.429)\n",
            "Test: [30/100]\tTime 0.021 (0.034)\tLoss 6.0165 (5.4663)\tPrec@1 71.000 (74.710)\tPrec@5 97.000 (97.129)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 5.1182 (5.4421)\tPrec@1 77.000 (74.732)\tPrec@5 97.000 (97.073)\n",
            "Test: [50/100]\tTime 0.027 (0.031)\tLoss 5.5144 (5.4111)\tPrec@1 75.000 (74.843)\tPrec@5 97.000 (97.176)\n",
            "Test: [60/100]\tTime 0.020 (0.029)\tLoss 5.1940 (5.4408)\tPrec@1 79.000 (74.770)\tPrec@5 95.000 (97.098)\n",
            "Test: [70/100]\tTime 0.028 (0.029)\tLoss 5.6188 (5.5212)\tPrec@1 77.000 (74.493)\tPrec@5 95.000 (97.014)\n",
            "Test: [80/100]\tTime 0.023 (0.028)\tLoss 4.5349 (5.4733)\tPrec@1 79.000 (74.679)\tPrec@5 97.000 (97.000)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 5.8545 (5.5417)\tPrec@1 75.000 (74.451)\tPrec@5 96.000 (96.978)\n",
            "val Results: Prec@1 74.400 Prec@5 96.990 Loss 5.55185\n",
            "val Class Accuracy: [0.970,0.882,0.615,0.715,0.883,0.701,0.692,0.769,0.430,0.783]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [94][0/329], lr: 0.01000\tTime 0.903 (0.903)\tData 0.808 (0.808)\tLoss 1.8812 (1.8812)\tPrec@1 90.234 (90.234)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [94][10/329], lr: 0.01000\tTime 0.104 (0.203)\tData 0.014 (0.101)\tLoss 2.2419 (2.6709)\tPrec@1 89.062 (85.795)\tPrec@5 97.656 (97.869)\n",
            "Epoch: [94][20/329], lr: 0.01000\tTime 0.085 (0.170)\tData 0.003 (0.066)\tLoss 2.9016 (2.5765)\tPrec@1 86.328 (86.310)\tPrec@5 98.047 (98.493)\n",
            "Epoch: [94][30/329], lr: 0.01000\tTime 0.100 (0.148)\tData 0.023 (0.047)\tLoss 1.7488 (2.5186)\tPrec@1 91.016 (86.706)\tPrec@5 99.219 (98.513)\n",
            "Epoch: [94][40/329], lr: 0.01000\tTime 0.083 (0.134)\tData 0.000 (0.037)\tLoss 1.5851 (2.3741)\tPrec@1 91.406 (87.605)\tPrec@5 99.219 (98.714)\n",
            "Epoch: [94][50/329], lr: 0.01000\tTime 0.078 (0.127)\tData 0.007 (0.031)\tLoss 2.2162 (2.3011)\tPrec@1 88.672 (87.929)\tPrec@5 99.219 (98.851)\n",
            "Epoch: [94][60/329], lr: 0.01000\tTime 0.093 (0.122)\tData 0.000 (0.027)\tLoss 1.9119 (2.2346)\tPrec@1 89.844 (88.352)\tPrec@5 100.000 (98.892)\n",
            "Epoch: [94][70/329], lr: 0.01000\tTime 0.085 (0.118)\tData 0.000 (0.023)\tLoss 2.0258 (2.1869)\tPrec@1 89.844 (88.655)\tPrec@5 99.609 (98.916)\n",
            "Epoch: [94][80/329], lr: 0.01000\tTime 0.093 (0.115)\tData 0.000 (0.021)\tLoss 2.0774 (2.1646)\tPrec@1 89.844 (88.749)\tPrec@5 99.219 (98.954)\n",
            "Epoch: [94][90/329], lr: 0.01000\tTime 0.062 (0.112)\tData 0.006 (0.020)\tLoss 1.8341 (2.1304)\tPrec@1 90.234 (88.947)\tPrec@5 100.000 (99.017)\n",
            "Epoch: [94][100/329], lr: 0.01000\tTime 0.087 (0.110)\tData 0.005 (0.018)\tLoss 1.6591 (2.0788)\tPrec@1 92.578 (89.233)\tPrec@5 99.609 (99.076)\n",
            "Epoch: [94][110/329], lr: 0.01000\tTime 0.096 (0.107)\tData 0.006 (0.018)\tLoss 2.0717 (2.0479)\tPrec@1 89.062 (89.411)\tPrec@5 100.000 (99.099)\n",
            "Epoch: [94][120/329], lr: 0.01000\tTime 0.118 (0.106)\tData 0.006 (0.016)\tLoss 1.4635 (2.0389)\tPrec@1 93.359 (89.447)\tPrec@5 98.438 (99.122)\n",
            "Epoch: [94][130/329], lr: 0.01000\tTime 0.087 (0.105)\tData 0.007 (0.016)\tLoss 1.9122 (2.0157)\tPrec@1 89.844 (89.563)\tPrec@5 99.219 (99.147)\n",
            "Epoch: [94][140/329], lr: 0.01000\tTime 0.068 (0.103)\tData 0.000 (0.015)\tLoss 1.5289 (1.9981)\tPrec@1 92.188 (89.680)\tPrec@5 99.219 (99.166)\n",
            "Epoch: [94][150/329], lr: 0.01000\tTime 0.083 (0.102)\tData 0.000 (0.015)\tLoss 1.7503 (1.9727)\tPrec@1 91.797 (89.823)\tPrec@5 99.609 (99.185)\n",
            "Epoch: [94][160/329], lr: 0.01000\tTime 0.099 (0.102)\tData 0.004 (0.014)\tLoss 1.3328 (1.9568)\tPrec@1 93.359 (89.914)\tPrec@5 99.609 (99.216)\n",
            "Epoch: [94][170/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.007 (0.014)\tLoss 2.0639 (1.9416)\tPrec@1 88.672 (89.985)\tPrec@5 99.219 (99.232)\n",
            "Epoch: [94][180/329], lr: 0.01000\tTime 0.084 (0.100)\tData 0.002 (0.013)\tLoss 1.2898 (1.9204)\tPrec@1 94.141 (90.109)\tPrec@5 99.609 (99.258)\n",
            "Epoch: [94][190/329], lr: 0.01000\tTime 0.071 (0.099)\tData 0.002 (0.013)\tLoss 1.2045 (1.9037)\tPrec@1 93.750 (90.193)\tPrec@5 100.000 (99.272)\n",
            "Epoch: [94][200/329], lr: 0.01000\tTime 0.084 (0.099)\tData 0.000 (0.013)\tLoss 1.5258 (1.9041)\tPrec@1 92.188 (90.188)\tPrec@5 99.609 (99.285)\n",
            "Epoch: [94][210/329], lr: 0.01000\tTime 0.106 (0.098)\tData 0.008 (0.012)\tLoss 1.3828 (1.8987)\tPrec@1 94.141 (90.207)\tPrec@5 100.000 (99.302)\n",
            "Epoch: [94][220/329], lr: 0.01000\tTime 0.093 (0.098)\tData 0.006 (0.012)\tLoss 1.0980 (1.8872)\tPrec@1 94.531 (90.270)\tPrec@5 100.000 (99.311)\n",
            "Epoch: [94][230/329], lr: 0.01000\tTime 0.088 (0.098)\tData 0.004 (0.012)\tLoss 2.0522 (1.8873)\tPrec@1 89.062 (90.282)\tPrec@5 98.438 (99.310)\n",
            "Epoch: [94][240/329], lr: 0.01000\tTime 0.082 (0.097)\tData 0.000 (0.012)\tLoss 1.9791 (1.8798)\tPrec@1 90.234 (90.328)\tPrec@5 98.828 (99.313)\n",
            "Epoch: [94][250/329], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.011)\tLoss 2.0329 (1.8892)\tPrec@1 88.672 (90.278)\tPrec@5 99.609 (99.318)\n",
            "Epoch: [94][260/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.007 (0.011)\tLoss 1.3721 (1.8839)\tPrec@1 92.188 (90.294)\tPrec@5 99.219 (99.324)\n",
            "Epoch: [94][270/329], lr: 0.01000\tTime 0.104 (0.096)\tData 0.004 (0.011)\tLoss 1.8014 (1.8846)\tPrec@1 91.016 (90.295)\tPrec@5 98.438 (99.314)\n",
            "Epoch: [94][280/329], lr: 0.01000\tTime 0.085 (0.096)\tData 0.005 (0.011)\tLoss 1.6232 (1.8774)\tPrec@1 91.406 (90.344)\tPrec@5 99.609 (99.322)\n",
            "Epoch: [94][290/329], lr: 0.01000\tTime 0.081 (0.096)\tData 0.000 (0.011)\tLoss 1.8601 (1.8664)\tPrec@1 90.625 (90.397)\tPrec@5 99.609 (99.336)\n",
            "Epoch: [94][300/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.005 (0.011)\tLoss 2.2433 (1.8626)\tPrec@1 88.672 (90.419)\tPrec@5 99.219 (99.337)\n",
            "Epoch: [94][310/329], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.011)\tLoss 1.8613 (1.8588)\tPrec@1 90.234 (90.443)\tPrec@5 98.828 (99.334)\n",
            "Epoch: [94][320/329], lr: 0.01000\tTime 0.145 (0.095)\tData 0.077 (0.011)\tLoss 1.7208 (1.8532)\tPrec@1 91.406 (90.475)\tPrec@5 100.000 (99.331)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 6.7178 (6.7178)\tPrec@1 69.000 (69.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.027 (0.053)\tLoss 5.8484 (6.3345)\tPrec@1 72.000 (71.091)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.010 (0.039)\tLoss 5.4371 (6.3006)\tPrec@1 74.000 (70.952)\tPrec@5 98.000 (97.905)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 6.4435 (6.2341)\tPrec@1 72.000 (71.774)\tPrec@5 97.000 (97.871)\n",
            "Test: [40/100]\tTime 0.027 (0.032)\tLoss 5.5632 (6.2201)\tPrec@1 75.000 (71.902)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/100]\tTime 0.035 (0.031)\tLoss 6.4321 (6.1966)\tPrec@1 70.000 (71.843)\tPrec@5 96.000 (97.765)\n",
            "Test: [60/100]\tTime 0.012 (0.029)\tLoss 5.9745 (6.2494)\tPrec@1 73.000 (71.443)\tPrec@5 99.000 (97.820)\n",
            "Test: [70/100]\tTime 0.027 (0.028)\tLoss 6.1788 (6.3122)\tPrec@1 70.000 (71.113)\tPrec@5 98.000 (97.789)\n",
            "Test: [80/100]\tTime 0.019 (0.028)\tLoss 4.5136 (6.2421)\tPrec@1 81.000 (71.432)\tPrec@5 97.000 (97.827)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 6.5314 (6.3221)\tPrec@1 71.000 (71.143)\tPrec@5 99.000 (97.725)\n",
            "val Results: Prec@1 71.030 Prec@5 97.750 Loss 6.33367\n",
            "val Class Accuracy: [0.955,0.950,0.797,0.718,0.853,0.687,0.353,0.740,0.290,0.760]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [95][0/329], lr: 0.01000\tTime 0.643 (0.643)\tData 0.558 (0.558)\tLoss 1.5341 (1.5341)\tPrec@1 91.797 (91.797)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][10/329], lr: 0.01000\tTime 0.088 (0.142)\tData 0.000 (0.056)\tLoss 1.2535 (2.0546)\tPrec@1 92.578 (89.098)\tPrec@5 99.219 (99.077)\n",
            "Epoch: [95][20/329], lr: 0.01000\tTime 0.089 (0.119)\tData 0.000 (0.032)\tLoss 1.8667 (2.0026)\tPrec@1 91.016 (89.639)\tPrec@5 99.609 (99.219)\n",
            "Epoch: [95][30/329], lr: 0.01000\tTime 0.065 (0.110)\tData 0.007 (0.025)\tLoss 2.1294 (1.9753)\tPrec@1 88.672 (89.831)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [95][40/329], lr: 0.01000\tTime 0.084 (0.105)\tData 0.006 (0.021)\tLoss 1.7068 (1.8895)\tPrec@1 92.578 (90.292)\tPrec@5 100.000 (99.381)\n",
            "Epoch: [95][50/329], lr: 0.01000\tTime 0.080 (0.102)\tData 0.000 (0.017)\tLoss 1.6437 (1.8453)\tPrec@1 92.578 (90.518)\tPrec@5 100.000 (99.433)\n",
            "Epoch: [95][60/329], lr: 0.01000\tTime 0.091 (0.101)\tData 0.008 (0.015)\tLoss 1.5646 (1.8167)\tPrec@1 92.188 (90.644)\tPrec@5 99.609 (99.417)\n",
            "Epoch: [95][70/329], lr: 0.01000\tTime 0.070 (0.099)\tData 0.000 (0.014)\tLoss 1.3749 (1.8265)\tPrec@1 92.188 (90.553)\tPrec@5 98.828 (99.406)\n",
            "Epoch: [95][80/329], lr: 0.01000\tTime 0.105 (0.098)\tData 0.000 (0.013)\tLoss 2.2101 (1.8435)\tPrec@1 89.062 (90.480)\tPrec@5 98.438 (99.412)\n",
            "Epoch: [95][90/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.000 (0.013)\tLoss 1.5993 (1.8294)\tPrec@1 92.188 (90.531)\tPrec@5 98.828 (99.408)\n",
            "Epoch: [95][100/329], lr: 0.01000\tTime 0.075 (0.096)\tData 0.000 (0.012)\tLoss 1.6551 (1.8232)\tPrec@1 91.406 (90.532)\tPrec@5 99.609 (99.412)\n",
            "Epoch: [95][110/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.007 (0.012)\tLoss 1.3383 (1.8144)\tPrec@1 93.750 (90.583)\tPrec@5 98.828 (99.419)\n",
            "Epoch: [95][120/329], lr: 0.01000\tTime 0.087 (0.095)\tData 0.000 (0.011)\tLoss 2.0781 (1.7977)\tPrec@1 90.234 (90.683)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [95][130/329], lr: 0.01000\tTime 0.076 (0.094)\tData 0.004 (0.011)\tLoss 2.1157 (1.7994)\tPrec@1 89.453 (90.682)\tPrec@5 99.219 (99.433)\n",
            "Epoch: [95][140/329], lr: 0.01000\tTime 0.087 (0.094)\tData 0.000 (0.011)\tLoss 2.3107 (1.7899)\tPrec@1 87.891 (90.739)\tPrec@5 98.828 (99.443)\n",
            "Epoch: [95][150/329], lr: 0.01000\tTime 0.163 (0.095)\tData 0.000 (0.010)\tLoss 1.3507 (1.7847)\tPrec@1 93.359 (90.762)\tPrec@5 98.828 (99.436)\n",
            "Epoch: [95][160/329], lr: 0.01000\tTime 0.111 (0.096)\tData 0.007 (0.010)\tLoss 1.8635 (1.7779)\tPrec@1 88.672 (90.800)\tPrec@5 99.219 (99.420)\n",
            "Epoch: [95][170/329], lr: 0.01000\tTime 0.101 (0.098)\tData 0.008 (0.010)\tLoss 1.5624 (1.7738)\tPrec@1 91.016 (90.828)\tPrec@5 99.609 (99.422)\n",
            "Epoch: [95][180/329], lr: 0.01000\tTime 0.093 (0.099)\tData 0.008 (0.011)\tLoss 1.2494 (1.7678)\tPrec@1 92.969 (90.847)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [95][190/329], lr: 0.01000\tTime 0.118 (0.099)\tData 0.004 (0.011)\tLoss 1.4477 (1.7712)\tPrec@1 93.750 (90.844)\tPrec@5 100.000 (99.438)\n",
            "Epoch: [95][200/329], lr: 0.01000\tTime 0.085 (0.098)\tData 0.000 (0.010)\tLoss 2.1276 (1.7741)\tPrec@1 89.844 (90.831)\tPrec@5 99.609 (99.442)\n",
            "Epoch: [95][210/329], lr: 0.01000\tTime 0.069 (0.098)\tData 0.003 (0.010)\tLoss 1.7248 (1.7658)\tPrec@1 92.188 (90.879)\tPrec@5 100.000 (99.443)\n",
            "Epoch: [95][220/329], lr: 0.01000\tTime 0.083 (0.098)\tData 0.004 (0.010)\tLoss 2.0496 (1.7564)\tPrec@1 88.672 (90.947)\tPrec@5 99.609 (99.447)\n",
            "Epoch: [95][230/329], lr: 0.01000\tTime 0.083 (0.097)\tData 0.005 (0.010)\tLoss 1.5162 (1.7495)\tPrec@1 92.969 (90.990)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [95][240/329], lr: 0.01000\tTime 0.095 (0.097)\tData 0.012 (0.010)\tLoss 1.8430 (1.7459)\tPrec@1 91.406 (91.019)\tPrec@5 99.609 (99.446)\n",
            "Epoch: [95][250/329], lr: 0.01000\tTime 0.121 (0.097)\tData 0.000 (0.010)\tLoss 1.7379 (1.7491)\tPrec@1 89.453 (90.999)\tPrec@5 99.609 (99.446)\n",
            "Epoch: [95][260/329], lr: 0.01000\tTime 0.088 (0.097)\tData 0.007 (0.010)\tLoss 1.4010 (1.7447)\tPrec@1 92.578 (91.016)\tPrec@5 98.828 (99.449)\n",
            "Epoch: [95][270/329], lr: 0.01000\tTime 0.079 (0.096)\tData 0.001 (0.010)\tLoss 1.8665 (1.7480)\tPrec@1 89.844 (90.994)\tPrec@5 99.219 (99.444)\n",
            "Epoch: [95][280/329], lr: 0.01000\tTime 0.082 (0.096)\tData 0.000 (0.010)\tLoss 2.1458 (1.7474)\tPrec@1 89.453 (90.995)\tPrec@5 98.828 (99.444)\n",
            "Epoch: [95][290/329], lr: 0.01000\tTime 0.070 (0.096)\tData 0.004 (0.009)\tLoss 1.6421 (1.7493)\tPrec@1 91.016 (90.983)\tPrec@5 98.828 (99.443)\n",
            "Epoch: [95][300/329], lr: 0.01000\tTime 0.090 (0.096)\tData 0.010 (0.009)\tLoss 1.9067 (1.7506)\tPrec@1 91.016 (90.981)\tPrec@5 99.219 (99.438)\n",
            "Epoch: [95][310/329], lr: 0.01000\tTime 0.070 (0.095)\tData 0.000 (0.009)\tLoss 1.8467 (1.7497)\tPrec@1 91.016 (90.992)\tPrec@5 99.219 (99.441)\n",
            "Epoch: [95][320/329], lr: 0.01000\tTime 0.091 (0.095)\tData 0.054 (0.009)\tLoss 1.4863 (1.7483)\tPrec@1 92.578 (91.007)\tPrec@5 99.219 (99.437)\n",
            "Test: [0/100]\tTime 0.369 (0.369)\tLoss 8.6980 (8.6980)\tPrec@1 58.000 (58.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.028 (0.057)\tLoss 6.8829 (8.0414)\tPrec@1 67.000 (64.364)\tPrec@5 99.000 (97.545)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 7.0789 (8.0872)\tPrec@1 68.000 (63.714)\tPrec@5 99.000 (97.429)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 7.3836 (8.0015)\tPrec@1 64.000 (64.194)\tPrec@5 97.000 (97.194)\n",
            "Test: [40/100]\tTime 0.028 (0.033)\tLoss 8.3782 (8.0041)\tPrec@1 61.000 (64.098)\tPrec@5 97.000 (97.073)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 8.5585 (8.0584)\tPrec@1 61.000 (63.627)\tPrec@5 98.000 (97.000)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 6.6676 (8.0351)\tPrec@1 70.000 (63.721)\tPrec@5 99.000 (97.082)\n",
            "Test: [70/100]\tTime 0.032 (0.029)\tLoss 7.9756 (7.9661)\tPrec@1 63.000 (64.028)\tPrec@5 99.000 (97.042)\n",
            "Test: [80/100]\tTime 0.041 (0.029)\tLoss 6.1419 (7.9568)\tPrec@1 74.000 (64.148)\tPrec@5 99.000 (97.160)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 7.9861 (7.9962)\tPrec@1 65.000 (63.923)\tPrec@5 98.000 (97.088)\n",
            "val Results: Prec@1 63.900 Prec@5 97.060 Loss 8.01625\n",
            "val Class Accuracy: [0.976,0.984,0.870,0.615,0.714,0.300,0.698,0.602,0.380,0.251]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [96][0/329], lr: 0.01000\tTime 0.651 (0.651)\tData 0.547 (0.547)\tLoss 2.3140 (2.3140)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [96][10/329], lr: 0.01000\tTime 0.064 (0.143)\tData 0.000 (0.057)\tLoss 2.8589 (2.8243)\tPrec@1 85.156 (85.156)\tPrec@5 97.656 (98.438)\n",
            "Epoch: [96][20/329], lr: 0.01000\tTime 0.097 (0.120)\tData 0.032 (0.035)\tLoss 2.1185 (2.5748)\tPrec@1 88.672 (86.589)\tPrec@5 99.609 (98.810)\n",
            "Epoch: [96][30/329], lr: 0.01000\tTime 0.087 (0.111)\tData 0.000 (0.025)\tLoss 2.4889 (2.4443)\tPrec@1 86.719 (87.336)\tPrec@5 99.609 (98.916)\n",
            "Epoch: [96][40/329], lr: 0.01000\tTime 0.093 (0.105)\tData 0.000 (0.020)\tLoss 1.6701 (2.3044)\tPrec@1 91.406 (88.081)\tPrec@5 99.219 (99.047)\n",
            "Epoch: [96][50/329], lr: 0.01000\tTime 0.103 (0.103)\tData 0.001 (0.018)\tLoss 2.0659 (2.2050)\tPrec@1 90.234 (88.687)\tPrec@5 97.656 (99.020)\n",
            "Epoch: [96][60/329], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.015)\tLoss 1.8208 (2.1134)\tPrec@1 89.062 (89.139)\tPrec@5 99.609 (99.148)\n",
            "Epoch: [96][70/329], lr: 0.01000\tTime 0.081 (0.099)\tData 0.000 (0.014)\tLoss 1.5675 (2.0663)\tPrec@1 92.578 (89.437)\tPrec@5 99.609 (99.197)\n",
            "Epoch: [96][80/329], lr: 0.01000\tTime 0.104 (0.098)\tData 0.016 (0.013)\tLoss 2.2786 (2.0433)\tPrec@1 87.500 (89.550)\tPrec@5 100.000 (99.209)\n",
            "Epoch: [96][90/329], lr: 0.01000\tTime 0.087 (0.097)\tData 0.000 (0.013)\tLoss 1.5983 (2.0275)\tPrec@1 91.406 (89.625)\tPrec@5 99.609 (99.210)\n",
            "Epoch: [96][100/329], lr: 0.01000\tTime 0.072 (0.096)\tData 0.007 (0.012)\tLoss 1.4201 (1.9900)\tPrec@1 92.188 (89.821)\tPrec@5 99.609 (99.203)\n",
            "Epoch: [96][110/329], lr: 0.01000\tTime 0.074 (0.095)\tData 0.006 (0.012)\tLoss 2.1992 (1.9791)\tPrec@1 88.672 (89.851)\tPrec@5 98.828 (99.219)\n",
            "Epoch: [96][120/329], lr: 0.01000\tTime 0.083 (0.094)\tData 0.009 (0.011)\tLoss 1.7628 (1.9540)\tPrec@1 92.578 (90.012)\tPrec@5 99.219 (99.232)\n",
            "Epoch: [96][130/329], lr: 0.01000\tTime 0.089 (0.094)\tData 0.003 (0.011)\tLoss 1.8556 (1.9437)\tPrec@1 91.797 (90.058)\tPrec@5 99.609 (99.263)\n",
            "Epoch: [96][140/329], lr: 0.01000\tTime 0.084 (0.093)\tData 0.005 (0.011)\tLoss 1.5873 (1.9330)\tPrec@1 91.797 (90.088)\tPrec@5 100.000 (99.255)\n",
            "Epoch: [96][150/329], lr: 0.01000\tTime 0.085 (0.093)\tData 0.005 (0.011)\tLoss 1.5259 (1.9153)\tPrec@1 91.406 (90.167)\tPrec@5 99.609 (99.283)\n",
            "Epoch: [96][160/329], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.010)\tLoss 1.5923 (1.8958)\tPrec@1 93.750 (90.271)\tPrec@5 99.219 (99.289)\n",
            "Epoch: [96][170/329], lr: 0.01000\tTime 0.089 (0.092)\tData 0.001 (0.010)\tLoss 2.0661 (1.8824)\tPrec@1 89.453 (90.328)\tPrec@5 100.000 (99.299)\n",
            "Epoch: [96][180/329], lr: 0.01000\tTime 0.068 (0.092)\tData 0.007 (0.010)\tLoss 1.8339 (1.8741)\tPrec@1 91.406 (90.368)\tPrec@5 99.609 (99.309)\n",
            "Epoch: [96][190/329], lr: 0.01000\tTime 0.069 (0.091)\tData 0.002 (0.010)\tLoss 1.4123 (1.8591)\tPrec@1 92.578 (90.468)\tPrec@5 99.609 (99.309)\n",
            "Epoch: [96][200/329], lr: 0.01000\tTime 0.080 (0.091)\tData 0.007 (0.010)\tLoss 1.3502 (1.8496)\tPrec@1 93.359 (90.505)\tPrec@5 100.000 (99.316)\n",
            "Epoch: [96][210/329], lr: 0.01000\tTime 0.096 (0.091)\tData 0.006 (0.010)\tLoss 2.1560 (1.8534)\tPrec@1 88.672 (90.471)\tPrec@5 99.219 (99.317)\n",
            "Epoch: [96][220/329], lr: 0.01000\tTime 0.079 (0.091)\tData 0.003 (0.009)\tLoss 2.0986 (1.8514)\tPrec@1 89.453 (90.477)\tPrec@5 98.438 (99.328)\n",
            "Epoch: [96][230/329], lr: 0.01000\tTime 0.073 (0.091)\tData 0.000 (0.009)\tLoss 1.8543 (1.8557)\tPrec@1 91.016 (90.437)\tPrec@5 99.609 (99.334)\n",
            "Epoch: [96][240/329], lr: 0.01000\tTime 0.087 (0.091)\tData 0.001 (0.009)\tLoss 1.9091 (1.8471)\tPrec@1 90.625 (90.468)\tPrec@5 100.000 (99.344)\n",
            "Epoch: [96][250/329], lr: 0.01000\tTime 0.109 (0.092)\tData 0.000 (0.009)\tLoss 1.8471 (1.8473)\tPrec@1 89.844 (90.472)\tPrec@5 100.000 (99.354)\n",
            "Epoch: [96][260/329], lr: 0.01000\tTime 0.115 (0.093)\tData 0.009 (0.009)\tLoss 1.7385 (1.8379)\tPrec@1 90.625 (90.513)\tPrec@5 100.000 (99.365)\n",
            "Epoch: [96][270/329], lr: 0.01000\tTime 0.172 (0.094)\tData 0.111 (0.010)\tLoss 1.5311 (1.8373)\tPrec@1 92.188 (90.521)\tPrec@5 100.000 (99.377)\n",
            "Epoch: [96][280/329], lr: 0.01000\tTime 0.100 (0.095)\tData 0.005 (0.010)\tLoss 1.6674 (1.8330)\tPrec@1 91.797 (90.546)\tPrec@5 99.219 (99.386)\n",
            "Epoch: [96][290/329], lr: 0.01000\tTime 0.106 (0.095)\tData 0.000 (0.010)\tLoss 2.1421 (1.8317)\tPrec@1 87.109 (90.547)\tPrec@5 98.828 (99.387)\n",
            "Epoch: [96][300/329], lr: 0.01000\tTime 0.104 (0.095)\tData 0.004 (0.010)\tLoss 1.7030 (1.8277)\tPrec@1 90.625 (90.574)\tPrec@5 99.609 (99.389)\n",
            "Epoch: [96][310/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.010)\tLoss 1.5271 (1.8240)\tPrec@1 92.188 (90.601)\tPrec@5 99.609 (99.393)\n",
            "Epoch: [96][320/329], lr: 0.01000\tTime 0.097 (0.095)\tData 0.065 (0.010)\tLoss 2.1499 (1.8207)\tPrec@1 88.281 (90.613)\tPrec@5 99.609 (99.398)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 7.4466 (7.4466)\tPrec@1 66.000 (66.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.024 (0.056)\tLoss 5.9544 (7.1491)\tPrec@1 73.000 (68.000)\tPrec@5 94.000 (97.182)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 4.8369 (7.1747)\tPrec@1 79.000 (67.762)\tPrec@5 100.000 (97.238)\n",
            "Test: [30/100]\tTime 0.039 (0.035)\tLoss 7.3914 (7.1844)\tPrec@1 67.000 (67.871)\tPrec@5 95.000 (97.323)\n",
            "Test: [40/100]\tTime 0.023 (0.032)\tLoss 7.6253 (7.1659)\tPrec@1 69.000 (67.805)\tPrec@5 95.000 (97.000)\n",
            "Test: [50/100]\tTime 0.015 (0.030)\tLoss 7.9314 (7.1471)\tPrec@1 67.000 (67.843)\tPrec@5 95.000 (96.922)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 6.3549 (7.1451)\tPrec@1 70.000 (67.754)\tPrec@5 95.000 (96.902)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 7.2133 (7.1286)\tPrec@1 63.000 (67.817)\tPrec@5 97.000 (96.930)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 6.0486 (7.1099)\tPrec@1 75.000 (67.815)\tPrec@5 97.000 (97.037)\n",
            "Test: [90/100]\tTime 0.024 (0.028)\tLoss 6.7201 (7.1776)\tPrec@1 69.000 (67.473)\tPrec@5 99.000 (97.044)\n",
            "val Results: Prec@1 67.570 Prec@5 97.050 Loss 7.16773\n",
            "val Class Accuracy: [0.983,0.939,0.808,0.659,0.557,0.715,0.540,0.622,0.315,0.619]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [97][0/329], lr: 0.01000\tTime 0.532 (0.532)\tData 0.442 (0.442)\tLoss 2.0437 (2.0437)\tPrec@1 90.625 (90.625)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [97][10/329], lr: 0.01000\tTime 0.072 (0.141)\tData 0.000 (0.050)\tLoss 1.9636 (2.2097)\tPrec@1 89.062 (88.494)\tPrec@5 98.828 (98.935)\n",
            "Epoch: [97][20/329], lr: 0.01000\tTime 0.080 (0.118)\tData 0.004 (0.029)\tLoss 2.2269 (2.1125)\tPrec@1 88.672 (89.007)\tPrec@5 98.828 (99.144)\n",
            "Epoch: [97][30/329], lr: 0.01000\tTime 0.079 (0.109)\tData 0.007 (0.022)\tLoss 1.7587 (1.9912)\tPrec@1 90.625 (89.718)\tPrec@5 98.828 (99.231)\n",
            "Epoch: [97][40/329], lr: 0.01000\tTime 0.082 (0.104)\tData 0.000 (0.018)\tLoss 2.1198 (1.9568)\tPrec@1 88.672 (89.929)\tPrec@5 99.219 (99.276)\n",
            "Epoch: [97][50/329], lr: 0.01000\tTime 0.081 (0.102)\tData 0.000 (0.016)\tLoss 2.1838 (1.9230)\tPrec@1 88.672 (90.035)\tPrec@5 99.609 (99.311)\n",
            "Epoch: [97][60/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.003 (0.015)\tLoss 1.9031 (1.9073)\tPrec@1 90.234 (90.132)\tPrec@5 98.828 (99.334)\n",
            "Epoch: [97][70/329], lr: 0.01000\tTime 0.091 (0.098)\tData 0.002 (0.014)\tLoss 1.7143 (1.8904)\tPrec@1 91.016 (90.201)\tPrec@5 99.609 (99.356)\n",
            "Epoch: [97][80/329], lr: 0.01000\tTime 0.097 (0.098)\tData 0.000 (0.012)\tLoss 1.8106 (1.8635)\tPrec@1 90.625 (90.350)\tPrec@5 99.609 (99.339)\n",
            "Epoch: [97][90/329], lr: 0.01000\tTime 0.098 (0.097)\tData 0.006 (0.012)\tLoss 2.3640 (1.8549)\tPrec@1 85.547 (90.389)\tPrec@5 99.219 (99.365)\n",
            "Epoch: [97][100/329], lr: 0.01000\tTime 0.092 (0.095)\tData 0.008 (0.011)\tLoss 1.6621 (1.8317)\tPrec@1 91.406 (90.513)\tPrec@5 99.219 (99.358)\n",
            "Epoch: [97][110/329], lr: 0.01000\tTime 0.083 (0.095)\tData 0.000 (0.011)\tLoss 1.4879 (1.8123)\tPrec@1 91.406 (90.607)\tPrec@5 98.438 (99.345)\n",
            "Epoch: [97][120/329], lr: 0.01000\tTime 0.086 (0.094)\tData 0.007 (0.011)\tLoss 1.6093 (1.7931)\tPrec@1 90.234 (90.706)\tPrec@5 100.000 (99.374)\n",
            "Epoch: [97][130/329], lr: 0.01000\tTime 0.108 (0.094)\tData 0.005 (0.010)\tLoss 1.3381 (1.7798)\tPrec@1 93.750 (90.762)\tPrec@5 99.609 (99.380)\n",
            "Epoch: [97][140/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 1.6987 (1.7697)\tPrec@1 91.406 (90.816)\tPrec@5 99.219 (99.399)\n",
            "Epoch: [97][150/329], lr: 0.01000\tTime 0.057 (0.093)\tData 0.000 (0.010)\tLoss 1.5443 (1.7695)\tPrec@1 92.188 (90.837)\tPrec@5 99.609 (99.408)\n",
            "Epoch: [97][160/329], lr: 0.01000\tTime 0.121 (0.093)\tData 0.004 (0.010)\tLoss 1.8430 (1.7662)\tPrec@1 90.234 (90.843)\tPrec@5 99.219 (99.413)\n",
            "Epoch: [97][170/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.005 (0.010)\tLoss 1.7314 (1.7697)\tPrec@1 91.406 (90.833)\tPrec@5 99.219 (99.415)\n",
            "Epoch: [97][180/329], lr: 0.01000\tTime 0.088 (0.092)\tData 0.007 (0.010)\tLoss 1.3871 (1.7612)\tPrec@1 92.188 (90.880)\tPrec@5 99.609 (99.428)\n",
            "Epoch: [97][190/329], lr: 0.01000\tTime 0.094 (0.092)\tData 0.006 (0.009)\tLoss 1.6633 (1.7594)\tPrec@1 91.406 (90.889)\tPrec@5 98.828 (99.421)\n",
            "Epoch: [97][200/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.005 (0.009)\tLoss 1.8430 (1.7482)\tPrec@1 90.234 (90.942)\tPrec@5 100.000 (99.425)\n",
            "Epoch: [97][210/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.000 (0.009)\tLoss 1.6244 (1.7414)\tPrec@1 91.016 (90.992)\tPrec@5 99.219 (99.434)\n",
            "Epoch: [97][220/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.000 (0.009)\tLoss 1.1421 (1.7401)\tPrec@1 94.922 (91.003)\tPrec@5 100.000 (99.443)\n",
            "Epoch: [97][230/329], lr: 0.01000\tTime 0.067 (0.091)\tData 0.000 (0.009)\tLoss 1.3166 (1.7379)\tPrec@1 93.359 (91.012)\tPrec@5 100.000 (99.449)\n",
            "Epoch: [97][240/329], lr: 0.01000\tTime 0.135 (0.092)\tData 0.002 (0.009)\tLoss 1.8120 (1.7347)\tPrec@1 89.844 (91.009)\tPrec@5 99.609 (99.459)\n",
            "Epoch: [97][250/329], lr: 0.01000\tTime 0.109 (0.092)\tData 0.005 (0.009)\tLoss 2.1383 (1.7327)\tPrec@1 90.234 (91.020)\tPrec@5 100.000 (99.460)\n",
            "Epoch: [97][260/329], lr: 0.01000\tTime 0.104 (0.092)\tData 0.000 (0.009)\tLoss 1.8593 (1.7313)\tPrec@1 89.062 (91.019)\tPrec@5 99.219 (99.458)\n",
            "Epoch: [97][270/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.008 (0.009)\tLoss 1.0751 (1.7259)\tPrec@1 94.922 (91.070)\tPrec@5 100.000 (99.457)\n",
            "Epoch: [97][280/329], lr: 0.01000\tTime 0.085 (0.092)\tData 0.016 (0.009)\tLoss 1.6975 (1.7250)\tPrec@1 91.797 (91.081)\tPrec@5 99.219 (99.458)\n",
            "Epoch: [97][290/329], lr: 0.01000\tTime 0.085 (0.091)\tData 0.001 (0.009)\tLoss 1.6680 (1.7203)\tPrec@1 91.797 (91.103)\tPrec@5 99.609 (99.455)\n",
            "Epoch: [97][300/329], lr: 0.01000\tTime 0.091 (0.091)\tData 0.000 (0.009)\tLoss 2.2951 (1.7261)\tPrec@1 87.891 (91.066)\tPrec@5 99.609 (99.451)\n",
            "Epoch: [97][310/329], lr: 0.01000\tTime 0.089 (0.091)\tData 0.000 (0.008)\tLoss 1.4875 (1.7255)\tPrec@1 91.406 (91.058)\tPrec@5 100.000 (99.457)\n",
            "Epoch: [97][320/329], lr: 0.01000\tTime 0.097 (0.091)\tData 0.040 (0.008)\tLoss 1.4606 (1.7256)\tPrec@1 92.578 (91.058)\tPrec@5 98.828 (99.446)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 6.0424 (6.0424)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.038 (0.057)\tLoss 4.5877 (6.3144)\tPrec@1 80.000 (70.636)\tPrec@5 97.000 (97.909)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 5.5853 (6.3728)\tPrec@1 73.000 (70.476)\tPrec@5 99.000 (97.524)\n",
            "Test: [30/100]\tTime 0.025 (0.039)\tLoss 7.2474 (6.3893)\tPrec@1 65.000 (70.581)\tPrec@5 99.000 (97.677)\n",
            "Test: [40/100]\tTime 0.058 (0.038)\tLoss 5.6791 (6.3949)\tPrec@1 75.000 (70.537)\tPrec@5 97.000 (97.732)\n",
            "Test: [50/100]\tTime 0.039 (0.039)\tLoss 6.7380 (6.3217)\tPrec@1 72.000 (71.020)\tPrec@5 95.000 (97.824)\n",
            "Test: [60/100]\tTime 0.041 (0.039)\tLoss 6.1250 (6.4041)\tPrec@1 70.000 (70.623)\tPrec@5 99.000 (97.967)\n",
            "Test: [70/100]\tTime 0.041 (0.039)\tLoss 6.8400 (6.4051)\tPrec@1 68.000 (70.535)\tPrec@5 96.000 (97.986)\n",
            "Test: [80/100]\tTime 0.040 (0.039)\tLoss 6.9312 (6.3768)\tPrec@1 66.000 (70.654)\tPrec@5 96.000 (98.025)\n",
            "Test: [90/100]\tTime 0.042 (0.039)\tLoss 7.2376 (6.4340)\tPrec@1 67.000 (70.396)\tPrec@5 99.000 (98.022)\n",
            "val Results: Prec@1 70.430 Prec@5 98.000 Loss 6.43567\n",
            "val Class Accuracy: [0.928,0.944,0.556,0.808,0.506,0.829,0.673,0.589,0.670,0.540]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/329], lr: 0.01000\tTime 0.891 (0.891)\tData 0.792 (0.792)\tLoss 1.4417 (1.4417)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][10/329], lr: 0.01000\tTime 0.109 (0.171)\tData 0.006 (0.079)\tLoss 2.7109 (2.2967)\tPrec@1 84.766 (87.749)\tPrec@5 99.219 (99.183)\n",
            "Epoch: [98][20/329], lr: 0.01000\tTime 0.084 (0.132)\tData 0.000 (0.043)\tLoss 2.3526 (2.1955)\tPrec@1 89.062 (88.374)\tPrec@5 98.828 (99.200)\n",
            "Epoch: [98][30/329], lr: 0.01000\tTime 0.102 (0.119)\tData 0.004 (0.031)\tLoss 1.4932 (2.1231)\tPrec@1 91.406 (88.861)\tPrec@5 100.000 (99.156)\n",
            "Epoch: [98][40/329], lr: 0.01000\tTime 0.085 (0.112)\tData 0.007 (0.026)\tLoss 1.5671 (2.0604)\tPrec@1 92.188 (89.272)\tPrec@5 99.609 (99.238)\n",
            "Epoch: [98][50/329], lr: 0.01000\tTime 0.076 (0.108)\tData 0.001 (0.022)\tLoss 1.3049 (1.9814)\tPrec@1 93.750 (89.652)\tPrec@5 100.000 (99.318)\n",
            "Epoch: [98][60/329], lr: 0.01000\tTime 0.094 (0.105)\tData 0.007 (0.020)\tLoss 1.7978 (1.9749)\tPrec@1 91.016 (89.780)\tPrec@5 99.609 (99.347)\n",
            "Epoch: [98][70/329], lr: 0.01000\tTime 0.074 (0.102)\tData 0.005 (0.018)\tLoss 1.8825 (1.9427)\tPrec@1 90.234 (89.915)\tPrec@5 99.219 (99.362)\n",
            "Epoch: [98][80/329], lr: 0.01000\tTime 0.093 (0.101)\tData 0.000 (0.017)\tLoss 1.1969 (1.9150)\tPrec@1 94.141 (90.104)\tPrec@5 100.000 (99.349)\n",
            "Epoch: [98][90/329], lr: 0.01000\tTime 0.082 (0.100)\tData 0.000 (0.016)\tLoss 1.5524 (1.8838)\tPrec@1 91.016 (90.243)\tPrec@5 99.609 (99.352)\n",
            "Epoch: [98][100/329], lr: 0.01000\tTime 0.102 (0.099)\tData 0.006 (0.015)\tLoss 2.0054 (1.8631)\tPrec@1 90.234 (90.412)\tPrec@5 99.609 (99.358)\n",
            "Epoch: [98][110/329], lr: 0.01000\tTime 0.079 (0.098)\tData 0.011 (0.014)\tLoss 1.9015 (1.8477)\tPrec@1 90.234 (90.558)\tPrec@5 100.000 (99.363)\n",
            "Epoch: [98][120/329], lr: 0.01000\tTime 0.064 (0.097)\tData 0.000 (0.013)\tLoss 1.7303 (1.8388)\tPrec@1 91.406 (90.596)\tPrec@5 99.609 (99.354)\n",
            "Epoch: [98][130/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.008 (0.013)\tLoss 1.3934 (1.8306)\tPrec@1 92.578 (90.637)\tPrec@5 100.000 (99.365)\n",
            "Epoch: [98][140/329], lr: 0.01000\tTime 0.101 (0.096)\tData 0.010 (0.013)\tLoss 1.5700 (1.8191)\tPrec@1 93.359 (90.675)\tPrec@5 100.000 (99.379)\n",
            "Epoch: [98][150/329], lr: 0.01000\tTime 0.081 (0.095)\tData 0.000 (0.012)\tLoss 1.8743 (1.8105)\tPrec@1 89.844 (90.710)\tPrec@5 99.609 (99.387)\n",
            "Epoch: [98][160/329], lr: 0.01000\tTime 0.093 (0.095)\tData 0.007 (0.012)\tLoss 1.9662 (1.8162)\tPrec@1 90.234 (90.676)\tPrec@5 99.219 (99.396)\n",
            "Epoch: [98][170/329], lr: 0.01000\tTime 0.085 (0.095)\tData 0.000 (0.011)\tLoss 1.6298 (1.8127)\tPrec@1 91.016 (90.687)\tPrec@5 99.609 (99.397)\n",
            "Epoch: [98][180/329], lr: 0.01000\tTime 0.084 (0.094)\tData 0.010 (0.011)\tLoss 1.6240 (1.8093)\tPrec@1 91.406 (90.709)\tPrec@5 99.609 (99.396)\n",
            "Epoch: [98][190/329], lr: 0.01000\tTime 0.098 (0.094)\tData 0.007 (0.011)\tLoss 2.1626 (1.8036)\tPrec@1 88.672 (90.756)\tPrec@5 99.609 (99.413)\n",
            "Epoch: [98][200/329], lr: 0.01000\tTime 0.067 (0.094)\tData 0.000 (0.011)\tLoss 1.2351 (1.7944)\tPrec@1 94.141 (90.808)\tPrec@5 100.000 (99.417)\n",
            "Epoch: [98][210/329], lr: 0.01000\tTime 0.085 (0.094)\tData 0.013 (0.011)\tLoss 1.3642 (1.7877)\tPrec@1 94.141 (90.851)\tPrec@5 100.000 (99.426)\n",
            "Epoch: [98][220/329], lr: 0.01000\tTime 0.080 (0.093)\tData 0.002 (0.010)\tLoss 1.7055 (1.7874)\tPrec@1 91.016 (90.849)\tPrec@5 98.828 (99.431)\n",
            "Epoch: [98][230/329], lr: 0.01000\tTime 0.063 (0.093)\tData 0.001 (0.010)\tLoss 1.9130 (1.7863)\tPrec@1 88.672 (90.850)\tPrec@5 99.219 (99.430)\n",
            "Epoch: [98][240/329], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.010)\tLoss 1.8841 (1.7812)\tPrec@1 90.625 (90.879)\tPrec@5 99.609 (99.426)\n",
            "Epoch: [98][250/329], lr: 0.01000\tTime 0.078 (0.093)\tData 0.000 (0.010)\tLoss 1.5589 (1.7779)\tPrec@1 92.969 (90.902)\tPrec@5 99.219 (99.430)\n",
            "Epoch: [98][260/329], lr: 0.01000\tTime 0.095 (0.093)\tData 0.006 (0.010)\tLoss 1.4558 (1.7748)\tPrec@1 93.359 (90.918)\tPrec@5 99.219 (99.436)\n",
            "Epoch: [98][270/329], lr: 0.01000\tTime 0.090 (0.092)\tData 0.006 (0.010)\tLoss 1.7054 (1.7731)\tPrec@1 92.578 (90.923)\tPrec@5 99.219 (99.429)\n",
            "Epoch: [98][280/329], lr: 0.01000\tTime 0.092 (0.092)\tData 0.000 (0.010)\tLoss 1.4094 (1.7692)\tPrec@1 92.188 (90.956)\tPrec@5 100.000 (99.424)\n",
            "Epoch: [98][290/329], lr: 0.01000\tTime 0.101 (0.093)\tData 0.000 (0.010)\tLoss 2.0032 (1.7687)\tPrec@1 90.625 (90.961)\tPrec@5 99.609 (99.430)\n",
            "Epoch: [98][300/329], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.009)\tLoss 1.8611 (1.7663)\tPrec@1 90.234 (90.970)\tPrec@5 98.828 (99.429)\n",
            "Epoch: [98][310/329], lr: 0.01000\tTime 0.084 (0.092)\tData 0.007 (0.009)\tLoss 1.8588 (1.7609)\tPrec@1 91.406 (91.007)\tPrec@5 99.609 (99.435)\n",
            "Epoch: [98][320/329], lr: 0.01000\tTime 0.107 (0.092)\tData 0.074 (0.010)\tLoss 1.7228 (1.7580)\tPrec@1 91.797 (91.019)\tPrec@5 99.609 (99.439)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 4.5520 (4.5520)\tPrec@1 81.000 (81.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.051)\tLoss 4.0206 (4.7218)\tPrec@1 81.000 (79.091)\tPrec@5 99.000 (97.636)\n",
            "Test: [20/100]\tTime 0.025 (0.039)\tLoss 4.4809 (4.6883)\tPrec@1 78.000 (78.524)\tPrec@5 100.000 (97.714)\n",
            "Test: [30/100]\tTime 0.010 (0.032)\tLoss 5.3113 (4.7823)\tPrec@1 76.000 (77.871)\tPrec@5 98.000 (97.484)\n",
            "Test: [40/100]\tTime 0.017 (0.031)\tLoss 5.2644 (4.8353)\tPrec@1 75.000 (77.634)\tPrec@5 94.000 (97.415)\n",
            "Test: [50/100]\tTime 0.027 (0.030)\tLoss 4.9235 (4.7811)\tPrec@1 76.000 (77.824)\tPrec@5 98.000 (97.569)\n",
            "Test: [60/100]\tTime 0.022 (0.029)\tLoss 4.2178 (4.8623)\tPrec@1 83.000 (77.557)\tPrec@5 96.000 (97.639)\n",
            "Test: [70/100]\tTime 0.024 (0.028)\tLoss 4.8573 (4.8565)\tPrec@1 78.000 (77.563)\tPrec@5 98.000 (97.606)\n",
            "Test: [80/100]\tTime 0.031 (0.028)\tLoss 4.4567 (4.8277)\tPrec@1 81.000 (77.728)\tPrec@5 98.000 (97.679)\n",
            "Test: [90/100]\tTime 0.010 (0.027)\tLoss 3.6547 (4.9018)\tPrec@1 84.000 (77.319)\tPrec@5 99.000 (97.637)\n",
            "val Results: Prec@1 77.400 Prec@5 97.680 Loss 4.89225\n",
            "val Class Accuracy: [0.903,0.966,0.911,0.596,0.798,0.718,0.799,0.566,0.726,0.757]\n",
            "Best Prec@1: 78.330\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/329], lr: 0.01000\tTime 0.599 (0.599)\tData 0.520 (0.520)\tLoss 1.7704 (1.7704)\tPrec@1 90.234 (90.234)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [99][10/329], lr: 0.01000\tTime 0.083 (0.143)\tData 0.004 (0.056)\tLoss 1.5553 (1.6455)\tPrec@1 92.578 (92.010)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [99][20/329], lr: 0.01000\tTime 0.084 (0.119)\tData 0.000 (0.033)\tLoss 1.9711 (1.7883)\tPrec@1 90.234 (91.034)\tPrec@5 99.609 (99.237)\n",
            "Epoch: [99][30/329], lr: 0.01000\tTime 0.092 (0.110)\tData 0.000 (0.025)\tLoss 1.5923 (1.7753)\tPrec@1 91.406 (90.915)\tPrec@5 98.438 (99.231)\n",
            "Epoch: [99][40/329], lr: 0.01000\tTime 0.087 (0.104)\tData 0.011 (0.021)\tLoss 1.4145 (1.7406)\tPrec@1 92.578 (91.149)\tPrec@5 99.609 (99.200)\n",
            "Epoch: [99][50/329], lr: 0.01000\tTime 0.098 (0.102)\tData 0.005 (0.018)\tLoss 1.2091 (1.7079)\tPrec@1 94.531 (91.345)\tPrec@5 99.609 (99.203)\n",
            "Epoch: [99][60/329], lr: 0.01000\tTime 0.091 (0.100)\tData 0.005 (0.016)\tLoss 1.6848 (1.7053)\tPrec@1 90.234 (91.297)\tPrec@5 99.219 (99.193)\n",
            "Epoch: [99][70/329], lr: 0.01000\tTime 0.069 (0.099)\tData 0.011 (0.015)\tLoss 1.6743 (1.7002)\tPrec@1 92.188 (91.346)\tPrec@5 99.609 (99.246)\n",
            "Epoch: [99][80/329], lr: 0.01000\tTime 0.111 (0.101)\tData 0.009 (0.014)\tLoss 1.7924 (1.7009)\tPrec@1 90.234 (91.319)\tPrec@5 98.828 (99.233)\n",
            "Epoch: [99][90/329], lr: 0.01000\tTime 0.182 (0.103)\tData 0.000 (0.013)\tLoss 1.6557 (1.6883)\tPrec@1 91.797 (91.389)\tPrec@5 100.000 (99.300)\n",
            "Epoch: [99][100/329], lr: 0.01000\tTime 0.117 (0.106)\tData 0.000 (0.012)\tLoss 1.3968 (1.6829)\tPrec@1 92.969 (91.472)\tPrec@5 99.609 (99.319)\n",
            "Epoch: [99][110/329], lr: 0.01000\tTime 0.091 (0.106)\tData 0.005 (0.012)\tLoss 1.7765 (1.6863)\tPrec@1 90.625 (91.456)\tPrec@5 99.609 (99.349)\n",
            "Epoch: [99][120/329], lr: 0.01000\tTime 0.084 (0.105)\tData 0.004 (0.012)\tLoss 1.7089 (1.6954)\tPrec@1 91.016 (91.364)\tPrec@5 98.828 (99.341)\n",
            "Epoch: [99][130/329], lr: 0.01000\tTime 0.095 (0.104)\tData 0.006 (0.012)\tLoss 2.0725 (1.7067)\tPrec@1 90.234 (91.275)\tPrec@5 99.609 (99.314)\n",
            "Epoch: [99][140/329], lr: 0.01000\tTime 0.117 (0.103)\tData 0.000 (0.011)\tLoss 1.5708 (1.6923)\tPrec@1 92.969 (91.365)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [99][150/329], lr: 0.01000\tTime 0.087 (0.103)\tData 0.000 (0.011)\tLoss 1.4232 (1.6930)\tPrec@1 94.531 (91.362)\tPrec@5 98.828 (99.343)\n",
            "Epoch: [99][160/329], lr: 0.01000\tTime 0.082 (0.102)\tData 0.004 (0.010)\tLoss 1.4963 (1.6920)\tPrec@1 91.406 (91.363)\tPrec@5 100.000 (99.362)\n",
            "Epoch: [99][170/329], lr: 0.01000\tTime 0.089 (0.101)\tData 0.010 (0.010)\tLoss 1.5686 (1.6969)\tPrec@1 92.578 (91.335)\tPrec@5 98.828 (99.360)\n",
            "Epoch: [99][180/329], lr: 0.01000\tTime 0.086 (0.101)\tData 0.005 (0.010)\tLoss 1.3463 (1.6905)\tPrec@1 92.578 (91.372)\tPrec@5 99.609 (99.372)\n",
            "Epoch: [99][190/329], lr: 0.01000\tTime 0.073 (0.100)\tData 0.000 (0.010)\tLoss 1.8134 (1.6944)\tPrec@1 90.234 (91.345)\tPrec@5 99.609 (99.378)\n",
            "Epoch: [99][200/329], lr: 0.01000\tTime 0.130 (0.100)\tData 0.005 (0.010)\tLoss 2.0262 (1.6991)\tPrec@1 90.625 (91.334)\tPrec@5 100.000 (99.380)\n",
            "Epoch: [99][210/329], lr: 0.01000\tTime 0.078 (0.099)\tData 0.000 (0.009)\tLoss 1.8363 (1.7027)\tPrec@1 90.625 (91.293)\tPrec@5 100.000 (99.393)\n",
            "Epoch: [99][220/329], lr: 0.01000\tTime 0.071 (0.099)\tData 0.003 (0.009)\tLoss 2.0884 (1.7070)\tPrec@1 88.672 (91.267)\tPrec@5 99.219 (99.392)\n",
            "Epoch: [99][230/329], lr: 0.01000\tTime 0.100 (0.098)\tData 0.001 (0.009)\tLoss 1.5662 (1.7108)\tPrec@1 92.188 (91.246)\tPrec@5 99.609 (99.393)\n",
            "Epoch: [99][240/329], lr: 0.01000\tTime 0.121 (0.098)\tData 0.000 (0.009)\tLoss 1.6046 (1.7115)\tPrec@1 91.016 (91.238)\tPrec@5 99.609 (99.400)\n",
            "Epoch: [99][250/329], lr: 0.01000\tTime 0.096 (0.098)\tData 0.007 (0.009)\tLoss 1.5320 (1.7149)\tPrec@1 93.750 (91.213)\tPrec@5 99.609 (99.395)\n",
            "Epoch: [99][260/329], lr: 0.01000\tTime 0.084 (0.097)\tData 0.006 (0.009)\tLoss 1.7994 (1.7110)\tPrec@1 91.016 (91.239)\tPrec@5 99.609 (99.397)\n",
            "Epoch: [99][270/329], lr: 0.01000\tTime 0.097 (0.097)\tData 0.004 (0.009)\tLoss 1.9458 (1.7080)\tPrec@1 90.625 (91.261)\tPrec@5 100.000 (99.399)\n",
            "Epoch: [99][280/329], lr: 0.01000\tTime 0.094 (0.097)\tData 0.005 (0.008)\tLoss 1.7685 (1.7074)\tPrec@1 91.406 (91.253)\tPrec@5 100.000 (99.409)\n",
            "Epoch: [99][290/329], lr: 0.01000\tTime 0.078 (0.097)\tData 0.000 (0.008)\tLoss 1.6311 (1.7032)\tPrec@1 92.188 (91.279)\tPrec@5 99.609 (99.420)\n",
            "Epoch: [99][300/329], lr: 0.01000\tTime 0.108 (0.096)\tData 0.012 (0.008)\tLoss 1.7709 (1.7063)\tPrec@1 90.234 (91.258)\tPrec@5 100.000 (99.430)\n",
            "Epoch: [99][310/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.002 (0.008)\tLoss 2.1551 (1.7074)\tPrec@1 89.453 (91.273)\tPrec@5 98.828 (99.429)\n",
            "Epoch: [99][320/329], lr: 0.01000\tTime 0.086 (0.096)\tData 0.046 (0.008)\tLoss 1.7195 (1.7078)\tPrec@1 91.797 (91.271)\tPrec@5 100.000 (99.433)\n",
            "Test: [0/100]\tTime 0.368 (0.368)\tLoss 7.4072 (7.4072)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.043 (0.057)\tLoss 5.6334 (6.3831)\tPrec@1 72.000 (70.727)\tPrec@5 97.000 (97.000)\n",
            "Test: [20/100]\tTime 0.030 (0.040)\tLoss 5.8674 (6.3460)\tPrec@1 71.000 (71.190)\tPrec@5 98.000 (96.476)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 6.5354 (6.3182)\tPrec@1 70.000 (71.290)\tPrec@5 95.000 (96.226)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 6.3936 (6.3420)\tPrec@1 71.000 (71.024)\tPrec@5 93.000 (95.976)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 6.2987 (6.3136)\tPrec@1 73.000 (71.020)\tPrec@5 95.000 (95.804)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 5.9682 (6.3726)\tPrec@1 74.000 (70.639)\tPrec@5 97.000 (95.803)\n",
            "Test: [70/100]\tTime 0.032 (0.029)\tLoss 6.1350 (6.4360)\tPrec@1 71.000 (70.338)\tPrec@5 96.000 (95.775)\n",
            "Test: [80/100]\tTime 0.009 (0.028)\tLoss 5.4740 (6.3838)\tPrec@1 75.000 (70.469)\tPrec@5 96.000 (95.926)\n",
            "Test: [90/100]\tTime 0.028 (0.028)\tLoss 5.5870 (6.4381)\tPrec@1 74.000 (70.209)\tPrec@5 99.000 (95.923)\n",
            "val Results: Prec@1 70.280 Prec@5 95.890 Loss 6.43267\n",
            "val Class Accuracy: [0.823,0.982,0.903,0.407,0.765,0.779,0.448,0.637,0.504,0.780]\n",
            "Best Prec@1: 78.330\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset cifar10 --loss_type LDAM --imb_factor 0.02 --imb_factor_unlabel 0.02 --epochs=100 --resume '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_LDAM_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' -e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7HZAWzdgX5D",
        "outputId": "608ea97f-72ec-4c17-8445-e87b4b50d103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Unlabeled est total:\t69980\n",
            "After processing:\t69974,\t[24999, 16186, 10477, 6784, 4390, 2843, 1839, 1189, 771, 496]\n",
            "Labeled data extracted:\t13996\n",
            "5000\n",
            "3237\n",
            "2096\n",
            "1357\n",
            "878\n",
            "568\n",
            "368\n",
            "238\n",
            "154\n",
            "100\n",
            "Loading unlabeled data from ./data/ti_80M_selected.pickle\n",
            "tcmalloc: large alloc 1536008192 bytes == 0x67146000 @  0x7fcfb99191e7 0x4b2590 0x5ad01c 0x5e46ad 0x58f90f 0x59172f 0x591ac9 0x4fc06a 0x4fc808 0x4fe70d 0x5f0318 0x58f62c 0x5105e2 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e\n",
            "tcmalloc: large alloc 1536008192 bytes == 0xc2a20000 @  0x7fcfb99191e7 0x4b2590 0x5ad01c 0x4fc81a 0x4fe70d 0x5f0318 0x58f62c 0x5105e2 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7fcfb9516c87 0x5b636a\n",
            "Loading pseudo labels from ./data/pseudo_labeled_cifar.pickle\n",
            "Unlabeled data extracted:\t83970\n",
            "29936\n",
            "19525\n",
            "12559\n",
            "8356\n",
            "4442\n",
            "3869\n",
            "2242\n",
            "1433\n",
            "965\n",
            "643\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_LDAM_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/100]\tTime 7.668 (7.668)\tLoss 1.9116 (1.9116)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.033 (0.715)\tLoss 1.9048 (1.9100)\tPrec@1 83.000 (79.545)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.017 (0.385)\tLoss 1.8979 (1.9081)\tPrec@1 80.000 (79.381)\tPrec@5 99.000 (98.476)\n",
            "Test: [30/100]\tTime 0.048 (0.271)\tLoss 1.9168 (1.9119)\tPrec@1 80.000 (78.839)\tPrec@5 96.000 (98.097)\n",
            "Test: [40/100]\tTime 0.031 (0.211)\tLoss 1.9096 (1.9128)\tPrec@1 81.000 (78.634)\tPrec@5 99.000 (97.976)\n",
            "Test: [50/100]\tTime 0.026 (0.175)\tLoss 1.9488 (1.9117)\tPrec@1 74.000 (78.882)\tPrec@5 96.000 (98.020)\n",
            "Test: [60/100]\tTime 0.012 (0.150)\tLoss 1.9373 (1.9143)\tPrec@1 77.000 (78.377)\tPrec@5 100.000 (98.131)\n",
            "Test: [70/100]\tTime 0.037 (0.132)\tLoss 1.9008 (1.9144)\tPrec@1 77.000 (78.282)\tPrec@5 98.000 (98.155)\n",
            "Test: [80/100]\tTime 0.022 (0.119)\tLoss 1.8808 (1.9142)\tPrec@1 84.000 (78.321)\tPrec@5 100.000 (98.185)\n",
            "Test: [90/100]\tTime 0.023 (0.109)\tLoss 1.8946 (1.9150)\tPrec@1 83.000 (78.176)\tPrec@5 100.000 (98.187)\n",
            "val Results: Prec@1 78.330 Prec@5 98.170 Loss 1.91447\n",
            "val Class Accuracy: [0.939,0.969,0.857,0.737,0.748,0.668,0.681,0.741,0.753,0.740]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu9boGG7gfsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRM4wR--gfgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-Supervised Imbalanced Learning**"
      ],
      "metadata": {
        "id": "_cCnx9Bin4h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function: Cross Entropy**"
      ],
      "metadata": {
        "id": "NPCg7NIrPORH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-supervised pre-training (SSP)"
      ],
      "metadata": {
        "id": "ZLeAJ1EyPs4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python pretrain_rot.py --dataset cifar10 --imb_factor 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGzw5Oa8pVOz",
        "outputId": "00dcb8fc-f582-4e50-dc3c-c4ec182394d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Creating model 'resnet50'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "cls num list:\n",
            "[5000, 2997, 1796, 1077, 645, 387, 232, 139, 83, 50]\n",
            "Epoch: [0][0/97], lr: 0.00200\tTime 4.350 (4.350)\tData 0.356 (0.356)\tLoss 1.6482 (1.6482)\tPrec@1 20.312 (20.312)\n",
            "Epoch: [0][10/97], lr: 0.00200\tTime 0.071 (0.458)\tData 0.000 (0.034)\tLoss 4.2344 (3.5006)\tPrec@1 25.000 (25.213)\n",
            "Epoch: [0][20/97], lr: 0.00200\tTime 0.059 (0.273)\tData 0.000 (0.019)\tLoss 2.7644 (3.4543)\tPrec@1 24.219 (25.335)\n",
            "Epoch: [0][30/97], lr: 0.00200\tTime 0.066 (0.208)\tData 0.004 (0.014)\tLoss 2.2727 (3.0594)\tPrec@1 24.219 (25.202)\n",
            "Epoch: [0][40/97], lr: 0.00200\tTime 0.067 (0.174)\tData 0.000 (0.011)\tLoss 1.8461 (3.1433)\tPrec@1 24.219 (25.038)\n",
            "Epoch: [0][50/97], lr: 0.00200\tTime 0.073 (0.154)\tData 0.007 (0.010)\tLoss 3.4681 (3.2748)\tPrec@1 25.000 (25.184)\n",
            "Epoch: [0][60/97], lr: 0.00200\tTime 0.064 (0.140)\tData 0.000 (0.009)\tLoss 2.6166 (3.1495)\tPrec@1 21.875 (25.435)\n",
            "Epoch: [0][70/97], lr: 0.00200\tTime 0.081 (0.130)\tData 0.000 (0.008)\tLoss 1.5727 (3.0537)\tPrec@1 29.688 (25.638)\n",
            "Epoch: [0][80/97], lr: 0.00200\tTime 0.083 (0.123)\tData 0.007 (0.007)\tLoss 2.0730 (2.9618)\tPrec@1 33.594 (26.061)\n",
            "Epoch: [0][90/97], lr: 0.00200\tTime 0.049 (0.117)\tData 0.000 (0.006)\tLoss 5.6576 (2.8806)\tPrec@1 23.438 (26.219)\n",
            "Test: [0/100]\tTime 0.601 (0.601)\tLoss 6.0482 (6.0482)\tPrec@1 31.000 (31.000)\n",
            "Test: [10/100]\tTime 0.033 (0.085)\tLoss 8.5536 (3.3062)\tPrec@1 26.000 (26.727)\n",
            "Test: [20/100]\tTime 0.026 (0.059)\tLoss 1.4130 (3.0473)\tPrec@1 27.000 (26.000)\n",
            "Test: [30/100]\tTime 0.032 (0.050)\tLoss 1.3855 (2.5738)\tPrec@1 25.000 (25.968)\n",
            "Test: [40/100]\tTime 0.027 (0.045)\tLoss 1.4378 (2.5408)\tPrec@1 28.000 (26.220)\n",
            "Test: [50/100]\tTime 0.024 (0.042)\tLoss 1.6438 (2.4990)\tPrec@1 26.000 (26.314)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.5076 (2.3790)\tPrec@1 24.000 (26.213)\n",
            "Test: [70/100]\tTime 0.034 (0.039)\tLoss 4.0052 (2.3365)\tPrec@1 25.000 (26.239)\n",
            "Test: [80/100]\tTime 0.030 (0.039)\tLoss 1.3749 (2.2969)\tPrec@1 26.000 (26.099)\n",
            "Test: [90/100]\tTime 0.028 (0.038)\tLoss 5.8370 (2.2914)\tPrec@1 27.000 (26.165)\n",
            "val Results: Prec@1 26.110 Loss 2.25382\n",
            "Best Prec@1: 26.110\n",
            "\n",
            "Epoch: [1][0/97], lr: 0.00400\tTime 0.508 (0.508)\tData 0.329 (0.329)\tLoss 1.6738 (1.6738)\tPrec@1 25.000 (25.000)\n",
            "Epoch: [1][10/97], lr: 0.00400\tTime 0.089 (0.117)\tData 0.005 (0.031)\tLoss 1.6751 (2.9571)\tPrec@1 25.000 (28.480)\n",
            "Epoch: [1][20/97], lr: 0.00400\tTime 0.072 (0.103)\tData 0.012 (0.019)\tLoss 2.3508 (3.6536)\tPrec@1 32.812 (29.874)\n",
            "Epoch: [1][30/97], lr: 0.00400\tTime 0.068 (0.094)\tData 0.000 (0.013)\tLoss 2.0124 (3.9115)\tPrec@1 35.938 (29.435)\n",
            "Epoch: [1][40/97], lr: 0.00400\tTime 0.060 (0.088)\tData 0.000 (0.011)\tLoss 2.4323 (3.8540)\tPrec@1 30.469 (29.573)\n",
            "Epoch: [1][50/97], lr: 0.00400\tTime 0.068 (0.084)\tData 0.003 (0.010)\tLoss 2.3772 (3.7156)\tPrec@1 25.781 (28.814)\n",
            "Epoch: [1][60/97], lr: 0.00400\tTime 0.092 (0.083)\tData 0.000 (0.009)\tLoss 2.0961 (3.5287)\tPrec@1 35.938 (29.034)\n",
            "Epoch: [1][70/97], lr: 0.00400\tTime 0.098 (0.084)\tData 0.000 (0.008)\tLoss 5.1399 (3.6183)\tPrec@1 30.469 (29.192)\n",
            "Epoch: [1][80/97], lr: 0.00400\tTime 0.157 (0.085)\tData 0.001 (0.007)\tLoss 1.7943 (3.5675)\tPrec@1 27.344 (29.128)\n",
            "Epoch: [1][90/97], lr: 0.00400\tTime 0.062 (0.085)\tData 0.000 (0.007)\tLoss 2.0087 (3.3834)\tPrec@1 25.781 (29.275)\n",
            "Test: [0/100]\tTime 0.411 (0.411)\tLoss 1.6941 (1.6941)\tPrec@1 37.000 (37.000)\n",
            "Test: [10/100]\tTime 0.057 (0.083)\tLoss 1.7386 (1.7102)\tPrec@1 30.000 (30.909)\n",
            "Test: [20/100]\tTime 0.029 (0.063)\tLoss 1.7342 (1.7079)\tPrec@1 21.000 (30.762)\n",
            "Test: [30/100]\tTime 0.050 (0.054)\tLoss 1.7370 (1.7107)\tPrec@1 31.000 (30.452)\n",
            "Test: [40/100]\tTime 0.025 (0.049)\tLoss 1.7285 (1.7081)\tPrec@1 30.000 (30.512)\n",
            "Test: [50/100]\tTime 0.043 (0.047)\tLoss 1.6789 (1.7077)\tPrec@1 38.000 (30.431)\n",
            "Test: [60/100]\tTime 0.069 (0.045)\tLoss 1.7764 (1.7094)\tPrec@1 29.000 (30.180)\n",
            "Test: [70/100]\tTime 0.032 (0.044)\tLoss 1.7212 (1.7085)\tPrec@1 33.000 (30.296)\n",
            "Test: [80/100]\tTime 0.022 (0.043)\tLoss 1.7424 (1.7091)\tPrec@1 32.000 (30.247)\n",
            "Test: [90/100]\tTime 0.023 (0.043)\tLoss 1.6843 (1.7087)\tPrec@1 31.000 (30.286)\n",
            "val Results: Prec@1 30.380 Loss 1.70825\n",
            "Best Prec@1: 30.380\n",
            "\n",
            "Epoch: [2][0/97], lr: 0.00600\tTime 0.510 (0.510)\tData 0.317 (0.317)\tLoss 3.6359 (3.6359)\tPrec@1 29.688 (29.688)\n",
            "Epoch: [2][10/97], lr: 0.00600\tTime 0.095 (0.136)\tData 0.001 (0.031)\tLoss 2.8499 (2.7198)\tPrec@1 25.000 (27.699)\n",
            "Epoch: [2][20/97], lr: 0.00600\tTime 0.149 (0.108)\tData 0.000 (0.017)\tLoss 3.2940 (2.7439)\tPrec@1 27.344 (27.344)\n",
            "Epoch: [2][30/97], lr: 0.00600\tTime 0.087 (0.099)\tData 0.000 (0.012)\tLoss 1.9403 (2.9831)\tPrec@1 35.156 (27.243)\n",
            "Epoch: [2][40/97], lr: 0.00600\tTime 0.090 (0.093)\tData 0.005 (0.010)\tLoss 2.5942 (2.9130)\tPrec@1 32.812 (28.087)\n",
            "Epoch: [2][50/97], lr: 0.00600\tTime 0.062 (0.088)\tData 0.000 (0.009)\tLoss 1.3359 (2.8606)\tPrec@1 32.031 (28.508)\n",
            "Epoch: [2][60/97], lr: 0.00600\tTime 0.069 (0.085)\tData 0.006 (0.008)\tLoss 1.6004 (2.7484)\tPrec@1 35.156 (29.137)\n",
            "Epoch: [2][70/97], lr: 0.00600\tTime 0.065 (0.083)\tData 0.003 (0.007)\tLoss 1.3321 (2.6176)\tPrec@1 35.156 (29.721)\n",
            "Epoch: [2][80/97], lr: 0.00600\tTime 0.087 (0.082)\tData 0.000 (0.007)\tLoss 3.9568 (2.6603)\tPrec@1 42.969 (30.372)\n",
            "Epoch: [2][90/97], lr: 0.00600\tTime 0.052 (0.080)\tData 0.000 (0.006)\tLoss 2.8456 (2.7493)\tPrec@1 30.469 (30.649)\n",
            "Test: [0/100]\tTime 0.260 (0.260)\tLoss 52.1966 (52.1966)\tPrec@1 20.000 (20.000)\n",
            "Test: [10/100]\tTime 0.030 (0.061)\tLoss 89.1943 (68.8672)\tPrec@1 25.000 (22.091)\n",
            "Test: [20/100]\tTime 0.040 (0.047)\tLoss 130.4506 (76.9849)\tPrec@1 25.000 (22.857)\n",
            "Test: [30/100]\tTime 0.082 (0.044)\tLoss 37.4034 (76.6744)\tPrec@1 23.000 (22.355)\n",
            "Test: [40/100]\tTime 0.032 (0.043)\tLoss 45.4141 (75.2435)\tPrec@1 19.000 (22.049)\n",
            "Test: [50/100]\tTime 0.041 (0.042)\tLoss 63.9164 (74.6743)\tPrec@1 20.000 (22.176)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 63.9976 (76.1092)\tPrec@1 24.000 (22.262)\n",
            "Test: [70/100]\tTime 0.036 (0.041)\tLoss 76.0405 (77.2472)\tPrec@1 25.000 (22.479)\n",
            "Test: [80/100]\tTime 0.026 (0.040)\tLoss 87.8001 (74.8424)\tPrec@1 19.000 (22.432)\n",
            "Test: [90/100]\tTime 0.039 (0.040)\tLoss 4.2503 (72.6767)\tPrec@1 26.000 (22.462)\n",
            "val Results: Prec@1 22.450 Loss 75.51829\n",
            "Best Prec@1: 30.380\n",
            "\n",
            "Epoch: [3][0/97], lr: 0.00800\tTime 0.485 (0.485)\tData 0.267 (0.267)\tLoss 4.3083 (4.3083)\tPrec@1 28.906 (28.906)\n",
            "Epoch: [3][10/97], lr: 0.00800\tTime 0.065 (0.119)\tData 0.000 (0.026)\tLoss 1.4131 (2.8642)\tPrec@1 21.094 (26.065)\n",
            "Epoch: [3][20/97], lr: 0.00800\tTime 0.097 (0.104)\tData 0.009 (0.015)\tLoss 6.8728 (3.6568)\tPrec@1 25.781 (26.339)\n",
            "Epoch: [3][30/97], lr: 0.00800\tTime 0.086 (0.098)\tData 0.000 (0.011)\tLoss 4.0243 (3.7572)\tPrec@1 24.219 (25.907)\n",
            "Epoch: [3][40/97], lr: 0.00800\tTime 0.072 (0.093)\tData 0.009 (0.009)\tLoss 1.5894 (3.8765)\tPrec@1 27.344 (25.762)\n",
            "Epoch: [3][50/97], lr: 0.00800\tTime 0.066 (0.091)\tData 0.000 (0.007)\tLoss 3.7445 (3.7378)\tPrec@1 35.938 (26.532)\n",
            "Epoch: [3][60/97], lr: 0.00800\tTime 0.083 (0.090)\tData 0.000 (0.007)\tLoss 2.6649 (3.7261)\tPrec@1 28.906 (26.703)\n",
            "Epoch: [3][70/97], lr: 0.00800\tTime 0.067 (0.088)\tData 0.002 (0.006)\tLoss 1.3708 (3.5686)\tPrec@1 25.781 (27.168)\n",
            "Epoch: [3][80/97], lr: 0.00800\tTime 0.078 (0.086)\tData 0.007 (0.006)\tLoss 2.6688 (3.4145)\tPrec@1 29.688 (27.228)\n",
            "Epoch: [3][90/97], lr: 0.00800\tTime 0.051 (0.084)\tData 0.000 (0.006)\tLoss 3.8205 (3.2799)\tPrec@1 21.094 (27.610)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 59.0855 (59.0855)\tPrec@1 27.000 (27.000)\n",
            "Test: [10/100]\tTime 0.037 (0.066)\tLoss 73.8819 (60.4541)\tPrec@1 25.000 (25.909)\n",
            "Test: [20/100]\tTime 0.041 (0.053)\tLoss 72.3410 (61.9572)\tPrec@1 23.000 (26.476)\n",
            "Test: [30/100]\tTime 0.066 (0.047)\tLoss 65.1156 (63.5554)\tPrec@1 26.000 (26.065)\n",
            "Test: [40/100]\tTime 0.023 (0.044)\tLoss 68.5689 (64.8055)\tPrec@1 18.000 (25.610)\n",
            "Test: [50/100]\tTime 0.033 (0.042)\tLoss 76.5795 (63.2050)\tPrec@1 32.000 (25.549)\n",
            "Test: [60/100]\tTime 0.037 (0.042)\tLoss 73.8448 (62.1202)\tPrec@1 27.000 (25.852)\n",
            "Test: [70/100]\tTime 0.045 (0.041)\tLoss 60.8360 (61.6899)\tPrec@1 31.000 (25.803)\n",
            "Test: [80/100]\tTime 0.047 (0.041)\tLoss 49.5087 (61.6055)\tPrec@1 25.000 (25.630)\n",
            "Test: [90/100]\tTime 0.049 (0.040)\tLoss 61.7595 (61.6076)\tPrec@1 26.000 (25.626)\n",
            "val Results: Prec@1 25.680 Loss 61.20166\n",
            "Best Prec@1: 30.380\n",
            "\n",
            "Epoch: [4][0/97], lr: 0.01000\tTime 0.499 (0.499)\tData 0.347 (0.347)\tLoss 3.5702 (3.5702)\tPrec@1 32.812 (32.812)\n",
            "Epoch: [4][10/97], lr: 0.01000\tTime 0.082 (0.112)\tData 0.008 (0.033)\tLoss 2.0052 (2.3416)\tPrec@1 24.219 (27.131)\n",
            "Epoch: [4][20/97], lr: 0.01000\tTime 0.063 (0.091)\tData 0.000 (0.019)\tLoss 1.6445 (2.1584)\tPrec@1 32.812 (27.716)\n",
            "Epoch: [4][30/97], lr: 0.01000\tTime 0.067 (0.085)\tData 0.006 (0.015)\tLoss 3.1584 (2.2794)\tPrec@1 28.125 (28.805)\n",
            "Epoch: [4][40/97], lr: 0.01000\tTime 0.061 (0.082)\tData 0.000 (0.012)\tLoss 1.2940 (2.3241)\tPrec@1 34.375 (28.887)\n",
            "Epoch: [4][50/97], lr: 0.01000\tTime 0.077 (0.080)\tData 0.006 (0.010)\tLoss 1.3989 (2.5292)\tPrec@1 27.344 (28.830)\n",
            "Epoch: [4][60/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.002 (0.009)\tLoss 1.6468 (2.4660)\tPrec@1 24.219 (28.676)\n",
            "Epoch: [4][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.008)\tLoss 1.3279 (2.4171)\tPrec@1 28.906 (29.126)\n",
            "Epoch: [4][80/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.008)\tLoss 2.6068 (2.3964)\tPrec@1 32.812 (29.659)\n",
            "Epoch: [4][90/97], lr: 0.01000\tTime 0.044 (0.076)\tData 0.000 (0.007)\tLoss 1.5869 (2.3800)\tPrec@1 35.156 (30.065)\n",
            "Test: [0/100]\tTime 0.260 (0.260)\tLoss 1.4508 (1.4508)\tPrec@1 35.000 (35.000)\n",
            "Test: [10/100]\tTime 0.022 (0.058)\tLoss 1.3943 (1.4532)\tPrec@1 32.000 (32.636)\n",
            "Test: [20/100]\tTime 0.026 (0.045)\tLoss 1.5311 (1.4525)\tPrec@1 32.000 (32.952)\n",
            "Test: [30/100]\tTime 0.043 (0.041)\tLoss 1.5592 (1.4645)\tPrec@1 24.000 (32.129)\n",
            "Test: [40/100]\tTime 0.042 (0.039)\tLoss 1.4650 (1.4590)\tPrec@1 30.000 (32.488)\n",
            "Test: [50/100]\tTime 0.022 (0.036)\tLoss 1.4620 (1.4620)\tPrec@1 34.000 (32.471)\n",
            "Test: [60/100]\tTime 0.078 (0.037)\tLoss 1.5408 (1.4625)\tPrec@1 24.000 (32.230)\n",
            "Test: [70/100]\tTime 0.030 (0.036)\tLoss 1.4276 (1.4618)\tPrec@1 33.000 (32.239)\n",
            "Test: [80/100]\tTime 0.040 (0.037)\tLoss 1.4635 (1.4591)\tPrec@1 34.000 (32.531)\n",
            "Test: [90/100]\tTime 0.044 (0.037)\tLoss 1.3974 (1.4572)\tPrec@1 35.000 (32.824)\n",
            "val Results: Prec@1 32.850 Loss 1.45581\n",
            "Best Prec@1: 32.850\n",
            "\n",
            "Epoch: [5][0/97], lr: 0.01000\tTime 0.517 (0.517)\tData 0.384 (0.384)\tLoss 1.3316 (1.3316)\tPrec@1 31.250 (31.250)\n",
            "Epoch: [5][10/97], lr: 0.01000\tTime 0.069 (0.117)\tData 0.000 (0.037)\tLoss 1.3967 (1.6959)\tPrec@1 29.688 (32.244)\n",
            "Epoch: [5][20/97], lr: 0.01000\tTime 0.079 (0.096)\tData 0.003 (0.021)\tLoss 1.3412 (1.7088)\tPrec@1 39.844 (32.403)\n",
            "Epoch: [5][30/97], lr: 0.01000\tTime 0.094 (0.092)\tData 0.005 (0.015)\tLoss 1.3313 (1.7572)\tPrec@1 35.156 (32.308)\n",
            "Epoch: [5][40/97], lr: 0.01000\tTime 0.135 (0.097)\tData 0.000 (0.012)\tLoss 1.6427 (1.7954)\tPrec@1 32.812 (33.003)\n",
            "Epoch: [5][50/97], lr: 0.01000\tTime 0.121 (0.099)\tData 0.007 (0.011)\tLoss 1.3619 (1.7655)\tPrec@1 26.562 (33.517)\n",
            "Epoch: [5][60/97], lr: 0.01000\tTime 0.147 (0.100)\tData 0.007 (0.010)\tLoss 1.6070 (1.7257)\tPrec@1 37.500 (33.594)\n",
            "Epoch: [5][70/97], lr: 0.01000\tTime 0.079 (0.100)\tData 0.000 (0.009)\tLoss 1.3853 (1.7588)\tPrec@1 32.812 (33.726)\n",
            "Epoch: [5][80/97], lr: 0.01000\tTime 0.065 (0.098)\tData 0.004 (0.008)\tLoss 1.7352 (1.7602)\tPrec@1 29.688 (33.700)\n",
            "Epoch: [5][90/97], lr: 0.01000\tTime 0.053 (0.096)\tData 0.000 (0.007)\tLoss 1.9501 (1.7570)\tPrec@1 36.719 (33.903)\n",
            "Test: [0/100]\tTime 0.379 (0.379)\tLoss 1.2490 (1.2490)\tPrec@1 48.000 (48.000)\n",
            "Test: [10/100]\tTime 0.028 (0.067)\tLoss 1.3470 (1.3371)\tPrec@1 40.000 (38.364)\n",
            "Test: [20/100]\tTime 0.028 (0.054)\tLoss 1.3565 (1.3353)\tPrec@1 30.000 (37.857)\n",
            "Test: [30/100]\tTime 0.022 (0.046)\tLoss 1.3391 (1.3423)\tPrec@1 36.000 (36.935)\n",
            "Test: [40/100]\tTime 0.021 (0.042)\tLoss 1.3743 (1.3436)\tPrec@1 34.000 (36.000)\n",
            "Test: [50/100]\tTime 0.035 (0.040)\tLoss 1.3386 (1.3460)\tPrec@1 36.000 (36.157)\n",
            "Test: [60/100]\tTime 0.024 (0.038)\tLoss 1.4292 (1.3487)\tPrec@1 29.000 (35.885)\n",
            "Test: [70/100]\tTime 0.053 (0.037)\tLoss 1.3622 (1.3500)\tPrec@1 35.000 (35.690)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 1.3878 (1.3506)\tPrec@1 31.000 (35.790)\n",
            "Test: [90/100]\tTime 0.055 (0.037)\tLoss 1.3285 (1.3483)\tPrec@1 34.000 (36.044)\n",
            "val Results: Prec@1 35.920 Loss 1.34952\n",
            "Best Prec@1: 35.920\n",
            "\n",
            "Epoch: [6][0/97], lr: 0.01000\tTime 0.568 (0.568)\tData 0.421 (0.421)\tLoss 1.6377 (1.6377)\tPrec@1 39.844 (39.844)\n",
            "Epoch: [6][10/97], lr: 0.01000\tTime 0.061 (0.116)\tData 0.001 (0.041)\tLoss 1.3127 (1.6734)\tPrec@1 44.531 (37.713)\n",
            "Epoch: [6][20/97], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.023)\tLoss 2.3081 (1.6730)\tPrec@1 48.438 (38.244)\n",
            "Epoch: [6][30/97], lr: 0.01000\tTime 0.063 (0.087)\tData 0.001 (0.017)\tLoss 1.3232 (1.6193)\tPrec@1 35.938 (38.180)\n",
            "Epoch: [6][40/97], lr: 0.01000\tTime 0.069 (0.083)\tData 0.007 (0.014)\tLoss 1.3548 (1.6219)\tPrec@1 42.188 (38.091)\n",
            "Epoch: [6][50/97], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.012)\tLoss 1.7356 (1.6262)\tPrec@1 32.031 (37.791)\n",
            "Epoch: [6][60/97], lr: 0.01000\tTime 0.084 (0.080)\tData 0.000 (0.010)\tLoss 1.9694 (1.6460)\tPrec@1 38.281 (37.948)\n",
            "Epoch: [6][70/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.009)\tLoss 1.3293 (1.6337)\tPrec@1 37.500 (37.632)\n",
            "Epoch: [6][80/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.008)\tLoss 1.7581 (1.6469)\tPrec@1 38.281 (37.500)\n",
            "Epoch: [6][90/97], lr: 0.01000\tTime 0.054 (0.077)\tData 0.000 (0.007)\tLoss 1.3232 (1.6381)\tPrec@1 38.281 (37.835)\n",
            "Test: [0/100]\tTime 0.330 (0.330)\tLoss 1.2274 (1.2274)\tPrec@1 44.000 (44.000)\n",
            "Test: [10/100]\tTime 0.030 (0.066)\tLoss 1.3740 (1.2866)\tPrec@1 31.000 (41.455)\n",
            "Test: [20/100]\tTime 0.033 (0.051)\tLoss 1.3411 (1.2900)\tPrec@1 32.000 (41.095)\n",
            "Test: [30/100]\tTime 0.021 (0.046)\tLoss 1.3755 (1.2988)\tPrec@1 35.000 (40.129)\n",
            "Test: [40/100]\tTime 0.031 (0.044)\tLoss 1.2949 (1.2955)\tPrec@1 40.000 (40.707)\n",
            "Test: [50/100]\tTime 0.042 (0.042)\tLoss 1.3088 (1.2945)\tPrec@1 43.000 (41.275)\n",
            "Test: [60/100]\tTime 0.031 (0.041)\tLoss 1.3179 (1.2987)\tPrec@1 36.000 (40.934)\n",
            "Test: [70/100]\tTime 0.041 (0.040)\tLoss 1.2685 (1.2983)\tPrec@1 48.000 (41.042)\n",
            "Test: [80/100]\tTime 0.023 (0.040)\tLoss 1.3799 (1.2995)\tPrec@1 31.000 (40.728)\n",
            "Test: [90/100]\tTime 0.040 (0.039)\tLoss 1.3209 (1.2985)\tPrec@1 45.000 (40.923)\n",
            "val Results: Prec@1 40.730 Loss 1.29946\n",
            "Best Prec@1: 40.730\n",
            "\n",
            "Epoch: [7][0/97], lr: 0.01000\tTime 0.472 (0.472)\tData 0.286 (0.286)\tLoss 1.9822 (1.9822)\tPrec@1 29.688 (29.688)\n",
            "Epoch: [7][10/97], lr: 0.01000\tTime 0.061 (0.113)\tData 0.000 (0.029)\tLoss 1.2370 (1.5379)\tPrec@1 45.312 (39.702)\n",
            "Epoch: [7][20/97], lr: 0.01000\tTime 0.066 (0.093)\tData 0.000 (0.017)\tLoss 1.7956 (1.4823)\tPrec@1 41.406 (40.253)\n",
            "Epoch: [7][30/97], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.013)\tLoss 1.2962 (1.4337)\tPrec@1 40.625 (40.953)\n",
            "Epoch: [7][40/97], lr: 0.01000\tTime 0.062 (0.082)\tData 0.000 (0.010)\tLoss 1.2879 (1.4143)\tPrec@1 41.406 (40.892)\n",
            "Epoch: [7][50/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.009)\tLoss 1.3341 (1.4158)\tPrec@1 41.406 (41.008)\n",
            "Epoch: [7][60/97], lr: 0.01000\tTime 0.067 (0.078)\tData 0.004 (0.007)\tLoss 1.3350 (1.4005)\tPrec@1 39.844 (40.907)\n",
            "Epoch: [7][70/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.006)\tLoss 1.2285 (1.3913)\tPrec@1 46.875 (41.241)\n",
            "Epoch: [7][80/97], lr: 0.01000\tTime 0.073 (0.076)\tData 0.000 (0.006)\tLoss 1.2786 (1.3811)\tPrec@1 41.406 (41.329)\n",
            "Epoch: [7][90/97], lr: 0.01000\tTime 0.055 (0.075)\tData 0.000 (0.005)\tLoss 1.3563 (1.3751)\tPrec@1 35.156 (41.243)\n",
            "Test: [0/100]\tTime 0.268 (0.268)\tLoss 1.1832 (1.1832)\tPrec@1 46.000 (46.000)\n",
            "Test: [10/100]\tTime 0.022 (0.058)\tLoss 1.3533 (1.2879)\tPrec@1 37.000 (42.455)\n",
            "Test: [20/100]\tTime 0.030 (0.046)\tLoss 1.4411 (1.2805)\tPrec@1 30.000 (42.476)\n",
            "Test: [30/100]\tTime 0.036 (0.042)\tLoss 1.3021 (1.2927)\tPrec@1 43.000 (41.194)\n",
            "Test: [40/100]\tTime 0.037 (0.040)\tLoss 1.3288 (1.2910)\tPrec@1 36.000 (40.927)\n",
            "Test: [50/100]\tTime 0.044 (0.039)\tLoss 1.2606 (1.2895)\tPrec@1 43.000 (41.118)\n",
            "Test: [60/100]\tTime 0.027 (0.040)\tLoss 1.4126 (1.2972)\tPrec@1 33.000 (40.393)\n",
            "Test: [70/100]\tTime 0.042 (0.039)\tLoss 1.3158 (1.2990)\tPrec@1 39.000 (40.211)\n",
            "Test: [80/100]\tTime 0.032 (0.038)\tLoss 1.2747 (1.2996)\tPrec@1 41.000 (39.975)\n",
            "Test: [90/100]\tTime 0.040 (0.038)\tLoss 1.3850 (1.3000)\tPrec@1 36.000 (39.934)\n",
            "val Results: Prec@1 39.750 Loss 1.30164\n",
            "Best Prec@1: 40.730\n",
            "\n",
            "Epoch: [8][0/97], lr: 0.01000\tTime 0.587 (0.587)\tData 0.437 (0.437)\tLoss 1.3117 (1.3117)\tPrec@1 38.281 (38.281)\n",
            "Epoch: [8][10/97], lr: 0.01000\tTime 0.067 (0.131)\tData 0.006 (0.043)\tLoss 1.4923 (1.3880)\tPrec@1 42.188 (39.276)\n",
            "Epoch: [8][20/97], lr: 0.01000\tTime 0.067 (0.104)\tData 0.000 (0.024)\tLoss 1.5172 (1.3782)\tPrec@1 35.938 (39.881)\n",
            "Epoch: [8][30/97], lr: 0.01000\tTime 0.062 (0.093)\tData 0.000 (0.017)\tLoss 1.3348 (1.3841)\tPrec@1 33.594 (40.827)\n",
            "Epoch: [8][40/97], lr: 0.01000\tTime 0.070 (0.088)\tData 0.007 (0.013)\tLoss 1.3457 (1.3688)\tPrec@1 36.719 (40.511)\n",
            "Epoch: [8][50/97], lr: 0.01000\tTime 0.062 (0.085)\tData 0.001 (0.011)\tLoss 1.3082 (1.3561)\tPrec@1 35.938 (40.686)\n",
            "Epoch: [8][60/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.006 (0.010)\tLoss 1.3542 (1.3521)\tPrec@1 39.062 (41.048)\n",
            "Epoch: [8][70/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.009)\tLoss 1.2446 (1.3503)\tPrec@1 46.875 (41.318)\n",
            "Epoch: [8][80/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.008)\tLoss 1.1151 (1.3414)\tPrec@1 55.469 (41.966)\n",
            "Epoch: [8][90/97], lr: 0.01000\tTime 0.054 (0.078)\tData 0.000 (0.007)\tLoss 1.2994 (1.3399)\tPrec@1 39.844 (42.359)\n",
            "Test: [0/100]\tTime 0.361 (0.361)\tLoss 1.2134 (1.2134)\tPrec@1 47.000 (47.000)\n",
            "Test: [10/100]\tTime 0.021 (0.065)\tLoss 1.3019 (1.3103)\tPrec@1 34.000 (39.818)\n",
            "Test: [20/100]\tTime 0.049 (0.050)\tLoss 1.4349 (1.3193)\tPrec@1 33.000 (39.333)\n",
            "Test: [30/100]\tTime 0.023 (0.045)\tLoss 1.4042 (1.3317)\tPrec@1 35.000 (38.710)\n",
            "Test: [40/100]\tTime 0.029 (0.043)\tLoss 1.4128 (1.3291)\tPrec@1 32.000 (38.780)\n",
            "Test: [50/100]\tTime 0.041 (0.042)\tLoss 1.3429 (1.3350)\tPrec@1 39.000 (38.549)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.3632 (1.3381)\tPrec@1 39.000 (38.049)\n",
            "Test: [70/100]\tTime 0.022 (0.040)\tLoss 1.3247 (1.3359)\tPrec@1 38.000 (38.141)\n",
            "Test: [80/100]\tTime 0.022 (0.039)\tLoss 1.3836 (1.3345)\tPrec@1 33.000 (38.148)\n",
            "Test: [90/100]\tTime 0.024 (0.039)\tLoss 1.3742 (1.3333)\tPrec@1 35.000 (38.242)\n",
            "val Results: Prec@1 38.300 Loss 1.33466\n",
            "Best Prec@1: 40.730\n",
            "\n",
            "Epoch: [9][0/97], lr: 0.01000\tTime 0.489 (0.489)\tData 0.301 (0.301)\tLoss 1.2391 (1.2391)\tPrec@1 47.656 (47.656)\n",
            "Epoch: [9][10/97], lr: 0.01000\tTime 0.073 (0.119)\tData 0.006 (0.029)\tLoss 1.2362 (1.3171)\tPrec@1 40.625 (42.259)\n",
            "Epoch: [9][20/97], lr: 0.01000\tTime 0.062 (0.095)\tData 0.000 (0.016)\tLoss 1.2140 (1.2871)\tPrec@1 48.438 (43.378)\n",
            "Epoch: [9][30/97], lr: 0.01000\tTime 0.068 (0.088)\tData 0.002 (0.012)\tLoss 1.3956 (1.2917)\tPrec@1 40.625 (42.818)\n",
            "Epoch: [9][40/97], lr: 0.01000\tTime 0.069 (0.084)\tData 0.000 (0.010)\tLoss 1.2866 (1.3007)\tPrec@1 49.219 (42.931)\n",
            "Epoch: [9][50/97], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.008)\tLoss 1.2643 (1.3074)\tPrec@1 44.531 (42.846)\n",
            "Epoch: [9][60/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.007 (0.007)\tLoss 1.1789 (1.3027)\tPrec@1 44.531 (43.289)\n",
            "Epoch: [9][70/97], lr: 0.01000\tTime 0.072 (0.079)\tData 0.000 (0.006)\tLoss 1.2069 (1.2979)\tPrec@1 45.312 (43.387)\n",
            "Epoch: [9][80/97], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.006)\tLoss 1.2815 (1.2984)\tPrec@1 41.406 (43.171)\n",
            "Epoch: [9][90/97], lr: 0.01000\tTime 0.053 (0.077)\tData 0.000 (0.005)\tLoss 1.3162 (1.2961)\tPrec@1 39.062 (43.261)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 1.1941 (1.1941)\tPrec@1 48.000 (48.000)\n",
            "Test: [10/100]\tTime 0.027 (0.068)\tLoss 1.3372 (1.2711)\tPrec@1 39.000 (42.091)\n",
            "Test: [20/100]\tTime 0.022 (0.053)\tLoss 1.3966 (1.2805)\tPrec@1 37.000 (41.476)\n",
            "Test: [30/100]\tTime 0.032 (0.048)\tLoss 1.2556 (1.2887)\tPrec@1 46.000 (41.097)\n",
            "Test: [40/100]\tTime 0.056 (0.046)\tLoss 1.3429 (1.2891)\tPrec@1 37.000 (40.756)\n",
            "Test: [50/100]\tTime 0.032 (0.044)\tLoss 1.2432 (1.2890)\tPrec@1 47.000 (40.745)\n",
            "Test: [60/100]\tTime 0.031 (0.043)\tLoss 1.3169 (1.2917)\tPrec@1 39.000 (40.803)\n",
            "Test: [70/100]\tTime 0.041 (0.042)\tLoss 1.2347 (1.2889)\tPrec@1 48.000 (40.662)\n",
            "Test: [80/100]\tTime 0.023 (0.041)\tLoss 1.3646 (1.2901)\tPrec@1 34.000 (40.531)\n",
            "Test: [90/100]\tTime 0.036 (0.039)\tLoss 1.3367 (1.2880)\tPrec@1 42.000 (40.835)\n",
            "val Results: Prec@1 40.840 Loss 1.28755\n",
            "Best Prec@1: 40.840\n",
            "\n",
            "Epoch: [10][0/97], lr: 0.01000\tTime 0.524 (0.524)\tData 0.386 (0.386)\tLoss 1.3907 (1.3907)\tPrec@1 42.969 (42.969)\n",
            "Epoch: [10][10/97], lr: 0.01000\tTime 0.070 (0.114)\tData 0.000 (0.038)\tLoss 1.3289 (1.2690)\tPrec@1 39.844 (43.963)\n",
            "Epoch: [10][20/97], lr: 0.01000\tTime 0.066 (0.093)\tData 0.000 (0.022)\tLoss 1.2038 (1.2459)\tPrec@1 44.531 (45.945)\n",
            "Epoch: [10][30/97], lr: 0.01000\tTime 0.063 (0.086)\tData 0.000 (0.015)\tLoss 1.3482 (1.2484)\tPrec@1 47.656 (45.615)\n",
            "Epoch: [10][40/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.001 (0.012)\tLoss 1.1994 (1.2493)\tPrec@1 45.312 (45.389)\n",
            "Epoch: [10][50/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.010)\tLoss 1.2536 (1.2526)\tPrec@1 44.531 (44.700)\n",
            "Epoch: [10][60/97], lr: 0.01000\tTime 0.086 (0.079)\tData 0.000 (0.008)\tLoss 1.2580 (1.2524)\tPrec@1 46.094 (44.518)\n",
            "Epoch: [10][70/97], lr: 0.01000\tTime 0.082 (0.078)\tData 0.007 (0.008)\tLoss 1.3020 (1.2556)\tPrec@1 39.844 (44.036)\n",
            "Epoch: [10][80/97], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.007)\tLoss 1.3039 (1.2538)\tPrec@1 38.281 (44.088)\n",
            "Epoch: [10][90/97], lr: 0.01000\tTime 0.053 (0.076)\tData 0.000 (0.006)\tLoss 1.2405 (1.2528)\tPrec@1 44.531 (44.188)\n",
            "Test: [0/100]\tTime 0.382 (0.382)\tLoss 1.1470 (1.1470)\tPrec@1 46.000 (46.000)\n",
            "Test: [10/100]\tTime 0.032 (0.072)\tLoss 1.3015 (1.2433)\tPrec@1 34.000 (44.182)\n",
            "Test: [20/100]\tTime 0.028 (0.052)\tLoss 1.3399 (1.2443)\tPrec@1 43.000 (43.619)\n",
            "Test: [30/100]\tTime 0.033 (0.046)\tLoss 1.3273 (1.2565)\tPrec@1 37.000 (42.452)\n",
            "Test: [40/100]\tTime 0.033 (0.045)\tLoss 1.2576 (1.2499)\tPrec@1 40.000 (42.902)\n",
            "Test: [50/100]\tTime 0.028 (0.043)\tLoss 1.2909 (1.2543)\tPrec@1 44.000 (43.020)\n",
            "Test: [60/100]\tTime 0.045 (0.042)\tLoss 1.3014 (1.2571)\tPrec@1 36.000 (42.820)\n",
            "Test: [70/100]\tTime 0.037 (0.041)\tLoss 1.2358 (1.2562)\tPrec@1 43.000 (43.070)\n",
            "Test: [80/100]\tTime 0.043 (0.040)\tLoss 1.2435 (1.2572)\tPrec@1 41.000 (42.951)\n",
            "Test: [90/100]\tTime 0.032 (0.040)\tLoss 1.2819 (1.2546)\tPrec@1 44.000 (43.209)\n",
            "val Results: Prec@1 42.960 Loss 1.25611\n",
            "Best Prec@1: 42.960\n",
            "\n",
            "Epoch: [11][0/97], lr: 0.01000\tTime 0.498 (0.498)\tData 0.307 (0.307)\tLoss 1.2525 (1.2525)\tPrec@1 43.750 (43.750)\n",
            "Epoch: [11][10/97], lr: 0.01000\tTime 0.061 (0.117)\tData 0.000 (0.030)\tLoss 1.3298 (1.2470)\tPrec@1 45.312 (43.679)\n",
            "Epoch: [11][20/97], lr: 0.01000\tTime 0.073 (0.095)\tData 0.003 (0.017)\tLoss 1.1618 (1.2438)\tPrec@1 50.000 (45.164)\n",
            "Epoch: [11][30/97], lr: 0.01000\tTime 0.076 (0.088)\tData 0.010 (0.013)\tLoss 1.1994 (1.2499)\tPrec@1 50.000 (45.186)\n",
            "Epoch: [11][40/97], lr: 0.01000\tTime 0.073 (0.084)\tData 0.010 (0.010)\tLoss 1.1892 (1.2446)\tPrec@1 48.438 (45.008)\n",
            "Epoch: [11][50/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.006 (0.009)\tLoss 1.2025 (1.2457)\tPrec@1 47.656 (44.960)\n",
            "Epoch: [11][60/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.001 (0.008)\tLoss 1.1683 (1.2465)\tPrec@1 46.875 (44.595)\n",
            "Epoch: [11][70/97], lr: 0.01000\tTime 0.061 (0.078)\tData 0.000 (0.007)\tLoss 1.2990 (1.2459)\tPrec@1 41.406 (44.674)\n",
            "Epoch: [11][80/97], lr: 0.01000\tTime 0.071 (0.077)\tData 0.000 (0.007)\tLoss 1.2232 (1.2452)\tPrec@1 50.000 (44.589)\n",
            "Epoch: [11][90/97], lr: 0.01000\tTime 0.053 (0.076)\tData 0.000 (0.006)\tLoss 1.2617 (1.2450)\tPrec@1 41.406 (44.548)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 1.1192 (1.1192)\tPrec@1 49.000 (49.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 1.2696 (1.2242)\tPrec@1 40.000 (44.000)\n",
            "Test: [20/100]\tTime 0.031 (0.047)\tLoss 1.3248 (1.2206)\tPrec@1 34.000 (44.524)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 1.2081 (1.2344)\tPrec@1 48.000 (43.839)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 1.2382 (1.2296)\tPrec@1 41.000 (44.341)\n",
            "Test: [50/100]\tTime 0.032 (0.038)\tLoss 1.2016 (1.2350)\tPrec@1 52.000 (44.196)\n",
            "Test: [60/100]\tTime 0.025 (0.037)\tLoss 1.2830 (1.2402)\tPrec@1 39.000 (43.902)\n",
            "Test: [70/100]\tTime 0.025 (0.038)\tLoss 1.2290 (1.2387)\tPrec@1 44.000 (44.042)\n",
            "Test: [80/100]\tTime 0.038 (0.038)\tLoss 1.3126 (1.2390)\tPrec@1 37.000 (43.864)\n",
            "Test: [90/100]\tTime 0.023 (0.037)\tLoss 1.3433 (1.2376)\tPrec@1 43.000 (44.077)\n",
            "val Results: Prec@1 43.960 Loss 1.23826\n",
            "Best Prec@1: 43.960\n",
            "\n",
            "Epoch: [12][0/97], lr: 0.01000\tTime 0.499 (0.499)\tData 0.320 (0.320)\tLoss 1.3116 (1.3116)\tPrec@1 42.188 (42.188)\n",
            "Epoch: [12][10/97], lr: 0.01000\tTime 0.057 (0.113)\tData 0.000 (0.032)\tLoss 1.2488 (1.2503)\tPrec@1 41.406 (43.466)\n",
            "Epoch: [12][20/97], lr: 0.01000\tTime 0.088 (0.093)\tData 0.000 (0.019)\tLoss 1.2301 (1.2469)\tPrec@1 44.531 (43.564)\n",
            "Epoch: [12][30/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.006 (0.014)\tLoss 1.2638 (1.2375)\tPrec@1 40.625 (44.078)\n",
            "Epoch: [12][40/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.011)\tLoss 1.1331 (1.2359)\tPrec@1 55.469 (44.493)\n",
            "Epoch: [12][50/97], lr: 0.01000\tTime 0.097 (0.080)\tData 0.006 (0.009)\tLoss 1.2445 (1.2303)\tPrec@1 46.094 (44.899)\n",
            "Epoch: [12][60/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.009)\tLoss 1.1511 (1.2296)\tPrec@1 50.781 (44.864)\n",
            "Epoch: [12][70/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.008)\tLoss 1.3586 (1.2310)\tPrec@1 39.062 (44.784)\n",
            "Epoch: [12][80/97], lr: 0.01000\tTime 0.078 (0.076)\tData 0.000 (0.007)\tLoss 1.1157 (1.2287)\tPrec@1 51.562 (44.907)\n",
            "Epoch: [12][90/97], lr: 0.01000\tTime 0.057 (0.075)\tData 0.000 (0.007)\tLoss 1.1832 (1.2294)\tPrec@1 46.875 (44.952)\n",
            "Test: [0/100]\tTime 0.331 (0.331)\tLoss 1.1542 (1.1542)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.022 (0.066)\tLoss 1.3343 (1.2575)\tPrec@1 31.000 (44.909)\n",
            "Test: [20/100]\tTime 0.022 (0.051)\tLoss 1.3755 (1.2616)\tPrec@1 34.000 (42.667)\n",
            "Test: [30/100]\tTime 0.032 (0.046)\tLoss 1.3157 (1.2740)\tPrec@1 40.000 (41.710)\n",
            "Test: [40/100]\tTime 0.027 (0.043)\tLoss 1.2516 (1.2686)\tPrec@1 45.000 (42.341)\n",
            "Test: [50/100]\tTime 0.022 (0.041)\tLoss 1.1965 (1.2683)\tPrec@1 51.000 (42.373)\n",
            "Test: [60/100]\tTime 0.029 (0.040)\tLoss 1.2689 (1.2717)\tPrec@1 38.000 (41.885)\n",
            "Test: [70/100]\tTime 0.029 (0.039)\tLoss 1.2568 (1.2693)\tPrec@1 45.000 (42.113)\n",
            "Test: [80/100]\tTime 0.035 (0.039)\tLoss 1.2911 (1.2700)\tPrec@1 41.000 (42.198)\n",
            "Test: [90/100]\tTime 0.053 (0.039)\tLoss 1.2893 (1.2666)\tPrec@1 42.000 (42.604)\n",
            "val Results: Prec@1 42.600 Loss 1.26552\n",
            "Best Prec@1: 43.960\n",
            "\n",
            "Epoch: [13][0/97], lr: 0.01000\tTime 0.518 (0.518)\tData 0.329 (0.329)\tLoss 1.1672 (1.1672)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [13][10/97], lr: 0.01000\tTime 0.076 (0.115)\tData 0.000 (0.032)\tLoss 1.1691 (1.2189)\tPrec@1 52.344 (47.372)\n",
            "Epoch: [13][20/97], lr: 0.01000\tTime 0.065 (0.093)\tData 0.003 (0.018)\tLoss 1.2729 (1.2468)\tPrec@1 32.812 (44.494)\n",
            "Epoch: [13][30/97], lr: 0.01000\tTime 0.078 (0.086)\tData 0.000 (0.013)\tLoss 1.1739 (1.2411)\tPrec@1 46.094 (44.204)\n",
            "Epoch: [13][40/97], lr: 0.01000\tTime 0.080 (0.088)\tData 0.000 (0.011)\tLoss 1.2527 (1.2344)\tPrec@1 42.969 (44.798)\n",
            "Epoch: [13][50/97], lr: 0.01000\tTime 0.110 (0.087)\tData 0.000 (0.009)\tLoss 1.2596 (1.2313)\tPrec@1 43.750 (44.991)\n",
            "Epoch: [13][60/97], lr: 0.01000\tTime 0.063 (0.086)\tData 0.000 (0.008)\tLoss 1.2081 (1.2275)\tPrec@1 46.875 (45.133)\n",
            "Epoch: [13][70/97], lr: 0.01000\tTime 0.080 (0.085)\tData 0.001 (0.007)\tLoss 1.2984 (1.2271)\tPrec@1 40.625 (45.279)\n",
            "Epoch: [13][80/97], lr: 0.01000\tTime 0.073 (0.084)\tData 0.007 (0.007)\tLoss 1.2554 (1.2271)\tPrec@1 41.406 (45.264)\n",
            "Epoch: [13][90/97], lr: 0.01000\tTime 0.056 (0.082)\tData 0.000 (0.006)\tLoss 1.2438 (1.2286)\tPrec@1 49.219 (45.184)\n",
            "Test: [0/100]\tTime 0.336 (0.336)\tLoss 1.1265 (1.1265)\tPrec@1 48.000 (48.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 1.3415 (1.2321)\tPrec@1 36.000 (43.727)\n",
            "Test: [20/100]\tTime 0.042 (0.054)\tLoss 1.3324 (1.2281)\tPrec@1 36.000 (44.000)\n",
            "Test: [30/100]\tTime 0.032 (0.048)\tLoss 1.3072 (1.2444)\tPrec@1 39.000 (43.065)\n",
            "Test: [40/100]\tTime 0.039 (0.045)\tLoss 1.2562 (1.2388)\tPrec@1 39.000 (43.537)\n",
            "Test: [50/100]\tTime 0.048 (0.044)\tLoss 1.2246 (1.2365)\tPrec@1 50.000 (43.961)\n",
            "Test: [60/100]\tTime 0.023 (0.042)\tLoss 1.3166 (1.2413)\tPrec@1 37.000 (43.672)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.1638 (1.2409)\tPrec@1 50.000 (43.535)\n",
            "Test: [80/100]\tTime 0.040 (0.041)\tLoss 1.2390 (1.2421)\tPrec@1 41.000 (43.519)\n",
            "Test: [90/100]\tTime 0.025 (0.040)\tLoss 1.3067 (1.2376)\tPrec@1 42.000 (43.868)\n",
            "val Results: Prec@1 43.750 Loss 1.23883\n",
            "Best Prec@1: 43.960\n",
            "\n",
            "Epoch: [14][0/97], lr: 0.01000\tTime 0.463 (0.463)\tData 0.293 (0.293)\tLoss 1.1185 (1.1185)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [14][10/97], lr: 0.01000\tTime 0.064 (0.112)\tData 0.000 (0.029)\tLoss 1.1923 (1.1695)\tPrec@1 44.531 (49.290)\n",
            "Epoch: [14][20/97], lr: 0.01000\tTime 0.071 (0.093)\tData 0.007 (0.017)\tLoss 1.3018 (1.1999)\tPrec@1 39.062 (46.987)\n",
            "Epoch: [14][30/97], lr: 0.01000\tTime 0.067 (0.086)\tData 0.003 (0.013)\tLoss 1.1704 (1.2076)\tPrec@1 50.781 (46.749)\n",
            "Epoch: [14][40/97], lr: 0.01000\tTime 0.079 (0.082)\tData 0.000 (0.010)\tLoss 1.1532 (1.2048)\tPrec@1 56.250 (47.142)\n",
            "Epoch: [14][50/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.007 (0.009)\tLoss 1.2966 (1.2096)\tPrec@1 36.719 (46.415)\n",
            "Epoch: [14][60/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.005 (0.008)\tLoss 1.2670 (1.2133)\tPrec@1 41.406 (46.068)\n",
            "Epoch: [14][70/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.008)\tLoss 1.1258 (1.2135)\tPrec@1 50.000 (46.138)\n",
            "Epoch: [14][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.000 (0.007)\tLoss 1.2237 (1.2161)\tPrec@1 42.188 (45.930)\n",
            "Epoch: [14][90/97], lr: 0.01000\tTime 0.053 (0.076)\tData 0.000 (0.007)\tLoss 1.1745 (1.2149)\tPrec@1 48.438 (46.008)\n",
            "Test: [0/100]\tTime 0.449 (0.449)\tLoss 1.0842 (1.0842)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.074)\tLoss 1.3072 (1.2179)\tPrec@1 37.000 (45.545)\n",
            "Test: [20/100]\tTime 0.028 (0.058)\tLoss 1.3040 (1.2170)\tPrec@1 39.000 (44.762)\n",
            "Test: [30/100]\tTime 0.023 (0.050)\tLoss 1.2945 (1.2289)\tPrec@1 34.000 (43.645)\n",
            "Test: [40/100]\tTime 0.031 (0.046)\tLoss 1.2738 (1.2274)\tPrec@1 40.000 (43.854)\n",
            "Test: [50/100]\tTime 0.033 (0.044)\tLoss 1.1874 (1.2314)\tPrec@1 50.000 (44.020)\n",
            "Test: [60/100]\tTime 0.029 (0.043)\tLoss 1.2919 (1.2363)\tPrec@1 38.000 (43.836)\n",
            "Test: [70/100]\tTime 0.022 (0.042)\tLoss 1.1903 (1.2350)\tPrec@1 48.000 (43.845)\n",
            "Test: [80/100]\tTime 0.057 (0.042)\tLoss 1.3076 (1.2376)\tPrec@1 40.000 (43.728)\n",
            "Test: [90/100]\tTime 0.037 (0.041)\tLoss 1.2929 (1.2352)\tPrec@1 41.000 (43.934)\n",
            "val Results: Prec@1 44.000 Loss 1.23366\n",
            "Best Prec@1: 44.000\n",
            "\n",
            "Epoch: [15][0/97], lr: 0.01000\tTime 0.544 (0.544)\tData 0.408 (0.408)\tLoss 1.2183 (1.2183)\tPrec@1 41.406 (41.406)\n",
            "Epoch: [15][10/97], lr: 0.01000\tTime 0.063 (0.117)\tData 0.000 (0.039)\tLoss 1.1657 (1.1893)\tPrec@1 49.219 (48.295)\n",
            "Epoch: [15][20/97], lr: 0.01000\tTime 0.073 (0.097)\tData 0.006 (0.022)\tLoss 1.2007 (1.2113)\tPrec@1 49.219 (47.135)\n",
            "Epoch: [15][30/97], lr: 0.01000\tTime 0.063 (0.088)\tData 0.000 (0.015)\tLoss 1.2766 (1.2185)\tPrec@1 38.281 (46.447)\n",
            "Epoch: [15][40/97], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.012)\tLoss 1.1764 (1.2188)\tPrec@1 46.094 (46.303)\n",
            "Epoch: [15][50/97], lr: 0.01000\tTime 0.059 (0.081)\tData 0.000 (0.011)\tLoss 1.1061 (1.2103)\tPrec@1 52.344 (46.952)\n",
            "Epoch: [15][60/97], lr: 0.01000\tTime 0.063 (0.079)\tData 0.000 (0.009)\tLoss 1.2345 (1.2111)\tPrec@1 43.750 (46.619)\n",
            "Epoch: [15][70/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.008)\tLoss 1.2027 (1.2094)\tPrec@1 45.312 (46.809)\n",
            "Epoch: [15][80/97], lr: 0.01000\tTime 0.071 (0.076)\tData 0.000 (0.007)\tLoss 1.2237 (1.2125)\tPrec@1 43.750 (46.431)\n",
            "Epoch: [15][90/97], lr: 0.01000\tTime 0.054 (0.077)\tData 0.000 (0.006)\tLoss 1.1919 (1.2144)\tPrec@1 50.781 (46.265)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 1.0708 (1.0708)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.047 (0.068)\tLoss 1.3262 (1.2081)\tPrec@1 39.000 (47.364)\n",
            "Test: [20/100]\tTime 0.022 (0.052)\tLoss 1.3228 (1.2111)\tPrec@1 36.000 (45.905)\n",
            "Test: [30/100]\tTime 0.021 (0.046)\tLoss 1.3042 (1.2216)\tPrec@1 41.000 (45.484)\n",
            "Test: [40/100]\tTime 0.026 (0.044)\tLoss 1.3266 (1.2161)\tPrec@1 37.000 (45.585)\n",
            "Test: [50/100]\tTime 0.025 (0.042)\tLoss 1.1756 (1.2229)\tPrec@1 48.000 (45.098)\n",
            "Test: [60/100]\tTime 0.026 (0.041)\tLoss 1.2888 (1.2278)\tPrec@1 44.000 (45.049)\n",
            "Test: [70/100]\tTime 0.053 (0.040)\tLoss 1.1887 (1.2283)\tPrec@1 52.000 (45.141)\n",
            "Test: [80/100]\tTime 0.022 (0.039)\tLoss 1.2371 (1.2274)\tPrec@1 43.000 (45.025)\n",
            "Test: [90/100]\tTime 0.056 (0.039)\tLoss 1.2511 (1.2242)\tPrec@1 45.000 (45.143)\n",
            "val Results: Prec@1 45.170 Loss 1.22403\n",
            "Best Prec@1: 45.170\n",
            "\n",
            "Epoch: [16][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.430 (0.430)\tLoss 1.2110 (1.2110)\tPrec@1 46.094 (46.094)\n",
            "Epoch: [16][10/97], lr: 0.01000\tTime 0.093 (0.121)\tData 0.009 (0.042)\tLoss 1.1982 (1.2137)\tPrec@1 42.188 (46.520)\n",
            "Epoch: [16][20/97], lr: 0.01000\tTime 0.071 (0.096)\tData 0.007 (0.024)\tLoss 1.2810 (1.2078)\tPrec@1 42.969 (47.061)\n",
            "Epoch: [16][30/97], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.016)\tLoss 1.2191 (1.2053)\tPrec@1 48.438 (46.749)\n",
            "Epoch: [16][40/97], lr: 0.01000\tTime 0.079 (0.084)\tData 0.011 (0.013)\tLoss 1.2043 (1.1992)\tPrec@1 45.312 (46.989)\n",
            "Epoch: [16][50/97], lr: 0.01000\tTime 0.071 (0.081)\tData 0.006 (0.011)\tLoss 1.2605 (1.2038)\tPrec@1 46.875 (46.829)\n",
            "Epoch: [16][60/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.006 (0.010)\tLoss 1.2341 (1.2022)\tPrec@1 39.844 (47.170)\n",
            "Epoch: [16][70/97], lr: 0.01000\tTime 0.060 (0.077)\tData 0.000 (0.009)\tLoss 1.1668 (1.2014)\tPrec@1 46.875 (47.073)\n",
            "Epoch: [16][80/97], lr: 0.01000\tTime 0.066 (0.076)\tData 0.000 (0.008)\tLoss 1.1460 (1.2052)\tPrec@1 50.781 (46.721)\n",
            "Epoch: [16][90/97], lr: 0.01000\tTime 0.056 (0.075)\tData 0.000 (0.007)\tLoss 1.2952 (1.2061)\tPrec@1 38.281 (46.506)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.0688 (1.0688)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.067)\tLoss 1.2604 (1.2028)\tPrec@1 42.000 (46.091)\n",
            "Test: [20/100]\tTime 0.022 (0.052)\tLoss 1.2987 (1.1931)\tPrec@1 43.000 (46.238)\n",
            "Test: [30/100]\tTime 0.032 (0.048)\tLoss 1.3064 (1.2098)\tPrec@1 37.000 (44.871)\n",
            "Test: [40/100]\tTime 0.029 (0.045)\tLoss 1.2566 (1.2075)\tPrec@1 44.000 (45.098)\n",
            "Test: [50/100]\tTime 0.048 (0.043)\tLoss 1.1801 (1.2103)\tPrec@1 48.000 (45.078)\n",
            "Test: [60/100]\tTime 0.050 (0.042)\tLoss 1.2436 (1.2161)\tPrec@1 39.000 (44.852)\n",
            "Test: [70/100]\tTime 0.024 (0.040)\tLoss 1.2428 (1.2149)\tPrec@1 42.000 (44.761)\n",
            "Test: [80/100]\tTime 0.044 (0.039)\tLoss 1.2533 (1.2148)\tPrec@1 45.000 (44.827)\n",
            "Test: [90/100]\tTime 0.033 (0.039)\tLoss 1.2625 (1.2121)\tPrec@1 44.000 (45.000)\n",
            "val Results: Prec@1 45.020 Loss 1.21269\n",
            "Best Prec@1: 45.170\n",
            "\n",
            "Epoch: [17][0/97], lr: 0.01000\tTime 0.529 (0.529)\tData 0.379 (0.379)\tLoss 1.1929 (1.1929)\tPrec@1 49.219 (49.219)\n",
            "Epoch: [17][10/97], lr: 0.01000\tTime 0.068 (0.116)\tData 0.005 (0.038)\tLoss 1.1860 (1.2256)\tPrec@1 46.094 (44.673)\n",
            "Epoch: [17][20/97], lr: 0.01000\tTime 0.063 (0.094)\tData 0.000 (0.021)\tLoss 1.1458 (1.2103)\tPrec@1 50.000 (46.205)\n",
            "Epoch: [17][30/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.015)\tLoss 1.2641 (1.2027)\tPrec@1 46.094 (46.371)\n",
            "Epoch: [17][40/97], lr: 0.01000\tTime 0.081 (0.082)\tData 0.000 (0.011)\tLoss 1.1911 (1.2035)\tPrec@1 45.312 (45.998)\n",
            "Epoch: [17][50/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.000 (0.009)\tLoss 1.2247 (1.1971)\tPrec@1 46.875 (46.538)\n",
            "Epoch: [17][60/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.007 (0.008)\tLoss 1.1389 (1.1958)\tPrec@1 52.344 (46.657)\n",
            "Epoch: [17][70/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.007)\tLoss 1.1914 (1.1952)\tPrec@1 42.188 (46.666)\n",
            "Epoch: [17][80/97], lr: 0.01000\tTime 0.076 (0.077)\tData 0.007 (0.007)\tLoss 1.1766 (1.1958)\tPrec@1 50.781 (46.682)\n",
            "Epoch: [17][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 1.2027 (1.1947)\tPrec@1 44.531 (46.815)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 1.0765 (1.0765)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.021 (0.059)\tLoss 1.3084 (1.2141)\tPrec@1 36.000 (45.909)\n",
            "Test: [20/100]\tTime 0.027 (0.046)\tLoss 1.3747 (1.2184)\tPrec@1 37.000 (45.143)\n",
            "Test: [30/100]\tTime 0.063 (0.042)\tLoss 1.1922 (1.2315)\tPrec@1 45.000 (44.323)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 1.2256 (1.2250)\tPrec@1 46.000 (44.829)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.1881 (1.2246)\tPrec@1 50.000 (45.137)\n",
            "Test: [60/100]\tTime 0.033 (0.036)\tLoss 1.3102 (1.2272)\tPrec@1 44.000 (45.180)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 1.2340 (1.2274)\tPrec@1 42.000 (45.155)\n",
            "Test: [80/100]\tTime 0.023 (0.037)\tLoss 1.2366 (1.2260)\tPrec@1 44.000 (45.210)\n",
            "Test: [90/100]\tTime 0.031 (0.038)\tLoss 1.2992 (1.2229)\tPrec@1 43.000 (45.385)\n",
            "val Results: Prec@1 45.250 Loss 1.22287\n",
            "Best Prec@1: 45.250\n",
            "\n",
            "Epoch: [18][0/97], lr: 0.01000\tTime 0.703 (0.703)\tData 0.490 (0.490)\tLoss 1.1610 (1.1610)\tPrec@1 46.094 (46.094)\n",
            "Epoch: [18][10/97], lr: 0.01000\tTime 0.065 (0.162)\tData 0.000 (0.049)\tLoss 1.1113 (1.1605)\tPrec@1 55.469 (48.082)\n",
            "Epoch: [18][20/97], lr: 0.01000\tTime 0.062 (0.118)\tData 0.000 (0.027)\tLoss 1.2378 (1.1866)\tPrec@1 42.969 (46.540)\n",
            "Epoch: [18][30/97], lr: 0.01000\tTime 0.060 (0.102)\tData 0.000 (0.019)\tLoss 1.1938 (1.1843)\tPrec@1 48.438 (47.077)\n",
            "Epoch: [18][40/97], lr: 0.01000\tTime 0.068 (0.096)\tData 0.000 (0.015)\tLoss 1.0980 (1.1890)\tPrec@1 51.562 (47.085)\n",
            "Epoch: [18][50/97], lr: 0.01000\tTime 0.071 (0.091)\tData 0.006 (0.013)\tLoss 1.1767 (1.1907)\tPrec@1 50.781 (46.936)\n",
            "Epoch: [18][60/97], lr: 0.01000\tTime 0.066 (0.088)\tData 0.003 (0.011)\tLoss 1.1696 (1.1906)\tPrec@1 50.000 (47.259)\n",
            "Epoch: [18][70/97], lr: 0.01000\tTime 0.077 (0.086)\tData 0.006 (0.010)\tLoss 1.2416 (1.1869)\tPrec@1 42.188 (47.348)\n",
            "Epoch: [18][80/97], lr: 0.01000\tTime 0.064 (0.084)\tData 0.000 (0.009)\tLoss 1.1795 (1.1835)\tPrec@1 51.562 (47.502)\n",
            "Epoch: [18][90/97], lr: 0.01000\tTime 0.057 (0.084)\tData 0.000 (0.009)\tLoss 1.3080 (1.1846)\tPrec@1 45.312 (47.588)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 1.0775 (1.0775)\tPrec@1 46.000 (46.000)\n",
            "Test: [10/100]\tTime 0.022 (0.066)\tLoss 1.2824 (1.1973)\tPrec@1 44.000 (44.727)\n",
            "Test: [20/100]\tTime 0.030 (0.051)\tLoss 1.2780 (1.1990)\tPrec@1 41.000 (45.476)\n",
            "Test: [30/100]\tTime 0.036 (0.047)\tLoss 1.2267 (1.2059)\tPrec@1 48.000 (45.484)\n",
            "Test: [40/100]\tTime 0.026 (0.044)\tLoss 1.2889 (1.2073)\tPrec@1 40.000 (45.585)\n",
            "Test: [50/100]\tTime 0.028 (0.042)\tLoss 1.1760 (1.2103)\tPrec@1 53.000 (45.588)\n",
            "Test: [60/100]\tTime 0.064 (0.041)\tLoss 1.3089 (1.2168)\tPrec@1 37.000 (45.525)\n",
            "Test: [70/100]\tTime 0.055 (0.040)\tLoss 1.1995 (1.2139)\tPrec@1 49.000 (45.606)\n",
            "Test: [80/100]\tTime 0.025 (0.039)\tLoss 1.1881 (1.2132)\tPrec@1 43.000 (45.531)\n",
            "Test: [90/100]\tTime 0.023 (0.038)\tLoss 1.2516 (1.2118)\tPrec@1 46.000 (45.725)\n",
            "val Results: Prec@1 45.730 Loss 1.21199\n",
            "Best Prec@1: 45.730\n",
            "\n",
            "Epoch: [19][0/97], lr: 0.01000\tTime 0.478 (0.478)\tData 0.300 (0.300)\tLoss 1.2256 (1.2256)\tPrec@1 46.875 (46.875)\n",
            "Epoch: [19][10/97], lr: 0.01000\tTime 0.061 (0.115)\tData 0.000 (0.030)\tLoss 1.2237 (1.1925)\tPrec@1 47.656 (47.372)\n",
            "Epoch: [19][20/97], lr: 0.01000\tTime 0.073 (0.093)\tData 0.007 (0.017)\tLoss 1.3061 (1.2004)\tPrec@1 40.625 (46.354)\n",
            "Epoch: [19][30/97], lr: 0.01000\tTime 0.066 (0.086)\tData 0.005 (0.012)\tLoss 1.1540 (1.2022)\tPrec@1 50.781 (46.447)\n",
            "Epoch: [19][40/97], lr: 0.01000\tTime 0.065 (0.082)\tData 0.000 (0.010)\tLoss 1.1404 (1.1953)\tPrec@1 53.125 (47.142)\n",
            "Epoch: [19][50/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.006 (0.009)\tLoss 1.1183 (1.1929)\tPrec@1 51.562 (47.181)\n",
            "Epoch: [19][60/97], lr: 0.01000\tTime 0.074 (0.078)\tData 0.005 (0.008)\tLoss 1.1270 (1.1910)\tPrec@1 49.219 (47.400)\n",
            "Epoch: [19][70/97], lr: 0.01000\tTime 0.110 (0.080)\tData 0.003 (0.007)\tLoss 1.2043 (1.1888)\tPrec@1 42.969 (47.392)\n",
            "Epoch: [19][80/97], lr: 0.01000\tTime 0.084 (0.080)\tData 0.002 (0.007)\tLoss 1.0694 (1.1856)\tPrec@1 59.375 (47.685)\n",
            "Epoch: [19][90/97], lr: 0.01000\tTime 0.052 (0.080)\tData 0.000 (0.006)\tLoss 1.2372 (1.1837)\tPrec@1 45.312 (47.828)\n",
            "Test: [0/100]\tTime 0.386 (0.386)\tLoss 1.0833 (1.0833)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.025 (0.069)\tLoss 1.2264 (1.1843)\tPrec@1 43.000 (47.455)\n",
            "Test: [20/100]\tTime 0.021 (0.054)\tLoss 1.2700 (1.1932)\tPrec@1 39.000 (45.381)\n",
            "Test: [30/100]\tTime 0.022 (0.046)\tLoss 1.2770 (1.2091)\tPrec@1 48.000 (44.871)\n",
            "Test: [40/100]\tTime 0.022 (0.042)\tLoss 1.3019 (1.2063)\tPrec@1 44.000 (45.561)\n",
            "Test: [50/100]\tTime 0.040 (0.040)\tLoss 1.1466 (1.2074)\tPrec@1 53.000 (45.588)\n",
            "Test: [60/100]\tTime 0.029 (0.039)\tLoss 1.2640 (1.2109)\tPrec@1 42.000 (45.607)\n",
            "Test: [70/100]\tTime 0.022 (0.038)\tLoss 1.1681 (1.2076)\tPrec@1 51.000 (45.746)\n",
            "Test: [80/100]\tTime 0.033 (0.037)\tLoss 1.2364 (1.2073)\tPrec@1 40.000 (45.568)\n",
            "Test: [90/100]\tTime 0.022 (0.037)\tLoss 1.2675 (1.2051)\tPrec@1 45.000 (45.714)\n",
            "val Results: Prec@1 45.880 Loss 1.20301\n",
            "Best Prec@1: 45.880\n",
            "\n",
            "Epoch: [20][0/97], lr: 0.01000\tTime 0.533 (0.533)\tData 0.347 (0.347)\tLoss 1.1363 (1.1363)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [20][10/97], lr: 0.01000\tTime 0.072 (0.114)\tData 0.000 (0.033)\tLoss 1.1267 (1.1817)\tPrec@1 49.219 (45.810)\n",
            "Epoch: [20][20/97], lr: 0.01000\tTime 0.062 (0.092)\tData 0.000 (0.019)\tLoss 1.2939 (1.1909)\tPrec@1 39.062 (46.429)\n",
            "Epoch: [20][30/97], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.014)\tLoss 1.1326 (1.1868)\tPrec@1 46.875 (47.102)\n",
            "Epoch: [20][40/97], lr: 0.01000\tTime 0.082 (0.082)\tData 0.007 (0.012)\tLoss 1.0669 (1.1822)\tPrec@1 53.125 (47.637)\n",
            "Epoch: [20][50/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.010)\tLoss 1.1805 (1.1842)\tPrec@1 50.000 (47.748)\n",
            "Epoch: [20][60/97], lr: 0.01000\tTime 0.060 (0.078)\tData 0.000 (0.009)\tLoss 1.1701 (1.1863)\tPrec@1 50.781 (47.759)\n",
            "Epoch: [20][70/97], lr: 0.01000\tTime 0.146 (0.079)\tData 0.001 (0.008)\tLoss 1.2035 (1.1816)\tPrec@1 42.188 (48.085)\n",
            "Epoch: [20][80/97], lr: 0.01000\tTime 0.069 (0.079)\tData 0.000 (0.007)\tLoss 1.1451 (1.1810)\tPrec@1 50.000 (48.119)\n",
            "Epoch: [20][90/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.007)\tLoss 1.1468 (1.1793)\tPrec@1 49.219 (48.223)\n",
            "Test: [0/100]\tTime 0.372 (0.372)\tLoss 1.0189 (1.0189)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.023 (0.065)\tLoss 1.2522 (1.1876)\tPrec@1 42.000 (47.000)\n",
            "Test: [20/100]\tTime 0.021 (0.051)\tLoss 1.3672 (1.1951)\tPrec@1 41.000 (46.381)\n",
            "Test: [30/100]\tTime 0.047 (0.046)\tLoss 1.2279 (1.2114)\tPrec@1 45.000 (45.548)\n",
            "Test: [40/100]\tTime 0.028 (0.043)\tLoss 1.2456 (1.2056)\tPrec@1 41.000 (45.805)\n",
            "Test: [50/100]\tTime 0.028 (0.042)\tLoss 1.1880 (1.2052)\tPrec@1 48.000 (46.137)\n",
            "Test: [60/100]\tTime 0.023 (0.040)\tLoss 1.2390 (1.2100)\tPrec@1 43.000 (46.033)\n",
            "Test: [70/100]\tTime 0.056 (0.039)\tLoss 1.1703 (1.2098)\tPrec@1 50.000 (46.239)\n",
            "Test: [80/100]\tTime 0.032 (0.038)\tLoss 1.2565 (1.2124)\tPrec@1 43.000 (45.926)\n",
            "Test: [90/100]\tTime 0.021 (0.037)\tLoss 1.3074 (1.2099)\tPrec@1 41.000 (46.132)\n",
            "val Results: Prec@1 46.110 Loss 1.20953\n",
            "Best Prec@1: 46.110\n",
            "\n",
            "Epoch: [21][0/97], lr: 0.01000\tTime 0.494 (0.494)\tData 0.352 (0.352)\tLoss 1.1405 (1.1405)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [21][10/97], lr: 0.01000\tTime 0.066 (0.114)\tData 0.005 (0.035)\tLoss 1.1213 (1.1698)\tPrec@1 57.031 (48.722)\n",
            "Epoch: [21][20/97], lr: 0.01000\tTime 0.068 (0.092)\tData 0.000 (0.019)\tLoss 1.2458 (1.1755)\tPrec@1 46.094 (48.624)\n",
            "Epoch: [21][30/97], lr: 0.01000\tTime 0.066 (0.085)\tData 0.000 (0.013)\tLoss 1.2389 (1.1801)\tPrec@1 44.531 (48.286)\n",
            "Epoch: [21][40/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.010)\tLoss 1.0405 (1.1691)\tPrec@1 57.031 (49.009)\n",
            "Epoch: [21][50/97], lr: 0.01000\tTime 0.061 (0.078)\tData 0.000 (0.009)\tLoss 1.2511 (1.1756)\tPrec@1 44.531 (48.866)\n",
            "Epoch: [21][60/97], lr: 0.01000\tTime 0.064 (0.077)\tData 0.000 (0.007)\tLoss 1.1012 (1.1738)\tPrec@1 51.562 (48.706)\n",
            "Epoch: [21][70/97], lr: 0.01000\tTime 0.091 (0.076)\tData 0.010 (0.007)\tLoss 1.1366 (1.1720)\tPrec@1 49.219 (48.636)\n",
            "Epoch: [21][80/97], lr: 0.01000\tTime 0.074 (0.075)\tData 0.000 (0.006)\tLoss 1.0564 (1.1699)\tPrec@1 60.938 (48.727)\n",
            "Epoch: [21][90/97], lr: 0.01000\tTime 0.055 (0.074)\tData 0.000 (0.006)\tLoss 1.1174 (1.1660)\tPrec@1 48.438 (48.867)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 1.0704 (1.0704)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.063 (0.072)\tLoss 1.3024 (1.2066)\tPrec@1 43.000 (47.182)\n",
            "Test: [20/100]\tTime 0.041 (0.054)\tLoss 1.3779 (1.2099)\tPrec@1 39.000 (45.429)\n",
            "Test: [30/100]\tTime 0.027 (0.048)\tLoss 1.2938 (1.2194)\tPrec@1 44.000 (45.290)\n",
            "Test: [40/100]\tTime 0.045 (0.045)\tLoss 1.2392 (1.2147)\tPrec@1 45.000 (45.439)\n",
            "Test: [50/100]\tTime 0.024 (0.043)\tLoss 1.1743 (1.2150)\tPrec@1 47.000 (45.686)\n",
            "Test: [60/100]\tTime 0.029 (0.041)\tLoss 1.2060 (1.2158)\tPrec@1 47.000 (45.689)\n",
            "Test: [70/100]\tTime 0.056 (0.040)\tLoss 1.1186 (1.2128)\tPrec@1 50.000 (45.803)\n",
            "Test: [80/100]\tTime 0.032 (0.040)\tLoss 1.1642 (1.2143)\tPrec@1 47.000 (45.630)\n",
            "Test: [90/100]\tTime 0.041 (0.040)\tLoss 1.2679 (1.2098)\tPrec@1 48.000 (45.978)\n",
            "val Results: Prec@1 45.930 Loss 1.20941\n",
            "Best Prec@1: 46.110\n",
            "\n",
            "Epoch: [22][0/97], lr: 0.01000\tTime 0.586 (0.586)\tData 0.437 (0.437)\tLoss 1.2367 (1.2367)\tPrec@1 46.094 (46.094)\n",
            "Epoch: [22][10/97], lr: 0.01000\tTime 0.062 (0.116)\tData 0.000 (0.043)\tLoss 1.2073 (1.1735)\tPrec@1 50.000 (49.645)\n",
            "Epoch: [22][20/97], lr: 0.01000\tTime 0.061 (0.095)\tData 0.000 (0.023)\tLoss 1.2397 (1.1790)\tPrec@1 46.094 (48.251)\n",
            "Epoch: [22][30/97], lr: 0.01000\tTime 0.077 (0.092)\tData 0.001 (0.016)\tLoss 1.0990 (1.1626)\tPrec@1 53.125 (49.042)\n",
            "Epoch: [22][40/97], lr: 0.01000\tTime 0.062 (0.089)\tData 0.000 (0.013)\tLoss 1.2060 (1.1671)\tPrec@1 44.531 (48.323)\n",
            "Epoch: [22][50/97], lr: 0.01000\tTime 0.111 (0.089)\tData 0.010 (0.011)\tLoss 1.1509 (1.1641)\tPrec@1 54.688 (48.698)\n",
            "Epoch: [22][60/97], lr: 0.01000\tTime 0.062 (0.088)\tData 0.000 (0.010)\tLoss 1.2188 (1.1668)\tPrec@1 44.531 (48.502)\n",
            "Epoch: [22][70/97], lr: 0.01000\tTime 0.061 (0.087)\tData 0.000 (0.008)\tLoss 1.1122 (1.1654)\tPrec@1 46.875 (48.404)\n",
            "Epoch: [22][80/97], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.008)\tLoss 1.1786 (1.1614)\tPrec@1 49.219 (48.621)\n",
            "Epoch: [22][90/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.007)\tLoss 1.1787 (1.1607)\tPrec@1 46.094 (48.807)\n",
            "Test: [0/100]\tTime 0.452 (0.452)\tLoss 1.0591 (1.0591)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.039 (0.075)\tLoss 1.2616 (1.1743)\tPrec@1 41.000 (47.000)\n",
            "Test: [20/100]\tTime 0.026 (0.054)\tLoss 1.3451 (1.1792)\tPrec@1 42.000 (46.714)\n",
            "Test: [30/100]\tTime 0.058 (0.049)\tLoss 1.2406 (1.1912)\tPrec@1 43.000 (45.839)\n",
            "Test: [40/100]\tTime 0.055 (0.047)\tLoss 1.2356 (1.1843)\tPrec@1 42.000 (46.220)\n",
            "Test: [50/100]\tTime 0.062 (0.045)\tLoss 1.1357 (1.1853)\tPrec@1 50.000 (46.529)\n",
            "Test: [60/100]\tTime 0.066 (0.043)\tLoss 1.2416 (1.1919)\tPrec@1 43.000 (46.689)\n",
            "Test: [70/100]\tTime 0.024 (0.041)\tLoss 1.1542 (1.1929)\tPrec@1 46.000 (46.521)\n",
            "Test: [80/100]\tTime 0.023 (0.041)\tLoss 1.1464 (1.1941)\tPrec@1 51.000 (46.494)\n",
            "Test: [90/100]\tTime 0.030 (0.040)\tLoss 1.3031 (1.1923)\tPrec@1 46.000 (46.857)\n",
            "val Results: Prec@1 46.930 Loss 1.19206\n",
            "Best Prec@1: 46.930\n",
            "\n",
            "Epoch: [23][0/97], lr: 0.01000\tTime 0.403 (0.403)\tData 0.286 (0.286)\tLoss 1.1017 (1.1017)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [23][10/97], lr: 0.01000\tTime 0.097 (0.118)\tData 0.007 (0.032)\tLoss 1.0991 (1.1514)\tPrec@1 51.562 (49.574)\n",
            "Epoch: [23][20/97], lr: 0.01000\tTime 0.065 (0.096)\tData 0.002 (0.018)\tLoss 1.2330 (1.1698)\tPrec@1 41.406 (48.438)\n",
            "Epoch: [23][30/97], lr: 0.01000\tTime 0.061 (0.087)\tData 0.000 (0.013)\tLoss 1.1345 (1.1643)\tPrec@1 49.219 (48.841)\n",
            "Epoch: [23][40/97], lr: 0.01000\tTime 0.072 (0.083)\tData 0.000 (0.010)\tLoss 1.1098 (1.1630)\tPrec@1 51.562 (49.028)\n",
            "Epoch: [23][50/97], lr: 0.01000\tTime 0.093 (0.081)\tData 0.000 (0.008)\tLoss 1.1208 (1.1620)\tPrec@1 53.125 (48.897)\n",
            "Epoch: [23][60/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.007)\tLoss 1.1769 (1.1632)\tPrec@1 45.312 (48.963)\n",
            "Epoch: [23][70/97], lr: 0.01000\tTime 0.084 (0.078)\tData 0.000 (0.006)\tLoss 1.1744 (1.1611)\tPrec@1 51.562 (49.219)\n",
            "Epoch: [23][80/97], lr: 0.01000\tTime 0.064 (0.077)\tData 0.000 (0.006)\tLoss 1.0818 (1.1579)\tPrec@1 54.688 (49.383)\n",
            "Epoch: [23][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.005)\tLoss 1.0692 (1.1561)\tPrec@1 53.906 (49.382)\n",
            "Test: [0/100]\tTime 0.389 (0.389)\tLoss 1.0443 (1.0443)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.025 (0.069)\tLoss 1.2768 (1.1844)\tPrec@1 33.000 (46.455)\n",
            "Test: [20/100]\tTime 0.035 (0.055)\tLoss 1.2787 (1.1749)\tPrec@1 37.000 (47.095)\n",
            "Test: [30/100]\tTime 0.026 (0.049)\tLoss 1.2366 (1.1805)\tPrec@1 45.000 (46.968)\n",
            "Test: [40/100]\tTime 0.040 (0.046)\tLoss 1.2195 (1.1787)\tPrec@1 42.000 (47.024)\n",
            "Test: [50/100]\tTime 0.022 (0.045)\tLoss 1.1730 (1.1821)\tPrec@1 52.000 (47.020)\n",
            "Test: [60/100]\tTime 0.023 (0.043)\tLoss 1.2462 (1.1856)\tPrec@1 37.000 (47.164)\n",
            "Test: [70/100]\tTime 0.028 (0.042)\tLoss 1.1339 (1.1847)\tPrec@1 51.000 (47.310)\n",
            "Test: [80/100]\tTime 0.037 (0.041)\tLoss 1.1719 (1.1855)\tPrec@1 47.000 (47.123)\n",
            "Test: [90/100]\tTime 0.035 (0.040)\tLoss 1.2737 (1.1855)\tPrec@1 45.000 (47.352)\n",
            "val Results: Prec@1 47.420 Loss 1.18413\n",
            "Best Prec@1: 47.420\n",
            "\n",
            "Epoch: [24][0/97], lr: 0.01000\tTime 0.538 (0.538)\tData 0.421 (0.421)\tLoss 1.1765 (1.1765)\tPrec@1 42.188 (42.188)\n",
            "Epoch: [24][10/97], lr: 0.01000\tTime 0.071 (0.119)\tData 0.000 (0.040)\tLoss 1.1389 (1.1183)\tPrec@1 49.219 (51.491)\n",
            "Epoch: [24][20/97], lr: 0.01000\tTime 0.059 (0.095)\tData 0.000 (0.022)\tLoss 1.0981 (1.1272)\tPrec@1 55.469 (50.967)\n",
            "Epoch: [24][30/97], lr: 0.01000\tTime 0.095 (0.089)\tData 0.013 (0.015)\tLoss 1.2067 (1.1413)\tPrec@1 41.406 (50.227)\n",
            "Epoch: [24][40/97], lr: 0.01000\tTime 0.075 (0.084)\tData 0.000 (0.012)\tLoss 1.1755 (1.1411)\tPrec@1 46.875 (50.305)\n",
            "Epoch: [24][50/97], lr: 0.01000\tTime 0.066 (0.082)\tData 0.000 (0.010)\tLoss 1.1280 (1.1492)\tPrec@1 53.906 (49.908)\n",
            "Epoch: [24][60/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.009)\tLoss 1.0948 (1.1507)\tPrec@1 53.906 (49.962)\n",
            "Epoch: [24][70/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.008 (0.008)\tLoss 1.1025 (1.1508)\tPrec@1 47.656 (49.956)\n",
            "Epoch: [24][80/97], lr: 0.01000\tTime 0.083 (0.079)\tData 0.012 (0.008)\tLoss 1.1913 (1.1498)\tPrec@1 50.000 (49.701)\n",
            "Epoch: [24][90/97], lr: 0.01000\tTime 0.051 (0.078)\tData 0.000 (0.007)\tLoss 1.1201 (1.1493)\tPrec@1 50.781 (49.854)\n",
            "Test: [0/100]\tTime 0.261 (0.261)\tLoss 1.0108 (1.0108)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.032 (0.060)\tLoss 1.3145 (1.1771)\tPrec@1 36.000 (47.909)\n",
            "Test: [20/100]\tTime 0.030 (0.047)\tLoss 1.2920 (1.1728)\tPrec@1 43.000 (48.381)\n",
            "Test: [30/100]\tTime 0.044 (0.042)\tLoss 1.2092 (1.1807)\tPrec@1 46.000 (47.806)\n",
            "Test: [40/100]\tTime 0.052 (0.043)\tLoss 1.1670 (1.1729)\tPrec@1 49.000 (47.927)\n",
            "Test: [50/100]\tTime 0.027 (0.043)\tLoss 1.1447 (1.1775)\tPrec@1 57.000 (47.784)\n",
            "Test: [60/100]\tTime 0.041 (0.042)\tLoss 1.2653 (1.1840)\tPrec@1 46.000 (47.557)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.1545 (1.1828)\tPrec@1 45.000 (47.366)\n",
            "Test: [80/100]\tTime 0.054 (0.041)\tLoss 1.1583 (1.1819)\tPrec@1 48.000 (47.420)\n",
            "Test: [90/100]\tTime 0.057 (0.040)\tLoss 1.2551 (1.1793)\tPrec@1 47.000 (47.670)\n",
            "val Results: Prec@1 47.670 Loss 1.17891\n",
            "Best Prec@1: 47.670\n",
            "\n",
            "Epoch: [25][0/97], lr: 0.01000\tTime 0.518 (0.518)\tData 0.367 (0.367)\tLoss 1.1292 (1.1292)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [25][10/97], lr: 0.01000\tTime 0.081 (0.115)\tData 0.007 (0.036)\tLoss 1.2060 (1.1675)\tPrec@1 42.969 (48.224)\n",
            "Epoch: [25][20/97], lr: 0.01000\tTime 0.071 (0.095)\tData 0.000 (0.021)\tLoss 1.1076 (1.1588)\tPrec@1 55.469 (48.661)\n",
            "Epoch: [25][30/97], lr: 0.01000\tTime 0.067 (0.086)\tData 0.000 (0.015)\tLoss 1.1849 (1.1544)\tPrec@1 42.188 (49.219)\n",
            "Epoch: [25][40/97], lr: 0.01000\tTime 0.072 (0.082)\tData 0.000 (0.012)\tLoss 1.1441 (1.1487)\tPrec@1 47.656 (49.505)\n",
            "Epoch: [25][50/97], lr: 0.01000\tTime 0.061 (0.081)\tData 0.000 (0.010)\tLoss 1.1428 (1.1471)\tPrec@1 42.969 (49.387)\n",
            "Epoch: [25][60/97], lr: 0.01000\tTime 0.073 (0.079)\tData 0.006 (0.009)\tLoss 1.1060 (1.1437)\tPrec@1 47.656 (49.603)\n",
            "Epoch: [25][70/97], lr: 0.01000\tTime 0.084 (0.078)\tData 0.014 (0.008)\tLoss 1.1188 (1.1404)\tPrec@1 50.781 (49.846)\n",
            "Epoch: [25][80/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.007)\tLoss 1.1902 (1.1361)\tPrec@1 48.438 (50.154)\n",
            "Epoch: [25][90/97], lr: 0.01000\tTime 0.054 (0.079)\tData 0.000 (0.007)\tLoss 1.2119 (1.1397)\tPrec@1 43.750 (50.000)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 1.0518 (1.0518)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.043 (0.068)\tLoss 1.2619 (1.1830)\tPrec@1 38.000 (47.364)\n",
            "Test: [20/100]\tTime 0.042 (0.053)\tLoss 1.3047 (1.1843)\tPrec@1 38.000 (47.048)\n",
            "Test: [30/100]\tTime 0.032 (0.047)\tLoss 1.1914 (1.1921)\tPrec@1 46.000 (46.387)\n",
            "Test: [40/100]\tTime 0.045 (0.044)\tLoss 1.1814 (1.1873)\tPrec@1 48.000 (47.000)\n",
            "Test: [50/100]\tTime 0.026 (0.042)\tLoss 1.1993 (1.1911)\tPrec@1 51.000 (46.804)\n",
            "Test: [60/100]\tTime 0.036 (0.041)\tLoss 1.2835 (1.1965)\tPrec@1 38.000 (46.525)\n",
            "Test: [70/100]\tTime 0.037 (0.040)\tLoss 1.1569 (1.1954)\tPrec@1 48.000 (46.479)\n",
            "Test: [80/100]\tTime 0.024 (0.039)\tLoss 1.1971 (1.1939)\tPrec@1 45.000 (46.346)\n",
            "Test: [90/100]\tTime 0.026 (0.038)\tLoss 1.2336 (1.1927)\tPrec@1 50.000 (46.582)\n",
            "val Results: Prec@1 46.720 Loss 1.19205\n",
            "Best Prec@1: 47.670\n",
            "\n",
            "Epoch: [26][0/97], lr: 0.01000\tTime 0.476 (0.476)\tData 0.286 (0.286)\tLoss 1.1132 (1.1132)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [26][10/97], lr: 0.01000\tTime 0.082 (0.112)\tData 0.000 (0.028)\tLoss 1.0620 (1.1391)\tPrec@1 50.781 (48.935)\n",
            "Epoch: [26][20/97], lr: 0.01000\tTime 0.079 (0.092)\tData 0.007 (0.016)\tLoss 1.2356 (1.1471)\tPrec@1 46.094 (48.698)\n",
            "Epoch: [26][30/97], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.011)\tLoss 1.1537 (1.1519)\tPrec@1 50.000 (49.042)\n",
            "Epoch: [26][40/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.009)\tLoss 1.0626 (1.1404)\tPrec@1 53.906 (49.962)\n",
            "Epoch: [26][50/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.007)\tLoss 1.0578 (1.1374)\tPrec@1 54.688 (50.306)\n",
            "Epoch: [26][60/97], lr: 0.01000\tTime 0.068 (0.077)\tData 0.006 (0.006)\tLoss 1.1827 (1.1367)\tPrec@1 50.781 (50.768)\n",
            "Epoch: [26][70/97], lr: 0.01000\tTime 0.066 (0.076)\tData 0.000 (0.006)\tLoss 1.1590 (1.1367)\tPrec@1 50.000 (50.836)\n",
            "Epoch: [26][80/97], lr: 0.01000\tTime 0.077 (0.075)\tData 0.015 (0.006)\tLoss 1.1124 (1.1376)\tPrec@1 50.781 (50.868)\n",
            "Epoch: [26][90/97], lr: 0.01000\tTime 0.054 (0.074)\tData 0.000 (0.005)\tLoss 1.0543 (1.1331)\tPrec@1 54.688 (51.039)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 0.9946 (0.9946)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.030 (0.058)\tLoss 1.2256 (1.1465)\tPrec@1 45.000 (50.273)\n",
            "Test: [20/100]\tTime 0.024 (0.045)\tLoss 1.2949 (1.1542)\tPrec@1 41.000 (49.762)\n",
            "Test: [30/100]\tTime 0.032 (0.041)\tLoss 1.2571 (1.1637)\tPrec@1 49.000 (49.000)\n",
            "Test: [40/100]\tTime 0.040 (0.039)\tLoss 1.1475 (1.1569)\tPrec@1 49.000 (49.390)\n",
            "Test: [50/100]\tTime 0.044 (0.039)\tLoss 1.1988 (1.1642)\tPrec@1 53.000 (49.725)\n",
            "Test: [60/100]\tTime 0.023 (0.039)\tLoss 1.2500 (1.1702)\tPrec@1 38.000 (49.049)\n",
            "Test: [70/100]\tTime 0.038 (0.038)\tLoss 1.1263 (1.1706)\tPrec@1 52.000 (48.930)\n",
            "Test: [80/100]\tTime 0.032 (0.038)\tLoss 1.1442 (1.1698)\tPrec@1 49.000 (48.728)\n",
            "Test: [90/100]\tTime 0.023 (0.038)\tLoss 1.2513 (1.1676)\tPrec@1 48.000 (48.912)\n",
            "val Results: Prec@1 48.930 Loss 1.16547\n",
            "Best Prec@1: 48.930\n",
            "\n",
            "Epoch: [27][0/97], lr: 0.01000\tTime 0.543 (0.543)\tData 0.384 (0.384)\tLoss 1.1283 (1.1283)\tPrec@1 49.219 (49.219)\n",
            "Epoch: [27][10/97], lr: 0.01000\tTime 0.059 (0.114)\tData 0.000 (0.037)\tLoss 1.0567 (1.1348)\tPrec@1 50.781 (50.284)\n",
            "Epoch: [27][20/97], lr: 0.01000\tTime 0.087 (0.093)\tData 0.000 (0.020)\tLoss 1.2257 (1.1336)\tPrec@1 46.094 (50.186)\n",
            "Epoch: [27][30/97], lr: 0.01000\tTime 0.066 (0.087)\tData 0.000 (0.014)\tLoss 1.1299 (1.1284)\tPrec@1 52.344 (50.806)\n",
            "Epoch: [27][40/97], lr: 0.01000\tTime 0.063 (0.084)\tData 0.000 (0.011)\tLoss 1.0837 (1.1327)\tPrec@1 50.000 (50.495)\n",
            "Epoch: [27][50/97], lr: 0.01000\tTime 0.075 (0.081)\tData 0.000 (0.009)\tLoss 1.0839 (1.1367)\tPrec@1 54.688 (50.567)\n",
            "Epoch: [27][60/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.003 (0.008)\tLoss 1.1643 (1.1344)\tPrec@1 53.906 (50.551)\n",
            "Epoch: [27][70/97], lr: 0.01000\tTime 0.075 (0.079)\tData 0.010 (0.007)\tLoss 1.0770 (1.1330)\tPrec@1 54.688 (50.737)\n",
            "Epoch: [27][80/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.007)\tLoss 1.1399 (1.1325)\tPrec@1 47.656 (50.598)\n",
            "Epoch: [27][90/97], lr: 0.01000\tTime 0.057 (0.079)\tData 0.000 (0.006)\tLoss 1.1830 (1.1323)\tPrec@1 48.438 (50.541)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 1.0190 (1.0190)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.034 (0.065)\tLoss 1.2615 (1.1662)\tPrec@1 37.000 (48.000)\n",
            "Test: [20/100]\tTime 0.029 (0.052)\tLoss 1.2305 (1.1660)\tPrec@1 43.000 (48.190)\n",
            "Test: [30/100]\tTime 0.045 (0.046)\tLoss 1.2174 (1.1713)\tPrec@1 46.000 (47.806)\n",
            "Test: [40/100]\tTime 0.042 (0.045)\tLoss 1.1731 (1.1649)\tPrec@1 46.000 (47.951)\n",
            "Test: [50/100]\tTime 0.030 (0.043)\tLoss 1.1669 (1.1663)\tPrec@1 45.000 (47.902)\n",
            "Test: [60/100]\tTime 0.023 (0.042)\tLoss 1.2519 (1.1703)\tPrec@1 44.000 (47.967)\n",
            "Test: [70/100]\tTime 0.036 (0.041)\tLoss 1.1380 (1.1684)\tPrec@1 52.000 (47.972)\n",
            "Test: [80/100]\tTime 0.031 (0.040)\tLoss 1.1742 (1.1684)\tPrec@1 45.000 (47.864)\n",
            "Test: [90/100]\tTime 0.034 (0.039)\tLoss 1.2848 (1.1667)\tPrec@1 44.000 (48.088)\n",
            "val Results: Prec@1 48.130 Loss 1.16485\n",
            "Best Prec@1: 48.930\n",
            "\n",
            "Epoch: [28][0/97], lr: 0.01000\tTime 0.547 (0.547)\tData 0.401 (0.401)\tLoss 1.1365 (1.1365)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [28][10/97], lr: 0.01000\tTime 0.066 (0.135)\tData 0.000 (0.039)\tLoss 1.0760 (1.0915)\tPrec@1 54.688 (53.693)\n",
            "Epoch: [28][20/97], lr: 0.01000\tTime 0.084 (0.108)\tData 0.000 (0.022)\tLoss 1.0552 (1.1032)\tPrec@1 50.781 (52.307)\n",
            "Epoch: [28][30/97], lr: 0.01000\tTime 0.083 (0.100)\tData 0.006 (0.016)\tLoss 1.2216 (1.1199)\tPrec@1 46.875 (51.840)\n",
            "Epoch: [28][40/97], lr: 0.01000\tTime 0.080 (0.095)\tData 0.011 (0.014)\tLoss 1.1383 (1.1154)\tPrec@1 51.562 (51.886)\n",
            "Epoch: [28][50/97], lr: 0.01000\tTime 0.079 (0.092)\tData 0.000 (0.012)\tLoss 1.1283 (1.1171)\tPrec@1 46.094 (51.762)\n",
            "Epoch: [28][60/97], lr: 0.01000\tTime 0.072 (0.088)\tData 0.004 (0.011)\tLoss 1.1195 (1.1190)\tPrec@1 47.656 (51.614)\n",
            "Epoch: [28][70/97], lr: 0.01000\tTime 0.067 (0.086)\tData 0.005 (0.010)\tLoss 1.1020 (1.1163)\tPrec@1 56.250 (51.728)\n",
            "Epoch: [28][80/97], lr: 0.01000\tTime 0.125 (0.085)\tData 0.000 (0.009)\tLoss 1.1239 (1.1154)\tPrec@1 53.125 (51.698)\n",
            "Epoch: [28][90/97], lr: 0.01000\tTime 0.049 (0.085)\tData 0.000 (0.008)\tLoss 1.1135 (1.1155)\tPrec@1 52.344 (51.640)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 1.0298 (1.0298)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.031 (0.067)\tLoss 1.3060 (1.1763)\tPrec@1 38.000 (47.273)\n",
            "Test: [20/100]\tTime 0.024 (0.053)\tLoss 1.2307 (1.1584)\tPrec@1 40.000 (49.238)\n",
            "Test: [30/100]\tTime 0.031 (0.049)\tLoss 1.1821 (1.1661)\tPrec@1 47.000 (48.355)\n",
            "Test: [40/100]\tTime 0.043 (0.046)\tLoss 1.1611 (1.1593)\tPrec@1 47.000 (49.122)\n",
            "Test: [50/100]\tTime 0.027 (0.044)\tLoss 1.1029 (1.1603)\tPrec@1 61.000 (49.353)\n",
            "Test: [60/100]\tTime 0.040 (0.043)\tLoss 1.1946 (1.1629)\tPrec@1 48.000 (49.279)\n",
            "Test: [70/100]\tTime 0.024 (0.042)\tLoss 1.0869 (1.1603)\tPrec@1 51.000 (49.183)\n",
            "Test: [80/100]\tTime 0.025 (0.041)\tLoss 1.1769 (1.1599)\tPrec@1 44.000 (48.988)\n",
            "Test: [90/100]\tTime 0.034 (0.040)\tLoss 1.2627 (1.1568)\tPrec@1 42.000 (48.978)\n",
            "val Results: Prec@1 49.010 Loss 1.15565\n",
            "Best Prec@1: 49.010\n",
            "\n",
            "Epoch: [29][0/97], lr: 0.01000\tTime 0.503 (0.503)\tData 0.294 (0.294)\tLoss 1.0761 (1.0761)\tPrec@1 50.000 (50.000)\n",
            "Epoch: [29][10/97], lr: 0.01000\tTime 0.065 (0.114)\tData 0.000 (0.028)\tLoss 1.0835 (1.1117)\tPrec@1 55.469 (52.557)\n",
            "Epoch: [29][20/97], lr: 0.01000\tTime 0.068 (0.095)\tData 0.000 (0.015)\tLoss 1.1143 (1.1092)\tPrec@1 51.562 (52.455)\n",
            "Epoch: [29][30/97], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.011)\tLoss 1.1789 (1.1182)\tPrec@1 51.562 (51.638)\n",
            "Epoch: [29][40/97], lr: 0.01000\tTime 0.070 (0.083)\tData 0.000 (0.009)\tLoss 1.1714 (1.1250)\tPrec@1 49.219 (51.220)\n",
            "Epoch: [29][50/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.007)\tLoss 1.0756 (1.1239)\tPrec@1 55.469 (51.455)\n",
            "Epoch: [29][60/97], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.007)\tLoss 1.0907 (1.1167)\tPrec@1 52.344 (51.831)\n",
            "Epoch: [29][70/97], lr: 0.01000\tTime 0.123 (0.079)\tData 0.001 (0.006)\tLoss 1.1562 (1.1198)\tPrec@1 50.000 (51.562)\n",
            "Epoch: [29][80/97], lr: 0.01000\tTime 0.073 (0.080)\tData 0.003 (0.006)\tLoss 1.1020 (1.1159)\tPrec@1 49.219 (51.688)\n",
            "Epoch: [29][90/97], lr: 0.01000\tTime 0.055 (0.080)\tData 0.000 (0.006)\tLoss 1.1694 (1.1147)\tPrec@1 50.781 (51.734)\n",
            "Test: [0/100]\tTime 0.399 (0.399)\tLoss 1.0164 (1.0164)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.034 (0.068)\tLoss 1.2438 (1.1430)\tPrec@1 42.000 (48.000)\n",
            "Test: [20/100]\tTime 0.042 (0.053)\tLoss 1.2437 (1.1429)\tPrec@1 41.000 (48.714)\n",
            "Test: [30/100]\tTime 0.040 (0.047)\tLoss 1.1385 (1.1507)\tPrec@1 54.000 (48.161)\n",
            "Test: [40/100]\tTime 0.034 (0.043)\tLoss 1.1160 (1.1441)\tPrec@1 48.000 (48.951)\n",
            "Test: [50/100]\tTime 0.032 (0.041)\tLoss 1.1397 (1.1450)\tPrec@1 53.000 (49.059)\n",
            "Test: [60/100]\tTime 0.036 (0.040)\tLoss 1.1922 (1.1508)\tPrec@1 44.000 (48.770)\n",
            "Test: [70/100]\tTime 0.039 (0.040)\tLoss 1.1220 (1.1487)\tPrec@1 50.000 (48.901)\n",
            "Test: [80/100]\tTime 0.044 (0.039)\tLoss 1.1504 (1.1461)\tPrec@1 46.000 (48.679)\n",
            "Test: [90/100]\tTime 0.055 (0.038)\tLoss 1.2339 (1.1430)\tPrec@1 45.000 (48.923)\n",
            "val Results: Prec@1 48.980 Loss 1.14102\n",
            "Best Prec@1: 49.010\n",
            "\n",
            "Epoch: [30][0/97], lr: 0.01000\tTime 0.526 (0.526)\tData 0.363 (0.363)\tLoss 1.0685 (1.0685)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [30][10/97], lr: 0.01000\tTime 0.103 (0.135)\tData 0.000 (0.035)\tLoss 1.0668 (1.0893)\tPrec@1 57.031 (51.776)\n",
            "Epoch: [30][20/97], lr: 0.01000\tTime 0.095 (0.111)\tData 0.001 (0.019)\tLoss 1.2328 (1.0978)\tPrec@1 44.531 (51.935)\n",
            "Epoch: [30][30/97], lr: 0.01000\tTime 0.100 (0.101)\tData 0.004 (0.014)\tLoss 1.1570 (1.0919)\tPrec@1 45.312 (51.991)\n",
            "Epoch: [30][40/97], lr: 0.01000\tTime 0.153 (0.108)\tData 0.007 (0.011)\tLoss 0.9651 (1.0938)\tPrec@1 60.938 (52.058)\n",
            "Epoch: [30][50/97], lr: 0.01000\tTime 0.087 (0.107)\tData 0.000 (0.010)\tLoss 1.2391 (1.1055)\tPrec@1 39.844 (51.593)\n",
            "Epoch: [30][60/97], lr: 0.01000\tTime 0.222 (0.111)\tData 0.016 (0.009)\tLoss 1.2120 (1.1068)\tPrec@1 50.000 (51.755)\n",
            "Epoch: [30][70/97], lr: 0.01000\tTime 0.102 (0.111)\tData 0.008 (0.009)\tLoss 1.1529 (1.1043)\tPrec@1 50.000 (51.794)\n",
            "Epoch: [30][80/97], lr: 0.01000\tTime 0.079 (0.107)\tData 0.004 (0.008)\tLoss 1.0898 (1.1014)\tPrec@1 50.000 (52.054)\n",
            "Epoch: [30][90/97], lr: 0.01000\tTime 0.037 (0.104)\tData 0.000 (0.007)\tLoss 1.1362 (1.1032)\tPrec@1 47.656 (51.897)\n",
            "Test: [0/100]\tTime 0.399 (0.399)\tLoss 1.0523 (1.0523)\tPrec@1 50.000 (50.000)\n",
            "Test: [10/100]\tTime 0.036 (0.066)\tLoss 1.2201 (1.1478)\tPrec@1 43.000 (48.000)\n",
            "Test: [20/100]\tTime 0.023 (0.049)\tLoss 1.2028 (1.1402)\tPrec@1 42.000 (49.143)\n",
            "Test: [30/100]\tTime 0.032 (0.044)\tLoss 1.1585 (1.1470)\tPrec@1 52.000 (48.581)\n",
            "Test: [40/100]\tTime 0.030 (0.041)\tLoss 1.0596 (1.1425)\tPrec@1 49.000 (49.073)\n",
            "Test: [50/100]\tTime 0.059 (0.039)\tLoss 1.1061 (1.1415)\tPrec@1 54.000 (49.373)\n",
            "Test: [60/100]\tTime 0.033 (0.038)\tLoss 1.2228 (1.1488)\tPrec@1 48.000 (49.131)\n",
            "Test: [70/100]\tTime 0.023 (0.037)\tLoss 1.1481 (1.1470)\tPrec@1 51.000 (49.338)\n",
            "Test: [80/100]\tTime 0.041 (0.036)\tLoss 1.2106 (1.1466)\tPrec@1 43.000 (49.235)\n",
            "Test: [90/100]\tTime 0.032 (0.036)\tLoss 1.2121 (1.1463)\tPrec@1 46.000 (49.330)\n",
            "val Results: Prec@1 49.450 Loss 1.14422\n",
            "Best Prec@1: 49.450\n",
            "\n",
            "Epoch: [31][0/97], lr: 0.01000\tTime 0.547 (0.547)\tData 0.408 (0.408)\tLoss 1.0217 (1.0217)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [31][10/97], lr: 0.01000\tTime 0.066 (0.116)\tData 0.000 (0.037)\tLoss 1.0649 (1.0906)\tPrec@1 54.688 (51.562)\n",
            "Epoch: [31][20/97], lr: 0.01000\tTime 0.067 (0.094)\tData 0.006 (0.021)\tLoss 1.1533 (1.0912)\tPrec@1 49.219 (52.307)\n",
            "Epoch: [31][30/97], lr: 0.01000\tTime 0.083 (0.087)\tData 0.007 (0.015)\tLoss 1.0219 (1.0942)\tPrec@1 52.344 (52.218)\n",
            "Epoch: [31][40/97], lr: 0.01000\tTime 0.083 (0.083)\tData 0.000 (0.012)\tLoss 1.0484 (1.0931)\tPrec@1 58.594 (52.439)\n",
            "Epoch: [31][50/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.006 (0.010)\tLoss 1.0917 (1.0895)\tPrec@1 54.688 (52.742)\n",
            "Epoch: [31][60/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.009)\tLoss 1.0932 (1.0893)\tPrec@1 53.906 (52.766)\n",
            "Epoch: [31][70/97], lr: 0.01000\tTime 0.078 (0.077)\tData 0.008 (0.008)\tLoss 1.1780 (1.0908)\tPrec@1 44.531 (52.674)\n",
            "Epoch: [31][80/97], lr: 0.01000\tTime 0.084 (0.077)\tData 0.006 (0.008)\tLoss 1.1672 (1.0933)\tPrec@1 50.000 (52.459)\n",
            "Epoch: [31][90/97], lr: 0.01000\tTime 0.055 (0.075)\tData 0.000 (0.007)\tLoss 1.0682 (1.0917)\tPrec@1 56.250 (52.661)\n",
            "Test: [0/100]\tTime 0.255 (0.255)\tLoss 1.0335 (1.0335)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.027 (0.060)\tLoss 1.1891 (1.1330)\tPrec@1 47.000 (49.364)\n",
            "Test: [20/100]\tTime 0.075 (0.050)\tLoss 1.2826 (1.1206)\tPrec@1 44.000 (51.143)\n",
            "Test: [30/100]\tTime 0.041 (0.047)\tLoss 1.1503 (1.1316)\tPrec@1 51.000 (50.032)\n",
            "Test: [40/100]\tTime 0.042 (0.045)\tLoss 1.1197 (1.1256)\tPrec@1 48.000 (50.537)\n",
            "Test: [50/100]\tTime 0.029 (0.043)\tLoss 1.0538 (1.1293)\tPrec@1 53.000 (50.353)\n",
            "Test: [60/100]\tTime 0.040 (0.042)\tLoss 1.2369 (1.1341)\tPrec@1 44.000 (50.377)\n",
            "Test: [70/100]\tTime 0.026 (0.042)\tLoss 1.0864 (1.1338)\tPrec@1 52.000 (50.197)\n",
            "Test: [80/100]\tTime 0.026 (0.041)\tLoss 1.1124 (1.1331)\tPrec@1 54.000 (50.173)\n",
            "Test: [90/100]\tTime 0.025 (0.041)\tLoss 1.2030 (1.1338)\tPrec@1 44.000 (50.198)\n",
            "val Results: Prec@1 50.350 Loss 1.13296\n",
            "Best Prec@1: 50.350\n",
            "\n",
            "Epoch: [32][0/97], lr: 0.01000\tTime 0.492 (0.492)\tData 0.310 (0.310)\tLoss 1.1121 (1.1121)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [32][10/97], lr: 0.01000\tTime 0.063 (0.117)\tData 0.000 (0.031)\tLoss 1.0066 (1.0719)\tPrec@1 57.812 (53.835)\n",
            "Epoch: [32][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.018)\tLoss 1.2449 (1.0965)\tPrec@1 42.969 (52.455)\n",
            "Epoch: [32][30/97], lr: 0.01000\tTime 0.066 (0.087)\tData 0.000 (0.013)\tLoss 1.0449 (1.0917)\tPrec@1 56.250 (52.697)\n",
            "Epoch: [32][40/97], lr: 0.01000\tTime 0.067 (0.083)\tData 0.005 (0.011)\tLoss 1.0766 (1.0865)\tPrec@1 59.375 (53.049)\n",
            "Epoch: [32][50/97], lr: 0.01000\tTime 0.078 (0.081)\tData 0.007 (0.010)\tLoss 1.0863 (1.0820)\tPrec@1 55.469 (53.523)\n",
            "Epoch: [32][60/97], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.009)\tLoss 0.9739 (1.0793)\tPrec@1 56.250 (53.548)\n",
            "Epoch: [32][70/97], lr: 0.01000\tTime 0.092 (0.081)\tData 0.000 (0.008)\tLoss 1.1383 (1.0753)\tPrec@1 47.656 (53.587)\n",
            "Epoch: [32][80/97], lr: 0.01000\tTime 0.086 (0.081)\tData 0.000 (0.007)\tLoss 1.0068 (1.0796)\tPrec@1 62.500 (53.530)\n",
            "Epoch: [32][90/97], lr: 0.01000\tTime 0.052 (0.081)\tData 0.000 (0.007)\tLoss 0.9927 (1.0781)\tPrec@1 60.156 (53.589)\n",
            "Test: [0/100]\tTime 0.370 (0.370)\tLoss 1.0439 (1.0439)\tPrec@1 49.000 (49.000)\n",
            "Test: [10/100]\tTime 0.030 (0.067)\tLoss 1.2016 (1.1253)\tPrec@1 43.000 (48.273)\n",
            "Test: [20/100]\tTime 0.026 (0.052)\tLoss 1.2402 (1.1297)\tPrec@1 40.000 (49.381)\n",
            "Test: [30/100]\tTime 0.025 (0.047)\tLoss 1.1385 (1.1331)\tPrec@1 51.000 (49.613)\n",
            "Test: [40/100]\tTime 0.051 (0.045)\tLoss 1.1367 (1.1239)\tPrec@1 51.000 (50.634)\n",
            "Test: [50/100]\tTime 0.044 (0.042)\tLoss 1.1095 (1.1251)\tPrec@1 50.000 (50.471)\n",
            "Test: [60/100]\tTime 0.032 (0.040)\tLoss 1.1903 (1.1320)\tPrec@1 41.000 (50.098)\n",
            "Test: [70/100]\tTime 0.032 (0.039)\tLoss 1.0951 (1.1280)\tPrec@1 57.000 (50.296)\n",
            "Test: [80/100]\tTime 0.024 (0.038)\tLoss 1.1369 (1.1271)\tPrec@1 47.000 (50.123)\n",
            "Test: [90/100]\tTime 0.021 (0.038)\tLoss 1.2231 (1.1262)\tPrec@1 48.000 (50.176)\n",
            "val Results: Prec@1 50.310 Loss 1.12528\n",
            "Best Prec@1: 50.350\n",
            "\n",
            "Epoch: [33][0/97], lr: 0.01000\tTime 0.692 (0.692)\tData 0.465 (0.465)\tLoss 1.0788 (1.0788)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [33][10/97], lr: 0.01000\tTime 0.064 (0.140)\tData 0.000 (0.045)\tLoss 1.0500 (1.0543)\tPrec@1 55.469 (56.037)\n",
            "Epoch: [33][20/97], lr: 0.01000\tTime 0.083 (0.115)\tData 0.000 (0.024)\tLoss 1.1657 (1.0561)\tPrec@1 49.219 (55.394)\n",
            "Epoch: [33][30/97], lr: 0.01000\tTime 0.083 (0.105)\tData 0.017 (0.018)\tLoss 1.1150 (1.0692)\tPrec@1 56.250 (54.864)\n",
            "Epoch: [33][40/97], lr: 0.01000\tTime 0.064 (0.099)\tData 0.000 (0.014)\tLoss 0.9746 (1.0667)\tPrec@1 63.281 (54.821)\n",
            "Epoch: [33][50/97], lr: 0.01000\tTime 0.082 (0.093)\tData 0.000 (0.011)\tLoss 1.0621 (1.0678)\tPrec@1 56.250 (54.366)\n",
            "Epoch: [33][60/97], lr: 0.01000\tTime 0.100 (0.090)\tData 0.007 (0.010)\tLoss 1.1311 (1.0768)\tPrec@1 52.344 (53.727)\n",
            "Epoch: [33][70/97], lr: 0.01000\tTime 0.095 (0.088)\tData 0.000 (0.009)\tLoss 1.1068 (1.0774)\tPrec@1 47.656 (53.807)\n",
            "Epoch: [33][80/97], lr: 0.01000\tTime 0.077 (0.088)\tData 0.014 (0.008)\tLoss 1.1519 (1.0727)\tPrec@1 53.125 (54.080)\n",
            "Epoch: [33][90/97], lr: 0.01000\tTime 0.037 (0.087)\tData 0.000 (0.008)\tLoss 1.1549 (1.0760)\tPrec@1 46.875 (53.872)\n",
            "Test: [0/100]\tTime 0.370 (0.370)\tLoss 1.0125 (1.0125)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.045 (0.071)\tLoss 1.2429 (1.1487)\tPrec@1 44.000 (49.091)\n",
            "Test: [20/100]\tTime 0.031 (0.055)\tLoss 1.2558 (1.1380)\tPrec@1 37.000 (49.571)\n",
            "Test: [30/100]\tTime 0.035 (0.050)\tLoss 1.1538 (1.1498)\tPrec@1 49.000 (49.355)\n",
            "Test: [40/100]\tTime 0.023 (0.046)\tLoss 1.1101 (1.1432)\tPrec@1 51.000 (49.732)\n",
            "Test: [50/100]\tTime 0.023 (0.043)\tLoss 1.1240 (1.1453)\tPrec@1 54.000 (49.627)\n",
            "Test: [60/100]\tTime 0.032 (0.042)\tLoss 1.2438 (1.1493)\tPrec@1 43.000 (49.508)\n",
            "Test: [70/100]\tTime 0.035 (0.040)\tLoss 1.0663 (1.1454)\tPrec@1 51.000 (49.465)\n",
            "Test: [80/100]\tTime 0.037 (0.039)\tLoss 1.1264 (1.1435)\tPrec@1 52.000 (49.383)\n",
            "Test: [90/100]\tTime 0.023 (0.038)\tLoss 1.1781 (1.1435)\tPrec@1 46.000 (49.451)\n",
            "val Results: Prec@1 49.500 Loss 1.14143\n",
            "Best Prec@1: 50.350\n",
            "\n",
            "Epoch: [34][0/97], lr: 0.01000\tTime 0.526 (0.526)\tData 0.361 (0.361)\tLoss 1.0165 (1.0165)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [34][10/97], lr: 0.01000\tTime 0.070 (0.115)\tData 0.007 (0.039)\tLoss 1.0787 (1.0462)\tPrec@1 51.562 (55.753)\n",
            "Epoch: [34][20/97], lr: 0.01000\tTime 0.068 (0.093)\tData 0.000 (0.021)\tLoss 1.0719 (1.0598)\tPrec@1 57.031 (54.539)\n",
            "Epoch: [34][30/97], lr: 0.01000\tTime 0.068 (0.087)\tData 0.000 (0.015)\tLoss 1.0316 (1.0574)\tPrec@1 57.031 (54.990)\n",
            "Epoch: [34][40/97], lr: 0.01000\tTime 0.073 (0.083)\tData 0.007 (0.012)\tLoss 1.1216 (1.0612)\tPrec@1 50.781 (54.516)\n",
            "Epoch: [34][50/97], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.010)\tLoss 1.0358 (1.0577)\tPrec@1 57.812 (54.519)\n",
            "Epoch: [34][60/97], lr: 0.01000\tTime 0.081 (0.079)\tData 0.009 (0.009)\tLoss 1.1273 (1.0626)\tPrec@1 50.781 (54.419)\n",
            "Epoch: [34][70/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.007 (0.008)\tLoss 1.0311 (1.0640)\tPrec@1 57.031 (54.346)\n",
            "Epoch: [34][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.000 (0.008)\tLoss 1.0375 (1.0638)\tPrec@1 57.031 (54.389)\n",
            "Epoch: [34][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 1.0948 (1.0625)\tPrec@1 50.781 (54.464)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 0.9838 (0.9838)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.025 (0.062)\tLoss 1.1970 (1.1255)\tPrec@1 45.000 (48.818)\n",
            "Test: [20/100]\tTime 0.023 (0.048)\tLoss 1.2063 (1.1161)\tPrec@1 44.000 (50.048)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 1.1608 (1.1243)\tPrec@1 47.000 (49.548)\n",
            "Test: [40/100]\tTime 0.032 (0.040)\tLoss 1.1126 (1.1165)\tPrec@1 50.000 (50.024)\n",
            "Test: [50/100]\tTime 0.034 (0.038)\tLoss 1.0976 (1.1173)\tPrec@1 48.000 (50.333)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 1.2191 (1.1232)\tPrec@1 39.000 (50.131)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 1.0912 (1.1224)\tPrec@1 57.000 (50.408)\n",
            "Test: [80/100]\tTime 0.047 (0.035)\tLoss 1.1161 (1.1224)\tPrec@1 46.000 (50.432)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 1.2055 (1.1215)\tPrec@1 49.000 (50.549)\n",
            "val Results: Prec@1 50.560 Loss 1.11927\n",
            "Best Prec@1: 50.560\n",
            "\n",
            "Epoch: [35][0/97], lr: 0.01000\tTime 0.529 (0.529)\tData 0.366 (0.366)\tLoss 1.0442 (1.0442)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [35][10/97], lr: 0.01000\tTime 0.059 (0.111)\tData 0.000 (0.035)\tLoss 0.9535 (1.0782)\tPrec@1 60.156 (52.344)\n",
            "Epoch: [35][20/97], lr: 0.01000\tTime 0.075 (0.093)\tData 0.013 (0.019)\tLoss 1.0339 (1.0827)\tPrec@1 52.344 (52.269)\n",
            "Epoch: [35][30/97], lr: 0.01000\tTime 0.063 (0.085)\tData 0.000 (0.014)\tLoss 1.1254 (1.0807)\tPrec@1 53.906 (52.697)\n",
            "Epoch: [35][40/97], lr: 0.01000\tTime 0.090 (0.081)\tData 0.008 (0.011)\tLoss 1.0998 (1.0714)\tPrec@1 46.875 (53.296)\n",
            "Epoch: [35][50/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.009)\tLoss 1.0670 (1.0718)\tPrec@1 53.906 (53.324)\n",
            "Epoch: [35][60/97], lr: 0.01000\tTime 0.080 (0.077)\tData 0.007 (0.008)\tLoss 0.9607 (1.0664)\tPrec@1 57.812 (53.765)\n",
            "Epoch: [35][70/97], lr: 0.01000\tTime 0.086 (0.076)\tData 0.000 (0.007)\tLoss 1.0623 (1.0697)\tPrec@1 57.812 (53.653)\n",
            "Epoch: [35][80/97], lr: 0.01000\tTime 0.062 (0.075)\tData 0.000 (0.006)\tLoss 1.1198 (1.0685)\tPrec@1 51.562 (53.492)\n",
            "Epoch: [35][90/97], lr: 0.01000\tTime 0.055 (0.074)\tData 0.000 (0.006)\tLoss 0.9776 (1.0660)\tPrec@1 54.688 (53.812)\n",
            "Test: [0/100]\tTime 0.261 (0.261)\tLoss 0.9739 (0.9739)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.044 (0.070)\tLoss 1.1643 (1.0987)\tPrec@1 46.000 (50.455)\n",
            "Test: [20/100]\tTime 0.023 (0.053)\tLoss 1.1934 (1.0957)\tPrec@1 43.000 (51.952)\n",
            "Test: [30/100]\tTime 0.032 (0.048)\tLoss 1.0908 (1.1012)\tPrec@1 55.000 (51.935)\n",
            "Test: [40/100]\tTime 0.051 (0.045)\tLoss 1.0584 (1.0959)\tPrec@1 54.000 (52.195)\n",
            "Test: [50/100]\tTime 0.023 (0.043)\tLoss 1.0782 (1.0966)\tPrec@1 56.000 (52.176)\n",
            "Test: [60/100]\tTime 0.031 (0.042)\tLoss 1.1882 (1.1059)\tPrec@1 43.000 (51.836)\n",
            "Test: [70/100]\tTime 0.046 (0.041)\tLoss 1.0791 (1.1059)\tPrec@1 54.000 (51.704)\n",
            "Test: [80/100]\tTime 0.030 (0.041)\tLoss 1.1141 (1.1061)\tPrec@1 51.000 (51.556)\n",
            "Test: [90/100]\tTime 0.044 (0.041)\tLoss 1.1742 (1.1074)\tPrec@1 49.000 (51.571)\n",
            "val Results: Prec@1 51.550 Loss 1.10651\n",
            "Best Prec@1: 51.550\n",
            "\n",
            "Epoch: [36][0/97], lr: 0.01000\tTime 0.477 (0.477)\tData 0.278 (0.278)\tLoss 1.1786 (1.1786)\tPrec@1 47.656 (47.656)\n",
            "Epoch: [36][10/97], lr: 0.01000\tTime 0.073 (0.116)\tData 0.000 (0.029)\tLoss 1.0072 (1.0693)\tPrec@1 59.375 (54.759)\n",
            "Epoch: [36][20/97], lr: 0.01000\tTime 0.060 (0.094)\tData 0.000 (0.016)\tLoss 1.0132 (1.0568)\tPrec@1 54.688 (55.097)\n",
            "Epoch: [36][30/97], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.011)\tLoss 0.9745 (1.0546)\tPrec@1 61.719 (55.066)\n",
            "Epoch: [36][40/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.009)\tLoss 0.9736 (1.0484)\tPrec@1 57.812 (55.450)\n",
            "Epoch: [36][50/97], lr: 0.01000\tTime 0.083 (0.081)\tData 0.000 (0.008)\tLoss 1.0018 (1.0506)\tPrec@1 60.938 (55.438)\n",
            "Epoch: [36][60/97], lr: 0.01000\tTime 0.073 (0.080)\tData 0.000 (0.007)\tLoss 1.0321 (1.0492)\tPrec@1 60.156 (55.584)\n",
            "Epoch: [36][70/97], lr: 0.01000\tTime 0.120 (0.081)\tData 0.009 (0.007)\tLoss 1.1805 (1.0505)\tPrec@1 46.094 (55.458)\n",
            "Epoch: [36][80/97], lr: 0.01000\tTime 0.072 (0.082)\tData 0.000 (0.006)\tLoss 1.1665 (1.0517)\tPrec@1 48.438 (55.343)\n",
            "Epoch: [36][90/97], lr: 0.01000\tTime 0.055 (0.081)\tData 0.000 (0.005)\tLoss 1.0349 (1.0474)\tPrec@1 55.469 (55.520)\n",
            "Test: [0/100]\tTime 0.376 (0.376)\tLoss 1.0350 (1.0350)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.024 (0.069)\tLoss 1.1916 (1.1529)\tPrec@1 42.000 (48.545)\n",
            "Test: [20/100]\tTime 0.051 (0.053)\tLoss 1.2253 (1.1519)\tPrec@1 43.000 (49.714)\n",
            "Test: [30/100]\tTime 0.023 (0.048)\tLoss 1.1536 (1.1499)\tPrec@1 49.000 (50.097)\n",
            "Test: [40/100]\tTime 0.037 (0.044)\tLoss 1.0319 (1.1407)\tPrec@1 55.000 (50.512)\n",
            "Test: [50/100]\tTime 0.025 (0.042)\tLoss 1.1580 (1.1427)\tPrec@1 49.000 (50.843)\n",
            "Test: [60/100]\tTime 0.049 (0.040)\tLoss 1.1676 (1.1499)\tPrec@1 47.000 (50.689)\n",
            "Test: [70/100]\tTime 0.033 (0.039)\tLoss 1.1230 (1.1485)\tPrec@1 54.000 (50.775)\n",
            "Test: [80/100]\tTime 0.030 (0.038)\tLoss 1.1201 (1.1472)\tPrec@1 52.000 (50.852)\n",
            "Test: [90/100]\tTime 0.030 (0.037)\tLoss 1.1524 (1.1433)\tPrec@1 49.000 (50.923)\n",
            "val Results: Prec@1 51.030 Loss 1.14114\n",
            "Best Prec@1: 51.550\n",
            "\n",
            "Epoch: [37][0/97], lr: 0.01000\tTime 0.521 (0.521)\tData 0.310 (0.310)\tLoss 1.1688 (1.1688)\tPrec@1 45.312 (45.312)\n",
            "Epoch: [37][10/97], lr: 0.01000\tTime 0.102 (0.116)\tData 0.013 (0.031)\tLoss 1.0754 (1.0614)\tPrec@1 53.906 (52.912)\n",
            "Epoch: [37][20/97], lr: 0.01000\tTime 0.060 (0.094)\tData 0.000 (0.017)\tLoss 1.0301 (1.0644)\tPrec@1 55.469 (53.943)\n",
            "Epoch: [37][30/97], lr: 0.01000\tTime 0.066 (0.089)\tData 0.000 (0.012)\tLoss 1.0488 (1.0515)\tPrec@1 53.125 (53.931)\n",
            "Epoch: [37][40/97], lr: 0.01000\tTime 0.074 (0.085)\tData 0.007 (0.010)\tLoss 1.1060 (1.0518)\tPrec@1 53.125 (54.078)\n",
            "Epoch: [37][50/97], lr: 0.01000\tTime 0.110 (0.084)\tData 0.001 (0.009)\tLoss 1.0686 (1.0524)\tPrec@1 52.344 (54.136)\n",
            "Epoch: [37][60/97], lr: 0.01000\tTime 0.063 (0.084)\tData 0.000 (0.007)\tLoss 0.9893 (1.0505)\tPrec@1 63.281 (54.419)\n",
            "Epoch: [37][70/97], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.007)\tLoss 1.0855 (1.0501)\tPrec@1 50.781 (54.489)\n",
            "Epoch: [37][80/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.006)\tLoss 1.1111 (1.0465)\tPrec@1 54.688 (54.649)\n",
            "Epoch: [37][90/97], lr: 0.01000\tTime 0.052 (0.084)\tData 0.000 (0.006)\tLoss 1.0021 (1.0474)\tPrec@1 60.938 (54.490)\n",
            "Test: [0/100]\tTime 0.376 (0.376)\tLoss 1.0458 (1.0458)\tPrec@1 50.000 (50.000)\n",
            "Test: [10/100]\tTime 0.044 (0.064)\tLoss 1.1561 (1.1022)\tPrec@1 49.000 (50.455)\n",
            "Test: [20/100]\tTime 0.030 (0.048)\tLoss 1.1466 (1.0967)\tPrec@1 48.000 (51.000)\n",
            "Test: [30/100]\tTime 0.024 (0.043)\tLoss 1.1488 (1.1070)\tPrec@1 51.000 (50.677)\n",
            "Test: [40/100]\tTime 0.051 (0.040)\tLoss 1.0567 (1.0990)\tPrec@1 59.000 (51.659)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 1.1597 (1.1005)\tPrec@1 51.000 (51.667)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1754 (1.1087)\tPrec@1 44.000 (51.328)\n",
            "Test: [70/100]\tTime 0.022 (0.037)\tLoss 1.0674 (1.1085)\tPrec@1 57.000 (51.268)\n",
            "Test: [80/100]\tTime 0.029 (0.036)\tLoss 1.1270 (1.1072)\tPrec@1 47.000 (51.235)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.1220 (1.1058)\tPrec@1 48.000 (51.253)\n",
            "val Results: Prec@1 51.310 Loss 1.10360\n",
            "Best Prec@1: 51.550\n",
            "\n",
            "Epoch: [38][0/97], lr: 0.01000\tTime 0.515 (0.515)\tData 0.388 (0.388)\tLoss 0.9895 (0.9895)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [38][10/97], lr: 0.01000\tTime 0.067 (0.112)\tData 0.000 (0.038)\tLoss 0.9915 (1.0050)\tPrec@1 58.594 (57.173)\n",
            "Epoch: [38][20/97], lr: 0.01000\tTime 0.071 (0.093)\tData 0.013 (0.022)\tLoss 1.0410 (1.0093)\tPrec@1 57.812 (57.106)\n",
            "Epoch: [38][30/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.016)\tLoss 0.9983 (1.0124)\tPrec@1 58.594 (56.552)\n",
            "Epoch: [38][40/97], lr: 0.01000\tTime 0.077 (0.082)\tData 0.000 (0.013)\tLoss 1.0555 (1.0124)\tPrec@1 53.906 (56.745)\n",
            "Epoch: [38][50/97], lr: 0.01000\tTime 0.074 (0.080)\tData 0.005 (0.011)\tLoss 1.1614 (1.0221)\tPrec@1 52.344 (56.342)\n",
            "Epoch: [38][60/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.001 (0.010)\tLoss 1.0392 (1.0270)\tPrec@1 53.906 (55.930)\n",
            "Epoch: [38][70/97], lr: 0.01000\tTime 0.058 (0.077)\tData 0.000 (0.009)\tLoss 1.2180 (1.0274)\tPrec@1 44.531 (55.821)\n",
            "Epoch: [38][80/97], lr: 0.01000\tTime 0.068 (0.076)\tData 0.005 (0.008)\tLoss 1.0954 (1.0311)\tPrec@1 53.125 (55.710)\n",
            "Epoch: [38][90/97], lr: 0.01000\tTime 0.055 (0.075)\tData 0.000 (0.008)\tLoss 0.9468 (1.0297)\tPrec@1 61.719 (55.709)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.0017 (1.0017)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.022 (0.058)\tLoss 1.1092 (1.1038)\tPrec@1 51.000 (51.091)\n",
            "Test: [20/100]\tTime 0.026 (0.046)\tLoss 1.2531 (1.1073)\tPrec@1 43.000 (51.333)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 1.1167 (1.1150)\tPrec@1 50.000 (51.065)\n",
            "Test: [40/100]\tTime 0.041 (0.039)\tLoss 1.1132 (1.1086)\tPrec@1 58.000 (51.634)\n",
            "Test: [50/100]\tTime 0.029 (0.037)\tLoss 1.1943 (1.1113)\tPrec@1 48.000 (51.745)\n",
            "Test: [60/100]\tTime 0.046 (0.036)\tLoss 1.2001 (1.1214)\tPrec@1 44.000 (51.213)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.0587 (1.1200)\tPrec@1 53.000 (51.239)\n",
            "Test: [80/100]\tTime 0.047 (0.036)\tLoss 1.0911 (1.1167)\tPrec@1 59.000 (51.420)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.1575 (1.1168)\tPrec@1 48.000 (51.308)\n",
            "val Results: Prec@1 51.430 Loss 1.11461\n",
            "Best Prec@1: 51.550\n",
            "\n",
            "Epoch: [39][0/97], lr: 0.01000\tTime 0.543 (0.543)\tData 0.390 (0.390)\tLoss 0.9736 (0.9736)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [39][10/97], lr: 0.01000\tTime 0.073 (0.117)\tData 0.000 (0.037)\tLoss 1.0826 (1.0200)\tPrec@1 50.000 (56.605)\n",
            "Epoch: [39][20/97], lr: 0.01000\tTime 0.067 (0.096)\tData 0.000 (0.020)\tLoss 0.9974 (1.0186)\tPrec@1 56.250 (55.618)\n",
            "Epoch: [39][30/97], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.015)\tLoss 1.0800 (1.0276)\tPrec@1 53.125 (55.595)\n",
            "Epoch: [39][40/97], lr: 0.01000\tTime 0.083 (0.086)\tData 0.000 (0.012)\tLoss 1.0760 (1.0293)\tPrec@1 54.688 (55.793)\n",
            "Epoch: [39][50/97], lr: 0.01000\tTime 0.066 (0.083)\tData 0.006 (0.010)\tLoss 0.9579 (1.0229)\tPrec@1 58.594 (55.990)\n",
            "Epoch: [39][60/97], lr: 0.01000\tTime 0.070 (0.081)\tData 0.007 (0.010)\tLoss 1.1026 (1.0244)\tPrec@1 49.219 (55.738)\n",
            "Epoch: [39][70/97], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.009)\tLoss 0.9511 (1.0245)\tPrec@1 54.688 (55.546)\n",
            "Epoch: [39][80/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.009)\tLoss 1.0457 (1.0226)\tPrec@1 55.469 (55.797)\n",
            "Epoch: [39][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.008)\tLoss 1.0693 (1.0234)\tPrec@1 55.469 (55.941)\n",
            "Test: [0/100]\tTime 0.264 (0.264)\tLoss 0.9875 (0.9875)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 1.1534 (1.0940)\tPrec@1 48.000 (51.545)\n",
            "Test: [20/100]\tTime 0.023 (0.046)\tLoss 1.2111 (1.0907)\tPrec@1 42.000 (51.905)\n",
            "Test: [30/100]\tTime 0.021 (0.040)\tLoss 1.0761 (1.0960)\tPrec@1 49.000 (51.419)\n",
            "Test: [40/100]\tTime 0.025 (0.039)\tLoss 1.0212 (1.0840)\tPrec@1 57.000 (52.195)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.0708 (1.0809)\tPrec@1 48.000 (52.471)\n",
            "Test: [60/100]\tTime 0.024 (0.036)\tLoss 1.1253 (1.0870)\tPrec@1 48.000 (52.197)\n",
            "Test: [70/100]\tTime 0.046 (0.035)\tLoss 1.0917 (1.0888)\tPrec@1 53.000 (52.085)\n",
            "Test: [80/100]\tTime 0.034 (0.035)\tLoss 1.1249 (1.0896)\tPrec@1 48.000 (51.975)\n",
            "Test: [90/100]\tTime 0.040 (0.035)\tLoss 1.1153 (1.0906)\tPrec@1 45.000 (51.868)\n",
            "val Results: Prec@1 51.950 Loss 1.08881\n",
            "Best Prec@1: 51.950\n",
            "\n",
            "Epoch: [40][0/97], lr: 0.01000\tTime 0.534 (0.534)\tData 0.415 (0.415)\tLoss 1.0154 (1.0154)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [40][10/97], lr: 0.01000\tTime 0.071 (0.122)\tData 0.005 (0.040)\tLoss 1.0216 (1.0267)\tPrec@1 55.469 (55.398)\n",
            "Epoch: [40][20/97], lr: 0.01000\tTime 0.063 (0.097)\tData 0.001 (0.021)\tLoss 0.9685 (1.0145)\tPrec@1 58.594 (56.399)\n",
            "Epoch: [40][30/97], lr: 0.01000\tTime 0.062 (0.089)\tData 0.000 (0.015)\tLoss 1.0610 (1.0075)\tPrec@1 53.906 (57.182)\n",
            "Epoch: [40][40/97], lr: 0.01000\tTime 0.078 (0.084)\tData 0.000 (0.012)\tLoss 0.9329 (1.0159)\tPrec@1 58.594 (56.517)\n",
            "Epoch: [40][50/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.010)\tLoss 1.0717 (1.0186)\tPrec@1 54.688 (56.342)\n",
            "Epoch: [40][60/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.008)\tLoss 1.0040 (1.0220)\tPrec@1 54.688 (56.032)\n",
            "Epoch: [40][70/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.008)\tLoss 1.1542 (1.0185)\tPrec@1 42.969 (55.986)\n",
            "Epoch: [40][80/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 0.9831 (1.0188)\tPrec@1 57.031 (55.922)\n",
            "Epoch: [40][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.9898 (1.0189)\tPrec@1 56.250 (55.958)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.0173 (1.0173)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.044 (0.059)\tLoss 1.1398 (1.0997)\tPrec@1 54.000 (52.182)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 1.1859 (1.0926)\tPrec@1 43.000 (51.762)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.1151 (1.0975)\tPrec@1 47.000 (51.484)\n",
            "Test: [40/100]\tTime 0.038 (0.039)\tLoss 1.0575 (1.0910)\tPrec@1 56.000 (51.976)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.1429 (1.0930)\tPrec@1 48.000 (51.863)\n",
            "Test: [60/100]\tTime 0.032 (0.037)\tLoss 1.2308 (1.1002)\tPrec@1 43.000 (51.770)\n",
            "Test: [70/100]\tTime 0.027 (0.036)\tLoss 1.0621 (1.0977)\tPrec@1 64.000 (51.845)\n",
            "Test: [80/100]\tTime 0.037 (0.035)\tLoss 1.1158 (1.0983)\tPrec@1 50.000 (51.716)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 1.1692 (1.1000)\tPrec@1 52.000 (51.604)\n",
            "val Results: Prec@1 51.850 Loss 1.09827\n",
            "Best Prec@1: 51.950\n",
            "\n",
            "Epoch: [41][0/97], lr: 0.01000\tTime 0.548 (0.548)\tData 0.344 (0.344)\tLoss 1.0943 (1.0943)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [41][10/97], lr: 0.01000\tTime 0.069 (0.118)\tData 0.000 (0.034)\tLoss 1.0168 (1.0271)\tPrec@1 56.250 (55.256)\n",
            "Epoch: [41][20/97], lr: 0.01000\tTime 0.075 (0.096)\tData 0.001 (0.019)\tLoss 1.0116 (1.0334)\tPrec@1 53.125 (55.134)\n",
            "Epoch: [41][30/97], lr: 0.01000\tTime 0.072 (0.087)\tData 0.007 (0.014)\tLoss 0.9241 (1.0194)\tPrec@1 63.281 (56.048)\n",
            "Epoch: [41][40/97], lr: 0.01000\tTime 0.065 (0.083)\tData 0.003 (0.012)\tLoss 0.8950 (1.0071)\tPrec@1 67.969 (57.279)\n",
            "Epoch: [41][50/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.007 (0.010)\tLoss 1.0575 (1.0067)\tPrec@1 55.469 (57.460)\n",
            "Epoch: [41][60/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.010)\tLoss 1.1215 (1.0119)\tPrec@1 53.906 (57.147)\n",
            "Epoch: [41][70/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.009)\tLoss 0.9854 (1.0149)\tPrec@1 57.031 (56.745)\n",
            "Epoch: [41][80/97], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.008)\tLoss 0.9819 (1.0108)\tPrec@1 60.938 (57.012)\n",
            "Epoch: [41][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.008)\tLoss 1.0807 (1.0141)\tPrec@1 52.344 (56.688)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 1.0256 (1.0256)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.036 (0.059)\tLoss 1.1234 (1.0911)\tPrec@1 53.000 (52.091)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 1.1740 (1.0886)\tPrec@1 44.000 (51.524)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.0406 (1.0904)\tPrec@1 54.000 (51.323)\n",
            "Test: [40/100]\tTime 0.022 (0.040)\tLoss 1.0201 (1.0850)\tPrec@1 58.000 (52.098)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.1096 (1.0859)\tPrec@1 46.000 (52.412)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1556 (1.0911)\tPrec@1 49.000 (52.557)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 1.0587 (1.0924)\tPrec@1 56.000 (52.380)\n",
            "Test: [80/100]\tTime 0.037 (0.036)\tLoss 1.0395 (1.0930)\tPrec@1 53.000 (52.123)\n",
            "Test: [90/100]\tTime 0.026 (0.036)\tLoss 1.0379 (1.0911)\tPrec@1 54.000 (52.319)\n",
            "val Results: Prec@1 52.320 Loss 1.08852\n",
            "Best Prec@1: 52.320\n",
            "\n",
            "Epoch: [42][0/97], lr: 0.01000\tTime 0.517 (0.517)\tData 0.324 (0.324)\tLoss 1.0504 (1.0504)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [42][10/97], lr: 0.01000\tTime 0.066 (0.118)\tData 0.000 (0.034)\tLoss 1.0142 (1.0109)\tPrec@1 53.125 (56.960)\n",
            "Epoch: [42][20/97], lr: 0.01000\tTime 0.064 (0.097)\tData 0.000 (0.019)\tLoss 0.9302 (1.0250)\tPrec@1 65.625 (56.176)\n",
            "Epoch: [42][30/97], lr: 0.01000\tTime 0.064 (0.089)\tData 0.000 (0.014)\tLoss 1.1367 (1.0218)\tPrec@1 52.344 (55.822)\n",
            "Epoch: [42][40/97], lr: 0.01000\tTime 0.066 (0.085)\tData 0.002 (0.011)\tLoss 0.9602 (1.0187)\tPrec@1 60.156 (56.193)\n",
            "Epoch: [42][50/97], lr: 0.01000\tTime 0.069 (0.082)\tData 0.006 (0.010)\tLoss 0.9840 (1.0145)\tPrec@1 56.250 (56.388)\n",
            "Epoch: [42][60/97], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.009)\tLoss 0.9646 (1.0105)\tPrec@1 60.938 (56.762)\n",
            "Epoch: [42][70/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.007 (0.008)\tLoss 0.9990 (1.0106)\tPrec@1 60.938 (56.932)\n",
            "Epoch: [42][80/97], lr: 0.01000\tTime 0.066 (0.078)\tData 0.001 (0.007)\tLoss 1.0276 (1.0084)\tPrec@1 60.156 (56.819)\n",
            "Epoch: [42][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.9490 (1.0062)\tPrec@1 57.031 (56.868)\n",
            "Test: [0/100]\tTime 0.254 (0.254)\tLoss 0.9441 (0.9441)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.021 (0.059)\tLoss 1.0706 (1.0972)\tPrec@1 58.000 (53.182)\n",
            "Test: [20/100]\tTime 0.039 (0.046)\tLoss 1.1568 (1.0873)\tPrec@1 50.000 (52.571)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0732 (1.0980)\tPrec@1 50.000 (52.032)\n",
            "Test: [40/100]\tTime 0.044 (0.039)\tLoss 1.0156 (1.0897)\tPrec@1 57.000 (52.024)\n",
            "Test: [50/100]\tTime 0.037 (0.037)\tLoss 1.0918 (1.0907)\tPrec@1 53.000 (52.490)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.1049 (1.0950)\tPrec@1 51.000 (52.508)\n",
            "Test: [70/100]\tTime 0.041 (0.036)\tLoss 1.0284 (1.0966)\tPrec@1 60.000 (52.451)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 1.0267 (1.0975)\tPrec@1 52.000 (52.284)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 1.1408 (1.0973)\tPrec@1 52.000 (52.176)\n",
            "val Results: Prec@1 52.470 Loss 1.09380\n",
            "Best Prec@1: 52.470\n",
            "\n",
            "Epoch: [43][0/97], lr: 0.01000\tTime 0.790 (0.790)\tData 0.553 (0.553)\tLoss 1.0930 (1.0930)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [43][10/97], lr: 0.01000\tTime 0.103 (0.181)\tData 0.007 (0.059)\tLoss 1.0297 (1.0032)\tPrec@1 56.250 (57.884)\n",
            "Epoch: [43][20/97], lr: 0.01000\tTime 0.112 (0.150)\tData 0.015 (0.036)\tLoss 0.9418 (1.0070)\tPrec@1 57.812 (57.366)\n",
            "Epoch: [43][30/97], lr: 0.01000\tTime 0.093 (0.134)\tData 0.000 (0.026)\tLoss 0.9223 (0.9983)\tPrec@1 58.594 (57.611)\n",
            "Epoch: [43][40/97], lr: 0.01000\tTime 0.062 (0.119)\tData 0.000 (0.020)\tLoss 1.0185 (0.9952)\tPrec@1 58.594 (58.270)\n",
            "Epoch: [43][50/97], lr: 0.01000\tTime 0.069 (0.110)\tData 0.006 (0.017)\tLoss 1.0002 (0.9998)\tPrec@1 59.375 (57.981)\n",
            "Epoch: [43][60/97], lr: 0.01000\tTime 0.064 (0.104)\tData 0.000 (0.015)\tLoss 0.9952 (1.0024)\tPrec@1 53.906 (57.646)\n",
            "Epoch: [43][70/97], lr: 0.01000\tTime 0.067 (0.099)\tData 0.000 (0.013)\tLoss 0.9909 (0.9982)\tPrec@1 57.812 (57.835)\n",
            "Epoch: [43][80/97], lr: 0.01000\tTime 0.074 (0.096)\tData 0.012 (0.012)\tLoss 1.0355 (0.9965)\tPrec@1 53.125 (57.822)\n",
            "Epoch: [43][90/97], lr: 0.01000\tTime 0.055 (0.092)\tData 0.000 (0.011)\tLoss 0.9702 (0.9950)\tPrec@1 56.250 (57.795)\n",
            "Test: [0/100]\tTime 0.356 (0.356)\tLoss 1.0016 (1.0016)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.025 (0.062)\tLoss 1.1660 (1.0978)\tPrec@1 52.000 (54.000)\n",
            "Test: [20/100]\tTime 0.025 (0.049)\tLoss 1.1927 (1.0909)\tPrec@1 43.000 (53.667)\n",
            "Test: [30/100]\tTime 0.035 (0.043)\tLoss 1.0971 (1.1002)\tPrec@1 50.000 (52.935)\n",
            "Test: [40/100]\tTime 0.055 (0.041)\tLoss 1.0079 (1.0912)\tPrec@1 61.000 (53.073)\n",
            "Test: [50/100]\tTime 0.050 (0.039)\tLoss 1.0841 (1.0918)\tPrec@1 54.000 (52.980)\n",
            "Test: [60/100]\tTime 0.027 (0.038)\tLoss 1.1708 (1.0971)\tPrec@1 48.000 (52.770)\n",
            "Test: [70/100]\tTime 0.030 (0.037)\tLoss 1.0418 (1.1001)\tPrec@1 52.000 (52.437)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 1.0690 (1.1018)\tPrec@1 50.000 (52.148)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.1264 (1.1021)\tPrec@1 50.000 (52.154)\n",
            "val Results: Prec@1 52.380 Loss 1.09905\n",
            "Best Prec@1: 52.470\n",
            "\n",
            "Epoch: [44][0/97], lr: 0.01000\tTime 0.564 (0.564)\tData 0.433 (0.433)\tLoss 0.9230 (0.9230)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [44][10/97], lr: 0.01000\tTime 0.076 (0.123)\tData 0.007 (0.042)\tLoss 1.0564 (0.9963)\tPrec@1 56.250 (58.168)\n",
            "Epoch: [44][20/97], lr: 0.01000\tTime 0.058 (0.097)\tData 0.000 (0.023)\tLoss 0.9273 (0.9935)\tPrec@1 62.500 (58.073)\n",
            "Epoch: [44][30/97], lr: 0.01000\tTime 0.066 (0.090)\tData 0.000 (0.016)\tLoss 0.9677 (1.0064)\tPrec@1 62.500 (57.006)\n",
            "Epoch: [44][40/97], lr: 0.01000\tTime 0.061 (0.085)\tData 0.000 (0.013)\tLoss 1.1943 (1.0116)\tPrec@1 46.875 (56.688)\n",
            "Epoch: [44][50/97], lr: 0.01000\tTime 0.064 (0.082)\tData 0.000 (0.011)\tLoss 0.9724 (1.0024)\tPrec@1 57.812 (57.123)\n",
            "Epoch: [44][60/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.010)\tLoss 1.0358 (1.0018)\tPrec@1 52.344 (57.262)\n",
            "Epoch: [44][70/97], lr: 0.01000\tTime 0.074 (0.080)\tData 0.004 (0.009)\tLoss 0.9598 (0.9980)\tPrec@1 55.469 (57.427)\n",
            "Epoch: [44][80/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.007 (0.008)\tLoss 0.9338 (0.9947)\tPrec@1 60.938 (57.542)\n",
            "Epoch: [44][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.008)\tLoss 1.0079 (0.9941)\tPrec@1 57.812 (57.478)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 1.0781 (1.0781)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.021 (0.060)\tLoss 1.1189 (1.1074)\tPrec@1 52.000 (51.091)\n",
            "Test: [20/100]\tTime 0.021 (0.046)\tLoss 1.1645 (1.0873)\tPrec@1 49.000 (52.286)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 1.0571 (1.0960)\tPrec@1 51.000 (51.613)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 1.0328 (1.0912)\tPrec@1 60.000 (51.902)\n",
            "Test: [50/100]\tTime 0.036 (0.037)\tLoss 1.0997 (1.0917)\tPrec@1 45.000 (52.000)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.1221 (1.0991)\tPrec@1 49.000 (51.803)\n",
            "Test: [70/100]\tTime 0.030 (0.035)\tLoss 1.1170 (1.1010)\tPrec@1 51.000 (51.634)\n",
            "Test: [80/100]\tTime 0.023 (0.034)\tLoss 1.0641 (1.0999)\tPrec@1 51.000 (51.667)\n",
            "Test: [90/100]\tTime 0.032 (0.034)\tLoss 1.0892 (1.0976)\tPrec@1 55.000 (51.879)\n",
            "val Results: Prec@1 51.970 Loss 1.09449\n",
            "Best Prec@1: 52.470\n",
            "\n",
            "Epoch: [45][0/97], lr: 0.01000\tTime 0.579 (0.579)\tData 0.437 (0.437)\tLoss 0.9656 (0.9656)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [45][10/97], lr: 0.01000\tTime 0.060 (0.115)\tData 0.000 (0.044)\tLoss 1.0401 (1.0315)\tPrec@1 55.469 (55.398)\n",
            "Epoch: [45][20/97], lr: 0.01000\tTime 0.063 (0.094)\tData 0.000 (0.023)\tLoss 0.9948 (1.0057)\tPrec@1 53.906 (56.696)\n",
            "Epoch: [45][30/97], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.016)\tLoss 1.1010 (0.9988)\tPrec@1 46.875 (57.384)\n",
            "Epoch: [45][40/97], lr: 0.01000\tTime 0.063 (0.082)\tData 0.000 (0.013)\tLoss 0.9614 (0.9928)\tPrec@1 54.688 (57.584)\n",
            "Epoch: [45][50/97], lr: 0.01000\tTime 0.073 (0.081)\tData 0.007 (0.011)\tLoss 1.0126 (0.9918)\tPrec@1 55.469 (57.736)\n",
            "Epoch: [45][60/97], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.010)\tLoss 0.8770 (0.9883)\tPrec@1 64.844 (57.723)\n",
            "Epoch: [45][70/97], lr: 0.01000\tTime 0.075 (0.078)\tData 0.010 (0.009)\tLoss 0.9717 (0.9889)\tPrec@1 60.156 (57.614)\n",
            "Epoch: [45][80/97], lr: 0.01000\tTime 0.075 (0.077)\tData 0.006 (0.008)\tLoss 1.0411 (0.9912)\tPrec@1 56.250 (57.494)\n",
            "Epoch: [45][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.008)\tLoss 1.0655 (0.9876)\tPrec@1 56.250 (57.649)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 1.0044 (1.0044)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.023 (0.060)\tLoss 1.1596 (1.1120)\tPrec@1 51.000 (50.091)\n",
            "Test: [20/100]\tTime 0.054 (0.047)\tLoss 1.1767 (1.1091)\tPrec@1 47.000 (51.000)\n",
            "Test: [30/100]\tTime 0.028 (0.041)\tLoss 1.0933 (1.1163)\tPrec@1 47.000 (50.645)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9878 (1.1038)\tPrec@1 59.000 (51.854)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.1166 (1.1043)\tPrec@1 51.000 (51.902)\n",
            "Test: [60/100]\tTime 0.033 (0.037)\tLoss 1.1601 (1.1074)\tPrec@1 45.000 (51.656)\n",
            "Test: [70/100]\tTime 0.026 (0.036)\tLoss 1.1047 (1.1066)\tPrec@1 53.000 (51.704)\n",
            "Test: [80/100]\tTime 0.023 (0.035)\tLoss 1.0652 (1.1055)\tPrec@1 54.000 (51.506)\n",
            "Test: [90/100]\tTime 0.031 (0.035)\tLoss 1.1696 (1.1057)\tPrec@1 49.000 (51.473)\n",
            "val Results: Prec@1 51.710 Loss 1.10375\n",
            "Best Prec@1: 52.470\n",
            "\n",
            "Epoch: [46][0/97], lr: 0.01000\tTime 0.506 (0.506)\tData 0.315 (0.315)\tLoss 1.0551 (1.0551)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [46][10/97], lr: 0.01000\tTime 0.073 (0.114)\tData 0.000 (0.030)\tLoss 0.8925 (0.9894)\tPrec@1 64.844 (58.736)\n",
            "Epoch: [46][20/97], lr: 0.01000\tTime 0.064 (0.093)\tData 0.004 (0.017)\tLoss 1.1153 (1.0021)\tPrec@1 50.000 (56.920)\n",
            "Epoch: [46][30/97], lr: 0.01000\tTime 0.061 (0.086)\tData 0.000 (0.013)\tLoss 0.9774 (1.0004)\tPrec@1 55.469 (56.855)\n",
            "Epoch: [46][40/97], lr: 0.01000\tTime 0.081 (0.082)\tData 0.004 (0.011)\tLoss 0.8795 (0.9941)\tPrec@1 66.406 (57.355)\n",
            "Epoch: [46][50/97], lr: 0.01000\tTime 0.071 (0.080)\tData 0.007 (0.009)\tLoss 1.0727 (0.9999)\tPrec@1 54.688 (57.154)\n",
            "Epoch: [46][60/97], lr: 0.01000\tTime 0.061 (0.078)\tData 0.000 (0.008)\tLoss 0.8387 (0.9969)\tPrec@1 65.625 (57.249)\n",
            "Epoch: [46][70/97], lr: 0.01000\tTime 0.077 (0.077)\tData 0.013 (0.008)\tLoss 1.1171 (0.9940)\tPrec@1 57.031 (57.394)\n",
            "Epoch: [46][80/97], lr: 0.01000\tTime 0.064 (0.076)\tData 0.000 (0.007)\tLoss 0.8143 (0.9893)\tPrec@1 67.969 (57.581)\n",
            "Epoch: [46][90/97], lr: 0.01000\tTime 0.050 (0.075)\tData 0.000 (0.007)\tLoss 0.9483 (0.9878)\tPrec@1 57.031 (57.641)\n",
            "Test: [0/100]\tTime 0.314 (0.314)\tLoss 1.0228 (1.0228)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.039 (0.068)\tLoss 1.0980 (1.1182)\tPrec@1 55.000 (51.909)\n",
            "Test: [20/100]\tTime 0.026 (0.053)\tLoss 1.2097 (1.1059)\tPrec@1 45.000 (52.762)\n",
            "Test: [30/100]\tTime 0.023 (0.047)\tLoss 1.1157 (1.1159)\tPrec@1 56.000 (52.774)\n",
            "Test: [40/100]\tTime 0.046 (0.044)\tLoss 1.0021 (1.1048)\tPrec@1 55.000 (53.415)\n",
            "Test: [50/100]\tTime 0.024 (0.042)\tLoss 1.1723 (1.1054)\tPrec@1 52.000 (53.667)\n",
            "Test: [60/100]\tTime 0.041 (0.041)\tLoss 1.1358 (1.1110)\tPrec@1 56.000 (53.541)\n",
            "Test: [70/100]\tTime 0.025 (0.040)\tLoss 1.0175 (1.1080)\tPrec@1 58.000 (53.606)\n",
            "Test: [80/100]\tTime 0.022 (0.040)\tLoss 1.1120 (1.1103)\tPrec@1 50.000 (53.383)\n",
            "Test: [90/100]\tTime 0.021 (0.040)\tLoss 1.0766 (1.1102)\tPrec@1 55.000 (53.308)\n",
            "val Results: Prec@1 53.360 Loss 1.10624\n",
            "Best Prec@1: 53.360\n",
            "\n",
            "Epoch: [47][0/97], lr: 0.01000\tTime 0.478 (0.478)\tData 0.355 (0.355)\tLoss 0.9709 (0.9709)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [47][10/97], lr: 0.01000\tTime 0.064 (0.116)\tData 0.000 (0.037)\tLoss 1.0118 (0.9791)\tPrec@1 60.156 (59.233)\n",
            "Epoch: [47][20/97], lr: 0.01000\tTime 0.082 (0.095)\tData 0.007 (0.020)\tLoss 0.9319 (0.9812)\tPrec@1 59.375 (58.854)\n",
            "Epoch: [47][30/97], lr: 0.01000\tTime 0.060 (0.087)\tData 0.000 (0.014)\tLoss 0.9105 (0.9827)\tPrec@1 60.156 (58.367)\n",
            "Epoch: [47][40/97], lr: 0.01000\tTime 0.074 (0.083)\tData 0.000 (0.012)\tLoss 1.0187 (0.9872)\tPrec@1 56.250 (57.870)\n",
            "Epoch: [47][50/97], lr: 0.01000\tTime 0.072 (0.081)\tData 0.000 (0.010)\tLoss 1.0522 (0.9852)\tPrec@1 57.031 (58.073)\n",
            "Epoch: [47][60/97], lr: 0.01000\tTime 0.071 (0.079)\tData 0.000 (0.009)\tLoss 1.0303 (0.9768)\tPrec@1 53.125 (58.491)\n",
            "Epoch: [47][70/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.006 (0.008)\tLoss 0.9035 (0.9767)\tPrec@1 57.812 (58.484)\n",
            "Epoch: [47][80/97], lr: 0.01000\tTime 0.069 (0.077)\tData 0.006 (0.008)\tLoss 1.0091 (0.9785)\tPrec@1 59.375 (58.439)\n",
            "Epoch: [47][90/97], lr: 0.01000\tTime 0.059 (0.076)\tData 0.000 (0.007)\tLoss 0.8216 (0.9764)\tPrec@1 64.062 (58.508)\n",
            "Test: [0/100]\tTime 0.333 (0.333)\tLoss 0.9979 (0.9979)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.027 (0.058)\tLoss 1.0380 (1.0767)\tPrec@1 58.000 (52.727)\n",
            "Test: [20/100]\tTime 0.038 (0.045)\tLoss 1.1402 (1.0727)\tPrec@1 52.000 (53.476)\n",
            "Test: [30/100]\tTime 0.029 (0.040)\tLoss 1.0617 (1.0800)\tPrec@1 53.000 (53.161)\n",
            "Test: [40/100]\tTime 0.029 (0.039)\tLoss 1.0091 (1.0699)\tPrec@1 55.000 (53.732)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 1.1218 (1.0708)\tPrec@1 51.000 (53.902)\n",
            "Test: [60/100]\tTime 0.035 (0.036)\tLoss 1.1286 (1.0758)\tPrec@1 47.000 (53.721)\n",
            "Test: [70/100]\tTime 0.021 (0.035)\tLoss 1.0838 (1.0755)\tPrec@1 57.000 (53.704)\n",
            "Test: [80/100]\tTime 0.046 (0.035)\tLoss 0.9865 (1.0747)\tPrec@1 55.000 (53.568)\n",
            "Test: [90/100]\tTime 0.038 (0.034)\tLoss 1.0710 (1.0720)\tPrec@1 55.000 (53.736)\n",
            "val Results: Prec@1 53.730 Loss 1.06984\n",
            "Best Prec@1: 53.730\n",
            "\n",
            "Epoch: [48][0/97], lr: 0.01000\tTime 0.525 (0.525)\tData 0.398 (0.398)\tLoss 1.0270 (1.0270)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [48][10/97], lr: 0.01000\tTime 0.065 (0.116)\tData 0.000 (0.039)\tLoss 1.0128 (0.9845)\tPrec@1 56.250 (56.889)\n",
            "Epoch: [48][20/97], lr: 0.01000\tTime 0.073 (0.095)\tData 0.008 (0.021)\tLoss 0.8887 (0.9708)\tPrec@1 67.969 (57.961)\n",
            "Epoch: [48][30/97], lr: 0.01000\tTime 0.064 (0.087)\tData 0.000 (0.015)\tLoss 1.0582 (0.9676)\tPrec@1 57.031 (57.913)\n",
            "Epoch: [48][40/97], lr: 0.01000\tTime 0.075 (0.083)\tData 0.000 (0.011)\tLoss 1.0298 (0.9694)\tPrec@1 53.906 (58.003)\n",
            "Epoch: [48][50/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.009)\tLoss 1.0002 (0.9734)\tPrec@1 56.250 (57.751)\n",
            "Epoch: [48][60/97], lr: 0.01000\tTime 0.060 (0.080)\tData 0.000 (0.008)\tLoss 1.0285 (0.9767)\tPrec@1 53.906 (57.825)\n",
            "Epoch: [48][70/97], lr: 0.01000\tTime 0.073 (0.079)\tData 0.008 (0.008)\tLoss 0.9313 (0.9746)\tPrec@1 59.375 (58.132)\n",
            "Epoch: [48][80/97], lr: 0.01000\tTime 0.090 (0.078)\tData 0.000 (0.007)\tLoss 0.9733 (0.9725)\tPrec@1 55.469 (58.247)\n",
            "Epoch: [48][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.8641 (0.9686)\tPrec@1 63.281 (58.439)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 1.0047 (1.0047)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.023 (0.061)\tLoss 1.1204 (1.0871)\tPrec@1 59.000 (53.636)\n",
            "Test: [20/100]\tTime 0.044 (0.047)\tLoss 1.1419 (1.0756)\tPrec@1 51.000 (54.524)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 1.1313 (1.0839)\tPrec@1 50.000 (53.774)\n",
            "Test: [40/100]\tTime 0.034 (0.040)\tLoss 0.9930 (1.0769)\tPrec@1 60.000 (54.146)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.1022 (1.0770)\tPrec@1 51.000 (54.294)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1416 (1.0829)\tPrec@1 48.000 (54.000)\n",
            "Test: [70/100]\tTime 0.045 (0.037)\tLoss 1.0679 (1.0848)\tPrec@1 55.000 (53.789)\n",
            "Test: [80/100]\tTime 0.042 (0.036)\tLoss 1.0736 (1.0861)\tPrec@1 51.000 (53.494)\n",
            "Test: [90/100]\tTime 0.028 (0.035)\tLoss 1.0576 (1.0860)\tPrec@1 56.000 (53.473)\n",
            "val Results: Prec@1 53.670 Loss 1.08363\n",
            "Best Prec@1: 53.730\n",
            "\n",
            "Epoch: [49][0/97], lr: 0.01000\tTime 0.522 (0.522)\tData 0.350 (0.350)\tLoss 0.9463 (0.9463)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [49][10/97], lr: 0.01000\tTime 0.076 (0.119)\tData 0.000 (0.034)\tLoss 0.9622 (0.9574)\tPrec@1 67.188 (58.239)\n",
            "Epoch: [49][20/97], lr: 0.01000\tTime 0.069 (0.098)\tData 0.000 (0.019)\tLoss 0.9192 (0.9704)\tPrec@1 63.281 (58.408)\n",
            "Epoch: [49][30/97], lr: 0.01000\tTime 0.064 (0.090)\tData 0.000 (0.013)\tLoss 0.9124 (0.9707)\tPrec@1 57.031 (58.317)\n",
            "Epoch: [49][40/97], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.010)\tLoss 0.9165 (0.9675)\tPrec@1 61.719 (58.327)\n",
            "Epoch: [49][50/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.009)\tLoss 0.9711 (0.9714)\tPrec@1 60.156 (58.441)\n",
            "Epoch: [49][60/97], lr: 0.01000\tTime 0.069 (0.081)\tData 0.005 (0.008)\tLoss 0.9295 (0.9739)\tPrec@1 61.719 (58.504)\n",
            "Epoch: [49][70/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.006 (0.008)\tLoss 0.9611 (0.9762)\tPrec@1 60.938 (58.418)\n",
            "Epoch: [49][80/97], lr: 0.01000\tTime 0.089 (0.081)\tData 0.009 (0.007)\tLoss 0.9966 (0.9781)\tPrec@1 55.469 (58.247)\n",
            "Epoch: [49][90/97], lr: 0.01000\tTime 0.057 (0.080)\tData 0.000 (0.007)\tLoss 0.9413 (0.9775)\tPrec@1 61.719 (58.156)\n",
            "Test: [0/100]\tTime 0.277 (0.277)\tLoss 0.9761 (0.9761)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.024 (0.066)\tLoss 1.1799 (1.0710)\tPrec@1 58.000 (53.636)\n",
            "Test: [20/100]\tTime 0.035 (0.051)\tLoss 1.1506 (1.0640)\tPrec@1 50.000 (54.667)\n",
            "Test: [30/100]\tTime 0.054 (0.047)\tLoss 1.1080 (1.0739)\tPrec@1 53.000 (53.903)\n",
            "Test: [40/100]\tTime 0.037 (0.044)\tLoss 0.9703 (1.0664)\tPrec@1 62.000 (54.293)\n",
            "Test: [50/100]\tTime 0.039 (0.043)\tLoss 1.0362 (1.0644)\tPrec@1 55.000 (54.392)\n",
            "Test: [60/100]\tTime 0.033 (0.041)\tLoss 1.1105 (1.0705)\tPrec@1 50.000 (54.393)\n",
            "Test: [70/100]\tTime 0.030 (0.040)\tLoss 1.0600 (1.0725)\tPrec@1 51.000 (54.099)\n",
            "Test: [80/100]\tTime 0.031 (0.039)\tLoss 1.0094 (1.0736)\tPrec@1 61.000 (53.963)\n",
            "Test: [90/100]\tTime 0.032 (0.038)\tLoss 1.1051 (1.0723)\tPrec@1 55.000 (53.923)\n",
            "val Results: Prec@1 53.860 Loss 1.07111\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [50][0/97], lr: 0.01000\tTime 0.531 (0.531)\tData 0.406 (0.406)\tLoss 1.1488 (1.1488)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [50][10/97], lr: 0.01000\tTime 0.070 (0.115)\tData 0.007 (0.039)\tLoss 0.9897 (0.9724)\tPrec@1 56.250 (57.599)\n",
            "Epoch: [50][20/97], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.022)\tLoss 1.0933 (0.9818)\tPrec@1 57.031 (57.701)\n",
            "Epoch: [50][30/97], lr: 0.01000\tTime 0.061 (0.086)\tData 0.001 (0.016)\tLoss 0.9230 (0.9757)\tPrec@1 62.500 (57.939)\n",
            "Epoch: [50][40/97], lr: 0.01000\tTime 0.077 (0.083)\tData 0.007 (0.013)\tLoss 0.9557 (0.9709)\tPrec@1 57.031 (58.422)\n",
            "Epoch: [50][50/97], lr: 0.01000\tTime 0.072 (0.081)\tData 0.001 (0.011)\tLoss 1.0005 (0.9771)\tPrec@1 57.812 (58.272)\n",
            "Epoch: [50][60/97], lr: 0.01000\tTime 0.085 (0.080)\tData 0.000 (0.010)\tLoss 0.9406 (0.9703)\tPrec@1 64.062 (58.530)\n",
            "Epoch: [50][70/97], lr: 0.01000\tTime 0.067 (0.078)\tData 0.007 (0.009)\tLoss 0.9383 (0.9696)\tPrec@1 62.500 (58.605)\n",
            "Epoch: [50][80/97], lr: 0.01000\tTime 0.124 (0.080)\tData 0.009 (0.008)\tLoss 0.9366 (0.9734)\tPrec@1 58.594 (58.343)\n",
            "Epoch: [50][90/97], lr: 0.01000\tTime 0.053 (0.080)\tData 0.000 (0.007)\tLoss 0.8913 (0.9706)\tPrec@1 64.844 (58.542)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 1.0254 (1.0254)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.048 (0.066)\tLoss 1.1168 (1.1028)\tPrec@1 53.000 (51.636)\n",
            "Test: [20/100]\tTime 0.035 (0.050)\tLoss 1.1685 (1.0874)\tPrec@1 48.000 (53.286)\n",
            "Test: [30/100]\tTime 0.024 (0.045)\tLoss 1.0392 (1.0941)\tPrec@1 51.000 (52.613)\n",
            "Test: [40/100]\tTime 0.024 (0.042)\tLoss 1.0352 (1.0805)\tPrec@1 60.000 (53.634)\n",
            "Test: [50/100]\tTime 0.022 (0.041)\tLoss 1.1204 (1.0773)\tPrec@1 49.000 (53.843)\n",
            "Test: [60/100]\tTime 0.026 (0.040)\tLoss 1.1661 (1.0843)\tPrec@1 50.000 (53.393)\n",
            "Test: [70/100]\tTime 0.041 (0.040)\tLoss 1.0748 (1.0819)\tPrec@1 58.000 (53.606)\n",
            "Test: [80/100]\tTime 0.023 (0.039)\tLoss 1.0128 (1.0817)\tPrec@1 57.000 (53.481)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 1.1200 (1.0808)\tPrec@1 51.000 (53.396)\n",
            "val Results: Prec@1 53.400 Loss 1.07836\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [51][0/97], lr: 0.01000\tTime 0.561 (0.561)\tData 0.444 (0.444)\tLoss 0.9653 (0.9653)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [51][10/97], lr: 0.01000\tTime 0.066 (0.119)\tData 0.000 (0.044)\tLoss 0.8894 (0.9574)\tPrec@1 63.281 (59.233)\n",
            "Epoch: [51][20/97], lr: 0.01000\tTime 0.075 (0.096)\tData 0.001 (0.024)\tLoss 0.9496 (0.9608)\tPrec@1 60.156 (58.891)\n",
            "Epoch: [51][30/97], lr: 0.01000\tTime 0.076 (0.090)\tData 0.007 (0.017)\tLoss 0.9702 (0.9542)\tPrec@1 54.688 (59.451)\n",
            "Epoch: [51][40/97], lr: 0.01000\tTime 0.072 (0.088)\tData 0.000 (0.014)\tLoss 0.9185 (0.9626)\tPrec@1 60.156 (58.880)\n",
            "Epoch: [51][50/97], lr: 0.01000\tTime 0.107 (0.089)\tData 0.002 (0.012)\tLoss 1.0472 (0.9633)\tPrec@1 53.906 (58.808)\n",
            "Epoch: [51][60/97], lr: 0.01000\tTime 0.098 (0.088)\tData 0.000 (0.010)\tLoss 1.0065 (0.9621)\tPrec@1 56.250 (58.811)\n",
            "Epoch: [51][70/97], lr: 0.01000\tTime 0.060 (0.087)\tData 0.000 (0.009)\tLoss 1.1364 (0.9676)\tPrec@1 47.656 (58.660)\n",
            "Epoch: [51][80/97], lr: 0.01000\tTime 0.061 (0.087)\tData 0.000 (0.009)\tLoss 1.0516 (0.9691)\tPrec@1 56.250 (58.652)\n",
            "Epoch: [51][90/97], lr: 0.01000\tTime 0.055 (0.085)\tData 0.000 (0.008)\tLoss 1.0092 (0.9751)\tPrec@1 61.719 (58.491)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 1.0240 (1.0240)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 1.1575 (1.0964)\tPrec@1 52.000 (51.909)\n",
            "Test: [20/100]\tTime 0.052 (0.046)\tLoss 1.1864 (1.0908)\tPrec@1 44.000 (52.095)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 1.0456 (1.0886)\tPrec@1 49.000 (52.032)\n",
            "Test: [40/100]\tTime 0.044 (0.039)\tLoss 1.0335 (1.0818)\tPrec@1 62.000 (52.756)\n",
            "Test: [50/100]\tTime 0.047 (0.037)\tLoss 1.0945 (1.0811)\tPrec@1 49.000 (52.941)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 1.1225 (1.0858)\tPrec@1 52.000 (52.967)\n",
            "Test: [70/100]\tTime 0.027 (0.035)\tLoss 1.0343 (1.0851)\tPrec@1 57.000 (52.873)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 1.0548 (1.0885)\tPrec@1 53.000 (52.667)\n",
            "Test: [90/100]\tTime 0.025 (0.034)\tLoss 1.1406 (1.0901)\tPrec@1 48.000 (52.484)\n",
            "val Results: Prec@1 52.650 Loss 1.08731\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [52][0/97], lr: 0.01000\tTime 0.579 (0.579)\tData 0.382 (0.382)\tLoss 1.0525 (1.0525)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [52][10/97], lr: 0.01000\tTime 0.065 (0.118)\tData 0.000 (0.038)\tLoss 1.0438 (1.0267)\tPrec@1 48.438 (55.256)\n",
            "Epoch: [52][20/97], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.020)\tLoss 0.9597 (0.9958)\tPrec@1 57.812 (56.250)\n",
            "Epoch: [52][30/97], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.015)\tLoss 0.8137 (0.9816)\tPrec@1 66.406 (57.082)\n",
            "Epoch: [52][40/97], lr: 0.01000\tTime 0.068 (0.084)\tData 0.002 (0.011)\tLoss 0.9024 (0.9836)\tPrec@1 64.844 (57.088)\n",
            "Epoch: [52][50/97], lr: 0.01000\tTime 0.060 (0.081)\tData 0.000 (0.010)\tLoss 1.0529 (0.9756)\tPrec@1 54.688 (57.751)\n",
            "Epoch: [52][60/97], lr: 0.01000\tTime 0.073 (0.079)\tData 0.006 (0.009)\tLoss 0.9785 (0.9754)\tPrec@1 56.250 (57.633)\n",
            "Epoch: [52][70/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.003 (0.008)\tLoss 1.0158 (0.9760)\tPrec@1 60.156 (57.735)\n",
            "Epoch: [52][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.001 (0.008)\tLoss 0.9145 (0.9726)\tPrec@1 61.719 (57.967)\n",
            "Epoch: [52][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.008)\tLoss 1.0187 (0.9771)\tPrec@1 59.375 (57.907)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 1.0159 (1.0159)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.034 (0.059)\tLoss 1.0968 (1.0852)\tPrec@1 54.000 (51.000)\n",
            "Test: [20/100]\tTime 0.023 (0.046)\tLoss 1.1670 (1.0667)\tPrec@1 47.000 (52.476)\n",
            "Test: [30/100]\tTime 0.027 (0.041)\tLoss 1.0538 (1.0685)\tPrec@1 50.000 (52.581)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 1.0109 (1.0630)\tPrec@1 55.000 (53.171)\n",
            "Test: [50/100]\tTime 0.039 (0.038)\tLoss 1.0536 (1.0590)\tPrec@1 50.000 (53.333)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1200 (1.0648)\tPrec@1 47.000 (53.000)\n",
            "Test: [70/100]\tTime 0.043 (0.036)\tLoss 1.0310 (1.0659)\tPrec@1 54.000 (53.028)\n",
            "Test: [80/100]\tTime 0.053 (0.035)\tLoss 1.0480 (1.0663)\tPrec@1 55.000 (52.988)\n",
            "Test: [90/100]\tTime 0.041 (0.035)\tLoss 1.0725 (1.0653)\tPrec@1 51.000 (52.989)\n",
            "val Results: Prec@1 53.230 Loss 1.06185\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [53][0/97], lr: 0.01000\tTime 0.455 (0.455)\tData 0.271 (0.271)\tLoss 0.8919 (0.8919)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [53][10/97], lr: 0.01000\tTime 0.065 (0.111)\tData 0.000 (0.027)\tLoss 1.0365 (0.9624)\tPrec@1 54.688 (58.665)\n",
            "Epoch: [53][20/97], lr: 0.01000\tTime 0.072 (0.093)\tData 0.000 (0.015)\tLoss 0.9267 (0.9570)\tPrec@1 57.812 (58.854)\n",
            "Epoch: [53][30/97], lr: 0.01000\tTime 0.075 (0.086)\tData 0.008 (0.010)\tLoss 0.9783 (0.9613)\tPrec@1 57.812 (58.745)\n",
            "Epoch: [53][40/97], lr: 0.01000\tTime 0.076 (0.082)\tData 0.011 (0.009)\tLoss 1.0008 (0.9631)\tPrec@1 58.594 (58.880)\n",
            "Epoch: [53][50/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.007)\tLoss 1.0232 (0.9689)\tPrec@1 57.812 (58.900)\n",
            "Epoch: [53][60/97], lr: 0.01000\tTime 0.073 (0.078)\tData 0.000 (0.007)\tLoss 0.9453 (0.9709)\tPrec@1 59.375 (58.888)\n",
            "Epoch: [53][70/97], lr: 0.01000\tTime 0.080 (0.077)\tData 0.008 (0.006)\tLoss 1.0046 (0.9731)\tPrec@1 53.906 (58.704)\n",
            "Epoch: [53][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.000 (0.006)\tLoss 0.8988 (0.9694)\tPrec@1 64.062 (58.854)\n",
            "Epoch: [53][90/97], lr: 0.01000\tTime 0.056 (0.075)\tData 0.000 (0.006)\tLoss 0.8294 (0.9661)\tPrec@1 67.188 (58.980)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 1.0138 (1.0138)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.066 (0.062)\tLoss 1.0643 (1.0964)\tPrec@1 54.000 (51.455)\n",
            "Test: [20/100]\tTime 0.026 (0.047)\tLoss 1.1623 (1.0829)\tPrec@1 50.000 (52.667)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.1531 (1.0953)\tPrec@1 48.000 (52.355)\n",
            "Test: [40/100]\tTime 0.044 (0.039)\tLoss 1.0446 (1.0875)\tPrec@1 53.000 (52.756)\n",
            "Test: [50/100]\tTime 0.037 (0.038)\tLoss 1.0611 (1.0878)\tPrec@1 56.000 (53.000)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.1373 (1.0901)\tPrec@1 48.000 (52.869)\n",
            "Test: [70/100]\tTime 0.031 (0.036)\tLoss 1.0557 (1.0883)\tPrec@1 58.000 (53.014)\n",
            "Test: [80/100]\tTime 0.022 (0.036)\tLoss 1.0730 (1.0884)\tPrec@1 55.000 (52.864)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.1080 (1.0865)\tPrec@1 56.000 (52.912)\n",
            "val Results: Prec@1 53.090 Loss 1.08177\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [54][0/97], lr: 0.01000\tTime 0.581 (0.581)\tData 0.430 (0.430)\tLoss 0.9386 (0.9386)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [54][10/97], lr: 0.01000\tTime 0.072 (0.118)\tData 0.000 (0.040)\tLoss 1.0230 (0.9411)\tPrec@1 59.375 (60.795)\n",
            "Epoch: [54][20/97], lr: 0.01000\tTime 0.070 (0.098)\tData 0.008 (0.023)\tLoss 0.8866 (0.9442)\tPrec@1 67.188 (60.454)\n",
            "Epoch: [54][30/97], lr: 0.01000\tTime 0.082 (0.089)\tData 0.006 (0.016)\tLoss 0.9035 (0.9471)\tPrec@1 58.594 (60.282)\n",
            "Epoch: [54][40/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.013)\tLoss 1.0814 (0.9508)\tPrec@1 48.438 (60.118)\n",
            "Epoch: [54][50/97], lr: 0.01000\tTime 0.069 (0.082)\tData 0.007 (0.011)\tLoss 0.9494 (0.9521)\tPrec@1 62.500 (60.141)\n",
            "Epoch: [54][60/97], lr: 0.01000\tTime 0.064 (0.080)\tData 0.002 (0.010)\tLoss 1.0101 (0.9522)\tPrec@1 53.906 (59.951)\n",
            "Epoch: [54][70/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.007 (0.009)\tLoss 0.9667 (0.9511)\tPrec@1 57.812 (60.101)\n",
            "Epoch: [54][80/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.009)\tLoss 0.9491 (0.9519)\tPrec@1 60.938 (60.060)\n",
            "Epoch: [54][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.008)\tLoss 0.9463 (0.9530)\tPrec@1 61.719 (59.950)\n",
            "Test: [0/100]\tTime 0.256 (0.256)\tLoss 0.9898 (0.9898)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.033 (0.060)\tLoss 1.0689 (1.0777)\tPrec@1 56.000 (52.182)\n",
            "Test: [20/100]\tTime 0.026 (0.046)\tLoss 1.1793 (1.0697)\tPrec@1 47.000 (53.048)\n",
            "Test: [30/100]\tTime 0.040 (0.041)\tLoss 1.0915 (1.0761)\tPrec@1 51.000 (52.710)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9529 (1.0695)\tPrec@1 58.000 (53.073)\n",
            "Test: [50/100]\tTime 0.059 (0.038)\tLoss 1.0832 (1.0711)\tPrec@1 53.000 (53.235)\n",
            "Test: [60/100]\tTime 0.035 (0.037)\tLoss 1.1496 (1.0762)\tPrec@1 50.000 (53.066)\n",
            "Test: [70/100]\tTime 0.033 (0.036)\tLoss 1.0154 (1.0729)\tPrec@1 51.000 (53.042)\n",
            "Test: [80/100]\tTime 0.029 (0.035)\tLoss 1.0150 (1.0736)\tPrec@1 57.000 (53.198)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0845 (1.0724)\tPrec@1 54.000 (53.253)\n",
            "val Results: Prec@1 53.430 Loss 1.06770\n",
            "Best Prec@1: 53.860\n",
            "\n",
            "Epoch: [55][0/97], lr: 0.01000\tTime 0.541 (0.541)\tData 0.392 (0.392)\tLoss 1.0440 (1.0440)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [55][10/97], lr: 0.01000\tTime 0.066 (0.117)\tData 0.000 (0.039)\tLoss 0.9287 (0.9873)\tPrec@1 61.719 (55.611)\n",
            "Epoch: [55][20/97], lr: 0.01000\tTime 0.082 (0.095)\tData 0.000 (0.021)\tLoss 0.9172 (0.9742)\tPrec@1 62.500 (57.664)\n",
            "Epoch: [55][30/97], lr: 0.01000\tTime 0.075 (0.088)\tData 0.010 (0.016)\tLoss 0.8859 (0.9698)\tPrec@1 60.156 (57.762)\n",
            "Epoch: [55][40/97], lr: 0.01000\tTime 0.079 (0.084)\tData 0.006 (0.013)\tLoss 0.9263 (0.9581)\tPrec@1 65.625 (58.822)\n",
            "Epoch: [55][50/97], lr: 0.01000\tTime 0.077 (0.081)\tData 0.007 (0.011)\tLoss 0.9536 (0.9495)\tPrec@1 57.812 (59.252)\n",
            "Epoch: [55][60/97], lr: 0.01000\tTime 0.071 (0.079)\tData 0.007 (0.010)\tLoss 0.9069 (0.9469)\tPrec@1 60.156 (59.413)\n",
            "Epoch: [55][70/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.009)\tLoss 0.9362 (0.9419)\tPrec@1 55.469 (59.606)\n",
            "Epoch: [55][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.002 (0.008)\tLoss 0.9209 (0.9464)\tPrec@1 62.500 (59.655)\n",
            "Epoch: [55][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.008)\tLoss 0.9543 (0.9494)\tPrec@1 60.938 (59.469)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 0.9898 (0.9898)\tPrec@1 50.000 (50.000)\n",
            "Test: [10/100]\tTime 0.043 (0.060)\tLoss 1.0735 (1.0548)\tPrec@1 59.000 (53.091)\n",
            "Test: [20/100]\tTime 0.039 (0.047)\tLoss 1.1162 (1.0459)\tPrec@1 55.000 (55.000)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 1.1275 (1.0586)\tPrec@1 49.000 (54.226)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9908 (1.0544)\tPrec@1 58.000 (54.561)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 1.0999 (1.0564)\tPrec@1 55.000 (54.765)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1034 (1.0641)\tPrec@1 58.000 (54.803)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.0370 (1.0638)\tPrec@1 53.000 (54.479)\n",
            "Test: [80/100]\tTime 0.047 (0.035)\tLoss 1.0042 (1.0634)\tPrec@1 61.000 (54.457)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.0385 (1.0625)\tPrec@1 61.000 (54.637)\n",
            "val Results: Prec@1 54.890 Loss 1.05914\n",
            "Best Prec@1: 54.890\n",
            "\n",
            "Epoch: [56][0/97], lr: 0.01000\tTime 0.563 (0.563)\tData 0.397 (0.397)\tLoss 1.0330 (1.0330)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [56][10/97], lr: 0.01000\tTime 0.080 (0.120)\tData 0.001 (0.038)\tLoss 0.9240 (0.9748)\tPrec@1 61.719 (59.091)\n",
            "Epoch: [56][20/97], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.021)\tLoss 0.9859 (0.9643)\tPrec@1 57.812 (59.747)\n",
            "Epoch: [56][30/97], lr: 0.01000\tTime 0.068 (0.091)\tData 0.007 (0.015)\tLoss 1.1163 (0.9549)\tPrec@1 52.344 (59.879)\n",
            "Epoch: [56][40/97], lr: 0.01000\tTime 0.124 (0.092)\tData 0.000 (0.012)\tLoss 0.9643 (0.9550)\tPrec@1 62.500 (59.985)\n",
            "Epoch: [56][50/97], lr: 0.01000\tTime 0.091 (0.094)\tData 0.000 (0.011)\tLoss 0.9651 (0.9602)\tPrec@1 57.812 (59.651)\n",
            "Epoch: [56][60/97], lr: 0.01000\tTime 0.103 (0.097)\tData 0.007 (0.010)\tLoss 1.0936 (0.9579)\tPrec@1 51.562 (59.695)\n",
            "Epoch: [56][70/97], lr: 0.01000\tTime 0.115 (0.099)\tData 0.000 (0.009)\tLoss 0.9409 (0.9557)\tPrec@1 59.375 (59.716)\n",
            "Epoch: [56][80/97], lr: 0.01000\tTime 0.070 (0.096)\tData 0.001 (0.009)\tLoss 0.9216 (0.9506)\tPrec@1 60.938 (59.886)\n",
            "Epoch: [56][90/97], lr: 0.01000\tTime 0.056 (0.093)\tData 0.000 (0.008)\tLoss 0.8847 (0.9508)\tPrec@1 63.281 (59.993)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 0.9714 (0.9714)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.026 (0.060)\tLoss 1.0632 (1.0405)\tPrec@1 57.000 (54.636)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 1.1041 (1.0427)\tPrec@1 49.000 (54.048)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0657 (1.0516)\tPrec@1 53.000 (53.516)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9663 (1.0475)\tPrec@1 63.000 (54.098)\n",
            "Test: [50/100]\tTime 0.044 (0.038)\tLoss 1.0422 (1.0477)\tPrec@1 55.000 (54.314)\n",
            "Test: [60/100]\tTime 0.024 (0.036)\tLoss 1.1258 (1.0533)\tPrec@1 51.000 (54.148)\n",
            "Test: [70/100]\tTime 0.040 (0.036)\tLoss 1.0497 (1.0546)\tPrec@1 51.000 (53.817)\n",
            "Test: [80/100]\tTime 0.029 (0.035)\tLoss 1.0020 (1.0550)\tPrec@1 56.000 (53.802)\n",
            "Test: [90/100]\tTime 0.036 (0.035)\tLoss 1.0702 (1.0551)\tPrec@1 53.000 (53.912)\n",
            "val Results: Prec@1 53.940 Loss 1.05344\n",
            "Best Prec@1: 54.890\n",
            "\n",
            "Epoch: [57][0/97], lr: 0.01000\tTime 0.566 (0.566)\tData 0.381 (0.381)\tLoss 0.9420 (0.9420)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [57][10/97], lr: 0.01000\tTime 0.088 (0.120)\tData 0.000 (0.036)\tLoss 0.8933 (0.9249)\tPrec@1 60.938 (60.724)\n",
            "Epoch: [57][20/97], lr: 0.01000\tTime 0.065 (0.095)\tData 0.000 (0.020)\tLoss 0.9891 (0.9486)\tPrec@1 58.594 (59.487)\n",
            "Epoch: [57][30/97], lr: 0.01000\tTime 0.080 (0.088)\tData 0.004 (0.015)\tLoss 0.8735 (0.9465)\tPrec@1 69.531 (59.703)\n",
            "Epoch: [57][40/97], lr: 0.01000\tTime 0.082 (0.084)\tData 0.000 (0.011)\tLoss 0.8287 (0.9419)\tPrec@1 62.500 (60.042)\n",
            "Epoch: [57][50/97], lr: 0.01000\tTime 0.063 (0.082)\tData 0.000 (0.010)\tLoss 0.9767 (0.9428)\tPrec@1 64.844 (60.095)\n",
            "Epoch: [57][60/97], lr: 0.01000\tTime 0.071 (0.080)\tData 0.006 (0.008)\tLoss 0.8730 (0.9366)\tPrec@1 63.281 (60.259)\n",
            "Epoch: [57][70/97], lr: 0.01000\tTime 0.058 (0.078)\tData 0.000 (0.007)\tLoss 0.9939 (0.9429)\tPrec@1 57.031 (59.947)\n",
            "Epoch: [57][80/97], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.006)\tLoss 0.8981 (0.9446)\tPrec@1 64.844 (59.896)\n",
            "Epoch: [57][90/97], lr: 0.01000\tTime 0.046 (0.077)\tData 0.000 (0.006)\tLoss 0.9561 (0.9466)\tPrec@1 61.719 (59.830)\n",
            "Test: [0/100]\tTime 0.260 (0.260)\tLoss 0.9442 (0.9442)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 1.0549 (1.0477)\tPrec@1 62.000 (55.455)\n",
            "Test: [20/100]\tTime 0.035 (0.047)\tLoss 1.1367 (1.0358)\tPrec@1 53.000 (56.571)\n",
            "Test: [30/100]\tTime 0.028 (0.042)\tLoss 1.0723 (1.0416)\tPrec@1 50.000 (55.516)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.9448 (1.0376)\tPrec@1 60.000 (55.585)\n",
            "Test: [50/100]\tTime 0.023 (0.038)\tLoss 1.0666 (1.0379)\tPrec@1 54.000 (55.647)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.0515 (1.0423)\tPrec@1 57.000 (55.738)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.0812 (1.0428)\tPrec@1 52.000 (55.704)\n",
            "Test: [80/100]\tTime 0.027 (0.036)\tLoss 0.9803 (1.0437)\tPrec@1 62.000 (55.580)\n",
            "Test: [90/100]\tTime 0.043 (0.035)\tLoss 1.0177 (1.0428)\tPrec@1 56.000 (55.527)\n",
            "val Results: Prec@1 55.790 Loss 1.03774\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [58][0/97], lr: 0.01000\tTime 0.549 (0.549)\tData 0.343 (0.343)\tLoss 0.8616 (0.8616)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [58][10/97], lr: 0.01000\tTime 0.066 (0.121)\tData 0.000 (0.033)\tLoss 0.8346 (0.9196)\tPrec@1 71.875 (62.287)\n",
            "Epoch: [58][20/97], lr: 0.01000\tTime 0.060 (0.097)\tData 0.000 (0.019)\tLoss 0.9279 (0.9373)\tPrec@1 63.281 (61.756)\n",
            "Epoch: [58][30/97], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.013)\tLoss 0.8335 (0.9421)\tPrec@1 67.188 (61.164)\n",
            "Epoch: [58][40/97], lr: 0.01000\tTime 0.064 (0.084)\tData 0.002 (0.010)\tLoss 1.0478 (0.9479)\tPrec@1 53.906 (60.461)\n",
            "Epoch: [58][50/97], lr: 0.01000\tTime 0.065 (0.083)\tData 0.000 (0.009)\tLoss 1.0243 (0.9425)\tPrec@1 58.594 (60.754)\n",
            "Epoch: [58][60/97], lr: 0.01000\tTime 0.063 (0.096)\tData 0.000 (0.008)\tLoss 0.9806 (0.9437)\tPrec@1 64.844 (60.681)\n",
            "Epoch: [58][70/97], lr: 0.01000\tTime 0.084 (0.092)\tData 0.000 (0.007)\tLoss 1.0284 (0.9431)\tPrec@1 52.344 (60.563)\n",
            "Epoch: [58][80/97], lr: 0.01000\tTime 0.062 (0.090)\tData 0.000 (0.007)\tLoss 0.9379 (0.9425)\tPrec@1 59.375 (60.397)\n",
            "Epoch: [58][90/97], lr: 0.01000\tTime 0.055 (0.087)\tData 0.000 (0.006)\tLoss 1.1034 (0.9428)\tPrec@1 58.594 (60.646)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 1.0305 (1.0305)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.023 (0.060)\tLoss 1.1170 (1.0906)\tPrec@1 55.000 (53.091)\n",
            "Test: [20/100]\tTime 0.025 (0.045)\tLoss 1.2235 (1.0747)\tPrec@1 46.000 (53.762)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 1.1402 (1.0925)\tPrec@1 50.000 (53.032)\n",
            "Test: [40/100]\tTime 0.038 (0.039)\tLoss 0.9849 (1.0877)\tPrec@1 61.000 (53.463)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 1.1480 (1.0859)\tPrec@1 48.000 (53.490)\n",
            "Test: [60/100]\tTime 0.043 (0.036)\tLoss 1.1309 (1.0917)\tPrec@1 50.000 (53.197)\n",
            "Test: [70/100]\tTime 0.028 (0.035)\tLoss 1.0533 (1.0913)\tPrec@1 53.000 (52.930)\n",
            "Test: [80/100]\tTime 0.052 (0.035)\tLoss 1.0187 (1.0915)\tPrec@1 52.000 (52.691)\n",
            "Test: [90/100]\tTime 0.029 (0.034)\tLoss 1.0778 (1.0886)\tPrec@1 54.000 (52.890)\n",
            "val Results: Prec@1 53.040 Loss 1.08525\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [59][0/97], lr: 0.01000\tTime 0.550 (0.550)\tData 0.350 (0.350)\tLoss 0.8850 (0.8850)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [59][10/97], lr: 0.01000\tTime 0.071 (0.120)\tData 0.000 (0.034)\tLoss 0.8222 (0.9213)\tPrec@1 62.500 (60.653)\n",
            "Epoch: [59][20/97], lr: 0.01000\tTime 0.085 (0.098)\tData 0.011 (0.019)\tLoss 0.9479 (0.9442)\tPrec@1 54.688 (59.970)\n",
            "Epoch: [59][30/97], lr: 0.01000\tTime 0.060 (0.088)\tData 0.000 (0.014)\tLoss 0.8508 (0.9493)\tPrec@1 69.531 (59.904)\n",
            "Epoch: [59][40/97], lr: 0.01000\tTime 0.076 (0.084)\tData 0.012 (0.011)\tLoss 0.9846 (0.9476)\tPrec@1 55.469 (59.680)\n",
            "Epoch: [59][50/97], lr: 0.01000\tTime 0.058 (0.082)\tData 0.000 (0.009)\tLoss 1.0920 (0.9516)\tPrec@1 50.781 (59.482)\n",
            "Epoch: [59][60/97], lr: 0.01000\tTime 0.082 (0.080)\tData 0.000 (0.008)\tLoss 0.9093 (0.9448)\tPrec@1 60.938 (59.670)\n",
            "Epoch: [59][70/97], lr: 0.01000\tTime 0.083 (0.079)\tData 0.000 (0.008)\tLoss 0.8432 (0.9485)\tPrec@1 67.188 (59.705)\n",
            "Epoch: [59][80/97], lr: 0.01000\tTime 0.075 (0.077)\tData 0.000 (0.007)\tLoss 0.8720 (0.9465)\tPrec@1 57.812 (59.674)\n",
            "Epoch: [59][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.006)\tLoss 1.0431 (0.9447)\tPrec@1 50.000 (59.718)\n",
            "Test: [0/100]\tTime 0.268 (0.268)\tLoss 0.9462 (0.9462)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.030 (0.060)\tLoss 1.0922 (1.0614)\tPrec@1 51.000 (54.727)\n",
            "Test: [20/100]\tTime 0.021 (0.045)\tLoss 1.1318 (1.0408)\tPrec@1 52.000 (56.143)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0679 (1.0511)\tPrec@1 50.000 (54.645)\n",
            "Test: [40/100]\tTime 0.028 (0.039)\tLoss 0.9773 (1.0442)\tPrec@1 53.000 (54.902)\n",
            "Test: [50/100]\tTime 0.035 (0.037)\tLoss 1.0468 (1.0449)\tPrec@1 56.000 (55.176)\n",
            "Test: [60/100]\tTime 0.037 (0.037)\tLoss 1.1258 (1.0512)\tPrec@1 52.000 (55.164)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.0116 (1.0501)\tPrec@1 55.000 (55.155)\n",
            "Test: [80/100]\tTime 0.021 (0.035)\tLoss 1.0178 (1.0517)\tPrec@1 56.000 (55.074)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.1026 (1.0511)\tPrec@1 54.000 (55.077)\n",
            "val Results: Prec@1 55.190 Loss 1.04767\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [60][0/97], lr: 0.01000\tTime 0.524 (0.524)\tData 0.308 (0.308)\tLoss 0.9599 (0.9599)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [60][10/97], lr: 0.01000\tTime 0.064 (0.123)\tData 0.000 (0.033)\tLoss 1.0342 (0.9623)\tPrec@1 53.125 (58.523)\n",
            "Epoch: [60][20/97], lr: 0.01000\tTime 0.061 (0.097)\tData 0.000 (0.018)\tLoss 0.9698 (0.9416)\tPrec@1 57.812 (59.487)\n",
            "Epoch: [60][30/97], lr: 0.01000\tTime 0.079 (0.090)\tData 0.006 (0.014)\tLoss 0.9363 (0.9374)\tPrec@1 62.500 (59.526)\n",
            "Epoch: [60][40/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.006 (0.011)\tLoss 1.0153 (0.9401)\tPrec@1 57.812 (59.470)\n",
            "Epoch: [60][50/97], lr: 0.01000\tTime 0.076 (0.083)\tData 0.006 (0.010)\tLoss 0.9734 (0.9389)\tPrec@1 53.906 (59.605)\n",
            "Epoch: [60][60/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.003 (0.009)\tLoss 0.8694 (0.9312)\tPrec@1 64.062 (60.169)\n",
            "Epoch: [60][70/97], lr: 0.01000\tTime 0.086 (0.080)\tData 0.009 (0.008)\tLoss 0.8478 (0.9345)\tPrec@1 69.531 (60.167)\n",
            "Epoch: [60][80/97], lr: 0.01000\tTime 0.093 (0.079)\tData 0.007 (0.007)\tLoss 0.9352 (0.9356)\tPrec@1 59.375 (60.041)\n",
            "Epoch: [60][90/97], lr: 0.01000\tTime 0.050 (0.077)\tData 0.000 (0.007)\tLoss 0.9051 (0.9365)\tPrec@1 65.625 (59.967)\n",
            "Test: [0/100]\tTime 0.250 (0.250)\tLoss 0.9668 (0.9668)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.037 (0.059)\tLoss 1.0519 (1.0682)\tPrec@1 54.000 (52.182)\n",
            "Test: [20/100]\tTime 0.048 (0.046)\tLoss 1.1122 (1.0515)\tPrec@1 53.000 (54.095)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 1.0818 (1.0625)\tPrec@1 45.000 (53.161)\n",
            "Test: [40/100]\tTime 0.023 (0.038)\tLoss 0.9866 (1.0544)\tPrec@1 60.000 (54.024)\n",
            "Test: [50/100]\tTime 0.038 (0.037)\tLoss 1.0958 (1.0555)\tPrec@1 52.000 (54.216)\n",
            "Test: [60/100]\tTime 0.034 (0.036)\tLoss 1.1233 (1.0622)\tPrec@1 47.000 (54.393)\n",
            "Test: [70/100]\tTime 0.045 (0.035)\tLoss 1.0702 (1.0625)\tPrec@1 53.000 (54.451)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 0.9920 (1.0631)\tPrec@1 58.000 (54.481)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.0445 (1.0607)\tPrec@1 57.000 (54.538)\n",
            "val Results: Prec@1 54.770 Loss 1.05629\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [61][0/97], lr: 0.01000\tTime 0.537 (0.537)\tData 0.376 (0.376)\tLoss 0.9231 (0.9231)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [61][10/97], lr: 0.01000\tTime 0.069 (0.115)\tData 0.000 (0.037)\tLoss 0.9543 (0.9450)\tPrec@1 59.375 (60.156)\n",
            "Epoch: [61][20/97], lr: 0.01000\tTime 0.064 (0.094)\tData 0.000 (0.020)\tLoss 0.8465 (0.9488)\tPrec@1 64.062 (59.673)\n",
            "Epoch: [61][30/97], lr: 0.01000\tTime 0.071 (0.087)\tData 0.004 (0.015)\tLoss 0.9077 (0.9358)\tPrec@1 61.719 (60.358)\n",
            "Epoch: [61][40/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.012)\tLoss 0.8472 (0.9402)\tPrec@1 63.281 (59.794)\n",
            "Epoch: [61][50/97], lr: 0.01000\tTime 0.069 (0.081)\tData 0.000 (0.010)\tLoss 1.0787 (0.9394)\tPrec@1 57.031 (60.141)\n",
            "Epoch: [61][60/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.009)\tLoss 0.8974 (0.9408)\tPrec@1 60.156 (60.118)\n",
            "Epoch: [61][70/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.000 (0.007)\tLoss 0.9248 (0.9422)\tPrec@1 62.500 (60.321)\n",
            "Epoch: [61][80/97], lr: 0.01000\tTime 0.068 (0.077)\tData 0.006 (0.007)\tLoss 0.8676 (0.9390)\tPrec@1 60.938 (60.330)\n",
            "Epoch: [61][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 1.0143 (0.9411)\tPrec@1 61.719 (60.199)\n",
            "Test: [0/100]\tTime 0.318 (0.318)\tLoss 0.9247 (0.9247)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 1.0442 (1.0537)\tPrec@1 56.000 (54.818)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 1.1637 (1.0484)\tPrec@1 49.000 (55.190)\n",
            "Test: [30/100]\tTime 0.029 (0.042)\tLoss 1.0658 (1.0523)\tPrec@1 55.000 (54.935)\n",
            "Test: [40/100]\tTime 0.029 (0.039)\tLoss 0.9811 (1.0504)\tPrec@1 62.000 (54.707)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 1.0957 (1.0489)\tPrec@1 53.000 (54.882)\n",
            "Test: [60/100]\tTime 0.030 (0.037)\tLoss 1.1639 (1.0527)\tPrec@1 48.000 (54.787)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 0.9985 (1.0530)\tPrec@1 54.000 (54.676)\n",
            "Test: [80/100]\tTime 0.069 (0.036)\tLoss 1.0033 (1.0506)\tPrec@1 55.000 (54.790)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.0483 (1.0479)\tPrec@1 56.000 (54.813)\n",
            "val Results: Prec@1 54.990 Loss 1.04369\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [62][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.354 (0.354)\tLoss 0.9093 (0.9093)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [62][10/97], lr: 0.01000\tTime 0.064 (0.117)\tData 0.000 (0.035)\tLoss 0.8718 (0.9170)\tPrec@1 65.625 (61.790)\n",
            "Epoch: [62][20/97], lr: 0.01000\tTime 0.065 (0.096)\tData 0.000 (0.019)\tLoss 0.8164 (0.9034)\tPrec@1 63.281 (60.938)\n",
            "Epoch: [62][30/97], lr: 0.01000\tTime 0.062 (0.087)\tData 0.000 (0.014)\tLoss 0.9408 (0.9188)\tPrec@1 61.719 (60.811)\n",
            "Epoch: [62][40/97], lr: 0.01000\tTime 0.064 (0.084)\tData 0.000 (0.011)\tLoss 1.0470 (0.9217)\tPrec@1 53.125 (60.480)\n",
            "Epoch: [62][50/97], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.009)\tLoss 0.8149 (0.9228)\tPrec@1 67.969 (60.769)\n",
            "Epoch: [62][60/97], lr: 0.01000\tTime 0.072 (0.080)\tData 0.007 (0.009)\tLoss 0.8749 (0.9202)\tPrec@1 66.406 (61.219)\n",
            "Epoch: [62][70/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.008)\tLoss 0.9233 (0.9285)\tPrec@1 64.062 (60.938)\n",
            "Epoch: [62][80/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.004 (0.007)\tLoss 0.8929 (0.9319)\tPrec@1 65.625 (60.793)\n",
            "Epoch: [62][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.9050 (0.9331)\tPrec@1 61.719 (60.740)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 0.9380 (0.9380)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.025 (0.060)\tLoss 1.0617 (1.0728)\tPrec@1 56.000 (54.636)\n",
            "Test: [20/100]\tTime 0.050 (0.046)\tLoss 1.1857 (1.0688)\tPrec@1 51.000 (55.000)\n",
            "Test: [30/100]\tTime 0.027 (0.041)\tLoss 1.1542 (1.0865)\tPrec@1 55.000 (53.903)\n",
            "Test: [40/100]\tTime 0.043 (0.039)\tLoss 1.0153 (1.0759)\tPrec@1 53.000 (54.293)\n",
            "Test: [50/100]\tTime 0.030 (0.037)\tLoss 1.1559 (1.0795)\tPrec@1 54.000 (54.392)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 1.1711 (1.0864)\tPrec@1 51.000 (54.377)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.1004 (1.0880)\tPrec@1 54.000 (54.282)\n",
            "Test: [80/100]\tTime 0.027 (0.035)\tLoss 1.0365 (1.0912)\tPrec@1 57.000 (54.222)\n",
            "Test: [90/100]\tTime 0.022 (0.034)\tLoss 1.1602 (1.0920)\tPrec@1 51.000 (54.264)\n",
            "val Results: Prec@1 54.320 Loss 1.08746\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [63][0/97], lr: 0.01000\tTime 0.485 (0.485)\tData 0.284 (0.284)\tLoss 1.0506 (1.0506)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [63][10/97], lr: 0.01000\tTime 0.063 (0.114)\tData 0.000 (0.028)\tLoss 0.8393 (0.9640)\tPrec@1 67.188 (59.233)\n",
            "Epoch: [63][20/97], lr: 0.01000\tTime 0.077 (0.095)\tData 0.007 (0.016)\tLoss 1.0272 (0.9572)\tPrec@1 56.250 (60.603)\n",
            "Epoch: [63][30/97], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.011)\tLoss 0.8746 (0.9394)\tPrec@1 64.844 (60.484)\n",
            "Epoch: [63][40/97], lr: 0.01000\tTime 0.077 (0.083)\tData 0.004 (0.009)\tLoss 0.9364 (0.9307)\tPrec@1 67.188 (60.880)\n",
            "Epoch: [63][50/97], lr: 0.01000\tTime 0.108 (0.085)\tData 0.000 (0.008)\tLoss 0.8425 (0.9260)\tPrec@1 68.750 (60.861)\n",
            "Epoch: [63][60/97], lr: 0.01000\tTime 0.072 (0.085)\tData 0.007 (0.007)\tLoss 1.0635 (0.9338)\tPrec@1 54.688 (60.540)\n",
            "Epoch: [63][70/97], lr: 0.01000\tTime 0.088 (0.086)\tData 0.000 (0.007)\tLoss 0.8226 (0.9296)\tPrec@1 65.625 (60.739)\n",
            "Epoch: [63][80/97], lr: 0.01000\tTime 0.060 (0.085)\tData 0.000 (0.006)\tLoss 0.9467 (0.9284)\tPrec@1 59.375 (60.745)\n",
            "Epoch: [63][90/97], lr: 0.01000\tTime 0.059 (0.084)\tData 0.000 (0.006)\tLoss 1.0109 (0.9312)\tPrec@1 55.469 (60.517)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 0.9724 (0.9724)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.020 (0.060)\tLoss 1.0729 (1.0359)\tPrec@1 54.000 (54.091)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 1.1263 (1.0233)\tPrec@1 54.000 (55.476)\n",
            "Test: [30/100]\tTime 0.039 (0.043)\tLoss 1.0810 (1.0379)\tPrec@1 47.000 (54.161)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.9699 (1.0371)\tPrec@1 59.000 (54.488)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.0240 (1.0383)\tPrec@1 55.000 (54.843)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1347 (1.0429)\tPrec@1 53.000 (55.016)\n",
            "Test: [70/100]\tTime 0.027 (0.039)\tLoss 1.0052 (1.0432)\tPrec@1 59.000 (54.915)\n",
            "Test: [80/100]\tTime 0.039 (0.038)\tLoss 1.0069 (1.0441)\tPrec@1 61.000 (55.049)\n",
            "Test: [90/100]\tTime 0.033 (0.038)\tLoss 1.0287 (1.0422)\tPrec@1 60.000 (55.077)\n",
            "val Results: Prec@1 55.320 Loss 1.03765\n",
            "Best Prec@1: 55.790\n",
            "\n",
            "Epoch: [64][0/97], lr: 0.01000\tTime 0.560 (0.560)\tData 0.333 (0.333)\tLoss 0.9312 (0.9312)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [64][10/97], lr: 0.01000\tTime 0.076 (0.120)\tData 0.007 (0.032)\tLoss 1.0354 (0.9233)\tPrec@1 55.469 (60.369)\n",
            "Epoch: [64][20/97], lr: 0.01000\tTime 0.063 (0.095)\tData 0.000 (0.019)\tLoss 1.1567 (0.9460)\tPrec@1 50.781 (59.635)\n",
            "Epoch: [64][30/97], lr: 0.01000\tTime 0.078 (0.089)\tData 0.004 (0.014)\tLoss 0.8965 (0.9486)\tPrec@1 64.062 (60.005)\n",
            "Epoch: [64][40/97], lr: 0.01000\tTime 0.076 (0.085)\tData 0.007 (0.012)\tLoss 1.0048 (0.9467)\tPrec@1 55.469 (59.585)\n",
            "Epoch: [64][50/97], lr: 0.01000\tTime 0.065 (0.082)\tData 0.001 (0.010)\tLoss 0.8894 (0.9398)\tPrec@1 60.156 (59.896)\n",
            "Epoch: [64][60/97], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.009)\tLoss 0.9835 (0.9381)\tPrec@1 57.812 (60.003)\n",
            "Epoch: [64][70/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.006 (0.008)\tLoss 0.9090 (0.9354)\tPrec@1 59.375 (60.233)\n",
            "Epoch: [64][80/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.002 (0.008)\tLoss 0.8115 (0.9331)\tPrec@1 64.062 (60.330)\n",
            "Epoch: [64][90/97], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.007)\tLoss 0.9748 (0.9312)\tPrec@1 58.594 (60.491)\n",
            "Test: [0/100]\tTime 0.383 (0.383)\tLoss 0.9382 (0.9382)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.036 (0.066)\tLoss 1.0527 (1.0353)\tPrec@1 56.000 (56.455)\n",
            "Test: [20/100]\tTime 0.046 (0.052)\tLoss 1.1419 (1.0260)\tPrec@1 56.000 (56.476)\n",
            "Test: [30/100]\tTime 0.022 (0.048)\tLoss 1.0987 (1.0310)\tPrec@1 51.000 (55.645)\n",
            "Test: [40/100]\tTime 0.035 (0.045)\tLoss 0.9951 (1.0253)\tPrec@1 53.000 (55.805)\n",
            "Test: [50/100]\tTime 0.043 (0.044)\tLoss 1.0032 (1.0253)\tPrec@1 61.000 (56.078)\n",
            "Test: [60/100]\tTime 0.048 (0.042)\tLoss 1.1599 (1.0322)\tPrec@1 44.000 (55.902)\n",
            "Test: [70/100]\tTime 0.024 (0.040)\tLoss 1.0555 (1.0342)\tPrec@1 53.000 (55.775)\n",
            "Test: [80/100]\tTime 0.034 (0.039)\tLoss 0.9966 (1.0344)\tPrec@1 57.000 (55.728)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 1.0244 (1.0313)\tPrec@1 61.000 (55.923)\n",
            "val Results: Prec@1 56.220 Loss 1.02636\n",
            "Best Prec@1: 56.220\n",
            "\n",
            "Epoch: [65][0/97], lr: 0.01000\tTime 0.508 (0.508)\tData 0.386 (0.386)\tLoss 0.9039 (0.9039)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [65][10/97], lr: 0.01000\tTime 0.065 (0.115)\tData 0.000 (0.036)\tLoss 0.9095 (0.9465)\tPrec@1 61.719 (58.949)\n",
            "Epoch: [65][20/97], lr: 0.01000\tTime 0.087 (0.096)\tData 0.007 (0.020)\tLoss 0.8735 (0.9421)\tPrec@1 67.969 (59.970)\n",
            "Epoch: [65][30/97], lr: 0.01000\tTime 0.071 (0.087)\tData 0.000 (0.014)\tLoss 0.9135 (0.9336)\tPrec@1 64.062 (60.685)\n",
            "Epoch: [65][40/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.011)\tLoss 0.8762 (0.9282)\tPrec@1 63.281 (60.499)\n",
            "Epoch: [65][50/97], lr: 0.01000\tTime 0.089 (0.081)\tData 0.001 (0.009)\tLoss 0.9862 (0.9278)\tPrec@1 60.156 (60.754)\n",
            "Epoch: [65][60/97], lr: 0.01000\tTime 0.076 (0.080)\tData 0.000 (0.007)\tLoss 1.1415 (0.9322)\tPrec@1 53.125 (60.592)\n",
            "Epoch: [65][70/97], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.007)\tLoss 1.1210 (0.9351)\tPrec@1 45.312 (60.376)\n",
            "Epoch: [65][80/97], lr: 0.01000\tTime 0.061 (0.077)\tData 0.000 (0.006)\tLoss 0.8836 (0.9285)\tPrec@1 63.281 (60.909)\n",
            "Epoch: [65][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.005)\tLoss 0.9320 (0.9285)\tPrec@1 61.719 (61.032)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 0.9343 (0.9343)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.062 (0.070)\tLoss 0.9827 (1.0236)\tPrec@1 58.000 (56.273)\n",
            "Test: [20/100]\tTime 0.043 (0.052)\tLoss 1.1075 (1.0146)\tPrec@1 53.000 (57.190)\n",
            "Test: [30/100]\tTime 0.047 (0.048)\tLoss 1.0509 (1.0205)\tPrec@1 53.000 (56.355)\n",
            "Test: [40/100]\tTime 0.030 (0.045)\tLoss 1.0035 (1.0202)\tPrec@1 59.000 (56.049)\n",
            "Test: [50/100]\tTime 0.064 (0.043)\tLoss 1.0438 (1.0227)\tPrec@1 55.000 (55.941)\n",
            "Test: [60/100]\tTime 0.048 (0.042)\tLoss 1.1404 (1.0282)\tPrec@1 45.000 (55.672)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.0222 (1.0308)\tPrec@1 54.000 (55.437)\n",
            "Test: [80/100]\tTime 0.024 (0.041)\tLoss 0.9296 (1.0282)\tPrec@1 62.000 (55.630)\n",
            "Test: [90/100]\tTime 0.023 (0.040)\tLoss 1.0217 (1.0250)\tPrec@1 59.000 (55.879)\n",
            "val Results: Prec@1 56.060 Loss 1.02123\n",
            "Best Prec@1: 56.220\n",
            "\n",
            "Epoch: [66][0/97], lr: 0.01000\tTime 0.548 (0.548)\tData 0.374 (0.374)\tLoss 0.8669 (0.8669)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [66][10/97], lr: 0.01000\tTime 0.072 (0.116)\tData 0.006 (0.039)\tLoss 0.9679 (0.9299)\tPrec@1 57.812 (59.659)\n",
            "Epoch: [66][20/97], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.022)\tLoss 0.9055 (0.9297)\tPrec@1 57.812 (59.673)\n",
            "Epoch: [66][30/97], lr: 0.01000\tTime 0.065 (0.088)\tData 0.003 (0.016)\tLoss 0.9093 (0.9130)\tPrec@1 57.812 (60.711)\n",
            "Epoch: [66][40/97], lr: 0.01000\tTime 0.077 (0.088)\tData 0.006 (0.013)\tLoss 1.0132 (0.9077)\tPrec@1 59.375 (61.071)\n",
            "Epoch: [66][50/97], lr: 0.01000\tTime 0.070 (0.087)\tData 0.000 (0.011)\tLoss 0.9688 (0.9167)\tPrec@1 63.281 (60.754)\n",
            "Epoch: [66][60/97], lr: 0.01000\tTime 0.122 (0.087)\tData 0.014 (0.009)\tLoss 0.9756 (0.9189)\tPrec@1 58.594 (60.669)\n",
            "Epoch: [66][70/97], lr: 0.01000\tTime 0.091 (0.088)\tData 0.004 (0.009)\tLoss 0.9037 (0.9161)\tPrec@1 60.156 (60.761)\n",
            "Epoch: [66][80/97], lr: 0.01000\tTime 0.061 (0.087)\tData 0.000 (0.008)\tLoss 0.8396 (0.9199)\tPrec@1 68.750 (60.947)\n",
            "Epoch: [66][90/97], lr: 0.01000\tTime 0.055 (0.085)\tData 0.000 (0.007)\tLoss 0.8032 (0.9218)\tPrec@1 70.312 (60.920)\n",
            "Test: [0/100]\tTime 0.292 (0.292)\tLoss 0.9539 (0.9539)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.055 (0.064)\tLoss 1.0280 (1.0497)\tPrec@1 59.000 (55.818)\n",
            "Test: [20/100]\tTime 0.034 (0.049)\tLoss 1.1622 (1.0473)\tPrec@1 50.000 (56.143)\n",
            "Test: [30/100]\tTime 0.030 (0.043)\tLoss 1.0957 (1.0503)\tPrec@1 54.000 (55.387)\n",
            "Test: [40/100]\tTime 0.028 (0.041)\tLoss 0.9279 (1.0461)\tPrec@1 59.000 (55.390)\n",
            "Test: [50/100]\tTime 0.037 (0.039)\tLoss 1.0399 (1.0463)\tPrec@1 55.000 (55.549)\n",
            "Test: [60/100]\tTime 0.029 (0.038)\tLoss 1.0689 (1.0490)\tPrec@1 53.000 (55.574)\n",
            "Test: [70/100]\tTime 0.045 (0.037)\tLoss 1.0262 (1.0487)\tPrec@1 54.000 (55.423)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 1.0225 (1.0466)\tPrec@1 58.000 (55.457)\n",
            "Test: [90/100]\tTime 0.032 (0.036)\tLoss 1.0287 (1.0430)\tPrec@1 59.000 (55.714)\n",
            "val Results: Prec@1 55.760 Loss 1.04015\n",
            "Best Prec@1: 56.220\n",
            "\n",
            "Epoch: [67][0/97], lr: 0.01000\tTime 0.462 (0.462)\tData 0.278 (0.278)\tLoss 0.9794 (0.9794)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [67][10/97], lr: 0.01000\tTime 0.064 (0.111)\tData 0.000 (0.028)\tLoss 0.8941 (0.9149)\tPrec@1 58.594 (60.511)\n",
            "Epoch: [67][20/97], lr: 0.01000\tTime 0.070 (0.092)\tData 0.004 (0.016)\tLoss 0.8537 (0.9074)\tPrec@1 61.719 (60.603)\n",
            "Epoch: [67][30/97], lr: 0.01000\tTime 0.070 (0.085)\tData 0.005 (0.011)\tLoss 1.0036 (0.9127)\tPrec@1 55.469 (61.139)\n",
            "Epoch: [67][40/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.009)\tLoss 0.8196 (0.9165)\tPrec@1 65.625 (61.147)\n",
            "Epoch: [67][50/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.008)\tLoss 1.0543 (0.9187)\tPrec@1 57.812 (61.474)\n",
            "Epoch: [67][60/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.007)\tLoss 0.8082 (0.9156)\tPrec@1 66.406 (61.335)\n",
            "Epoch: [67][70/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.004 (0.007)\tLoss 0.8822 (0.9123)\tPrec@1 63.281 (61.752)\n",
            "Epoch: [67][80/97], lr: 0.01000\tTime 0.085 (0.076)\tData 0.002 (0.006)\tLoss 0.9659 (0.9139)\tPrec@1 63.281 (61.661)\n",
            "Epoch: [67][90/97], lr: 0.01000\tTime 0.056 (0.075)\tData 0.000 (0.006)\tLoss 0.9545 (0.9150)\tPrec@1 56.250 (61.616)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.9214 (0.9214)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.020 (0.059)\tLoss 1.0774 (1.0277)\tPrec@1 58.000 (56.818)\n",
            "Test: [20/100]\tTime 0.043 (0.047)\tLoss 1.1215 (1.0208)\tPrec@1 54.000 (57.238)\n",
            "Test: [30/100]\tTime 0.033 (0.041)\tLoss 0.9495 (1.0315)\tPrec@1 62.000 (56.516)\n",
            "Test: [40/100]\tTime 0.021 (0.038)\tLoss 0.9646 (1.0288)\tPrec@1 62.000 (56.537)\n",
            "Test: [50/100]\tTime 0.030 (0.037)\tLoss 1.0217 (1.0292)\tPrec@1 56.000 (56.627)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.1071 (1.0341)\tPrec@1 47.000 (56.213)\n",
            "Test: [70/100]\tTime 0.024 (0.035)\tLoss 1.0050 (1.0341)\tPrec@1 60.000 (56.099)\n",
            "Test: [80/100]\tTime 0.021 (0.035)\tLoss 0.9721 (1.0344)\tPrec@1 59.000 (56.198)\n",
            "Test: [90/100]\tTime 0.041 (0.034)\tLoss 1.0785 (1.0321)\tPrec@1 55.000 (56.319)\n",
            "val Results: Prec@1 56.460 Loss 1.02880\n",
            "Best Prec@1: 56.460\n",
            "\n",
            "Epoch: [68][0/97], lr: 0.01000\tTime 0.491 (0.491)\tData 0.291 (0.291)\tLoss 1.0898 (1.0898)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [68][10/97], lr: 0.01000\tTime 0.067 (0.116)\tData 0.000 (0.029)\tLoss 0.9094 (0.9128)\tPrec@1 60.938 (60.440)\n",
            "Epoch: [68][20/97], lr: 0.01000\tTime 0.060 (0.093)\tData 0.000 (0.016)\tLoss 0.8572 (0.9027)\tPrec@1 63.281 (61.012)\n",
            "Epoch: [68][30/97], lr: 0.01000\tTime 0.064 (0.085)\tData 0.000 (0.011)\tLoss 1.0410 (0.9149)\tPrec@1 53.906 (60.635)\n",
            "Epoch: [68][40/97], lr: 0.01000\tTime 0.080 (0.082)\tData 0.000 (0.009)\tLoss 1.0618 (0.9256)\tPrec@1 56.250 (60.156)\n",
            "Epoch: [68][50/97], lr: 0.01000\tTime 0.088 (0.080)\tData 0.009 (0.007)\tLoss 0.8191 (0.9210)\tPrec@1 67.188 (60.386)\n",
            "Epoch: [68][60/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.006)\tLoss 0.8466 (0.9205)\tPrec@1 65.625 (60.643)\n",
            "Epoch: [68][70/97], lr: 0.01000\tTime 0.069 (0.077)\tData 0.007 (0.006)\tLoss 0.8155 (0.9145)\tPrec@1 61.719 (60.915)\n",
            "Epoch: [68][80/97], lr: 0.01000\tTime 0.076 (0.077)\tData 0.011 (0.006)\tLoss 0.8619 (0.9172)\tPrec@1 61.719 (60.793)\n",
            "Epoch: [68][90/97], lr: 0.01000\tTime 0.055 (0.075)\tData 0.000 (0.005)\tLoss 0.8868 (0.9165)\tPrec@1 66.406 (60.972)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 0.9336 (0.9336)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 1.0478 (1.0330)\tPrec@1 51.000 (54.545)\n",
            "Test: [20/100]\tTime 0.023 (0.048)\tLoss 1.1127 (1.0292)\tPrec@1 57.000 (55.714)\n",
            "Test: [30/100]\tTime 0.034 (0.042)\tLoss 1.1100 (1.0415)\tPrec@1 54.000 (54.806)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.9800 (1.0379)\tPrec@1 56.000 (55.024)\n",
            "Test: [50/100]\tTime 0.023 (0.039)\tLoss 1.0172 (1.0395)\tPrec@1 55.000 (55.157)\n",
            "Test: [60/100]\tTime 0.035 (0.037)\tLoss 1.1470 (1.0435)\tPrec@1 48.000 (55.180)\n",
            "Test: [70/100]\tTime 0.029 (0.037)\tLoss 1.0479 (1.0415)\tPrec@1 51.000 (55.000)\n",
            "Test: [80/100]\tTime 0.030 (0.036)\tLoss 0.9310 (1.0404)\tPrec@1 62.000 (54.951)\n",
            "Test: [90/100]\tTime 0.024 (0.036)\tLoss 1.0383 (1.0385)\tPrec@1 55.000 (55.055)\n",
            "val Results: Prec@1 55.400 Loss 1.03581\n",
            "Best Prec@1: 56.460\n",
            "\n",
            "Epoch: [69][0/97], lr: 0.01000\tTime 0.532 (0.532)\tData 0.370 (0.370)\tLoss 0.8814 (0.8814)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [69][10/97], lr: 0.01000\tTime 0.082 (0.117)\tData 0.007 (0.036)\tLoss 0.8889 (0.8854)\tPrec@1 60.938 (63.281)\n",
            "Epoch: [69][20/97], lr: 0.01000\tTime 0.063 (0.096)\tData 0.000 (0.020)\tLoss 0.8310 (0.8917)\tPrec@1 64.844 (62.612)\n",
            "Epoch: [69][30/97], lr: 0.01000\tTime 0.062 (0.088)\tData 0.000 (0.015)\tLoss 0.9265 (0.9068)\tPrec@1 60.156 (61.517)\n",
            "Epoch: [69][40/97], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.012)\tLoss 0.9004 (0.9105)\tPrec@1 60.938 (60.880)\n",
            "Epoch: [69][50/97], lr: 0.01000\tTime 0.069 (0.081)\tData 0.005 (0.011)\tLoss 0.8417 (0.9124)\tPrec@1 63.281 (61.045)\n",
            "Epoch: [69][60/97], lr: 0.01000\tTime 0.103 (0.080)\tData 0.003 (0.010)\tLoss 0.9276 (0.9148)\tPrec@1 60.938 (60.809)\n",
            "Epoch: [69][70/97], lr: 0.01000\tTime 0.151 (0.083)\tData 0.007 (0.009)\tLoss 0.9021 (0.9146)\tPrec@1 58.594 (60.993)\n",
            "Epoch: [69][80/97], lr: 0.01000\tTime 0.067 (0.086)\tData 0.000 (0.009)\tLoss 0.9172 (0.9154)\tPrec@1 61.719 (61.044)\n",
            "Epoch: [69][90/97], lr: 0.01000\tTime 0.052 (0.087)\tData 0.000 (0.008)\tLoss 0.9977 (0.9171)\tPrec@1 60.156 (60.963)\n",
            "Test: [0/100]\tTime 0.395 (0.395)\tLoss 0.9834 (0.9834)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.022 (0.067)\tLoss 1.0857 (1.0587)\tPrec@1 55.000 (54.727)\n",
            "Test: [20/100]\tTime 0.030 (0.051)\tLoss 1.1809 (1.0518)\tPrec@1 53.000 (55.238)\n",
            "Test: [30/100]\tTime 0.022 (0.044)\tLoss 1.1610 (1.0694)\tPrec@1 54.000 (54.290)\n",
            "Test: [40/100]\tTime 0.033 (0.041)\tLoss 1.0596 (1.0647)\tPrec@1 57.000 (54.634)\n",
            "Test: [50/100]\tTime 0.023 (0.039)\tLoss 1.1969 (1.0665)\tPrec@1 47.000 (54.647)\n",
            "Test: [60/100]\tTime 0.024 (0.038)\tLoss 1.1714 (1.0720)\tPrec@1 47.000 (54.525)\n",
            "Test: [70/100]\tTime 0.048 (0.037)\tLoss 0.9773 (1.0694)\tPrec@1 60.000 (54.577)\n",
            "Test: [80/100]\tTime 0.023 (0.036)\tLoss 0.9855 (1.0715)\tPrec@1 59.000 (54.568)\n",
            "Test: [90/100]\tTime 0.049 (0.036)\tLoss 1.1447 (1.0719)\tPrec@1 54.000 (54.538)\n",
            "val Results: Prec@1 54.560 Loss 1.06727\n",
            "Best Prec@1: 56.460\n",
            "\n",
            "Epoch: [70][0/97], lr: 0.01000\tTime 0.510 (0.510)\tData 0.366 (0.366)\tLoss 1.0308 (1.0308)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [70][10/97], lr: 0.01000\tTime 0.063 (0.115)\tData 0.000 (0.036)\tLoss 0.8904 (0.9300)\tPrec@1 60.938 (61.577)\n",
            "Epoch: [70][20/97], lr: 0.01000\tTime 0.077 (0.095)\tData 0.007 (0.020)\tLoss 0.8668 (0.9154)\tPrec@1 60.156 (61.793)\n",
            "Epoch: [70][30/97], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.014)\tLoss 0.8755 (0.9167)\tPrec@1 63.281 (61.568)\n",
            "Epoch: [70][40/97], lr: 0.01000\tTime 0.069 (0.083)\tData 0.000 (0.011)\tLoss 1.0654 (0.9261)\tPrec@1 53.906 (61.319)\n",
            "Epoch: [70][50/97], lr: 0.01000\tTime 0.078 (0.081)\tData 0.000 (0.009)\tLoss 0.8444 (0.9213)\tPrec@1 64.844 (61.504)\n",
            "Epoch: [70][60/97], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.008)\tLoss 0.8982 (0.9172)\tPrec@1 65.625 (61.821)\n",
            "Epoch: [70][70/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.007)\tLoss 0.8487 (0.9152)\tPrec@1 60.938 (61.818)\n",
            "Epoch: [70][80/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.006)\tLoss 0.8495 (0.9141)\tPrec@1 66.406 (61.863)\n",
            "Epoch: [70][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.006)\tLoss 0.9376 (0.9138)\tPrec@1 61.719 (61.916)\n",
            "Test: [0/100]\tTime 0.281 (0.281)\tLoss 0.9629 (0.9629)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.021 (0.060)\tLoss 0.9934 (1.0378)\tPrec@1 65.000 (56.091)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 1.0698 (1.0366)\tPrec@1 57.000 (56.524)\n",
            "Test: [30/100]\tTime 0.028 (0.041)\tLoss 1.0585 (1.0331)\tPrec@1 53.000 (56.355)\n",
            "Test: [40/100]\tTime 0.036 (0.039)\tLoss 1.0021 (1.0304)\tPrec@1 60.000 (56.317)\n",
            "Test: [50/100]\tTime 0.054 (0.038)\tLoss 1.0909 (1.0314)\tPrec@1 56.000 (56.471)\n",
            "Test: [60/100]\tTime 0.034 (0.037)\tLoss 1.0842 (1.0356)\tPrec@1 56.000 (56.426)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9965 (1.0338)\tPrec@1 58.000 (56.535)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.9978 (1.0345)\tPrec@1 59.000 (56.432)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 1.0208 (1.0320)\tPrec@1 53.000 (56.242)\n",
            "val Results: Prec@1 56.230 Loss 1.02936\n",
            "Best Prec@1: 56.460\n",
            "\n",
            "Epoch: [71][0/97], lr: 0.01000\tTime 0.541 (0.541)\tData 0.389 (0.389)\tLoss 1.0343 (1.0343)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [71][10/97], lr: 0.01000\tTime 0.065 (0.119)\tData 0.000 (0.040)\tLoss 0.9365 (0.9228)\tPrec@1 58.594 (61.293)\n",
            "Epoch: [71][20/97], lr: 0.01000\tTime 0.075 (0.095)\tData 0.000 (0.022)\tLoss 0.8931 (0.9106)\tPrec@1 63.281 (62.054)\n",
            "Epoch: [71][30/97], lr: 0.01000\tTime 0.058 (0.088)\tData 0.000 (0.016)\tLoss 0.9702 (0.9038)\tPrec@1 57.812 (62.324)\n",
            "Epoch: [71][40/97], lr: 0.01000\tTime 0.065 (0.084)\tData 0.000 (0.012)\tLoss 0.8815 (0.9048)\tPrec@1 61.719 (62.386)\n",
            "Epoch: [71][50/97], lr: 0.01000\tTime 0.077 (0.082)\tData 0.006 (0.010)\tLoss 0.9147 (0.9080)\tPrec@1 62.500 (62.270)\n",
            "Epoch: [71][60/97], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.009)\tLoss 0.9962 (0.9145)\tPrec@1 56.250 (61.808)\n",
            "Epoch: [71][70/97], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.008)\tLoss 0.8298 (0.9091)\tPrec@1 66.406 (62.104)\n",
            "Epoch: [71][80/97], lr: 0.01000\tTime 0.061 (0.077)\tData 0.000 (0.008)\tLoss 0.9270 (0.9079)\tPrec@1 60.938 (62.114)\n",
            "Epoch: [71][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8743 (0.9053)\tPrec@1 63.281 (62.174)\n",
            "Test: [0/100]\tTime 0.271 (0.271)\tLoss 0.9434 (0.9434)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.023 (0.057)\tLoss 1.1312 (1.0554)\tPrec@1 52.000 (54.545)\n",
            "Test: [20/100]\tTime 0.022 (0.044)\tLoss 1.1577 (1.0547)\tPrec@1 52.000 (54.810)\n",
            "Test: [30/100]\tTime 0.029 (0.040)\tLoss 1.1058 (1.0661)\tPrec@1 53.000 (54.258)\n",
            "Test: [40/100]\tTime 0.024 (0.038)\tLoss 1.0456 (1.0643)\tPrec@1 57.000 (54.317)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 1.1048 (1.0618)\tPrec@1 53.000 (54.549)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 1.1663 (1.0693)\tPrec@1 49.000 (54.443)\n",
            "Test: [70/100]\tTime 0.045 (0.035)\tLoss 1.0044 (1.0650)\tPrec@1 52.000 (54.437)\n",
            "Test: [80/100]\tTime 0.022 (0.035)\tLoss 0.9558 (1.0635)\tPrec@1 60.000 (54.556)\n",
            "Test: [90/100]\tTime 0.038 (0.034)\tLoss 1.0765 (1.0619)\tPrec@1 53.000 (54.582)\n",
            "val Results: Prec@1 54.620 Loss 1.05949\n",
            "Best Prec@1: 56.460\n",
            "\n",
            "Epoch: [72][0/97], lr: 0.01000\tTime 0.563 (0.563)\tData 0.415 (0.415)\tLoss 0.9332 (0.9332)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [72][10/97], lr: 0.01000\tTime 0.063 (0.117)\tData 0.000 (0.040)\tLoss 0.8806 (0.9140)\tPrec@1 60.156 (62.642)\n",
            "Epoch: [72][20/97], lr: 0.01000\tTime 0.063 (0.094)\tData 0.005 (0.022)\tLoss 0.9451 (0.9163)\tPrec@1 63.281 (62.240)\n",
            "Epoch: [72][30/97], lr: 0.01000\tTime 0.089 (0.087)\tData 0.007 (0.016)\tLoss 0.8735 (0.9108)\tPrec@1 66.406 (62.147)\n",
            "Epoch: [72][40/97], lr: 0.01000\tTime 0.067 (0.083)\tData 0.003 (0.013)\tLoss 0.7610 (0.9091)\tPrec@1 71.094 (61.986)\n",
            "Epoch: [72][50/97], lr: 0.01000\tTime 0.079 (0.081)\tData 0.000 (0.011)\tLoss 0.8839 (0.9037)\tPrec@1 65.625 (62.224)\n",
            "Epoch: [72][60/97], lr: 0.01000\tTime 0.068 (0.080)\tData 0.003 (0.010)\tLoss 0.8125 (0.9080)\tPrec@1 60.938 (61.744)\n",
            "Epoch: [72][70/97], lr: 0.01000\tTime 0.073 (0.079)\tData 0.000 (0.009)\tLoss 1.0253 (0.9099)\tPrec@1 59.375 (61.774)\n",
            "Epoch: [72][80/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.008)\tLoss 0.9762 (0.9065)\tPrec@1 59.375 (62.018)\n",
            "Epoch: [72][90/97], lr: 0.01000\tTime 0.050 (0.078)\tData 0.000 (0.008)\tLoss 1.0150 (0.9036)\tPrec@1 59.375 (62.148)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 0.9278 (0.9278)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.049 (0.069)\tLoss 1.1183 (1.0263)\tPrec@1 52.000 (55.818)\n",
            "Test: [20/100]\tTime 0.026 (0.053)\tLoss 1.0640 (1.0084)\tPrec@1 55.000 (56.524)\n",
            "Test: [30/100]\tTime 0.022 (0.047)\tLoss 0.9926 (1.0083)\tPrec@1 62.000 (56.742)\n",
            "Test: [40/100]\tTime 0.038 (0.046)\tLoss 0.9920 (1.0084)\tPrec@1 58.000 (56.780)\n",
            "Test: [50/100]\tTime 0.024 (0.043)\tLoss 1.0890 (1.0132)\tPrec@1 50.000 (56.784)\n",
            "Test: [60/100]\tTime 0.055 (0.043)\tLoss 1.0621 (1.0190)\tPrec@1 58.000 (56.590)\n",
            "Test: [70/100]\tTime 0.026 (0.042)\tLoss 1.0291 (1.0190)\tPrec@1 59.000 (56.606)\n",
            "Test: [80/100]\tTime 0.042 (0.040)\tLoss 0.9362 (1.0144)\tPrec@1 59.000 (56.765)\n",
            "Test: [90/100]\tTime 0.024 (0.039)\tLoss 0.9802 (1.0123)\tPrec@1 57.000 (56.791)\n",
            "val Results: Prec@1 56.970 Loss 1.00986\n",
            "Best Prec@1: 56.970\n",
            "\n",
            "Epoch: [73][0/97], lr: 0.01000\tTime 0.465 (0.465)\tData 0.311 (0.311)\tLoss 1.0544 (1.0544)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [73][10/97], lr: 0.01000\tTime 0.067 (0.117)\tData 0.000 (0.033)\tLoss 0.8310 (0.9350)\tPrec@1 65.625 (61.932)\n",
            "Epoch: [73][20/97], lr: 0.01000\tTime 0.094 (0.095)\tData 0.000 (0.018)\tLoss 0.8769 (0.9226)\tPrec@1 58.594 (61.570)\n",
            "Epoch: [73][30/97], lr: 0.01000\tTime 0.083 (0.088)\tData 0.008 (0.013)\tLoss 0.8028 (0.9064)\tPrec@1 67.188 (62.072)\n",
            "Epoch: [73][40/97], lr: 0.01000\tTime 0.083 (0.084)\tData 0.000 (0.011)\tLoss 0.9111 (0.9110)\tPrec@1 58.594 (61.681)\n",
            "Epoch: [73][50/97], lr: 0.01000\tTime 0.074 (0.081)\tData 0.000 (0.009)\tLoss 0.8486 (0.9133)\tPrec@1 60.938 (61.428)\n",
            "Epoch: [73][60/97], lr: 0.01000\tTime 0.077 (0.080)\tData 0.000 (0.008)\tLoss 0.9492 (0.9124)\tPrec@1 60.156 (61.488)\n",
            "Epoch: [73][70/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.003 (0.007)\tLoss 1.0335 (0.9142)\tPrec@1 59.375 (61.510)\n",
            "Epoch: [73][80/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.004 (0.007)\tLoss 0.9818 (0.9133)\tPrec@1 57.812 (61.294)\n",
            "Epoch: [73][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.006)\tLoss 0.9783 (0.9117)\tPrec@1 53.906 (61.315)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 0.9132 (0.9132)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.043 (0.061)\tLoss 1.0283 (1.0080)\tPrec@1 59.000 (58.455)\n",
            "Test: [20/100]\tTime 0.054 (0.047)\tLoss 1.1108 (1.0172)\tPrec@1 54.000 (58.429)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 1.0494 (1.0251)\tPrec@1 62.000 (57.484)\n",
            "Test: [40/100]\tTime 0.024 (0.039)\tLoss 0.9913 (1.0250)\tPrec@1 55.000 (57.024)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.0235 (1.0233)\tPrec@1 58.000 (57.176)\n",
            "Test: [60/100]\tTime 0.030 (0.037)\tLoss 1.1490 (1.0305)\tPrec@1 49.000 (56.902)\n",
            "Test: [70/100]\tTime 0.034 (0.035)\tLoss 0.9925 (1.0285)\tPrec@1 57.000 (56.746)\n",
            "Test: [80/100]\tTime 0.027 (0.035)\tLoss 0.8999 (1.0265)\tPrec@1 58.000 (56.877)\n",
            "Test: [90/100]\tTime 0.020 (0.034)\tLoss 1.0388 (1.0240)\tPrec@1 53.000 (56.780)\n",
            "val Results: Prec@1 56.960 Loss 1.02045\n",
            "Best Prec@1: 56.970\n",
            "\n",
            "Epoch: [74][0/97], lr: 0.01000\tTime 0.544 (0.544)\tData 0.336 (0.336)\tLoss 0.8775 (0.8775)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [74][10/97], lr: 0.01000\tTime 0.065 (0.118)\tData 0.000 (0.033)\tLoss 0.7910 (0.8804)\tPrec@1 67.188 (61.719)\n",
            "Epoch: [74][20/97], lr: 0.01000\tTime 0.079 (0.097)\tData 0.000 (0.018)\tLoss 0.8126 (0.8899)\tPrec@1 67.188 (61.644)\n",
            "Epoch: [74][30/97], lr: 0.01000\tTime 0.076 (0.089)\tData 0.000 (0.013)\tLoss 1.0671 (0.9047)\tPrec@1 49.219 (61.517)\n",
            "Epoch: [74][40/97], lr: 0.01000\tTime 0.060 (0.084)\tData 0.000 (0.010)\tLoss 0.9635 (0.9045)\tPrec@1 57.031 (61.795)\n",
            "Epoch: [74][50/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.009)\tLoss 0.8626 (0.9018)\tPrec@1 62.500 (61.949)\n",
            "Epoch: [74][60/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.008)\tLoss 0.9825 (0.9001)\tPrec@1 57.031 (61.911)\n",
            "Epoch: [74][70/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.007)\tLoss 0.9166 (0.8984)\tPrec@1 58.594 (62.093)\n",
            "Epoch: [74][80/97], lr: 0.01000\tTime 0.085 (0.080)\tData 0.007 (0.006)\tLoss 0.9378 (0.9050)\tPrec@1 57.812 (61.757)\n",
            "Epoch: [74][90/97], lr: 0.01000\tTime 0.055 (0.079)\tData 0.000 (0.006)\tLoss 0.9611 (0.9045)\tPrec@1 60.938 (61.753)\n",
            "Test: [0/100]\tTime 0.272 (0.272)\tLoss 0.8997 (0.8997)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.030 (0.064)\tLoss 1.0166 (0.9942)\tPrec@1 58.000 (58.000)\n",
            "Test: [20/100]\tTime 0.023 (0.049)\tLoss 1.1250 (0.9874)\tPrec@1 56.000 (58.048)\n",
            "Test: [30/100]\tTime 0.024 (0.042)\tLoss 0.9976 (0.9965)\tPrec@1 55.000 (57.387)\n",
            "Test: [40/100]\tTime 0.030 (0.040)\tLoss 0.9337 (0.9951)\tPrec@1 57.000 (57.488)\n",
            "Test: [50/100]\tTime 0.023 (0.039)\tLoss 1.0211 (0.9949)\tPrec@1 59.000 (57.529)\n",
            "Test: [60/100]\tTime 0.031 (0.038)\tLoss 1.0964 (1.0026)\tPrec@1 53.000 (57.230)\n",
            "Test: [70/100]\tTime 0.045 (0.037)\tLoss 0.9332 (1.0010)\tPrec@1 59.000 (57.155)\n",
            "Test: [80/100]\tTime 0.029 (0.037)\tLoss 0.9145 (1.0006)\tPrec@1 62.000 (57.198)\n",
            "Test: [90/100]\tTime 0.031 (0.036)\tLoss 0.9497 (0.9979)\tPrec@1 61.000 (57.220)\n",
            "val Results: Prec@1 57.460 Loss 0.99297\n",
            "Best Prec@1: 57.460\n",
            "\n",
            "Epoch: [75][0/97], lr: 0.01000\tTime 0.554 (0.554)\tData 0.366 (0.366)\tLoss 0.9085 (0.9085)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [75][10/97], lr: 0.01000\tTime 0.066 (0.115)\tData 0.000 (0.034)\tLoss 0.9598 (0.8686)\tPrec@1 57.812 (63.281)\n",
            "Epoch: [75][20/97], lr: 0.01000\tTime 0.063 (0.094)\tData 0.000 (0.020)\tLoss 0.9250 (0.8803)\tPrec@1 63.281 (62.835)\n",
            "Epoch: [75][30/97], lr: 0.01000\tTime 0.076 (0.087)\tData 0.000 (0.014)\tLoss 0.9190 (0.8981)\tPrec@1 62.500 (62.198)\n",
            "Epoch: [75][40/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.011)\tLoss 0.9296 (0.8990)\tPrec@1 57.031 (61.947)\n",
            "Epoch: [75][50/97], lr: 0.01000\tTime 0.095 (0.081)\tData 0.008 (0.009)\tLoss 1.0060 (0.8963)\tPrec@1 53.906 (61.949)\n",
            "Epoch: [75][60/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.008)\tLoss 0.8530 (0.8941)\tPrec@1 59.375 (61.834)\n",
            "Epoch: [75][70/97], lr: 0.01000\tTime 0.061 (0.078)\tData 0.000 (0.007)\tLoss 0.8365 (0.8893)\tPrec@1 62.500 (62.005)\n",
            "Epoch: [75][80/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.007)\tLoss 0.7804 (0.8927)\tPrec@1 67.188 (62.037)\n",
            "Epoch: [75][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.006)\tLoss 0.8664 (0.8969)\tPrec@1 62.500 (61.745)\n",
            "Test: [0/100]\tTime 0.274 (0.274)\tLoss 0.9033 (0.9033)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.035 (0.058)\tLoss 1.0488 (1.0766)\tPrec@1 60.000 (56.364)\n",
            "Test: [20/100]\tTime 0.030 (0.046)\tLoss 1.2247 (1.0679)\tPrec@1 52.000 (56.143)\n",
            "Test: [30/100]\tTime 0.020 (0.040)\tLoss 1.1369 (1.0853)\tPrec@1 55.000 (55.387)\n",
            "Test: [40/100]\tTime 0.023 (0.038)\tLoss 1.0146 (1.0883)\tPrec@1 57.000 (55.634)\n",
            "Test: [50/100]\tTime 0.023 (0.036)\tLoss 1.1938 (1.0869)\tPrec@1 56.000 (55.510)\n",
            "Test: [60/100]\tTime 0.043 (0.036)\tLoss 1.2021 (1.0936)\tPrec@1 46.000 (55.361)\n",
            "Test: [70/100]\tTime 0.060 (0.035)\tLoss 1.0699 (1.0902)\tPrec@1 60.000 (55.535)\n",
            "Test: [80/100]\tTime 0.026 (0.035)\tLoss 0.9575 (1.0867)\tPrec@1 64.000 (55.815)\n",
            "Test: [90/100]\tTime 0.048 (0.034)\tLoss 1.1922 (1.0841)\tPrec@1 53.000 (55.901)\n",
            "val Results: Prec@1 56.040 Loss 1.08327\n",
            "Best Prec@1: 57.460\n",
            "\n",
            "Epoch: [76][0/97], lr: 0.01000\tTime 0.563 (0.563)\tData 0.411 (0.411)\tLoss 0.7857 (0.7857)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [76][10/97], lr: 0.01000\tTime 0.067 (0.117)\tData 0.003 (0.040)\tLoss 0.8742 (0.8920)\tPrec@1 62.500 (62.713)\n",
            "Epoch: [76][20/97], lr: 0.01000\tTime 0.062 (0.094)\tData 0.000 (0.021)\tLoss 0.9057 (0.8940)\tPrec@1 61.719 (62.463)\n",
            "Epoch: [76][30/97], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.015)\tLoss 0.8055 (0.8802)\tPrec@1 69.531 (63.004)\n",
            "Epoch: [76][40/97], lr: 0.01000\tTime 0.073 (0.084)\tData 0.008 (0.012)\tLoss 1.0604 (0.8857)\tPrec@1 57.812 (62.576)\n",
            "Epoch: [76][50/97], lr: 0.01000\tTime 0.069 (0.082)\tData 0.001 (0.011)\tLoss 0.9063 (0.8932)\tPrec@1 57.812 (62.148)\n",
            "Epoch: [76][60/97], lr: 0.01000\tTime 0.088 (0.081)\tData 0.007 (0.009)\tLoss 0.7959 (0.8979)\tPrec@1 69.531 (62.282)\n",
            "Epoch: [76][70/97], lr: 0.01000\tTime 0.075 (0.080)\tData 0.007 (0.008)\tLoss 0.9358 (0.8951)\tPrec@1 61.719 (62.522)\n",
            "Epoch: [76][80/97], lr: 0.01000\tTime 0.063 (0.079)\tData 0.000 (0.008)\tLoss 0.9208 (0.9016)\tPrec@1 60.938 (62.066)\n",
            "Epoch: [76][90/97], lr: 0.01000\tTime 0.051 (0.077)\tData 0.000 (0.007)\tLoss 0.7767 (0.9008)\tPrec@1 67.969 (62.088)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.0004 (1.0004)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.038 (0.061)\tLoss 1.0499 (0.9988)\tPrec@1 55.000 (58.545)\n",
            "Test: [20/100]\tTime 0.026 (0.048)\tLoss 1.0374 (1.0000)\tPrec@1 58.000 (58.857)\n",
            "Test: [30/100]\tTime 0.022 (0.043)\tLoss 1.0188 (1.0096)\tPrec@1 55.000 (57.968)\n",
            "Test: [40/100]\tTime 0.027 (0.040)\tLoss 0.9353 (1.0075)\tPrec@1 62.000 (58.244)\n",
            "Test: [50/100]\tTime 0.037 (0.039)\tLoss 1.0233 (1.0090)\tPrec@1 60.000 (57.961)\n",
            "Test: [60/100]\tTime 0.031 (0.038)\tLoss 1.0748 (1.0146)\tPrec@1 54.000 (57.607)\n",
            "Test: [70/100]\tTime 0.033 (0.037)\tLoss 0.9985 (1.0172)\tPrec@1 62.000 (57.479)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.9856 (1.0164)\tPrec@1 62.000 (57.370)\n",
            "Test: [90/100]\tTime 0.043 (0.036)\tLoss 1.0594 (1.0140)\tPrec@1 57.000 (57.484)\n",
            "val Results: Prec@1 57.720 Loss 1.00904\n",
            "Best Prec@1: 57.720\n",
            "\n",
            "Epoch: [77][0/97], lr: 0.01000\tTime 0.537 (0.537)\tData 0.418 (0.418)\tLoss 0.9344 (0.9344)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [77][10/97], lr: 0.01000\tTime 0.063 (0.118)\tData 0.000 (0.040)\tLoss 0.8758 (0.9073)\tPrec@1 64.844 (62.216)\n",
            "Epoch: [77][20/97], lr: 0.01000\tTime 0.065 (0.095)\tData 0.000 (0.022)\tLoss 0.7927 (0.8947)\tPrec@1 67.969 (62.016)\n",
            "Epoch: [77][30/97], lr: 0.01000\tTime 0.074 (0.087)\tData 0.012 (0.016)\tLoss 0.8456 (0.9032)\tPrec@1 66.406 (62.021)\n",
            "Epoch: [77][40/97], lr: 0.01000\tTime 0.066 (0.083)\tData 0.007 (0.013)\tLoss 0.9272 (0.9028)\tPrec@1 58.594 (61.890)\n",
            "Epoch: [77][50/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.006 (0.011)\tLoss 0.8815 (0.8989)\tPrec@1 57.031 (61.811)\n",
            "Epoch: [77][60/97], lr: 0.01000\tTime 0.072 (0.079)\tData 0.009 (0.010)\tLoss 0.9409 (0.8964)\tPrec@1 61.719 (61.860)\n",
            "Epoch: [77][70/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.000 (0.009)\tLoss 0.8995 (0.9014)\tPrec@1 60.156 (61.653)\n",
            "Epoch: [77][80/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.007 (0.009)\tLoss 0.9131 (0.8975)\tPrec@1 60.938 (61.960)\n",
            "Epoch: [77][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.008)\tLoss 0.8940 (0.8975)\tPrec@1 63.281 (62.054)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.9765 (0.9765)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.056 (0.061)\tLoss 1.0384 (1.0360)\tPrec@1 59.000 (56.455)\n",
            "Test: [20/100]\tTime 0.029 (0.046)\tLoss 1.1074 (1.0287)\tPrec@1 55.000 (57.524)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0679 (1.0416)\tPrec@1 50.000 (56.581)\n",
            "Test: [40/100]\tTime 0.023 (0.038)\tLoss 0.9450 (1.0378)\tPrec@1 62.000 (56.585)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 1.1048 (1.0379)\tPrec@1 53.000 (56.529)\n",
            "Test: [60/100]\tTime 0.055 (0.036)\tLoss 1.1982 (1.0446)\tPrec@1 46.000 (56.361)\n",
            "Test: [70/100]\tTime 0.057 (0.035)\tLoss 0.9976 (1.0393)\tPrec@1 62.000 (56.676)\n",
            "Test: [80/100]\tTime 0.035 (0.035)\tLoss 0.9652 (1.0387)\tPrec@1 60.000 (56.654)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.1395 (1.0373)\tPrec@1 50.000 (56.670)\n",
            "val Results: Prec@1 56.840 Loss 1.03165\n",
            "Best Prec@1: 57.720\n",
            "\n",
            "Epoch: [78][0/97], lr: 0.01000\tTime 0.668 (0.668)\tData 0.454 (0.454)\tLoss 0.7980 (0.7980)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [78][10/97], lr: 0.01000\tTime 0.071 (0.139)\tData 0.012 (0.043)\tLoss 0.9799 (0.9045)\tPrec@1 58.594 (61.790)\n",
            "Epoch: [78][20/97], lr: 0.01000\tTime 0.060 (0.113)\tData 0.000 (0.023)\tLoss 0.8673 (0.9189)\tPrec@1 65.625 (60.751)\n",
            "Epoch: [78][30/97], lr: 0.01000\tTime 0.063 (0.103)\tData 0.000 (0.017)\tLoss 0.8342 (0.8993)\tPrec@1 62.500 (62.072)\n",
            "Epoch: [78][40/97], lr: 0.01000\tTime 0.109 (0.100)\tData 0.000 (0.013)\tLoss 0.8517 (0.8953)\tPrec@1 64.844 (62.519)\n",
            "Epoch: [78][50/97], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.012)\tLoss 0.8575 (0.8932)\tPrec@1 71.094 (62.653)\n",
            "Epoch: [78][60/97], lr: 0.01000\tTime 0.082 (0.091)\tData 0.009 (0.010)\tLoss 0.9584 (0.8991)\tPrec@1 58.594 (62.423)\n",
            "Epoch: [78][70/97], lr: 0.01000\tTime 0.090 (0.088)\tData 0.013 (0.009)\tLoss 0.7941 (0.8933)\tPrec@1 70.312 (62.720)\n",
            "Epoch: [78][80/97], lr: 0.01000\tTime 0.126 (0.088)\tData 0.001 (0.008)\tLoss 0.8715 (0.8899)\tPrec@1 60.938 (62.731)\n",
            "Epoch: [78][90/97], lr: 0.01000\tTime 0.050 (0.087)\tData 0.000 (0.008)\tLoss 0.7992 (0.8909)\tPrec@1 67.188 (62.740)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 0.9365 (0.9365)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.071 (0.073)\tLoss 0.9537 (1.0333)\tPrec@1 61.000 (57.727)\n",
            "Test: [20/100]\tTime 0.058 (0.055)\tLoss 1.1657 (1.0284)\tPrec@1 51.000 (57.571)\n",
            "Test: [30/100]\tTime 0.038 (0.049)\tLoss 1.0036 (1.0301)\tPrec@1 57.000 (57.194)\n",
            "Test: [40/100]\tTime 0.059 (0.047)\tLoss 0.9745 (1.0208)\tPrec@1 61.000 (57.195)\n",
            "Test: [50/100]\tTime 0.028 (0.043)\tLoss 1.0954 (1.0211)\tPrec@1 50.000 (57.235)\n",
            "Test: [60/100]\tTime 0.025 (0.041)\tLoss 1.1254 (1.0290)\tPrec@1 50.000 (57.098)\n",
            "Test: [70/100]\tTime 0.032 (0.040)\tLoss 0.9752 (1.0269)\tPrec@1 58.000 (57.042)\n",
            "Test: [80/100]\tTime 0.025 (0.039)\tLoss 0.9806 (1.0243)\tPrec@1 58.000 (57.173)\n",
            "Test: [90/100]\tTime 0.024 (0.038)\tLoss 1.1458 (1.0225)\tPrec@1 51.000 (57.308)\n",
            "val Results: Prec@1 57.370 Loss 1.02036\n",
            "Best Prec@1: 57.720\n",
            "\n",
            "Epoch: [79][0/97], lr: 0.01000\tTime 0.522 (0.522)\tData 0.312 (0.312)\tLoss 0.8536 (0.8536)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [79][10/97], lr: 0.01000\tTime 0.077 (0.116)\tData 0.007 (0.031)\tLoss 0.7754 (0.8719)\tPrec@1 71.094 (62.997)\n",
            "Epoch: [79][20/97], lr: 0.01000\tTime 0.060 (0.093)\tData 0.000 (0.017)\tLoss 0.9219 (0.8970)\tPrec@1 62.500 (62.091)\n",
            "Epoch: [79][30/97], lr: 0.01000\tTime 0.064 (0.087)\tData 0.000 (0.012)\tLoss 0.9486 (0.8989)\tPrec@1 56.250 (61.719)\n",
            "Epoch: [79][40/97], lr: 0.01000\tTime 0.060 (0.082)\tData 0.000 (0.010)\tLoss 0.9863 (0.8971)\tPrec@1 61.719 (61.986)\n",
            "Epoch: [79][50/97], lr: 0.01000\tTime 0.078 (0.080)\tData 0.004 (0.009)\tLoss 0.8840 (0.8973)\tPrec@1 58.594 (61.964)\n",
            "Epoch: [79][60/97], lr: 0.01000\tTime 0.080 (0.081)\tData 0.007 (0.008)\tLoss 0.8696 (0.8955)\tPrec@1 60.938 (62.103)\n",
            "Epoch: [79][70/97], lr: 0.01000\tTime 0.062 (0.082)\tData 0.000 (0.007)\tLoss 0.9008 (0.8919)\tPrec@1 57.812 (62.423)\n",
            "Epoch: [79][80/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.006)\tLoss 0.8114 (0.8920)\tPrec@1 65.625 (62.355)\n",
            "Epoch: [79][90/97], lr: 0.01000\tTime 0.060 (0.081)\tData 0.000 (0.006)\tLoss 0.9158 (0.8885)\tPrec@1 60.938 (62.577)\n",
            "Test: [0/100]\tTime 0.371 (0.371)\tLoss 0.9429 (0.9429)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.040 (0.068)\tLoss 1.0274 (1.0021)\tPrec@1 55.000 (54.909)\n",
            "Test: [20/100]\tTime 0.029 (0.052)\tLoss 1.1028 (1.0079)\tPrec@1 55.000 (55.524)\n",
            "Test: [30/100]\tTime 0.027 (0.046)\tLoss 0.9957 (1.0188)\tPrec@1 53.000 (55.129)\n",
            "Test: [40/100]\tTime 0.024 (0.042)\tLoss 0.9853 (1.0130)\tPrec@1 54.000 (55.659)\n",
            "Test: [50/100]\tTime 0.024 (0.040)\tLoss 1.1057 (1.0155)\tPrec@1 53.000 (55.588)\n",
            "Test: [60/100]\tTime 0.023 (0.038)\tLoss 1.0966 (1.0217)\tPrec@1 52.000 (55.639)\n",
            "Test: [70/100]\tTime 0.023 (0.037)\tLoss 0.9547 (1.0187)\tPrec@1 58.000 (55.718)\n",
            "Test: [80/100]\tTime 0.021 (0.037)\tLoss 0.9664 (1.0172)\tPrec@1 56.000 (55.765)\n",
            "Test: [90/100]\tTime 0.030 (0.036)\tLoss 1.0495 (1.0148)\tPrec@1 53.000 (55.868)\n",
            "val Results: Prec@1 56.210 Loss 1.00923\n",
            "Best Prec@1: 57.720\n",
            "\n",
            "Epoch: [80][0/97], lr: 0.01000\tTime 0.521 (0.521)\tData 0.416 (0.416)\tLoss 0.7908 (0.7908)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [80][10/97], lr: 0.01000\tTime 0.062 (0.118)\tData 0.000 (0.041)\tLoss 0.8944 (0.8741)\tPrec@1 61.719 (62.926)\n",
            "Epoch: [80][20/97], lr: 0.01000\tTime 0.088 (0.096)\tData 0.000 (0.023)\tLoss 0.9556 (0.8720)\tPrec@1 60.938 (63.095)\n",
            "Epoch: [80][30/97], lr: 0.01000\tTime 0.071 (0.088)\tData 0.004 (0.016)\tLoss 0.9534 (0.8741)\tPrec@1 61.719 (63.231)\n",
            "Epoch: [80][40/97], lr: 0.01000\tTime 0.079 (0.087)\tData 0.007 (0.012)\tLoss 0.8454 (0.8812)\tPrec@1 67.188 (62.957)\n",
            "Epoch: [80][50/97], lr: 0.01000\tTime 0.068 (0.087)\tData 0.000 (0.011)\tLoss 0.7855 (0.8751)\tPrec@1 63.281 (62.929)\n",
            "Epoch: [80][60/97], lr: 0.01000\tTime 0.091 (0.086)\tData 0.000 (0.009)\tLoss 1.0145 (0.8797)\tPrec@1 61.719 (62.833)\n",
            "Epoch: [80][70/97], lr: 0.01000\tTime 0.123 (0.087)\tData 0.006 (0.008)\tLoss 0.8275 (0.8775)\tPrec@1 66.406 (62.852)\n",
            "Epoch: [80][80/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.007)\tLoss 0.8831 (0.8747)\tPrec@1 62.500 (62.905)\n",
            "Epoch: [80][90/97], lr: 0.01000\tTime 0.056 (0.084)\tData 0.000 (0.007)\tLoss 0.9120 (0.8791)\tPrec@1 61.719 (62.680)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 0.9058 (0.9058)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.021 (0.058)\tLoss 0.9999 (0.9936)\tPrec@1 61.000 (58.273)\n",
            "Test: [20/100]\tTime 0.028 (0.045)\tLoss 1.0862 (0.9918)\tPrec@1 58.000 (59.000)\n",
            "Test: [30/100]\tTime 0.025 (0.041)\tLoss 0.9459 (0.9944)\tPrec@1 59.000 (58.129)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 0.9533 (0.9924)\tPrec@1 58.000 (58.098)\n",
            "Test: [50/100]\tTime 0.046 (0.038)\tLoss 1.0378 (0.9922)\tPrec@1 58.000 (58.569)\n",
            "Test: [60/100]\tTime 0.027 (0.036)\tLoss 1.0849 (0.9978)\tPrec@1 53.000 (58.475)\n",
            "Test: [70/100]\tTime 0.021 (0.035)\tLoss 0.9442 (0.9954)\tPrec@1 63.000 (58.465)\n",
            "Test: [80/100]\tTime 0.035 (0.035)\tLoss 0.8831 (0.9944)\tPrec@1 61.000 (58.469)\n",
            "Test: [90/100]\tTime 0.047 (0.035)\tLoss 0.9419 (0.9926)\tPrec@1 57.000 (58.571)\n",
            "val Results: Prec@1 58.690 Loss 0.99044\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [81][0/97], lr: 0.01000\tTime 0.496 (0.496)\tData 0.315 (0.315)\tLoss 0.8757 (0.8757)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [81][10/97], lr: 0.01000\tTime 0.073 (0.119)\tData 0.002 (0.033)\tLoss 0.8356 (0.8672)\tPrec@1 64.062 (63.849)\n",
            "Epoch: [81][20/97], lr: 0.01000\tTime 0.073 (0.096)\tData 0.008 (0.019)\tLoss 0.9085 (0.8739)\tPrec@1 61.719 (63.690)\n",
            "Epoch: [81][30/97], lr: 0.01000\tTime 0.082 (0.087)\tData 0.000 (0.013)\tLoss 0.7545 (0.8724)\tPrec@1 67.969 (63.180)\n",
            "Epoch: [81][40/97], lr: 0.01000\tTime 0.068 (0.084)\tData 0.006 (0.011)\tLoss 1.0278 (0.8715)\tPrec@1 57.812 (63.186)\n",
            "Epoch: [81][50/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.007 (0.010)\tLoss 0.8802 (0.8747)\tPrec@1 60.938 (63.006)\n",
            "Epoch: [81][60/97], lr: 0.01000\tTime 0.074 (0.079)\tData 0.000 (0.008)\tLoss 0.8427 (0.8787)\tPrec@1 64.062 (62.935)\n",
            "Epoch: [81][70/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.005 (0.008)\tLoss 0.9411 (0.8744)\tPrec@1 60.938 (63.292)\n",
            "Epoch: [81][80/97], lr: 0.01000\tTime 0.060 (0.078)\tData 0.001 (0.007)\tLoss 0.8053 (0.8757)\tPrec@1 61.719 (63.310)\n",
            "Epoch: [81][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.006)\tLoss 0.9446 (0.8726)\tPrec@1 64.844 (63.547)\n",
            "Test: [0/100]\tTime 0.278 (0.278)\tLoss 0.9297 (0.9297)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.038 (0.062)\tLoss 0.9813 (1.0093)\tPrec@1 58.000 (56.545)\n",
            "Test: [20/100]\tTime 0.049 (0.047)\tLoss 1.0993 (1.0084)\tPrec@1 55.000 (56.762)\n",
            "Test: [30/100]\tTime 0.029 (0.042)\tLoss 1.0400 (1.0101)\tPrec@1 53.000 (56.452)\n",
            "Test: [40/100]\tTime 0.042 (0.039)\tLoss 0.9873 (1.0042)\tPrec@1 56.000 (56.756)\n",
            "Test: [50/100]\tTime 0.044 (0.038)\tLoss 1.0687 (1.0037)\tPrec@1 52.000 (57.059)\n",
            "Test: [60/100]\tTime 0.062 (0.037)\tLoss 1.0981 (1.0115)\tPrec@1 57.000 (56.967)\n",
            "Test: [70/100]\tTime 0.039 (0.036)\tLoss 0.9400 (1.0054)\tPrec@1 62.000 (57.423)\n",
            "Test: [80/100]\tTime 0.021 (0.036)\tLoss 0.9570 (1.0056)\tPrec@1 57.000 (57.407)\n",
            "Test: [90/100]\tTime 0.044 (0.035)\tLoss 0.9798 (1.0035)\tPrec@1 56.000 (57.505)\n",
            "val Results: Prec@1 57.830 Loss 0.99816\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [82][0/97], lr: 0.01000\tTime 0.545 (0.545)\tData 0.367 (0.367)\tLoss 0.8858 (0.8858)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [82][10/97], lr: 0.01000\tTime 0.087 (0.119)\tData 0.000 (0.035)\tLoss 0.8726 (0.8927)\tPrec@1 65.625 (62.003)\n",
            "Epoch: [82][20/97], lr: 0.01000\tTime 0.062 (0.095)\tData 0.000 (0.020)\tLoss 0.8624 (0.8717)\tPrec@1 62.500 (63.281)\n",
            "Epoch: [82][30/97], lr: 0.01000\tTime 0.064 (0.088)\tData 0.000 (0.014)\tLoss 0.9571 (0.8733)\tPrec@1 57.031 (63.105)\n",
            "Epoch: [82][40/97], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.011)\tLoss 0.7889 (0.8811)\tPrec@1 67.188 (62.710)\n",
            "Epoch: [82][50/97], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.009)\tLoss 0.8668 (0.8745)\tPrec@1 63.281 (63.128)\n",
            "Epoch: [82][60/97], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.008)\tLoss 0.9426 (0.8729)\tPrec@1 60.156 (63.268)\n",
            "Epoch: [82][70/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.007)\tLoss 0.9525 (0.8741)\tPrec@1 60.938 (63.028)\n",
            "Epoch: [82][80/97], lr: 0.01000\tTime 0.060 (0.078)\tData 0.000 (0.006)\tLoss 0.9807 (0.8750)\tPrec@1 56.250 (62.982)\n",
            "Epoch: [82][90/97], lr: 0.01000\tTime 0.055 (0.079)\tData 0.000 (0.006)\tLoss 0.8062 (0.8717)\tPrec@1 68.750 (63.230)\n",
            "Test: [0/100]\tTime 0.520 (0.520)\tLoss 0.9114 (0.9114)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.052 (0.095)\tLoss 0.9469 (0.9748)\tPrec@1 64.000 (59.091)\n",
            "Test: [20/100]\tTime 0.046 (0.074)\tLoss 1.0802 (0.9656)\tPrec@1 58.000 (59.238)\n",
            "Test: [30/100]\tTime 0.048 (0.067)\tLoss 0.9615 (0.9745)\tPrec@1 60.000 (58.194)\n",
            "Test: [40/100]\tTime 0.027 (0.061)\tLoss 0.9553 (0.9758)\tPrec@1 59.000 (57.927)\n",
            "Test: [50/100]\tTime 0.022 (0.055)\tLoss 0.9448 (0.9767)\tPrec@1 59.000 (58.235)\n",
            "Test: [60/100]\tTime 0.047 (0.052)\tLoss 1.0670 (0.9865)\tPrec@1 56.000 (57.967)\n",
            "Test: [70/100]\tTime 0.023 (0.049)\tLoss 0.9171 (0.9852)\tPrec@1 63.000 (58.211)\n",
            "Test: [80/100]\tTime 0.031 (0.047)\tLoss 0.8955 (0.9848)\tPrec@1 62.000 (58.259)\n",
            "Test: [90/100]\tTime 0.035 (0.045)\tLoss 0.9575 (0.9835)\tPrec@1 60.000 (58.341)\n",
            "val Results: Prec@1 58.450 Loss 0.98022\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [83][0/97], lr: 0.01000\tTime 0.539 (0.539)\tData 0.407 (0.407)\tLoss 0.8946 (0.8946)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [83][10/97], lr: 0.01000\tTime 0.079 (0.115)\tData 0.009 (0.039)\tLoss 0.8919 (0.8791)\tPrec@1 63.281 (62.713)\n",
            "Epoch: [83][20/97], lr: 0.01000\tTime 0.074 (0.093)\tData 0.009 (0.022)\tLoss 0.9550 (0.8812)\tPrec@1 57.812 (62.686)\n",
            "Epoch: [83][30/97], lr: 0.01000\tTime 0.074 (0.086)\tData 0.006 (0.015)\tLoss 0.7995 (0.8669)\tPrec@1 66.406 (63.458)\n",
            "Epoch: [83][40/97], lr: 0.01000\tTime 0.082 (0.083)\tData 0.000 (0.012)\tLoss 0.9026 (0.8653)\tPrec@1 63.281 (63.338)\n",
            "Epoch: [83][50/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.010)\tLoss 0.8777 (0.8739)\tPrec@1 60.938 (63.082)\n",
            "Epoch: [83][60/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.008)\tLoss 0.7585 (0.8713)\tPrec@1 70.312 (63.371)\n",
            "Epoch: [83][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.007)\tLoss 0.8860 (0.8700)\tPrec@1 57.812 (63.512)\n",
            "Epoch: [83][80/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.007)\tLoss 0.8682 (0.8712)\tPrec@1 60.938 (63.590)\n",
            "Epoch: [83][90/97], lr: 0.01000\tTime 0.042 (0.079)\tData 0.000 (0.007)\tLoss 0.8075 (0.8721)\tPrec@1 69.531 (63.479)\n",
            "Test: [0/100]\tTime 0.373 (0.373)\tLoss 0.9667 (0.9667)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.061 (0.069)\tLoss 1.0023 (0.9908)\tPrec@1 59.000 (58.273)\n",
            "Test: [20/100]\tTime 0.032 (0.052)\tLoss 1.0314 (0.9903)\tPrec@1 55.000 (58.190)\n",
            "Test: [30/100]\tTime 0.029 (0.047)\tLoss 1.0109 (1.0035)\tPrec@1 63.000 (57.516)\n",
            "Test: [40/100]\tTime 0.024 (0.044)\tLoss 0.9289 (0.9974)\tPrec@1 63.000 (57.463)\n",
            "Test: [50/100]\tTime 0.023 (0.043)\tLoss 1.0164 (0.9999)\tPrec@1 60.000 (57.412)\n",
            "Test: [60/100]\tTime 0.022 (0.041)\tLoss 1.0734 (1.0050)\tPrec@1 53.000 (57.393)\n",
            "Test: [70/100]\tTime 0.029 (0.041)\tLoss 0.9615 (1.0046)\tPrec@1 63.000 (57.746)\n",
            "Test: [80/100]\tTime 0.033 (0.040)\tLoss 0.9476 (1.0012)\tPrec@1 60.000 (57.864)\n",
            "Test: [90/100]\tTime 0.035 (0.039)\tLoss 1.0235 (0.9980)\tPrec@1 48.000 (57.923)\n",
            "val Results: Prec@1 58.250 Loss 0.99531\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [84][0/97], lr: 0.01000\tTime 0.542 (0.542)\tData 0.396 (0.396)\tLoss 0.9162 (0.9162)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [84][10/97], lr: 0.01000\tTime 0.086 (0.116)\tData 0.008 (0.039)\tLoss 0.9065 (0.8547)\tPrec@1 60.156 (64.205)\n",
            "Epoch: [84][20/97], lr: 0.01000\tTime 0.061 (0.094)\tData 0.000 (0.021)\tLoss 0.9501 (0.8504)\tPrec@1 56.250 (63.839)\n",
            "Epoch: [84][30/97], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.015)\tLoss 0.8962 (0.8675)\tPrec@1 64.844 (63.256)\n",
            "Epoch: [84][40/97], lr: 0.01000\tTime 0.084 (0.085)\tData 0.000 (0.012)\tLoss 0.8193 (0.8716)\tPrec@1 65.625 (62.767)\n",
            "Epoch: [84][50/97], lr: 0.01000\tTime 0.071 (0.083)\tData 0.005 (0.010)\tLoss 0.8039 (0.8754)\tPrec@1 67.969 (62.714)\n",
            "Epoch: [84][60/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.009)\tLoss 0.7499 (0.8729)\tPrec@1 66.406 (62.923)\n",
            "Epoch: [84][70/97], lr: 0.01000\tTime 0.073 (0.080)\tData 0.001 (0.008)\tLoss 0.8911 (0.8711)\tPrec@1 60.938 (63.149)\n",
            "Epoch: [84][80/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 0.7104 (0.8728)\tPrec@1 70.312 (63.156)\n",
            "Epoch: [84][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.9314 (0.8762)\tPrec@1 57.031 (62.946)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 0.9686 (0.9686)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.047 (0.061)\tLoss 1.0266 (1.0084)\tPrec@1 59.000 (56.273)\n",
            "Test: [20/100]\tTime 0.051 (0.046)\tLoss 1.0737 (1.0063)\tPrec@1 60.000 (56.571)\n",
            "Test: [30/100]\tTime 0.035 (0.042)\tLoss 1.0029 (1.0023)\tPrec@1 55.000 (56.806)\n",
            "Test: [40/100]\tTime 0.028 (0.039)\tLoss 1.0107 (1.0012)\tPrec@1 53.000 (57.024)\n",
            "Test: [50/100]\tTime 0.044 (0.037)\tLoss 1.0051 (1.0000)\tPrec@1 56.000 (57.255)\n",
            "Test: [60/100]\tTime 0.070 (0.037)\tLoss 1.1146 (1.0068)\tPrec@1 52.000 (57.131)\n",
            "Test: [70/100]\tTime 0.037 (0.036)\tLoss 1.0011 (1.0030)\tPrec@1 57.000 (57.211)\n",
            "Test: [80/100]\tTime 0.036 (0.035)\tLoss 0.9594 (1.0020)\tPrec@1 59.000 (57.284)\n",
            "Test: [90/100]\tTime 0.042 (0.035)\tLoss 1.0024 (1.0002)\tPrec@1 54.000 (57.220)\n",
            "val Results: Prec@1 57.550 Loss 0.99495\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [85][0/97], lr: 0.01000\tTime 0.529 (0.529)\tData 0.331 (0.331)\tLoss 0.8809 (0.8809)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [85][10/97], lr: 0.01000\tTime 0.061 (0.117)\tData 0.000 (0.032)\tLoss 0.8477 (0.8509)\tPrec@1 68.750 (64.276)\n",
            "Epoch: [85][20/97], lr: 0.01000\tTime 0.074 (0.095)\tData 0.000 (0.018)\tLoss 0.7690 (0.8604)\tPrec@1 72.656 (64.211)\n",
            "Epoch: [85][30/97], lr: 0.01000\tTime 0.067 (0.088)\tData 0.000 (0.013)\tLoss 0.8136 (0.8557)\tPrec@1 63.281 (64.592)\n",
            "Epoch: [85][40/97], lr: 0.01000\tTime 0.070 (0.084)\tData 0.007 (0.011)\tLoss 0.9091 (0.8645)\tPrec@1 61.719 (64.367)\n",
            "Epoch: [85][50/97], lr: 0.01000\tTime 0.070 (0.082)\tData 0.006 (0.009)\tLoss 0.9452 (0.8642)\tPrec@1 58.594 (64.093)\n",
            "Epoch: [85][60/97], lr: 0.01000\tTime 0.068 (0.080)\tData 0.000 (0.008)\tLoss 0.8462 (0.8665)\tPrec@1 63.281 (63.909)\n",
            "Epoch: [85][70/97], lr: 0.01000\tTime 0.066 (0.078)\tData 0.003 (0.008)\tLoss 0.9615 (0.8707)\tPrec@1 61.719 (63.677)\n",
            "Epoch: [85][80/97], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.007)\tLoss 0.8248 (0.8706)\tPrec@1 64.062 (63.783)\n",
            "Epoch: [85][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.7510 (0.8717)\tPrec@1 70.312 (63.745)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 0.9411 (0.9411)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.031 (0.060)\tLoss 1.0190 (1.0046)\tPrec@1 56.000 (57.091)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 1.0413 (0.9907)\tPrec@1 61.000 (58.810)\n",
            "Test: [30/100]\tTime 0.023 (0.041)\tLoss 0.9391 (0.9951)\tPrec@1 59.000 (58.774)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9261 (0.9974)\tPrec@1 65.000 (58.707)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.0796 (1.0006)\tPrec@1 58.000 (58.627)\n",
            "Test: [60/100]\tTime 0.027 (0.036)\tLoss 1.1774 (1.0090)\tPrec@1 54.000 (58.115)\n",
            "Test: [70/100]\tTime 0.028 (0.036)\tLoss 0.9876 (1.0096)\tPrec@1 58.000 (58.070)\n",
            "Test: [80/100]\tTime 0.031 (0.035)\tLoss 1.0537 (1.0091)\tPrec@1 51.000 (58.173)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0258 (1.0062)\tPrec@1 56.000 (58.132)\n",
            "val Results: Prec@1 58.490 Loss 1.00189\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [86][0/97], lr: 0.01000\tTime 0.569 (0.569)\tData 0.404 (0.404)\tLoss 0.8617 (0.8617)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [86][10/97], lr: 0.01000\tTime 0.060 (0.117)\tData 0.000 (0.041)\tLoss 0.8733 (0.8887)\tPrec@1 64.062 (63.494)\n",
            "Epoch: [86][20/97], lr: 0.01000\tTime 0.093 (0.097)\tData 0.011 (0.023)\tLoss 0.9460 (0.8860)\tPrec@1 56.250 (63.021)\n",
            "Epoch: [86][30/97], lr: 0.01000\tTime 0.073 (0.088)\tData 0.007 (0.017)\tLoss 0.7994 (0.8701)\tPrec@1 71.094 (63.533)\n",
            "Epoch: [86][40/97], lr: 0.01000\tTime 0.077 (0.084)\tData 0.007 (0.013)\tLoss 0.8885 (0.8707)\tPrec@1 62.500 (63.548)\n",
            "Epoch: [86][50/97], lr: 0.01000\tTime 0.061 (0.082)\tData 0.000 (0.012)\tLoss 0.8762 (0.8747)\tPrec@1 56.250 (63.343)\n",
            "Epoch: [86][60/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.006 (0.010)\tLoss 0.7833 (0.8713)\tPrec@1 67.969 (63.832)\n",
            "Epoch: [86][70/97], lr: 0.01000\tTime 0.078 (0.079)\tData 0.012 (0.010)\tLoss 0.8531 (0.8726)\tPrec@1 60.938 (63.677)\n",
            "Epoch: [86][80/97], lr: 0.01000\tTime 0.078 (0.078)\tData 0.008 (0.009)\tLoss 0.9047 (0.8728)\tPrec@1 63.281 (63.764)\n",
            "Epoch: [86][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.008)\tLoss 0.9249 (0.8778)\tPrec@1 63.281 (63.487)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 1.0108 (1.0108)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.025 (0.058)\tLoss 1.0224 (1.0705)\tPrec@1 62.000 (55.909)\n",
            "Test: [20/100]\tTime 0.033 (0.047)\tLoss 1.1134 (1.0472)\tPrec@1 56.000 (56.476)\n",
            "Test: [30/100]\tTime 0.059 (0.042)\tLoss 1.0456 (1.0456)\tPrec@1 55.000 (56.677)\n",
            "Test: [40/100]\tTime 0.024 (0.039)\tLoss 1.0685 (1.0431)\tPrec@1 54.000 (56.585)\n",
            "Test: [50/100]\tTime 0.023 (0.038)\tLoss 1.0990 (1.0450)\tPrec@1 56.000 (56.353)\n",
            "Test: [60/100]\tTime 0.034 (0.037)\tLoss 1.2158 (1.0581)\tPrec@1 53.000 (55.951)\n",
            "Test: [70/100]\tTime 0.037 (0.036)\tLoss 0.9343 (1.0545)\tPrec@1 63.000 (56.127)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 1.0026 (1.0528)\tPrec@1 56.000 (56.123)\n",
            "Test: [90/100]\tTime 0.070 (0.036)\tLoss 0.9699 (1.0505)\tPrec@1 60.000 (56.374)\n",
            "val Results: Prec@1 56.480 Loss 1.04659\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [87][0/97], lr: 0.01000\tTime 0.543 (0.543)\tData 0.456 (0.456)\tLoss 0.9976 (0.9976)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [87][10/97], lr: 0.01000\tTime 0.079 (0.117)\tData 0.007 (0.045)\tLoss 0.8640 (0.8985)\tPrec@1 70.312 (64.062)\n",
            "Epoch: [87][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.025)\tLoss 0.8412 (0.8868)\tPrec@1 68.750 (64.137)\n",
            "Epoch: [87][30/97], lr: 0.01000\tTime 0.086 (0.088)\tData 0.007 (0.018)\tLoss 0.8362 (0.8743)\tPrec@1 64.062 (64.592)\n",
            "Epoch: [87][40/97], lr: 0.01000\tTime 0.067 (0.084)\tData 0.000 (0.014)\tLoss 0.9219 (0.8685)\tPrec@1 60.938 (64.748)\n",
            "Epoch: [87][50/97], lr: 0.01000\tTime 0.070 (0.082)\tData 0.007 (0.012)\tLoss 0.8106 (0.8632)\tPrec@1 62.500 (64.752)\n",
            "Epoch: [87][60/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.011)\tLoss 0.9197 (0.8684)\tPrec@1 64.062 (64.165)\n",
            "Epoch: [87][70/97], lr: 0.01000\tTime 0.081 (0.079)\tData 0.007 (0.010)\tLoss 0.8303 (0.8720)\tPrec@1 65.625 (63.776)\n",
            "Epoch: [87][80/97], lr: 0.01000\tTime 0.084 (0.078)\tData 0.000 (0.009)\tLoss 0.8481 (0.8683)\tPrec@1 65.625 (63.899)\n",
            "Epoch: [87][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.008)\tLoss 0.9060 (0.8713)\tPrec@1 60.938 (63.856)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 1.0168 (1.0168)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.021 (0.060)\tLoss 1.1080 (1.0722)\tPrec@1 51.000 (55.091)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 1.1854 (1.0754)\tPrec@1 47.000 (54.524)\n",
            "Test: [30/100]\tTime 0.039 (0.041)\tLoss 1.0829 (1.0836)\tPrec@1 54.000 (53.742)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 1.0530 (1.0802)\tPrec@1 59.000 (53.976)\n",
            "Test: [50/100]\tTime 0.062 (0.038)\tLoss 1.0498 (1.0795)\tPrec@1 56.000 (54.078)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.2202 (1.0838)\tPrec@1 52.000 (54.115)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 1.0331 (1.0866)\tPrec@1 56.000 (54.070)\n",
            "Test: [80/100]\tTime 0.047 (0.035)\tLoss 1.0524 (1.0881)\tPrec@1 55.000 (53.963)\n",
            "Test: [90/100]\tTime 0.022 (0.034)\tLoss 1.0619 (1.0890)\tPrec@1 55.000 (53.967)\n",
            "val Results: Prec@1 54.180 Loss 1.08692\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [88][0/97], lr: 0.01000\tTime 0.519 (0.519)\tData 0.432 (0.432)\tLoss 0.8381 (0.8381)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [88][10/97], lr: 0.01000\tTime 0.063 (0.117)\tData 0.000 (0.041)\tLoss 1.0538 (0.9385)\tPrec@1 51.562 (60.511)\n",
            "Epoch: [88][20/97], lr: 0.01000\tTime 0.065 (0.095)\tData 0.000 (0.022)\tLoss 0.9780 (0.9273)\tPrec@1 63.281 (61.384)\n",
            "Epoch: [88][30/97], lr: 0.01000\tTime 0.068 (0.089)\tData 0.000 (0.016)\tLoss 0.9914 (0.9287)\tPrec@1 62.500 (60.938)\n",
            "Epoch: [88][40/97], lr: 0.01000\tTime 0.068 (0.085)\tData 0.000 (0.013)\tLoss 0.8586 (0.9097)\tPrec@1 61.719 (61.814)\n",
            "Epoch: [88][50/97], lr: 0.01000\tTime 0.062 (0.082)\tData 0.000 (0.011)\tLoss 0.8961 (0.9129)\tPrec@1 62.500 (61.596)\n",
            "Epoch: [88][60/97], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.010)\tLoss 0.8582 (0.9148)\tPrec@1 59.375 (61.245)\n",
            "Epoch: [88][70/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.009)\tLoss 0.8688 (0.9066)\tPrec@1 60.938 (61.389)\n",
            "Epoch: [88][80/97], lr: 0.01000\tTime 0.083 (0.079)\tData 0.013 (0.008)\tLoss 0.7279 (0.9000)\tPrec@1 71.875 (61.854)\n",
            "Epoch: [88][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.008)\tLoss 0.8952 (0.8991)\tPrec@1 62.500 (61.942)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 0.9685 (0.9685)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.038 (0.061)\tLoss 0.9951 (0.9925)\tPrec@1 56.000 (58.182)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 1.1410 (0.9872)\tPrec@1 53.000 (58.524)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 1.0473 (0.9949)\tPrec@1 53.000 (57.806)\n",
            "Test: [40/100]\tTime 0.034 (0.038)\tLoss 0.9405 (0.9887)\tPrec@1 63.000 (58.220)\n",
            "Test: [50/100]\tTime 0.051 (0.038)\tLoss 1.0103 (0.9896)\tPrec@1 61.000 (58.529)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 1.0748 (0.9986)\tPrec@1 50.000 (58.000)\n",
            "Test: [70/100]\tTime 0.064 (0.036)\tLoss 0.9355 (0.9971)\tPrec@1 62.000 (57.915)\n",
            "Test: [80/100]\tTime 0.032 (0.035)\tLoss 0.9997 (0.9968)\tPrec@1 55.000 (57.753)\n",
            "Test: [90/100]\tTime 0.047 (0.035)\tLoss 1.0367 (0.9966)\tPrec@1 55.000 (57.824)\n",
            "val Results: Prec@1 58.130 Loss 0.99232\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [89][0/97], lr: 0.01000\tTime 0.535 (0.535)\tData 0.390 (0.390)\tLoss 0.7637 (0.7637)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [89][10/97], lr: 0.01000\tTime 0.069 (0.119)\tData 0.000 (0.040)\tLoss 0.9813 (0.8880)\tPrec@1 57.812 (62.855)\n",
            "Epoch: [89][20/97], lr: 0.01000\tTime 0.072 (0.096)\tData 0.000 (0.021)\tLoss 0.9600 (0.8806)\tPrec@1 57.812 (62.798)\n",
            "Epoch: [89][30/97], lr: 0.01000\tTime 0.064 (0.088)\tData 0.000 (0.015)\tLoss 0.8507 (0.8868)\tPrec@1 66.406 (63.155)\n",
            "Epoch: [89][40/97], lr: 0.01000\tTime 0.093 (0.085)\tData 0.000 (0.012)\tLoss 0.8347 (0.8816)\tPrec@1 67.969 (63.224)\n",
            "Epoch: [89][50/97], lr: 0.01000\tTime 0.079 (0.082)\tData 0.009 (0.010)\tLoss 0.8474 (0.8788)\tPrec@1 63.281 (63.343)\n",
            "Epoch: [89][60/97], lr: 0.01000\tTime 0.078 (0.080)\tData 0.000 (0.009)\tLoss 0.8225 (0.8785)\tPrec@1 63.281 (63.166)\n",
            "Epoch: [89][70/97], lr: 0.01000\tTime 0.072 (0.079)\tData 0.007 (0.008)\tLoss 0.9206 (0.8797)\tPrec@1 64.844 (63.116)\n",
            "Epoch: [89][80/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.007)\tLoss 0.9184 (0.8757)\tPrec@1 63.281 (63.223)\n",
            "Epoch: [89][90/97], lr: 0.01000\tTime 0.057 (0.077)\tData 0.000 (0.007)\tLoss 0.7463 (0.8753)\tPrec@1 70.312 (63.238)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 0.9353 (0.9353)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.071 (0.061)\tLoss 1.0235 (0.9995)\tPrec@1 56.000 (57.455)\n",
            "Test: [20/100]\tTime 0.040 (0.047)\tLoss 1.1063 (0.9868)\tPrec@1 56.000 (57.810)\n",
            "Test: [30/100]\tTime 0.031 (0.041)\tLoss 0.9852 (0.9974)\tPrec@1 58.000 (56.419)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.9378 (0.9978)\tPrec@1 63.000 (56.341)\n",
            "Test: [50/100]\tTime 0.028 (0.038)\tLoss 0.9815 (0.9972)\tPrec@1 55.000 (56.647)\n",
            "Test: [60/100]\tTime 0.036 (0.037)\tLoss 1.1362 (1.0047)\tPrec@1 53.000 (56.803)\n",
            "Test: [70/100]\tTime 0.047 (0.036)\tLoss 0.9479 (1.0024)\tPrec@1 61.000 (57.014)\n",
            "Test: [80/100]\tTime 0.061 (0.036)\tLoss 0.9588 (0.9994)\tPrec@1 56.000 (57.210)\n",
            "Test: [90/100]\tTime 0.030 (0.035)\tLoss 1.1067 (1.0010)\tPrec@1 57.000 (57.374)\n",
            "val Results: Prec@1 57.510 Loss 0.99650\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [90][0/97], lr: 0.01000\tTime 0.570 (0.570)\tData 0.444 (0.444)\tLoss 0.9114 (0.9114)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [90][10/97], lr: 0.01000\tTime 0.069 (0.118)\tData 0.000 (0.043)\tLoss 0.8930 (0.8517)\tPrec@1 61.719 (64.773)\n",
            "Epoch: [90][20/97], lr: 0.01000\tTime 0.063 (0.096)\tData 0.000 (0.024)\tLoss 0.8674 (0.8462)\tPrec@1 67.188 (64.732)\n",
            "Epoch: [90][30/97], lr: 0.01000\tTime 0.075 (0.089)\tData 0.009 (0.018)\tLoss 0.7169 (0.8346)\tPrec@1 71.094 (65.045)\n",
            "Epoch: [90][40/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.014)\tLoss 0.8622 (0.8366)\tPrec@1 62.500 (64.863)\n",
            "Epoch: [90][50/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.012)\tLoss 0.8249 (0.8428)\tPrec@1 64.062 (64.629)\n",
            "Epoch: [90][60/97], lr: 0.01000\tTime 0.089 (0.080)\tData 0.000 (0.010)\tLoss 0.7574 (0.8447)\tPrec@1 69.531 (64.485)\n",
            "Epoch: [90][70/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.007 (0.009)\tLoss 0.8199 (0.8450)\tPrec@1 66.406 (64.426)\n",
            "Epoch: [90][80/97], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.008)\tLoss 0.8354 (0.8455)\tPrec@1 63.281 (64.419)\n",
            "Epoch: [90][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.7349 (0.8493)\tPrec@1 71.094 (64.208)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 0.9949 (0.9949)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.022 (0.062)\tLoss 1.0823 (1.0660)\tPrec@1 56.000 (57.091)\n",
            "Test: [20/100]\tTime 0.026 (0.048)\tLoss 1.1995 (1.0488)\tPrec@1 53.000 (57.143)\n",
            "Test: [30/100]\tTime 0.039 (0.042)\tLoss 1.0807 (1.0612)\tPrec@1 57.000 (56.323)\n",
            "Test: [40/100]\tTime 0.045 (0.041)\tLoss 1.0251 (1.0571)\tPrec@1 59.000 (56.512)\n",
            "Test: [50/100]\tTime 0.053 (0.039)\tLoss 1.0807 (1.0561)\tPrec@1 57.000 (56.922)\n",
            "Test: [60/100]\tTime 0.033 (0.037)\tLoss 1.1797 (1.0633)\tPrec@1 51.000 (56.557)\n",
            "Test: [70/100]\tTime 0.073 (0.037)\tLoss 0.9057 (1.0530)\tPrec@1 63.000 (56.803)\n",
            "Test: [80/100]\tTime 0.055 (0.036)\tLoss 0.9411 (1.0540)\tPrec@1 60.000 (56.519)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.1259 (1.0511)\tPrec@1 54.000 (56.615)\n",
            "val Results: Prec@1 56.760 Loss 1.04717\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [91][0/97], lr: 0.01000\tTime 0.605 (0.605)\tData 0.390 (0.390)\tLoss 0.8072 (0.8072)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [91][10/97], lr: 0.01000\tTime 0.070 (0.121)\tData 0.007 (0.039)\tLoss 0.8542 (0.8297)\tPrec@1 60.938 (65.270)\n",
            "Epoch: [91][20/97], lr: 0.01000\tTime 0.083 (0.097)\tData 0.006 (0.023)\tLoss 0.8232 (0.8543)\tPrec@1 66.406 (64.509)\n",
            "Epoch: [91][30/97], lr: 0.01000\tTime 0.068 (0.088)\tData 0.000 (0.015)\tLoss 0.8593 (0.8501)\tPrec@1 66.406 (64.768)\n",
            "Epoch: [91][40/97], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.012)\tLoss 0.7558 (0.8477)\tPrec@1 67.188 (64.844)\n",
            "Epoch: [91][50/97], lr: 0.01000\tTime 0.081 (0.083)\tData 0.006 (0.010)\tLoss 0.8425 (0.8513)\tPrec@1 63.281 (64.721)\n",
            "Epoch: [91][60/97], lr: 0.01000\tTime 0.079 (0.081)\tData 0.001 (0.009)\tLoss 0.8456 (0.8567)\tPrec@1 64.844 (64.395)\n",
            "Epoch: [91][70/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.009)\tLoss 0.9171 (0.8589)\tPrec@1 60.938 (64.327)\n",
            "Epoch: [91][80/97], lr: 0.01000\tTime 0.081 (0.079)\tData 0.010 (0.008)\tLoss 0.8253 (0.8515)\tPrec@1 70.312 (64.709)\n",
            "Epoch: [91][90/97], lr: 0.01000\tTime 0.056 (0.078)\tData 0.000 (0.008)\tLoss 0.9550 (0.8541)\tPrec@1 57.812 (64.775)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 0.9717 (0.9717)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.022 (0.062)\tLoss 0.9869 (1.0103)\tPrec@1 59.000 (56.273)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 1.0244 (0.9957)\tPrec@1 57.000 (57.476)\n",
            "Test: [30/100]\tTime 0.031 (0.043)\tLoss 0.9937 (0.9999)\tPrec@1 57.000 (57.000)\n",
            "Test: [40/100]\tTime 0.037 (0.040)\tLoss 0.9347 (1.0000)\tPrec@1 61.000 (56.878)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 1.0545 (0.9991)\tPrec@1 57.000 (56.902)\n",
            "Test: [60/100]\tTime 0.030 (0.036)\tLoss 1.1269 (1.0013)\tPrec@1 53.000 (56.984)\n",
            "Test: [70/100]\tTime 0.022 (0.035)\tLoss 0.9416 (1.0013)\tPrec@1 55.000 (56.915)\n",
            "Test: [80/100]\tTime 0.046 (0.035)\tLoss 0.9654 (1.0000)\tPrec@1 58.000 (57.062)\n",
            "Test: [90/100]\tTime 0.052 (0.035)\tLoss 0.9286 (0.9988)\tPrec@1 62.000 (57.231)\n",
            "val Results: Prec@1 57.510 Loss 0.99377\n",
            "Best Prec@1: 58.690\n",
            "\n",
            "Epoch: [92][0/97], lr: 0.01000\tTime 0.484 (0.484)\tData 0.310 (0.310)\tLoss 0.9839 (0.9839)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [92][10/97], lr: 0.01000\tTime 0.062 (0.119)\tData 0.000 (0.032)\tLoss 0.8110 (0.9036)\tPrec@1 67.969 (62.429)\n",
            "Epoch: [92][20/97], lr: 0.01000\tTime 0.073 (0.098)\tData 0.009 (0.019)\tLoss 0.8418 (0.8825)\tPrec@1 63.281 (63.467)\n",
            "Epoch: [92][30/97], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.013)\tLoss 0.8363 (0.8666)\tPrec@1 67.188 (64.365)\n",
            "Epoch: [92][40/97], lr: 0.01000\tTime 0.065 (0.085)\tData 0.000 (0.011)\tLoss 0.7826 (0.8654)\tPrec@1 67.969 (64.386)\n",
            "Epoch: [92][50/97], lr: 0.01000\tTime 0.062 (0.082)\tData 0.000 (0.009)\tLoss 0.8897 (0.8752)\tPrec@1 64.844 (63.894)\n",
            "Epoch: [92][60/97], lr: 0.01000\tTime 0.080 (0.081)\tData 0.000 (0.009)\tLoss 0.8535 (0.8743)\tPrec@1 60.156 (63.986)\n",
            "Epoch: [92][70/97], lr: 0.01000\tTime 0.073 (0.080)\tData 0.007 (0.008)\tLoss 0.8817 (0.8747)\tPrec@1 61.719 (63.853)\n",
            "Epoch: [92][80/97], lr: 0.01000\tTime 0.091 (0.079)\tData 0.007 (0.008)\tLoss 0.9229 (0.8815)\tPrec@1 59.375 (63.551)\n",
            "Epoch: [92][90/97], lr: 0.01000\tTime 0.057 (0.078)\tData 0.000 (0.007)\tLoss 0.8892 (0.8775)\tPrec@1 64.062 (63.788)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 0.9801 (0.9801)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 0.9885 (0.9978)\tPrec@1 62.000 (58.727)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 1.0604 (0.9865)\tPrec@1 58.000 (59.524)\n",
            "Test: [30/100]\tTime 0.035 (0.041)\tLoss 1.0011 (0.9905)\tPrec@1 52.000 (59.065)\n",
            "Test: [40/100]\tTime 0.031 (0.039)\tLoss 0.9440 (0.9899)\tPrec@1 56.000 (58.927)\n",
            "Test: [50/100]\tTime 0.033 (0.038)\tLoss 1.0726 (0.9918)\tPrec@1 54.000 (58.745)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1134 (0.9995)\tPrec@1 56.000 (58.705)\n",
            "Test: [70/100]\tTime 0.027 (0.036)\tLoss 0.9969 (0.9981)\tPrec@1 60.000 (58.620)\n",
            "Test: [80/100]\tTime 0.027 (0.035)\tLoss 0.9550 (0.9987)\tPrec@1 57.000 (58.506)\n",
            "Test: [90/100]\tTime 0.036 (0.035)\tLoss 0.9906 (0.9981)\tPrec@1 58.000 (58.637)\n",
            "val Results: Prec@1 59.070 Loss 0.99326\n",
            "Best Prec@1: 59.070\n",
            "\n",
            "Epoch: [93][0/97], lr: 0.01000\tTime 0.528 (0.528)\tData 0.356 (0.356)\tLoss 0.7125 (0.7125)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [93][10/97], lr: 0.01000\tTime 0.073 (0.115)\tData 0.010 (0.035)\tLoss 0.9031 (0.8678)\tPrec@1 63.281 (64.418)\n",
            "Epoch: [93][20/97], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.020)\tLoss 0.8867 (0.8653)\tPrec@1 62.500 (64.062)\n",
            "Epoch: [93][30/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.014)\tLoss 0.8349 (0.8602)\tPrec@1 64.844 (64.239)\n",
            "Epoch: [93][40/97], lr: 0.01000\tTime 0.083 (0.082)\tData 0.015 (0.012)\tLoss 0.8005 (0.8633)\tPrec@1 67.969 (63.834)\n",
            "Epoch: [93][50/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.007 (0.010)\tLoss 0.9202 (0.8630)\tPrec@1 61.719 (63.971)\n",
            "Epoch: [93][60/97], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.009)\tLoss 0.7809 (0.8583)\tPrec@1 66.406 (64.178)\n",
            "Epoch: [93][70/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.003 (0.008)\tLoss 0.8585 (0.8631)\tPrec@1 62.500 (63.930)\n",
            "Epoch: [93][80/97], lr: 0.01000\tTime 0.094 (0.079)\tData 0.000 (0.007)\tLoss 0.7126 (0.8585)\tPrec@1 69.531 (64.265)\n",
            "Epoch: [93][90/97], lr: 0.01000\tTime 0.040 (0.079)\tData 0.000 (0.007)\tLoss 0.7960 (0.8580)\tPrec@1 63.281 (64.277)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.9518 (0.9518)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.034 (0.065)\tLoss 0.9969 (0.9824)\tPrec@1 54.000 (58.182)\n",
            "Test: [20/100]\tTime 0.021 (0.050)\tLoss 1.1278 (0.9816)\tPrec@1 56.000 (58.381)\n",
            "Test: [30/100]\tTime 0.054 (0.046)\tLoss 1.0264 (0.9895)\tPrec@1 55.000 (57.419)\n",
            "Test: [40/100]\tTime 0.045 (0.044)\tLoss 0.9664 (0.9904)\tPrec@1 57.000 (57.171)\n",
            "Test: [50/100]\tTime 0.028 (0.041)\tLoss 1.0341 (0.9934)\tPrec@1 56.000 (57.255)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.1544 (1.0012)\tPrec@1 46.000 (57.197)\n",
            "Test: [70/100]\tTime 0.034 (0.040)\tLoss 0.9644 (0.9994)\tPrec@1 63.000 (57.493)\n",
            "Test: [80/100]\tTime 0.039 (0.040)\tLoss 0.9319 (0.9971)\tPrec@1 58.000 (57.420)\n",
            "Test: [90/100]\tTime 0.026 (0.039)\tLoss 1.0382 (0.9975)\tPrec@1 55.000 (57.330)\n",
            "val Results: Prec@1 57.600 Loss 0.99322\n",
            "Best Prec@1: 59.070\n",
            "\n",
            "Epoch: [94][0/97], lr: 0.01000\tTime 0.718 (0.718)\tData 0.567 (0.567)\tLoss 0.8618 (0.8618)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [94][10/97], lr: 0.01000\tTime 0.127 (0.211)\tData 0.006 (0.057)\tLoss 0.8364 (0.8447)\tPrec@1 64.062 (63.068)\n",
            "Epoch: [94][20/97], lr: 0.01000\tTime 0.075 (0.169)\tData 0.000 (0.032)\tLoss 0.8494 (0.8495)\tPrec@1 62.500 (63.095)\n",
            "Epoch: [94][30/97], lr: 0.01000\tTime 0.109 (0.143)\tData 0.007 (0.022)\tLoss 0.8125 (0.8422)\tPrec@1 67.188 (64.315)\n",
            "Epoch: [94][40/97], lr: 0.01000\tTime 0.084 (0.126)\tData 0.003 (0.018)\tLoss 0.8073 (0.8351)\tPrec@1 64.844 (64.615)\n",
            "Epoch: [94][50/97], lr: 0.01000\tTime 0.082 (0.116)\tData 0.000 (0.015)\tLoss 0.7771 (0.8430)\tPrec@1 64.062 (64.445)\n",
            "Epoch: [94][60/97], lr: 0.01000\tTime 0.086 (0.109)\tData 0.007 (0.013)\tLoss 0.9275 (0.8482)\tPrec@1 60.156 (64.331)\n",
            "Epoch: [94][70/97], lr: 0.01000\tTime 0.081 (0.107)\tData 0.000 (0.011)\tLoss 0.7632 (0.8534)\tPrec@1 67.188 (64.007)\n",
            "Epoch: [94][80/97], lr: 0.01000\tTime 0.073 (0.105)\tData 0.008 (0.010)\tLoss 0.8362 (0.8503)\tPrec@1 65.625 (64.169)\n",
            "Epoch: [94][90/97], lr: 0.01000\tTime 0.056 (0.102)\tData 0.000 (0.009)\tLoss 0.8544 (0.8499)\tPrec@1 66.406 (64.337)\n",
            "Test: [0/100]\tTime 0.402 (0.402)\tLoss 0.9099 (0.9099)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.024 (0.071)\tLoss 0.9427 (0.9625)\tPrec@1 62.000 (59.545)\n",
            "Test: [20/100]\tTime 0.071 (0.057)\tLoss 1.0517 (0.9588)\tPrec@1 56.000 (59.810)\n",
            "Test: [30/100]\tTime 0.036 (0.050)\tLoss 1.0157 (0.9638)\tPrec@1 57.000 (59.710)\n",
            "Test: [40/100]\tTime 0.024 (0.045)\tLoss 0.9732 (0.9646)\tPrec@1 57.000 (59.829)\n",
            "Test: [50/100]\tTime 0.047 (0.043)\tLoss 0.9919 (0.9647)\tPrec@1 58.000 (59.471)\n",
            "Test: [60/100]\tTime 0.026 (0.042)\tLoss 1.0690 (0.9708)\tPrec@1 56.000 (59.279)\n",
            "Test: [70/100]\tTime 0.022 (0.040)\tLoss 0.9056 (0.9699)\tPrec@1 59.000 (59.099)\n",
            "Test: [80/100]\tTime 0.024 (0.039)\tLoss 0.9650 (0.9679)\tPrec@1 55.000 (59.111)\n",
            "Test: [90/100]\tTime 0.046 (0.038)\tLoss 0.9237 (0.9658)\tPrec@1 58.000 (59.165)\n",
            "val Results: Prec@1 59.420 Loss 0.96078\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [95][0/97], lr: 0.01000\tTime 0.470 (0.470)\tData 0.273 (0.273)\tLoss 0.7661 (0.7661)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [95][10/97], lr: 0.01000\tTime 0.062 (0.117)\tData 0.000 (0.028)\tLoss 0.9333 (0.8645)\tPrec@1 63.281 (63.068)\n",
            "Epoch: [95][20/97], lr: 0.01000\tTime 0.077 (0.097)\tData 0.007 (0.017)\tLoss 0.7788 (0.8460)\tPrec@1 66.406 (64.435)\n",
            "Epoch: [95][30/97], lr: 0.01000\tTime 0.062 (0.088)\tData 0.000 (0.012)\tLoss 0.8924 (0.8502)\tPrec@1 56.250 (63.936)\n",
            "Epoch: [95][40/97], lr: 0.01000\tTime 0.066 (0.084)\tData 0.000 (0.010)\tLoss 0.8512 (0.8495)\tPrec@1 61.719 (64.444)\n",
            "Epoch: [95][50/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.008)\tLoss 0.8074 (0.8467)\tPrec@1 65.625 (64.660)\n",
            "Epoch: [95][60/97], lr: 0.01000\tTime 0.066 (0.080)\tData 0.001 (0.008)\tLoss 0.8790 (0.8522)\tPrec@1 62.500 (64.255)\n",
            "Epoch: [95][70/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.007)\tLoss 0.8299 (0.8476)\tPrec@1 65.625 (64.679)\n",
            "Epoch: [95][80/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.006 (0.007)\tLoss 0.8114 (0.8478)\tPrec@1 68.750 (64.709)\n",
            "Epoch: [95][90/97], lr: 0.01000\tTime 0.061 (0.077)\tData 0.000 (0.006)\tLoss 0.9239 (0.8501)\tPrec@1 60.156 (64.569)\n",
            "Test: [0/100]\tTime 0.441 (0.441)\tLoss 0.9331 (0.9331)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.057 (0.105)\tLoss 1.0198 (1.0236)\tPrec@1 57.000 (58.091)\n",
            "Test: [20/100]\tTime 0.054 (0.084)\tLoss 1.1411 (1.0115)\tPrec@1 54.000 (58.333)\n",
            "Test: [30/100]\tTime 0.088 (0.076)\tLoss 1.0307 (1.0125)\tPrec@1 56.000 (57.968)\n",
            "Test: [40/100]\tTime 0.080 (0.072)\tLoss 1.0538 (1.0140)\tPrec@1 57.000 (57.341)\n",
            "Test: [50/100]\tTime 0.051 (0.069)\tLoss 1.0279 (1.0131)\tPrec@1 52.000 (57.196)\n",
            "Test: [60/100]\tTime 0.031 (0.067)\tLoss 1.1610 (1.0201)\tPrec@1 51.000 (56.934)\n",
            "Test: [70/100]\tTime 0.029 (0.063)\tLoss 0.9265 (1.0156)\tPrec@1 63.000 (57.324)\n",
            "Test: [80/100]\tTime 0.023 (0.059)\tLoss 0.9345 (1.0151)\tPrec@1 62.000 (57.185)\n",
            "Test: [90/100]\tTime 0.036 (0.056)\tLoss 1.0206 (1.0140)\tPrec@1 60.000 (57.132)\n",
            "val Results: Prec@1 57.360 Loss 1.00824\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [96][0/97], lr: 0.01000\tTime 0.450 (0.450)\tData 0.301 (0.301)\tLoss 0.8001 (0.8001)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [96][10/97], lr: 0.01000\tTime 0.077 (0.115)\tData 0.000 (0.031)\tLoss 0.8171 (0.8213)\tPrec@1 69.531 (66.193)\n",
            "Epoch: [96][20/97], lr: 0.01000\tTime 0.062 (0.100)\tData 0.000 (0.017)\tLoss 0.8641 (0.8305)\tPrec@1 65.625 (66.146)\n",
            "Epoch: [96][30/97], lr: 0.01000\tTime 0.089 (0.096)\tData 0.000 (0.013)\tLoss 0.7937 (0.8348)\tPrec@1 71.875 (65.927)\n",
            "Epoch: [96][40/97], lr: 0.01000\tTime 0.068 (0.093)\tData 0.001 (0.011)\tLoss 0.7753 (0.8420)\tPrec@1 67.188 (65.511)\n",
            "Epoch: [96][50/97], lr: 0.01000\tTime 0.088 (0.092)\tData 0.005 (0.009)\tLoss 0.8649 (0.8469)\tPrec@1 64.844 (65.242)\n",
            "Epoch: [96][60/97], lr: 0.01000\tTime 0.074 (0.091)\tData 0.001 (0.008)\tLoss 0.8902 (0.8515)\tPrec@1 60.156 (64.921)\n",
            "Epoch: [96][70/97], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.007)\tLoss 0.8999 (0.8480)\tPrec@1 63.281 (64.954)\n",
            "Epoch: [96][80/97], lr: 0.01000\tTime 0.064 (0.087)\tData 0.000 (0.007)\tLoss 0.9476 (0.8465)\tPrec@1 53.125 (64.931)\n",
            "Epoch: [96][90/97], lr: 0.01000\tTime 0.046 (0.085)\tData 0.000 (0.006)\tLoss 0.9072 (0.8473)\tPrec@1 62.500 (64.955)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 1.2202 (1.2202)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.048 (0.062)\tLoss 1.2108 (1.1870)\tPrec@1 53.000 (48.818)\n",
            "Test: [20/100]\tTime 0.033 (0.053)\tLoss 1.1555 (1.1671)\tPrec@1 53.000 (50.286)\n",
            "Test: [30/100]\tTime 0.029 (0.048)\tLoss 1.1469 (1.1563)\tPrec@1 50.000 (50.355)\n",
            "Test: [40/100]\tTime 0.025 (0.044)\tLoss 0.9911 (1.1459)\tPrec@1 59.000 (50.878)\n",
            "Test: [50/100]\tTime 0.031 (0.043)\tLoss 1.1207 (1.1432)\tPrec@1 54.000 (51.098)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.2633 (1.1462)\tPrec@1 49.000 (51.246)\n",
            "Test: [70/100]\tTime 0.033 (0.041)\tLoss 1.1239 (1.1435)\tPrec@1 53.000 (51.437)\n",
            "Test: [80/100]\tTime 0.040 (0.040)\tLoss 1.1404 (1.1370)\tPrec@1 50.000 (51.790)\n",
            "Test: [90/100]\tTime 0.023 (0.040)\tLoss 1.0488 (1.1366)\tPrec@1 51.000 (51.681)\n",
            "val Results: Prec@1 51.900 Loss 1.13303\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [97][0/97], lr: 0.01000\tTime 0.524 (0.524)\tData 0.340 (0.340)\tLoss 0.9828 (0.9828)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [97][10/97], lr: 0.01000\tTime 0.091 (0.117)\tData 0.007 (0.036)\tLoss 1.0174 (0.9428)\tPrec@1 60.156 (61.151)\n",
            "Epoch: [97][20/97], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.020)\tLoss 0.9279 (0.9268)\tPrec@1 63.281 (60.863)\n",
            "Epoch: [97][30/97], lr: 0.01000\tTime 0.073 (0.087)\tData 0.009 (0.015)\tLoss 0.9110 (0.9172)\tPrec@1 64.062 (61.593)\n",
            "Epoch: [97][40/97], lr: 0.01000\tTime 0.080 (0.084)\tData 0.011 (0.012)\tLoss 0.8660 (0.9126)\tPrec@1 63.281 (61.757)\n",
            "Epoch: [97][50/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.010)\tLoss 0.7776 (0.9076)\tPrec@1 65.625 (61.612)\n",
            "Epoch: [97][60/97], lr: 0.01000\tTime 0.094 (0.080)\tData 0.000 (0.009)\tLoss 0.7880 (0.9013)\tPrec@1 74.219 (62.065)\n",
            "Epoch: [97][70/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.002 (0.008)\tLoss 0.8050 (0.9058)\tPrec@1 66.406 (61.906)\n",
            "Epoch: [97][80/97], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.007)\tLoss 0.8366 (0.8991)\tPrec@1 65.625 (62.297)\n",
            "Epoch: [97][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.9585 (0.8995)\tPrec@1 61.719 (62.328)\n",
            "Test: [0/100]\tTime 0.261 (0.261)\tLoss 0.9735 (0.9735)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.032 (0.061)\tLoss 1.0809 (1.0269)\tPrec@1 57.000 (56.364)\n",
            "Test: [20/100]\tTime 0.034 (0.045)\tLoss 1.1169 (1.0114)\tPrec@1 50.000 (56.952)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 1.0539 (1.0195)\tPrec@1 56.000 (56.516)\n",
            "Test: [40/100]\tTime 0.025 (0.040)\tLoss 1.0443 (1.0142)\tPrec@1 55.000 (56.683)\n",
            "Test: [50/100]\tTime 0.031 (0.039)\tLoss 1.0211 (1.0153)\tPrec@1 56.000 (56.490)\n",
            "Test: [60/100]\tTime 0.030 (0.038)\tLoss 1.0918 (1.0165)\tPrec@1 51.000 (56.623)\n",
            "Test: [70/100]\tTime 0.024 (0.037)\tLoss 1.0152 (1.0159)\tPrec@1 56.000 (56.634)\n",
            "Test: [80/100]\tTime 0.033 (0.036)\tLoss 0.9776 (1.0152)\tPrec@1 58.000 (56.679)\n",
            "Test: [90/100]\tTime 0.037 (0.036)\tLoss 1.0320 (1.0131)\tPrec@1 57.000 (56.758)\n",
            "val Results: Prec@1 57.010 Loss 1.00701\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [98][0/97], lr: 0.01000\tTime 0.450 (0.450)\tData 0.258 (0.258)\tLoss 0.9908 (0.9908)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [98][10/97], lr: 0.01000\tTime 0.064 (0.116)\tData 0.000 (0.027)\tLoss 0.8004 (0.8741)\tPrec@1 64.844 (63.494)\n",
            "Epoch: [98][20/97], lr: 0.01000\tTime 0.075 (0.096)\tData 0.000 (0.015)\tLoss 0.9398 (0.8766)\tPrec@1 60.938 (64.025)\n",
            "Epoch: [98][30/97], lr: 0.01000\tTime 0.070 (0.088)\tData 0.000 (0.011)\tLoss 0.8378 (0.8657)\tPrec@1 61.719 (64.113)\n",
            "Epoch: [98][40/97], lr: 0.01000\tTime 0.065 (0.085)\tData 0.000 (0.009)\tLoss 0.7628 (0.8585)\tPrec@1 64.062 (64.196)\n",
            "Epoch: [98][50/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.008)\tLoss 1.0340 (0.8673)\tPrec@1 56.250 (64.017)\n",
            "Epoch: [98][60/97], lr: 0.01000\tTime 0.076 (0.081)\tData 0.011 (0.007)\tLoss 0.7851 (0.8664)\tPrec@1 66.406 (63.730)\n",
            "Epoch: [98][70/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.007)\tLoss 0.8301 (0.8636)\tPrec@1 64.844 (63.831)\n",
            "Epoch: [98][80/97], lr: 0.01000\tTime 0.073 (0.081)\tData 0.012 (0.006)\tLoss 0.9382 (0.8674)\tPrec@1 60.156 (63.667)\n",
            "Epoch: [98][90/97], lr: 0.01000\tTime 0.057 (0.081)\tData 0.000 (0.006)\tLoss 0.8343 (0.8658)\tPrec@1 65.625 (63.805)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 0.9429 (0.9429)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.046 (0.064)\tLoss 0.9605 (1.0148)\tPrec@1 64.000 (57.727)\n",
            "Test: [20/100]\tTime 0.045 (0.048)\tLoss 1.1897 (1.0279)\tPrec@1 46.000 (57.476)\n",
            "Test: [30/100]\tTime 0.069 (0.044)\tLoss 1.0656 (1.0296)\tPrec@1 54.000 (56.806)\n",
            "Test: [40/100]\tTime 0.028 (0.041)\tLoss 1.0258 (1.0318)\tPrec@1 55.000 (56.317)\n",
            "Test: [50/100]\tTime 0.038 (0.040)\tLoss 0.9966 (1.0312)\tPrec@1 59.000 (56.588)\n",
            "Test: [60/100]\tTime 0.025 (0.039)\tLoss 1.1656 (1.0365)\tPrec@1 49.000 (56.393)\n",
            "Test: [70/100]\tTime 0.036 (0.038)\tLoss 0.9494 (1.0359)\tPrec@1 61.000 (56.338)\n",
            "Test: [80/100]\tTime 0.053 (0.037)\tLoss 0.9992 (1.0377)\tPrec@1 60.000 (56.469)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 1.0707 (1.0347)\tPrec@1 54.000 (56.560)\n",
            "val Results: Prec@1 56.870 Loss 1.02980\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [99][0/97], lr: 0.01000\tTime 0.548 (0.548)\tData 0.353 (0.353)\tLoss 0.8360 (0.8360)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [99][10/97], lr: 0.01000\tTime 0.073 (0.119)\tData 0.007 (0.035)\tLoss 0.9658 (0.9013)\tPrec@1 56.250 (61.222)\n",
            "Epoch: [99][20/97], lr: 0.01000\tTime 0.068 (0.098)\tData 0.000 (0.020)\tLoss 1.0152 (0.9277)\tPrec@1 58.594 (60.007)\n",
            "Epoch: [99][30/97], lr: 0.01000\tTime 0.064 (0.090)\tData 0.000 (0.015)\tLoss 0.9528 (0.9075)\tPrec@1 60.938 (61.114)\n",
            "Epoch: [99][40/97], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.011)\tLoss 0.8560 (0.8910)\tPrec@1 64.062 (61.719)\n",
            "Epoch: [99][50/97], lr: 0.01000\tTime 0.066 (0.084)\tData 0.000 (0.010)\tLoss 0.8011 (0.8870)\tPrec@1 68.750 (62.270)\n",
            "Epoch: [99][60/97], lr: 0.01000\tTime 0.080 (0.083)\tData 0.000 (0.008)\tLoss 0.9020 (0.8895)\tPrec@1 60.156 (62.398)\n",
            "Epoch: [99][70/97], lr: 0.01000\tTime 0.069 (0.081)\tData 0.006 (0.008)\tLoss 0.7792 (0.8812)\tPrec@1 63.281 (62.797)\n",
            "Epoch: [99][80/97], lr: 0.01000\tTime 0.072 (0.080)\tData 0.007 (0.007)\tLoss 0.8287 (0.8766)\tPrec@1 62.500 (63.040)\n",
            "Epoch: [99][90/97], lr: 0.01000\tTime 0.055 (0.079)\tData 0.000 (0.007)\tLoss 0.9276 (0.8733)\tPrec@1 60.156 (63.170)\n",
            "Test: [0/100]\tTime 0.314 (0.314)\tLoss 0.9393 (0.9393)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.024 (0.061)\tLoss 0.9968 (0.9890)\tPrec@1 57.000 (57.545)\n",
            "Test: [20/100]\tTime 0.034 (0.048)\tLoss 1.1127 (0.9867)\tPrec@1 49.000 (57.048)\n",
            "Test: [30/100]\tTime 0.023 (0.043)\tLoss 1.0038 (0.9975)\tPrec@1 58.000 (56.677)\n",
            "Test: [40/100]\tTime 0.036 (0.040)\tLoss 0.9655 (0.9949)\tPrec@1 59.000 (56.927)\n",
            "Test: [50/100]\tTime 0.023 (0.038)\tLoss 1.0038 (0.9966)\tPrec@1 62.000 (57.039)\n",
            "Test: [60/100]\tTime 0.022 (0.038)\tLoss 1.0661 (1.0054)\tPrec@1 57.000 (56.984)\n",
            "Test: [70/100]\tTime 0.031 (0.037)\tLoss 0.9186 (1.0055)\tPrec@1 62.000 (57.113)\n",
            "Test: [80/100]\tTime 0.022 (0.036)\tLoss 0.9837 (1.0050)\tPrec@1 55.000 (57.148)\n",
            "Test: [90/100]\tTime 0.037 (0.036)\tLoss 1.1106 (1.0020)\tPrec@1 54.000 (57.374)\n",
            "val Results: Prec@1 57.490 Loss 0.99661\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [100][0/97], lr: 0.01000\tTime 0.444 (0.444)\tData 0.303 (0.303)\tLoss 0.7580 (0.7580)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [100][10/97], lr: 0.01000\tTime 0.068 (0.120)\tData 0.000 (0.034)\tLoss 0.9970 (0.8323)\tPrec@1 59.375 (65.483)\n",
            "Epoch: [100][20/97], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.018)\tLoss 0.9659 (0.8367)\tPrec@1 64.062 (65.699)\n",
            "Epoch: [100][30/97], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.013)\tLoss 0.8756 (0.8472)\tPrec@1 61.719 (64.945)\n",
            "Epoch: [100][40/97], lr: 0.01000\tTime 0.097 (0.085)\tData 0.011 (0.011)\tLoss 0.9037 (0.8557)\tPrec@1 67.188 (64.691)\n",
            "Epoch: [100][50/97], lr: 0.01000\tTime 0.071 (0.083)\tData 0.009 (0.010)\tLoss 0.8488 (0.8566)\tPrec@1 64.062 (64.369)\n",
            "Epoch: [100][60/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.008)\tLoss 0.8269 (0.8535)\tPrec@1 64.844 (64.588)\n",
            "Epoch: [100][70/97], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.007)\tLoss 0.8899 (0.8571)\tPrec@1 60.938 (64.349)\n",
            "Epoch: [100][80/97], lr: 0.01000\tTime 0.083 (0.080)\tData 0.000 (0.007)\tLoss 0.8624 (0.8561)\tPrec@1 65.625 (64.439)\n",
            "Epoch: [100][90/97], lr: 0.01000\tTime 0.053 (0.078)\tData 0.000 (0.006)\tLoss 0.9055 (0.8632)\tPrec@1 60.938 (64.028)\n",
            "Test: [0/100]\tTime 0.261 (0.261)\tLoss 0.9113 (0.9113)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.036 (0.061)\tLoss 0.9882 (0.9969)\tPrec@1 61.000 (58.273)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 1.1011 (1.0169)\tPrec@1 52.000 (56.524)\n",
            "Test: [30/100]\tTime 0.031 (0.043)\tLoss 1.0207 (1.0276)\tPrec@1 57.000 (56.484)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9355 (1.0229)\tPrec@1 60.000 (56.512)\n",
            "Test: [50/100]\tTime 0.051 (0.038)\tLoss 1.0668 (1.0301)\tPrec@1 52.000 (56.627)\n",
            "Test: [60/100]\tTime 0.032 (0.037)\tLoss 1.1152 (1.0388)\tPrec@1 49.000 (56.426)\n",
            "Test: [70/100]\tTime 0.027 (0.036)\tLoss 1.0071 (1.0375)\tPrec@1 60.000 (56.563)\n",
            "Test: [80/100]\tTime 0.027 (0.035)\tLoss 1.0341 (1.0356)\tPrec@1 59.000 (56.568)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.0739 (1.0365)\tPrec@1 57.000 (56.637)\n",
            "val Results: Prec@1 57.020 Loss 1.03232\n",
            "Best Prec@1: 59.420\n",
            "\n",
            "Epoch: [101][0/97], lr: 0.01000\tTime 0.509 (0.509)\tData 0.313 (0.313)\tLoss 0.9635 (0.9635)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [101][10/97], lr: 0.01000\tTime 0.068 (0.115)\tData 0.000 (0.031)\tLoss 0.8079 (0.9009)\tPrec@1 66.406 (61.080)\n",
            "Epoch: [101][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.018)\tLoss 0.9016 (0.8849)\tPrec@1 62.500 (62.984)\n",
            "Epoch: [101][30/97], lr: 0.01000\tTime 0.064 (0.088)\tData 0.000 (0.012)\tLoss 0.7376 (0.8595)\tPrec@1 75.000 (64.340)\n",
            "Epoch: [101][40/97], lr: 0.01000\tTime 0.070 (0.085)\tData 0.000 (0.011)\tLoss 0.8849 (0.8680)\tPrec@1 65.625 (64.082)\n",
            "Epoch: [101][50/97], lr: 0.01000\tTime 0.088 (0.083)\tData 0.002 (0.009)\tLoss 0.8218 (0.8632)\tPrec@1 69.531 (64.093)\n",
            "Epoch: [101][60/97], lr: 0.01000\tTime 0.090 (0.081)\tData 0.000 (0.008)\tLoss 0.8592 (0.8642)\tPrec@1 64.062 (64.114)\n",
            "Epoch: [101][70/97], lr: 0.01000\tTime 0.091 (0.079)\tData 0.000 (0.007)\tLoss 0.7270 (0.8624)\tPrec@1 68.750 (64.074)\n",
            "Epoch: [101][80/97], lr: 0.01000\tTime 0.067 (0.078)\tData 0.000 (0.006)\tLoss 0.7885 (0.8611)\tPrec@1 67.188 (64.159)\n",
            "Epoch: [101][90/97], lr: 0.01000\tTime 0.053 (0.077)\tData 0.000 (0.006)\tLoss 0.8030 (0.8606)\tPrec@1 64.844 (64.286)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 0.9183 (0.9183)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.030 (0.061)\tLoss 0.9588 (0.9558)\tPrec@1 63.000 (60.091)\n",
            "Test: [20/100]\tTime 0.042 (0.048)\tLoss 1.0575 (0.9487)\tPrec@1 54.000 (59.714)\n",
            "Test: [30/100]\tTime 0.034 (0.043)\tLoss 0.9167 (0.9592)\tPrec@1 62.000 (59.194)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.9277 (0.9592)\tPrec@1 61.000 (59.073)\n",
            "Test: [50/100]\tTime 0.037 (0.039)\tLoss 1.0018 (0.9598)\tPrec@1 59.000 (58.980)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.0705 (0.9678)\tPrec@1 61.000 (59.016)\n",
            "Test: [70/100]\tTime 0.034 (0.037)\tLoss 0.9245 (0.9659)\tPrec@1 60.000 (58.901)\n",
            "Test: [80/100]\tTime 0.044 (0.036)\tLoss 0.9174 (0.9634)\tPrec@1 61.000 (59.074)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 1.0232 (0.9631)\tPrec@1 60.000 (59.231)\n",
            "val Results: Prec@1 59.430 Loss 0.95919\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "Epoch: [102][0/97], lr: 0.01000\tTime 0.561 (0.561)\tData 0.369 (0.369)\tLoss 0.8937 (0.8937)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [102][10/97], lr: 0.01000\tTime 0.071 (0.118)\tData 0.008 (0.037)\tLoss 0.8413 (0.8592)\tPrec@1 68.750 (64.702)\n",
            "Epoch: [102][20/97], lr: 0.01000\tTime 0.077 (0.096)\tData 0.007 (0.021)\tLoss 0.9096 (0.8828)\tPrec@1 67.969 (63.765)\n",
            "Epoch: [102][30/97], lr: 0.01000\tTime 0.082 (0.088)\tData 0.012 (0.015)\tLoss 0.7740 (0.8887)\tPrec@1 71.875 (63.558)\n",
            "Epoch: [102][40/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.012)\tLoss 1.0459 (0.8928)\tPrec@1 51.562 (63.014)\n",
            "Epoch: [102][50/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.010)\tLoss 0.8244 (0.8873)\tPrec@1 68.750 (63.327)\n",
            "Epoch: [102][60/97], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.008)\tLoss 0.9306 (0.8854)\tPrec@1 61.719 (63.461)\n",
            "Epoch: [102][70/97], lr: 0.01000\tTime 0.099 (0.079)\tData 0.000 (0.007)\tLoss 0.7689 (0.8842)\tPrec@1 70.312 (63.402)\n",
            "Epoch: [102][80/97], lr: 0.01000\tTime 0.087 (0.078)\tData 0.000 (0.007)\tLoss 0.6475 (0.8798)\tPrec@1 74.219 (63.436)\n",
            "Epoch: [102][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.006)\tLoss 0.8730 (0.8775)\tPrec@1 65.625 (63.427)\n",
            "Test: [0/100]\tTime 0.363 (0.363)\tLoss 0.9459 (0.9459)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 1.0036 (1.0004)\tPrec@1 54.000 (57.909)\n",
            "Test: [20/100]\tTime 0.025 (0.047)\tLoss 1.1250 (1.0048)\tPrec@1 50.000 (57.667)\n",
            "Test: [30/100]\tTime 0.039 (0.043)\tLoss 0.9831 (1.0176)\tPrec@1 57.000 (57.065)\n",
            "Test: [40/100]\tTime 0.031 (0.040)\tLoss 0.9332 (1.0203)\tPrec@1 57.000 (57.146)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 1.0655 (1.0251)\tPrec@1 58.000 (57.039)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1650 (1.0320)\tPrec@1 50.000 (56.934)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9420 (1.0267)\tPrec@1 59.000 (57.014)\n",
            "Test: [80/100]\tTime 0.021 (0.036)\tLoss 0.9920 (1.0254)\tPrec@1 57.000 (56.963)\n",
            "Test: [90/100]\tTime 0.028 (0.035)\tLoss 1.1265 (1.0245)\tPrec@1 56.000 (56.945)\n",
            "val Results: Prec@1 57.210 Loss 1.01894\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "Epoch: [103][0/97], lr: 0.01000\tTime 0.510 (0.510)\tData 0.311 (0.311)\tLoss 0.8166 (0.8166)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [103][10/97], lr: 0.01000\tTime 0.067 (0.119)\tData 0.000 (0.033)\tLoss 0.9435 (0.8622)\tPrec@1 59.375 (63.707)\n",
            "Epoch: [103][20/97], lr: 0.01000\tTime 0.063 (0.095)\tData 0.000 (0.018)\tLoss 0.8131 (0.8654)\tPrec@1 65.625 (63.690)\n",
            "Epoch: [103][30/97], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.013)\tLoss 0.7516 (0.8620)\tPrec@1 67.969 (64.264)\n",
            "Epoch: [103][40/97], lr: 0.01000\tTime 0.082 (0.085)\tData 0.006 (0.011)\tLoss 0.8506 (0.8685)\tPrec@1 62.500 (63.796)\n",
            "Epoch: [103][50/97], lr: 0.01000\tTime 0.071 (0.081)\tData 0.000 (0.009)\tLoss 0.8293 (0.8712)\tPrec@1 62.500 (63.281)\n",
            "Epoch: [103][60/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.008)\tLoss 0.8820 (0.8688)\tPrec@1 60.938 (63.192)\n",
            "Epoch: [103][70/97], lr: 0.01000\tTime 0.092 (0.079)\tData 0.006 (0.008)\tLoss 0.8221 (0.8647)\tPrec@1 64.844 (63.556)\n",
            "Epoch: [103][80/97], lr: 0.01000\tTime 0.069 (0.077)\tData 0.000 (0.007)\tLoss 0.7797 (0.8575)\tPrec@1 65.625 (63.927)\n",
            "Epoch: [103][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 0.7186 (0.8517)\tPrec@1 72.656 (64.320)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 0.9011 (0.9011)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.029 (0.059)\tLoss 0.9757 (0.9774)\tPrec@1 62.000 (60.727)\n",
            "Test: [20/100]\tTime 0.058 (0.047)\tLoss 1.0802 (0.9710)\tPrec@1 51.000 (60.333)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9773 (0.9816)\tPrec@1 55.000 (59.194)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9973 (0.9882)\tPrec@1 56.000 (58.732)\n",
            "Test: [50/100]\tTime 0.043 (0.038)\tLoss 1.0961 (0.9911)\tPrec@1 52.000 (58.529)\n",
            "Test: [60/100]\tTime 0.044 (0.037)\tLoss 1.0901 (0.9958)\tPrec@1 48.000 (58.574)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9190 (0.9985)\tPrec@1 63.000 (58.296)\n",
            "Test: [80/100]\tTime 0.048 (0.035)\tLoss 0.9107 (0.9972)\tPrec@1 57.000 (58.198)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 0.9939 (0.9965)\tPrec@1 59.000 (58.088)\n",
            "val Results: Prec@1 58.320 Loss 0.99059\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "Epoch: [104][0/97], lr: 0.01000\tTime 0.521 (0.521)\tData 0.394 (0.394)\tLoss 0.7404 (0.7404)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [104][10/97], lr: 0.01000\tTime 0.063 (0.116)\tData 0.003 (0.040)\tLoss 0.8750 (0.8339)\tPrec@1 64.062 (64.134)\n",
            "Epoch: [104][20/97], lr: 0.01000\tTime 0.110 (0.096)\tData 0.006 (0.022)\tLoss 0.7951 (0.8245)\tPrec@1 66.406 (64.323)\n",
            "Epoch: [104][30/97], lr: 0.01000\tTime 0.081 (0.088)\tData 0.000 (0.016)\tLoss 0.7019 (0.8276)\tPrec@1 69.531 (64.491)\n",
            "Epoch: [104][40/97], lr: 0.01000\tTime 0.067 (0.086)\tData 0.000 (0.013)\tLoss 0.9538 (0.8411)\tPrec@1 60.156 (64.253)\n",
            "Epoch: [104][50/97], lr: 0.01000\tTime 0.074 (0.084)\tData 0.000 (0.011)\tLoss 0.9172 (0.8524)\tPrec@1 62.500 (63.741)\n",
            "Epoch: [104][60/97], lr: 0.01000\tTime 0.091 (0.082)\tData 0.007 (0.009)\tLoss 0.8642 (0.8614)\tPrec@1 60.156 (63.537)\n",
            "Epoch: [104][70/97], lr: 0.01000\tTime 0.074 (0.080)\tData 0.001 (0.008)\tLoss 0.7858 (0.8627)\tPrec@1 70.312 (63.578)\n",
            "Epoch: [104][80/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.007)\tLoss 0.8357 (0.8656)\tPrec@1 67.188 (63.503)\n",
            "Epoch: [104][90/97], lr: 0.01000\tTime 0.056 (0.078)\tData 0.000 (0.006)\tLoss 0.7361 (0.8663)\tPrec@1 68.750 (63.625)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.9022 (0.9022)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.045 (0.062)\tLoss 1.0058 (1.0027)\tPrec@1 62.000 (57.818)\n",
            "Test: [20/100]\tTime 0.024 (0.048)\tLoss 1.1176 (0.9950)\tPrec@1 50.000 (57.905)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.1036 (1.0042)\tPrec@1 51.000 (56.935)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9539 (1.0038)\tPrec@1 61.000 (56.976)\n",
            "Test: [50/100]\tTime 0.035 (0.038)\tLoss 1.0696 (1.0047)\tPrec@1 52.000 (57.059)\n",
            "Test: [60/100]\tTime 0.041 (0.037)\tLoss 1.1211 (1.0106)\tPrec@1 48.000 (57.049)\n",
            "Test: [70/100]\tTime 0.047 (0.036)\tLoss 1.0149 (1.0122)\tPrec@1 56.000 (57.028)\n",
            "Test: [80/100]\tTime 0.031 (0.035)\tLoss 1.0154 (1.0122)\tPrec@1 57.000 (56.975)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.0169 (1.0108)\tPrec@1 53.000 (56.989)\n",
            "val Results: Prec@1 57.050 Loss 1.00972\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "Epoch: [105][0/97], lr: 0.01000\tTime 0.531 (0.531)\tData 0.371 (0.371)\tLoss 0.9581 (0.9581)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [105][10/97], lr: 0.01000\tTime 0.065 (0.114)\tData 0.000 (0.034)\tLoss 0.8403 (0.8473)\tPrec@1 67.969 (65.199)\n",
            "Epoch: [105][20/97], lr: 0.01000\tTime 0.078 (0.095)\tData 0.001 (0.019)\tLoss 0.7194 (0.8422)\tPrec@1 74.219 (65.141)\n",
            "Epoch: [105][30/97], lr: 0.01000\tTime 0.078 (0.087)\tData 0.000 (0.014)\tLoss 0.9852 (0.8481)\tPrec@1 57.812 (64.768)\n",
            "Epoch: [105][40/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.011)\tLoss 0.8746 (0.8471)\tPrec@1 71.875 (65.111)\n",
            "Epoch: [105][50/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.010)\tLoss 0.8542 (0.8484)\tPrec@1 64.062 (65.395)\n",
            "Epoch: [105][60/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.008)\tLoss 0.9003 (0.8474)\tPrec@1 61.719 (65.202)\n",
            "Epoch: [105][70/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.007)\tLoss 0.8686 (0.8511)\tPrec@1 60.938 (64.888)\n",
            "Epoch: [105][80/97], lr: 0.01000\tTime 0.067 (0.077)\tData 0.002 (0.007)\tLoss 0.8242 (0.8509)\tPrec@1 68.750 (64.882)\n",
            "Epoch: [105][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8277 (0.8482)\tPrec@1 69.531 (65.067)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 0.9556 (0.9556)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.022 (0.061)\tLoss 0.9674 (0.9794)\tPrec@1 62.000 (58.273)\n",
            "Test: [20/100]\tTime 0.028 (0.047)\tLoss 1.0906 (0.9738)\tPrec@1 56.000 (58.429)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 1.0359 (0.9800)\tPrec@1 59.000 (58.161)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.8981 (0.9743)\tPrec@1 59.000 (58.146)\n",
            "Test: [50/100]\tTime 0.028 (0.038)\tLoss 0.9625 (0.9704)\tPrec@1 61.000 (58.451)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.0944 (0.9778)\tPrec@1 56.000 (58.262)\n",
            "Test: [70/100]\tTime 0.041 (0.036)\tLoss 0.8659 (0.9748)\tPrec@1 63.000 (58.465)\n",
            "Test: [80/100]\tTime 0.019 (0.035)\tLoss 0.9254 (0.9769)\tPrec@1 61.000 (58.284)\n",
            "Test: [90/100]\tTime 0.051 (0.035)\tLoss 0.9862 (0.9733)\tPrec@1 59.000 (58.495)\n",
            "val Results: Prec@1 58.780 Loss 0.96846\n",
            "Best Prec@1: 59.430\n",
            "\n",
            "Epoch: [106][0/97], lr: 0.01000\tTime 0.527 (0.527)\tData 0.362 (0.362)\tLoss 0.6654 (0.6654)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [106][10/97], lr: 0.01000\tTime 0.066 (0.117)\tData 0.006 (0.036)\tLoss 0.7650 (0.8006)\tPrec@1 66.406 (67.259)\n",
            "Epoch: [106][20/97], lr: 0.01000\tTime 0.058 (0.095)\tData 0.000 (0.021)\tLoss 0.7872 (0.8007)\tPrec@1 71.094 (67.671)\n",
            "Epoch: [106][30/97], lr: 0.01000\tTime 0.066 (0.088)\tData 0.005 (0.015)\tLoss 0.8276 (0.8078)\tPrec@1 66.406 (66.885)\n",
            "Epoch: [106][40/97], lr: 0.01000\tTime 0.065 (0.083)\tData 0.000 (0.012)\tLoss 0.7929 (0.8125)\tPrec@1 71.875 (66.654)\n",
            "Epoch: [106][50/97], lr: 0.01000\tTime 0.058 (0.081)\tData 0.000 (0.010)\tLoss 0.8705 (0.8139)\tPrec@1 65.625 (66.513)\n",
            "Epoch: [106][60/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.009)\tLoss 0.8555 (0.8222)\tPrec@1 66.406 (66.022)\n",
            "Epoch: [106][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.002 (0.008)\tLoss 0.8003 (0.8279)\tPrec@1 68.750 (65.735)\n",
            "Epoch: [106][80/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.008 (0.007)\tLoss 0.8631 (0.8296)\tPrec@1 64.844 (65.750)\n",
            "Epoch: [106][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.9892 (0.8335)\tPrec@1 61.719 (65.419)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 0.9282 (0.9282)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.039 (0.061)\tLoss 0.9483 (0.9619)\tPrec@1 60.000 (60.091)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 1.0413 (0.9477)\tPrec@1 54.000 (60.095)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 0.9278 (0.9522)\tPrec@1 57.000 (59.194)\n",
            "Test: [40/100]\tTime 0.038 (0.040)\tLoss 0.9461 (0.9520)\tPrec@1 66.000 (59.268)\n",
            "Test: [50/100]\tTime 0.024 (0.038)\tLoss 0.9782 (0.9550)\tPrec@1 58.000 (59.549)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1192 (0.9606)\tPrec@1 52.000 (59.279)\n",
            "Test: [70/100]\tTime 0.027 (0.036)\tLoss 0.8564 (0.9574)\tPrec@1 67.000 (59.662)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.9130 (0.9552)\tPrec@1 61.000 (59.704)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 0.9595 (0.9559)\tPrec@1 63.000 (59.835)\n",
            "val Results: Prec@1 60.260 Loss 0.95020\n",
            "Best Prec@1: 60.260\n",
            "\n",
            "Epoch: [107][0/97], lr: 0.01000\tTime 0.561 (0.561)\tData 0.428 (0.428)\tLoss 0.9399 (0.9399)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [107][10/97], lr: 0.01000\tTime 0.077 (0.123)\tData 0.012 (0.044)\tLoss 0.8110 (0.8469)\tPrec@1 64.844 (63.707)\n",
            "Epoch: [107][20/97], lr: 0.01000\tTime 0.062 (0.097)\tData 0.000 (0.024)\tLoss 0.7833 (0.8349)\tPrec@1 70.312 (65.030)\n",
            "Epoch: [107][30/97], lr: 0.01000\tTime 0.056 (0.089)\tData 0.000 (0.018)\tLoss 0.8708 (0.8296)\tPrec@1 61.719 (65.121)\n",
            "Epoch: [107][40/97], lr: 0.01000\tTime 0.063 (0.084)\tData 0.000 (0.014)\tLoss 0.9370 (0.8344)\tPrec@1 58.594 (65.034)\n",
            "Epoch: [107][50/97], lr: 0.01000\tTime 0.070 (0.081)\tData 0.005 (0.012)\tLoss 0.8709 (0.8300)\tPrec@1 63.281 (65.365)\n",
            "Epoch: [107][60/97], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.010)\tLoss 0.8704 (0.8329)\tPrec@1 62.500 (65.049)\n",
            "Epoch: [107][70/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.000 (0.009)\tLoss 0.8008 (0.8370)\tPrec@1 64.844 (64.943)\n",
            "Epoch: [107][80/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.008)\tLoss 0.7149 (0.8377)\tPrec@1 71.875 (64.959)\n",
            "Epoch: [107][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.008)\tLoss 0.7872 (0.8379)\tPrec@1 68.750 (64.998)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.9076 (0.9076)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.030 (0.061)\tLoss 1.0391 (0.9759)\tPrec@1 54.000 (58.909)\n",
            "Test: [20/100]\tTime 0.021 (0.047)\tLoss 1.0783 (0.9700)\tPrec@1 59.000 (58.667)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9463 (0.9723)\tPrec@1 62.000 (58.323)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9029 (0.9701)\tPrec@1 63.000 (58.585)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 1.0220 (0.9694)\tPrec@1 60.000 (58.980)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1522 (0.9809)\tPrec@1 51.000 (58.721)\n",
            "Test: [70/100]\tTime 0.045 (0.037)\tLoss 0.9422 (0.9791)\tPrec@1 61.000 (58.915)\n",
            "Test: [80/100]\tTime 0.028 (0.036)\tLoss 0.9502 (0.9809)\tPrec@1 58.000 (58.765)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.0211 (0.9775)\tPrec@1 60.000 (58.978)\n",
            "val Results: Prec@1 59.090 Loss 0.97350\n",
            "Best Prec@1: 60.260\n",
            "\n",
            "Epoch: [108][0/97], lr: 0.01000\tTime 0.533 (0.533)\tData 0.410 (0.410)\tLoss 0.8043 (0.8043)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [108][10/97], lr: 0.01000\tTime 0.067 (0.119)\tData 0.000 (0.039)\tLoss 0.8636 (0.8027)\tPrec@1 64.844 (67.472)\n",
            "Epoch: [108][20/97], lr: 0.01000\tTime 0.080 (0.098)\tData 0.004 (0.023)\tLoss 0.7690 (0.8003)\tPrec@1 72.656 (67.708)\n",
            "Epoch: [108][30/97], lr: 0.01000\tTime 0.064 (0.089)\tData 0.000 (0.016)\tLoss 0.7080 (0.8139)\tPrec@1 71.875 (66.961)\n",
            "Epoch: [108][40/97], lr: 0.01000\tTime 0.081 (0.085)\tData 0.001 (0.012)\tLoss 0.8887 (0.8216)\tPrec@1 60.938 (66.463)\n",
            "Epoch: [108][50/97], lr: 0.01000\tTime 0.082 (0.082)\tData 0.012 (0.011)\tLoss 0.8241 (0.8232)\tPrec@1 67.188 (66.115)\n",
            "Epoch: [108][60/97], lr: 0.01000\tTime 0.068 (0.080)\tData 0.000 (0.009)\tLoss 0.7902 (0.8247)\tPrec@1 69.531 (66.009)\n",
            "Epoch: [108][70/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.008)\tLoss 0.8526 (0.8200)\tPrec@1 61.719 (66.296)\n",
            "Epoch: [108][80/97], lr: 0.01000\tTime 0.062 (0.079)\tData 0.000 (0.008)\tLoss 0.8411 (0.8158)\tPrec@1 67.969 (66.667)\n",
            "Epoch: [108][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.8401 (0.8204)\tPrec@1 62.500 (66.329)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 0.9698 (0.9698)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.038 (0.060)\tLoss 1.0826 (0.9755)\tPrec@1 65.000 (61.000)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 1.0756 (0.9940)\tPrec@1 51.000 (60.000)\n",
            "Test: [30/100]\tTime 0.036 (0.041)\tLoss 1.0423 (1.0011)\tPrec@1 63.000 (59.194)\n",
            "Test: [40/100]\tTime 0.031 (0.039)\tLoss 1.0224 (1.0008)\tPrec@1 51.000 (58.707)\n",
            "Test: [50/100]\tTime 0.033 (0.037)\tLoss 1.0226 (1.0021)\tPrec@1 61.000 (58.922)\n",
            "Test: [60/100]\tTime 0.033 (0.037)\tLoss 1.1323 (1.0023)\tPrec@1 52.000 (58.902)\n",
            "Test: [70/100]\tTime 0.027 (0.036)\tLoss 1.0023 (0.9992)\tPrec@1 56.000 (58.944)\n",
            "Test: [80/100]\tTime 0.032 (0.035)\tLoss 1.1046 (1.0011)\tPrec@1 59.000 (58.790)\n",
            "Test: [90/100]\tTime 0.050 (0.035)\tLoss 1.1228 (1.0018)\tPrec@1 55.000 (58.758)\n",
            "val Results: Prec@1 58.840 Loss 0.99972\n",
            "Best Prec@1: 60.260\n",
            "\n",
            "Epoch: [109][0/97], lr: 0.01000\tTime 0.802 (0.802)\tData 0.558 (0.558)\tLoss 0.7591 (0.7591)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [109][10/97], lr: 0.01000\tTime 0.109 (0.170)\tData 0.004 (0.055)\tLoss 0.9898 (0.8265)\tPrec@1 57.031 (65.838)\n",
            "Epoch: [109][20/97], lr: 0.01000\tTime 0.107 (0.143)\tData 0.006 (0.032)\tLoss 0.9597 (0.8367)\tPrec@1 57.812 (65.439)\n",
            "Epoch: [109][30/97], lr: 0.01000\tTime 0.068 (0.130)\tData 0.006 (0.024)\tLoss 0.8032 (0.8372)\tPrec@1 68.750 (65.801)\n",
            "Epoch: [109][40/97], lr: 0.01000\tTime 0.119 (0.119)\tData 0.001 (0.019)\tLoss 0.8897 (0.8320)\tPrec@1 62.500 (65.835)\n",
            "Epoch: [109][50/97], lr: 0.01000\tTime 0.062 (0.112)\tData 0.000 (0.016)\tLoss 0.8868 (0.8309)\tPrec@1 62.500 (65.947)\n",
            "Epoch: [109][60/97], lr: 0.01000\tTime 0.071 (0.107)\tData 0.000 (0.014)\tLoss 0.7233 (0.8279)\tPrec@1 72.656 (66.099)\n",
            "Epoch: [109][70/97], lr: 0.01000\tTime 0.069 (0.103)\tData 0.000 (0.012)\tLoss 0.8977 (0.8289)\tPrec@1 57.812 (65.933)\n",
            "Epoch: [109][80/97], lr: 0.01000\tTime 0.069 (0.100)\tData 0.004 (0.011)\tLoss 0.9075 (0.8244)\tPrec@1 56.250 (66.040)\n",
            "Epoch: [109][90/97], lr: 0.01000\tTime 0.056 (0.097)\tData 0.000 (0.010)\tLoss 0.7926 (0.8246)\tPrec@1 65.625 (66.011)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 0.9729 (0.9729)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.039 (0.060)\tLoss 1.0029 (0.9875)\tPrec@1 57.000 (59.364)\n",
            "Test: [20/100]\tTime 0.021 (0.046)\tLoss 1.0747 (0.9788)\tPrec@1 59.000 (59.714)\n",
            "Test: [30/100]\tTime 0.026 (0.045)\tLoss 1.0043 (0.9877)\tPrec@1 61.000 (59.032)\n",
            "Test: [40/100]\tTime 0.029 (0.043)\tLoss 0.9227 (0.9851)\tPrec@1 64.000 (59.293)\n",
            "Test: [50/100]\tTime 0.026 (0.042)\tLoss 0.9992 (0.9880)\tPrec@1 61.000 (59.333)\n",
            "Test: [60/100]\tTime 0.030 (0.041)\tLoss 1.1493 (0.9935)\tPrec@1 57.000 (59.180)\n",
            "Test: [70/100]\tTime 0.029 (0.041)\tLoss 0.8969 (0.9925)\tPrec@1 63.000 (59.056)\n",
            "Test: [80/100]\tTime 0.029 (0.040)\tLoss 0.9162 (0.9925)\tPrec@1 58.000 (58.975)\n",
            "Test: [90/100]\tTime 0.025 (0.040)\tLoss 1.0945 (0.9918)\tPrec@1 56.000 (58.967)\n",
            "val Results: Prec@1 59.170 Loss 0.98539\n",
            "Best Prec@1: 60.260\n",
            "\n",
            "Epoch: [110][0/97], lr: 0.01000\tTime 0.496 (0.496)\tData 0.339 (0.339)\tLoss 0.7350 (0.7350)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [110][10/97], lr: 0.01000\tTime 0.061 (0.114)\tData 0.000 (0.033)\tLoss 0.7922 (0.7740)\tPrec@1 67.188 (67.898)\n",
            "Epoch: [110][20/97], lr: 0.01000\tTime 0.064 (0.093)\tData 0.000 (0.019)\tLoss 0.8601 (0.7946)\tPrec@1 66.406 (66.778)\n",
            "Epoch: [110][30/97], lr: 0.01000\tTime 0.064 (0.086)\tData 0.000 (0.014)\tLoss 0.9358 (0.8049)\tPrec@1 58.594 (66.104)\n",
            "Epoch: [110][40/97], lr: 0.01000\tTime 0.079 (0.083)\tData 0.005 (0.011)\tLoss 0.9060 (0.8117)\tPrec@1 67.188 (66.273)\n",
            "Epoch: [110][50/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.010)\tLoss 0.8398 (0.8226)\tPrec@1 64.062 (65.901)\n",
            "Epoch: [110][60/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.007 (0.009)\tLoss 0.7642 (0.8237)\tPrec@1 71.875 (65.856)\n",
            "Epoch: [110][70/97], lr: 0.01000\tTime 0.077 (0.078)\tData 0.007 (0.008)\tLoss 0.8240 (0.8228)\tPrec@1 63.281 (65.889)\n",
            "Epoch: [110][80/97], lr: 0.01000\tTime 0.066 (0.076)\tData 0.000 (0.007)\tLoss 0.9446 (0.8237)\tPrec@1 63.281 (65.924)\n",
            "Epoch: [110][90/97], lr: 0.01000\tTime 0.051 (0.075)\tData 0.000 (0.007)\tLoss 0.9100 (0.8274)\tPrec@1 61.719 (65.685)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.9324 (0.9324)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.023 (0.058)\tLoss 0.9807 (0.9514)\tPrec@1 59.000 (59.091)\n",
            "Test: [20/100]\tTime 0.021 (0.045)\tLoss 0.9741 (0.9408)\tPrec@1 61.000 (60.000)\n",
            "Test: [30/100]\tTime 0.021 (0.044)\tLoss 0.9492 (0.9476)\tPrec@1 64.000 (59.903)\n",
            "Test: [40/100]\tTime 0.032 (0.043)\tLoss 0.8926 (0.9494)\tPrec@1 61.000 (59.512)\n",
            "Test: [50/100]\tTime 0.035 (0.043)\tLoss 1.0318 (0.9483)\tPrec@1 56.000 (59.922)\n",
            "Test: [60/100]\tTime 0.025 (0.042)\tLoss 1.1387 (0.9555)\tPrec@1 56.000 (60.049)\n",
            "Test: [70/100]\tTime 0.025 (0.041)\tLoss 0.8494 (0.9530)\tPrec@1 67.000 (60.014)\n",
            "Test: [80/100]\tTime 0.029 (0.040)\tLoss 0.9007 (0.9493)\tPrec@1 58.000 (60.086)\n",
            "Test: [90/100]\tTime 0.021 (0.040)\tLoss 0.9191 (0.9488)\tPrec@1 65.000 (60.198)\n",
            "val Results: Prec@1 60.680 Loss 0.94097\n",
            "Best Prec@1: 60.680\n",
            "\n",
            "Epoch: [111][0/97], lr: 0.01000\tTime 0.552 (0.552)\tData 0.346 (0.346)\tLoss 0.8914 (0.8914)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [111][10/97], lr: 0.01000\tTime 0.077 (0.116)\tData 0.007 (0.034)\tLoss 0.8492 (0.8737)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [111][20/97], lr: 0.01000\tTime 0.080 (0.094)\tData 0.007 (0.019)\tLoss 0.7495 (0.8389)\tPrec@1 68.750 (65.551)\n",
            "Epoch: [111][30/97], lr: 0.01000\tTime 0.081 (0.087)\tData 0.000 (0.014)\tLoss 0.7253 (0.8321)\tPrec@1 69.531 (65.297)\n",
            "Epoch: [111][40/97], lr: 0.01000\tTime 0.070 (0.083)\tData 0.001 (0.011)\tLoss 0.7875 (0.8347)\tPrec@1 68.750 (64.996)\n",
            "Epoch: [111][50/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.010)\tLoss 0.8808 (0.8294)\tPrec@1 60.938 (65.395)\n",
            "Epoch: [111][60/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.007 (0.008)\tLoss 0.7882 (0.8299)\tPrec@1 66.406 (65.587)\n",
            "Epoch: [111][70/97], lr: 0.01000\tTime 0.070 (0.078)\tData 0.000 (0.008)\tLoss 0.9147 (0.8254)\tPrec@1 61.719 (65.647)\n",
            "Epoch: [111][80/97], lr: 0.01000\tTime 0.062 (0.077)\tData 0.000 (0.007)\tLoss 0.7510 (0.8238)\tPrec@1 65.625 (65.721)\n",
            "Epoch: [111][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.7624 (0.8219)\tPrec@1 67.188 (65.977)\n",
            "Test: [0/100]\tTime 0.333 (0.333)\tLoss 0.8858 (0.8858)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.023 (0.062)\tLoss 0.9201 (0.9493)\tPrec@1 58.000 (59.545)\n",
            "Test: [20/100]\tTime 0.048 (0.047)\tLoss 1.0493 (0.9436)\tPrec@1 61.000 (59.810)\n",
            "Test: [30/100]\tTime 0.043 (0.043)\tLoss 1.0159 (0.9489)\tPrec@1 59.000 (59.516)\n",
            "Test: [40/100]\tTime 0.030 (0.039)\tLoss 0.8681 (0.9475)\tPrec@1 67.000 (59.756)\n",
            "Test: [50/100]\tTime 0.025 (0.038)\tLoss 1.0434 (0.9502)\tPrec@1 59.000 (59.902)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.0760 (0.9593)\tPrec@1 54.000 (59.787)\n",
            "Test: [70/100]\tTime 0.029 (0.036)\tLoss 0.8905 (0.9600)\tPrec@1 63.000 (59.789)\n",
            "Test: [80/100]\tTime 0.033 (0.035)\tLoss 0.8784 (0.9569)\tPrec@1 63.000 (59.951)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 0.9895 (0.9568)\tPrec@1 58.000 (60.055)\n",
            "val Results: Prec@1 60.300 Loss 0.95064\n",
            "Best Prec@1: 60.680\n",
            "\n",
            "Epoch: [112][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.436 (0.436)\tLoss 0.7710 (0.7710)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [112][10/97], lr: 0.01000\tTime 0.065 (0.118)\tData 0.002 (0.042)\tLoss 0.8239 (0.7783)\tPrec@1 64.844 (67.543)\n",
            "Epoch: [112][20/97], lr: 0.01000\tTime 0.062 (0.095)\tData 0.000 (0.023)\tLoss 0.8729 (0.7945)\tPrec@1 61.719 (66.443)\n",
            "Epoch: [112][30/97], lr: 0.01000\tTime 0.082 (0.088)\tData 0.000 (0.016)\tLoss 0.7393 (0.7947)\tPrec@1 75.781 (66.935)\n",
            "Epoch: [112][40/97], lr: 0.01000\tTime 0.075 (0.084)\tData 0.007 (0.013)\tLoss 0.7324 (0.7953)\tPrec@1 69.531 (67.016)\n",
            "Epoch: [112][50/97], lr: 0.01000\tTime 0.077 (0.082)\tData 0.007 (0.011)\tLoss 0.9557 (0.8014)\tPrec@1 64.062 (66.881)\n",
            "Epoch: [112][60/97], lr: 0.01000\tTime 0.072 (0.081)\tData 0.000 (0.010)\tLoss 0.8412 (0.8088)\tPrec@1 60.938 (66.611)\n",
            "Epoch: [112][70/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.009)\tLoss 0.7458 (0.8092)\tPrec@1 66.406 (66.604)\n",
            "Epoch: [112][80/97], lr: 0.01000\tTime 0.060 (0.078)\tData 0.000 (0.008)\tLoss 0.9372 (0.8108)\tPrec@1 59.375 (66.464)\n",
            "Epoch: [112][90/97], lr: 0.01000\tTime 0.057 (0.077)\tData 0.000 (0.007)\tLoss 0.7472 (0.8117)\tPrec@1 69.531 (66.346)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 0.9271 (0.9271)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.025 (0.062)\tLoss 0.9269 (0.9437)\tPrec@1 67.000 (61.182)\n",
            "Test: [20/100]\tTime 0.044 (0.047)\tLoss 1.0538 (0.9313)\tPrec@1 54.000 (62.000)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9542 (0.9409)\tPrec@1 61.000 (61.290)\n",
            "Test: [40/100]\tTime 0.035 (0.040)\tLoss 0.8738 (0.9414)\tPrec@1 62.000 (60.585)\n",
            "Test: [50/100]\tTime 0.030 (0.038)\tLoss 0.9374 (0.9441)\tPrec@1 64.000 (60.529)\n",
            "Test: [60/100]\tTime 0.050 (0.037)\tLoss 1.1546 (0.9536)\tPrec@1 51.000 (60.164)\n",
            "Test: [70/100]\tTime 0.041 (0.036)\tLoss 0.8038 (0.9493)\tPrec@1 66.000 (60.310)\n",
            "Test: [80/100]\tTime 0.046 (0.036)\tLoss 0.9295 (0.9480)\tPrec@1 61.000 (60.432)\n",
            "Test: [90/100]\tTime 0.041 (0.035)\tLoss 1.0011 (0.9449)\tPrec@1 59.000 (60.495)\n",
            "val Results: Prec@1 60.910 Loss 0.93885\n",
            "Best Prec@1: 60.910\n",
            "\n",
            "Epoch: [113][0/97], lr: 0.01000\tTime 0.441 (0.441)\tData 0.290 (0.290)\tLoss 0.9008 (0.9008)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [113][10/97], lr: 0.01000\tTime 0.081 (0.118)\tData 0.007 (0.032)\tLoss 0.7194 (0.8281)\tPrec@1 71.094 (65.980)\n",
            "Epoch: [113][20/97], lr: 0.01000\tTime 0.067 (0.094)\tData 0.006 (0.018)\tLoss 0.8053 (0.8313)\tPrec@1 71.875 (66.332)\n",
            "Epoch: [113][30/97], lr: 0.01000\tTime 0.066 (0.087)\tData 0.000 (0.013)\tLoss 0.9164 (0.8263)\tPrec@1 61.719 (66.431)\n",
            "Epoch: [113][40/97], lr: 0.01000\tTime 0.073 (0.083)\tData 0.010 (0.011)\tLoss 0.8430 (0.8329)\tPrec@1 67.188 (65.949)\n",
            "Epoch: [113][50/97], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.009)\tLoss 0.7474 (0.8322)\tPrec@1 66.406 (65.732)\n",
            "Epoch: [113][60/97], lr: 0.01000\tTime 0.078 (0.079)\tData 0.000 (0.008)\tLoss 0.8880 (0.8296)\tPrec@1 64.844 (66.022)\n",
            "Epoch: [113][70/97], lr: 0.01000\tTime 0.078 (0.078)\tData 0.000 (0.007)\tLoss 0.8133 (0.8322)\tPrec@1 65.625 (65.856)\n",
            "Epoch: [113][80/97], lr: 0.01000\tTime 0.076 (0.077)\tData 0.011 (0.006)\tLoss 0.9039 (0.8332)\tPrec@1 66.406 (65.837)\n",
            "Epoch: [113][90/97], lr: 0.01000\tTime 0.054 (0.075)\tData 0.000 (0.006)\tLoss 0.6563 (0.8229)\tPrec@1 75.000 (66.183)\n",
            "Test: [0/100]\tTime 0.290 (0.290)\tLoss 0.9434 (0.9434)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.023 (0.059)\tLoss 0.9169 (0.9239)\tPrec@1 58.000 (61.455)\n",
            "Test: [20/100]\tTime 0.055 (0.046)\tLoss 1.1388 (0.9300)\tPrec@1 56.000 (60.905)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 0.9193 (0.9407)\tPrec@1 62.000 (60.516)\n",
            "Test: [40/100]\tTime 0.044 (0.039)\tLoss 0.8421 (0.9382)\tPrec@1 60.000 (60.366)\n",
            "Test: [50/100]\tTime 0.055 (0.037)\tLoss 1.0404 (0.9374)\tPrec@1 59.000 (60.706)\n",
            "Test: [60/100]\tTime 0.059 (0.036)\tLoss 1.0884 (0.9456)\tPrec@1 51.000 (60.672)\n",
            "Test: [70/100]\tTime 0.041 (0.035)\tLoss 0.9564 (0.9429)\tPrec@1 64.000 (60.915)\n",
            "Test: [80/100]\tTime 0.036 (0.035)\tLoss 0.9438 (0.9421)\tPrec@1 58.000 (60.975)\n",
            "Test: [90/100]\tTime 0.026 (0.034)\tLoss 1.0008 (0.9406)\tPrec@1 57.000 (60.824)\n",
            "val Results: Prec@1 61.080 Loss 0.93414\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [114][0/97], lr: 0.01000\tTime 0.579 (0.579)\tData 0.419 (0.419)\tLoss 0.8978 (0.8978)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [114][10/97], lr: 0.01000\tTime 0.077 (0.124)\tData 0.008 (0.040)\tLoss 0.9364 (0.8412)\tPrec@1 59.375 (64.986)\n",
            "Epoch: [114][20/97], lr: 0.01000\tTime 0.064 (0.098)\tData 0.000 (0.022)\tLoss 0.8746 (0.8269)\tPrec@1 66.406 (65.848)\n",
            "Epoch: [114][30/97], lr: 0.01000\tTime 0.062 (0.091)\tData 0.000 (0.016)\tLoss 0.8162 (0.8131)\tPrec@1 66.406 (66.230)\n",
            "Epoch: [114][40/97], lr: 0.01000\tTime 0.072 (0.088)\tData 0.003 (0.013)\tLoss 0.8552 (0.8130)\tPrec@1 63.281 (66.521)\n",
            "Epoch: [114][50/97], lr: 0.01000\tTime 0.079 (0.085)\tData 0.000 (0.011)\tLoss 0.8033 (0.8166)\tPrec@1 65.625 (66.054)\n",
            "Epoch: [114][60/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.009)\tLoss 0.7285 (0.8150)\tPrec@1 73.438 (66.099)\n",
            "Epoch: [114][70/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.003 (0.009)\tLoss 0.7350 (0.8104)\tPrec@1 70.312 (66.351)\n",
            "Epoch: [114][80/97], lr: 0.01000\tTime 0.087 (0.080)\tData 0.007 (0.008)\tLoss 0.8761 (0.8176)\tPrec@1 60.938 (66.011)\n",
            "Epoch: [114][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.007)\tLoss 0.7165 (0.8156)\tPrec@1 71.094 (66.269)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 1.0340 (1.0340)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.046 (0.060)\tLoss 0.9692 (1.0034)\tPrec@1 61.000 (58.364)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 1.0386 (0.9946)\tPrec@1 57.000 (58.714)\n",
            "Test: [30/100]\tTime 0.054 (0.041)\tLoss 0.9712 (0.9962)\tPrec@1 60.000 (58.452)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 0.9220 (0.9863)\tPrec@1 60.000 (58.951)\n",
            "Test: [50/100]\tTime 0.041 (0.038)\tLoss 1.1196 (0.9967)\tPrec@1 56.000 (58.745)\n",
            "Test: [60/100]\tTime 0.026 (0.037)\tLoss 1.2826 (1.0088)\tPrec@1 50.000 (58.557)\n",
            "Test: [70/100]\tTime 0.041 (0.036)\tLoss 0.9597 (1.0088)\tPrec@1 64.000 (58.324)\n",
            "Test: [80/100]\tTime 0.052 (0.035)\tLoss 1.0416 (1.0115)\tPrec@1 64.000 (58.494)\n",
            "Test: [90/100]\tTime 0.051 (0.035)\tLoss 1.0771 (1.0110)\tPrec@1 59.000 (58.714)\n",
            "val Results: Prec@1 59.130 Loss 1.00382\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [115][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.392 (0.392)\tLoss 0.8320 (0.8320)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [115][10/97], lr: 0.01000\tTime 0.078 (0.118)\tData 0.007 (0.038)\tLoss 0.7924 (0.7997)\tPrec@1 67.969 (68.182)\n",
            "Epoch: [115][20/97], lr: 0.01000\tTime 0.065 (0.096)\tData 0.000 (0.021)\tLoss 0.6638 (0.8095)\tPrec@1 72.656 (67.225)\n",
            "Epoch: [115][30/97], lr: 0.01000\tTime 0.071 (0.088)\tData 0.000 (0.015)\tLoss 0.8715 (0.8112)\tPrec@1 64.844 (66.759)\n",
            "Epoch: [115][40/97], lr: 0.01000\tTime 0.082 (0.084)\tData 0.007 (0.012)\tLoss 0.7788 (0.8080)\tPrec@1 69.531 (66.749)\n",
            "Epoch: [115][50/97], lr: 0.01000\tTime 0.081 (0.082)\tData 0.000 (0.010)\tLoss 0.8730 (0.8150)\tPrec@1 58.594 (66.391)\n",
            "Epoch: [115][60/97], lr: 0.01000\tTime 0.072 (0.080)\tData 0.000 (0.009)\tLoss 0.8430 (0.8164)\tPrec@1 64.844 (66.099)\n",
            "Epoch: [115][70/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.000 (0.008)\tLoss 0.8319 (0.8166)\tPrec@1 64.062 (66.109)\n",
            "Epoch: [115][80/97], lr: 0.01000\tTime 0.066 (0.078)\tData 0.001 (0.007)\tLoss 0.9852 (0.8136)\tPrec@1 64.844 (66.368)\n",
            "Epoch: [115][90/97], lr: 0.01000\tTime 0.047 (0.077)\tData 0.000 (0.007)\tLoss 0.8521 (0.8160)\tPrec@1 64.062 (66.166)\n",
            "Test: [0/100]\tTime 0.311 (0.311)\tLoss 0.9409 (0.9409)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.029 (0.061)\tLoss 1.0312 (0.9802)\tPrec@1 55.000 (59.182)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 1.1065 (0.9793)\tPrec@1 56.000 (58.810)\n",
            "Test: [30/100]\tTime 0.053 (0.042)\tLoss 0.9906 (1.0046)\tPrec@1 64.000 (58.323)\n",
            "Test: [40/100]\tTime 0.035 (0.039)\tLoss 0.9843 (1.0078)\tPrec@1 61.000 (58.220)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 1.0046 (1.0075)\tPrec@1 59.000 (58.529)\n",
            "Test: [60/100]\tTime 0.044 (0.037)\tLoss 1.1399 (1.0152)\tPrec@1 50.000 (58.459)\n",
            "Test: [70/100]\tTime 0.039 (0.036)\tLoss 0.9941 (1.0139)\tPrec@1 61.000 (58.394)\n",
            "Test: [80/100]\tTime 0.025 (0.036)\tLoss 0.9862 (1.0123)\tPrec@1 58.000 (58.333)\n",
            "Test: [90/100]\tTime 0.034 (0.035)\tLoss 1.0462 (1.0104)\tPrec@1 59.000 (58.560)\n",
            "val Results: Prec@1 58.700 Loss 1.00571\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [116][0/97], lr: 0.01000\tTime 0.579 (0.579)\tData 0.419 (0.419)\tLoss 0.8102 (0.8102)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [116][10/97], lr: 0.01000\tTime 0.087 (0.121)\tData 0.000 (0.040)\tLoss 0.8788 (0.7793)\tPrec@1 63.281 (68.253)\n",
            "Epoch: [116][20/97], lr: 0.01000\tTime 0.064 (0.097)\tData 0.000 (0.021)\tLoss 0.6954 (0.7892)\tPrec@1 71.094 (67.374)\n",
            "Epoch: [116][30/97], lr: 0.01000\tTime 0.069 (0.090)\tData 0.000 (0.015)\tLoss 0.7542 (0.7961)\tPrec@1 67.969 (67.339)\n",
            "Epoch: [116][40/97], lr: 0.01000\tTime 0.064 (0.085)\tData 0.000 (0.012)\tLoss 0.8342 (0.8114)\tPrec@1 62.500 (66.216)\n",
            "Epoch: [116][50/97], lr: 0.01000\tTime 0.095 (0.083)\tData 0.013 (0.010)\tLoss 0.7349 (0.8164)\tPrec@1 70.312 (66.146)\n",
            "Epoch: [116][60/97], lr: 0.01000\tTime 0.073 (0.081)\tData 0.006 (0.009)\tLoss 0.8839 (0.8220)\tPrec@1 58.594 (65.920)\n",
            "Epoch: [116][70/97], lr: 0.01000\tTime 0.067 (0.080)\tData 0.002 (0.008)\tLoss 0.9732 (0.8197)\tPrec@1 60.156 (66.098)\n",
            "Epoch: [116][80/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.007)\tLoss 0.8588 (0.8204)\tPrec@1 67.188 (66.175)\n",
            "Epoch: [116][90/97], lr: 0.01000\tTime 0.056 (0.078)\tData 0.000 (0.007)\tLoss 0.8285 (0.8182)\tPrec@1 67.188 (66.226)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 1.0220 (1.0220)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.050 (0.060)\tLoss 0.9130 (0.9370)\tPrec@1 63.000 (61.636)\n",
            "Test: [20/100]\tTime 0.021 (0.046)\tLoss 1.0002 (0.9400)\tPrec@1 62.000 (61.286)\n",
            "Test: [30/100]\tTime 0.036 (0.043)\tLoss 1.0584 (0.9420)\tPrec@1 58.000 (60.613)\n",
            "Test: [40/100]\tTime 0.045 (0.039)\tLoss 0.9250 (0.9446)\tPrec@1 59.000 (60.537)\n",
            "Test: [50/100]\tTime 0.036 (0.038)\tLoss 0.9270 (0.9466)\tPrec@1 62.000 (60.549)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.0992 (0.9576)\tPrec@1 57.000 (60.623)\n",
            "Test: [70/100]\tTime 0.043 (0.037)\tLoss 0.9152 (0.9568)\tPrec@1 61.000 (60.437)\n",
            "Test: [80/100]\tTime 0.023 (0.036)\tLoss 0.8355 (0.9561)\tPrec@1 65.000 (60.556)\n",
            "Test: [90/100]\tTime 0.027 (0.036)\tLoss 1.0385 (0.9544)\tPrec@1 59.000 (60.615)\n",
            "val Results: Prec@1 60.790 Loss 0.95060\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [117][0/97], lr: 0.01000\tTime 0.551 (0.551)\tData 0.411 (0.411)\tLoss 0.7763 (0.7763)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [117][10/97], lr: 0.01000\tTime 0.064 (0.118)\tData 0.000 (0.039)\tLoss 0.9117 (0.8030)\tPrec@1 58.594 (66.690)\n",
            "Epoch: [117][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.021)\tLoss 0.8795 (0.8052)\tPrec@1 64.844 (67.374)\n",
            "Epoch: [117][30/97], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.014)\tLoss 0.6820 (0.7984)\tPrec@1 70.312 (67.162)\n",
            "Epoch: [117][40/97], lr: 0.01000\tTime 0.065 (0.085)\tData 0.003 (0.012)\tLoss 0.9389 (0.8061)\tPrec@1 61.719 (66.825)\n",
            "Epoch: [117][50/97], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.011)\tLoss 0.8156 (0.8059)\tPrec@1 70.312 (66.743)\n",
            "Epoch: [117][60/97], lr: 0.01000\tTime 0.076 (0.081)\tData 0.006 (0.009)\tLoss 0.6923 (0.8085)\tPrec@1 72.656 (66.598)\n",
            "Epoch: [117][70/97], lr: 0.01000\tTime 0.075 (0.080)\tData 0.006 (0.008)\tLoss 0.7614 (0.8102)\tPrec@1 74.219 (66.571)\n",
            "Epoch: [117][80/97], lr: 0.01000\tTime 0.082 (0.079)\tData 0.006 (0.008)\tLoss 0.9279 (0.8105)\tPrec@1 65.625 (66.782)\n",
            "Epoch: [117][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.8043 (0.8103)\tPrec@1 66.406 (66.784)\n",
            "Test: [0/100]\tTime 0.359 (0.359)\tLoss 0.9100 (0.9100)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.038 (0.063)\tLoss 1.0285 (0.9477)\tPrec@1 57.000 (61.818)\n",
            "Test: [20/100]\tTime 0.039 (0.049)\tLoss 1.0590 (0.9441)\tPrec@1 61.000 (61.714)\n",
            "Test: [30/100]\tTime 0.032 (0.043)\tLoss 0.9650 (0.9599)\tPrec@1 59.000 (59.871)\n",
            "Test: [40/100]\tTime 0.059 (0.040)\tLoss 0.9004 (0.9521)\tPrec@1 67.000 (60.098)\n",
            "Test: [50/100]\tTime 0.043 (0.039)\tLoss 0.9205 (0.9473)\tPrec@1 66.000 (60.157)\n",
            "Test: [60/100]\tTime 0.028 (0.037)\tLoss 1.1282 (0.9548)\tPrec@1 52.000 (60.033)\n",
            "Test: [70/100]\tTime 0.025 (0.036)\tLoss 0.9518 (0.9528)\tPrec@1 55.000 (59.873)\n",
            "Test: [80/100]\tTime 0.029 (0.036)\tLoss 0.8816 (0.9525)\tPrec@1 62.000 (59.716)\n",
            "Test: [90/100]\tTime 0.047 (0.035)\tLoss 1.0206 (0.9526)\tPrec@1 57.000 (59.758)\n",
            "val Results: Prec@1 60.060 Loss 0.94646\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [118][0/97], lr: 0.01000\tTime 0.517 (0.517)\tData 0.331 (0.331)\tLoss 0.7289 (0.7289)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [118][10/97], lr: 0.01000\tTime 0.066 (0.116)\tData 0.000 (0.033)\tLoss 0.8729 (0.8099)\tPrec@1 62.500 (65.909)\n",
            "Epoch: [118][20/97], lr: 0.01000\tTime 0.062 (0.095)\tData 0.000 (0.018)\tLoss 0.8094 (0.7943)\tPrec@1 64.062 (67.001)\n",
            "Epoch: [118][30/97], lr: 0.01000\tTime 0.064 (0.087)\tData 0.002 (0.014)\tLoss 0.9293 (0.7830)\tPrec@1 60.938 (67.061)\n",
            "Epoch: [118][40/97], lr: 0.01000\tTime 0.074 (0.083)\tData 0.006 (0.011)\tLoss 0.8678 (0.7831)\tPrec@1 64.844 (67.283)\n",
            "Epoch: [118][50/97], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.010)\tLoss 0.8632 (0.7861)\tPrec@1 59.375 (67.203)\n",
            "Epoch: [118][60/97], lr: 0.01000\tTime 0.079 (0.079)\tData 0.006 (0.009)\tLoss 0.8068 (0.7949)\tPrec@1 66.406 (66.765)\n",
            "Epoch: [118][70/97], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.008)\tLoss 0.8112 (0.8023)\tPrec@1 65.625 (66.549)\n",
            "Epoch: [118][80/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.007)\tLoss 0.6244 (0.8004)\tPrec@1 78.125 (66.744)\n",
            "Epoch: [118][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.7326 (0.8024)\tPrec@1 68.750 (66.836)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 0.8852 (0.8852)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.032 (0.062)\tLoss 1.0467 (0.9280)\tPrec@1 55.000 (62.000)\n",
            "Test: [20/100]\tTime 0.039 (0.048)\tLoss 1.0417 (0.9343)\tPrec@1 54.000 (61.238)\n",
            "Test: [30/100]\tTime 0.038 (0.042)\tLoss 0.9990 (0.9467)\tPrec@1 60.000 (60.806)\n",
            "Test: [40/100]\tTime 0.062 (0.040)\tLoss 0.9617 (0.9481)\tPrec@1 60.000 (60.366)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.9856 (0.9476)\tPrec@1 62.000 (60.765)\n",
            "Test: [60/100]\tTime 0.028 (0.037)\tLoss 1.0960 (0.9550)\tPrec@1 54.000 (60.459)\n",
            "Test: [70/100]\tTime 0.029 (0.036)\tLoss 0.9278 (0.9550)\tPrec@1 62.000 (60.310)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.9422 (0.9547)\tPrec@1 62.000 (60.333)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.0052 (0.9531)\tPrec@1 58.000 (60.319)\n",
            "val Results: Prec@1 60.510 Loss 0.95060\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [119][0/97], lr: 0.01000\tTime 0.565 (0.565)\tData 0.349 (0.349)\tLoss 0.7959 (0.7959)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [119][10/97], lr: 0.01000\tTime 0.068 (0.120)\tData 0.000 (0.033)\tLoss 0.8696 (0.8049)\tPrec@1 66.406 (66.903)\n",
            "Epoch: [119][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.019)\tLoss 0.7282 (0.8094)\tPrec@1 72.656 (66.629)\n",
            "Epoch: [119][30/97], lr: 0.01000\tTime 0.092 (0.089)\tData 0.000 (0.013)\tLoss 0.7957 (0.8130)\tPrec@1 64.844 (66.356)\n",
            "Epoch: [119][40/97], lr: 0.01000\tTime 0.071 (0.084)\tData 0.006 (0.011)\tLoss 0.6802 (0.8047)\tPrec@1 77.344 (66.768)\n",
            "Epoch: [119][50/97], lr: 0.01000\tTime 0.070 (0.082)\tData 0.000 (0.009)\tLoss 0.8142 (0.8009)\tPrec@1 64.844 (66.835)\n",
            "Epoch: [119][60/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.008)\tLoss 0.7222 (0.7973)\tPrec@1 71.094 (67.111)\n",
            "Epoch: [119][70/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.008)\tLoss 0.9713 (0.8002)\tPrec@1 59.375 (66.978)\n",
            "Epoch: [119][80/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.002 (0.007)\tLoss 0.8494 (0.8005)\tPrec@1 66.406 (66.937)\n",
            "Epoch: [119][90/97], lr: 0.01000\tTime 0.054 (0.077)\tData 0.000 (0.007)\tLoss 0.8966 (0.8033)\tPrec@1 58.594 (66.844)\n",
            "Test: [0/100]\tTime 0.271 (0.271)\tLoss 0.9823 (0.9823)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.026 (0.058)\tLoss 1.0496 (0.9855)\tPrec@1 62.000 (60.182)\n",
            "Test: [20/100]\tTime 0.023 (0.047)\tLoss 1.1976 (0.9887)\tPrec@1 50.000 (60.095)\n",
            "Test: [30/100]\tTime 0.076 (0.043)\tLoss 0.9801 (1.0021)\tPrec@1 59.000 (59.387)\n",
            "Test: [40/100]\tTime 0.046 (0.040)\tLoss 0.9630 (0.9999)\tPrec@1 61.000 (59.366)\n",
            "Test: [50/100]\tTime 0.051 (0.038)\tLoss 1.0150 (1.0000)\tPrec@1 61.000 (59.451)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.1364 (1.0075)\tPrec@1 57.000 (59.279)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9578 (1.0050)\tPrec@1 62.000 (59.197)\n",
            "Test: [80/100]\tTime 0.029 (0.036)\tLoss 1.0311 (1.0080)\tPrec@1 57.000 (59.136)\n",
            "Test: [90/100]\tTime 0.042 (0.037)\tLoss 1.2007 (1.0067)\tPrec@1 54.000 (59.165)\n",
            "val Results: Prec@1 59.390 Loss 1.00228\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [120][0/97], lr: 0.01000\tTime 0.642 (0.642)\tData 0.473 (0.473)\tLoss 0.7283 (0.7283)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [120][10/97], lr: 0.01000\tTime 0.089 (0.138)\tData 0.000 (0.044)\tLoss 0.7045 (0.7714)\tPrec@1 73.438 (68.040)\n",
            "Epoch: [120][20/97], lr: 0.01000\tTime 0.066 (0.110)\tData 0.000 (0.024)\tLoss 0.7645 (0.7841)\tPrec@1 66.406 (67.225)\n",
            "Epoch: [120][30/97], lr: 0.01000\tTime 0.082 (0.102)\tData 0.000 (0.017)\tLoss 0.7092 (0.7837)\tPrec@1 74.219 (67.087)\n",
            "Epoch: [120][40/97], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.014)\tLoss 0.8728 (0.8025)\tPrec@1 64.844 (66.463)\n",
            "Epoch: [120][50/97], lr: 0.01000\tTime 0.082 (0.090)\tData 0.000 (0.012)\tLoss 0.7731 (0.7995)\tPrec@1 69.531 (66.805)\n",
            "Epoch: [120][60/97], lr: 0.01000\tTime 0.070 (0.087)\tData 0.009 (0.010)\tLoss 0.8797 (0.8014)\tPrec@1 64.844 (66.547)\n",
            "Epoch: [120][70/97], lr: 0.01000\tTime 0.068 (0.087)\tData 0.000 (0.009)\tLoss 0.7318 (0.8001)\tPrec@1 71.875 (66.483)\n",
            "Epoch: [120][80/97], lr: 0.01000\tTime 0.070 (0.087)\tData 0.000 (0.008)\tLoss 0.7795 (0.7998)\tPrec@1 66.406 (66.580)\n",
            "Epoch: [120][90/97], lr: 0.01000\tTime 0.057 (0.086)\tData 0.000 (0.008)\tLoss 0.7238 (0.7983)\tPrec@1 69.531 (66.732)\n",
            "Test: [0/100]\tTime 0.392 (0.392)\tLoss 0.8955 (0.8955)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.024 (0.071)\tLoss 1.0197 (0.9987)\tPrec@1 63.000 (59.636)\n",
            "Test: [20/100]\tTime 0.036 (0.054)\tLoss 1.2058 (1.0089)\tPrec@1 58.000 (60.190)\n",
            "Test: [30/100]\tTime 0.033 (0.047)\tLoss 0.9614 (1.0264)\tPrec@1 63.000 (59.613)\n",
            "Test: [40/100]\tTime 0.032 (0.043)\tLoss 0.9218 (1.0330)\tPrec@1 61.000 (59.415)\n",
            "Test: [50/100]\tTime 0.038 (0.041)\tLoss 0.9917 (1.0296)\tPrec@1 58.000 (59.412)\n",
            "Test: [60/100]\tTime 0.038 (0.039)\tLoss 1.1727 (1.0323)\tPrec@1 52.000 (59.328)\n",
            "Test: [70/100]\tTime 0.038 (0.038)\tLoss 0.9192 (1.0270)\tPrec@1 66.000 (59.324)\n",
            "Test: [80/100]\tTime 0.027 (0.037)\tLoss 0.9503 (1.0260)\tPrec@1 58.000 (59.333)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 1.1258 (1.0227)\tPrec@1 56.000 (59.549)\n",
            "val Results: Prec@1 59.610 Loss 1.02073\n",
            "Best Prec@1: 61.080\n",
            "\n",
            "Epoch: [121][0/97], lr: 0.01000\tTime 0.545 (0.545)\tData 0.415 (0.415)\tLoss 0.8330 (0.8330)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [121][10/97], lr: 0.01000\tTime 0.097 (0.120)\tData 0.000 (0.041)\tLoss 0.7590 (0.8145)\tPrec@1 66.406 (66.264)\n",
            "Epoch: [121][20/97], lr: 0.01000\tTime 0.064 (0.097)\tData 0.000 (0.022)\tLoss 0.7458 (0.8016)\tPrec@1 73.438 (67.299)\n",
            "Epoch: [121][30/97], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.016)\tLoss 0.7190 (0.7871)\tPrec@1 71.094 (67.792)\n",
            "Epoch: [121][40/97], lr: 0.01000\tTime 0.096 (0.085)\tData 0.005 (0.012)\tLoss 0.7323 (0.7892)\tPrec@1 70.312 (67.969)\n",
            "Epoch: [121][50/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.010)\tLoss 0.7920 (0.7945)\tPrec@1 64.844 (67.525)\n",
            "Epoch: [121][60/97], lr: 0.01000\tTime 0.083 (0.081)\tData 0.000 (0.009)\tLoss 0.7262 (0.7943)\tPrec@1 67.969 (67.405)\n",
            "Epoch: [121][70/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.008)\tLoss 0.7952 (0.7992)\tPrec@1 63.281 (67.088)\n",
            "Epoch: [121][80/97], lr: 0.01000\tTime 0.069 (0.079)\tData 0.004 (0.007)\tLoss 0.8112 (0.8035)\tPrec@1 67.969 (66.975)\n",
            "Epoch: [121][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.007)\tLoss 0.7132 (0.8025)\tPrec@1 74.219 (67.110)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 0.9815 (0.9815)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.022 (0.063)\tLoss 0.9539 (0.9201)\tPrec@1 60.000 (62.091)\n",
            "Test: [20/100]\tTime 0.032 (0.048)\tLoss 1.0009 (0.9087)\tPrec@1 60.000 (62.571)\n",
            "Test: [30/100]\tTime 0.041 (0.042)\tLoss 0.9302 (0.9212)\tPrec@1 63.000 (61.871)\n",
            "Test: [40/100]\tTime 0.044 (0.042)\tLoss 0.8443 (0.9192)\tPrec@1 65.000 (61.659)\n",
            "Test: [50/100]\tTime 0.030 (0.041)\tLoss 0.8965 (0.9229)\tPrec@1 60.000 (61.627)\n",
            "Test: [60/100]\tTime 0.066 (0.040)\tLoss 1.1435 (0.9325)\tPrec@1 53.000 (61.164)\n",
            "Test: [70/100]\tTime 0.022 (0.040)\tLoss 0.8074 (0.9325)\tPrec@1 66.000 (61.352)\n",
            "Test: [80/100]\tTime 0.053 (0.040)\tLoss 0.8966 (0.9287)\tPrec@1 60.000 (61.469)\n",
            "Test: [90/100]\tTime 0.025 (0.039)\tLoss 1.0112 (0.9260)\tPrec@1 58.000 (61.516)\n",
            "val Results: Prec@1 61.820 Loss 0.91903\n",
            "Best Prec@1: 61.820\n",
            "\n",
            "Epoch: [122][0/97], lr: 0.01000\tTime 0.574 (0.574)\tData 0.439 (0.439)\tLoss 0.7507 (0.7507)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [122][10/97], lr: 0.01000\tTime 0.065 (0.122)\tData 0.002 (0.043)\tLoss 0.9028 (0.7933)\tPrec@1 63.281 (67.827)\n",
            "Epoch: [122][20/97], lr: 0.01000\tTime 0.062 (0.097)\tData 0.000 (0.024)\tLoss 0.8125 (0.7943)\tPrec@1 64.844 (67.076)\n",
            "Epoch: [122][30/97], lr: 0.01000\tTime 0.118 (0.094)\tData 0.010 (0.018)\tLoss 0.8083 (0.7900)\tPrec@1 69.531 (67.339)\n",
            "Epoch: [122][40/97], lr: 0.01000\tTime 0.122 (0.098)\tData 0.000 (0.014)\tLoss 0.7968 (0.7875)\tPrec@1 64.062 (67.378)\n",
            "Epoch: [122][50/97], lr: 0.01000\tTime 0.121 (0.101)\tData 0.011 (0.013)\tLoss 0.8114 (0.7951)\tPrec@1 65.625 (66.866)\n",
            "Epoch: [122][60/97], lr: 0.01000\tTime 0.118 (0.102)\tData 0.000 (0.012)\tLoss 0.8485 (0.7898)\tPrec@1 64.844 (66.970)\n",
            "Epoch: [122][70/97], lr: 0.01000\tTime 0.063 (0.098)\tData 0.000 (0.011)\tLoss 0.8217 (0.7930)\tPrec@1 60.938 (66.868)\n",
            "Epoch: [122][80/97], lr: 0.01000\tTime 0.079 (0.095)\tData 0.007 (0.010)\tLoss 0.8719 (0.7939)\tPrec@1 62.500 (66.811)\n",
            "Epoch: [122][90/97], lr: 0.01000\tTime 0.056 (0.092)\tData 0.000 (0.009)\tLoss 0.7905 (0.7956)\tPrec@1 66.406 (66.793)\n",
            "Test: [0/100]\tTime 0.336 (0.336)\tLoss 0.9975 (0.9975)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 0.9690 (0.9755)\tPrec@1 61.000 (58.636)\n",
            "Test: [20/100]\tTime 0.033 (0.047)\tLoss 1.0970 (0.9688)\tPrec@1 62.000 (59.238)\n",
            "Test: [30/100]\tTime 0.042 (0.042)\tLoss 0.9640 (0.9706)\tPrec@1 58.000 (58.806)\n",
            "Test: [40/100]\tTime 0.046 (0.039)\tLoss 0.8972 (0.9719)\tPrec@1 59.000 (59.098)\n",
            "Test: [50/100]\tTime 0.026 (0.039)\tLoss 0.9797 (0.9721)\tPrec@1 64.000 (59.235)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.2127 (0.9806)\tPrec@1 50.000 (59.098)\n",
            "Test: [70/100]\tTime 0.030 (0.037)\tLoss 0.8703 (0.9791)\tPrec@1 64.000 (59.085)\n",
            "Test: [80/100]\tTime 0.028 (0.036)\tLoss 0.8775 (0.9746)\tPrec@1 63.000 (59.383)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.0116 (0.9739)\tPrec@1 61.000 (59.451)\n",
            "val Results: Prec@1 59.710 Loss 0.96721\n",
            "Best Prec@1: 61.820\n",
            "\n",
            "Epoch: [123][0/97], lr: 0.01000\tTime 0.561 (0.561)\tData 0.384 (0.384)\tLoss 0.7511 (0.7511)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [123][10/97], lr: 0.01000\tTime 0.079 (0.118)\tData 0.000 (0.039)\tLoss 0.8041 (0.7733)\tPrec@1 69.531 (68.040)\n",
            "Epoch: [123][20/97], lr: 0.01000\tTime 0.063 (0.095)\tData 0.000 (0.021)\tLoss 0.8424 (0.7979)\tPrec@1 63.281 (66.853)\n",
            "Epoch: [123][30/97], lr: 0.01000\tTime 0.063 (0.088)\tData 0.000 (0.015)\tLoss 0.7717 (0.7957)\tPrec@1 65.625 (67.238)\n",
            "Epoch: [123][40/97], lr: 0.01000\tTime 0.067 (0.084)\tData 0.000 (0.013)\tLoss 0.8003 (0.8069)\tPrec@1 63.281 (66.654)\n",
            "Epoch: [123][50/97], lr: 0.01000\tTime 0.069 (0.082)\tData 0.006 (0.011)\tLoss 0.6314 (0.7994)\tPrec@1 73.438 (66.958)\n",
            "Epoch: [123][60/97], lr: 0.01000\tTime 0.086 (0.081)\tData 0.007 (0.010)\tLoss 0.7677 (0.7993)\tPrec@1 67.188 (67.136)\n",
            "Epoch: [123][70/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.008)\tLoss 0.6200 (0.7896)\tPrec@1 75.000 (67.540)\n",
            "Epoch: [123][80/97], lr: 0.01000\tTime 0.067 (0.078)\tData 0.004 (0.008)\tLoss 0.8823 (0.7947)\tPrec@1 64.844 (67.120)\n",
            "Epoch: [123][90/97], lr: 0.01000\tTime 0.054 (0.077)\tData 0.000 (0.007)\tLoss 0.8973 (0.7919)\tPrec@1 60.938 (67.230)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 0.9442 (0.9442)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.037 (0.059)\tLoss 0.9328 (0.9351)\tPrec@1 63.000 (60.909)\n",
            "Test: [20/100]\tTime 0.025 (0.046)\tLoss 1.0517 (0.9344)\tPrec@1 56.000 (60.667)\n",
            "Test: [30/100]\tTime 0.040 (0.042)\tLoss 0.9847 (0.9360)\tPrec@1 59.000 (60.129)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.8382 (0.9355)\tPrec@1 64.000 (60.390)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 0.9644 (0.9352)\tPrec@1 58.000 (60.431)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 1.0090 (0.9388)\tPrec@1 58.000 (60.361)\n",
            "Test: [70/100]\tTime 0.050 (0.036)\tLoss 0.7763 (0.9373)\tPrec@1 68.000 (60.620)\n",
            "Test: [80/100]\tTime 0.034 (0.035)\tLoss 0.8633 (0.9371)\tPrec@1 58.000 (60.568)\n",
            "Test: [90/100]\tTime 0.029 (0.035)\tLoss 0.9854 (0.9375)\tPrec@1 55.000 (60.440)\n",
            "val Results: Prec@1 60.850 Loss 0.92922\n",
            "Best Prec@1: 61.820\n",
            "\n",
            "Epoch: [124][0/97], lr: 0.01000\tTime 0.547 (0.547)\tData 0.366 (0.366)\tLoss 0.9024 (0.9024)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [124][10/97], lr: 0.01000\tTime 0.067 (0.118)\tData 0.000 (0.035)\tLoss 0.8521 (0.7693)\tPrec@1 69.531 (68.679)\n",
            "Epoch: [124][20/97], lr: 0.01000\tTime 0.059 (0.095)\tData 0.000 (0.019)\tLoss 0.8147 (0.7904)\tPrec@1 68.750 (67.857)\n",
            "Epoch: [124][30/97], lr: 0.01000\tTime 0.072 (0.088)\tData 0.007 (0.014)\tLoss 0.7368 (0.8038)\tPrec@1 69.531 (67.288)\n",
            "Epoch: [124][40/97], lr: 0.01000\tTime 0.063 (0.084)\tData 0.000 (0.012)\tLoss 0.8816 (0.7997)\tPrec@1 60.938 (67.321)\n",
            "Epoch: [124][50/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.004 (0.010)\tLoss 0.8731 (0.8000)\tPrec@1 66.406 (67.249)\n",
            "Epoch: [124][60/97], lr: 0.01000\tTime 0.068 (0.080)\tData 0.006 (0.010)\tLoss 0.7285 (0.7932)\tPrec@1 71.094 (67.559)\n",
            "Epoch: [124][70/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.007 (0.009)\tLoss 0.7760 (0.7900)\tPrec@1 67.969 (67.749)\n",
            "Epoch: [124][80/97], lr: 0.01000\tTime 0.091 (0.078)\tData 0.000 (0.008)\tLoss 0.8138 (0.7896)\tPrec@1 67.188 (67.708)\n",
            "Epoch: [124][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.008)\tLoss 0.8779 (0.7903)\tPrec@1 63.281 (67.548)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 0.9291 (0.9291)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 0.8409 (0.9114)\tPrec@1 70.000 (63.273)\n",
            "Test: [20/100]\tTime 0.048 (0.047)\tLoss 0.9194 (0.9049)\tPrec@1 67.000 (63.524)\n",
            "Test: [30/100]\tTime 0.037 (0.042)\tLoss 0.9717 (0.9073)\tPrec@1 60.000 (62.677)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.8911 (0.9125)\tPrec@1 62.000 (62.415)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 0.8931 (0.9113)\tPrec@1 66.000 (62.392)\n",
            "Test: [60/100]\tTime 0.042 (0.037)\tLoss 1.1016 (0.9182)\tPrec@1 50.000 (62.131)\n",
            "Test: [70/100]\tTime 0.036 (0.036)\tLoss 0.8731 (0.9186)\tPrec@1 72.000 (62.225)\n",
            "Test: [80/100]\tTime 0.028 (0.036)\tLoss 0.9105 (0.9172)\tPrec@1 62.000 (62.395)\n",
            "Test: [90/100]\tTime 0.038 (0.035)\tLoss 0.9620 (0.9157)\tPrec@1 62.000 (62.440)\n",
            "val Results: Prec@1 62.730 Loss 0.90988\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [125][0/97], lr: 0.01000\tTime 0.556 (0.556)\tData 0.393 (0.393)\tLoss 0.8012 (0.8012)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [125][10/97], lr: 0.01000\tTime 0.067 (0.119)\tData 0.005 (0.039)\tLoss 0.8167 (0.7896)\tPrec@1 67.969 (67.898)\n",
            "Epoch: [125][20/97], lr: 0.01000\tTime 0.088 (0.097)\tData 0.000 (0.021)\tLoss 0.8399 (0.7972)\tPrec@1 60.156 (67.448)\n",
            "Epoch: [125][30/97], lr: 0.01000\tTime 0.065 (0.091)\tData 0.000 (0.016)\tLoss 0.6926 (0.7907)\tPrec@1 75.000 (67.792)\n",
            "Epoch: [125][40/97], lr: 0.01000\tTime 0.060 (0.085)\tData 0.000 (0.013)\tLoss 0.7893 (0.7824)\tPrec@1 67.969 (68.064)\n",
            "Epoch: [125][50/97], lr: 0.01000\tTime 0.074 (0.083)\tData 0.007 (0.011)\tLoss 0.7481 (0.7826)\tPrec@1 72.656 (68.015)\n",
            "Epoch: [125][60/97], lr: 0.01000\tTime 0.073 (0.082)\tData 0.006 (0.009)\tLoss 0.8168 (0.7872)\tPrec@1 67.188 (67.930)\n",
            "Epoch: [125][70/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.008)\tLoss 0.9030 (0.7951)\tPrec@1 64.062 (67.573)\n",
            "Epoch: [125][80/97], lr: 0.01000\tTime 0.075 (0.079)\tData 0.005 (0.008)\tLoss 0.6996 (0.7926)\tPrec@1 67.188 (67.612)\n",
            "Epoch: [125][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.007)\tLoss 0.8398 (0.7926)\tPrec@1 69.531 (67.728)\n",
            "Test: [0/100]\tTime 0.353 (0.353)\tLoss 0.9196 (0.9196)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.042 (0.063)\tLoss 0.8723 (0.8959)\tPrec@1 62.000 (62.091)\n",
            "Test: [20/100]\tTime 0.026 (0.047)\tLoss 1.0101 (0.8980)\tPrec@1 55.000 (61.667)\n",
            "Test: [30/100]\tTime 0.028 (0.042)\tLoss 0.9642 (0.9018)\tPrec@1 55.000 (61.806)\n",
            "Test: [40/100]\tTime 0.022 (0.040)\tLoss 0.9567 (0.9003)\tPrec@1 54.000 (61.659)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.9321 (0.9001)\tPrec@1 63.000 (61.824)\n",
            "Test: [60/100]\tTime 0.021 (0.037)\tLoss 1.0422 (0.9075)\tPrec@1 48.000 (61.459)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.8663 (0.9103)\tPrec@1 66.000 (61.211)\n",
            "Test: [80/100]\tTime 0.030 (0.036)\tLoss 0.8617 (0.9078)\tPrec@1 62.000 (61.259)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 0.9780 (0.9090)\tPrec@1 62.000 (61.418)\n",
            "val Results: Prec@1 61.650 Loss 0.90320\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [126][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.318 (0.318)\tLoss 0.8179 (0.8179)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [126][10/97], lr: 0.01000\tTime 0.070 (0.121)\tData 0.007 (0.031)\tLoss 0.7771 (0.7472)\tPrec@1 68.750 (68.892)\n",
            "Epoch: [126][20/97], lr: 0.01000\tTime 0.063 (0.097)\tData 0.000 (0.017)\tLoss 0.8564 (0.7733)\tPrec@1 71.094 (68.452)\n",
            "Epoch: [126][30/97], lr: 0.01000\tTime 0.077 (0.090)\tData 0.012 (0.012)\tLoss 0.9177 (0.7867)\tPrec@1 57.031 (67.868)\n",
            "Epoch: [126][40/97], lr: 0.01000\tTime 0.087 (0.085)\tData 0.000 (0.010)\tLoss 0.7357 (0.7845)\tPrec@1 70.312 (67.702)\n",
            "Epoch: [126][50/97], lr: 0.01000\tTime 0.068 (0.083)\tData 0.001 (0.008)\tLoss 0.6596 (0.7792)\tPrec@1 76.562 (67.984)\n",
            "Epoch: [126][60/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.007)\tLoss 0.7666 (0.7796)\tPrec@1 66.406 (67.789)\n",
            "Epoch: [126][70/97], lr: 0.01000\tTime 0.070 (0.080)\tData 0.001 (0.007)\tLoss 0.7396 (0.7823)\tPrec@1 71.875 (67.826)\n",
            "Epoch: [126][80/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.006)\tLoss 0.9398 (0.7865)\tPrec@1 56.250 (67.631)\n",
            "Epoch: [126][90/97], lr: 0.01000\tTime 0.052 (0.077)\tData 0.000 (0.006)\tLoss 0.7629 (0.7879)\tPrec@1 73.438 (67.694)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 0.9311 (0.9311)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 0.9267 (0.9226)\tPrec@1 63.000 (61.273)\n",
            "Test: [20/100]\tTime 0.049 (0.047)\tLoss 1.0117 (0.9224)\tPrec@1 66.000 (62.143)\n",
            "Test: [30/100]\tTime 0.050 (0.042)\tLoss 0.8563 (0.9256)\tPrec@1 65.000 (61.968)\n",
            "Test: [40/100]\tTime 0.058 (0.040)\tLoss 0.9177 (0.9327)\tPrec@1 61.000 (61.317)\n",
            "Test: [50/100]\tTime 0.029 (0.038)\tLoss 0.9919 (0.9336)\tPrec@1 64.000 (61.725)\n",
            "Test: [60/100]\tTime 0.035 (0.037)\tLoss 1.0239 (0.9406)\tPrec@1 55.000 (61.393)\n",
            "Test: [70/100]\tTime 0.029 (0.036)\tLoss 0.8425 (0.9386)\tPrec@1 66.000 (61.366)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.8805 (0.9348)\tPrec@1 63.000 (61.679)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 1.0367 (0.9328)\tPrec@1 54.000 (61.593)\n",
            "val Results: Prec@1 61.820 Loss 0.92671\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [127][0/97], lr: 0.01000\tTime 0.565 (0.565)\tData 0.366 (0.366)\tLoss 0.7807 (0.7807)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [127][10/97], lr: 0.01000\tTime 0.063 (0.118)\tData 0.000 (0.037)\tLoss 0.8048 (0.7998)\tPrec@1 67.188 (67.756)\n",
            "Epoch: [127][20/97], lr: 0.01000\tTime 0.063 (0.096)\tData 0.000 (0.021)\tLoss 0.6480 (0.7809)\tPrec@1 78.125 (68.006)\n",
            "Epoch: [127][30/97], lr: 0.01000\tTime 0.081 (0.089)\tData 0.007 (0.014)\tLoss 0.7979 (0.7924)\tPrec@1 68.750 (67.515)\n",
            "Epoch: [127][40/97], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.011)\tLoss 0.8186 (0.7899)\tPrec@1 66.406 (67.702)\n",
            "Epoch: [127][50/97], lr: 0.01000\tTime 0.079 (0.082)\tData 0.006 (0.010)\tLoss 0.7940 (0.7898)\tPrec@1 67.188 (67.586)\n",
            "Epoch: [127][60/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.009)\tLoss 0.6606 (0.7911)\tPrec@1 68.750 (67.431)\n",
            "Epoch: [127][70/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.001 (0.008)\tLoss 0.7725 (0.7858)\tPrec@1 64.062 (67.430)\n",
            "Epoch: [127][80/97], lr: 0.01000\tTime 0.082 (0.078)\tData 0.006 (0.008)\tLoss 0.8140 (0.7858)\tPrec@1 68.750 (67.323)\n",
            "Epoch: [127][90/97], lr: 0.01000\tTime 0.057 (0.077)\tData 0.000 (0.007)\tLoss 0.8896 (0.7827)\tPrec@1 61.719 (67.419)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 1.1223 (1.1223)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.033 (0.062)\tLoss 0.9276 (0.9998)\tPrec@1 64.000 (59.182)\n",
            "Test: [20/100]\tTime 0.021 (0.046)\tLoss 1.1085 (0.9843)\tPrec@1 57.000 (59.667)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 1.0558 (0.9978)\tPrec@1 59.000 (58.935)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.9346 (0.9965)\tPrec@1 58.000 (58.878)\n",
            "Test: [50/100]\tTime 0.020 (0.037)\tLoss 1.1158 (0.9907)\tPrec@1 58.000 (59.392)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.2584 (0.9975)\tPrec@1 49.000 (59.525)\n",
            "Test: [70/100]\tTime 0.022 (0.035)\tLoss 0.9118 (0.9954)\tPrec@1 65.000 (59.465)\n",
            "Test: [80/100]\tTime 0.026 (0.035)\tLoss 0.9294 (0.9940)\tPrec@1 57.000 (59.716)\n",
            "Test: [90/100]\tTime 0.037 (0.035)\tLoss 1.0555 (0.9974)\tPrec@1 62.000 (59.538)\n",
            "val Results: Prec@1 59.950 Loss 0.98916\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [128][0/97], lr: 0.01000\tTime 0.605 (0.605)\tData 0.403 (0.403)\tLoss 0.7550 (0.7550)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [128][10/97], lr: 0.01000\tTime 0.067 (0.119)\tData 0.000 (0.039)\tLoss 0.6989 (0.7594)\tPrec@1 67.969 (69.957)\n",
            "Epoch: [128][20/97], lr: 0.01000\tTime 0.067 (0.097)\tData 0.000 (0.022)\tLoss 0.9137 (0.7614)\tPrec@1 63.281 (69.606)\n",
            "Epoch: [128][30/97], lr: 0.01000\tTime 0.081 (0.088)\tData 0.006 (0.016)\tLoss 0.8116 (0.7711)\tPrec@1 68.750 (68.952)\n",
            "Epoch: [128][40/97], lr: 0.01000\tTime 0.062 (0.084)\tData 0.001 (0.013)\tLoss 0.7675 (0.7712)\tPrec@1 69.531 (68.731)\n",
            "Epoch: [128][50/97], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.011)\tLoss 0.7724 (0.7737)\tPrec@1 68.750 (68.735)\n",
            "Epoch: [128][60/97], lr: 0.01000\tTime 0.071 (0.080)\tData 0.004 (0.010)\tLoss 0.6708 (0.7818)\tPrec@1 71.094 (68.353)\n",
            "Epoch: [128][70/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.009)\tLoss 0.6881 (0.7813)\tPrec@1 73.438 (68.255)\n",
            "Epoch: [128][80/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.001 (0.008)\tLoss 0.8141 (0.7829)\tPrec@1 65.625 (68.229)\n",
            "Epoch: [128][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.7266 (0.7863)\tPrec@1 68.750 (68.012)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 0.9654 (0.9654)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.025 (0.061)\tLoss 1.0070 (0.9519)\tPrec@1 56.000 (59.364)\n",
            "Test: [20/100]\tTime 0.023 (0.048)\tLoss 1.0221 (0.9441)\tPrec@1 62.000 (59.286)\n",
            "Test: [30/100]\tTime 0.024 (0.042)\tLoss 0.9107 (0.9485)\tPrec@1 62.000 (59.161)\n",
            "Test: [40/100]\tTime 0.049 (0.040)\tLoss 0.8987 (0.9515)\tPrec@1 61.000 (59.098)\n",
            "Test: [50/100]\tTime 0.030 (0.038)\tLoss 0.9216 (0.9491)\tPrec@1 63.000 (59.549)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.0133 (0.9538)\tPrec@1 55.000 (59.311)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9227 (0.9551)\tPrec@1 63.000 (59.394)\n",
            "Test: [80/100]\tTime 0.022 (0.035)\tLoss 0.8011 (0.9503)\tPrec@1 64.000 (59.605)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 0.9756 (0.9491)\tPrec@1 53.000 (59.527)\n",
            "val Results: Prec@1 59.750 Loss 0.94363\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [129][0/97], lr: 0.01000\tTime 0.483 (0.483)\tData 0.299 (0.299)\tLoss 0.7499 (0.7499)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [129][10/97], lr: 0.01000\tTime 0.076 (0.116)\tData 0.000 (0.030)\tLoss 0.8390 (0.8012)\tPrec@1 61.719 (65.341)\n",
            "Epoch: [129][20/97], lr: 0.01000\tTime 0.064 (0.094)\tData 0.000 (0.017)\tLoss 0.8203 (0.7949)\tPrec@1 65.625 (66.369)\n",
            "Epoch: [129][30/97], lr: 0.01000\tTime 0.061 (0.086)\tData 0.000 (0.013)\tLoss 0.6989 (0.7879)\tPrec@1 70.312 (66.860)\n",
            "Epoch: [129][40/97], lr: 0.01000\tTime 0.065 (0.083)\tData 0.001 (0.011)\tLoss 0.7164 (0.7821)\tPrec@1 67.188 (67.359)\n",
            "Epoch: [129][50/97], lr: 0.01000\tTime 0.079 (0.081)\tData 0.007 (0.009)\tLoss 0.7694 (0.7799)\tPrec@1 65.625 (67.693)\n",
            "Epoch: [129][60/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.008)\tLoss 0.8619 (0.7879)\tPrec@1 67.188 (67.623)\n",
            "Epoch: [129][70/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.008)\tLoss 0.7629 (0.7905)\tPrec@1 70.312 (67.617)\n",
            "Epoch: [129][80/97], lr: 0.01000\tTime 0.080 (0.078)\tData 0.007 (0.007)\tLoss 0.7600 (0.7896)\tPrec@1 70.312 (67.728)\n",
            "Epoch: [129][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8036 (0.7866)\tPrec@1 66.406 (67.763)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 0.9172 (0.9172)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.021 (0.060)\tLoss 0.8509 (0.9077)\tPrec@1 64.000 (62.273)\n",
            "Test: [20/100]\tTime 0.043 (0.048)\tLoss 1.0155 (0.9102)\tPrec@1 59.000 (62.857)\n",
            "Test: [30/100]\tTime 0.023 (0.043)\tLoss 0.9095 (0.9142)\tPrec@1 62.000 (62.258)\n",
            "Test: [40/100]\tTime 0.027 (0.040)\tLoss 0.9018 (0.9105)\tPrec@1 58.000 (62.122)\n",
            "Test: [50/100]\tTime 0.025 (0.038)\tLoss 1.0363 (0.9138)\tPrec@1 56.000 (61.902)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1098 (0.9251)\tPrec@1 52.000 (61.361)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 0.9042 (0.9251)\tPrec@1 66.000 (61.127)\n",
            "Test: [80/100]\tTime 0.049 (0.036)\tLoss 0.8446 (0.9259)\tPrec@1 65.000 (61.222)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 1.0557 (0.9277)\tPrec@1 54.000 (61.099)\n",
            "val Results: Prec@1 61.290 Loss 0.92276\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [130][0/97], lr: 0.01000\tTime 0.486 (0.486)\tData 0.302 (0.302)\tLoss 0.7969 (0.7969)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [130][10/97], lr: 0.01000\tTime 0.069 (0.119)\tData 0.006 (0.031)\tLoss 0.9029 (0.7890)\tPrec@1 58.594 (68.111)\n",
            "Epoch: [130][20/97], lr: 0.01000\tTime 0.097 (0.098)\tData 0.007 (0.018)\tLoss 0.7162 (0.7816)\tPrec@1 68.750 (68.564)\n",
            "Epoch: [130][30/97], lr: 0.01000\tTime 0.070 (0.089)\tData 0.007 (0.013)\tLoss 0.8236 (0.7913)\tPrec@1 65.625 (67.893)\n",
            "Epoch: [130][40/97], lr: 0.01000\tTime 0.068 (0.085)\tData 0.000 (0.010)\tLoss 0.8188 (0.7889)\tPrec@1 68.750 (67.816)\n",
            "Epoch: [130][50/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.005 (0.009)\tLoss 0.8670 (0.7864)\tPrec@1 64.062 (67.708)\n",
            "Epoch: [130][60/97], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.008)\tLoss 0.8300 (0.7830)\tPrec@1 64.062 (67.700)\n",
            "Epoch: [130][70/97], lr: 0.01000\tTime 0.074 (0.080)\tData 0.009 (0.008)\tLoss 0.6126 (0.7824)\tPrec@1 77.344 (67.617)\n",
            "Epoch: [130][80/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.000 (0.007)\tLoss 0.7027 (0.7840)\tPrec@1 68.750 (67.679)\n",
            "Epoch: [130][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.007)\tLoss 0.6647 (0.7815)\tPrec@1 71.875 (67.874)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 0.9362 (0.9362)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.036 (0.058)\tLoss 0.9529 (0.9243)\tPrec@1 61.000 (61.091)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 0.9730 (0.9218)\tPrec@1 64.000 (62.524)\n",
            "Test: [30/100]\tTime 0.021 (0.042)\tLoss 0.9513 (0.9330)\tPrec@1 59.000 (61.677)\n",
            "Test: [40/100]\tTime 0.027 (0.039)\tLoss 0.8497 (0.9339)\tPrec@1 66.000 (61.000)\n",
            "Test: [50/100]\tTime 0.038 (0.038)\tLoss 1.0150 (0.9324)\tPrec@1 55.000 (61.255)\n",
            "Test: [60/100]\tTime 0.027 (0.036)\tLoss 1.0211 (0.9344)\tPrec@1 53.000 (61.082)\n",
            "Test: [70/100]\tTime 0.033 (0.036)\tLoss 0.8851 (0.9331)\tPrec@1 63.000 (61.169)\n",
            "Test: [80/100]\tTime 0.028 (0.035)\tLoss 0.8895 (0.9316)\tPrec@1 61.000 (61.321)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0891 (0.9320)\tPrec@1 60.000 (61.418)\n",
            "val Results: Prec@1 61.640 Loss 0.92636\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [131][0/97], lr: 0.01000\tTime 0.563 (0.563)\tData 0.345 (0.345)\tLoss 0.8345 (0.8345)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [131][10/97], lr: 0.01000\tTime 0.065 (0.115)\tData 0.000 (0.034)\tLoss 0.7265 (0.8233)\tPrec@1 73.438 (65.199)\n",
            "Epoch: [131][20/97], lr: 0.01000\tTime 0.075 (0.095)\tData 0.006 (0.019)\tLoss 0.7334 (0.8112)\tPrec@1 71.875 (66.555)\n",
            "Epoch: [131][30/97], lr: 0.01000\tTime 0.085 (0.086)\tData 0.000 (0.013)\tLoss 0.8171 (0.8047)\tPrec@1 66.406 (66.759)\n",
            "Epoch: [131][40/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.001 (0.010)\tLoss 0.6323 (0.7976)\tPrec@1 76.562 (66.787)\n",
            "Epoch: [131][50/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.008)\tLoss 0.9027 (0.8048)\tPrec@1 63.281 (66.590)\n",
            "Epoch: [131][60/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.007 (0.007)\tLoss 0.8387 (0.8081)\tPrec@1 63.281 (66.586)\n",
            "Epoch: [131][70/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.004 (0.007)\tLoss 0.6579 (0.8011)\tPrec@1 71.875 (66.978)\n",
            "Epoch: [131][80/97], lr: 0.01000\tTime 0.073 (0.077)\tData 0.006 (0.006)\tLoss 0.6819 (0.7931)\tPrec@1 75.000 (67.313)\n",
            "Epoch: [131][90/97], lr: 0.01000\tTime 0.049 (0.075)\tData 0.000 (0.006)\tLoss 0.7789 (0.7896)\tPrec@1 65.625 (67.436)\n",
            "Test: [0/100]\tTime 0.256 (0.256)\tLoss 1.0151 (1.0151)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.041 (0.059)\tLoss 0.8001 (0.9105)\tPrec@1 70.000 (61.455)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.9209 (0.9002)\tPrec@1 66.000 (61.667)\n",
            "Test: [30/100]\tTime 0.036 (0.041)\tLoss 0.9266 (0.9038)\tPrec@1 59.000 (61.194)\n",
            "Test: [40/100]\tTime 0.023 (0.038)\tLoss 0.8814 (0.9003)\tPrec@1 60.000 (61.244)\n",
            "Test: [50/100]\tTime 0.025 (0.037)\tLoss 0.9132 (0.9003)\tPrec@1 63.000 (61.353)\n",
            "Test: [60/100]\tTime 0.044 (0.037)\tLoss 1.0093 (0.9082)\tPrec@1 59.000 (61.197)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.8148 (0.9045)\tPrec@1 65.000 (61.535)\n",
            "Test: [80/100]\tTime 0.026 (0.035)\tLoss 0.7943 (0.9020)\tPrec@1 64.000 (61.667)\n",
            "Test: [90/100]\tTime 0.056 (0.035)\tLoss 0.9945 (0.8987)\tPrec@1 59.000 (61.868)\n",
            "val Results: Prec@1 62.150 Loss 0.89390\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [132][0/97], lr: 0.01000\tTime 0.555 (0.555)\tData 0.421 (0.421)\tLoss 0.7660 (0.7660)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [132][10/97], lr: 0.01000\tTime 0.062 (0.115)\tData 0.000 (0.041)\tLoss 0.7349 (0.7263)\tPrec@1 66.406 (70.170)\n",
            "Epoch: [132][20/97], lr: 0.01000\tTime 0.069 (0.094)\tData 0.007 (0.023)\tLoss 0.9333 (0.7724)\tPrec@1 62.500 (68.006)\n",
            "Epoch: [132][30/97], lr: 0.01000\tTime 0.064 (0.086)\tData 0.000 (0.016)\tLoss 0.8783 (0.7837)\tPrec@1 67.188 (67.767)\n",
            "Epoch: [132][40/97], lr: 0.01000\tTime 0.086 (0.084)\tData 0.006 (0.013)\tLoss 0.7335 (0.7862)\tPrec@1 70.312 (68.045)\n",
            "Epoch: [132][50/97], lr: 0.01000\tTime 0.065 (0.082)\tData 0.000 (0.011)\tLoss 0.7583 (0.7862)\tPrec@1 67.188 (67.693)\n",
            "Epoch: [132][60/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.009)\tLoss 0.8133 (0.7861)\tPrec@1 64.062 (67.674)\n",
            "Epoch: [132][70/97], lr: 0.01000\tTime 0.074 (0.079)\tData 0.009 (0.009)\tLoss 0.6556 (0.7862)\tPrec@1 75.000 (67.716)\n",
            "Epoch: [132][80/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.008)\tLoss 0.9355 (0.7920)\tPrec@1 57.812 (67.303)\n",
            "Epoch: [132][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.7830 (0.7950)\tPrec@1 63.281 (67.153)\n",
            "Test: [0/100]\tTime 0.261 (0.261)\tLoss 0.9417 (0.9417)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.9178 (0.8887)\tPrec@1 67.000 (64.091)\n",
            "Test: [20/100]\tTime 0.025 (0.046)\tLoss 1.0088 (0.9009)\tPrec@1 60.000 (63.429)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.9342 (0.9086)\tPrec@1 62.000 (62.613)\n",
            "Test: [40/100]\tTime 0.046 (0.039)\tLoss 0.8939 (0.9150)\tPrec@1 60.000 (61.976)\n",
            "Test: [50/100]\tTime 0.052 (0.038)\tLoss 1.0010 (0.9168)\tPrec@1 59.000 (62.059)\n",
            "Test: [60/100]\tTime 0.059 (0.037)\tLoss 1.0636 (0.9253)\tPrec@1 61.000 (61.951)\n",
            "Test: [70/100]\tTime 0.040 (0.036)\tLoss 0.8244 (0.9207)\tPrec@1 67.000 (62.169)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 0.9102 (0.9227)\tPrec@1 63.000 (62.000)\n",
            "Test: [90/100]\tTime 0.039 (0.035)\tLoss 0.9343 (0.9232)\tPrec@1 64.000 (61.890)\n",
            "val Results: Prec@1 62.120 Loss 0.91702\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [133][0/97], lr: 0.01000\tTime 0.552 (0.552)\tData 0.399 (0.399)\tLoss 0.6945 (0.6945)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [133][10/97], lr: 0.01000\tTime 0.080 (0.115)\tData 0.000 (0.039)\tLoss 0.6755 (0.7614)\tPrec@1 71.875 (68.821)\n",
            "Epoch: [133][20/97], lr: 0.01000\tTime 0.067 (0.093)\tData 0.000 (0.021)\tLoss 0.7688 (0.7811)\tPrec@1 67.188 (68.192)\n",
            "Epoch: [133][30/97], lr: 0.01000\tTime 0.074 (0.087)\tData 0.002 (0.015)\tLoss 0.6703 (0.7709)\tPrec@1 73.438 (68.448)\n",
            "Epoch: [133][40/97], lr: 0.01000\tTime 0.063 (0.082)\tData 0.000 (0.012)\tLoss 0.8454 (0.7723)\tPrec@1 64.844 (68.445)\n",
            "Epoch: [133][50/97], lr: 0.01000\tTime 0.099 (0.084)\tData 0.000 (0.010)\tLoss 0.7840 (0.7674)\tPrec@1 70.312 (68.536)\n",
            "Epoch: [133][60/97], lr: 0.01000\tTime 0.071 (0.084)\tData 0.007 (0.009)\tLoss 0.7727 (0.7648)\tPrec@1 67.969 (68.391)\n",
            "Epoch: [133][70/97], lr: 0.01000\tTime 0.071 (0.083)\tData 0.000 (0.008)\tLoss 0.7625 (0.7723)\tPrec@1 67.188 (68.057)\n",
            "Epoch: [133][80/97], lr: 0.01000\tTime 0.061 (0.083)\tData 0.000 (0.007)\tLoss 0.9165 (0.7768)\tPrec@1 59.375 (67.554)\n",
            "Epoch: [133][90/97], lr: 0.01000\tTime 0.055 (0.082)\tData 0.000 (0.007)\tLoss 0.8412 (0.7803)\tPrec@1 67.188 (67.488)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.9616 (0.9616)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.022 (0.061)\tLoss 0.9179 (0.9266)\tPrec@1 62.000 (61.091)\n",
            "Test: [20/100]\tTime 0.034 (0.047)\tLoss 0.9021 (0.9184)\tPrec@1 67.000 (61.476)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9365 (0.9251)\tPrec@1 61.000 (61.097)\n",
            "Test: [40/100]\tTime 0.024 (0.039)\tLoss 0.8540 (0.9258)\tPrec@1 66.000 (61.195)\n",
            "Test: [50/100]\tTime 0.060 (0.038)\tLoss 1.0633 (0.9284)\tPrec@1 57.000 (61.353)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1144 (0.9345)\tPrec@1 52.000 (61.213)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.8451 (0.9342)\tPrec@1 68.000 (61.225)\n",
            "Test: [80/100]\tTime 0.038 (0.036)\tLoss 0.7943 (0.9307)\tPrec@1 61.000 (61.296)\n",
            "Test: [90/100]\tTime 0.031 (0.037)\tLoss 1.0135 (0.9297)\tPrec@1 56.000 (61.297)\n",
            "val Results: Prec@1 61.560 Loss 0.92292\n",
            "Best Prec@1: 62.730\n",
            "\n",
            "Epoch: [134][0/97], lr: 0.01000\tTime 0.550 (0.550)\tData 0.337 (0.337)\tLoss 0.7561 (0.7561)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [134][10/97], lr: 0.01000\tTime 0.075 (0.116)\tData 0.004 (0.034)\tLoss 0.6710 (0.8159)\tPrec@1 73.438 (66.406)\n",
            "Epoch: [134][20/97], lr: 0.01000\tTime 0.078 (0.095)\tData 0.007 (0.020)\tLoss 0.8628 (0.7986)\tPrec@1 63.281 (67.001)\n",
            "Epoch: [134][30/97], lr: 0.01000\tTime 0.093 (0.088)\tData 0.013 (0.014)\tLoss 0.7974 (0.7906)\tPrec@1 66.406 (67.137)\n",
            "Epoch: [134][40/97], lr: 0.01000\tTime 0.077 (0.084)\tData 0.006 (0.012)\tLoss 0.7538 (0.7821)\tPrec@1 67.969 (67.607)\n",
            "Epoch: [134][50/97], lr: 0.01000\tTime 0.085 (0.081)\tData 0.006 (0.009)\tLoss 0.7224 (0.7790)\tPrec@1 71.094 (67.923)\n",
            "Epoch: [134][60/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.008)\tLoss 0.8095 (0.7797)\tPrec@1 66.406 (67.956)\n",
            "Epoch: [134][70/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.008)\tLoss 0.6700 (0.7798)\tPrec@1 71.875 (68.046)\n",
            "Epoch: [134][80/97], lr: 0.01000\tTime 0.071 (0.077)\tData 0.007 (0.007)\tLoss 0.7915 (0.7780)\tPrec@1 64.062 (68.075)\n",
            "Epoch: [134][90/97], lr: 0.01000\tTime 0.048 (0.078)\tData 0.000 (0.007)\tLoss 0.6915 (0.7751)\tPrec@1 72.656 (68.209)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 0.9497 (0.9497)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.059 (0.072)\tLoss 0.8951 (0.8903)\tPrec@1 64.000 (62.818)\n",
            "Test: [20/100]\tTime 0.023 (0.052)\tLoss 0.9383 (0.8874)\tPrec@1 68.000 (63.429)\n",
            "Test: [30/100]\tTime 0.022 (0.047)\tLoss 0.9354 (0.9041)\tPrec@1 63.000 (62.097)\n",
            "Test: [40/100]\tTime 0.024 (0.045)\tLoss 0.8582 (0.8981)\tPrec@1 63.000 (62.805)\n",
            "Test: [50/100]\tTime 0.069 (0.044)\tLoss 0.9997 (0.9007)\tPrec@1 60.000 (62.725)\n",
            "Test: [60/100]\tTime 0.035 (0.043)\tLoss 1.1401 (0.9083)\tPrec@1 54.000 (62.492)\n",
            "Test: [70/100]\tTime 0.046 (0.042)\tLoss 0.7601 (0.9108)\tPrec@1 70.000 (62.239)\n",
            "Test: [80/100]\tTime 0.024 (0.040)\tLoss 0.8846 (0.9104)\tPrec@1 64.000 (62.580)\n",
            "Test: [90/100]\tTime 0.033 (0.039)\tLoss 0.9937 (0.9095)\tPrec@1 62.000 (62.769)\n",
            "val Results: Prec@1 63.030 Loss 0.90491\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [135][0/97], lr: 0.01000\tTime 0.530 (0.530)\tData 0.391 (0.391)\tLoss 0.7006 (0.7006)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [135][10/97], lr: 0.01000\tTime 0.063 (0.118)\tData 0.000 (0.037)\tLoss 0.8677 (0.7514)\tPrec@1 69.531 (69.673)\n",
            "Epoch: [135][20/97], lr: 0.01000\tTime 0.076 (0.096)\tData 0.007 (0.020)\tLoss 0.9006 (0.7752)\tPrec@1 60.938 (68.415)\n",
            "Epoch: [135][30/97], lr: 0.01000\tTime 0.069 (0.088)\tData 0.007 (0.015)\tLoss 0.7910 (0.7693)\tPrec@1 68.750 (68.498)\n",
            "Epoch: [135][40/97], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.012)\tLoss 0.7012 (0.7723)\tPrec@1 69.531 (68.121)\n",
            "Epoch: [135][50/97], lr: 0.01000\tTime 0.087 (0.081)\tData 0.000 (0.010)\tLoss 0.8307 (0.7822)\tPrec@1 66.406 (67.770)\n",
            "Epoch: [135][60/97], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.009)\tLoss 0.8719 (0.7831)\tPrec@1 69.531 (67.969)\n",
            "Epoch: [135][70/97], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.008)\tLoss 0.7864 (0.7819)\tPrec@1 69.531 (68.178)\n",
            "Epoch: [135][80/97], lr: 0.01000\tTime 0.068 (0.078)\tData 0.004 (0.007)\tLoss 0.6963 (0.7807)\tPrec@1 69.531 (68.094)\n",
            "Epoch: [135][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.8084 (0.7799)\tPrec@1 63.281 (68.115)\n",
            "Test: [0/100]\tTime 0.246 (0.246)\tLoss 0.8566 (0.8566)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.024 (0.058)\tLoss 0.8569 (0.8890)\tPrec@1 63.000 (63.636)\n",
            "Test: [20/100]\tTime 0.025 (0.046)\tLoss 0.9177 (0.8861)\tPrec@1 63.000 (63.095)\n",
            "Test: [30/100]\tTime 0.050 (0.047)\tLoss 0.9325 (0.8995)\tPrec@1 59.000 (62.065)\n",
            "Test: [40/100]\tTime 0.064 (0.045)\tLoss 0.8051 (0.8939)\tPrec@1 71.000 (62.439)\n",
            "Test: [50/100]\tTime 0.036 (0.044)\tLoss 0.9703 (0.8984)\tPrec@1 56.000 (62.235)\n",
            "Test: [60/100]\tTime 0.036 (0.042)\tLoss 0.9972 (0.9023)\tPrec@1 59.000 (62.230)\n",
            "Test: [70/100]\tTime 0.093 (0.043)\tLoss 0.8440 (0.9013)\tPrec@1 67.000 (62.296)\n",
            "Test: [80/100]\tTime 0.023 (0.044)\tLoss 0.8226 (0.8984)\tPrec@1 66.000 (62.556)\n",
            "Test: [90/100]\tTime 0.101 (0.047)\tLoss 1.0140 (0.8996)\tPrec@1 60.000 (62.297)\n",
            "val Results: Prec@1 62.530 Loss 0.89422\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [136][0/97], lr: 0.01000\tTime 0.714 (0.714)\tData 0.533 (0.533)\tLoss 0.8081 (0.8081)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [136][10/97], lr: 0.01000\tTime 0.066 (0.147)\tData 0.003 (0.054)\tLoss 0.8287 (0.7683)\tPrec@1 66.406 (67.827)\n",
            "Epoch: [136][20/97], lr: 0.01000\tTime 0.068 (0.111)\tData 0.000 (0.030)\tLoss 0.6975 (0.7668)\tPrec@1 70.312 (68.118)\n",
            "Epoch: [136][30/97], lr: 0.01000\tTime 0.079 (0.098)\tData 0.007 (0.021)\tLoss 0.7225 (0.7806)\tPrec@1 66.406 (67.591)\n",
            "Epoch: [136][40/97], lr: 0.01000\tTime 0.063 (0.091)\tData 0.000 (0.017)\tLoss 0.7611 (0.7807)\tPrec@1 67.969 (67.473)\n",
            "Epoch: [136][50/97], lr: 0.01000\tTime 0.122 (0.089)\tData 0.002 (0.014)\tLoss 0.6961 (0.7837)\tPrec@1 75.000 (67.479)\n",
            "Epoch: [136][60/97], lr: 0.01000\tTime 0.107 (0.090)\tData 0.000 (0.012)\tLoss 0.7802 (0.7786)\tPrec@1 67.188 (67.853)\n",
            "Epoch: [136][70/97], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.011)\tLoss 0.8442 (0.7799)\tPrec@1 67.188 (67.870)\n",
            "Epoch: [136][80/97], lr: 0.01000\tTime 0.070 (0.087)\tData 0.000 (0.010)\tLoss 0.9111 (0.7784)\tPrec@1 60.938 (68.027)\n",
            "Epoch: [136][90/97], lr: 0.01000\tTime 0.055 (0.087)\tData 0.000 (0.009)\tLoss 0.8586 (0.7754)\tPrec@1 61.719 (68.158)\n",
            "Test: [0/100]\tTime 0.387 (0.387)\tLoss 0.9666 (0.9666)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.026 (0.066)\tLoss 0.9118 (0.9155)\tPrec@1 62.000 (62.273)\n",
            "Test: [20/100]\tTime 0.032 (0.050)\tLoss 1.0888 (0.9102)\tPrec@1 53.000 (62.095)\n",
            "Test: [30/100]\tTime 0.038 (0.044)\tLoss 0.9431 (0.9136)\tPrec@1 64.000 (61.839)\n",
            "Test: [40/100]\tTime 0.025 (0.041)\tLoss 0.8309 (0.9074)\tPrec@1 64.000 (62.000)\n",
            "Test: [50/100]\tTime 0.040 (0.039)\tLoss 1.0067 (0.9147)\tPrec@1 62.000 (61.824)\n",
            "Test: [60/100]\tTime 0.039 (0.038)\tLoss 1.1241 (0.9213)\tPrec@1 49.000 (61.738)\n",
            "Test: [70/100]\tTime 0.051 (0.037)\tLoss 0.8544 (0.9229)\tPrec@1 62.000 (61.803)\n",
            "Test: [80/100]\tTime 0.022 (0.036)\tLoss 0.8174 (0.9194)\tPrec@1 68.000 (61.951)\n",
            "Test: [90/100]\tTime 0.026 (0.036)\tLoss 1.1195 (0.9202)\tPrec@1 52.000 (61.659)\n",
            "val Results: Prec@1 61.840 Loss 0.91587\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [137][0/97], lr: 0.01000\tTime 0.546 (0.546)\tData 0.373 (0.373)\tLoss 0.7193 (0.7193)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [137][10/97], lr: 0.01000\tTime 0.077 (0.118)\tData 0.007 (0.039)\tLoss 0.8622 (0.7443)\tPrec@1 67.969 (70.597)\n",
            "Epoch: [137][20/97], lr: 0.01000\tTime 0.071 (0.097)\tData 0.002 (0.022)\tLoss 0.6878 (0.7679)\tPrec@1 69.531 (68.713)\n",
            "Epoch: [137][30/97], lr: 0.01000\tTime 0.068 (0.089)\tData 0.003 (0.016)\tLoss 0.8406 (0.7675)\tPrec@1 64.062 (68.674)\n",
            "Epoch: [137][40/97], lr: 0.01000\tTime 0.065 (0.085)\tData 0.001 (0.013)\tLoss 0.7775 (0.7674)\tPrec@1 67.188 (68.540)\n",
            "Epoch: [137][50/97], lr: 0.01000\tTime 0.080 (0.083)\tData 0.000 (0.011)\tLoss 0.7092 (0.7607)\tPrec@1 71.094 (68.873)\n",
            "Epoch: [137][60/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.009)\tLoss 0.7145 (0.7661)\tPrec@1 67.969 (68.327)\n",
            "Epoch: [137][70/97], lr: 0.01000\tTime 0.084 (0.080)\tData 0.007 (0.008)\tLoss 0.8535 (0.7748)\tPrec@1 60.938 (67.782)\n",
            "Epoch: [137][80/97], lr: 0.01000\tTime 0.062 (0.079)\tData 0.000 (0.008)\tLoss 0.7667 (0.7789)\tPrec@1 72.656 (67.631)\n",
            "Epoch: [137][90/97], lr: 0.01000\tTime 0.056 (0.078)\tData 0.000 (0.007)\tLoss 0.8618 (0.7762)\tPrec@1 60.938 (67.685)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.8941 (0.8941)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.029 (0.060)\tLoss 0.8806 (0.9074)\tPrec@1 67.000 (62.636)\n",
            "Test: [20/100]\tTime 0.023 (0.047)\tLoss 0.9933 (0.9200)\tPrec@1 59.000 (63.143)\n",
            "Test: [30/100]\tTime 0.037 (0.042)\tLoss 0.9113 (0.9265)\tPrec@1 58.000 (62.065)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 0.8826 (0.9257)\tPrec@1 69.000 (62.073)\n",
            "Test: [50/100]\tTime 0.024 (0.038)\tLoss 0.9196 (0.9220)\tPrec@1 64.000 (62.137)\n",
            "Test: [60/100]\tTime 0.035 (0.037)\tLoss 1.1308 (0.9263)\tPrec@1 53.000 (62.066)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 0.8572 (0.9214)\tPrec@1 64.000 (62.324)\n",
            "Test: [80/100]\tTime 0.028 (0.036)\tLoss 0.9950 (0.9201)\tPrec@1 59.000 (62.235)\n",
            "Test: [90/100]\tTime 0.032 (0.035)\tLoss 0.9698 (0.9191)\tPrec@1 62.000 (62.253)\n",
            "val Results: Prec@1 62.480 Loss 0.91439\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [138][0/97], lr: 0.01000\tTime 0.464 (0.464)\tData 0.333 (0.333)\tLoss 0.7512 (0.7512)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [138][10/97], lr: 0.01000\tTime 0.071 (0.115)\tData 0.000 (0.031)\tLoss 0.7313 (0.7253)\tPrec@1 69.531 (69.673)\n",
            "Epoch: [138][20/97], lr: 0.01000\tTime 0.061 (0.094)\tData 0.000 (0.018)\tLoss 0.7453 (0.7324)\tPrec@1 70.312 (69.866)\n",
            "Epoch: [138][30/97], lr: 0.01000\tTime 0.077 (0.087)\tData 0.000 (0.013)\tLoss 0.6465 (0.7441)\tPrec@1 71.875 (69.531)\n",
            "Epoch: [138][40/97], lr: 0.01000\tTime 0.084 (0.083)\tData 0.007 (0.011)\tLoss 0.8403 (0.7519)\tPrec@1 64.844 (68.864)\n",
            "Epoch: [138][50/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.004 (0.009)\tLoss 0.6763 (0.7516)\tPrec@1 72.656 (69.087)\n",
            "Epoch: [138][60/97], lr: 0.01000\tTime 0.093 (0.080)\tData 0.007 (0.008)\tLoss 0.7932 (0.7552)\tPrec@1 68.750 (69.006)\n",
            "Epoch: [138][70/97], lr: 0.01000\tTime 0.073 (0.078)\tData 0.010 (0.008)\tLoss 0.7976 (0.7545)\tPrec@1 68.750 (69.036)\n",
            "Epoch: [138][80/97], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.007)\tLoss 0.8426 (0.7609)\tPrec@1 64.062 (68.692)\n",
            "Epoch: [138][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.6566 (0.7607)\tPrec@1 74.219 (68.681)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 1.0427 (1.0427)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.031 (0.061)\tLoss 0.9239 (0.9045)\tPrec@1 58.000 (63.091)\n",
            "Test: [20/100]\tTime 0.040 (0.047)\tLoss 0.9806 (0.9053)\tPrec@1 64.000 (62.857)\n",
            "Test: [30/100]\tTime 0.028 (0.042)\tLoss 0.9073 (0.9107)\tPrec@1 66.000 (62.161)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.8823 (0.9136)\tPrec@1 64.000 (61.537)\n",
            "Test: [50/100]\tTime 0.036 (0.038)\tLoss 0.9100 (0.9102)\tPrec@1 67.000 (61.627)\n",
            "Test: [60/100]\tTime 0.031 (0.037)\tLoss 1.1122 (0.9161)\tPrec@1 54.000 (61.672)\n",
            "Test: [70/100]\tTime 0.044 (0.036)\tLoss 0.9053 (0.9175)\tPrec@1 64.000 (61.521)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 0.8771 (0.9133)\tPrec@1 61.000 (61.679)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 0.9776 (0.9144)\tPrec@1 57.000 (61.549)\n",
            "val Results: Prec@1 61.860 Loss 0.90870\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [139][0/97], lr: 0.01000\tTime 0.555 (0.555)\tData 0.391 (0.391)\tLoss 0.9038 (0.9038)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [139][10/97], lr: 0.01000\tTime 0.069 (0.115)\tData 0.002 (0.038)\tLoss 0.6620 (0.8069)\tPrec@1 75.781 (66.974)\n",
            "Epoch: [139][20/97], lr: 0.01000\tTime 0.069 (0.094)\tData 0.004 (0.021)\tLoss 0.7492 (0.7832)\tPrec@1 71.875 (68.080)\n",
            "Epoch: [139][30/97], lr: 0.01000\tTime 0.081 (0.086)\tData 0.000 (0.015)\tLoss 0.7978 (0.7674)\tPrec@1 66.406 (68.826)\n",
            "Epoch: [139][40/97], lr: 0.01000\tTime 0.080 (0.083)\tData 0.005 (0.012)\tLoss 0.8462 (0.7693)\tPrec@1 64.062 (68.483)\n",
            "Epoch: [139][50/97], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.010)\tLoss 0.7315 (0.7658)\tPrec@1 71.875 (68.903)\n",
            "Epoch: [139][60/97], lr: 0.01000\tTime 0.072 (0.079)\tData 0.007 (0.009)\tLoss 0.7144 (0.7647)\tPrec@1 71.875 (68.904)\n",
            "Epoch: [139][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.008)\tLoss 0.8143 (0.7719)\tPrec@1 67.188 (68.640)\n",
            "Epoch: [139][80/97], lr: 0.01000\tTime 0.077 (0.077)\tData 0.007 (0.008)\tLoss 0.8103 (0.7734)\tPrec@1 64.844 (68.432)\n",
            "Epoch: [139][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8001 (0.7735)\tPrec@1 66.406 (68.261)\n",
            "Test: [0/100]\tTime 0.353 (0.353)\tLoss 0.9332 (0.9332)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.025 (0.063)\tLoss 0.8791 (0.8831)\tPrec@1 58.000 (63.545)\n",
            "Test: [20/100]\tTime 0.032 (0.047)\tLoss 0.9933 (0.8946)\tPrec@1 59.000 (63.143)\n",
            "Test: [30/100]\tTime 0.055 (0.043)\tLoss 0.9030 (0.9071)\tPrec@1 65.000 (62.548)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.8955 (0.9010)\tPrec@1 65.000 (62.707)\n",
            "Test: [50/100]\tTime 0.029 (0.039)\tLoss 1.0561 (0.9056)\tPrec@1 54.000 (62.412)\n",
            "Test: [60/100]\tTime 0.022 (0.038)\tLoss 1.0107 (0.9148)\tPrec@1 54.000 (61.852)\n",
            "Test: [70/100]\tTime 0.043 (0.037)\tLoss 0.8730 (0.9156)\tPrec@1 65.000 (61.803)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 0.8572 (0.9120)\tPrec@1 62.000 (62.222)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 0.9887 (0.9124)\tPrec@1 58.000 (62.154)\n",
            "val Results: Prec@1 62.420 Loss 0.90733\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [140][0/97], lr: 0.01000\tTime 0.498 (0.498)\tData 0.309 (0.309)\tLoss 0.8193 (0.8193)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [140][10/97], lr: 0.01000\tTime 0.073 (0.117)\tData 0.001 (0.029)\tLoss 0.7922 (0.7714)\tPrec@1 65.625 (68.892)\n",
            "Epoch: [140][20/97], lr: 0.01000\tTime 0.073 (0.097)\tData 0.009 (0.017)\tLoss 0.6934 (0.7721)\tPrec@1 71.094 (68.155)\n",
            "Epoch: [140][30/97], lr: 0.01000\tTime 0.065 (0.088)\tData 0.005 (0.013)\tLoss 0.6175 (0.7636)\tPrec@1 75.000 (68.296)\n",
            "Epoch: [140][40/97], lr: 0.01000\tTime 0.080 (0.084)\tData 0.000 (0.010)\tLoss 0.7409 (0.7643)\tPrec@1 70.312 (68.636)\n",
            "Epoch: [140][50/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.008)\tLoss 0.8371 (0.7708)\tPrec@1 62.500 (68.459)\n",
            "Epoch: [140][60/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.007)\tLoss 0.8477 (0.7647)\tPrec@1 72.656 (68.840)\n",
            "Epoch: [140][70/97], lr: 0.01000\tTime 0.098 (0.079)\tData 0.010 (0.006)\tLoss 0.7567 (0.7679)\tPrec@1 67.188 (68.475)\n",
            "Epoch: [140][80/97], lr: 0.01000\tTime 0.080 (0.078)\tData 0.006 (0.006)\tLoss 0.7507 (0.7670)\tPrec@1 67.969 (68.461)\n",
            "Epoch: [140][90/97], lr: 0.01000\tTime 0.053 (0.077)\tData 0.000 (0.005)\tLoss 0.6910 (0.7686)\tPrec@1 71.094 (68.381)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 0.8766 (0.8766)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.8708 (0.8918)\tPrec@1 68.000 (64.818)\n",
            "Test: [20/100]\tTime 0.049 (0.047)\tLoss 0.9741 (0.8937)\tPrec@1 63.000 (64.000)\n",
            "Test: [30/100]\tTime 0.027 (0.042)\tLoss 0.8711 (0.9047)\tPrec@1 66.000 (63.000)\n",
            "Test: [40/100]\tTime 0.025 (0.039)\tLoss 0.9774 (0.9066)\tPrec@1 57.000 (62.756)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 0.9721 (0.9094)\tPrec@1 60.000 (62.373)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 0.9993 (0.9146)\tPrec@1 56.000 (62.508)\n",
            "Test: [70/100]\tTime 0.046 (0.036)\tLoss 0.9084 (0.9173)\tPrec@1 62.000 (62.070)\n",
            "Test: [80/100]\tTime 0.045 (0.036)\tLoss 0.7877 (0.9146)\tPrec@1 57.000 (62.198)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0142 (0.9129)\tPrec@1 62.000 (62.330)\n",
            "val Results: Prec@1 62.510 Loss 0.90952\n",
            "Best Prec@1: 63.030\n",
            "\n",
            "Epoch: [141][0/97], lr: 0.01000\tTime 0.561 (0.561)\tData 0.441 (0.441)\tLoss 0.6638 (0.6638)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [141][10/97], lr: 0.01000\tTime 0.072 (0.117)\tData 0.007 (0.043)\tLoss 0.7887 (0.7577)\tPrec@1 65.625 (68.466)\n",
            "Epoch: [141][20/97], lr: 0.01000\tTime 0.088 (0.094)\tData 0.012 (0.023)\tLoss 0.9233 (0.7630)\tPrec@1 64.062 (68.304)\n",
            "Epoch: [141][30/97], lr: 0.01000\tTime 0.078 (0.087)\tData 0.007 (0.017)\tLoss 0.6944 (0.7665)\tPrec@1 71.094 (68.624)\n",
            "Epoch: [141][40/97], lr: 0.01000\tTime 0.067 (0.083)\tData 0.000 (0.014)\tLoss 0.6959 (0.7658)\tPrec@1 74.219 (68.921)\n",
            "Epoch: [141][50/97], lr: 0.01000\tTime 0.057 (0.081)\tData 0.000 (0.012)\tLoss 0.8226 (0.7629)\tPrec@1 60.938 (69.041)\n",
            "Epoch: [141][60/97], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.010)\tLoss 0.8787 (0.7647)\tPrec@1 61.719 (68.801)\n",
            "Epoch: [141][70/97], lr: 0.01000\tTime 0.074 (0.078)\tData 0.005 (0.009)\tLoss 0.7500 (0.7646)\tPrec@1 71.875 (68.717)\n",
            "Epoch: [141][80/97], lr: 0.01000\tTime 0.060 (0.077)\tData 0.000 (0.008)\tLoss 0.8711 (0.7685)\tPrec@1 62.500 (68.557)\n",
            "Epoch: [141][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.008)\tLoss 0.7820 (0.7701)\tPrec@1 64.844 (68.450)\n",
            "Test: [0/100]\tTime 0.277 (0.277)\tLoss 0.8238 (0.8238)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 0.8772 (0.8786)\tPrec@1 69.000 (64.636)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 0.9010 (0.8729)\tPrec@1 63.000 (64.429)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.8987 (0.8838)\tPrec@1 65.000 (63.484)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 0.8503 (0.8829)\tPrec@1 63.000 (63.341)\n",
            "Test: [50/100]\tTime 0.042 (0.037)\tLoss 0.8716 (0.8834)\tPrec@1 65.000 (63.451)\n",
            "Test: [60/100]\tTime 0.047 (0.036)\tLoss 0.9967 (0.8893)\tPrec@1 57.000 (63.311)\n",
            "Test: [70/100]\tTime 0.054 (0.036)\tLoss 0.8932 (0.8909)\tPrec@1 62.000 (63.099)\n",
            "Test: [80/100]\tTime 0.039 (0.035)\tLoss 0.8458 (0.8911)\tPrec@1 63.000 (63.148)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9121 (0.8897)\tPrec@1 63.000 (63.242)\n",
            "val Results: Prec@1 63.530 Loss 0.88237\n",
            "Best Prec@1: 63.530\n",
            "\n",
            "Epoch: [142][0/97], lr: 0.01000\tTime 0.531 (0.531)\tData 0.394 (0.394)\tLoss 0.6839 (0.6839)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [142][10/97], lr: 0.01000\tTime 0.067 (0.121)\tData 0.003 (0.039)\tLoss 0.5949 (0.7378)\tPrec@1 80.469 (69.744)\n",
            "Epoch: [142][20/97], lr: 0.01000\tTime 0.081 (0.098)\tData 0.007 (0.022)\tLoss 0.7886 (0.7505)\tPrec@1 68.750 (69.494)\n",
            "Epoch: [142][30/97], lr: 0.01000\tTime 0.086 (0.090)\tData 0.007 (0.016)\tLoss 0.7204 (0.7573)\tPrec@1 71.094 (69.229)\n",
            "Epoch: [142][40/97], lr: 0.01000\tTime 0.081 (0.086)\tData 0.006 (0.014)\tLoss 0.7672 (0.7618)\tPrec@1 69.531 (68.750)\n",
            "Epoch: [142][50/97], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.012)\tLoss 0.7709 (0.7631)\tPrec@1 64.844 (68.765)\n",
            "Epoch: [142][60/97], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.010)\tLoss 0.7162 (0.7599)\tPrec@1 71.875 (68.801)\n",
            "Epoch: [142][70/97], lr: 0.01000\tTime 0.082 (0.080)\tData 0.011 (0.010)\tLoss 0.7001 (0.7605)\tPrec@1 73.438 (68.805)\n",
            "Epoch: [142][80/97], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.009)\tLoss 0.6321 (0.7632)\tPrec@1 78.125 (68.904)\n",
            "Epoch: [142][90/97], lr: 0.01000\tTime 0.057 (0.078)\tData 0.000 (0.008)\tLoss 0.8444 (0.7630)\tPrec@1 62.500 (68.913)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 0.8298 (0.8298)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.034 (0.060)\tLoss 0.9250 (0.8794)\tPrec@1 59.000 (63.091)\n",
            "Test: [20/100]\tTime 0.037 (0.045)\tLoss 0.9607 (0.8922)\tPrec@1 63.000 (62.190)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.8705 (0.8875)\tPrec@1 60.000 (62.194)\n",
            "Test: [40/100]\tTime 0.035 (0.039)\tLoss 0.8466 (0.8907)\tPrec@1 63.000 (61.927)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 0.9060 (0.8866)\tPrec@1 57.000 (62.255)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 0.9487 (0.8914)\tPrec@1 61.000 (62.213)\n",
            "Test: [70/100]\tTime 0.040 (0.036)\tLoss 0.7940 (0.8900)\tPrec@1 66.000 (62.282)\n",
            "Test: [80/100]\tTime 0.054 (0.035)\tLoss 0.9018 (0.8875)\tPrec@1 63.000 (62.580)\n",
            "Test: [90/100]\tTime 0.041 (0.035)\tLoss 0.9282 (0.8853)\tPrec@1 61.000 (62.637)\n",
            "val Results: Prec@1 63.210 Loss 0.87646\n",
            "Best Prec@1: 63.530\n",
            "\n",
            "Epoch: [143][0/97], lr: 0.01000\tTime 0.514 (0.514)\tData 0.326 (0.326)\tLoss 0.7454 (0.7454)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [143][10/97], lr: 0.01000\tTime 0.065 (0.115)\tData 0.000 (0.032)\tLoss 0.7451 (0.7330)\tPrec@1 68.750 (69.886)\n",
            "Epoch: [143][20/97], lr: 0.01000\tTime 0.067 (0.094)\tData 0.006 (0.019)\tLoss 0.7227 (0.7738)\tPrec@1 71.094 (67.820)\n",
            "Epoch: [143][30/97], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.014)\tLoss 0.7308 (0.7692)\tPrec@1 64.062 (67.717)\n",
            "Epoch: [143][40/97], lr: 0.01000\tTime 0.066 (0.083)\tData 0.000 (0.011)\tLoss 0.8561 (0.7692)\tPrec@1 67.188 (68.255)\n",
            "Epoch: [143][50/97], lr: 0.01000\tTime 0.071 (0.081)\tData 0.007 (0.009)\tLoss 0.5734 (0.7661)\tPrec@1 79.688 (68.413)\n",
            "Epoch: [143][60/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.007 (0.008)\tLoss 0.7372 (0.7647)\tPrec@1 70.312 (68.225)\n",
            "Epoch: [143][70/97], lr: 0.01000\tTime 0.064 (0.078)\tData 0.001 (0.008)\tLoss 0.6612 (0.7647)\tPrec@1 74.219 (68.321)\n",
            "Epoch: [143][80/97], lr: 0.01000\tTime 0.073 (0.077)\tData 0.006 (0.007)\tLoss 0.8583 (0.7631)\tPrec@1 66.406 (68.586)\n",
            "Epoch: [143][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.007)\tLoss 0.9318 (0.7661)\tPrec@1 62.500 (68.492)\n",
            "Test: [0/100]\tTime 0.274 (0.274)\tLoss 0.9416 (0.9416)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.023 (0.060)\tLoss 0.8163 (0.8750)\tPrec@1 68.000 (65.364)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 0.8815 (0.8714)\tPrec@1 66.000 (64.857)\n",
            "Test: [30/100]\tTime 0.039 (0.042)\tLoss 0.9018 (0.8792)\tPrec@1 66.000 (63.806)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.8329 (0.8785)\tPrec@1 66.000 (63.756)\n",
            "Test: [50/100]\tTime 0.040 (0.037)\tLoss 0.9230 (0.8751)\tPrec@1 62.000 (63.784)\n",
            "Test: [60/100]\tTime 0.043 (0.037)\tLoss 0.9882 (0.8811)\tPrec@1 58.000 (63.459)\n",
            "Test: [70/100]\tTime 0.059 (0.036)\tLoss 0.7851 (0.8815)\tPrec@1 70.000 (63.648)\n",
            "Test: [80/100]\tTime 0.030 (0.035)\tLoss 0.8210 (0.8785)\tPrec@1 68.000 (63.753)\n",
            "Test: [90/100]\tTime 0.034 (0.035)\tLoss 0.9305 (0.8790)\tPrec@1 60.000 (63.670)\n",
            "val Results: Prec@1 63.760 Loss 0.87386\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [144][0/97], lr: 0.01000\tTime 0.535 (0.535)\tData 0.424 (0.424)\tLoss 0.7561 (0.7561)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [144][10/97], lr: 0.01000\tTime 0.068 (0.116)\tData 0.000 (0.041)\tLoss 0.7581 (0.7453)\tPrec@1 68.750 (69.602)\n",
            "Epoch: [144][20/97], lr: 0.01000\tTime 0.064 (0.095)\tData 0.000 (0.023)\tLoss 0.8205 (0.7771)\tPrec@1 67.969 (68.378)\n",
            "Epoch: [144][30/97], lr: 0.01000\tTime 0.071 (0.088)\tData 0.007 (0.017)\tLoss 0.7913 (0.7685)\tPrec@1 64.844 (68.750)\n",
            "Epoch: [144][40/97], lr: 0.01000\tTime 0.089 (0.084)\tData 0.000 (0.014)\tLoss 0.9352 (0.7775)\tPrec@1 62.500 (68.464)\n",
            "Epoch: [144][50/97], lr: 0.01000\tTime 0.069 (0.081)\tData 0.005 (0.012)\tLoss 0.7476 (0.7719)\tPrec@1 71.094 (68.735)\n",
            "Epoch: [144][60/97], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.010)\tLoss 0.5623 (0.7661)\tPrec@1 78.906 (69.057)\n",
            "Epoch: [144][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.009)\tLoss 0.7346 (0.7586)\tPrec@1 74.219 (69.267)\n",
            "Epoch: [144][80/97], lr: 0.01000\tTime 0.065 (0.077)\tData 0.004 (0.008)\tLoss 0.7920 (0.7618)\tPrec@1 65.625 (69.039)\n",
            "Epoch: [144][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.008)\tLoss 0.7878 (0.7651)\tPrec@1 67.188 (68.698)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 0.8528 (0.8528)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.039 (0.062)\tLoss 0.8884 (0.8736)\tPrec@1 65.000 (64.091)\n",
            "Test: [20/100]\tTime 0.036 (0.047)\tLoss 0.9516 (0.8807)\tPrec@1 63.000 (63.714)\n",
            "Test: [30/100]\tTime 0.035 (0.043)\tLoss 0.9564 (0.8840)\tPrec@1 61.000 (63.290)\n",
            "Test: [40/100]\tTime 0.029 (0.040)\tLoss 0.8256 (0.8803)\tPrec@1 66.000 (63.317)\n",
            "Test: [50/100]\tTime 0.021 (0.038)\tLoss 0.9053 (0.8785)\tPrec@1 60.000 (63.412)\n",
            "Test: [60/100]\tTime 0.046 (0.038)\tLoss 0.9896 (0.8892)\tPrec@1 57.000 (62.803)\n",
            "Test: [70/100]\tTime 0.022 (0.037)\tLoss 0.7753 (0.8869)\tPrec@1 66.000 (62.859)\n",
            "Test: [80/100]\tTime 0.035 (0.036)\tLoss 0.7867 (0.8844)\tPrec@1 68.000 (63.000)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 0.9598 (0.8832)\tPrec@1 63.000 (62.912)\n",
            "val Results: Prec@1 63.110 Loss 0.87828\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [145][0/97], lr: 0.01000\tTime 0.536 (0.536)\tData 0.351 (0.351)\tLoss 0.7626 (0.7626)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [145][10/97], lr: 0.01000\tTime 0.061 (0.118)\tData 0.000 (0.035)\tLoss 0.7235 (0.7586)\tPrec@1 67.188 (67.543)\n",
            "Epoch: [145][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.019)\tLoss 0.7039 (0.7552)\tPrec@1 72.656 (68.824)\n",
            "Epoch: [145][30/97], lr: 0.01000\tTime 0.063 (0.087)\tData 0.000 (0.014)\tLoss 0.6378 (0.7507)\tPrec@1 76.562 (69.153)\n",
            "Epoch: [145][40/97], lr: 0.01000\tTime 0.067 (0.084)\tData 0.000 (0.011)\tLoss 0.8500 (0.7453)\tPrec@1 66.406 (69.245)\n",
            "Epoch: [145][50/97], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.009)\tLoss 0.7204 (0.7478)\tPrec@1 69.531 (69.118)\n",
            "Epoch: [145][60/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.007)\tLoss 0.7924 (0.7524)\tPrec@1 66.406 (69.057)\n",
            "Epoch: [145][70/97], lr: 0.01000\tTime 0.083 (0.079)\tData 0.008 (0.007)\tLoss 0.7501 (0.7598)\tPrec@1 73.438 (68.794)\n",
            "Epoch: [145][80/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.006)\tLoss 0.8519 (0.7638)\tPrec@1 64.844 (68.682)\n",
            "Epoch: [145][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.006)\tLoss 0.6896 (0.7642)\tPrec@1 75.000 (68.741)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.9588 (0.9588)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.029 (0.058)\tLoss 0.8394 (0.8724)\tPrec@1 67.000 (64.545)\n",
            "Test: [20/100]\tTime 0.038 (0.047)\tLoss 0.9841 (0.8793)\tPrec@1 63.000 (64.286)\n",
            "Test: [30/100]\tTime 0.032 (0.042)\tLoss 0.8998 (0.8816)\tPrec@1 61.000 (63.710)\n",
            "Test: [40/100]\tTime 0.024 (0.039)\tLoss 0.8474 (0.8799)\tPrec@1 64.000 (63.463)\n",
            "Test: [50/100]\tTime 0.029 (0.038)\tLoss 0.9677 (0.8842)\tPrec@1 57.000 (63.235)\n",
            "Test: [60/100]\tTime 0.054 (0.037)\tLoss 1.0481 (0.8879)\tPrec@1 53.000 (63.033)\n",
            "Test: [70/100]\tTime 0.050 (0.036)\tLoss 0.8666 (0.8889)\tPrec@1 66.000 (63.141)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 0.8471 (0.8877)\tPrec@1 65.000 (63.333)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 0.9057 (0.8855)\tPrec@1 65.000 (63.429)\n",
            "val Results: Prec@1 63.580 Loss 0.88034\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [146][0/97], lr: 0.01000\tTime 0.505 (0.505)\tData 0.282 (0.282)\tLoss 0.7542 (0.7542)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [146][10/97], lr: 0.01000\tTime 0.061 (0.114)\tData 0.000 (0.026)\tLoss 0.7779 (0.7879)\tPrec@1 68.750 (68.324)\n",
            "Epoch: [146][20/97], lr: 0.01000\tTime 0.068 (0.094)\tData 0.000 (0.015)\tLoss 0.6899 (0.7606)\tPrec@1 73.438 (69.234)\n",
            "Epoch: [146][30/97], lr: 0.01000\tTime 0.060 (0.086)\tData 0.000 (0.011)\tLoss 0.7653 (0.7670)\tPrec@1 61.719 (68.725)\n",
            "Epoch: [146][40/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.009)\tLoss 0.7381 (0.7613)\tPrec@1 73.438 (69.036)\n",
            "Epoch: [146][50/97], lr: 0.01000\tTime 0.073 (0.080)\tData 0.004 (0.008)\tLoss 0.6838 (0.7547)\tPrec@1 73.438 (69.256)\n",
            "Epoch: [146][60/97], lr: 0.01000\tTime 0.067 (0.079)\tData 0.005 (0.007)\tLoss 0.8209 (0.7520)\tPrec@1 61.719 (69.301)\n",
            "Epoch: [146][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.006)\tLoss 0.8320 (0.7530)\tPrec@1 63.281 (69.190)\n",
            "Epoch: [146][80/97], lr: 0.01000\tTime 0.062 (0.077)\tData 0.000 (0.006)\tLoss 0.7563 (0.7563)\tPrec@1 68.750 (69.097)\n",
            "Epoch: [146][90/97], lr: 0.01000\tTime 0.056 (0.076)\tData 0.000 (0.006)\tLoss 0.6684 (0.7607)\tPrec@1 72.656 (68.887)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 1.0007 (1.0007)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.051 (0.060)\tLoss 0.8757 (0.9443)\tPrec@1 62.000 (61.000)\n",
            "Test: [20/100]\tTime 0.044 (0.047)\tLoss 0.9948 (0.9521)\tPrec@1 61.000 (61.524)\n",
            "Test: [30/100]\tTime 0.038 (0.042)\tLoss 0.9156 (0.9660)\tPrec@1 61.000 (60.323)\n",
            "Test: [40/100]\tTime 0.025 (0.039)\tLoss 0.9493 (0.9666)\tPrec@1 66.000 (60.732)\n",
            "Test: [50/100]\tTime 0.030 (0.037)\tLoss 1.0499 (0.9643)\tPrec@1 56.000 (60.784)\n",
            "Test: [60/100]\tTime 0.026 (0.037)\tLoss 1.1308 (0.9679)\tPrec@1 59.000 (60.967)\n",
            "Test: [70/100]\tTime 0.036 (0.036)\tLoss 0.8940 (0.9616)\tPrec@1 62.000 (61.014)\n",
            "Test: [80/100]\tTime 0.039 (0.035)\tLoss 0.8019 (0.9577)\tPrec@1 69.000 (61.049)\n",
            "Test: [90/100]\tTime 0.037 (0.035)\tLoss 1.0879 (0.9585)\tPrec@1 58.000 (61.055)\n",
            "val Results: Prec@1 61.270 Loss 0.95298\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [147][0/97], lr: 0.01000\tTime 0.524 (0.524)\tData 0.319 (0.319)\tLoss 0.7381 (0.7381)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [147][10/97], lr: 0.01000\tTime 0.064 (0.114)\tData 0.000 (0.031)\tLoss 0.7216 (0.7477)\tPrec@1 67.188 (68.679)\n",
            "Epoch: [147][20/97], lr: 0.01000\tTime 0.063 (0.093)\tData 0.000 (0.018)\tLoss 0.7327 (0.7542)\tPrec@1 69.531 (68.676)\n",
            "Epoch: [147][30/97], lr: 0.01000\tTime 0.080 (0.086)\tData 0.009 (0.013)\tLoss 0.8701 (0.7471)\tPrec@1 67.188 (68.952)\n",
            "Epoch: [147][40/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.010)\tLoss 0.7134 (0.7578)\tPrec@1 67.969 (68.617)\n",
            "Epoch: [147][50/97], lr: 0.01000\tTime 0.060 (0.079)\tData 0.000 (0.009)\tLoss 0.7860 (0.7494)\tPrec@1 69.531 (69.455)\n",
            "Epoch: [147][60/97], lr: 0.01000\tTime 0.084 (0.078)\tData 0.007 (0.008)\tLoss 0.6861 (0.7504)\tPrec@1 71.094 (69.185)\n",
            "Epoch: [147][70/97], lr: 0.01000\tTime 0.072 (0.077)\tData 0.000 (0.007)\tLoss 0.7312 (0.7525)\tPrec@1 71.094 (68.959)\n",
            "Epoch: [147][80/97], lr: 0.01000\tTime 0.081 (0.077)\tData 0.007 (0.007)\tLoss 0.7582 (0.7497)\tPrec@1 70.312 (69.213)\n",
            "Epoch: [147][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.007)\tLoss 0.7054 (0.7477)\tPrec@1 73.438 (69.248)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 0.9737 (0.9737)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.042 (0.062)\tLoss 0.9041 (0.9194)\tPrec@1 62.000 (62.364)\n",
            "Test: [20/100]\tTime 0.027 (0.047)\tLoss 1.0227 (0.9137)\tPrec@1 55.000 (62.810)\n",
            "Test: [30/100]\tTime 0.021 (0.042)\tLoss 0.9548 (0.9334)\tPrec@1 64.000 (61.290)\n",
            "Test: [40/100]\tTime 0.042 (0.041)\tLoss 1.0530 (0.9348)\tPrec@1 54.000 (61.220)\n",
            "Test: [50/100]\tTime 0.040 (0.038)\tLoss 1.0222 (0.9416)\tPrec@1 60.000 (61.255)\n",
            "Test: [60/100]\tTime 0.051 (0.037)\tLoss 1.2133 (0.9514)\tPrec@1 52.000 (60.869)\n",
            "Test: [70/100]\tTime 0.022 (0.038)\tLoss 0.8957 (0.9471)\tPrec@1 63.000 (61.014)\n",
            "Test: [80/100]\tTime 0.022 (0.038)\tLoss 0.9436 (0.9455)\tPrec@1 64.000 (61.148)\n",
            "Test: [90/100]\tTime 0.026 (0.038)\tLoss 1.0279 (0.9465)\tPrec@1 58.000 (61.055)\n",
            "val Results: Prec@1 61.270 Loss 0.94222\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [148][0/97], lr: 0.01000\tTime 0.436 (0.436)\tData 0.297 (0.297)\tLoss 0.7253 (0.7253)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [148][10/97], lr: 0.01000\tTime 0.072 (0.119)\tData 0.011 (0.033)\tLoss 0.6698 (0.7570)\tPrec@1 72.656 (68.821)\n",
            "Epoch: [148][20/97], lr: 0.01000\tTime 0.120 (0.099)\tData 0.001 (0.019)\tLoss 0.6904 (0.7559)\tPrec@1 71.094 (69.048)\n",
            "Epoch: [148][30/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.014)\tLoss 0.7087 (0.7633)\tPrec@1 72.656 (69.178)\n",
            "Epoch: [148][40/97], lr: 0.01000\tTime 0.087 (0.094)\tData 0.000 (0.012)\tLoss 0.8007 (0.7559)\tPrec@1 68.750 (69.245)\n",
            "Epoch: [148][50/97], lr: 0.01000\tTime 0.064 (0.091)\tData 0.000 (0.010)\tLoss 0.7839 (0.7489)\tPrec@1 67.969 (69.470)\n",
            "Epoch: [148][60/97], lr: 0.01000\tTime 0.087 (0.089)\tData 0.001 (0.009)\tLoss 0.7424 (0.7491)\tPrec@1 71.094 (69.634)\n",
            "Epoch: [148][70/97], lr: 0.01000\tTime 0.067 (0.088)\tData 0.000 (0.008)\tLoss 0.7322 (0.7524)\tPrec@1 70.312 (69.377)\n",
            "Epoch: [148][80/97], lr: 0.01000\tTime 0.060 (0.085)\tData 0.000 (0.007)\tLoss 0.8225 (0.7499)\tPrec@1 67.969 (69.618)\n",
            "Epoch: [148][90/97], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.007)\tLoss 0.6558 (0.7466)\tPrec@1 75.781 (69.772)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 0.8507 (0.8507)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.047 (0.074)\tLoss 0.9669 (0.8964)\tPrec@1 63.000 (64.455)\n",
            "Test: [20/100]\tTime 0.024 (0.055)\tLoss 0.9409 (0.8953)\tPrec@1 66.000 (64.000)\n",
            "Test: [30/100]\tTime 0.031 (0.049)\tLoss 0.9814 (0.9125)\tPrec@1 64.000 (62.548)\n",
            "Test: [40/100]\tTime 0.031 (0.046)\tLoss 0.8645 (0.9127)\tPrec@1 65.000 (62.634)\n",
            "Test: [50/100]\tTime 0.042 (0.043)\tLoss 0.8783 (0.9109)\tPrec@1 64.000 (62.529)\n",
            "Test: [60/100]\tTime 0.022 (0.042)\tLoss 1.0224 (0.9218)\tPrec@1 56.000 (61.984)\n",
            "Test: [70/100]\tTime 0.035 (0.041)\tLoss 0.7869 (0.9186)\tPrec@1 69.000 (62.113)\n",
            "Test: [80/100]\tTime 0.040 (0.040)\tLoss 0.7994 (0.9196)\tPrec@1 66.000 (62.123)\n",
            "Test: [90/100]\tTime 0.036 (0.040)\tLoss 0.9948 (0.9191)\tPrec@1 59.000 (62.198)\n",
            "val Results: Prec@1 62.550 Loss 0.91330\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [149][0/97], lr: 0.01000\tTime 0.509 (0.509)\tData 0.336 (0.336)\tLoss 0.7865 (0.7865)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [149][10/97], lr: 0.01000\tTime 0.078 (0.117)\tData 0.000 (0.034)\tLoss 0.7583 (0.7752)\tPrec@1 67.969 (67.614)\n",
            "Epoch: [149][20/97], lr: 0.01000\tTime 0.063 (0.104)\tData 0.000 (0.018)\tLoss 0.7314 (0.7671)\tPrec@1 69.531 (68.006)\n",
            "Epoch: [149][30/97], lr: 0.01000\tTime 0.097 (0.098)\tData 0.007 (0.013)\tLoss 0.7523 (0.7505)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [149][40/97], lr: 0.01000\tTime 0.096 (0.094)\tData 0.000 (0.011)\tLoss 0.7212 (0.7570)\tPrec@1 70.312 (68.864)\n",
            "Epoch: [149][50/97], lr: 0.01000\tTime 0.110 (0.093)\tData 0.000 (0.009)\tLoss 0.8180 (0.7549)\tPrec@1 64.844 (69.072)\n",
            "Epoch: [149][60/97], lr: 0.01000\tTime 0.114 (0.093)\tData 0.000 (0.008)\tLoss 0.6745 (0.7508)\tPrec@1 74.219 (69.096)\n",
            "Epoch: [149][70/97], lr: 0.01000\tTime 0.118 (0.095)\tData 0.011 (0.008)\tLoss 0.7709 (0.7503)\tPrec@1 75.000 (69.278)\n",
            "Epoch: [149][80/97], lr: 0.01000\tTime 0.143 (0.097)\tData 0.009 (0.007)\tLoss 0.7698 (0.7549)\tPrec@1 64.844 (69.117)\n",
            "Epoch: [149][90/97], lr: 0.01000\tTime 0.064 (0.097)\tData 0.000 (0.007)\tLoss 0.8812 (0.7514)\tPrec@1 60.938 (69.093)\n",
            "Test: [0/100]\tTime 0.293 (0.293)\tLoss 0.9389 (0.9389)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.035 (0.075)\tLoss 0.8721 (0.9480)\tPrec@1 63.000 (62.273)\n",
            "Test: [20/100]\tTime 0.030 (0.056)\tLoss 1.0370 (0.9412)\tPrec@1 59.000 (62.476)\n",
            "Test: [30/100]\tTime 0.050 (0.051)\tLoss 1.0017 (0.9663)\tPrec@1 63.000 (61.097)\n",
            "Test: [40/100]\tTime 0.052 (0.048)\tLoss 0.9915 (0.9716)\tPrec@1 64.000 (61.073)\n",
            "Test: [50/100]\tTime 0.074 (0.046)\tLoss 1.1201 (0.9742)\tPrec@1 55.000 (60.627)\n",
            "Test: [60/100]\tTime 0.054 (0.045)\tLoss 1.1996 (0.9806)\tPrec@1 48.000 (60.557)\n",
            "Test: [70/100]\tTime 0.035 (0.043)\tLoss 0.8088 (0.9722)\tPrec@1 70.000 (60.873)\n",
            "Test: [80/100]\tTime 0.029 (0.043)\tLoss 0.8980 (0.9684)\tPrec@1 62.000 (61.037)\n",
            "Test: [90/100]\tTime 0.023 (0.041)\tLoss 1.1512 (0.9709)\tPrec@1 58.000 (61.000)\n",
            "val Results: Prec@1 61.390 Loss 0.96258\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [150][0/97], lr: 0.01000\tTime 0.544 (0.544)\tData 0.385 (0.385)\tLoss 0.8092 (0.8092)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [150][10/97], lr: 0.01000\tTime 0.089 (0.114)\tData 0.007 (0.036)\tLoss 0.7441 (0.7551)\tPrec@1 69.531 (70.170)\n",
            "Epoch: [150][20/97], lr: 0.01000\tTime 0.061 (0.094)\tData 0.000 (0.020)\tLoss 0.7109 (0.7365)\tPrec@1 70.312 (70.089)\n",
            "Epoch: [150][30/97], lr: 0.01000\tTime 0.093 (0.088)\tData 0.000 (0.014)\tLoss 0.7061 (0.7496)\tPrec@1 71.875 (69.355)\n",
            "Epoch: [150][40/97], lr: 0.01000\tTime 0.084 (0.084)\tData 0.000 (0.011)\tLoss 0.7678 (0.7588)\tPrec@1 66.406 (68.769)\n",
            "Epoch: [150][50/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.009)\tLoss 0.6280 (0.7593)\tPrec@1 76.562 (68.964)\n",
            "Epoch: [150][60/97], lr: 0.01000\tTime 0.085 (0.080)\tData 0.006 (0.008)\tLoss 0.6505 (0.7612)\tPrec@1 75.000 (68.865)\n",
            "Epoch: [150][70/97], lr: 0.01000\tTime 0.071 (0.079)\tData 0.007 (0.008)\tLoss 0.6232 (0.7576)\tPrec@1 76.562 (68.948)\n",
            "Epoch: [150][80/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.006 (0.007)\tLoss 0.7527 (0.7571)\tPrec@1 66.406 (68.981)\n",
            "Epoch: [150][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.9294 (0.7556)\tPrec@1 60.938 (69.050)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 0.9008 (0.9008)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.028 (0.060)\tLoss 0.8161 (0.8742)\tPrec@1 64.000 (65.636)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.9841 (0.8741)\tPrec@1 62.000 (64.762)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.8901 (0.8822)\tPrec@1 64.000 (63.774)\n",
            "Test: [40/100]\tTime 0.041 (0.039)\tLoss 0.9762 (0.8769)\tPrec@1 60.000 (63.829)\n",
            "Test: [50/100]\tTime 0.022 (0.036)\tLoss 0.9460 (0.8804)\tPrec@1 63.000 (63.549)\n",
            "Test: [60/100]\tTime 0.030 (0.036)\tLoss 1.0221 (0.8912)\tPrec@1 58.000 (63.246)\n",
            "Test: [70/100]\tTime 0.036 (0.035)\tLoss 0.8439 (0.8926)\tPrec@1 69.000 (63.324)\n",
            "Test: [80/100]\tTime 0.033 (0.035)\tLoss 0.8500 (0.8877)\tPrec@1 63.000 (63.494)\n",
            "Test: [90/100]\tTime 0.030 (0.035)\tLoss 0.9996 (0.8904)\tPrec@1 62.000 (63.374)\n",
            "val Results: Prec@1 63.650 Loss 0.88474\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [151][0/97], lr: 0.01000\tTime 0.450 (0.450)\tData 0.272 (0.272)\tLoss 0.8028 (0.8028)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [151][10/97], lr: 0.01000\tTime 0.071 (0.117)\tData 0.007 (0.031)\tLoss 0.7216 (0.7435)\tPrec@1 68.750 (70.099)\n",
            "Epoch: [151][20/97], lr: 0.01000\tTime 0.097 (0.094)\tData 0.006 (0.018)\tLoss 0.8100 (0.7355)\tPrec@1 69.531 (70.499)\n",
            "Epoch: [151][30/97], lr: 0.01000\tTime 0.066 (0.087)\tData 0.000 (0.013)\tLoss 0.8192 (0.7327)\tPrec@1 67.188 (70.439)\n",
            "Epoch: [151][40/97], lr: 0.01000\tTime 0.080 (0.083)\tData 0.001 (0.010)\tLoss 0.8104 (0.7436)\tPrec@1 61.719 (69.779)\n",
            "Epoch: [151][50/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.000 (0.009)\tLoss 0.6958 (0.7445)\tPrec@1 75.000 (69.868)\n",
            "Epoch: [151][60/97], lr: 0.01000\tTime 0.062 (0.079)\tData 0.000 (0.008)\tLoss 0.7026 (0.7417)\tPrec@1 67.188 (69.928)\n",
            "Epoch: [151][70/97], lr: 0.01000\tTime 0.075 (0.078)\tData 0.006 (0.008)\tLoss 0.7364 (0.7417)\tPrec@1 71.875 (69.905)\n",
            "Epoch: [151][80/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.007)\tLoss 0.7489 (0.7479)\tPrec@1 69.531 (69.695)\n",
            "Epoch: [151][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8537 (0.7506)\tPrec@1 63.281 (69.720)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 0.9167 (0.9167)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.034 (0.060)\tLoss 0.8749 (0.8832)\tPrec@1 62.000 (62.182)\n",
            "Test: [20/100]\tTime 0.041 (0.046)\tLoss 0.9907 (0.8866)\tPrec@1 58.000 (62.952)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9625 (0.8853)\tPrec@1 59.000 (62.968)\n",
            "Test: [40/100]\tTime 0.046 (0.039)\tLoss 0.9255 (0.8942)\tPrec@1 59.000 (62.341)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.9767 (0.8938)\tPrec@1 60.000 (62.451)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 1.1210 (0.9018)\tPrec@1 56.000 (62.541)\n",
            "Test: [70/100]\tTime 0.026 (0.036)\tLoss 0.8153 (0.8985)\tPrec@1 65.000 (62.718)\n",
            "Test: [80/100]\tTime 0.031 (0.036)\tLoss 0.8904 (0.8964)\tPrec@1 59.000 (62.852)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0174 (0.9002)\tPrec@1 54.000 (62.451)\n",
            "val Results: Prec@1 62.790 Loss 0.89297\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [152][0/97], lr: 0.01000\tTime 0.545 (0.545)\tData 0.378 (0.378)\tLoss 0.7016 (0.7016)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [152][10/97], lr: 0.01000\tTime 0.063 (0.116)\tData 0.000 (0.036)\tLoss 0.7315 (0.7405)\tPrec@1 71.094 (69.460)\n",
            "Epoch: [152][20/97], lr: 0.01000\tTime 0.089 (0.096)\tData 0.007 (0.021)\tLoss 0.7174 (0.7543)\tPrec@1 72.656 (68.787)\n",
            "Epoch: [152][30/97], lr: 0.01000\tTime 0.063 (0.087)\tData 0.000 (0.014)\tLoss 0.9377 (0.7558)\tPrec@1 62.500 (68.826)\n",
            "Epoch: [152][40/97], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.011)\tLoss 0.6416 (0.7436)\tPrec@1 69.531 (69.055)\n",
            "Epoch: [152][50/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.010)\tLoss 0.9061 (0.7515)\tPrec@1 60.938 (68.842)\n",
            "Epoch: [152][60/97], lr: 0.01000\tTime 0.103 (0.079)\tData 0.000 (0.008)\tLoss 0.7201 (0.7495)\tPrec@1 70.312 (69.070)\n",
            "Epoch: [152][70/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 0.7471 (0.7518)\tPrec@1 68.750 (68.970)\n",
            "Epoch: [152][80/97], lr: 0.01000\tTime 0.062 (0.077)\tData 0.000 (0.006)\tLoss 0.7608 (0.7520)\tPrec@1 68.750 (69.010)\n",
            "Epoch: [152][90/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.000 (0.006)\tLoss 0.8123 (0.7527)\tPrec@1 65.625 (69.128)\n",
            "Test: [0/100]\tTime 0.333 (0.333)\tLoss 0.9397 (0.9397)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.041 (0.061)\tLoss 0.8714 (0.8770)\tPrec@1 67.000 (64.091)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 0.9762 (0.8832)\tPrec@1 59.000 (63.476)\n",
            "Test: [30/100]\tTime 0.028 (0.042)\tLoss 0.9331 (0.8987)\tPrec@1 60.000 (62.387)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 1.0146 (0.9006)\tPrec@1 60.000 (62.171)\n",
            "Test: [50/100]\tTime 0.025 (0.038)\tLoss 0.8731 (0.9020)\tPrec@1 67.000 (62.235)\n",
            "Test: [60/100]\tTime 0.020 (0.037)\tLoss 0.9570 (0.9044)\tPrec@1 58.000 (62.262)\n",
            "Test: [70/100]\tTime 0.033 (0.036)\tLoss 0.9305 (0.9015)\tPrec@1 62.000 (62.310)\n",
            "Test: [80/100]\tTime 0.029 (0.036)\tLoss 0.8367 (0.8981)\tPrec@1 67.000 (62.667)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.0295 (0.8989)\tPrec@1 60.000 (62.703)\n",
            "val Results: Prec@1 62.820 Loss 0.89395\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [153][0/97], lr: 0.01000\tTime 0.538 (0.538)\tData 0.372 (0.372)\tLoss 0.6638 (0.6638)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [153][10/97], lr: 0.01000\tTime 0.063 (0.115)\tData 0.000 (0.036)\tLoss 0.7607 (0.7456)\tPrec@1 70.312 (71.094)\n",
            "Epoch: [153][20/97], lr: 0.01000\tTime 0.061 (0.094)\tData 0.000 (0.020)\tLoss 0.7791 (0.7519)\tPrec@1 67.188 (69.978)\n",
            "Epoch: [153][30/97], lr: 0.01000\tTime 0.064 (0.087)\tData 0.000 (0.015)\tLoss 0.7794 (0.7506)\tPrec@1 64.844 (69.934)\n",
            "Epoch: [153][40/97], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.012)\tLoss 0.7316 (0.7510)\tPrec@1 68.750 (69.550)\n",
            "Epoch: [153][50/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.010)\tLoss 0.6849 (0.7504)\tPrec@1 75.000 (69.501)\n",
            "Epoch: [153][60/97], lr: 0.01000\tTime 0.077 (0.079)\tData 0.006 (0.009)\tLoss 0.7260 (0.7472)\tPrec@1 68.750 (69.621)\n",
            "Epoch: [153][70/97], lr: 0.01000\tTime 0.069 (0.078)\tData 0.004 (0.008)\tLoss 0.7719 (0.7473)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [153][80/97], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.008)\tLoss 0.7006 (0.7471)\tPrec@1 70.312 (69.338)\n",
            "Epoch: [153][90/97], lr: 0.01000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.6997 (0.7494)\tPrec@1 71.094 (69.239)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 0.8893 (0.8893)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.8842 (0.8773)\tPrec@1 63.000 (63.000)\n",
            "Test: [20/100]\tTime 0.025 (0.046)\tLoss 0.9123 (0.8779)\tPrec@1 64.000 (63.381)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 0.8684 (0.8819)\tPrec@1 63.000 (63.161)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.8467 (0.8829)\tPrec@1 62.000 (62.756)\n",
            "Test: [50/100]\tTime 0.045 (0.037)\tLoss 1.0090 (0.8861)\tPrec@1 61.000 (62.608)\n",
            "Test: [60/100]\tTime 0.047 (0.036)\tLoss 1.0102 (0.8911)\tPrec@1 58.000 (62.721)\n",
            "Test: [70/100]\tTime 0.025 (0.035)\tLoss 0.8494 (0.8896)\tPrec@1 66.000 (62.662)\n",
            "Test: [80/100]\tTime 0.030 (0.035)\tLoss 0.8071 (0.8870)\tPrec@1 67.000 (62.753)\n",
            "Test: [90/100]\tTime 0.046 (0.034)\tLoss 0.9722 (0.8876)\tPrec@1 61.000 (62.824)\n",
            "val Results: Prec@1 63.160 Loss 0.88108\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [154][0/97], lr: 0.01000\tTime 0.529 (0.529)\tData 0.402 (0.402)\tLoss 0.7652 (0.7652)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [154][10/97], lr: 0.01000\tTime 0.067 (0.113)\tData 0.000 (0.039)\tLoss 0.7324 (0.7725)\tPrec@1 67.188 (67.614)\n",
            "Epoch: [154][20/97], lr: 0.01000\tTime 0.074 (0.092)\tData 0.000 (0.021)\tLoss 0.6219 (0.7353)\tPrec@1 76.562 (70.052)\n",
            "Epoch: [154][30/97], lr: 0.01000\tTime 0.091 (0.085)\tData 0.007 (0.015)\tLoss 0.8688 (0.7504)\tPrec@1 65.625 (69.506)\n",
            "Epoch: [154][40/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.012)\tLoss 0.6635 (0.7489)\tPrec@1 76.562 (69.417)\n",
            "Epoch: [154][50/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.010)\tLoss 0.8110 (0.7479)\tPrec@1 64.844 (69.470)\n",
            "Epoch: [154][60/97], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.009)\tLoss 0.6646 (0.7445)\tPrec@1 70.312 (69.647)\n",
            "Epoch: [154][70/97], lr: 0.01000\tTime 0.073 (0.077)\tData 0.001 (0.008)\tLoss 0.7186 (0.7443)\tPrec@1 71.875 (69.773)\n",
            "Epoch: [154][80/97], lr: 0.01000\tTime 0.068 (0.077)\tData 0.007 (0.008)\tLoss 0.6916 (0.7466)\tPrec@1 73.438 (69.743)\n",
            "Epoch: [154][90/97], lr: 0.01000\tTime 0.056 (0.075)\tData 0.000 (0.007)\tLoss 0.7637 (0.7474)\tPrec@1 62.500 (69.514)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 0.9266 (0.9266)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.049 (0.060)\tLoss 0.9028 (0.9090)\tPrec@1 64.000 (62.818)\n",
            "Test: [20/100]\tTime 0.020 (0.045)\tLoss 1.1399 (0.9308)\tPrec@1 54.000 (62.190)\n",
            "Test: [30/100]\tTime 0.041 (0.041)\tLoss 0.9307 (0.9370)\tPrec@1 60.000 (61.839)\n",
            "Test: [40/100]\tTime 0.037 (0.039)\tLoss 0.8798 (0.9385)\tPrec@1 66.000 (61.854)\n",
            "Test: [50/100]\tTime 0.024 (0.037)\tLoss 0.9261 (0.9353)\tPrec@1 62.000 (61.667)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 1.0213 (0.9373)\tPrec@1 55.000 (61.328)\n",
            "Test: [70/100]\tTime 0.044 (0.036)\tLoss 0.8685 (0.9397)\tPrec@1 63.000 (61.211)\n",
            "Test: [80/100]\tTime 0.031 (0.035)\tLoss 0.8872 (0.9395)\tPrec@1 62.000 (61.235)\n",
            "Test: [90/100]\tTime 0.022 (0.034)\tLoss 1.0584 (0.9400)\tPrec@1 57.000 (61.154)\n",
            "val Results: Prec@1 61.440 Loss 0.93322\n",
            "Best Prec@1: 63.760\n",
            "\n",
            "Epoch: [155][0/97], lr: 0.01000\tTime 0.535 (0.535)\tData 0.305 (0.305)\tLoss 0.8562 (0.8562)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [155][10/97], lr: 0.01000\tTime 0.076 (0.122)\tData 0.011 (0.031)\tLoss 0.7143 (0.7666)\tPrec@1 74.219 (68.253)\n",
            "Epoch: [155][20/97], lr: 0.01000\tTime 0.062 (0.097)\tData 0.000 (0.017)\tLoss 0.6988 (0.7514)\tPrec@1 67.969 (68.601)\n",
            "Epoch: [155][30/97], lr: 0.01000\tTime 0.107 (0.089)\tData 0.000 (0.012)\tLoss 0.7932 (0.7500)\tPrec@1 71.094 (68.851)\n",
            "Epoch: [155][40/97], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.010)\tLoss 0.6520 (0.7473)\tPrec@1 72.656 (69.036)\n",
            "Epoch: [155][50/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.008)\tLoss 0.7441 (0.7526)\tPrec@1 67.969 (69.118)\n",
            "Epoch: [155][60/97], lr: 0.01000\tTime 0.082 (0.080)\tData 0.000 (0.007)\tLoss 0.7566 (0.7515)\tPrec@1 68.750 (69.032)\n",
            "Epoch: [155][70/97], lr: 0.01000\tTime 0.073 (0.079)\tData 0.000 (0.006)\tLoss 0.7349 (0.7473)\tPrec@1 68.750 (69.113)\n",
            "Epoch: [155][80/97], lr: 0.01000\tTime 0.072 (0.078)\tData 0.007 (0.006)\tLoss 0.7531 (0.7473)\tPrec@1 67.969 (69.001)\n",
            "Epoch: [155][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.005)\tLoss 0.5845 (0.7486)\tPrec@1 80.469 (69.050)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 0.9968 (0.9968)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.021 (0.056)\tLoss 0.8395 (0.8825)\tPrec@1 62.000 (64.455)\n",
            "Test: [20/100]\tTime 0.032 (0.046)\tLoss 0.9540 (0.8779)\tPrec@1 62.000 (65.048)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.8473 (0.8816)\tPrec@1 67.000 (63.839)\n",
            "Test: [40/100]\tTime 0.046 (0.039)\tLoss 0.8533 (0.8831)\tPrec@1 64.000 (63.366)\n",
            "Test: [50/100]\tTime 0.027 (0.037)\tLoss 0.9696 (0.8783)\tPrec@1 60.000 (63.784)\n",
            "Test: [60/100]\tTime 0.039 (0.036)\tLoss 0.9714 (0.8837)\tPrec@1 59.000 (63.672)\n",
            "Test: [70/100]\tTime 0.034 (0.035)\tLoss 0.7638 (0.8812)\tPrec@1 73.000 (63.972)\n",
            "Test: [80/100]\tTime 0.041 (0.035)\tLoss 0.8386 (0.8782)\tPrec@1 67.000 (64.210)\n",
            "Test: [90/100]\tTime 0.039 (0.034)\tLoss 0.8445 (0.8790)\tPrec@1 68.000 (64.165)\n",
            "val Results: Prec@1 64.380 Loss 0.87276\n",
            "Best Prec@1: 64.380\n",
            "\n",
            "Epoch: [156][0/97], lr: 0.01000\tTime 0.510 (0.510)\tData 0.319 (0.319)\tLoss 0.6595 (0.6595)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [156][10/97], lr: 0.01000\tTime 0.067 (0.119)\tData 0.007 (0.033)\tLoss 0.7327 (0.7075)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [156][20/97], lr: 0.01000\tTime 0.070 (0.096)\tData 0.010 (0.018)\tLoss 0.7276 (0.7158)\tPrec@1 68.750 (71.131)\n",
            "Epoch: [156][30/97], lr: 0.01000\tTime 0.061 (0.088)\tData 0.000 (0.013)\tLoss 0.6685 (0.7253)\tPrec@1 74.219 (70.741)\n",
            "Epoch: [156][40/97], lr: 0.01000\tTime 0.063 (0.084)\tData 0.003 (0.011)\tLoss 0.8499 (0.7320)\tPrec@1 68.750 (70.560)\n",
            "Epoch: [156][50/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.009)\tLoss 0.7054 (0.7330)\tPrec@1 72.656 (70.604)\n",
            "Epoch: [156][60/97], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.008)\tLoss 0.5932 (0.7342)\tPrec@1 80.469 (70.492)\n",
            "Epoch: [156][70/97], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.008)\tLoss 0.8037 (0.7325)\tPrec@1 71.094 (70.665)\n",
            "Epoch: [156][80/97], lr: 0.01000\tTime 0.063 (0.078)\tData 0.001 (0.007)\tLoss 0.8138 (0.7385)\tPrec@1 66.406 (70.158)\n",
            "Epoch: [156][90/97], lr: 0.01000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.6929 (0.7378)\tPrec@1 72.656 (70.218)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 0.9432 (0.9432)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.050 (0.061)\tLoss 0.7878 (0.8674)\tPrec@1 78.000 (64.273)\n",
            "Test: [20/100]\tTime 0.024 (0.046)\tLoss 0.8518 (0.8633)\tPrec@1 65.000 (64.238)\n",
            "Test: [30/100]\tTime 0.030 (0.042)\tLoss 0.8886 (0.8707)\tPrec@1 66.000 (64.161)\n",
            "Test: [40/100]\tTime 0.022 (0.040)\tLoss 0.8303 (0.8733)\tPrec@1 68.000 (63.902)\n",
            "Test: [50/100]\tTime 0.026 (0.038)\tLoss 0.9159 (0.8705)\tPrec@1 57.000 (64.059)\n",
            "Test: [60/100]\tTime 0.042 (0.037)\tLoss 1.0480 (0.8762)\tPrec@1 61.000 (63.984)\n",
            "Test: [70/100]\tTime 0.021 (0.036)\tLoss 0.7815 (0.8750)\tPrec@1 68.000 (64.000)\n",
            "Test: [80/100]\tTime 0.037 (0.036)\tLoss 0.8160 (0.8734)\tPrec@1 63.000 (64.099)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 1.0369 (0.8752)\tPrec@1 58.000 (63.956)\n",
            "val Results: Prec@1 64.020 Loss 0.87082\n",
            "Best Prec@1: 64.380\n",
            "\n",
            "Epoch: [157][0/97], lr: 0.01000\tTime 0.487 (0.487)\tData 0.311 (0.311)\tLoss 0.8780 (0.8780)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [157][10/97], lr: 0.01000\tTime 0.075 (0.115)\tData 0.000 (0.030)\tLoss 0.7660 (0.7526)\tPrec@1 69.531 (69.318)\n",
            "Epoch: [157][20/97], lr: 0.01000\tTime 0.066 (0.094)\tData 0.002 (0.018)\tLoss 0.6781 (0.7571)\tPrec@1 73.438 (68.341)\n",
            "Epoch: [157][30/97], lr: 0.01000\tTime 0.086 (0.087)\tData 0.000 (0.012)\tLoss 0.7166 (0.7425)\tPrec@1 70.312 (68.926)\n",
            "Epoch: [157][40/97], lr: 0.01000\tTime 0.069 (0.084)\tData 0.000 (0.010)\tLoss 0.7715 (0.7425)\tPrec@1 64.062 (69.093)\n",
            "Epoch: [157][50/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.008)\tLoss 0.5931 (0.7307)\tPrec@1 76.562 (69.531)\n",
            "Epoch: [157][60/97], lr: 0.01000\tTime 0.086 (0.080)\tData 0.005 (0.007)\tLoss 0.6568 (0.7339)\tPrec@1 75.000 (69.429)\n",
            "Epoch: [157][70/97], lr: 0.01000\tTime 0.069 (0.079)\tData 0.000 (0.007)\tLoss 0.7075 (0.7360)\tPrec@1 71.094 (69.454)\n",
            "Epoch: [157][80/97], lr: 0.01000\tTime 0.079 (0.078)\tData 0.007 (0.006)\tLoss 0.7144 (0.7413)\tPrec@1 73.438 (69.396)\n",
            "Epoch: [157][90/97], lr: 0.01000\tTime 0.055 (0.077)\tData 0.000 (0.006)\tLoss 0.7009 (0.7404)\tPrec@1 72.656 (69.497)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 0.8159 (0.8159)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.022 (0.061)\tLoss 0.8984 (0.8735)\tPrec@1 65.000 (63.818)\n",
            "Test: [20/100]\tTime 0.036 (0.047)\tLoss 0.9300 (0.8694)\tPrec@1 62.000 (64.381)\n",
            "Test: [30/100]\tTime 0.024 (0.043)\tLoss 0.8512 (0.8844)\tPrec@1 64.000 (63.323)\n",
            "Test: [40/100]\tTime 0.022 (0.040)\tLoss 0.9115 (0.8840)\tPrec@1 61.000 (63.585)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.9324 (0.8837)\tPrec@1 60.000 (63.667)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 0.9630 (0.8882)\tPrec@1 57.000 (63.328)\n",
            "Test: [70/100]\tTime 0.039 (0.037)\tLoss 0.7703 (0.8908)\tPrec@1 70.000 (63.268)\n",
            "Test: [80/100]\tTime 0.020 (0.036)\tLoss 0.8561 (0.8918)\tPrec@1 67.000 (63.296)\n",
            "Test: [90/100]\tTime 0.038 (0.036)\tLoss 0.9893 (0.8911)\tPrec@1 57.000 (63.275)\n",
            "val Results: Prec@1 63.480 Loss 0.88538\n",
            "Best Prec@1: 64.380\n",
            "\n",
            "Epoch: [158][0/97], lr: 0.01000\tTime 0.486 (0.486)\tData 0.326 (0.326)\tLoss 0.7792 (0.7792)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [158][10/97], lr: 0.01000\tTime 0.093 (0.119)\tData 0.006 (0.034)\tLoss 0.5596 (0.6862)\tPrec@1 75.781 (73.224)\n",
            "Epoch: [158][20/97], lr: 0.01000\tTime 0.063 (0.095)\tData 0.000 (0.019)\tLoss 0.9195 (0.7263)\tPrec@1 66.406 (71.094)\n",
            "Epoch: [158][30/97], lr: 0.01000\tTime 0.069 (0.087)\tData 0.007 (0.014)\tLoss 0.8105 (0.7250)\tPrec@1 67.969 (70.413)\n",
            "Epoch: [158][40/97], lr: 0.01000\tTime 0.069 (0.083)\tData 0.000 (0.012)\tLoss 0.6681 (0.7257)\tPrec@1 73.438 (70.389)\n",
            "Epoch: [158][50/97], lr: 0.01000\tTime 0.082 (0.081)\tData 0.009 (0.010)\tLoss 0.8429 (0.7298)\tPrec@1 61.719 (70.175)\n",
            "Epoch: [158][60/97], lr: 0.01000\tTime 0.076 (0.079)\tData 0.000 (0.009)\tLoss 0.7934 (0.7367)\tPrec@1 70.312 (69.787)\n",
            "Epoch: [158][70/97], lr: 0.01000\tTime 0.062 (0.078)\tData 0.001 (0.008)\tLoss 0.7101 (0.7348)\tPrec@1 67.969 (69.784)\n",
            "Epoch: [158][80/97], lr: 0.01000\tTime 0.068 (0.077)\tData 0.004 (0.008)\tLoss 0.6093 (0.7375)\tPrec@1 76.562 (69.772)\n",
            "Epoch: [158][90/97], lr: 0.01000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.8971 (0.7373)\tPrec@1 60.156 (69.866)\n",
            "Test: [0/100]\tTime 0.348 (0.348)\tLoss 0.9695 (0.9695)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.046 (0.061)\tLoss 0.9225 (0.9476)\tPrec@1 70.000 (62.818)\n",
            "Test: [20/100]\tTime 0.058 (0.047)\tLoss 0.9699 (0.9477)\tPrec@1 59.000 (62.857)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.0762 (0.9506)\tPrec@1 55.000 (62.387)\n",
            "Test: [40/100]\tTime 0.033 (0.040)\tLoss 1.0242 (0.9498)\tPrec@1 59.000 (61.902)\n",
            "Test: [50/100]\tTime 0.042 (0.038)\tLoss 0.9626 (0.9475)\tPrec@1 65.000 (62.255)\n",
            "Test: [60/100]\tTime 0.030 (0.038)\tLoss 1.0065 (0.9514)\tPrec@1 63.000 (62.131)\n",
            "Test: [70/100]\tTime 0.042 (0.037)\tLoss 0.8935 (0.9455)\tPrec@1 63.000 (62.225)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.8330 (0.9448)\tPrec@1 63.000 (62.037)\n",
            "Test: [90/100]\tTime 0.041 (0.036)\tLoss 1.0926 (0.9432)\tPrec@1 58.000 (62.220)\n",
            "val Results: Prec@1 62.430 Loss 0.93897\n",
            "Best Prec@1: 64.380\n",
            "\n",
            "Epoch: [159][0/97], lr: 0.01000\tTime 0.475 (0.475)\tData 0.317 (0.317)\tLoss 0.7798 (0.7798)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [159][10/97], lr: 0.01000\tTime 0.065 (0.114)\tData 0.000 (0.030)\tLoss 0.6830 (0.7829)\tPrec@1 71.875 (67.401)\n",
            "Epoch: [159][20/97], lr: 0.01000\tTime 0.078 (0.106)\tData 0.010 (0.019)\tLoss 0.7634 (0.7756)\tPrec@1 69.531 (68.155)\n",
            "Epoch: [159][30/97], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.014)\tLoss 0.7930 (0.7728)\tPrec@1 69.531 (68.574)\n",
            "Epoch: [159][40/97], lr: 0.01000\tTime 0.066 (0.088)\tData 0.004 (0.011)\tLoss 0.9068 (0.7710)\tPrec@1 64.062 (69.017)\n",
            "Epoch: [159][50/97], lr: 0.01000\tTime 0.068 (0.085)\tData 0.007 (0.010)\tLoss 0.6828 (0.7589)\tPrec@1 67.188 (69.455)\n",
            "Epoch: [159][60/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.008)\tLoss 0.7936 (0.7477)\tPrec@1 66.406 (69.826)\n",
            "Epoch: [159][70/97], lr: 0.01000\tTime 0.078 (0.081)\tData 0.007 (0.007)\tLoss 0.7815 (0.7454)\tPrec@1 73.438 (69.993)\n",
            "Epoch: [159][80/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.007 (0.007)\tLoss 0.9113 (0.7453)\tPrec@1 57.812 (69.772)\n",
            "Epoch: [159][90/97], lr: 0.01000\tTime 0.055 (0.078)\tData 0.000 (0.006)\tLoss 0.7118 (0.7417)\tPrec@1 72.656 (70.081)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.9104 (0.9104)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.051 (0.061)\tLoss 0.8477 (0.8828)\tPrec@1 65.000 (62.364)\n",
            "Test: [20/100]\tTime 0.023 (0.047)\tLoss 0.9685 (0.8787)\tPrec@1 60.000 (62.857)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 0.9775 (0.8899)\tPrec@1 59.000 (62.226)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.8991 (0.8787)\tPrec@1 63.000 (62.488)\n",
            "Test: [50/100]\tTime 0.031 (0.038)\tLoss 0.9418 (0.8781)\tPrec@1 60.000 (62.608)\n",
            "Test: [60/100]\tTime 0.052 (0.037)\tLoss 0.9571 (0.8853)\tPrec@1 56.000 (62.393)\n",
            "Test: [70/100]\tTime 0.025 (0.036)\tLoss 0.8009 (0.8830)\tPrec@1 69.000 (62.718)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 0.8099 (0.8812)\tPrec@1 67.000 (62.852)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 1.0238 (0.8842)\tPrec@1 55.000 (62.703)\n",
            "val Results: Prec@1 62.940 Loss 0.87854\n",
            "Best Prec@1: 64.380\n",
            "\n",
            "Epoch: [160][0/97], lr: 0.00010\tTime 0.534 (0.534)\tData 0.373 (0.373)\tLoss 0.8046 (0.8046)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [160][10/97], lr: 0.00010\tTime 0.062 (0.113)\tData 0.000 (0.036)\tLoss 0.7638 (0.7340)\tPrec@1 63.281 (69.176)\n",
            "Epoch: [160][20/97], lr: 0.00010\tTime 0.069 (0.094)\tData 0.000 (0.020)\tLoss 0.6210 (0.7368)\tPrec@1 75.000 (69.196)\n",
            "Epoch: [160][30/97], lr: 0.00010\tTime 0.065 (0.088)\tData 0.000 (0.014)\tLoss 0.7423 (0.7267)\tPrec@1 68.750 (69.808)\n",
            "Epoch: [160][40/97], lr: 0.00010\tTime 0.064 (0.084)\tData 0.000 (0.011)\tLoss 0.7611 (0.7368)\tPrec@1 68.750 (69.627)\n",
            "Epoch: [160][50/97], lr: 0.00010\tTime 0.082 (0.081)\tData 0.007 (0.010)\tLoss 0.6411 (0.7293)\tPrec@1 75.000 (70.006)\n",
            "Epoch: [160][60/97], lr: 0.00010\tTime 0.070 (0.079)\tData 0.000 (0.008)\tLoss 0.7257 (0.7231)\tPrec@1 71.094 (70.351)\n",
            "Epoch: [160][70/97], lr: 0.00010\tTime 0.068 (0.078)\tData 0.007 (0.008)\tLoss 0.6452 (0.7160)\tPrec@1 71.094 (70.665)\n",
            "Epoch: [160][80/97], lr: 0.00010\tTime 0.061 (0.077)\tData 0.000 (0.007)\tLoss 0.6659 (0.7154)\tPrec@1 75.000 (70.920)\n",
            "Epoch: [160][90/97], lr: 0.00010\tTime 0.054 (0.076)\tData 0.000 (0.006)\tLoss 0.8653 (0.7182)\tPrec@1 64.844 (70.853)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 0.8704 (0.8704)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 0.8145 (0.8495)\tPrec@1 64.000 (65.364)\n",
            "Test: [20/100]\tTime 0.032 (0.046)\tLoss 0.9020 (0.8402)\tPrec@1 63.000 (65.810)\n",
            "Test: [30/100]\tTime 0.041 (0.041)\tLoss 0.9380 (0.8535)\tPrec@1 57.000 (64.806)\n",
            "Test: [40/100]\tTime 0.028 (0.039)\tLoss 0.7782 (0.8427)\tPrec@1 71.000 (65.171)\n",
            "Test: [50/100]\tTime 0.045 (0.037)\tLoss 0.8837 (0.8403)\tPrec@1 66.000 (65.392)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 0.9503 (0.8465)\tPrec@1 57.000 (65.279)\n",
            "Test: [70/100]\tTime 0.040 (0.035)\tLoss 0.8012 (0.8442)\tPrec@1 62.000 (65.211)\n",
            "Test: [80/100]\tTime 0.027 (0.036)\tLoss 0.8586 (0.8410)\tPrec@1 65.000 (65.506)\n",
            "Test: [90/100]\tTime 0.044 (0.036)\tLoss 0.9804 (0.8432)\tPrec@1 61.000 (65.451)\n",
            "val Results: Prec@1 65.680 Loss 0.83821\n",
            "Best Prec@1: 65.680\n",
            "\n",
            "Epoch: [161][0/97], lr: 0.00010\tTime 0.549 (0.549)\tData 0.399 (0.399)\tLoss 0.7930 (0.7930)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [161][10/97], lr: 0.00010\tTime 0.098 (0.122)\tData 0.000 (0.039)\tLoss 0.8141 (0.7060)\tPrec@1 65.625 (71.307)\n",
            "Epoch: [161][20/97], lr: 0.00010\tTime 0.079 (0.097)\tData 0.007 (0.022)\tLoss 0.7132 (0.6979)\tPrec@1 69.531 (71.280)\n",
            "Epoch: [161][30/97], lr: 0.00010\tTime 0.070 (0.088)\tData 0.007 (0.016)\tLoss 0.7009 (0.6927)\tPrec@1 66.406 (71.522)\n",
            "Epoch: [161][40/97], lr: 0.00010\tTime 0.077 (0.084)\tData 0.000 (0.013)\tLoss 0.7082 (0.6938)\tPrec@1 73.438 (71.761)\n",
            "Epoch: [161][50/97], lr: 0.00010\tTime 0.068 (0.081)\tData 0.007 (0.011)\tLoss 0.8273 (0.7024)\tPrec@1 67.188 (71.415)\n",
            "Epoch: [161][60/97], lr: 0.00010\tTime 0.067 (0.079)\tData 0.002 (0.010)\tLoss 0.6095 (0.7009)\tPrec@1 78.906 (71.580)\n",
            "Epoch: [161][70/97], lr: 0.00010\tTime 0.071 (0.078)\tData 0.003 (0.009)\tLoss 0.8729 (0.7049)\tPrec@1 67.969 (71.391)\n",
            "Epoch: [161][80/97], lr: 0.00010\tTime 0.071 (0.077)\tData 0.006 (0.009)\tLoss 0.7201 (0.7012)\tPrec@1 70.312 (71.624)\n",
            "Epoch: [161][90/97], lr: 0.00010\tTime 0.055 (0.076)\tData 0.000 (0.008)\tLoss 0.5334 (0.7022)\tPrec@1 83.594 (71.609)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 0.8839 (0.8839)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.022 (0.056)\tLoss 0.7593 (0.8297)\tPrec@1 67.000 (65.273)\n",
            "Test: [20/100]\tTime 0.045 (0.045)\tLoss 0.9018 (0.8342)\tPrec@1 66.000 (65.571)\n",
            "Test: [30/100]\tTime 0.056 (0.043)\tLoss 0.8490 (0.8464)\tPrec@1 61.000 (64.871)\n",
            "Test: [40/100]\tTime 0.023 (0.041)\tLoss 0.7956 (0.8409)\tPrec@1 69.000 (65.317)\n",
            "Test: [50/100]\tTime 0.038 (0.040)\tLoss 0.8695 (0.8448)\tPrec@1 63.000 (65.333)\n",
            "Test: [60/100]\tTime 0.051 (0.040)\tLoss 1.0112 (0.8509)\tPrec@1 58.000 (65.213)\n",
            "Test: [70/100]\tTime 0.023 (0.039)\tLoss 0.7586 (0.8490)\tPrec@1 70.000 (65.268)\n",
            "Test: [80/100]\tTime 0.027 (0.039)\tLoss 0.7796 (0.8484)\tPrec@1 66.000 (65.333)\n",
            "Test: [90/100]\tTime 0.027 (0.038)\tLoss 1.0091 (0.8483)\tPrec@1 59.000 (65.143)\n",
            "val Results: Prec@1 65.300 Loss 0.84439\n",
            "Best Prec@1: 65.680\n",
            "\n",
            "Epoch: [162][0/97], lr: 0.00010\tTime 0.517 (0.517)\tData 0.361 (0.361)\tLoss 0.7063 (0.7063)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [162][10/97], lr: 0.00010\tTime 0.063 (0.115)\tData 0.000 (0.036)\tLoss 0.8946 (0.7217)\tPrec@1 59.375 (70.668)\n",
            "Epoch: [162][20/97], lr: 0.00010\tTime 0.066 (0.095)\tData 0.001 (0.020)\tLoss 0.7164 (0.7019)\tPrec@1 70.312 (71.280)\n",
            "Epoch: [162][30/97], lr: 0.00010\tTime 0.064 (0.086)\tData 0.000 (0.014)\tLoss 0.7077 (0.6997)\tPrec@1 69.531 (71.371)\n",
            "Epoch: [162][40/97], lr: 0.00010\tTime 0.081 (0.084)\tData 0.000 (0.011)\tLoss 0.6487 (0.7033)\tPrec@1 68.750 (71.265)\n",
            "Epoch: [162][50/97], lr: 0.00010\tTime 0.091 (0.085)\tData 0.000 (0.009)\tLoss 0.6659 (0.6937)\tPrec@1 74.219 (71.615)\n",
            "Epoch: [162][60/97], lr: 0.00010\tTime 0.110 (0.085)\tData 0.000 (0.008)\tLoss 0.7858 (0.6959)\tPrec@1 67.969 (71.555)\n",
            "Epoch: [162][70/97], lr: 0.00010\tTime 0.092 (0.085)\tData 0.001 (0.008)\tLoss 0.5710 (0.6972)\tPrec@1 75.781 (71.523)\n",
            "Epoch: [162][80/97], lr: 0.00010\tTime 0.063 (0.084)\tData 0.000 (0.007)\tLoss 0.6476 (0.6933)\tPrec@1 73.438 (71.721)\n",
            "Epoch: [162][90/97], lr: 0.00010\tTime 0.050 (0.084)\tData 0.000 (0.007)\tLoss 0.6621 (0.6903)\tPrec@1 71.875 (71.866)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 0.8284 (0.8284)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.024 (0.062)\tLoss 0.7654 (0.8084)\tPrec@1 68.000 (66.000)\n",
            "Test: [20/100]\tTime 0.049 (0.048)\tLoss 0.7775 (0.8090)\tPrec@1 72.000 (66.476)\n",
            "Test: [30/100]\tTime 0.026 (0.042)\tLoss 0.9086 (0.8269)\tPrec@1 66.000 (65.645)\n",
            "Test: [40/100]\tTime 0.029 (0.041)\tLoss 0.8313 (0.8256)\tPrec@1 68.000 (65.610)\n",
            "Test: [50/100]\tTime 0.048 (0.039)\tLoss 0.9079 (0.8281)\tPrec@1 67.000 (65.706)\n",
            "Test: [60/100]\tTime 0.051 (0.038)\tLoss 0.9719 (0.8347)\tPrec@1 57.000 (65.508)\n",
            "Test: [70/100]\tTime 0.061 (0.037)\tLoss 0.7780 (0.8337)\tPrec@1 67.000 (65.676)\n",
            "Test: [80/100]\tTime 0.037 (0.036)\tLoss 0.7744 (0.8313)\tPrec@1 67.000 (65.877)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 0.9310 (0.8340)\tPrec@1 63.000 (65.714)\n",
            "val Results: Prec@1 65.870 Loss 0.82927\n",
            "Best Prec@1: 65.870\n",
            "\n",
            "Epoch: [163][0/97], lr: 0.00010\tTime 0.722 (0.722)\tData 0.453 (0.453)\tLoss 0.7485 (0.7485)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [163][10/97], lr: 0.00010\tTime 0.122 (0.168)\tData 0.012 (0.045)\tLoss 0.6127 (0.6771)\tPrec@1 75.781 (71.733)\n",
            "Epoch: [163][20/97], lr: 0.00010\tTime 0.120 (0.140)\tData 0.011 (0.028)\tLoss 0.7059 (0.6821)\tPrec@1 71.094 (71.652)\n",
            "Epoch: [163][30/97], lr: 0.00010\tTime 0.090 (0.128)\tData 0.000 (0.020)\tLoss 0.6495 (0.6854)\tPrec@1 72.656 (71.900)\n",
            "Epoch: [163][40/97], lr: 0.00010\tTime 0.069 (0.115)\tData 0.000 (0.016)\tLoss 0.7041 (0.6824)\tPrec@1 75.000 (72.504)\n",
            "Epoch: [163][50/97], lr: 0.00010\tTime 0.063 (0.106)\tData 0.000 (0.013)\tLoss 0.5823 (0.6729)\tPrec@1 78.125 (72.855)\n",
            "Epoch: [163][60/97], lr: 0.00010\tTime 0.097 (0.101)\tData 0.000 (0.011)\tLoss 0.7575 (0.6731)\tPrec@1 70.312 (72.874)\n",
            "Epoch: [163][70/97], lr: 0.00010\tTime 0.061 (0.096)\tData 0.000 (0.010)\tLoss 0.7369 (0.6744)\tPrec@1 67.188 (72.854)\n",
            "Epoch: [163][80/97], lr: 0.00010\tTime 0.063 (0.093)\tData 0.000 (0.009)\tLoss 0.7656 (0.6788)\tPrec@1 64.844 (72.608)\n",
            "Epoch: [163][90/97], lr: 0.00010\tTime 0.055 (0.091)\tData 0.000 (0.008)\tLoss 0.7465 (0.6828)\tPrec@1 67.188 (72.236)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 0.8271 (0.8271)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.7378 (0.8241)\tPrec@1 71.000 (66.182)\n",
            "Test: [20/100]\tTime 0.035 (0.047)\tLoss 0.8838 (0.8274)\tPrec@1 67.000 (65.905)\n",
            "Test: [30/100]\tTime 0.040 (0.041)\tLoss 0.8929 (0.8352)\tPrec@1 65.000 (65.065)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.8170 (0.8343)\tPrec@1 66.000 (65.073)\n",
            "Test: [50/100]\tTime 0.027 (0.037)\tLoss 0.8403 (0.8303)\tPrec@1 68.000 (65.549)\n",
            "Test: [60/100]\tTime 0.021 (0.036)\tLoss 0.9201 (0.8365)\tPrec@1 59.000 (65.557)\n",
            "Test: [70/100]\tTime 0.036 (0.035)\tLoss 0.7742 (0.8330)\tPrec@1 68.000 (65.746)\n",
            "Test: [80/100]\tTime 0.020 (0.035)\tLoss 0.7517 (0.8292)\tPrec@1 70.000 (65.827)\n",
            "Test: [90/100]\tTime 0.043 (0.034)\tLoss 1.0452 (0.8304)\tPrec@1 59.000 (65.857)\n",
            "val Results: Prec@1 66.150 Loss 0.82520\n",
            "Best Prec@1: 66.150\n",
            "\n",
            "Epoch: [164][0/97], lr: 0.00010\tTime 0.534 (0.534)\tData 0.372 (0.372)\tLoss 0.5450 (0.5450)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [164][10/97], lr: 0.00010\tTime 0.066 (0.116)\tData 0.000 (0.035)\tLoss 0.7300 (0.6837)\tPrec@1 74.219 (73.295)\n",
            "Epoch: [164][20/97], lr: 0.00010\tTime 0.068 (0.096)\tData 0.000 (0.020)\tLoss 0.6824 (0.6869)\tPrec@1 70.312 (72.545)\n",
            "Epoch: [164][30/97], lr: 0.00010\tTime 0.062 (0.088)\tData 0.000 (0.014)\tLoss 0.6702 (0.6779)\tPrec@1 71.094 (72.933)\n",
            "Epoch: [164][40/97], lr: 0.00010\tTime 0.063 (0.084)\tData 0.000 (0.011)\tLoss 0.6734 (0.6772)\tPrec@1 69.531 (72.752)\n",
            "Epoch: [164][50/97], lr: 0.00010\tTime 0.077 (0.082)\tData 0.007 (0.010)\tLoss 0.9259 (0.6785)\tPrec@1 60.156 (72.809)\n",
            "Epoch: [164][60/97], lr: 0.00010\tTime 0.070 (0.080)\tData 0.007 (0.009)\tLoss 0.8486 (0.6744)\tPrec@1 63.281 (73.156)\n",
            "Epoch: [164][70/97], lr: 0.00010\tTime 0.065 (0.078)\tData 0.003 (0.008)\tLoss 0.7228 (0.6753)\tPrec@1 72.656 (73.052)\n",
            "Epoch: [164][80/97], lr: 0.00010\tTime 0.068 (0.077)\tData 0.000 (0.007)\tLoss 0.6894 (0.6783)\tPrec@1 69.531 (72.753)\n",
            "Epoch: [164][90/97], lr: 0.00010\tTime 0.057 (0.076)\tData 0.000 (0.007)\tLoss 0.7737 (0.6754)\tPrec@1 67.969 (72.837)\n",
            "Test: [0/100]\tTime 0.269 (0.269)\tLoss 0.8173 (0.8173)\tPrec@1 72.000 (72.000)\n",
            "Test: [10/100]\tTime 0.024 (0.060)\tLoss 0.8266 (0.8142)\tPrec@1 66.000 (66.909)\n",
            "Test: [20/100]\tTime 0.030 (0.047)\tLoss 0.8023 (0.8160)\tPrec@1 68.000 (67.000)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 0.8588 (0.8328)\tPrec@1 63.000 (65.645)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.8156 (0.8293)\tPrec@1 67.000 (65.610)\n",
            "Test: [50/100]\tTime 0.028 (0.038)\tLoss 0.8288 (0.8255)\tPrec@1 67.000 (65.980)\n",
            "Test: [60/100]\tTime 0.039 (0.037)\tLoss 1.0295 (0.8328)\tPrec@1 56.000 (65.639)\n",
            "Test: [70/100]\tTime 0.029 (0.036)\tLoss 0.7709 (0.8334)\tPrec@1 71.000 (65.648)\n",
            "Test: [80/100]\tTime 0.026 (0.035)\tLoss 0.8210 (0.8321)\tPrec@1 66.000 (65.815)\n",
            "Test: [90/100]\tTime 0.031 (0.035)\tLoss 0.9421 (0.8327)\tPrec@1 62.000 (65.736)\n",
            "val Results: Prec@1 66.020 Loss 0.82779\n",
            "Best Prec@1: 66.150\n",
            "\n",
            "Epoch: [165][0/97], lr: 0.00010\tTime 0.524 (0.524)\tData 0.311 (0.311)\tLoss 0.8323 (0.8323)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [165][10/97], lr: 0.00010\tTime 0.062 (0.118)\tData 0.002 (0.031)\tLoss 0.5999 (0.6978)\tPrec@1 78.906 (71.591)\n",
            "Epoch: [165][20/97], lr: 0.00010\tTime 0.071 (0.096)\tData 0.010 (0.018)\tLoss 0.6028 (0.6895)\tPrec@1 74.219 (71.763)\n",
            "Epoch: [165][30/97], lr: 0.00010\tTime 0.073 (0.089)\tData 0.012 (0.013)\tLoss 0.8276 (0.6910)\tPrec@1 67.188 (71.976)\n",
            "Epoch: [165][40/97], lr: 0.00010\tTime 0.072 (0.084)\tData 0.007 (0.011)\tLoss 0.6799 (0.6851)\tPrec@1 70.312 (72.218)\n",
            "Epoch: [165][50/97], lr: 0.00010\tTime 0.079 (0.081)\tData 0.000 (0.009)\tLoss 0.6286 (0.6806)\tPrec@1 72.656 (72.580)\n",
            "Epoch: [165][60/97], lr: 0.00010\tTime 0.085 (0.080)\tData 0.006 (0.008)\tLoss 0.7426 (0.6843)\tPrec@1 68.750 (72.208)\n",
            "Epoch: [165][70/97], lr: 0.00010\tTime 0.078 (0.079)\tData 0.007 (0.008)\tLoss 0.7018 (0.6828)\tPrec@1 69.531 (72.293)\n",
            "Epoch: [165][80/97], lr: 0.00010\tTime 0.064 (0.078)\tData 0.000 (0.007)\tLoss 0.7492 (0.6832)\tPrec@1 67.188 (72.280)\n",
            "Epoch: [165][90/97], lr: 0.00010\tTime 0.051 (0.077)\tData 0.000 (0.007)\tLoss 0.5815 (0.6807)\tPrec@1 76.562 (72.356)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 0.8238 (0.8238)\tPrec@1 69.000 (69.000)\n",
            "Test: [10/100]\tTime 0.021 (0.059)\tLoss 0.7529 (0.8091)\tPrec@1 68.000 (66.364)\n",
            "Test: [20/100]\tTime 0.030 (0.045)\tLoss 0.8107 (0.8066)\tPrec@1 68.000 (66.619)\n",
            "Test: [30/100]\tTime 0.044 (0.042)\tLoss 0.9114 (0.8188)\tPrec@1 63.000 (65.355)\n",
            "Test: [40/100]\tTime 0.045 (0.039)\tLoss 0.7908 (0.8177)\tPrec@1 67.000 (65.439)\n",
            "Test: [50/100]\tTime 0.043 (0.037)\tLoss 0.8033 (0.8157)\tPrec@1 68.000 (65.725)\n",
            "Test: [60/100]\tTime 0.052 (0.037)\tLoss 0.9326 (0.8219)\tPrec@1 63.000 (65.705)\n",
            "Test: [70/100]\tTime 0.056 (0.036)\tLoss 0.7972 (0.8250)\tPrec@1 65.000 (65.634)\n",
            "Test: [80/100]\tTime 0.020 (0.035)\tLoss 0.7150 (0.8216)\tPrec@1 67.000 (65.630)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9447 (0.8233)\tPrec@1 62.000 (65.648)\n",
            "val Results: Prec@1 66.000 Loss 0.81698\n",
            "Best Prec@1: 66.150\n",
            "\n",
            "Epoch: [166][0/97], lr: 0.00010\tTime 0.553 (0.553)\tData 0.372 (0.372)\tLoss 0.6971 (0.6971)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [166][10/97], lr: 0.00010\tTime 0.065 (0.119)\tData 0.000 (0.037)\tLoss 0.5846 (0.7069)\tPrec@1 75.781 (71.023)\n",
            "Epoch: [166][20/97], lr: 0.00010\tTime 0.081 (0.097)\tData 0.000 (0.021)\tLoss 0.6902 (0.6843)\tPrec@1 75.000 (72.098)\n",
            "Epoch: [166][30/97], lr: 0.00010\tTime 0.060 (0.087)\tData 0.000 (0.015)\tLoss 0.7116 (0.6821)\tPrec@1 66.406 (72.278)\n",
            "Epoch: [166][40/97], lr: 0.00010\tTime 0.069 (0.084)\tData 0.000 (0.012)\tLoss 0.6936 (0.6883)\tPrec@1 67.969 (71.875)\n",
            "Epoch: [166][50/97], lr: 0.00010\tTime 0.078 (0.082)\tData 0.007 (0.010)\tLoss 0.7150 (0.6852)\tPrec@1 70.312 (71.844)\n",
            "Epoch: [166][60/97], lr: 0.00010\tTime 0.062 (0.080)\tData 0.000 (0.009)\tLoss 0.5853 (0.6771)\tPrec@1 76.562 (72.182)\n",
            "Epoch: [166][70/97], lr: 0.00010\tTime 0.075 (0.079)\tData 0.007 (0.008)\tLoss 0.6112 (0.6754)\tPrec@1 75.000 (72.216)\n",
            "Epoch: [166][80/97], lr: 0.00010\tTime 0.076 (0.078)\tData 0.006 (0.007)\tLoss 0.6528 (0.6711)\tPrec@1 74.219 (72.521)\n",
            "Epoch: [166][90/97], lr: 0.00010\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.7182 (0.6712)\tPrec@1 71.094 (72.579)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.8483 (0.8483)\tPrec@1 69.000 (69.000)\n",
            "Test: [10/100]\tTime 0.045 (0.061)\tLoss 0.7597 (0.7983)\tPrec@1 69.000 (66.818)\n",
            "Test: [20/100]\tTime 0.021 (0.047)\tLoss 0.9312 (0.8028)\tPrec@1 64.000 (66.619)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.8634 (0.8124)\tPrec@1 62.000 (65.839)\n",
            "Test: [40/100]\tTime 0.053 (0.039)\tLoss 0.7906 (0.8156)\tPrec@1 70.000 (65.585)\n",
            "Test: [50/100]\tTime 0.030 (0.038)\tLoss 0.9039 (0.8196)\tPrec@1 64.000 (65.510)\n",
            "Test: [60/100]\tTime 0.027 (0.037)\tLoss 0.9781 (0.8277)\tPrec@1 59.000 (65.475)\n",
            "Test: [70/100]\tTime 0.042 (0.036)\tLoss 0.7703 (0.8262)\tPrec@1 66.000 (65.803)\n",
            "Test: [80/100]\tTime 0.037 (0.036)\tLoss 0.7497 (0.8268)\tPrec@1 70.000 (65.679)\n",
            "Test: [90/100]\tTime 0.042 (0.035)\tLoss 1.0182 (0.8265)\tPrec@1 56.000 (65.758)\n",
            "val Results: Prec@1 66.140 Loss 0.81907\n",
            "Best Prec@1: 66.150\n",
            "\n",
            "Epoch: [167][0/97], lr: 0.00010\tTime 0.501 (0.501)\tData 0.331 (0.331)\tLoss 0.6929 (0.6929)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [167][10/97], lr: 0.00010\tTime 0.077 (0.120)\tData 0.007 (0.035)\tLoss 0.6992 (0.6943)\tPrec@1 76.562 (73.082)\n",
            "Epoch: [167][20/97], lr: 0.00010\tTime 0.064 (0.095)\tData 0.000 (0.019)\tLoss 0.6618 (0.6625)\tPrec@1 70.312 (73.661)\n",
            "Epoch: [167][30/97], lr: 0.00010\tTime 0.079 (0.088)\tData 0.000 (0.014)\tLoss 0.6782 (0.6825)\tPrec@1 73.438 (73.059)\n",
            "Epoch: [167][40/97], lr: 0.00010\tTime 0.063 (0.084)\tData 0.000 (0.011)\tLoss 0.6396 (0.6858)\tPrec@1 71.875 (72.732)\n",
            "Epoch: [167][50/97], lr: 0.00010\tTime 0.068 (0.081)\tData 0.004 (0.009)\tLoss 0.6389 (0.6767)\tPrec@1 71.875 (73.146)\n",
            "Epoch: [167][60/97], lr: 0.00010\tTime 0.063 (0.080)\tData 0.000 (0.008)\tLoss 0.7235 (0.6764)\tPrec@1 75.000 (73.207)\n",
            "Epoch: [167][70/97], lr: 0.00010\tTime 0.068 (0.079)\tData 0.005 (0.008)\tLoss 0.6264 (0.6787)\tPrec@1 77.344 (72.909)\n",
            "Epoch: [167][80/97], lr: 0.00010\tTime 0.076 (0.078)\tData 0.012 (0.008)\tLoss 0.6839 (0.6729)\tPrec@1 75.000 (73.148)\n",
            "Epoch: [167][90/97], lr: 0.00010\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.6339 (0.6711)\tPrec@1 75.000 (73.171)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 0.8215 (0.8215)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.036 (0.062)\tLoss 0.7681 (0.8073)\tPrec@1 68.000 (66.818)\n",
            "Test: [20/100]\tTime 0.021 (0.046)\tLoss 0.8208 (0.8139)\tPrec@1 64.000 (67.143)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 0.8809 (0.8202)\tPrec@1 62.000 (66.323)\n",
            "Test: [40/100]\tTime 0.025 (0.039)\tLoss 0.8074 (0.8177)\tPrec@1 69.000 (66.439)\n",
            "Test: [50/100]\tTime 0.037 (0.037)\tLoss 0.8227 (0.8159)\tPrec@1 69.000 (66.667)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 0.9267 (0.8216)\tPrec@1 57.000 (66.410)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.6739 (0.8208)\tPrec@1 72.000 (66.493)\n",
            "Test: [80/100]\tTime 0.038 (0.035)\tLoss 0.7511 (0.8180)\tPrec@1 67.000 (66.543)\n",
            "Test: [90/100]\tTime 0.047 (0.035)\tLoss 0.9682 (0.8191)\tPrec@1 58.000 (66.484)\n",
            "val Results: Prec@1 66.650 Loss 0.81486\n",
            "Best Prec@1: 66.650\n",
            "\n",
            "Epoch: [168][0/97], lr: 0.00010\tTime 0.462 (0.462)\tData 0.300 (0.300)\tLoss 0.5936 (0.5936)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [168][10/97], lr: 0.00010\tTime 0.063 (0.116)\tData 0.000 (0.033)\tLoss 0.8517 (0.6724)\tPrec@1 63.281 (72.514)\n",
            "Epoch: [168][20/97], lr: 0.00010\tTime 0.063 (0.093)\tData 0.000 (0.019)\tLoss 0.6272 (0.6735)\tPrec@1 75.000 (72.917)\n",
            "Epoch: [168][30/97], lr: 0.00010\tTime 0.063 (0.086)\tData 0.000 (0.013)\tLoss 0.8004 (0.6752)\tPrec@1 67.188 (72.858)\n",
            "Epoch: [168][40/97], lr: 0.00010\tTime 0.073 (0.082)\tData 0.000 (0.011)\tLoss 0.6394 (0.6657)\tPrec@1 75.000 (73.266)\n",
            "Epoch: [168][50/97], lr: 0.00010\tTime 0.061 (0.080)\tData 0.000 (0.010)\tLoss 0.7757 (0.6722)\tPrec@1 66.406 (72.978)\n",
            "Epoch: [168][60/97], lr: 0.00010\tTime 0.062 (0.079)\tData 0.000 (0.009)\tLoss 0.7486 (0.6705)\tPrec@1 72.656 (73.258)\n",
            "Epoch: [168][70/97], lr: 0.00010\tTime 0.059 (0.078)\tData 0.000 (0.008)\tLoss 0.6362 (0.6696)\tPrec@1 75.781 (73.184)\n",
            "Epoch: [168][80/97], lr: 0.00010\tTime 0.059 (0.077)\tData 0.000 (0.007)\tLoss 0.7310 (0.6742)\tPrec@1 68.750 (72.868)\n",
            "Epoch: [168][90/97], lr: 0.00010\tTime 0.051 (0.076)\tData 0.000 (0.007)\tLoss 0.6985 (0.6711)\tPrec@1 68.750 (72.879)\n",
            "Test: [0/100]\tTime 0.281 (0.281)\tLoss 0.8266 (0.8266)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 0.7883 (0.8113)\tPrec@1 66.000 (66.364)\n",
            "Test: [20/100]\tTime 0.021 (0.045)\tLoss 0.8275 (0.8117)\tPrec@1 69.000 (66.333)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 0.8392 (0.8169)\tPrec@1 62.000 (65.710)\n",
            "Test: [40/100]\tTime 0.021 (0.039)\tLoss 0.7829 (0.8122)\tPrec@1 68.000 (65.902)\n",
            "Test: [50/100]\tTime 0.045 (0.038)\tLoss 0.7886 (0.8096)\tPrec@1 70.000 (66.373)\n",
            "Test: [60/100]\tTime 0.025 (0.037)\tLoss 0.9111 (0.8156)\tPrec@1 63.000 (66.230)\n",
            "Test: [70/100]\tTime 0.060 (0.036)\tLoss 0.7686 (0.8140)\tPrec@1 69.000 (66.521)\n",
            "Test: [80/100]\tTime 0.036 (0.035)\tLoss 0.6933 (0.8119)\tPrec@1 67.000 (66.679)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9407 (0.8147)\tPrec@1 63.000 (66.571)\n",
            "val Results: Prec@1 66.870 Loss 0.80840\n",
            "Best Prec@1: 66.870\n",
            "\n",
            "Epoch: [169][0/97], lr: 0.00010\tTime 0.573 (0.573)\tData 0.438 (0.438)\tLoss 0.6611 (0.6611)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [169][10/97], lr: 0.00010\tTime 0.063 (0.122)\tData 0.000 (0.041)\tLoss 0.6830 (0.6518)\tPrec@1 71.094 (73.651)\n",
            "Epoch: [169][20/97], lr: 0.00010\tTime 0.066 (0.099)\tData 0.006 (0.023)\tLoss 0.6496 (0.6440)\tPrec@1 73.438 (73.921)\n",
            "Epoch: [169][30/97], lr: 0.00010\tTime 0.067 (0.089)\tData 0.000 (0.016)\tLoss 0.7096 (0.6484)\tPrec@1 72.656 (73.841)\n",
            "Epoch: [169][40/97], lr: 0.00010\tTime 0.061 (0.085)\tData 0.000 (0.012)\tLoss 0.6801 (0.6591)\tPrec@1 73.438 (72.999)\n",
            "Epoch: [169][50/97], lr: 0.00010\tTime 0.069 (0.082)\tData 0.004 (0.011)\tLoss 0.7106 (0.6599)\tPrec@1 67.188 (72.917)\n",
            "Epoch: [169][60/97], lr: 0.00010\tTime 0.069 (0.080)\tData 0.007 (0.009)\tLoss 0.7200 (0.6638)\tPrec@1 71.094 (73.015)\n",
            "Epoch: [169][70/97], lr: 0.00010\tTime 0.076 (0.079)\tData 0.000 (0.008)\tLoss 0.6110 (0.6649)\tPrec@1 75.000 (73.063)\n",
            "Epoch: [169][80/97], lr: 0.00010\tTime 0.065 (0.078)\tData 0.000 (0.008)\tLoss 0.6713 (0.6672)\tPrec@1 70.312 (72.955)\n",
            "Epoch: [169][90/97], lr: 0.00010\tTime 0.054 (0.077)\tData 0.000 (0.007)\tLoss 0.6764 (0.6710)\tPrec@1 68.750 (72.879)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 0.8208 (0.8208)\tPrec@1 69.000 (69.000)\n",
            "Test: [10/100]\tTime 0.044 (0.060)\tLoss 0.7860 (0.7914)\tPrec@1 70.000 (67.182)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 0.8463 (0.8040)\tPrec@1 68.000 (66.952)\n",
            "Test: [30/100]\tTime 0.038 (0.042)\tLoss 0.8295 (0.8154)\tPrec@1 65.000 (66.194)\n",
            "Test: [40/100]\tTime 0.041 (0.040)\tLoss 0.8324 (0.8151)\tPrec@1 66.000 (66.195)\n",
            "Test: [50/100]\tTime 0.021 (0.038)\tLoss 0.7559 (0.8103)\tPrec@1 72.000 (66.608)\n",
            "Test: [60/100]\tTime 0.027 (0.037)\tLoss 0.9331 (0.8156)\tPrec@1 60.000 (66.262)\n",
            "Test: [70/100]\tTime 0.031 (0.035)\tLoss 0.7475 (0.8129)\tPrec@1 69.000 (66.479)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 0.6869 (0.8108)\tPrec@1 70.000 (66.605)\n",
            "Test: [90/100]\tTime 0.053 (0.035)\tLoss 0.9684 (0.8116)\tPrec@1 60.000 (66.582)\n",
            "val Results: Prec@1 66.770 Loss 0.80743\n",
            "Best Prec@1: 66.870\n",
            "\n",
            "Epoch: [170][0/97], lr: 0.00010\tTime 0.497 (0.497)\tData 0.335 (0.335)\tLoss 0.6116 (0.6116)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [170][10/97], lr: 0.00010\tTime 0.080 (0.117)\tData 0.007 (0.034)\tLoss 0.8182 (0.6580)\tPrec@1 64.062 (73.864)\n",
            "Epoch: [170][20/97], lr: 0.00010\tTime 0.078 (0.094)\tData 0.007 (0.018)\tLoss 0.5836 (0.6488)\tPrec@1 76.562 (74.182)\n",
            "Epoch: [170][30/97], lr: 0.00010\tTime 0.062 (0.087)\tData 0.000 (0.013)\tLoss 0.7099 (0.6605)\tPrec@1 71.875 (73.513)\n",
            "Epoch: [170][40/97], lr: 0.00010\tTime 0.067 (0.083)\tData 0.000 (0.010)\tLoss 0.7069 (0.6626)\tPrec@1 72.656 (73.399)\n",
            "Epoch: [170][50/97], lr: 0.00010\tTime 0.063 (0.081)\tData 0.000 (0.009)\tLoss 0.6550 (0.6562)\tPrec@1 71.094 (73.713)\n",
            "Epoch: [170][60/97], lr: 0.00010\tTime 0.064 (0.080)\tData 0.000 (0.008)\tLoss 0.7032 (0.6599)\tPrec@1 69.531 (73.540)\n",
            "Epoch: [170][70/97], lr: 0.00010\tTime 0.065 (0.079)\tData 0.000 (0.007)\tLoss 0.7421 (0.6661)\tPrec@1 69.531 (73.228)\n",
            "Epoch: [170][80/97], lr: 0.00010\tTime 0.075 (0.078)\tData 0.000 (0.006)\tLoss 0.7569 (0.6685)\tPrec@1 71.094 (73.129)\n",
            "Epoch: [170][90/97], lr: 0.00010\tTime 0.052 (0.076)\tData 0.000 (0.006)\tLoss 0.7294 (0.6651)\tPrec@1 61.719 (73.154)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 0.8654 (0.8654)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.048 (0.060)\tLoss 0.7979 (0.7933)\tPrec@1 67.000 (67.636)\n",
            "Test: [20/100]\tTime 0.031 (0.047)\tLoss 0.8537 (0.8006)\tPrec@1 68.000 (67.714)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 0.8349 (0.8122)\tPrec@1 61.000 (66.613)\n",
            "Test: [40/100]\tTime 0.021 (0.039)\tLoss 0.7586 (0.8094)\tPrec@1 68.000 (66.610)\n",
            "Test: [50/100]\tTime 0.024 (0.038)\tLoss 0.8358 (0.8075)\tPrec@1 68.000 (66.784)\n",
            "Test: [60/100]\tTime 0.032 (0.037)\tLoss 0.8681 (0.8124)\tPrec@1 65.000 (66.803)\n",
            "Test: [70/100]\tTime 0.041 (0.036)\tLoss 0.7219 (0.8093)\tPrec@1 70.000 (67.000)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.7461 (0.8080)\tPrec@1 66.000 (66.988)\n",
            "Test: [90/100]\tTime 0.025 (0.035)\tLoss 0.9301 (0.8098)\tPrec@1 61.000 (66.846)\n",
            "val Results: Prec@1 67.070 Loss 0.80344\n",
            "Best Prec@1: 67.070\n",
            "\n",
            "Epoch: [171][0/97], lr: 0.00010\tTime 0.472 (0.472)\tData 0.330 (0.330)\tLoss 0.5374 (0.5374)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [171][10/97], lr: 0.00010\tTime 0.070 (0.114)\tData 0.000 (0.033)\tLoss 0.6386 (0.6133)\tPrec@1 73.438 (74.716)\n",
            "Epoch: [171][20/97], lr: 0.00010\tTime 0.062 (0.094)\tData 0.000 (0.020)\tLoss 0.7060 (0.6581)\tPrec@1 71.875 (73.103)\n",
            "Epoch: [171][30/97], lr: 0.00010\tTime 0.074 (0.088)\tData 0.007 (0.014)\tLoss 0.6267 (0.6515)\tPrec@1 75.000 (73.034)\n",
            "Epoch: [171][40/97], lr: 0.00010\tTime 0.065 (0.084)\tData 0.005 (0.012)\tLoss 0.6409 (0.6536)\tPrec@1 74.219 (72.828)\n",
            "Epoch: [171][50/97], lr: 0.00010\tTime 0.071 (0.081)\tData 0.001 (0.010)\tLoss 0.6251 (0.6596)\tPrec@1 73.438 (72.718)\n",
            "Epoch: [171][60/97], lr: 0.00010\tTime 0.088 (0.080)\tData 0.006 (0.009)\tLoss 0.8361 (0.6632)\tPrec@1 61.719 (72.592)\n",
            "Epoch: [171][70/97], lr: 0.00010\tTime 0.069 (0.078)\tData 0.000 (0.008)\tLoss 0.7581 (0.6674)\tPrec@1 67.969 (72.513)\n",
            "Epoch: [171][80/97], lr: 0.00010\tTime 0.062 (0.078)\tData 0.000 (0.008)\tLoss 0.5809 (0.6680)\tPrec@1 74.219 (72.550)\n",
            "Epoch: [171][90/97], lr: 0.00010\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.6900 (0.6666)\tPrec@1 71.875 (72.639)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 0.8220 (0.8220)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.023 (0.060)\tLoss 0.7395 (0.7837)\tPrec@1 68.000 (67.545)\n",
            "Test: [20/100]\tTime 0.027 (0.046)\tLoss 0.8029 (0.7920)\tPrec@1 69.000 (67.381)\n",
            "Test: [30/100]\tTime 0.024 (0.042)\tLoss 0.8083 (0.8031)\tPrec@1 66.000 (66.871)\n",
            "Test: [40/100]\tTime 0.024 (0.040)\tLoss 0.7866 (0.8043)\tPrec@1 70.000 (66.537)\n",
            "Test: [50/100]\tTime 0.060 (0.038)\tLoss 0.7915 (0.7989)\tPrec@1 65.000 (66.902)\n",
            "Test: [60/100]\tTime 0.030 (0.037)\tLoss 0.9410 (0.8056)\tPrec@1 57.000 (66.672)\n",
            "Test: [70/100]\tTime 0.035 (0.036)\tLoss 0.6615 (0.8047)\tPrec@1 72.000 (66.718)\n",
            "Test: [80/100]\tTime 0.044 (0.035)\tLoss 0.7257 (0.8038)\tPrec@1 68.000 (66.691)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 0.9326 (0.8042)\tPrec@1 61.000 (66.681)\n",
            "val Results: Prec@1 67.070 Loss 0.79922\n",
            "Best Prec@1: 67.070\n",
            "\n",
            "Epoch: [172][0/97], lr: 0.00010\tTime 0.555 (0.555)\tData 0.349 (0.349)\tLoss 0.5628 (0.5628)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [172][10/97], lr: 0.00010\tTime 0.063 (0.115)\tData 0.000 (0.033)\tLoss 0.6532 (0.6367)\tPrec@1 69.531 (74.858)\n",
            "Epoch: [172][20/97], lr: 0.00010\tTime 0.062 (0.094)\tData 0.000 (0.019)\tLoss 0.6582 (0.6642)\tPrec@1 75.000 (73.586)\n",
            "Epoch: [172][30/97], lr: 0.00010\tTime 0.059 (0.086)\tData 0.000 (0.013)\tLoss 0.6286 (0.6622)\tPrec@1 74.219 (73.614)\n",
            "Epoch: [172][40/97], lr: 0.00010\tTime 0.064 (0.082)\tData 0.000 (0.010)\tLoss 0.6221 (0.6557)\tPrec@1 75.000 (74.009)\n",
            "Epoch: [172][50/97], lr: 0.00010\tTime 0.062 (0.079)\tData 0.000 (0.008)\tLoss 0.7081 (0.6600)\tPrec@1 68.750 (73.882)\n",
            "Epoch: [172][60/97], lr: 0.00010\tTime 0.065 (0.078)\tData 0.000 (0.007)\tLoss 0.5854 (0.6614)\tPrec@1 75.000 (73.668)\n",
            "Epoch: [172][70/97], lr: 0.00010\tTime 0.062 (0.076)\tData 0.000 (0.007)\tLoss 0.6637 (0.6612)\tPrec@1 78.125 (73.669)\n",
            "Epoch: [172][80/97], lr: 0.00010\tTime 0.065 (0.076)\tData 0.000 (0.006)\tLoss 0.5827 (0.6619)\tPrec@1 77.344 (73.621)\n",
            "Epoch: [172][90/97], lr: 0.00010\tTime 0.055 (0.075)\tData 0.000 (0.006)\tLoss 0.6800 (0.6596)\tPrec@1 71.094 (73.704)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 0.8282 (0.8282)\tPrec@1 70.000 (70.000)\n",
            "Test: [10/100]\tTime 0.032 (0.060)\tLoss 0.7266 (0.7910)\tPrec@1 69.000 (68.091)\n",
            "Test: [20/100]\tTime 0.024 (0.047)\tLoss 0.8422 (0.7937)\tPrec@1 66.000 (67.762)\n",
            "Test: [30/100]\tTime 0.027 (0.042)\tLoss 0.7887 (0.7979)\tPrec@1 64.000 (67.161)\n",
            "Test: [40/100]\tTime 0.041 (0.040)\tLoss 0.7678 (0.7950)\tPrec@1 69.000 (67.098)\n",
            "Test: [50/100]\tTime 0.024 (0.038)\tLoss 0.8703 (0.7956)\tPrec@1 67.000 (67.039)\n",
            "Test: [60/100]\tTime 0.031 (0.037)\tLoss 0.9071 (0.8029)\tPrec@1 63.000 (66.689)\n",
            "Test: [70/100]\tTime 0.033 (0.037)\tLoss 0.7459 (0.8018)\tPrec@1 69.000 (66.901)\n",
            "Test: [80/100]\tTime 0.026 (0.036)\tLoss 0.6951 (0.7981)\tPrec@1 71.000 (66.951)\n",
            "Test: [90/100]\tTime 0.021 (0.036)\tLoss 0.9906 (0.8006)\tPrec@1 59.000 (66.879)\n",
            "val Results: Prec@1 67.130 Loss 0.79498\n",
            "Best Prec@1: 67.130\n",
            "\n",
            "Epoch: [173][0/97], lr: 0.00010\tTime 0.543 (0.543)\tData 0.408 (0.408)\tLoss 0.6139 (0.6139)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [173][10/97], lr: 0.00010\tTime 0.071 (0.117)\tData 0.006 (0.040)\tLoss 0.6178 (0.6460)\tPrec@1 77.344 (74.219)\n",
            "Epoch: [173][20/97], lr: 0.00010\tTime 0.067 (0.095)\tData 0.006 (0.023)\tLoss 0.7443 (0.6542)\tPrec@1 71.094 (73.400)\n",
            "Epoch: [173][30/97], lr: 0.00010\tTime 0.065 (0.087)\tData 0.000 (0.016)\tLoss 0.6573 (0.6569)\tPrec@1 71.875 (73.185)\n",
            "Epoch: [173][40/97], lr: 0.00010\tTime 0.089 (0.083)\tData 0.000 (0.013)\tLoss 0.6750 (0.6584)\tPrec@1 77.344 (73.209)\n",
            "Epoch: [173][50/97], lr: 0.00010\tTime 0.084 (0.081)\tData 0.000 (0.010)\tLoss 0.7149 (0.6540)\tPrec@1 69.531 (73.468)\n",
            "Epoch: [173][60/97], lr: 0.00010\tTime 0.059 (0.079)\tData 0.000 (0.009)\tLoss 0.5914 (0.6594)\tPrec@1 78.125 (73.412)\n",
            "Epoch: [173][70/97], lr: 0.00010\tTime 0.116 (0.081)\tData 0.000 (0.008)\tLoss 0.5904 (0.6553)\tPrec@1 75.781 (73.559)\n",
            "Epoch: [173][80/97], lr: 0.00010\tTime 0.082 (0.081)\tData 0.017 (0.008)\tLoss 0.6694 (0.6562)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [173][90/97], lr: 0.00010\tTime 0.055 (0.081)\tData 0.000 (0.007)\tLoss 0.6660 (0.6557)\tPrec@1 70.312 (73.455)\n",
            "Test: [0/100]\tTime 0.379 (0.379)\tLoss 0.8065 (0.8065)\tPrec@1 70.000 (70.000)\n",
            "Test: [10/100]\tTime 0.036 (0.068)\tLoss 0.7516 (0.7808)\tPrec@1 72.000 (68.364)\n",
            "Test: [20/100]\tTime 0.032 (0.053)\tLoss 0.8131 (0.8010)\tPrec@1 72.000 (68.286)\n",
            "Test: [30/100]\tTime 0.040 (0.046)\tLoss 0.9023 (0.8125)\tPrec@1 63.000 (66.806)\n",
            "Test: [40/100]\tTime 0.023 (0.042)\tLoss 0.7495 (0.8069)\tPrec@1 67.000 (66.756)\n",
            "Test: [50/100]\tTime 0.025 (0.040)\tLoss 0.8134 (0.8069)\tPrec@1 67.000 (66.804)\n",
            "Test: [60/100]\tTime 0.021 (0.039)\tLoss 0.9688 (0.8117)\tPrec@1 60.000 (66.689)\n",
            "Test: [70/100]\tTime 0.035 (0.038)\tLoss 0.7517 (0.8127)\tPrec@1 70.000 (66.775)\n",
            "Test: [80/100]\tTime 0.033 (0.038)\tLoss 0.7233 (0.8108)\tPrec@1 70.000 (66.840)\n",
            "Test: [90/100]\tTime 0.021 (0.037)\tLoss 0.9070 (0.8097)\tPrec@1 67.000 (66.989)\n",
            "val Results: Prec@1 67.250 Loss 0.80314\n",
            "Best Prec@1: 67.250\n",
            "\n",
            "Epoch: [174][0/97], lr: 0.00010\tTime 0.531 (0.531)\tData 0.334 (0.334)\tLoss 0.6792 (0.6792)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [174][10/97], lr: 0.00010\tTime 0.066 (0.116)\tData 0.000 (0.033)\tLoss 0.6652 (0.6658)\tPrec@1 76.562 (73.366)\n",
            "Epoch: [174][20/97], lr: 0.00010\tTime 0.066 (0.095)\tData 0.000 (0.019)\tLoss 0.6687 (0.6783)\tPrec@1 71.094 (72.842)\n",
            "Epoch: [174][30/97], lr: 0.00010\tTime 0.072 (0.088)\tData 0.000 (0.014)\tLoss 0.7096 (0.6711)\tPrec@1 71.875 (73.286)\n",
            "Epoch: [174][40/97], lr: 0.00010\tTime 0.061 (0.083)\tData 0.001 (0.011)\tLoss 0.6662 (0.6750)\tPrec@1 73.438 (72.809)\n",
            "Epoch: [174][50/97], lr: 0.00010\tTime 0.074 (0.080)\tData 0.006 (0.009)\tLoss 0.5886 (0.6706)\tPrec@1 75.781 (72.825)\n",
            "Epoch: [174][60/97], lr: 0.00010\tTime 0.061 (0.079)\tData 0.000 (0.008)\tLoss 0.7150 (0.6589)\tPrec@1 69.531 (73.297)\n",
            "Epoch: [174][70/97], lr: 0.00010\tTime 0.073 (0.078)\tData 0.010 (0.007)\tLoss 0.6664 (0.6632)\tPrec@1 71.875 (73.019)\n",
            "Epoch: [174][80/97], lr: 0.00010\tTime 0.067 (0.077)\tData 0.000 (0.007)\tLoss 0.6398 (0.6600)\tPrec@1 71.875 (73.061)\n",
            "Epoch: [174][90/97], lr: 0.00010\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 0.6331 (0.6598)\tPrec@1 74.219 (73.137)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 0.8344 (0.8344)\tPrec@1 70.000 (70.000)\n",
            "Test: [10/100]\tTime 0.021 (0.058)\tLoss 0.7633 (0.7967)\tPrec@1 68.000 (67.000)\n",
            "Test: [20/100]\tTime 0.023 (0.054)\tLoss 0.8050 (0.7964)\tPrec@1 70.000 (67.524)\n",
            "Test: [30/100]\tTime 0.022 (0.048)\tLoss 0.8200 (0.8052)\tPrec@1 64.000 (66.806)\n",
            "Test: [40/100]\tTime 0.022 (0.045)\tLoss 0.8330 (0.8048)\tPrec@1 68.000 (66.707)\n",
            "Test: [50/100]\tTime 0.041 (0.044)\tLoss 0.8422 (0.8054)\tPrec@1 62.000 (66.824)\n",
            "Test: [60/100]\tTime 0.036 (0.042)\tLoss 0.9662 (0.8116)\tPrec@1 57.000 (66.770)\n",
            "Test: [70/100]\tTime 0.022 (0.041)\tLoss 0.6847 (0.8077)\tPrec@1 72.000 (67.028)\n",
            "Test: [80/100]\tTime 0.042 (0.041)\tLoss 0.7229 (0.8061)\tPrec@1 71.000 (67.037)\n",
            "Test: [90/100]\tTime 0.023 (0.040)\tLoss 0.9789 (0.8067)\tPrec@1 59.000 (66.901)\n",
            "val Results: Prec@1 67.420 Loss 0.79927\n",
            "Best Prec@1: 67.420\n",
            "\n",
            "Epoch: [175][0/97], lr: 0.00010\tTime 0.506 (0.506)\tData 0.357 (0.357)\tLoss 0.5050 (0.5050)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [175][10/97], lr: 0.00010\tTime 0.082 (0.119)\tData 0.000 (0.034)\tLoss 0.5658 (0.6328)\tPrec@1 78.125 (75.142)\n",
            "Epoch: [175][20/97], lr: 0.00010\tTime 0.071 (0.097)\tData 0.010 (0.019)\tLoss 0.5916 (0.6325)\tPrec@1 74.219 (74.479)\n",
            "Epoch: [175][30/97], lr: 0.00010\tTime 0.059 (0.088)\tData 0.000 (0.014)\tLoss 0.6627 (0.6307)\tPrec@1 71.094 (74.294)\n",
            "Epoch: [175][40/97], lr: 0.00010\tTime 0.064 (0.084)\tData 0.001 (0.011)\tLoss 0.7122 (0.6426)\tPrec@1 71.094 (73.990)\n",
            "Epoch: [175][50/97], lr: 0.00010\tTime 0.068 (0.081)\tData 0.000 (0.010)\tLoss 0.5883 (0.6412)\tPrec@1 80.469 (74.326)\n",
            "Epoch: [175][60/97], lr: 0.00010\tTime 0.064 (0.079)\tData 0.000 (0.009)\tLoss 0.7046 (0.6470)\tPrec@1 73.438 (74.078)\n",
            "Epoch: [175][70/97], lr: 0.00010\tTime 0.068 (0.078)\tData 0.007 (0.008)\tLoss 0.7085 (0.6472)\tPrec@1 75.781 (74.186)\n",
            "Epoch: [175][80/97], lr: 0.00010\tTime 0.069 (0.077)\tData 0.000 (0.007)\tLoss 0.6340 (0.6530)\tPrec@1 71.094 (73.843)\n",
            "Epoch: [175][90/97], lr: 0.00010\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 0.7572 (0.6534)\tPrec@1 71.875 (73.815)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 0.8564 (0.8564)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.046 (0.060)\tLoss 0.7365 (0.7987)\tPrec@1 68.000 (66.545)\n",
            "Test: [20/100]\tTime 0.028 (0.046)\tLoss 0.8037 (0.7916)\tPrec@1 70.000 (67.333)\n",
            "Test: [30/100]\tTime 0.023 (0.041)\tLoss 0.9281 (0.8039)\tPrec@1 58.000 (66.226)\n",
            "Test: [40/100]\tTime 0.024 (0.039)\tLoss 0.8094 (0.8036)\tPrec@1 72.000 (65.976)\n",
            "Test: [50/100]\tTime 0.049 (0.038)\tLoss 0.7555 (0.8031)\tPrec@1 73.000 (66.392)\n",
            "Test: [60/100]\tTime 0.033 (0.036)\tLoss 0.9268 (0.8088)\tPrec@1 63.000 (66.279)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 0.6994 (0.8071)\tPrec@1 70.000 (66.493)\n",
            "Test: [80/100]\tTime 0.041 (0.036)\tLoss 0.7316 (0.8048)\tPrec@1 70.000 (66.580)\n",
            "Test: [90/100]\tTime 0.036 (0.035)\tLoss 0.9741 (0.8071)\tPrec@1 63.000 (66.560)\n",
            "val Results: Prec@1 66.880 Loss 0.80095\n",
            "Best Prec@1: 67.420\n",
            "\n",
            "Epoch: [176][0/97], lr: 0.00010\tTime 0.551 (0.551)\tData 0.381 (0.381)\tLoss 0.6345 (0.6345)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [176][10/97], lr: 0.00010\tTime 0.066 (0.117)\tData 0.000 (0.036)\tLoss 0.7320 (0.6589)\tPrec@1 67.188 (72.656)\n",
            "Epoch: [176][20/97], lr: 0.00010\tTime 0.071 (0.095)\tData 0.000 (0.021)\tLoss 0.5920 (0.6693)\tPrec@1 72.656 (72.135)\n",
            "Epoch: [176][30/97], lr: 0.00010\tTime 0.076 (0.089)\tData 0.000 (0.015)\tLoss 0.6349 (0.6665)\tPrec@1 69.531 (72.253)\n",
            "Epoch: [176][40/97], lr: 0.00010\tTime 0.070 (0.084)\tData 0.005 (0.012)\tLoss 0.5792 (0.6620)\tPrec@1 78.906 (72.828)\n",
            "Epoch: [176][50/97], lr: 0.00010\tTime 0.072 (0.082)\tData 0.007 (0.011)\tLoss 0.6013 (0.6590)\tPrec@1 72.656 (72.993)\n",
            "Epoch: [176][60/97], lr: 0.00010\tTime 0.094 (0.086)\tData 0.000 (0.009)\tLoss 0.7436 (0.6559)\tPrec@1 71.875 (73.207)\n",
            "Epoch: [176][70/97], lr: 0.00010\tTime 0.117 (0.090)\tData 0.006 (0.009)\tLoss 0.6857 (0.6507)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [176][80/97], lr: 0.00010\tTime 0.116 (0.093)\tData 0.006 (0.008)\tLoss 0.7922 (0.6509)\tPrec@1 71.875 (73.486)\n",
            "Epoch: [176][90/97], lr: 0.00010\tTime 0.055 (0.092)\tData 0.000 (0.008)\tLoss 0.5537 (0.6523)\tPrec@1 79.688 (73.515)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 0.8269 (0.8269)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.033 (0.059)\tLoss 0.7762 (0.7853)\tPrec@1 63.000 (67.182)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 0.8134 (0.7913)\tPrec@1 69.000 (67.762)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.8423 (0.8030)\tPrec@1 64.000 (67.290)\n",
            "Test: [40/100]\tTime 0.022 (0.040)\tLoss 0.8101 (0.7989)\tPrec@1 70.000 (67.293)\n",
            "Test: [50/100]\tTime 0.035 (0.039)\tLoss 0.8335 (0.7970)\tPrec@1 64.000 (67.471)\n",
            "Test: [60/100]\tTime 0.028 (0.037)\tLoss 0.9984 (0.8044)\tPrec@1 59.000 (67.344)\n",
            "Test: [70/100]\tTime 0.049 (0.037)\tLoss 0.7425 (0.8013)\tPrec@1 70.000 (67.521)\n",
            "Test: [80/100]\tTime 0.019 (0.036)\tLoss 0.7572 (0.8032)\tPrec@1 69.000 (67.457)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 0.9609 (0.8041)\tPrec@1 63.000 (67.473)\n",
            "val Results: Prec@1 67.750 Loss 0.79737\n",
            "Best Prec@1: 67.750\n",
            "\n",
            "Epoch: [177][0/97], lr: 0.00010\tTime 0.474 (0.474)\tData 0.282 (0.282)\tLoss 0.5856 (0.5856)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [177][10/97], lr: 0.00010\tTime 0.065 (0.117)\tData 0.000 (0.031)\tLoss 0.5980 (0.6482)\tPrec@1 73.438 (72.372)\n",
            "Epoch: [177][20/97], lr: 0.00010\tTime 0.084 (0.098)\tData 0.000 (0.017)\tLoss 0.7234 (0.6430)\tPrec@1 66.406 (73.251)\n",
            "Epoch: [177][30/97], lr: 0.00010\tTime 0.062 (0.089)\tData 0.002 (0.012)\tLoss 0.7509 (0.6419)\tPrec@1 68.750 (74.042)\n",
            "Epoch: [177][40/97], lr: 0.00010\tTime 0.065 (0.085)\tData 0.003 (0.010)\tLoss 0.5356 (0.6522)\tPrec@1 78.125 (73.571)\n",
            "Epoch: [177][50/97], lr: 0.00010\tTime 0.058 (0.082)\tData 0.000 (0.009)\tLoss 0.6673 (0.6534)\tPrec@1 71.875 (73.514)\n",
            "Epoch: [177][60/97], lr: 0.00010\tTime 0.068 (0.081)\tData 0.000 (0.008)\tLoss 0.6325 (0.6549)\tPrec@1 75.000 (73.514)\n",
            "Epoch: [177][70/97], lr: 0.00010\tTime 0.080 (0.080)\tData 0.005 (0.007)\tLoss 0.7172 (0.6551)\tPrec@1 71.875 (73.504)\n",
            "Epoch: [177][80/97], lr: 0.00010\tTime 0.073 (0.079)\tData 0.000 (0.007)\tLoss 0.7333 (0.6559)\tPrec@1 70.312 (73.553)\n",
            "Epoch: [177][90/97], lr: 0.00010\tTime 0.055 (0.078)\tData 0.000 (0.006)\tLoss 0.7574 (0.6565)\tPrec@1 71.094 (73.575)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 0.8407 (0.8407)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.063 (0.060)\tLoss 0.7134 (0.7764)\tPrec@1 67.000 (67.364)\n",
            "Test: [20/100]\tTime 0.034 (0.046)\tLoss 0.8306 (0.7763)\tPrec@1 71.000 (67.905)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 0.7773 (0.7864)\tPrec@1 66.000 (67.355)\n",
            "Test: [40/100]\tTime 0.041 (0.039)\tLoss 0.7843 (0.7886)\tPrec@1 68.000 (67.439)\n",
            "Test: [50/100]\tTime 0.027 (0.037)\tLoss 0.7880 (0.7899)\tPrec@1 67.000 (67.451)\n",
            "Test: [60/100]\tTime 0.028 (0.036)\tLoss 0.9406 (0.7955)\tPrec@1 66.000 (67.607)\n",
            "Test: [70/100]\tTime 0.023 (0.035)\tLoss 0.7430 (0.7954)\tPrec@1 69.000 (67.662)\n",
            "Test: [80/100]\tTime 0.022 (0.035)\tLoss 0.7332 (0.7943)\tPrec@1 73.000 (67.753)\n",
            "Test: [90/100]\tTime 0.032 (0.035)\tLoss 0.9781 (0.7956)\tPrec@1 62.000 (67.802)\n",
            "val Results: Prec@1 68.070 Loss 0.78933\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [178][0/97], lr: 0.00010\tTime 0.547 (0.547)\tData 0.370 (0.370)\tLoss 0.6564 (0.6564)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [178][10/97], lr: 0.00010\tTime 0.061 (0.115)\tData 0.000 (0.036)\tLoss 0.5975 (0.6366)\tPrec@1 75.000 (74.574)\n",
            "Epoch: [178][20/97], lr: 0.00010\tTime 0.067 (0.095)\tData 0.000 (0.019)\tLoss 0.7561 (0.6446)\tPrec@1 73.438 (74.814)\n",
            "Epoch: [178][30/97], lr: 0.00010\tTime 0.061 (0.087)\tData 0.000 (0.013)\tLoss 0.5725 (0.6399)\tPrec@1 77.344 (74.824)\n",
            "Epoch: [178][40/97], lr: 0.00010\tTime 0.078 (0.083)\tData 0.007 (0.010)\tLoss 0.6991 (0.6497)\tPrec@1 71.875 (74.066)\n",
            "Epoch: [178][50/97], lr: 0.00010\tTime 0.076 (0.081)\tData 0.007 (0.009)\tLoss 0.6428 (0.6436)\tPrec@1 71.875 (74.449)\n",
            "Epoch: [178][60/97], lr: 0.00010\tTime 0.063 (0.080)\tData 0.001 (0.008)\tLoss 0.5879 (0.6495)\tPrec@1 79.688 (74.078)\n",
            "Epoch: [178][70/97], lr: 0.00010\tTime 0.066 (0.079)\tData 0.000 (0.008)\tLoss 0.6296 (0.6470)\tPrec@1 75.781 (74.296)\n",
            "Epoch: [178][80/97], lr: 0.00010\tTime 0.079 (0.078)\tData 0.007 (0.007)\tLoss 0.6799 (0.6511)\tPrec@1 72.656 (74.035)\n",
            "Epoch: [178][90/97], lr: 0.00010\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.7061 (0.6492)\tPrec@1 71.094 (74.047)\n",
            "Test: [0/100]\tTime 0.262 (0.262)\tLoss 0.8446 (0.8446)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 0.7160 (0.7774)\tPrec@1 72.000 (67.455)\n",
            "Test: [20/100]\tTime 0.023 (0.047)\tLoss 0.8153 (0.7798)\tPrec@1 68.000 (68.524)\n",
            "Test: [30/100]\tTime 0.038 (0.042)\tLoss 0.8305 (0.7894)\tPrec@1 64.000 (67.677)\n",
            "Test: [40/100]\tTime 0.030 (0.040)\tLoss 0.7747 (0.7883)\tPrec@1 70.000 (67.854)\n",
            "Test: [50/100]\tTime 0.034 (0.038)\tLoss 0.8554 (0.7910)\tPrec@1 66.000 (67.863)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 0.9018 (0.7952)\tPrec@1 64.000 (67.607)\n",
            "Test: [70/100]\tTime 0.051 (0.037)\tLoss 0.7075 (0.7948)\tPrec@1 73.000 (67.676)\n",
            "Test: [80/100]\tTime 0.036 (0.036)\tLoss 0.7722 (0.7943)\tPrec@1 67.000 (67.580)\n",
            "Test: [90/100]\tTime 0.029 (0.035)\tLoss 0.8846 (0.7935)\tPrec@1 64.000 (67.670)\n",
            "val Results: Prec@1 67.900 Loss 0.78965\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [179][0/97], lr: 0.00010\tTime 0.500 (0.500)\tData 0.304 (0.304)\tLoss 0.5762 (0.5762)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [179][10/97], lr: 0.00010\tTime 0.079 (0.119)\tData 0.000 (0.031)\tLoss 0.6744 (0.6235)\tPrec@1 75.000 (76.065)\n",
            "Epoch: [179][20/97], lr: 0.00010\tTime 0.097 (0.095)\tData 0.000 (0.016)\tLoss 0.6801 (0.6459)\tPrec@1 71.094 (74.368)\n",
            "Epoch: [179][30/97], lr: 0.00010\tTime 0.063 (0.087)\tData 0.000 (0.012)\tLoss 0.6687 (0.6514)\tPrec@1 73.438 (73.816)\n",
            "Epoch: [179][40/97], lr: 0.00010\tTime 0.082 (0.084)\tData 0.009 (0.010)\tLoss 0.6083 (0.6474)\tPrec@1 74.219 (73.990)\n",
            "Epoch: [179][50/97], lr: 0.00010\tTime 0.065 (0.081)\tData 0.000 (0.008)\tLoss 0.6095 (0.6467)\tPrec@1 75.781 (74.050)\n",
            "Epoch: [179][60/97], lr: 0.00010\tTime 0.062 (0.079)\tData 0.000 (0.007)\tLoss 0.5696 (0.6467)\tPrec@1 78.906 (73.899)\n",
            "Epoch: [179][70/97], lr: 0.00010\tTime 0.066 (0.078)\tData 0.000 (0.006)\tLoss 0.6842 (0.6530)\tPrec@1 73.438 (73.801)\n",
            "Epoch: [179][80/97], lr: 0.00010\tTime 0.065 (0.077)\tData 0.000 (0.005)\tLoss 0.5756 (0.6519)\tPrec@1 77.344 (74.026)\n",
            "Epoch: [179][90/97], lr: 0.00010\tTime 0.054 (0.076)\tData 0.000 (0.005)\tLoss 0.6040 (0.6499)\tPrec@1 74.219 (74.064)\n",
            "Test: [0/100]\tTime 0.319 (0.319)\tLoss 0.8312 (0.8312)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.051 (0.060)\tLoss 0.6944 (0.7857)\tPrec@1 70.000 (67.273)\n",
            "Test: [20/100]\tTime 0.039 (0.046)\tLoss 0.8282 (0.7886)\tPrec@1 68.000 (67.143)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.7951 (0.7938)\tPrec@1 68.000 (67.097)\n",
            "Test: [40/100]\tTime 0.052 (0.038)\tLoss 0.7547 (0.7928)\tPrec@1 70.000 (67.171)\n",
            "Test: [50/100]\tTime 0.030 (0.037)\tLoss 0.8629 (0.7964)\tPrec@1 65.000 (67.176)\n",
            "Test: [60/100]\tTime 0.027 (0.035)\tLoss 0.9521 (0.7991)\tPrec@1 63.000 (67.262)\n",
            "Test: [70/100]\tTime 0.033 (0.035)\tLoss 0.7066 (0.7956)\tPrec@1 72.000 (67.549)\n",
            "Test: [80/100]\tTime 0.038 (0.035)\tLoss 0.7626 (0.7967)\tPrec@1 66.000 (67.444)\n",
            "Test: [90/100]\tTime 0.046 (0.035)\tLoss 0.9387 (0.7981)\tPrec@1 60.000 (67.418)\n",
            "val Results: Prec@1 67.710 Loss 0.79228\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [180][0/97], lr: 0.00000\tTime 0.606 (0.606)\tData 0.399 (0.399)\tLoss 0.6368 (0.6368)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [180][10/97], lr: 0.00000\tTime 0.064 (0.122)\tData 0.000 (0.038)\tLoss 0.5550 (0.6172)\tPrec@1 77.344 (75.568)\n",
            "Epoch: [180][20/97], lr: 0.00000\tTime 0.064 (0.100)\tData 0.001 (0.021)\tLoss 0.5543 (0.6291)\tPrec@1 82.031 (75.260)\n",
            "Epoch: [180][30/97], lr: 0.00000\tTime 0.078 (0.091)\tData 0.012 (0.015)\tLoss 0.6082 (0.6433)\tPrec@1 78.906 (74.546)\n",
            "Epoch: [180][40/97], lr: 0.00000\tTime 0.061 (0.085)\tData 0.000 (0.011)\tLoss 0.5872 (0.6414)\tPrec@1 72.656 (74.524)\n",
            "Epoch: [180][50/97], lr: 0.00000\tTime 0.070 (0.083)\tData 0.005 (0.010)\tLoss 0.6604 (0.6407)\tPrec@1 72.656 (74.494)\n",
            "Epoch: [180][60/97], lr: 0.00000\tTime 0.086 (0.082)\tData 0.003 (0.009)\tLoss 0.7260 (0.6460)\tPrec@1 69.531 (74.103)\n",
            "Epoch: [180][70/97], lr: 0.00000\tTime 0.060 (0.080)\tData 0.000 (0.008)\tLoss 0.5986 (0.6446)\tPrec@1 77.344 (74.054)\n",
            "Epoch: [180][80/97], lr: 0.00000\tTime 0.068 (0.079)\tData 0.000 (0.007)\tLoss 0.6521 (0.6447)\tPrec@1 74.219 (74.064)\n",
            "Epoch: [180][90/97], lr: 0.00000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.6486 (0.6429)\tPrec@1 77.344 (74.081)\n",
            "Test: [0/100]\tTime 0.255 (0.255)\tLoss 0.8114 (0.8114)\tPrec@1 73.000 (73.000)\n",
            "Test: [10/100]\tTime 0.047 (0.059)\tLoss 0.7664 (0.7885)\tPrec@1 67.000 (67.273)\n",
            "Test: [20/100]\tTime 0.030 (0.046)\tLoss 0.8212 (0.7932)\tPrec@1 68.000 (67.905)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 0.8908 (0.8070)\tPrec@1 63.000 (66.613)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 0.8211 (0.8064)\tPrec@1 72.000 (66.878)\n",
            "Test: [50/100]\tTime 0.030 (0.037)\tLoss 0.8222 (0.8067)\tPrec@1 69.000 (66.941)\n",
            "Test: [60/100]\tTime 0.028 (0.036)\tLoss 0.9589 (0.8108)\tPrec@1 57.000 (66.672)\n",
            "Test: [70/100]\tTime 0.024 (0.035)\tLoss 0.7064 (0.8062)\tPrec@1 73.000 (67.014)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 0.7470 (0.8053)\tPrec@1 70.000 (67.049)\n",
            "Test: [90/100]\tTime 0.045 (0.035)\tLoss 0.9245 (0.8047)\tPrec@1 59.000 (67.011)\n",
            "val Results: Prec@1 67.400 Loss 0.80052\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [181][0/97], lr: 0.00000\tTime 0.497 (0.497)\tData 0.327 (0.327)\tLoss 0.6141 (0.6141)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [181][10/97], lr: 0.00000\tTime 0.067 (0.116)\tData 0.004 (0.035)\tLoss 0.6831 (0.6840)\tPrec@1 73.438 (72.159)\n",
            "Epoch: [181][20/97], lr: 0.00000\tTime 0.062 (0.095)\tData 0.000 (0.019)\tLoss 0.7063 (0.6635)\tPrec@1 68.750 (73.363)\n",
            "Epoch: [181][30/97], lr: 0.00000\tTime 0.066 (0.087)\tData 0.004 (0.013)\tLoss 0.6949 (0.6606)\tPrec@1 73.438 (73.185)\n",
            "Epoch: [181][40/97], lr: 0.00000\tTime 0.073 (0.084)\tData 0.007 (0.011)\tLoss 0.6248 (0.6621)\tPrec@1 73.438 (73.342)\n",
            "Epoch: [181][50/97], lr: 0.00000\tTime 0.075 (0.082)\tData 0.006 (0.009)\tLoss 0.6152 (0.6612)\tPrec@1 75.781 (73.162)\n",
            "Epoch: [181][60/97], lr: 0.00000\tTime 0.064 (0.080)\tData 0.000 (0.008)\tLoss 0.5397 (0.6592)\tPrec@1 78.906 (73.105)\n",
            "Epoch: [181][70/97], lr: 0.00000\tTime 0.075 (0.079)\tData 0.005 (0.007)\tLoss 0.7733 (0.6577)\tPrec@1 68.750 (73.283)\n",
            "Epoch: [181][80/97], lr: 0.00000\tTime 0.079 (0.078)\tData 0.003 (0.007)\tLoss 0.5824 (0.6510)\tPrec@1 78.125 (73.563)\n",
            "Epoch: [181][90/97], lr: 0.00000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.6533 (0.6512)\tPrec@1 72.656 (73.626)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.8324 (0.8324)\tPrec@1 70.000 (70.000)\n",
            "Test: [10/100]\tTime 0.052 (0.059)\tLoss 0.7558 (0.7916)\tPrec@1 67.000 (67.636)\n",
            "Test: [20/100]\tTime 0.041 (0.047)\tLoss 0.8356 (0.7935)\tPrec@1 67.000 (67.429)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 0.8122 (0.7980)\tPrec@1 64.000 (66.677)\n",
            "Test: [40/100]\tTime 0.030 (0.039)\tLoss 0.8204 (0.7996)\tPrec@1 68.000 (66.585)\n",
            "Test: [50/100]\tTime 0.027 (0.037)\tLoss 0.8202 (0.7999)\tPrec@1 69.000 (66.941)\n",
            "Test: [60/100]\tTime 0.024 (0.036)\tLoss 0.9695 (0.8091)\tPrec@1 62.000 (66.770)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.7356 (0.8062)\tPrec@1 72.000 (67.085)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 0.7565 (0.8036)\tPrec@1 70.000 (67.210)\n",
            "Test: [90/100]\tTime 0.027 (0.035)\tLoss 0.8603 (0.8018)\tPrec@1 62.000 (67.253)\n",
            "val Results: Prec@1 67.520 Loss 0.79573\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [182][0/97], lr: 0.00000\tTime 0.540 (0.540)\tData 0.403 (0.403)\tLoss 0.6489 (0.6489)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [182][10/97], lr: 0.00000\tTime 0.067 (0.117)\tData 0.000 (0.039)\tLoss 0.7102 (0.6448)\tPrec@1 68.750 (73.722)\n",
            "Epoch: [182][20/97], lr: 0.00000\tTime 0.061 (0.095)\tData 0.000 (0.021)\tLoss 0.6090 (0.6442)\tPrec@1 75.000 (73.884)\n",
            "Epoch: [182][30/97], lr: 0.00000\tTime 0.080 (0.087)\tData 0.000 (0.015)\tLoss 0.6925 (0.6451)\tPrec@1 70.312 (73.942)\n",
            "Epoch: [182][40/97], lr: 0.00000\tTime 0.067 (0.084)\tData 0.000 (0.011)\tLoss 0.6962 (0.6508)\tPrec@1 71.094 (73.647)\n",
            "Epoch: [182][50/97], lr: 0.00000\tTime 0.060 (0.081)\tData 0.000 (0.009)\tLoss 0.5263 (0.6433)\tPrec@1 76.562 (73.958)\n",
            "Epoch: [182][60/97], lr: 0.00000\tTime 0.079 (0.080)\tData 0.007 (0.009)\tLoss 0.6761 (0.6453)\tPrec@1 72.656 (73.835)\n",
            "Epoch: [182][70/97], lr: 0.00000\tTime 0.072 (0.078)\tData 0.005 (0.008)\tLoss 0.6922 (0.6444)\tPrec@1 67.969 (73.955)\n",
            "Epoch: [182][80/97], lr: 0.00000\tTime 0.073 (0.077)\tData 0.006 (0.008)\tLoss 0.5940 (0.6408)\tPrec@1 75.000 (74.113)\n",
            "Epoch: [182][90/97], lr: 0.00000\tTime 0.057 (0.076)\tData 0.000 (0.007)\tLoss 0.5861 (0.6422)\tPrec@1 77.344 (74.124)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 0.8364 (0.8364)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.022 (0.062)\tLoss 0.7726 (0.7878)\tPrec@1 68.000 (68.273)\n",
            "Test: [20/100]\tTime 0.039 (0.047)\tLoss 0.8236 (0.7898)\tPrec@1 70.000 (69.000)\n",
            "Test: [30/100]\tTime 0.045 (0.042)\tLoss 0.8031 (0.7994)\tPrec@1 68.000 (67.516)\n",
            "Test: [40/100]\tTime 0.024 (0.040)\tLoss 0.7590 (0.7990)\tPrec@1 71.000 (67.415)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.8487 (0.7993)\tPrec@1 71.000 (67.431)\n",
            "Test: [60/100]\tTime 0.037 (0.037)\tLoss 0.9177 (0.8029)\tPrec@1 65.000 (67.295)\n",
            "Test: [70/100]\tTime 0.031 (0.036)\tLoss 0.6896 (0.8021)\tPrec@1 70.000 (67.296)\n",
            "Test: [80/100]\tTime 0.045 (0.036)\tLoss 0.7065 (0.8009)\tPrec@1 72.000 (67.457)\n",
            "Test: [90/100]\tTime 0.032 (0.035)\tLoss 0.9739 (0.8000)\tPrec@1 62.000 (67.495)\n",
            "val Results: Prec@1 67.730 Loss 0.79394\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [183][0/97], lr: 0.00000\tTime 0.509 (0.509)\tData 0.300 (0.300)\tLoss 0.6674 (0.6674)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [183][10/97], lr: 0.00000\tTime 0.084 (0.117)\tData 0.000 (0.029)\tLoss 0.5498 (0.6258)\tPrec@1 76.562 (75.284)\n",
            "Epoch: [183][20/97], lr: 0.00000\tTime 0.065 (0.095)\tData 0.003 (0.017)\tLoss 0.6010 (0.6479)\tPrec@1 73.438 (74.182)\n",
            "Epoch: [183][30/97], lr: 0.00000\tTime 0.068 (0.088)\tData 0.000 (0.012)\tLoss 0.5983 (0.6342)\tPrec@1 74.219 (74.572)\n",
            "Epoch: [183][40/97], lr: 0.00000\tTime 0.076 (0.084)\tData 0.000 (0.010)\tLoss 0.7564 (0.6403)\tPrec@1 66.406 (74.200)\n",
            "Epoch: [183][50/97], lr: 0.00000\tTime 0.064 (0.081)\tData 0.000 (0.008)\tLoss 0.7591 (0.6412)\tPrec@1 69.531 (74.203)\n",
            "Epoch: [183][60/97], lr: 0.00000\tTime 0.063 (0.080)\tData 0.000 (0.008)\tLoss 0.6811 (0.6446)\tPrec@1 71.875 (73.911)\n",
            "Epoch: [183][70/97], lr: 0.00000\tTime 0.065 (0.079)\tData 0.000 (0.007)\tLoss 0.6709 (0.6434)\tPrec@1 74.219 (73.977)\n",
            "Epoch: [183][80/97], lr: 0.00000\tTime 0.065 (0.078)\tData 0.000 (0.007)\tLoss 0.6812 (0.6441)\tPrec@1 71.094 (73.910)\n",
            "Epoch: [183][90/97], lr: 0.00000\tTime 0.055 (0.077)\tData 0.000 (0.006)\tLoss 0.6487 (0.6460)\tPrec@1 73.438 (73.918)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 0.8038 (0.8038)\tPrec@1 71.000 (71.000)\n",
            "Test: [10/100]\tTime 0.024 (0.061)\tLoss 0.7172 (0.7772)\tPrec@1 72.000 (68.000)\n",
            "Test: [20/100]\tTime 0.035 (0.047)\tLoss 0.8655 (0.7880)\tPrec@1 68.000 (68.429)\n",
            "Test: [30/100]\tTime 0.033 (0.041)\tLoss 0.8790 (0.7932)\tPrec@1 62.000 (67.484)\n",
            "Test: [40/100]\tTime 0.030 (0.039)\tLoss 0.7404 (0.7945)\tPrec@1 74.000 (67.659)\n",
            "Test: [50/100]\tTime 0.031 (0.037)\tLoss 0.8089 (0.7937)\tPrec@1 65.000 (67.725)\n",
            "Test: [60/100]\tTime 0.042 (0.037)\tLoss 0.9161 (0.7989)\tPrec@1 61.000 (67.656)\n",
            "Test: [70/100]\tTime 0.035 (0.036)\tLoss 0.7293 (0.7981)\tPrec@1 71.000 (67.704)\n",
            "Test: [80/100]\tTime 0.021 (0.035)\tLoss 0.7334 (0.7983)\tPrec@1 70.000 (67.790)\n",
            "Test: [90/100]\tTime 0.035 (0.035)\tLoss 1.0006 (0.8005)\tPrec@1 63.000 (67.604)\n",
            "val Results: Prec@1 67.970 Loss 0.79389\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [184][0/97], lr: 0.00000\tTime 0.543 (0.543)\tData 0.382 (0.382)\tLoss 0.6047 (0.6047)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [184][10/97], lr: 0.00000\tTime 0.079 (0.116)\tData 0.013 (0.038)\tLoss 0.7163 (0.6247)\tPrec@1 74.219 (75.710)\n",
            "Epoch: [184][20/97], lr: 0.00000\tTime 0.065 (0.093)\tData 0.002 (0.021)\tLoss 0.6811 (0.6432)\tPrec@1 71.875 (74.293)\n",
            "Epoch: [184][30/97], lr: 0.00000\tTime 0.066 (0.086)\tData 0.000 (0.015)\tLoss 0.7278 (0.6441)\tPrec@1 65.625 (74.345)\n",
            "Epoch: [184][40/97], lr: 0.00000\tTime 0.060 (0.083)\tData 0.000 (0.012)\tLoss 0.7205 (0.6528)\tPrec@1 70.312 (73.742)\n",
            "Epoch: [184][50/97], lr: 0.00000\tTime 0.071 (0.081)\tData 0.000 (0.011)\tLoss 0.6442 (0.6444)\tPrec@1 75.000 (74.173)\n",
            "Epoch: [184][60/97], lr: 0.00000\tTime 0.071 (0.079)\tData 0.010 (0.009)\tLoss 0.5129 (0.6403)\tPrec@1 81.250 (74.398)\n",
            "Epoch: [184][70/97], lr: 0.00000\tTime 0.071 (0.078)\tData 0.006 (0.009)\tLoss 0.5717 (0.6463)\tPrec@1 75.000 (74.109)\n",
            "Epoch: [184][80/97], lr: 0.00000\tTime 0.064 (0.077)\tData 0.000 (0.008)\tLoss 0.6703 (0.6495)\tPrec@1 71.875 (73.852)\n",
            "Epoch: [184][90/97], lr: 0.00000\tTime 0.056 (0.076)\tData 0.000 (0.007)\tLoss 0.7289 (0.6465)\tPrec@1 68.750 (73.978)\n",
            "Test: [0/100]\tTime 0.345 (0.345)\tLoss 0.8534 (0.8534)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.034 (0.058)\tLoss 0.7068 (0.7808)\tPrec@1 72.000 (68.364)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.8110 (0.7883)\tPrec@1 69.000 (68.714)\n",
            "Test: [30/100]\tTime 0.059 (0.042)\tLoss 0.7736 (0.7943)\tPrec@1 67.000 (67.484)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.8232 (0.7959)\tPrec@1 67.000 (67.634)\n",
            "Test: [50/100]\tTime 0.024 (0.037)\tLoss 0.8945 (0.7966)\tPrec@1 65.000 (67.608)\n",
            "Test: [60/100]\tTime 0.027 (0.036)\tLoss 0.8367 (0.8004)\tPrec@1 69.000 (67.869)\n",
            "Test: [70/100]\tTime 0.038 (0.036)\tLoss 0.7252 (0.7998)\tPrec@1 70.000 (67.817)\n",
            "Test: [80/100]\tTime 0.029 (0.035)\tLoss 0.7613 (0.8010)\tPrec@1 68.000 (67.877)\n",
            "Test: [90/100]\tTime 0.051 (0.034)\tLoss 0.9314 (0.8036)\tPrec@1 64.000 (67.747)\n",
            "val Results: Prec@1 68.000 Loss 0.79851\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [185][0/97], lr: 0.00000\tTime 0.524 (0.524)\tData 0.394 (0.394)\tLoss 0.4884 (0.4884)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [185][10/97], lr: 0.00000\tTime 0.063 (0.114)\tData 0.000 (0.039)\tLoss 0.5283 (0.6391)\tPrec@1 80.469 (74.148)\n",
            "Epoch: [185][20/97], lr: 0.00000\tTime 0.059 (0.092)\tData 0.000 (0.021)\tLoss 0.6442 (0.6422)\tPrec@1 76.562 (74.442)\n",
            "Epoch: [185][30/97], lr: 0.00000\tTime 0.063 (0.086)\tData 0.000 (0.015)\tLoss 0.5995 (0.6404)\tPrec@1 75.000 (74.219)\n",
            "Epoch: [185][40/97], lr: 0.00000\tTime 0.069 (0.083)\tData 0.000 (0.013)\tLoss 0.5858 (0.6457)\tPrec@1 76.562 (73.800)\n",
            "Epoch: [185][50/97], lr: 0.00000\tTime 0.075 (0.085)\tData 0.012 (0.011)\tLoss 0.6693 (0.6526)\tPrec@1 69.531 (73.330)\n",
            "Epoch: [185][60/97], lr: 0.00000\tTime 0.117 (0.085)\tData 0.000 (0.009)\tLoss 0.5916 (0.6490)\tPrec@1 78.125 (73.386)\n",
            "Epoch: [185][70/97], lr: 0.00000\tTime 0.067 (0.084)\tData 0.001 (0.008)\tLoss 0.6030 (0.6519)\tPrec@1 75.781 (73.228)\n",
            "Epoch: [185][80/97], lr: 0.00000\tTime 0.074 (0.083)\tData 0.000 (0.008)\tLoss 0.5947 (0.6500)\tPrec@1 74.219 (73.370)\n",
            "Epoch: [185][90/97], lr: 0.00000\tTime 0.053 (0.083)\tData 0.000 (0.007)\tLoss 0.6854 (0.6468)\tPrec@1 72.656 (73.558)\n",
            "Test: [0/100]\tTime 0.353 (0.353)\tLoss 0.8102 (0.8102)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.043 (0.062)\tLoss 0.7681 (0.7884)\tPrec@1 69.000 (66.727)\n",
            "Test: [20/100]\tTime 0.021 (0.047)\tLoss 0.7768 (0.7937)\tPrec@1 70.000 (67.429)\n",
            "Test: [30/100]\tTime 0.023 (0.043)\tLoss 0.9009 (0.8042)\tPrec@1 60.000 (66.355)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.8136 (0.8034)\tPrec@1 67.000 (66.610)\n",
            "Test: [50/100]\tTime 0.026 (0.038)\tLoss 0.7901 (0.7997)\tPrec@1 68.000 (67.020)\n",
            "Test: [60/100]\tTime 0.027 (0.037)\tLoss 0.9279 (0.8020)\tPrec@1 61.000 (66.902)\n",
            "Test: [70/100]\tTime 0.084 (0.037)\tLoss 0.7145 (0.8011)\tPrec@1 70.000 (67.014)\n",
            "Test: [80/100]\tTime 0.059 (0.038)\tLoss 0.7720 (0.8006)\tPrec@1 67.000 (67.284)\n",
            "Test: [90/100]\tTime 0.023 (0.038)\tLoss 0.9394 (0.8020)\tPrec@1 63.000 (67.242)\n",
            "val Results: Prec@1 67.480 Loss 0.79550\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [186][0/97], lr: 0.00000\tTime 0.516 (0.516)\tData 0.352 (0.352)\tLoss 0.6782 (0.6782)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [186][10/97], lr: 0.00000\tTime 0.070 (0.114)\tData 0.000 (0.034)\tLoss 0.6093 (0.6268)\tPrec@1 76.562 (75.000)\n",
            "Epoch: [186][20/97], lr: 0.00000\tTime 0.064 (0.092)\tData 0.000 (0.019)\tLoss 0.7030 (0.6387)\tPrec@1 67.188 (74.070)\n",
            "Epoch: [186][30/97], lr: 0.00000\tTime 0.075 (0.086)\tData 0.007 (0.013)\tLoss 0.6469 (0.6434)\tPrec@1 71.875 (73.538)\n",
            "Epoch: [186][40/97], lr: 0.00000\tTime 0.080 (0.084)\tData 0.000 (0.010)\tLoss 0.6154 (0.6422)\tPrec@1 76.562 (73.876)\n",
            "Epoch: [186][50/97], lr: 0.00000\tTime 0.065 (0.084)\tData 0.005 (0.009)\tLoss 0.6425 (0.6397)\tPrec@1 75.781 (74.066)\n",
            "Epoch: [186][60/97], lr: 0.00000\tTime 0.107 (0.084)\tData 0.006 (0.008)\tLoss 0.6605 (0.6448)\tPrec@1 75.781 (73.809)\n",
            "Epoch: [186][70/97], lr: 0.00000\tTime 0.078 (0.083)\tData 0.007 (0.007)\tLoss 0.6044 (0.6406)\tPrec@1 76.562 (74.219)\n",
            "Epoch: [186][80/97], lr: 0.00000\tTime 0.094 (0.083)\tData 0.000 (0.007)\tLoss 0.6448 (0.6369)\tPrec@1 74.219 (74.392)\n",
            "Epoch: [186][90/97], lr: 0.00000\tTime 0.056 (0.082)\tData 0.000 (0.006)\tLoss 0.6797 (0.6408)\tPrec@1 71.875 (74.184)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.8446 (0.8446)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.033 (0.062)\tLoss 0.8018 (0.7945)\tPrec@1 64.000 (67.455)\n",
            "Test: [20/100]\tTime 0.023 (0.048)\tLoss 0.7798 (0.7921)\tPrec@1 68.000 (67.762)\n",
            "Test: [30/100]\tTime 0.023 (0.043)\tLoss 0.8305 (0.7995)\tPrec@1 65.000 (66.871)\n",
            "Test: [40/100]\tTime 0.024 (0.040)\tLoss 0.7818 (0.7984)\tPrec@1 70.000 (66.805)\n",
            "Test: [50/100]\tTime 0.074 (0.038)\tLoss 0.7886 (0.7966)\tPrec@1 69.000 (66.961)\n",
            "Test: [60/100]\tTime 0.040 (0.037)\tLoss 0.8975 (0.8010)\tPrec@1 61.000 (66.836)\n",
            "Test: [70/100]\tTime 0.025 (0.036)\tLoss 0.6914 (0.7998)\tPrec@1 72.000 (67.042)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.7472 (0.8005)\tPrec@1 69.000 (67.012)\n",
            "Test: [90/100]\tTime 0.026 (0.036)\tLoss 0.9650 (0.8031)\tPrec@1 59.000 (66.934)\n",
            "val Results: Prec@1 67.250 Loss 0.79582\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [187][0/97], lr: 0.00000\tTime 0.523 (0.523)\tData 0.325 (0.325)\tLoss 0.5621 (0.5621)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [187][10/97], lr: 0.00000\tTime 0.062 (0.117)\tData 0.000 (0.031)\tLoss 0.5963 (0.6441)\tPrec@1 78.125 (73.722)\n",
            "Epoch: [187][20/97], lr: 0.00000\tTime 0.060 (0.094)\tData 0.000 (0.017)\tLoss 0.7482 (0.6509)\tPrec@1 71.094 (72.619)\n",
            "Epoch: [187][30/97], lr: 0.00000\tTime 0.072 (0.087)\tData 0.000 (0.012)\tLoss 0.6049 (0.6470)\tPrec@1 79.688 (73.261)\n",
            "Epoch: [187][40/97], lr: 0.00000\tTime 0.073 (0.084)\tData 0.011 (0.010)\tLoss 0.6756 (0.6499)\tPrec@1 71.875 (73.438)\n",
            "Epoch: [187][50/97], lr: 0.00000\tTime 0.061 (0.081)\tData 0.000 (0.009)\tLoss 0.6043 (0.6428)\tPrec@1 75.000 (73.928)\n",
            "Epoch: [187][60/97], lr: 0.00000\tTime 0.068 (0.079)\tData 0.006 (0.008)\tLoss 0.6724 (0.6429)\tPrec@1 68.750 (74.065)\n",
            "Epoch: [187][70/97], lr: 0.00000\tTime 0.068 (0.078)\tData 0.004 (0.007)\tLoss 0.5401 (0.6406)\tPrec@1 79.688 (74.175)\n",
            "Epoch: [187][80/97], lr: 0.00000\tTime 0.077 (0.077)\tData 0.007 (0.007)\tLoss 0.6496 (0.6462)\tPrec@1 72.656 (73.862)\n",
            "Epoch: [187][90/97], lr: 0.00000\tTime 0.056 (0.076)\tData 0.000 (0.006)\tLoss 0.6673 (0.6459)\tPrec@1 73.438 (73.918)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 0.8164 (0.8164)\tPrec@1 72.000 (72.000)\n",
            "Test: [10/100]\tTime 0.035 (0.061)\tLoss 0.7999 (0.7833)\tPrec@1 65.000 (67.636)\n",
            "Test: [20/100]\tTime 0.044 (0.047)\tLoss 0.8000 (0.7852)\tPrec@1 68.000 (67.619)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 0.8379 (0.7963)\tPrec@1 66.000 (66.968)\n",
            "Test: [40/100]\tTime 0.039 (0.040)\tLoss 0.7736 (0.7942)\tPrec@1 69.000 (67.000)\n",
            "Test: [50/100]\tTime 0.059 (0.039)\tLoss 0.8522 (0.7977)\tPrec@1 64.000 (67.039)\n",
            "Test: [60/100]\tTime 0.033 (0.038)\tLoss 0.9861 (0.7991)\tPrec@1 60.000 (67.131)\n",
            "Test: [70/100]\tTime 0.022 (0.037)\tLoss 0.7305 (0.7993)\tPrec@1 69.000 (67.197)\n",
            "Test: [80/100]\tTime 0.032 (0.036)\tLoss 0.7295 (0.7975)\tPrec@1 65.000 (67.259)\n",
            "Test: [90/100]\tTime 0.038 (0.036)\tLoss 0.9565 (0.8004)\tPrec@1 59.000 (67.154)\n",
            "val Results: Prec@1 67.360 Loss 0.79354\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [188][0/97], lr: 0.00000\tTime 0.480 (0.480)\tData 0.297 (0.297)\tLoss 0.5988 (0.5988)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [188][10/97], lr: 0.00000\tTime 0.065 (0.112)\tData 0.000 (0.030)\tLoss 0.5774 (0.6396)\tPrec@1 75.781 (74.361)\n",
            "Epoch: [188][20/97], lr: 0.00000\tTime 0.063 (0.092)\tData 0.000 (0.017)\tLoss 0.6326 (0.6555)\tPrec@1 70.312 (73.549)\n",
            "Epoch: [188][30/97], lr: 0.00000\tTime 0.064 (0.085)\tData 0.000 (0.012)\tLoss 0.6043 (0.6459)\tPrec@1 74.219 (73.765)\n",
            "Epoch: [188][40/97], lr: 0.00000\tTime 0.063 (0.082)\tData 0.000 (0.010)\tLoss 0.8176 (0.6598)\tPrec@1 64.062 (73.380)\n",
            "Epoch: [188][50/97], lr: 0.00000\tTime 0.065 (0.079)\tData 0.000 (0.008)\tLoss 0.5140 (0.6609)\tPrec@1 79.688 (73.453)\n",
            "Epoch: [188][60/97], lr: 0.00000\tTime 0.068 (0.078)\tData 0.002 (0.007)\tLoss 0.5825 (0.6587)\tPrec@1 75.781 (73.540)\n",
            "Epoch: [188][70/97], lr: 0.00000\tTime 0.058 (0.077)\tData 0.000 (0.007)\tLoss 0.8130 (0.6580)\tPrec@1 68.750 (73.636)\n",
            "Epoch: [188][80/97], lr: 0.00000\tTime 0.098 (0.077)\tData 0.007 (0.006)\tLoss 0.6853 (0.6534)\tPrec@1 71.094 (73.823)\n",
            "Epoch: [188][90/97], lr: 0.00000\tTime 0.055 (0.075)\tData 0.000 (0.006)\tLoss 0.6627 (0.6518)\tPrec@1 70.312 (73.807)\n",
            "Test: [0/100]\tTime 0.268 (0.268)\tLoss 0.8162 (0.8162)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.033 (0.060)\tLoss 0.7409 (0.8018)\tPrec@1 68.000 (66.909)\n",
            "Test: [20/100]\tTime 0.030 (0.047)\tLoss 0.7741 (0.8014)\tPrec@1 74.000 (67.667)\n",
            "Test: [30/100]\tTime 0.021 (0.041)\tLoss 0.8143 (0.8097)\tPrec@1 63.000 (66.516)\n",
            "Test: [40/100]\tTime 0.021 (0.038)\tLoss 0.7718 (0.8039)\tPrec@1 71.000 (66.854)\n",
            "Test: [50/100]\tTime 0.043 (0.037)\tLoss 0.8292 (0.8011)\tPrec@1 67.000 (67.255)\n",
            "Test: [60/100]\tTime 0.031 (0.036)\tLoss 0.9530 (0.8073)\tPrec@1 60.000 (67.016)\n",
            "Test: [70/100]\tTime 0.019 (0.035)\tLoss 0.7048 (0.8047)\tPrec@1 69.000 (67.127)\n",
            "Test: [80/100]\tTime 0.034 (0.035)\tLoss 0.7155 (0.8018)\tPrec@1 72.000 (67.296)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 0.9485 (0.8018)\tPrec@1 61.000 (67.484)\n",
            "val Results: Prec@1 67.790 Loss 0.79620\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [189][0/97], lr: 0.00000\tTime 0.513 (0.513)\tData 0.387 (0.387)\tLoss 0.7546 (0.7546)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [189][10/97], lr: 0.00000\tTime 0.073 (0.116)\tData 0.000 (0.037)\tLoss 0.7453 (0.6531)\tPrec@1 73.438 (73.864)\n",
            "Epoch: [189][20/97], lr: 0.00000\tTime 0.075 (0.095)\tData 0.003 (0.021)\tLoss 0.6335 (0.6325)\tPrec@1 73.438 (74.740)\n",
            "Epoch: [189][30/97], lr: 0.00000\tTime 0.065 (0.086)\tData 0.002 (0.015)\tLoss 0.5658 (0.6470)\tPrec@1 76.562 (73.639)\n",
            "Epoch: [189][40/97], lr: 0.00000\tTime 0.071 (0.083)\tData 0.010 (0.013)\tLoss 0.7097 (0.6467)\tPrec@1 72.656 (73.819)\n",
            "Epoch: [189][50/97], lr: 0.00000\tTime 0.070 (0.081)\tData 0.006 (0.011)\tLoss 0.6395 (0.6465)\tPrec@1 74.219 (73.989)\n",
            "Epoch: [189][60/97], lr: 0.00000\tTime 0.086 (0.079)\tData 0.000 (0.010)\tLoss 0.6583 (0.6402)\tPrec@1 74.219 (74.398)\n",
            "Epoch: [189][70/97], lr: 0.00000\tTime 0.074 (0.079)\tData 0.009 (0.009)\tLoss 0.6934 (0.6486)\tPrec@1 71.094 (74.065)\n",
            "Epoch: [189][80/97], lr: 0.00000\tTime 0.069 (0.078)\tData 0.000 (0.008)\tLoss 0.6266 (0.6538)\tPrec@1 77.344 (73.804)\n",
            "Epoch: [189][90/97], lr: 0.00000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.6700 (0.6541)\tPrec@1 75.781 (73.764)\n",
            "Test: [0/100]\tTime 0.260 (0.260)\tLoss 0.8785 (0.8785)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.021 (0.059)\tLoss 0.7730 (0.7829)\tPrec@1 66.000 (67.818)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.7806 (0.7897)\tPrec@1 69.000 (67.476)\n",
            "Test: [30/100]\tTime 0.026 (0.041)\tLoss 0.8994 (0.7942)\tPrec@1 59.000 (66.935)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.7605 (0.7962)\tPrec@1 68.000 (66.707)\n",
            "Test: [50/100]\tTime 0.021 (0.037)\tLoss 0.7428 (0.7957)\tPrec@1 73.000 (66.784)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 0.9355 (0.8036)\tPrec@1 63.000 (66.885)\n",
            "Test: [70/100]\tTime 0.025 (0.036)\tLoss 0.7890 (0.8011)\tPrec@1 67.000 (67.070)\n",
            "Test: [80/100]\tTime 0.044 (0.035)\tLoss 0.7766 (0.8012)\tPrec@1 70.000 (67.160)\n",
            "Test: [90/100]\tTime 0.029 (0.035)\tLoss 0.8993 (0.8028)\tPrec@1 65.000 (67.110)\n",
            "val Results: Prec@1 67.310 Loss 0.79695\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [190][0/97], lr: 0.00000\tTime 0.528 (0.528)\tData 0.334 (0.334)\tLoss 0.6916 (0.6916)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [190][10/97], lr: 0.00000\tTime 0.113 (0.140)\tData 0.013 (0.035)\tLoss 0.7107 (0.6751)\tPrec@1 70.312 (72.301)\n",
            "Epoch: [190][20/97], lr: 0.00000\tTime 0.056 (0.125)\tData 0.000 (0.022)\tLoss 0.6987 (0.6749)\tPrec@1 71.875 (72.582)\n",
            "Epoch: [190][30/97], lr: 0.00000\tTime 0.104 (0.120)\tData 0.013 (0.017)\tLoss 0.6613 (0.6503)\tPrec@1 75.000 (73.992)\n",
            "Epoch: [190][40/97], lr: 0.00000\tTime 0.107 (0.118)\tData 0.000 (0.014)\tLoss 0.5915 (0.6541)\tPrec@1 75.781 (73.876)\n",
            "Epoch: [190][50/97], lr: 0.00000\tTime 0.086 (0.109)\tData 0.000 (0.012)\tLoss 0.5983 (0.6515)\tPrec@1 75.000 (73.928)\n",
            "Epoch: [190][60/97], lr: 0.00000\tTime 0.070 (0.103)\tData 0.000 (0.010)\tLoss 0.5158 (0.6493)\tPrec@1 78.906 (73.860)\n",
            "Epoch: [190][70/97], lr: 0.00000\tTime 0.064 (0.099)\tData 0.000 (0.009)\tLoss 0.6520 (0.6514)\tPrec@1 71.875 (73.592)\n",
            "Epoch: [190][80/97], lr: 0.00000\tTime 0.080 (0.096)\tData 0.000 (0.009)\tLoss 0.6078 (0.6468)\tPrec@1 74.219 (73.630)\n",
            "Epoch: [190][90/97], lr: 0.00000\tTime 0.057 (0.093)\tData 0.000 (0.008)\tLoss 0.8359 (0.6472)\tPrec@1 64.844 (73.729)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.8390 (0.8390)\tPrec@1 72.000 (72.000)\n",
            "Test: [10/100]\tTime 0.032 (0.057)\tLoss 0.7274 (0.7928)\tPrec@1 68.000 (68.091)\n",
            "Test: [20/100]\tTime 0.023 (0.044)\tLoss 0.7604 (0.7921)\tPrec@1 71.000 (68.238)\n",
            "Test: [30/100]\tTime 0.039 (0.041)\tLoss 0.8179 (0.8062)\tPrec@1 67.000 (67.258)\n",
            "Test: [40/100]\tTime 0.041 (0.038)\tLoss 0.7883 (0.8032)\tPrec@1 68.000 (67.146)\n",
            "Test: [50/100]\tTime 0.042 (0.037)\tLoss 0.8423 (0.8010)\tPrec@1 67.000 (67.373)\n",
            "Test: [60/100]\tTime 0.024 (0.036)\tLoss 0.9531 (0.8076)\tPrec@1 61.000 (67.262)\n",
            "Test: [70/100]\tTime 0.028 (0.035)\tLoss 0.7303 (0.8048)\tPrec@1 68.000 (67.465)\n",
            "Test: [80/100]\tTime 0.034 (0.035)\tLoss 0.6764 (0.8026)\tPrec@1 74.000 (67.568)\n",
            "Test: [90/100]\tTime 0.024 (0.034)\tLoss 0.9367 (0.8037)\tPrec@1 60.000 (67.527)\n",
            "val Results: Prec@1 67.690 Loss 0.79851\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [191][0/97], lr: 0.00000\tTime 0.537 (0.537)\tData 0.360 (0.360)\tLoss 0.6405 (0.6405)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [191][10/97], lr: 0.00000\tTime 0.065 (0.116)\tData 0.000 (0.036)\tLoss 0.7750 (0.6621)\tPrec@1 63.281 (73.224)\n",
            "Epoch: [191][20/97], lr: 0.00000\tTime 0.064 (0.096)\tData 0.001 (0.019)\tLoss 0.5571 (0.6421)\tPrec@1 82.812 (74.442)\n",
            "Epoch: [191][30/97], lr: 0.00000\tTime 0.060 (0.087)\tData 0.000 (0.015)\tLoss 0.6726 (0.6432)\tPrec@1 68.750 (74.143)\n",
            "Epoch: [191][40/97], lr: 0.00000\tTime 0.074 (0.083)\tData 0.007 (0.012)\tLoss 0.7206 (0.6453)\tPrec@1 71.094 (74.066)\n",
            "Epoch: [191][50/97], lr: 0.00000\tTime 0.061 (0.081)\tData 0.000 (0.010)\tLoss 0.5604 (0.6360)\tPrec@1 75.000 (74.571)\n",
            "Epoch: [191][60/97], lr: 0.00000\tTime 0.065 (0.079)\tData 0.000 (0.009)\tLoss 0.6340 (0.6382)\tPrec@1 71.875 (74.424)\n",
            "Epoch: [191][70/97], lr: 0.00000\tTime 0.075 (0.078)\tData 0.007 (0.008)\tLoss 0.5485 (0.6394)\tPrec@1 78.906 (74.439)\n",
            "Epoch: [191][80/97], lr: 0.00000\tTime 0.074 (0.077)\tData 0.013 (0.008)\tLoss 0.6320 (0.6387)\tPrec@1 77.344 (74.470)\n",
            "Epoch: [191][90/97], lr: 0.00000\tTime 0.060 (0.076)\tData 0.000 (0.008)\tLoss 0.5682 (0.6396)\tPrec@1 77.344 (74.390)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 0.7977 (0.7977)\tPrec@1 72.000 (72.000)\n",
            "Test: [10/100]\tTime 0.022 (0.060)\tLoss 0.7098 (0.7662)\tPrec@1 72.000 (68.636)\n",
            "Test: [20/100]\tTime 0.022 (0.046)\tLoss 0.8000 (0.7723)\tPrec@1 71.000 (68.571)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.8578 (0.7933)\tPrec@1 64.000 (66.935)\n",
            "Test: [40/100]\tTime 0.032 (0.038)\tLoss 0.7655 (0.7886)\tPrec@1 71.000 (67.171)\n",
            "Test: [50/100]\tTime 0.040 (0.037)\tLoss 0.8031 (0.7934)\tPrec@1 70.000 (67.059)\n",
            "Test: [60/100]\tTime 0.048 (0.036)\tLoss 0.9398 (0.8025)\tPrec@1 60.000 (66.951)\n",
            "Test: [70/100]\tTime 0.030 (0.035)\tLoss 0.7306 (0.8006)\tPrec@1 75.000 (67.268)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 0.7229 (0.8019)\tPrec@1 68.000 (67.123)\n",
            "Test: [90/100]\tTime 0.040 (0.035)\tLoss 0.9646 (0.8020)\tPrec@1 62.000 (67.176)\n",
            "val Results: Prec@1 67.520 Loss 0.79638\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [192][0/97], lr: 0.00000\tTime 0.494 (0.494)\tData 0.386 (0.386)\tLoss 0.7649 (0.7649)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [192][10/97], lr: 0.00000\tTime 0.063 (0.118)\tData 0.000 (0.037)\tLoss 0.6426 (0.6746)\tPrec@1 72.656 (72.443)\n",
            "Epoch: [192][20/97], lr: 0.00000\tTime 0.060 (0.095)\tData 0.000 (0.020)\tLoss 0.6717 (0.6693)\tPrec@1 73.438 (73.065)\n",
            "Epoch: [192][30/97], lr: 0.00000\tTime 0.073 (0.088)\tData 0.000 (0.015)\tLoss 0.6684 (0.6631)\tPrec@1 74.219 (73.488)\n",
            "Epoch: [192][40/97], lr: 0.00000\tTime 0.062 (0.083)\tData 0.000 (0.012)\tLoss 0.7522 (0.6599)\tPrec@1 71.094 (73.399)\n",
            "Epoch: [192][50/97], lr: 0.00000\tTime 0.071 (0.082)\tData 0.000 (0.011)\tLoss 0.6603 (0.6560)\tPrec@1 72.656 (73.407)\n",
            "Epoch: [192][60/97], lr: 0.00000\tTime 0.072 (0.080)\tData 0.006 (0.009)\tLoss 0.6362 (0.6547)\tPrec@1 72.656 (73.502)\n",
            "Epoch: [192][70/97], lr: 0.00000\tTime 0.071 (0.079)\tData 0.007 (0.008)\tLoss 0.5383 (0.6494)\tPrec@1 79.688 (73.691)\n",
            "Epoch: [192][80/97], lr: 0.00000\tTime 0.084 (0.078)\tData 0.007 (0.007)\tLoss 0.5945 (0.6503)\tPrec@1 75.781 (73.582)\n",
            "Epoch: [192][90/97], lr: 0.00000\tTime 0.056 (0.077)\tData 0.000 (0.007)\tLoss 0.7526 (0.6490)\tPrec@1 64.844 (73.592)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 0.8206 (0.8206)\tPrec@1 71.000 (71.000)\n",
            "Test: [10/100]\tTime 0.030 (0.059)\tLoss 0.7131 (0.7833)\tPrec@1 72.000 (68.000)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.8111 (0.7893)\tPrec@1 66.000 (67.476)\n",
            "Test: [30/100]\tTime 0.039 (0.041)\tLoss 0.8238 (0.7965)\tPrec@1 62.000 (66.581)\n",
            "Test: [40/100]\tTime 0.045 (0.039)\tLoss 0.7234 (0.7955)\tPrec@1 70.000 (66.976)\n",
            "Test: [50/100]\tTime 0.049 (0.037)\tLoss 0.8167 (0.7968)\tPrec@1 67.000 (67.176)\n",
            "Test: [60/100]\tTime 0.034 (0.036)\tLoss 0.8860 (0.7982)\tPrec@1 62.000 (67.148)\n",
            "Test: [70/100]\tTime 0.024 (0.035)\tLoss 0.7031 (0.7969)\tPrec@1 71.000 (67.296)\n",
            "Test: [80/100]\tTime 0.051 (0.035)\tLoss 0.7801 (0.7989)\tPrec@1 68.000 (67.333)\n",
            "Test: [90/100]\tTime 0.044 (0.034)\tLoss 0.9926 (0.8013)\tPrec@1 61.000 (67.319)\n",
            "val Results: Prec@1 67.720 Loss 0.79466\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [193][0/97], lr: 0.00000\tTime 0.551 (0.551)\tData 0.430 (0.430)\tLoss 0.5995 (0.5995)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [193][10/97], lr: 0.00000\tTime 0.092 (0.119)\tData 0.000 (0.042)\tLoss 0.5859 (0.6300)\tPrec@1 71.875 (73.366)\n",
            "Epoch: [193][20/97], lr: 0.00000\tTime 0.070 (0.097)\tData 0.000 (0.024)\tLoss 0.7096 (0.6299)\tPrec@1 71.094 (73.661)\n",
            "Epoch: [193][30/97], lr: 0.00000\tTime 0.060 (0.089)\tData 0.000 (0.016)\tLoss 0.6130 (0.6398)\tPrec@1 74.219 (73.816)\n",
            "Epoch: [193][40/97], lr: 0.00000\tTime 0.072 (0.085)\tData 0.000 (0.013)\tLoss 0.7788 (0.6484)\tPrec@1 70.312 (73.399)\n",
            "Epoch: [193][50/97], lr: 0.00000\tTime 0.071 (0.082)\tData 0.007 (0.011)\tLoss 0.6825 (0.6482)\tPrec@1 73.438 (73.483)\n",
            "Epoch: [193][60/97], lr: 0.00000\tTime 0.067 (0.080)\tData 0.004 (0.010)\tLoss 0.6113 (0.6463)\tPrec@1 76.562 (73.655)\n",
            "Epoch: [193][70/97], lr: 0.00000\tTime 0.067 (0.079)\tData 0.000 (0.009)\tLoss 0.6757 (0.6468)\tPrec@1 73.438 (73.724)\n",
            "Epoch: [193][80/97], lr: 0.00000\tTime 0.069 (0.078)\tData 0.000 (0.008)\tLoss 0.5168 (0.6454)\tPrec@1 79.688 (73.717)\n",
            "Epoch: [193][90/97], lr: 0.00000\tTime 0.054 (0.077)\tData 0.000 (0.007)\tLoss 0.6700 (0.6481)\tPrec@1 69.531 (73.601)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.8853 (0.8853)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 0.7744 (0.7950)\tPrec@1 66.000 (68.000)\n",
            "Test: [20/100]\tTime 0.021 (0.045)\tLoss 0.8067 (0.7964)\tPrec@1 68.000 (68.143)\n",
            "Test: [30/100]\tTime 0.025 (0.041)\tLoss 0.8439 (0.8070)\tPrec@1 64.000 (67.000)\n",
            "Test: [40/100]\tTime 0.038 (0.038)\tLoss 0.7799 (0.8057)\tPrec@1 70.000 (67.024)\n",
            "Test: [50/100]\tTime 0.028 (0.037)\tLoss 0.8351 (0.8003)\tPrec@1 69.000 (67.412)\n",
            "Test: [60/100]\tTime 0.035 (0.036)\tLoss 0.9059 (0.8062)\tPrec@1 62.000 (67.410)\n",
            "Test: [70/100]\tTime 0.022 (0.035)\tLoss 0.7507 (0.8047)\tPrec@1 67.000 (67.549)\n",
            "Test: [80/100]\tTime 0.049 (0.035)\tLoss 0.7530 (0.8024)\tPrec@1 72.000 (67.741)\n",
            "Test: [90/100]\tTime 0.030 (0.035)\tLoss 0.9081 (0.8036)\tPrec@1 63.000 (67.549)\n",
            "val Results: Prec@1 67.800 Loss 0.79747\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [194][0/97], lr: 0.00000\tTime 0.452 (0.452)\tData 0.344 (0.344)\tLoss 0.6296 (0.6296)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [194][10/97], lr: 0.00000\tTime 0.064 (0.118)\tData 0.000 (0.033)\tLoss 0.5960 (0.6475)\tPrec@1 77.344 (74.645)\n",
            "Epoch: [194][20/97], lr: 0.00000\tTime 0.059 (0.095)\tData 0.000 (0.018)\tLoss 0.5523 (0.6390)\tPrec@1 76.562 (74.665)\n",
            "Epoch: [194][30/97], lr: 0.00000\tTime 0.081 (0.087)\tData 0.007 (0.013)\tLoss 0.6340 (0.6432)\tPrec@1 74.219 (74.269)\n",
            "Epoch: [194][40/97], lr: 0.00000\tTime 0.063 (0.083)\tData 0.000 (0.011)\tLoss 0.6669 (0.6393)\tPrec@1 75.000 (74.276)\n",
            "Epoch: [194][50/97], lr: 0.00000\tTime 0.088 (0.081)\tData 0.000 (0.009)\tLoss 0.6757 (0.6374)\tPrec@1 69.531 (74.295)\n",
            "Epoch: [194][60/97], lr: 0.00000\tTime 0.087 (0.079)\tData 0.002 (0.008)\tLoss 0.6173 (0.6406)\tPrec@1 74.219 (74.206)\n",
            "Epoch: [194][70/97], lr: 0.00000\tTime 0.072 (0.078)\tData 0.000 (0.007)\tLoss 0.5901 (0.6444)\tPrec@1 75.781 (74.164)\n",
            "Epoch: [194][80/97], lr: 0.00000\tTime 0.074 (0.078)\tData 0.007 (0.007)\tLoss 0.6100 (0.6456)\tPrec@1 77.344 (74.074)\n",
            "Epoch: [194][90/97], lr: 0.00000\tTime 0.056 (0.076)\tData 0.000 (0.006)\tLoss 0.5002 (0.6473)\tPrec@1 79.688 (73.824)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 0.8787 (0.8787)\tPrec@1 69.000 (69.000)\n",
            "Test: [10/100]\tTime 0.025 (0.061)\tLoss 0.7467 (0.7856)\tPrec@1 70.000 (67.455)\n",
            "Test: [20/100]\tTime 0.036 (0.047)\tLoss 0.7831 (0.7907)\tPrec@1 68.000 (67.762)\n",
            "Test: [30/100]\tTime 0.036 (0.042)\tLoss 0.7759 (0.7944)\tPrec@1 66.000 (67.097)\n",
            "Test: [40/100]\tTime 0.020 (0.039)\tLoss 0.7785 (0.7982)\tPrec@1 72.000 (67.073)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.7779 (0.7947)\tPrec@1 69.000 (67.373)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 0.9560 (0.8029)\tPrec@1 58.000 (67.213)\n",
            "Test: [70/100]\tTime 0.045 (0.036)\tLoss 0.7176 (0.7998)\tPrec@1 72.000 (67.394)\n",
            "Test: [80/100]\tTime 0.027 (0.035)\tLoss 0.7068 (0.8000)\tPrec@1 69.000 (67.346)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9816 (0.7998)\tPrec@1 60.000 (67.385)\n",
            "val Results: Prec@1 67.650 Loss 0.79434\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [195][0/97], lr: 0.00000\tTime 0.429 (0.429)\tData 0.279 (0.279)\tLoss 0.7482 (0.7482)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [195][10/97], lr: 0.00000\tTime 0.080 (0.117)\tData 0.007 (0.030)\tLoss 0.8245 (0.6626)\tPrec@1 66.406 (73.651)\n",
            "Epoch: [195][20/97], lr: 0.00000\tTime 0.074 (0.097)\tData 0.009 (0.018)\tLoss 0.7174 (0.6580)\tPrec@1 69.531 (73.921)\n",
            "Epoch: [195][30/97], lr: 0.00000\tTime 0.092 (0.088)\tData 0.000 (0.013)\tLoss 0.5701 (0.6520)\tPrec@1 78.906 (74.143)\n",
            "Epoch: [195][40/97], lr: 0.00000\tTime 0.063 (0.084)\tData 0.000 (0.010)\tLoss 0.6611 (0.6455)\tPrec@1 73.438 (73.971)\n",
            "Epoch: [195][50/97], lr: 0.00000\tTime 0.079 (0.082)\tData 0.000 (0.009)\tLoss 0.7131 (0.6471)\tPrec@1 71.875 (74.112)\n",
            "Epoch: [195][60/97], lr: 0.00000\tTime 0.066 (0.080)\tData 0.001 (0.008)\tLoss 0.6845 (0.6493)\tPrec@1 71.094 (73.886)\n",
            "Epoch: [195][70/97], lr: 0.00000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 0.6262 (0.6453)\tPrec@1 76.562 (74.098)\n",
            "Epoch: [195][80/97], lr: 0.00000\tTime 0.080 (0.078)\tData 0.007 (0.006)\tLoss 0.5683 (0.6434)\tPrec@1 75.781 (74.103)\n",
            "Epoch: [195][90/97], lr: 0.00000\tTime 0.060 (0.077)\tData 0.000 (0.006)\tLoss 0.6827 (0.6420)\tPrec@1 70.312 (74.219)\n",
            "Test: [0/100]\tTime 0.319 (0.319)\tLoss 0.8330 (0.8330)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.022 (0.061)\tLoss 0.7571 (0.7916)\tPrec@1 63.000 (67.364)\n",
            "Test: [20/100]\tTime 0.032 (0.048)\tLoss 0.7885 (0.7830)\tPrec@1 66.000 (68.429)\n",
            "Test: [30/100]\tTime 0.035 (0.042)\tLoss 0.8322 (0.7986)\tPrec@1 67.000 (67.387)\n",
            "Test: [40/100]\tTime 0.038 (0.039)\tLoss 0.7949 (0.7985)\tPrec@1 67.000 (67.171)\n",
            "Test: [50/100]\tTime 0.043 (0.038)\tLoss 0.7484 (0.7999)\tPrec@1 72.000 (67.451)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 0.9020 (0.8063)\tPrec@1 63.000 (67.295)\n",
            "Test: [70/100]\tTime 0.043 (0.036)\tLoss 0.7321 (0.8063)\tPrec@1 72.000 (67.352)\n",
            "Test: [80/100]\tTime 0.054 (0.036)\tLoss 0.6847 (0.8062)\tPrec@1 70.000 (67.222)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 0.9292 (0.8058)\tPrec@1 61.000 (67.055)\n",
            "val Results: Prec@1 67.330 Loss 0.80173\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [196][0/97], lr: 0.00000\tTime 0.570 (0.570)\tData 0.427 (0.427)\tLoss 0.7097 (0.7097)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [196][10/97], lr: 0.00000\tTime 0.068 (0.117)\tData 0.000 (0.042)\tLoss 0.5556 (0.6565)\tPrec@1 78.906 (72.869)\n",
            "Epoch: [196][20/97], lr: 0.00000\tTime 0.063 (0.095)\tData 0.000 (0.022)\tLoss 0.6503 (0.6572)\tPrec@1 72.656 (72.954)\n",
            "Epoch: [196][30/97], lr: 0.00000\tTime 0.066 (0.087)\tData 0.000 (0.016)\tLoss 0.6169 (0.6673)\tPrec@1 75.781 (72.908)\n",
            "Epoch: [196][40/97], lr: 0.00000\tTime 0.074 (0.083)\tData 0.000 (0.012)\tLoss 0.5598 (0.6640)\tPrec@1 80.469 (73.037)\n",
            "Epoch: [196][50/97], lr: 0.00000\tTime 0.071 (0.080)\tData 0.000 (0.010)\tLoss 0.6482 (0.6525)\tPrec@1 77.344 (73.790)\n",
            "Epoch: [196][60/97], lr: 0.00000\tTime 0.087 (0.079)\tData 0.007 (0.009)\tLoss 0.6351 (0.6486)\tPrec@1 78.125 (74.039)\n",
            "Epoch: [196][70/97], lr: 0.00000\tTime 0.071 (0.078)\tData 0.000 (0.008)\tLoss 0.6335 (0.6539)\tPrec@1 74.219 (73.779)\n",
            "Epoch: [196][80/97], lr: 0.00000\tTime 0.064 (0.077)\tData 0.000 (0.007)\tLoss 0.5877 (0.6529)\tPrec@1 75.781 (73.814)\n",
            "Epoch: [196][90/97], lr: 0.00000\tTime 0.054 (0.076)\tData 0.000 (0.007)\tLoss 0.5042 (0.6504)\tPrec@1 84.375 (74.004)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 0.8575 (0.8575)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.028 (0.063)\tLoss 0.7113 (0.8079)\tPrec@1 74.000 (67.182)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 0.7660 (0.8056)\tPrec@1 72.000 (67.048)\n",
            "Test: [30/100]\tTime 0.021 (0.042)\tLoss 0.7827 (0.8074)\tPrec@1 68.000 (66.613)\n",
            "Test: [40/100]\tTime 0.030 (0.039)\tLoss 0.8115 (0.8046)\tPrec@1 68.000 (66.610)\n",
            "Test: [50/100]\tTime 0.062 (0.038)\tLoss 0.8206 (0.8044)\tPrec@1 66.000 (66.804)\n",
            "Test: [60/100]\tTime 0.048 (0.037)\tLoss 0.9179 (0.8082)\tPrec@1 63.000 (66.705)\n",
            "Test: [70/100]\tTime 0.055 (0.036)\tLoss 0.7057 (0.8051)\tPrec@1 75.000 (66.958)\n",
            "Test: [80/100]\tTime 0.046 (0.035)\tLoss 0.8232 (0.8031)\tPrec@1 65.000 (67.111)\n",
            "Test: [90/100]\tTime 0.040 (0.035)\tLoss 0.9955 (0.8044)\tPrec@1 58.000 (67.088)\n",
            "val Results: Prec@1 67.290 Loss 0.79908\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [197][0/97], lr: 0.00000\tTime 0.560 (0.560)\tData 0.402 (0.402)\tLoss 0.6885 (0.6885)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [197][10/97], lr: 0.00000\tTime 0.068 (0.117)\tData 0.000 (0.040)\tLoss 0.6280 (0.6214)\tPrec@1 75.781 (75.710)\n",
            "Epoch: [197][20/97], lr: 0.00000\tTime 0.072 (0.095)\tData 0.008 (0.021)\tLoss 0.7050 (0.6519)\tPrec@1 69.531 (73.326)\n",
            "Epoch: [197][30/97], lr: 0.00000\tTime 0.076 (0.088)\tData 0.007 (0.015)\tLoss 0.5456 (0.6568)\tPrec@1 77.344 (73.211)\n",
            "Epoch: [197][40/97], lr: 0.00000\tTime 0.061 (0.084)\tData 0.000 (0.012)\tLoss 0.6096 (0.6506)\tPrec@1 78.125 (73.533)\n",
            "Epoch: [197][50/97], lr: 0.00000\tTime 0.060 (0.081)\tData 0.000 (0.010)\tLoss 0.5778 (0.6482)\tPrec@1 75.781 (73.698)\n",
            "Epoch: [197][60/97], lr: 0.00000\tTime 0.093 (0.081)\tData 0.000 (0.008)\tLoss 0.6778 (0.6495)\tPrec@1 75.000 (73.617)\n",
            "Epoch: [197][70/97], lr: 0.00000\tTime 0.079 (0.079)\tData 0.007 (0.008)\tLoss 0.6639 (0.6486)\tPrec@1 70.312 (73.713)\n",
            "Epoch: [197][80/97], lr: 0.00000\tTime 0.062 (0.078)\tData 0.000 (0.007)\tLoss 0.6254 (0.6473)\tPrec@1 73.438 (73.843)\n",
            "Epoch: [197][90/97], lr: 0.00000\tTime 0.047 (0.077)\tData 0.000 (0.006)\tLoss 0.5812 (0.6488)\tPrec@1 75.000 (73.824)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 0.8595 (0.8595)\tPrec@1 69.000 (69.000)\n",
            "Test: [10/100]\tTime 0.021 (0.058)\tLoss 0.7547 (0.7798)\tPrec@1 73.000 (67.909)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 0.7860 (0.7828)\tPrec@1 65.000 (67.429)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.7727 (0.7896)\tPrec@1 66.000 (66.903)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 0.7799 (0.7930)\tPrec@1 71.000 (67.073)\n",
            "Test: [50/100]\tTime 0.022 (0.037)\tLoss 0.8080 (0.7928)\tPrec@1 69.000 (67.196)\n",
            "Test: [60/100]\tTime 0.028 (0.036)\tLoss 0.8543 (0.7961)\tPrec@1 63.000 (67.131)\n",
            "Test: [70/100]\tTime 0.022 (0.035)\tLoss 0.7135 (0.7968)\tPrec@1 73.000 (67.169)\n",
            "Test: [80/100]\tTime 0.032 (0.035)\tLoss 0.7537 (0.7970)\tPrec@1 69.000 (67.173)\n",
            "Test: [90/100]\tTime 0.021 (0.034)\tLoss 0.8934 (0.7983)\tPrec@1 66.000 (67.198)\n",
            "val Results: Prec@1 67.560 Loss 0.79158\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [198][0/97], lr: 0.00000\tTime 0.583 (0.583)\tData 0.416 (0.416)\tLoss 0.6864 (0.6864)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [198][10/97], lr: 0.00000\tTime 0.093 (0.138)\tData 0.007 (0.041)\tLoss 0.6178 (0.6636)\tPrec@1 76.562 (73.722)\n",
            "Epoch: [198][20/97], lr: 0.00000\tTime 0.086 (0.108)\tData 0.000 (0.024)\tLoss 0.5703 (0.6647)\tPrec@1 76.562 (73.586)\n",
            "Epoch: [198][30/97], lr: 0.00000\tTime 0.071 (0.096)\tData 0.009 (0.017)\tLoss 0.6927 (0.6585)\tPrec@1 71.875 (73.438)\n",
            "Epoch: [198][40/97], lr: 0.00000\tTime 0.067 (0.090)\tData 0.000 (0.014)\tLoss 0.6768 (0.6631)\tPrec@1 71.875 (72.942)\n",
            "Epoch: [198][50/97], lr: 0.00000\tTime 0.090 (0.088)\tData 0.000 (0.012)\tLoss 0.4961 (0.6536)\tPrec@1 80.469 (73.177)\n",
            "Epoch: [198][60/97], lr: 0.00000\tTime 0.069 (0.085)\tData 0.007 (0.010)\tLoss 0.6263 (0.6486)\tPrec@1 75.000 (73.412)\n",
            "Epoch: [198][70/97], lr: 0.00000\tTime 0.069 (0.083)\tData 0.007 (0.009)\tLoss 0.6467 (0.6492)\tPrec@1 72.656 (73.360)\n",
            "Epoch: [198][80/97], lr: 0.00000\tTime 0.068 (0.081)\tData 0.005 (0.009)\tLoss 0.6170 (0.6542)\tPrec@1 71.094 (73.225)\n",
            "Epoch: [198][90/97], lr: 0.00000\tTime 0.057 (0.080)\tData 0.000 (0.008)\tLoss 0.5778 (0.6486)\tPrec@1 77.344 (73.463)\n",
            "Test: [0/100]\tTime 0.274 (0.274)\tLoss 0.8850 (0.8850)\tPrec@1 68.000 (68.000)\n",
            "Test: [10/100]\tTime 0.063 (0.071)\tLoss 0.7897 (0.8012)\tPrec@1 66.000 (67.545)\n",
            "Test: [20/100]\tTime 0.031 (0.052)\tLoss 0.7977 (0.7948)\tPrec@1 70.000 (67.762)\n",
            "Test: [30/100]\tTime 0.023 (0.044)\tLoss 0.8253 (0.7959)\tPrec@1 63.000 (67.323)\n",
            "Test: [40/100]\tTime 0.023 (0.042)\tLoss 0.7648 (0.7971)\tPrec@1 68.000 (67.049)\n",
            "Test: [50/100]\tTime 0.039 (0.040)\tLoss 0.7737 (0.7925)\tPrec@1 69.000 (67.275)\n",
            "Test: [60/100]\tTime 0.045 (0.039)\tLoss 0.9549 (0.7979)\tPrec@1 64.000 (67.082)\n",
            "Test: [70/100]\tTime 0.022 (0.037)\tLoss 0.7135 (0.7963)\tPrec@1 72.000 (67.183)\n",
            "Test: [80/100]\tTime 0.035 (0.038)\tLoss 0.7116 (0.7955)\tPrec@1 71.000 (67.272)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 0.8827 (0.7943)\tPrec@1 62.000 (67.385)\n",
            "val Results: Prec@1 67.620 Loss 0.78861\n",
            "Best Prec@1: 68.070\n",
            "\n",
            "Epoch: [199][0/97], lr: 0.00000\tTime 0.476 (0.476)\tData 0.381 (0.381)\tLoss 0.5936 (0.5936)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [199][10/97], lr: 0.00000\tTime 0.092 (0.112)\tData 0.008 (0.037)\tLoss 0.5808 (0.6300)\tPrec@1 78.125 (75.071)\n",
            "Epoch: [199][20/97], lr: 0.00000\tTime 0.082 (0.093)\tData 0.000 (0.020)\tLoss 0.5667 (0.6198)\tPrec@1 82.031 (75.818)\n",
            "Epoch: [199][30/97], lr: 0.00000\tTime 0.076 (0.086)\tData 0.006 (0.015)\tLoss 0.7210 (0.6336)\tPrec@1 67.969 (75.000)\n",
            "Epoch: [199][40/97], lr: 0.00000\tTime 0.064 (0.082)\tData 0.000 (0.012)\tLoss 0.6367 (0.6454)\tPrec@1 72.656 (74.390)\n",
            "Epoch: [199][50/97], lr: 0.00000\tTime 0.063 (0.080)\tData 0.000 (0.010)\tLoss 0.5479 (0.6457)\tPrec@1 78.906 (74.142)\n",
            "Epoch: [199][60/97], lr: 0.00000\tTime 0.065 (0.079)\tData 0.000 (0.009)\tLoss 0.6804 (0.6512)\tPrec@1 71.875 (73.758)\n",
            "Epoch: [199][70/97], lr: 0.00000\tTime 0.091 (0.078)\tData 0.017 (0.008)\tLoss 0.7196 (0.6503)\tPrec@1 71.875 (73.966)\n",
            "Epoch: [199][80/97], lr: 0.00000\tTime 0.059 (0.077)\tData 0.000 (0.007)\tLoss 0.5552 (0.6485)\tPrec@1 77.344 (74.113)\n",
            "Epoch: [199][90/97], lr: 0.00000\tTime 0.055 (0.076)\tData 0.000 (0.007)\tLoss 0.6021 (0.6517)\tPrec@1 75.781 (73.927)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.8470 (0.8470)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.043 (0.058)\tLoss 0.7796 (0.7810)\tPrec@1 64.000 (68.455)\n",
            "Test: [20/100]\tTime 0.047 (0.046)\tLoss 0.8386 (0.7904)\tPrec@1 67.000 (68.190)\n",
            "Test: [30/100]\tTime 0.035 (0.042)\tLoss 0.8804 (0.7999)\tPrec@1 63.000 (67.613)\n",
            "Test: [40/100]\tTime 0.026 (0.039)\tLoss 0.7587 (0.7921)\tPrec@1 75.000 (67.927)\n",
            "Test: [50/100]\tTime 0.029 (0.038)\tLoss 0.8172 (0.7945)\tPrec@1 71.000 (67.647)\n",
            "Test: [60/100]\tTime 0.030 (0.036)\tLoss 0.9447 (0.8028)\tPrec@1 63.000 (67.262)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.7209 (0.8022)\tPrec@1 66.000 (67.324)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 0.6843 (0.7996)\tPrec@1 72.000 (67.358)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 0.9188 (0.8011)\tPrec@1 64.000 (67.308)\n",
            "val Results: Prec@1 67.600 Loss 0.79398\n",
            "Best Prec@1: 68.070\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network training with SSP models"
      ],
      "metadata": {
        "id": "35PXOI9BPSZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --imb_factor 0.01 --pretrained_model '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet50_CE_None_exp_0.01_pretrain_rot/ckpt.best.pth.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xpRH-qA8mch",
        "outputId": "b488d4f1-aad5-4bbe-da74-bb48310afa3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.6739 (2.0344)\tPrec@1 52.000 (42.197)\tPrec@5 89.000 (91.803)\n",
            "Test: [70/100]\tTime 0.037 (0.030)\tLoss 2.0216 (2.0376)\tPrec@1 45.000 (42.225)\tPrec@5 93.000 (91.732)\n",
            "Test: [80/100]\tTime 0.027 (0.030)\tLoss 1.8628 (2.0341)\tPrec@1 49.000 (42.395)\tPrec@5 87.000 (91.741)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.7966 (2.0480)\tPrec@1 46.000 (42.209)\tPrec@5 97.000 (91.758)\n",
            "val Results: Prec@1 42.070 Prec@5 91.700 Loss 2.05131\n",
            "val Class Accuracy: [0.957,0.941,0.492,0.405,0.635,0.409,0.222,0.142,0.004,0.000]\n",
            "Best Prec@1: 42.070\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [8][0/97], lr: 0.01000\tTime 0.485 (0.485)\tData 0.395 (0.395)\tLoss 0.5637 (0.5637)\tPrec@1 85.156 (85.156)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [8][10/97], lr: 0.01000\tTime 0.066 (0.104)\tData 0.007 (0.041)\tLoss 0.5507 (0.6054)\tPrec@1 81.250 (78.977)\tPrec@5 98.438 (98.011)\n",
            "Epoch: [8][20/97], lr: 0.01000\tTime 0.061 (0.083)\tData 0.010 (0.024)\tLoss 0.5821 (0.6358)\tPrec@1 77.344 (78.162)\tPrec@5 100.000 (98.065)\n",
            "Epoch: [8][30/97], lr: 0.01000\tTime 0.069 (0.074)\tData 0.007 (0.018)\tLoss 0.6938 (0.6441)\tPrec@1 73.438 (77.797)\tPrec@5 99.219 (98.311)\n",
            "Epoch: [8][40/97], lr: 0.01000\tTime 0.040 (0.070)\tData 0.003 (0.014)\tLoss 0.4356 (0.6435)\tPrec@1 88.281 (78.011)\tPrec@5 100.000 (98.418)\n",
            "Epoch: [8][50/97], lr: 0.01000\tTime 0.070 (0.067)\tData 0.020 (0.013)\tLoss 0.6736 (0.6327)\tPrec@1 78.125 (78.508)\tPrec@5 97.656 (98.514)\n",
            "Epoch: [8][60/97], lr: 0.01000\tTime 0.069 (0.066)\tData 0.003 (0.011)\tLoss 0.5842 (0.6271)\tPrec@1 77.344 (78.676)\tPrec@5 99.219 (98.514)\n",
            "Epoch: [8][70/97], lr: 0.01000\tTime 0.056 (0.065)\tData 0.000 (0.010)\tLoss 0.7174 (0.6294)\tPrec@1 75.000 (78.587)\tPrec@5 99.219 (98.493)\n",
            "Epoch: [8][80/97], lr: 0.01000\tTime 0.072 (0.064)\tData 0.007 (0.010)\tLoss 0.5838 (0.6275)\tPrec@1 76.562 (78.665)\tPrec@5 99.219 (98.495)\n",
            "Epoch: [8][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.6563 (0.6253)\tPrec@1 75.781 (78.657)\tPrec@5 99.219 (98.541)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 2.3771 (2.3771)\tPrec@1 37.000 (37.000)\tPrec@5 89.000 (89.000)\n",
            "Test: [10/100]\tTime 0.034 (0.054)\tLoss 1.8327 (2.2549)\tPrec@1 49.000 (38.909)\tPrec@5 93.000 (91.091)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 2.1260 (2.3122)\tPrec@1 35.000 (37.571)\tPrec@5 93.000 (90.476)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 2.1900 (2.3100)\tPrec@1 41.000 (37.194)\tPrec@5 91.000 (90.387)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 2.4087 (2.3114)\tPrec@1 34.000 (37.024)\tPrec@5 83.000 (90.317)\n",
            "Test: [50/100]\tTime 0.035 (0.030)\tLoss 2.2030 (2.2792)\tPrec@1 41.000 (37.608)\tPrec@5 86.000 (90.353)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 1.9514 (2.2742)\tPrec@1 38.000 (37.475)\tPrec@5 90.000 (90.262)\n",
            "Test: [70/100]\tTime 0.039 (0.029)\tLoss 2.3769 (2.2731)\tPrec@1 39.000 (37.423)\tPrec@5 90.000 (90.352)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 1.9059 (2.2675)\tPrec@1 47.000 (37.691)\tPrec@5 90.000 (90.383)\n",
            "Test: [90/100]\tTime 0.039 (0.028)\tLoss 2.0738 (2.2745)\tPrec@1 38.000 (37.473)\tPrec@5 93.000 (90.385)\n",
            "val Results: Prec@1 37.390 Prec@5 90.360 Loss 2.26762\n",
            "val Class Accuracy: [0.968,0.978,0.412,0.324,0.442,0.030,0.340,0.172,0.017,0.056]\n",
            "Best Prec@1: 42.070\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [9][0/97], lr: 0.01000\tTime 0.465 (0.465)\tData 0.382 (0.382)\tLoss 0.6742 (0.6742)\tPrec@1 76.562 (76.562)\tPrec@5 96.875 (96.875)\n",
            "Epoch: [9][10/97], lr: 0.01000\tTime 0.054 (0.101)\tData 0.004 (0.039)\tLoss 0.5484 (0.6187)\tPrec@1 82.031 (77.770)\tPrec@5 99.219 (98.651)\n",
            "Epoch: [9][20/97], lr: 0.01000\tTime 0.049 (0.081)\tData 0.006 (0.022)\tLoss 0.5075 (0.5875)\tPrec@1 83.594 (79.911)\tPrec@5 100.000 (98.847)\n",
            "Epoch: [9][30/97], lr: 0.01000\tTime 0.062 (0.074)\tData 0.008 (0.017)\tLoss 0.5038 (0.5893)\tPrec@1 85.156 (79.940)\tPrec@5 100.000 (98.765)\n",
            "Epoch: [9][40/97], lr: 0.01000\tTime 0.044 (0.069)\tData 0.000 (0.013)\tLoss 0.6997 (0.5920)\tPrec@1 73.438 (79.745)\tPrec@5 99.219 (98.761)\n",
            "Epoch: [9][50/97], lr: 0.01000\tTime 0.048 (0.067)\tData 0.001 (0.012)\tLoss 0.5525 (0.5940)\tPrec@1 75.781 (79.550)\tPrec@5 100.000 (98.698)\n",
            "Epoch: [9][60/97], lr: 0.01000\tTime 0.055 (0.066)\tData 0.006 (0.011)\tLoss 0.5174 (0.5955)\tPrec@1 84.375 (79.457)\tPrec@5 98.438 (98.796)\n",
            "Epoch: [9][70/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 0.6645 (0.6003)\tPrec@1 76.562 (79.291)\tPrec@5 99.219 (98.823)\n",
            "Epoch: [9][80/97], lr: 0.01000\tTime 0.052 (0.063)\tData 0.009 (0.009)\tLoss 0.6870 (0.6045)\tPrec@1 77.344 (79.369)\tPrec@5 98.438 (98.775)\n",
            "Epoch: [9][90/97], lr: 0.01000\tTime 0.034 (0.062)\tData 0.000 (0.009)\tLoss 0.5353 (0.6047)\tPrec@1 80.469 (79.473)\tPrec@5 99.219 (98.764)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 2.0335 (2.0335)\tPrec@1 39.000 (39.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.017 (0.050)\tLoss 1.4894 (1.9528)\tPrec@1 62.000 (45.636)\tPrec@5 93.000 (93.636)\n",
            "Test: [20/100]\tTime 0.045 (0.043)\tLoss 1.7294 (1.9915)\tPrec@1 44.000 (44.381)\tPrec@5 93.000 (93.619)\n",
            "Test: [30/100]\tTime 0.030 (0.036)\tLoss 1.7106 (1.9820)\tPrec@1 51.000 (44.516)\tPrec@5 94.000 (93.419)\n",
            "Test: [40/100]\tTime 0.015 (0.033)\tLoss 2.0439 (1.9781)\tPrec@1 43.000 (44.634)\tPrec@5 89.000 (93.341)\n",
            "Test: [50/100]\tTime 0.041 (0.032)\tLoss 1.8957 (1.9587)\tPrec@1 50.000 (45.373)\tPrec@5 91.000 (93.471)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 1.6096 (1.9517)\tPrec@1 50.000 (45.262)\tPrec@5 96.000 (93.443)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 2.1693 (1.9490)\tPrec@1 47.000 (45.423)\tPrec@5 92.000 (93.521)\n",
            "Test: [80/100]\tTime 0.021 (0.029)\tLoss 1.6010 (1.9380)\tPrec@1 50.000 (45.457)\tPrec@5 94.000 (93.605)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.7869 (1.9479)\tPrec@1 45.000 (45.099)\tPrec@5 97.000 (93.659)\n",
            "val Results: Prec@1 45.150 Prec@5 93.750 Loss 1.94678\n",
            "val Class Accuracy: [0.932,0.978,0.415,0.392,0.623,0.248,0.618,0.219,0.065,0.025]\n",
            "Best Prec@1: 45.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [10][0/97], lr: 0.01000\tTime 0.452 (0.452)\tData 0.386 (0.386)\tLoss 0.5125 (0.5125)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [10][10/97], lr: 0.01000\tTime 0.042 (0.098)\tData 0.007 (0.040)\tLoss 0.5798 (0.5553)\tPrec@1 78.906 (81.392)\tPrec@5 99.219 (99.077)\n",
            "Epoch: [10][20/97], lr: 0.01000\tTime 0.048 (0.080)\tData 0.006 (0.025)\tLoss 0.4905 (0.5385)\tPrec@1 82.031 (81.957)\tPrec@5 99.219 (99.107)\n",
            "Epoch: [10][30/97], lr: 0.01000\tTime 0.061 (0.073)\tData 0.003 (0.018)\tLoss 0.7238 (0.5418)\tPrec@1 75.000 (81.830)\tPrec@5 98.438 (99.017)\n",
            "Epoch: [10][40/97], lr: 0.01000\tTime 0.054 (0.068)\tData 0.004 (0.015)\tLoss 0.5490 (0.5420)\tPrec@1 82.031 (81.936)\tPrec@5 100.000 (98.952)\n",
            "Epoch: [10][50/97], lr: 0.01000\tTime 0.051 (0.066)\tData 0.000 (0.013)\tLoss 0.6698 (0.5481)\tPrec@1 76.562 (81.740)\tPrec@5 99.219 (98.928)\n",
            "Epoch: [10][60/97], lr: 0.01000\tTime 0.092 (0.066)\tData 0.009 (0.012)\tLoss 0.6508 (0.5499)\tPrec@1 78.125 (81.493)\tPrec@5 97.656 (98.911)\n",
            "Epoch: [10][70/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.000 (0.011)\tLoss 0.6196 (0.5599)\tPrec@1 79.688 (81.041)\tPrec@5 100.000 (98.845)\n",
            "Epoch: [10][80/97], lr: 0.01000\tTime 0.041 (0.063)\tData 0.000 (0.010)\tLoss 0.4960 (0.5554)\tPrec@1 82.031 (81.173)\tPrec@5 99.219 (98.794)\n",
            "Epoch: [10][90/97], lr: 0.01000\tTime 0.060 (0.062)\tData 0.000 (0.009)\tLoss 0.5988 (0.5569)\tPrec@1 78.906 (81.121)\tPrec@5 98.438 (98.815)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 2.7126 (2.7126)\tPrec@1 30.000 (30.000)\tPrec@5 87.000 (87.000)\n",
            "Test: [10/100]\tTime 0.034 (0.053)\tLoss 1.9212 (2.5560)\tPrec@1 48.000 (37.091)\tPrec@5 91.000 (89.545)\n",
            "Test: [20/100]\tTime 0.023 (0.039)\tLoss 2.0857 (2.5353)\tPrec@1 42.000 (36.095)\tPrec@5 91.000 (90.095)\n",
            "Test: [30/100]\tTime 0.034 (0.036)\tLoss 2.1501 (2.5332)\tPrec@1 44.000 (36.419)\tPrec@5 91.000 (89.613)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 2.7597 (2.5646)\tPrec@1 37.000 (36.585)\tPrec@5 89.000 (89.293)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 2.5748 (2.5425)\tPrec@1 39.000 (37.314)\tPrec@5 88.000 (89.529)\n",
            "Test: [60/100]\tTime 0.029 (0.030)\tLoss 2.0508 (2.5399)\tPrec@1 45.000 (36.902)\tPrec@5 88.000 (89.590)\n",
            "Test: [70/100]\tTime 0.043 (0.030)\tLoss 2.4822 (2.5369)\tPrec@1 42.000 (36.859)\tPrec@5 87.000 (89.479)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 2.3264 (2.5292)\tPrec@1 46.000 (36.914)\tPrec@5 90.000 (89.580)\n",
            "Test: [90/100]\tTime 0.034 (0.028)\tLoss 2.4801 (2.5432)\tPrec@1 36.000 (36.681)\tPrec@5 90.000 (89.714)\n",
            "val Results: Prec@1 36.560 Prec@5 89.670 Loss 2.55213\n",
            "val Class Accuracy: [0.938,0.974,0.710,0.552,0.124,0.085,0.138,0.012,0.121,0.002]\n",
            "Best Prec@1: 45.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [11][0/97], lr: 0.01000\tTime 0.433 (0.433)\tData 0.335 (0.335)\tLoss 0.3575 (0.3575)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [11][10/97], lr: 0.01000\tTime 0.059 (0.101)\tData 0.010 (0.036)\tLoss 0.5691 (0.5141)\tPrec@1 81.250 (82.173)\tPrec@5 98.438 (99.432)\n",
            "Epoch: [11][20/97], lr: 0.01000\tTime 0.045 (0.081)\tData 0.000 (0.022)\tLoss 0.5212 (0.5415)\tPrec@1 82.031 (81.585)\tPrec@5 98.438 (99.219)\n",
            "Epoch: [11][30/97], lr: 0.01000\tTime 0.063 (0.073)\tData 0.000 (0.017)\tLoss 0.5566 (0.5359)\tPrec@1 79.688 (81.578)\tPrec@5 100.000 (99.168)\n",
            "Epoch: [11][40/97], lr: 0.01000\tTime 0.055 (0.069)\tData 0.009 (0.014)\tLoss 0.5201 (0.5373)\tPrec@1 82.031 (81.536)\tPrec@5 99.219 (99.028)\n",
            "Epoch: [11][50/97], lr: 0.01000\tTime 0.055 (0.067)\tData 0.007 (0.013)\tLoss 0.5124 (0.5405)\tPrec@1 81.250 (81.388)\tPrec@5 100.000 (99.081)\n",
            "Epoch: [11][60/97], lr: 0.01000\tTime 0.040 (0.065)\tData 0.000 (0.012)\tLoss 0.4714 (0.5386)\tPrec@1 84.375 (81.352)\tPrec@5 100.000 (99.039)\n",
            "Epoch: [11][70/97], lr: 0.01000\tTime 0.057 (0.064)\tData 0.007 (0.011)\tLoss 0.6707 (0.5362)\tPrec@1 76.562 (81.492)\tPrec@5 98.438 (99.087)\n",
            "Epoch: [11][80/97], lr: 0.01000\tTime 0.058 (0.063)\tData 0.010 (0.011)\tLoss 0.4510 (0.5286)\tPrec@1 86.719 (81.674)\tPrec@5 99.219 (99.122)\n",
            "Epoch: [11][90/97], lr: 0.01000\tTime 0.026 (0.062)\tData 0.000 (0.010)\tLoss 0.5657 (0.5309)\tPrec@1 81.250 (81.619)\tPrec@5 99.219 (99.081)\n",
            "Test: [0/100]\tTime 0.277 (0.277)\tLoss 1.8454 (1.8454)\tPrec@1 44.000 (44.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.041 (0.056)\tLoss 1.5952 (1.6756)\tPrec@1 55.000 (49.818)\tPrec@5 91.000 (94.182)\n",
            "Test: [20/100]\tTime 0.037 (0.042)\tLoss 1.3272 (1.6776)\tPrec@1 50.000 (49.333)\tPrec@5 96.000 (93.857)\n",
            "Test: [30/100]\tTime 0.038 (0.036)\tLoss 1.5053 (1.6735)\tPrec@1 56.000 (49.129)\tPrec@5 91.000 (93.774)\n",
            "Test: [40/100]\tTime 0.015 (0.033)\tLoss 1.6777 (1.6654)\tPrec@1 48.000 (49.829)\tPrec@5 93.000 (93.585)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.5084 (1.6466)\tPrec@1 48.000 (50.255)\tPrec@5 98.000 (93.980)\n",
            "Test: [60/100]\tTime 0.013 (0.031)\tLoss 1.4648 (1.6469)\tPrec@1 57.000 (49.918)\tPrec@5 95.000 (93.934)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 1.6390 (1.6485)\tPrec@1 46.000 (49.986)\tPrec@5 97.000 (94.000)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 1.3668 (1.6390)\tPrec@1 56.000 (50.185)\tPrec@5 96.000 (94.025)\n",
            "Test: [90/100]\tTime 0.039 (0.029)\tLoss 1.4279 (1.6523)\tPrec@1 54.000 (49.813)\tPrec@5 98.000 (93.912)\n",
            "val Results: Prec@1 49.890 Prec@5 93.950 Loss 1.64921\n",
            "val Class Accuracy: [0.937,0.980,0.675,0.577,0.321,0.343,0.175,0.539,0.135,0.307]\n",
            "Best Prec@1: 49.890\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [12][0/97], lr: 0.01000\tTime 0.463 (0.463)\tData 0.391 (0.391)\tLoss 0.3875 (0.3875)\tPrec@1 84.375 (84.375)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [12][10/97], lr: 0.01000\tTime 0.059 (0.100)\tData 0.000 (0.039)\tLoss 0.5281 (0.4867)\tPrec@1 85.938 (83.736)\tPrec@5 98.438 (99.361)\n",
            "Epoch: [12][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.006 (0.023)\tLoss 0.5259 (0.4896)\tPrec@1 82.031 (82.850)\tPrec@5 100.000 (99.368)\n",
            "Epoch: [12][30/97], lr: 0.01000\tTime 0.043 (0.073)\tData 0.000 (0.017)\tLoss 0.3829 (0.4989)\tPrec@1 88.281 (82.409)\tPrec@5 98.438 (99.168)\n",
            "Epoch: [12][40/97], lr: 0.01000\tTime 0.050 (0.069)\tData 0.000 (0.014)\tLoss 0.4287 (0.5027)\tPrec@1 86.719 (82.450)\tPrec@5 99.219 (99.143)\n",
            "Epoch: [12][50/97], lr: 0.01000\tTime 0.057 (0.067)\tData 0.005 (0.013)\tLoss 0.4993 (0.5038)\tPrec@1 82.812 (82.583)\tPrec@5 98.438 (99.050)\n",
            "Epoch: [12][60/97], lr: 0.01000\tTime 0.049 (0.066)\tData 0.007 (0.012)\tLoss 0.5184 (0.4998)\tPrec@1 82.031 (82.582)\tPrec@5 100.000 (99.052)\n",
            "Epoch: [12][70/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.005 (0.011)\tLoss 0.4782 (0.4974)\tPrec@1 87.500 (82.735)\tPrec@5 99.219 (99.109)\n",
            "Epoch: [12][80/97], lr: 0.01000\tTime 0.055 (0.064)\tData 0.007 (0.010)\tLoss 0.4547 (0.4995)\tPrec@1 85.938 (82.571)\tPrec@5 98.438 (99.122)\n",
            "Epoch: [12][90/97], lr: 0.01000\tTime 0.033 (0.062)\tData 0.000 (0.010)\tLoss 0.6776 (0.5017)\tPrec@1 75.781 (82.641)\tPrec@5 99.219 (99.116)\n",
            "Test: [0/100]\tTime 0.281 (0.281)\tLoss 1.9260 (1.9260)\tPrec@1 42.000 (42.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.020 (0.050)\tLoss 1.5514 (1.8799)\tPrec@1 58.000 (48.636)\tPrec@5 94.000 (94.000)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 1.5250 (1.8847)\tPrec@1 50.000 (47.810)\tPrec@5 96.000 (94.143)\n",
            "Test: [30/100]\tTime 0.025 (0.035)\tLoss 1.7129 (1.9141)\tPrec@1 52.000 (47.419)\tPrec@5 94.000 (93.645)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 2.2595 (1.9283)\tPrec@1 49.000 (47.683)\tPrec@5 91.000 (93.634)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 1.9687 (1.9082)\tPrec@1 50.000 (48.451)\tPrec@5 92.000 (93.627)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 1.3502 (1.8834)\tPrec@1 60.000 (48.721)\tPrec@5 97.000 (93.754)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 1.9257 (1.8869)\tPrec@1 52.000 (48.901)\tPrec@5 96.000 (93.859)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.5942 (1.8740)\tPrec@1 58.000 (48.988)\tPrec@5 92.000 (93.988)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 1.7063 (1.8903)\tPrec@1 53.000 (48.747)\tPrec@5 97.000 (94.022)\n",
            "val Results: Prec@1 48.590 Prec@5 93.990 Loss 1.89615\n",
            "val Class Accuracy: [0.960,0.931,0.750,0.274,0.632,0.460,0.407,0.362,0.056,0.027]\n",
            "Best Prec@1: 49.890\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [13][0/97], lr: 0.01000\tTime 0.467 (0.467)\tData 0.393 (0.393)\tLoss 0.5171 (0.5171)\tPrec@1 82.031 (82.031)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [13][10/97], lr: 0.01000\tTime 0.065 (0.101)\tData 0.005 (0.040)\tLoss 0.4079 (0.4847)\tPrec@1 85.156 (82.955)\tPrec@5 99.219 (99.148)\n",
            "Epoch: [13][20/97], lr: 0.01000\tTime 0.067 (0.081)\tData 0.018 (0.025)\tLoss 0.4862 (0.5112)\tPrec@1 86.719 (82.515)\tPrec@5 99.219 (98.996)\n",
            "Epoch: [13][30/97], lr: 0.01000\tTime 0.060 (0.073)\tData 0.000 (0.019)\tLoss 0.4913 (0.5158)\tPrec@1 85.156 (82.586)\tPrec@5 100.000 (99.042)\n",
            "Epoch: [13][40/97], lr: 0.01000\tTime 0.077 (0.070)\tData 0.006 (0.016)\tLoss 0.3674 (0.5064)\tPrec@1 91.406 (83.022)\tPrec@5 99.219 (99.066)\n",
            "Epoch: [13][50/97], lr: 0.01000\tTime 0.061 (0.068)\tData 0.000 (0.014)\tLoss 0.3869 (0.4961)\tPrec@1 86.719 (83.318)\tPrec@5 99.219 (99.066)\n",
            "Epoch: [13][60/97], lr: 0.01000\tTime 0.068 (0.066)\tData 0.006 (0.012)\tLoss 0.5774 (0.4838)\tPrec@1 76.562 (83.645)\tPrec@5 100.000 (99.116)\n",
            "Epoch: [13][70/97], lr: 0.01000\tTime 0.048 (0.064)\tData 0.000 (0.011)\tLoss 0.4649 (0.4815)\tPrec@1 83.594 (83.649)\tPrec@5 100.000 (99.098)\n",
            "Epoch: [13][80/97], lr: 0.01000\tTime 0.065 (0.065)\tData 0.005 (0.010)\tLoss 0.6013 (0.4910)\tPrec@1 77.344 (83.275)\tPrec@5 99.219 (99.084)\n",
            "Epoch: [13][90/97], lr: 0.01000\tTime 0.053 (0.067)\tData 0.000 (0.009)\tLoss 0.6020 (0.4930)\tPrec@1 78.125 (83.156)\tPrec@5 100.000 (99.107)\n",
            "Test: [0/100]\tTime 0.465 (0.465)\tLoss 2.1476 (2.1476)\tPrec@1 45.000 (45.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.028 (0.088)\tLoss 1.4493 (1.8336)\tPrec@1 56.000 (49.909)\tPrec@5 91.000 (93.455)\n",
            "Test: [20/100]\tTime 0.036 (0.065)\tLoss 1.3252 (1.7987)\tPrec@1 53.000 (49.095)\tPrec@5 97.000 (93.476)\n",
            "Test: [30/100]\tTime 0.043 (0.057)\tLoss 1.6881 (1.8227)\tPrec@1 55.000 (48.806)\tPrec@5 94.000 (93.290)\n",
            "Test: [40/100]\tTime 0.057 (0.052)\tLoss 1.8693 (1.8184)\tPrec@1 49.000 (49.049)\tPrec@5 95.000 (93.537)\n",
            "Test: [50/100]\tTime 0.033 (0.046)\tLoss 1.7831 (1.8003)\tPrec@1 47.000 (49.588)\tPrec@5 95.000 (93.725)\n",
            "Test: [60/100]\tTime 0.010 (0.042)\tLoss 1.3700 (1.7897)\tPrec@1 58.000 (49.361)\tPrec@5 95.000 (93.689)\n",
            "Test: [70/100]\tTime 0.029 (0.040)\tLoss 1.5765 (1.7958)\tPrec@1 51.000 (49.268)\tPrec@5 95.000 (93.648)\n",
            "Test: [80/100]\tTime 0.018 (0.039)\tLoss 1.7455 (1.7781)\tPrec@1 54.000 (49.383)\tPrec@5 93.000 (93.753)\n",
            "Test: [90/100]\tTime 0.026 (0.037)\tLoss 1.7040 (1.7976)\tPrec@1 47.000 (49.143)\tPrec@5 95.000 (93.692)\n",
            "val Results: Prec@1 49.060 Prec@5 93.640 Loss 1.80498\n",
            "val Class Accuracy: [0.923,0.891,0.755,0.751,0.537,0.239,0.269,0.380,0.053,0.108]\n",
            "Best Prec@1: 49.890\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [14][0/97], lr: 0.01000\tTime 0.471 (0.471)\tData 0.371 (0.371)\tLoss 0.4494 (0.4494)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [14][10/97], lr: 0.01000\tTime 0.050 (0.102)\tData 0.007 (0.042)\tLoss 0.4253 (0.4644)\tPrec@1 84.375 (84.659)\tPrec@5 100.000 (99.290)\n",
            "Epoch: [14][20/97], lr: 0.01000\tTime 0.074 (0.080)\tData 0.006 (0.024)\tLoss 0.3905 (0.4633)\tPrec@1 86.719 (84.449)\tPrec@5 99.219 (99.107)\n",
            "Epoch: [14][30/97], lr: 0.01000\tTime 0.043 (0.072)\tData 0.000 (0.019)\tLoss 0.5491 (0.4739)\tPrec@1 82.031 (83.997)\tPrec@5 98.438 (99.068)\n",
            "Epoch: [14][40/97], lr: 0.01000\tTime 0.062 (0.069)\tData 0.005 (0.015)\tLoss 0.6301 (0.4706)\tPrec@1 76.562 (84.089)\tPrec@5 98.438 (99.162)\n",
            "Epoch: [14][50/97], lr: 0.01000\tTime 0.039 (0.067)\tData 0.000 (0.013)\tLoss 0.4310 (0.4688)\tPrec@1 82.812 (84.176)\tPrec@5 100.000 (99.157)\n",
            "Epoch: [14][60/97], lr: 0.01000\tTime 0.071 (0.066)\tData 0.018 (0.012)\tLoss 0.5704 (0.4761)\tPrec@1 80.469 (83.722)\tPrec@5 100.000 (99.193)\n",
            "Epoch: [14][70/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.006 (0.011)\tLoss 0.4398 (0.4727)\tPrec@1 83.594 (83.847)\tPrec@5 99.219 (99.164)\n",
            "Epoch: [14][80/97], lr: 0.01000\tTime 0.065 (0.064)\tData 0.007 (0.010)\tLoss 0.5164 (0.4713)\tPrec@1 80.469 (84.018)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [14][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.010)\tLoss 0.4451 (0.4694)\tPrec@1 79.688 (84.040)\tPrec@5 100.000 (99.227)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.9219 (1.9219)\tPrec@1 44.000 (44.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.037 (0.056)\tLoss 1.4464 (1.8276)\tPrec@1 55.000 (48.545)\tPrec@5 93.000 (94.818)\n",
            "Test: [20/100]\tTime 0.039 (0.041)\tLoss 1.5796 (1.8136)\tPrec@1 47.000 (48.476)\tPrec@5 95.000 (94.571)\n",
            "Test: [30/100]\tTime 0.030 (0.036)\tLoss 1.6502 (1.8488)\tPrec@1 51.000 (48.548)\tPrec@5 97.000 (94.645)\n",
            "Test: [40/100]\tTime 0.014 (0.033)\tLoss 1.8691 (1.8647)\tPrec@1 48.000 (48.317)\tPrec@5 94.000 (94.390)\n",
            "Test: [50/100]\tTime 0.038 (0.031)\tLoss 1.7245 (1.8362)\tPrec@1 51.000 (49.020)\tPrec@5 95.000 (94.608)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 1.5078 (1.8283)\tPrec@1 53.000 (48.902)\tPrec@5 95.000 (94.525)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 1.8289 (1.8310)\tPrec@1 52.000 (48.901)\tPrec@5 94.000 (94.479)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 1.7860 (1.8204)\tPrec@1 54.000 (49.074)\tPrec@5 93.000 (94.654)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 1.7690 (1.8343)\tPrec@1 50.000 (48.923)\tPrec@5 97.000 (94.703)\n",
            "val Results: Prec@1 48.730 Prec@5 94.670 Loss 1.83800\n",
            "val Class Accuracy: [0.980,0.954,0.514,0.633,0.683,0.234,0.421,0.209,0.135,0.110]\n",
            "Best Prec@1: 49.890\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [15][0/97], lr: 0.01000\tTime 0.469 (0.469)\tData 0.369 (0.369)\tLoss 0.3534 (0.3534)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [15][10/97], lr: 0.01000\tTime 0.076 (0.102)\tData 0.000 (0.036)\tLoss 0.5291 (0.4373)\tPrec@1 82.812 (85.085)\tPrec@5 99.219 (99.503)\n",
            "Epoch: [15][20/97], lr: 0.01000\tTime 0.056 (0.081)\tData 0.000 (0.020)\tLoss 0.4138 (0.4338)\tPrec@1 84.375 (84.896)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [15][30/97], lr: 0.01000\tTime 0.034 (0.074)\tData 0.000 (0.014)\tLoss 0.4508 (0.4411)\tPrec@1 88.281 (84.879)\tPrec@5 97.656 (99.370)\n",
            "Epoch: [15][40/97], lr: 0.01000\tTime 0.041 (0.070)\tData 0.000 (0.012)\tLoss 0.3402 (0.4413)\tPrec@1 86.719 (84.851)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [15][50/97], lr: 0.01000\tTime 0.055 (0.067)\tData 0.006 (0.010)\tLoss 0.7003 (0.4465)\tPrec@1 75.781 (84.666)\tPrec@5 96.875 (99.311)\n",
            "Epoch: [15][60/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.005 (0.009)\tLoss 0.4384 (0.4399)\tPrec@1 87.500 (85.092)\tPrec@5 99.219 (99.308)\n",
            "Epoch: [15][70/97], lr: 0.01000\tTime 0.064 (0.065)\tData 0.009 (0.009)\tLoss 0.4972 (0.4388)\tPrec@1 79.688 (85.035)\tPrec@5 98.438 (99.296)\n",
            "Epoch: [15][80/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.4884 (0.4399)\tPrec@1 82.031 (85.002)\tPrec@5 99.219 (99.267)\n",
            "Epoch: [15][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.008)\tLoss 0.4008 (0.4439)\tPrec@1 82.031 (84.830)\tPrec@5 100.000 (99.227)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 1.5907 (1.5907)\tPrec@1 57.000 (57.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.028 (0.055)\tLoss 1.1852 (1.4703)\tPrec@1 62.000 (56.727)\tPrec@5 96.000 (93.818)\n",
            "Test: [20/100]\tTime 0.018 (0.040)\tLoss 1.1368 (1.3965)\tPrec@1 63.000 (57.619)\tPrec@5 99.000 (94.429)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.2472 (1.4332)\tPrec@1 60.000 (56.935)\tPrec@5 97.000 (94.194)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.6746 (1.4401)\tPrec@1 51.000 (56.976)\tPrec@5 90.000 (94.073)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.5304 (1.4302)\tPrec@1 59.000 (57.255)\tPrec@5 95.000 (94.216)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.1815 (1.4357)\tPrec@1 61.000 (56.623)\tPrec@5 94.000 (94.295)\n",
            "Test: [70/100]\tTime 0.032 (0.029)\tLoss 1.4496 (1.4412)\tPrec@1 59.000 (56.606)\tPrec@5 96.000 (94.296)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.3910 (1.4354)\tPrec@1 58.000 (56.556)\tPrec@5 90.000 (94.284)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 1.3198 (1.4491)\tPrec@1 60.000 (56.319)\tPrec@5 97.000 (94.264)\n",
            "val Results: Prec@1 56.270 Prec@5 94.090 Loss 1.45244\n",
            "val Class Accuracy: [0.877,0.959,0.851,0.593,0.547,0.490,0.274,0.325,0.438,0.273]\n",
            "Best Prec@1: 56.270\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [16][0/97], lr: 0.01000\tTime 0.512 (0.512)\tData 0.413 (0.413)\tLoss 0.3495 (0.3495)\tPrec@1 86.719 (86.719)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [16][10/97], lr: 0.01000\tTime 0.060 (0.101)\tData 0.000 (0.041)\tLoss 0.4617 (0.4350)\tPrec@1 84.375 (85.795)\tPrec@5 100.000 (99.077)\n",
            "Epoch: [16][20/97], lr: 0.01000\tTime 0.060 (0.081)\tData 0.000 (0.023)\tLoss 0.4152 (0.4269)\tPrec@1 85.938 (85.826)\tPrec@5 100.000 (99.144)\n",
            "Epoch: [16][30/97], lr: 0.01000\tTime 0.057 (0.072)\tData 0.006 (0.018)\tLoss 0.4635 (0.4323)\tPrec@1 84.375 (85.459)\tPrec@5 100.000 (99.294)\n",
            "Epoch: [16][40/97], lr: 0.01000\tTime 0.061 (0.069)\tData 0.000 (0.014)\tLoss 0.4233 (0.4337)\tPrec@1 84.375 (85.385)\tPrec@5 98.438 (99.314)\n",
            "Epoch: [16][50/97], lr: 0.01000\tTime 0.040 (0.066)\tData 0.000 (0.012)\tLoss 0.4155 (0.4323)\tPrec@1 85.938 (85.141)\tPrec@5 98.438 (99.326)\n",
            "Epoch: [16][60/97], lr: 0.01000\tTime 0.045 (0.066)\tData 0.000 (0.011)\tLoss 0.4946 (0.4365)\tPrec@1 85.156 (85.143)\tPrec@5 98.438 (99.296)\n",
            "Epoch: [16][70/97], lr: 0.01000\tTime 0.055 (0.065)\tData 0.003 (0.010)\tLoss 0.4407 (0.4341)\tPrec@1 86.719 (85.332)\tPrec@5 99.219 (99.318)\n",
            "Epoch: [16][80/97], lr: 0.01000\tTime 0.067 (0.064)\tData 0.003 (0.009)\tLoss 0.3662 (0.4284)\tPrec@1 88.281 (85.552)\tPrec@5 100.000 (99.354)\n",
            "Epoch: [16][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.008)\tLoss 0.5469 (0.4314)\tPrec@1 83.594 (85.543)\tPrec@5 98.438 (99.356)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 2.8652 (2.8652)\tPrec@1 37.000 (37.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.025 (0.055)\tLoss 2.3749 (2.6900)\tPrec@1 51.000 (40.727)\tPrec@5 93.000 (93.273)\n",
            "Test: [20/100]\tTime 0.027 (0.040)\tLoss 2.2108 (2.7030)\tPrec@1 46.000 (39.952)\tPrec@5 94.000 (93.143)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 2.5274 (2.6902)\tPrec@1 44.000 (40.323)\tPrec@5 93.000 (93.290)\n",
            "Test: [40/100]\tTime 0.013 (0.032)\tLoss 2.8169 (2.6921)\tPrec@1 37.000 (40.268)\tPrec@5 93.000 (93.195)\n",
            "Test: [50/100]\tTime 0.051 (0.032)\tLoss 2.7067 (2.6630)\tPrec@1 48.000 (41.118)\tPrec@5 92.000 (93.412)\n",
            "Test: [60/100]\tTime 0.013 (0.030)\tLoss 2.0609 (2.6498)\tPrec@1 51.000 (40.770)\tPrec@5 93.000 (93.361)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 2.8527 (2.6523)\tPrec@1 41.000 (40.662)\tPrec@5 93.000 (93.465)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 2.4171 (2.6378)\tPrec@1 51.000 (40.765)\tPrec@5 93.000 (93.580)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 2.5743 (2.6592)\tPrec@1 46.000 (40.626)\tPrec@5 95.000 (93.495)\n",
            "val Results: Prec@1 40.440 Prec@5 93.440 Loss 2.67397\n",
            "val Class Accuracy: [0.978,0.945,0.683,0.425,0.438,0.212,0.148,0.098,0.079,0.038]\n",
            "Best Prec@1: 56.270\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [17][0/97], lr: 0.01000\tTime 0.467 (0.467)\tData 0.381 (0.381)\tLoss 0.3904 (0.3904)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][10/97], lr: 0.01000\tTime 0.075 (0.102)\tData 0.008 (0.038)\tLoss 0.3263 (0.4369)\tPrec@1 89.062 (84.801)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [17][20/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.003 (0.022)\tLoss 0.3293 (0.4070)\tPrec@1 89.844 (85.975)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [17][30/97], lr: 0.01000\tTime 0.058 (0.073)\tData 0.000 (0.016)\tLoss 0.4754 (0.4195)\tPrec@1 82.812 (85.509)\tPrec@5 97.656 (99.219)\n",
            "Epoch: [17][40/97], lr: 0.01000\tTime 0.059 (0.070)\tData 0.012 (0.014)\tLoss 0.4641 (0.4260)\tPrec@1 80.469 (85.423)\tPrec@5 99.219 (99.181)\n",
            "Epoch: [17][50/97], lr: 0.01000\tTime 0.066 (0.068)\tData 0.004 (0.013)\tLoss 0.4137 (0.4229)\tPrec@1 87.500 (85.677)\tPrec@5 99.219 (99.203)\n",
            "Epoch: [17][60/97], lr: 0.01000\tTime 0.062 (0.066)\tData 0.004 (0.011)\tLoss 0.3907 (0.4154)\tPrec@1 86.719 (85.912)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [17][70/97], lr: 0.01000\tTime 0.055 (0.065)\tData 0.006 (0.011)\tLoss 0.4288 (0.4190)\tPrec@1 85.938 (85.816)\tPrec@5 99.219 (99.175)\n",
            "Epoch: [17][80/97], lr: 0.01000\tTime 0.063 (0.064)\tData 0.006 (0.010)\tLoss 0.4584 (0.4225)\tPrec@1 84.375 (85.716)\tPrec@5 99.219 (99.161)\n",
            "Epoch: [17][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.009)\tLoss 0.3507 (0.4210)\tPrec@1 89.062 (85.740)\tPrec@5 100.000 (99.184)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.5052 (1.5052)\tPrec@1 55.000 (55.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.019 (0.054)\tLoss 1.1221 (1.4286)\tPrec@1 64.000 (57.455)\tPrec@5 95.000 (95.545)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.1970 (1.3628)\tPrec@1 56.000 (58.190)\tPrec@5 98.000 (95.619)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 1.3572 (1.4035)\tPrec@1 61.000 (57.710)\tPrec@5 95.000 (95.161)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 1.5672 (1.4204)\tPrec@1 55.000 (57.927)\tPrec@5 96.000 (94.951)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 1.5112 (1.4060)\tPrec@1 61.000 (58.765)\tPrec@5 92.000 (94.902)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.2060 (1.4073)\tPrec@1 62.000 (58.590)\tPrec@5 97.000 (94.820)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 1.1869 (1.4163)\tPrec@1 68.000 (58.648)\tPrec@5 97.000 (94.775)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.2961 (1.4089)\tPrec@1 64.000 (58.852)\tPrec@5 94.000 (94.790)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 1.3129 (1.4215)\tPrec@1 59.000 (58.604)\tPrec@5 95.000 (94.824)\n",
            "val Results: Prec@1 58.620 Prec@5 94.730 Loss 1.42528\n",
            "val Class Accuracy: [0.890,0.927,0.718,0.710,0.753,0.240,0.625,0.251,0.278,0.470]\n",
            "Best Prec@1: 58.620\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [18][0/97], lr: 0.01000\tTime 0.498 (0.498)\tData 0.406 (0.406)\tLoss 0.3670 (0.3670)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][10/97], lr: 0.01000\tTime 0.063 (0.104)\tData 0.011 (0.040)\tLoss 0.2624 (0.3320)\tPrec@1 94.531 (88.778)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [18][20/97], lr: 0.01000\tTime 0.035 (0.080)\tData 0.000 (0.023)\tLoss 0.4094 (0.3432)\tPrec@1 85.938 (88.467)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [18][30/97], lr: 0.01000\tTime 0.051 (0.073)\tData 0.000 (0.017)\tLoss 0.4113 (0.3661)\tPrec@1 83.594 (87.576)\tPrec@5 100.000 (99.521)\n",
            "Epoch: [18][40/97], lr: 0.01000\tTime 0.041 (0.069)\tData 0.000 (0.014)\tLoss 0.2859 (0.3784)\tPrec@1 91.406 (86.909)\tPrec@5 99.219 (99.543)\n",
            "Epoch: [18][50/97], lr: 0.01000\tTime 0.040 (0.066)\tData 0.000 (0.012)\tLoss 0.3918 (0.3847)\tPrec@1 85.938 (86.734)\tPrec@5 98.438 (99.479)\n",
            "Epoch: [18][60/97], lr: 0.01000\tTime 0.066 (0.066)\tData 0.008 (0.010)\tLoss 0.4286 (0.3864)\tPrec@1 87.500 (86.808)\tPrec@5 97.656 (99.475)\n",
            "Epoch: [18][70/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.000 (0.009)\tLoss 0.4073 (0.3897)\tPrec@1 88.281 (86.785)\tPrec@5 100.000 (99.450)\n",
            "Epoch: [18][80/97], lr: 0.01000\tTime 0.062 (0.064)\tData 0.007 (0.009)\tLoss 0.5848 (0.4000)\tPrec@1 81.250 (86.574)\tPrec@5 99.219 (99.421)\n",
            "Epoch: [18][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.008)\tLoss 0.4438 (0.4051)\tPrec@1 84.375 (86.324)\tPrec@5 100.000 (99.408)\n",
            "Test: [0/100]\tTime 0.269 (0.269)\tLoss 1.7759 (1.7759)\tPrec@1 50.000 (50.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.037 (0.054)\tLoss 1.0896 (1.7072)\tPrec@1 66.000 (53.091)\tPrec@5 96.000 (94.727)\n",
            "Test: [20/100]\tTime 0.028 (0.040)\tLoss 1.3713 (1.6632)\tPrec@1 59.000 (54.000)\tPrec@5 95.000 (94.810)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 1.3759 (1.6881)\tPrec@1 62.000 (53.645)\tPrec@5 96.000 (94.323)\n",
            "Test: [40/100]\tTime 0.038 (0.033)\tLoss 1.8109 (1.7070)\tPrec@1 52.000 (53.561)\tPrec@5 93.000 (94.390)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 1.7312 (1.6806)\tPrec@1 54.000 (54.314)\tPrec@5 94.000 (94.392)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 1.4613 (1.6748)\tPrec@1 63.000 (54.328)\tPrec@5 92.000 (94.426)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 1.5903 (1.6774)\tPrec@1 57.000 (54.394)\tPrec@5 97.000 (94.338)\n",
            "Test: [80/100]\tTime 0.025 (0.028)\tLoss 1.6749 (1.6741)\tPrec@1 57.000 (54.457)\tPrec@5 94.000 (94.444)\n",
            "Test: [90/100]\tTime 0.028 (0.028)\tLoss 2.1604 (1.6868)\tPrec@1 46.000 (54.242)\tPrec@5 92.000 (94.407)\n",
            "val Results: Prec@1 53.970 Prec@5 94.340 Loss 1.69569\n",
            "val Class Accuracy: [0.938,0.953,0.396,0.854,0.542,0.410,0.620,0.354,0.193,0.137]\n",
            "Best Prec@1: 58.620\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [19][0/97], lr: 0.01000\tTime 0.482 (0.482)\tData 0.395 (0.395)\tLoss 0.4806 (0.4806)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [19][10/97], lr: 0.01000\tTime 0.034 (0.097)\tData 0.000 (0.038)\tLoss 0.2716 (0.4036)\tPrec@1 88.281 (86.222)\tPrec@5 100.000 (99.503)\n",
            "Epoch: [19][20/97], lr: 0.01000\tTime 0.049 (0.080)\tData 0.004 (0.023)\tLoss 0.3585 (0.3821)\tPrec@1 86.719 (86.905)\tPrec@5 99.219 (99.479)\n",
            "Epoch: [19][30/97], lr: 0.01000\tTime 0.075 (0.073)\tData 0.005 (0.017)\tLoss 0.4435 (0.3867)\tPrec@1 86.719 (86.694)\tPrec@5 98.438 (99.420)\n",
            "Epoch: [19][40/97], lr: 0.01000\tTime 0.039 (0.069)\tData 0.000 (0.015)\tLoss 0.4915 (0.3914)\tPrec@1 83.594 (86.528)\tPrec@5 98.438 (99.466)\n",
            "Epoch: [19][50/97], lr: 0.01000\tTime 0.055 (0.067)\tData 0.005 (0.013)\tLoss 0.3448 (0.3845)\tPrec@1 89.062 (86.765)\tPrec@5 98.438 (99.449)\n",
            "Epoch: [19][60/97], lr: 0.01000\tTime 0.072 (0.065)\tData 0.003 (0.011)\tLoss 0.3376 (0.3897)\tPrec@1 87.500 (86.565)\tPrec@5 99.219 (99.424)\n",
            "Epoch: [19][70/97], lr: 0.01000\tTime 0.049 (0.064)\tData 0.000 (0.010)\tLoss 0.3476 (0.3934)\tPrec@1 88.281 (86.433)\tPrec@5 100.000 (99.439)\n",
            "Epoch: [19][80/97], lr: 0.01000\tTime 0.065 (0.063)\tData 0.000 (0.009)\tLoss 0.4633 (0.4011)\tPrec@1 86.719 (86.188)\tPrec@5 98.438 (99.383)\n",
            "Epoch: [19][90/97], lr: 0.01000\tTime 0.032 (0.062)\tData 0.000 (0.009)\tLoss 0.3957 (0.3983)\tPrec@1 89.062 (86.341)\tPrec@5 100.000 (99.408)\n",
            "Test: [0/100]\tTime 0.359 (0.359)\tLoss 1.8525 (1.8525)\tPrec@1 44.000 (44.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.023 (0.055)\tLoss 1.2543 (1.7756)\tPrec@1 61.000 (49.636)\tPrec@5 94.000 (94.909)\n",
            "Test: [20/100]\tTime 0.023 (0.042)\tLoss 1.6658 (1.8031)\tPrec@1 51.000 (48.429)\tPrec@5 98.000 (95.476)\n",
            "Test: [30/100]\tTime 0.026 (0.034)\tLoss 1.6228 (1.8137)\tPrec@1 50.000 (48.613)\tPrec@5 95.000 (95.161)\n",
            "Test: [40/100]\tTime 0.043 (0.033)\tLoss 1.9365 (1.8168)\tPrec@1 47.000 (48.683)\tPrec@5 96.000 (95.073)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 1.9262 (1.8033)\tPrec@1 49.000 (49.137)\tPrec@5 96.000 (95.235)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 1.4461 (1.8053)\tPrec@1 56.000 (48.656)\tPrec@5 98.000 (95.328)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 1.7564 (1.8076)\tPrec@1 50.000 (48.676)\tPrec@5 97.000 (95.324)\n",
            "Test: [80/100]\tTime 0.035 (0.029)\tLoss 1.4734 (1.8003)\tPrec@1 55.000 (48.827)\tPrec@5 95.000 (95.383)\n",
            "Test: [90/100]\tTime 0.039 (0.029)\tLoss 1.5754 (1.8189)\tPrec@1 50.000 (48.692)\tPrec@5 96.000 (95.418)\n",
            "val Results: Prec@1 48.680 Prec@5 95.330 Loss 1.82092\n",
            "val Class Accuracy: [0.957,0.961,0.848,0.258,0.371,0.314,0.578,0.376,0.093,0.112]\n",
            "Best Prec@1: 58.620\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [20][0/97], lr: 0.01000\tTime 0.525 (0.525)\tData 0.435 (0.435)\tLoss 0.3689 (0.3689)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [20][10/97], lr: 0.01000\tTime 0.074 (0.101)\tData 0.006 (0.045)\tLoss 0.3222 (0.3835)\tPrec@1 89.844 (87.074)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [20][20/97], lr: 0.01000\tTime 0.048 (0.079)\tData 0.000 (0.026)\tLoss 0.2983 (0.3806)\tPrec@1 89.844 (86.719)\tPrec@5 99.219 (99.554)\n",
            "Epoch: [20][30/97], lr: 0.01000\tTime 0.054 (0.073)\tData 0.006 (0.019)\tLoss 0.4135 (0.3691)\tPrec@1 89.844 (87.248)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [20][40/97], lr: 0.01000\tTime 0.071 (0.070)\tData 0.000 (0.015)\tLoss 0.4688 (0.3779)\tPrec@1 82.031 (86.700)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [20][50/97], lr: 0.01000\tTime 0.062 (0.067)\tData 0.000 (0.013)\tLoss 0.3018 (0.3737)\tPrec@1 89.062 (87.010)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [20][60/97], lr: 0.01000\tTime 0.055 (0.066)\tData 0.000 (0.011)\tLoss 0.3419 (0.3703)\tPrec@1 89.062 (87.065)\tPrec@5 98.438 (99.436)\n",
            "Epoch: [20][70/97], lr: 0.01000\tTime 0.057 (0.065)\tData 0.007 (0.011)\tLoss 0.5246 (0.3794)\tPrec@1 81.250 (86.774)\tPrec@5 99.219 (99.417)\n",
            "Epoch: [20][80/97], lr: 0.01000\tTime 0.062 (0.064)\tData 0.011 (0.010)\tLoss 0.3119 (0.3825)\tPrec@1 88.281 (86.738)\tPrec@5 99.219 (99.421)\n",
            "Epoch: [20][90/97], lr: 0.01000\tTime 0.028 (0.063)\tData 0.000 (0.010)\tLoss 0.3289 (0.3824)\tPrec@1 89.844 (86.684)\tPrec@5 99.219 (99.408)\n",
            "Test: [0/100]\tTime 0.271 (0.271)\tLoss 1.4449 (1.4449)\tPrec@1 57.000 (57.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.031 (0.050)\tLoss 0.9081 (1.4254)\tPrec@1 69.000 (58.273)\tPrec@5 97.000 (95.000)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 1.2107 (1.3821)\tPrec@1 58.000 (58.810)\tPrec@5 99.000 (95.238)\n",
            "Test: [30/100]\tTime 0.016 (0.035)\tLoss 1.2514 (1.4031)\tPrec@1 63.000 (58.355)\tPrec@5 97.000 (94.774)\n",
            "Test: [40/100]\tTime 0.030 (0.032)\tLoss 1.4605 (1.4264)\tPrec@1 56.000 (58.122)\tPrec@5 94.000 (94.756)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 1.6362 (1.4128)\tPrec@1 60.000 (58.627)\tPrec@5 93.000 (94.784)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 1.0943 (1.4110)\tPrec@1 65.000 (58.459)\tPrec@5 97.000 (94.836)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 1.3556 (1.4194)\tPrec@1 62.000 (58.479)\tPrec@5 94.000 (94.761)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 1.3979 (1.4142)\tPrec@1 57.000 (58.333)\tPrec@5 92.000 (94.852)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.2573 (1.4266)\tPrec@1 56.000 (58.077)\tPrec@5 97.000 (94.802)\n",
            "val Results: Prec@1 58.100 Prec@5 94.700 Loss 1.43195\n",
            "val Class Accuracy: [0.845,0.926,0.853,0.656,0.618,0.259,0.704,0.372,0.400,0.177]\n",
            "Best Prec@1: 58.620\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [21][0/97], lr: 0.01000\tTime 0.484 (0.484)\tData 0.397 (0.397)\tLoss 0.3320 (0.3320)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [21][10/97], lr: 0.01000\tTime 0.066 (0.106)\tData 0.006 (0.039)\tLoss 0.3538 (0.3571)\tPrec@1 89.062 (88.068)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [21][20/97], lr: 0.01000\tTime 0.077 (0.082)\tData 0.000 (0.023)\tLoss 0.3364 (0.3449)\tPrec@1 89.844 (88.356)\tPrec@5 98.438 (99.591)\n",
            "Epoch: [21][30/97], lr: 0.01000\tTime 0.053 (0.076)\tData 0.007 (0.017)\tLoss 0.3447 (0.3554)\tPrec@1 87.500 (88.130)\tPrec@5 100.000 (99.546)\n",
            "Epoch: [21][40/97], lr: 0.01000\tTime 0.062 (0.071)\tData 0.015 (0.015)\tLoss 0.5345 (0.3710)\tPrec@1 80.469 (87.557)\tPrec@5 98.438 (99.581)\n",
            "Epoch: [21][50/97], lr: 0.01000\tTime 0.049 (0.069)\tData 0.007 (0.013)\tLoss 0.4760 (0.3728)\tPrec@1 85.938 (87.515)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [21][60/97], lr: 0.01000\tTime 0.056 (0.068)\tData 0.000 (0.012)\tLoss 0.4222 (0.3747)\tPrec@1 86.719 (87.410)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [21][70/97], lr: 0.01000\tTime 0.064 (0.066)\tData 0.005 (0.011)\tLoss 0.3458 (0.3720)\tPrec@1 89.844 (87.412)\tPrec@5 100.000 (99.582)\n",
            "Epoch: [21][80/97], lr: 0.01000\tTime 0.047 (0.065)\tData 0.009 (0.010)\tLoss 0.3320 (0.3775)\tPrec@1 86.719 (87.259)\tPrec@5 100.000 (99.547)\n",
            "Epoch: [21][90/97], lr: 0.01000\tTime 0.038 (0.064)\tData 0.000 (0.010)\tLoss 0.4590 (0.3740)\tPrec@1 83.594 (87.294)\tPrec@5 98.438 (99.545)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 1.9232 (1.9232)\tPrec@1 49.000 (49.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.021 (0.056)\tLoss 1.2761 (1.7997)\tPrec@1 64.000 (52.727)\tPrec@5 94.000 (96.273)\n",
            "Test: [20/100]\tTime 0.045 (0.042)\tLoss 1.5146 (1.7437)\tPrec@1 51.000 (53.286)\tPrec@5 98.000 (96.429)\n",
            "Test: [30/100]\tTime 0.020 (0.035)\tLoss 1.4425 (1.7614)\tPrec@1 63.000 (53.839)\tPrec@5 95.000 (96.161)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 1.5765 (1.7648)\tPrec@1 53.000 (53.610)\tPrec@5 96.000 (96.220)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.8287 (1.7453)\tPrec@1 55.000 (54.471)\tPrec@5 94.000 (96.314)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 1.3608 (1.7348)\tPrec@1 63.000 (54.131)\tPrec@5 98.000 (96.246)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 1.8288 (1.7432)\tPrec@1 56.000 (54.070)\tPrec@5 96.000 (96.085)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.8411 (1.7346)\tPrec@1 52.000 (54.272)\tPrec@5 93.000 (96.099)\n",
            "Test: [90/100]\tTime 0.044 (0.029)\tLoss 1.6959 (1.7468)\tPrec@1 49.000 (54.132)\tPrec@5 97.000 (96.033)\n",
            "val Results: Prec@1 53.910 Prec@5 95.970 Loss 1.75559\n",
            "val Class Accuracy: [0.850,0.983,0.608,0.835,0.751,0.239,0.314,0.338,0.289,0.184]\n",
            "Best Prec@1: 58.620\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [22][0/97], lr: 0.01000\tTime 0.482 (0.482)\tData 0.392 (0.392)\tLoss 0.4389 (0.4389)\tPrec@1 83.594 (83.594)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [22][10/97], lr: 0.01000\tTime 0.056 (0.103)\tData 0.005 (0.044)\tLoss 0.3440 (0.3324)\tPrec@1 85.156 (87.997)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [22][20/97], lr: 0.01000\tTime 0.056 (0.080)\tData 0.005 (0.026)\tLoss 0.3031 (0.3651)\tPrec@1 89.844 (87.054)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [22][30/97], lr: 0.01000\tTime 0.071 (0.074)\tData 0.007 (0.019)\tLoss 0.3393 (0.3583)\tPrec@1 88.281 (87.374)\tPrec@5 99.219 (99.572)\n",
            "Epoch: [22][40/97], lr: 0.01000\tTime 0.058 (0.070)\tData 0.000 (0.015)\tLoss 0.3037 (0.3567)\tPrec@1 90.625 (87.614)\tPrec@5 100.000 (99.543)\n",
            "Epoch: [22][50/97], lr: 0.01000\tTime 0.069 (0.068)\tData 0.012 (0.014)\tLoss 0.3387 (0.3568)\tPrec@1 88.281 (87.714)\tPrec@5 99.219 (99.586)\n",
            "Epoch: [22][60/97], lr: 0.01000\tTime 0.076 (0.066)\tData 0.000 (0.012)\tLoss 0.4140 (0.3638)\tPrec@1 85.156 (87.538)\tPrec@5 99.219 (99.577)\n",
            "Epoch: [22][70/97], lr: 0.01000\tTime 0.071 (0.065)\tData 0.008 (0.011)\tLoss 0.2472 (0.3596)\tPrec@1 91.406 (87.764)\tPrec@5 99.219 (99.560)\n",
            "Epoch: [22][80/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.003 (0.010)\tLoss 0.4535 (0.3658)\tPrec@1 82.812 (87.587)\tPrec@5 100.000 (99.556)\n",
            "Epoch: [22][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.010)\tLoss 0.3909 (0.3629)\tPrec@1 85.938 (87.620)\tPrec@5 99.219 (99.562)\n",
            "Test: [0/100]\tTime 0.311 (0.311)\tLoss 1.2293 (1.2293)\tPrec@1 63.000 (63.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.021 (0.054)\tLoss 1.1187 (1.3646)\tPrec@1 66.000 (60.818)\tPrec@5 98.000 (95.273)\n",
            "Test: [20/100]\tTime 0.010 (0.038)\tLoss 1.0451 (1.3074)\tPrec@1 59.000 (61.286)\tPrec@5 100.000 (95.810)\n",
            "Test: [30/100]\tTime 0.029 (0.034)\tLoss 1.2379 (1.3426)\tPrec@1 61.000 (60.516)\tPrec@5 92.000 (95.516)\n",
            "Test: [40/100]\tTime 0.016 (0.032)\tLoss 1.3530 (1.3571)\tPrec@1 58.000 (60.146)\tPrec@5 94.000 (95.537)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 1.4855 (1.3443)\tPrec@1 63.000 (60.686)\tPrec@5 95.000 (95.647)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 1.0750 (1.3500)\tPrec@1 68.000 (60.115)\tPrec@5 94.000 (95.607)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 1.2945 (1.3484)\tPrec@1 62.000 (60.056)\tPrec@5 94.000 (95.352)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.2520 (1.3404)\tPrec@1 69.000 (60.210)\tPrec@5 94.000 (95.333)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.2390 (1.3486)\tPrec@1 62.000 (60.044)\tPrec@5 98.000 (95.352)\n",
            "val Results: Prec@1 60.080 Prec@5 95.250 Loss 1.35403\n",
            "val Class Accuracy: [0.894,0.980,0.706,0.766,0.573,0.267,0.757,0.316,0.412,0.337]\n",
            "Best Prec@1: 60.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [23][0/97], lr: 0.01000\tTime 0.399 (0.399)\tData 0.304 (0.304)\tLoss 0.3012 (0.3012)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [23][10/97], lr: 0.01000\tTime 0.060 (0.103)\tData 0.007 (0.036)\tLoss 0.3225 (0.3368)\tPrec@1 88.281 (88.849)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [23][20/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.002 (0.021)\tLoss 0.2833 (0.3365)\tPrec@1 90.625 (88.542)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [23][30/97], lr: 0.01000\tTime 0.078 (0.074)\tData 0.000 (0.016)\tLoss 0.4176 (0.3351)\tPrec@1 85.938 (88.558)\tPrec@5 99.219 (99.647)\n",
            "Epoch: [23][40/97], lr: 0.01000\tTime 0.039 (0.069)\tData 0.000 (0.014)\tLoss 0.2359 (0.3350)\tPrec@1 92.969 (88.510)\tPrec@5 100.000 (99.524)\n",
            "Epoch: [23][50/97], lr: 0.01000\tTime 0.068 (0.067)\tData 0.000 (0.013)\tLoss 0.4123 (0.3477)\tPrec@1 85.938 (88.128)\tPrec@5 100.000 (99.464)\n",
            "Epoch: [23][60/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.000 (0.011)\tLoss 0.2647 (0.3420)\tPrec@1 87.500 (88.294)\tPrec@5 100.000 (99.462)\n",
            "Epoch: [23][70/97], lr: 0.01000\tTime 0.075 (0.065)\tData 0.011 (0.011)\tLoss 0.3628 (0.3456)\tPrec@1 89.844 (88.259)\tPrec@5 98.438 (99.439)\n",
            "Epoch: [23][80/97], lr: 0.01000\tTime 0.051 (0.063)\tData 0.008 (0.010)\tLoss 0.3302 (0.3449)\tPrec@1 89.844 (88.291)\tPrec@5 98.438 (99.441)\n",
            "Epoch: [23][90/97], lr: 0.01000\tTime 0.032 (0.062)\tData 0.000 (0.009)\tLoss 0.2540 (0.3461)\tPrec@1 90.625 (88.273)\tPrec@5 100.000 (99.451)\n",
            "Test: [0/100]\tTime 0.259 (0.259)\tLoss 1.7054 (1.7054)\tPrec@1 60.000 (60.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.023 (0.053)\tLoss 1.2526 (1.5537)\tPrec@1 66.000 (60.091)\tPrec@5 94.000 (93.909)\n",
            "Test: [20/100]\tTime 0.035 (0.040)\tLoss 1.2973 (1.5278)\tPrec@1 64.000 (60.857)\tPrec@5 98.000 (94.238)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 1.4128 (1.5554)\tPrec@1 64.000 (60.129)\tPrec@5 94.000 (93.710)\n",
            "Test: [40/100]\tTime 0.046 (0.034)\tLoss 1.4206 (1.5461)\tPrec@1 57.000 (60.244)\tPrec@5 95.000 (93.829)\n",
            "Test: [50/100]\tTime 0.043 (0.032)\tLoss 1.3918 (1.5311)\tPrec@1 63.000 (60.765)\tPrec@5 92.000 (93.980)\n",
            "Test: [60/100]\tTime 0.010 (0.031)\tLoss 1.1467 (1.5110)\tPrec@1 68.000 (60.705)\tPrec@5 94.000 (94.049)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 1.3715 (1.5295)\tPrec@1 64.000 (60.493)\tPrec@5 97.000 (93.986)\n",
            "Test: [80/100]\tTime 0.047 (0.029)\tLoss 1.4591 (1.5268)\tPrec@1 61.000 (60.568)\tPrec@5 94.000 (94.000)\n",
            "Test: [90/100]\tTime 0.039 (0.029)\tLoss 1.3406 (1.5454)\tPrec@1 65.000 (60.176)\tPrec@5 94.000 (93.901)\n",
            "val Results: Prec@1 60.150 Prec@5 93.800 Loss 1.55173\n",
            "val Class Accuracy: [0.850,0.961,0.648,0.463,0.903,0.601,0.610,0.602,0.056,0.321]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [24][0/97], lr: 0.01000\tTime 0.526 (0.526)\tData 0.418 (0.418)\tLoss 0.2809 (0.2809)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [24][10/97], lr: 0.01000\tTime 0.071 (0.104)\tData 0.007 (0.042)\tLoss 0.2990 (0.3082)\tPrec@1 90.625 (89.915)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [24][20/97], lr: 0.01000\tTime 0.053 (0.082)\tData 0.000 (0.024)\tLoss 0.3521 (0.3128)\tPrec@1 89.062 (89.658)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [24][30/97], lr: 0.01000\tTime 0.056 (0.074)\tData 0.007 (0.018)\tLoss 0.3857 (0.3296)\tPrec@1 86.719 (89.062)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [24][40/97], lr: 0.01000\tTime 0.068 (0.070)\tData 0.005 (0.015)\tLoss 0.2868 (0.3408)\tPrec@1 92.969 (88.758)\tPrec@5 98.438 (99.600)\n",
            "Epoch: [24][50/97], lr: 0.01000\tTime 0.068 (0.068)\tData 0.011 (0.013)\tLoss 0.3898 (0.3428)\tPrec@1 86.719 (88.710)\tPrec@5 99.219 (99.602)\n",
            "Epoch: [24][60/97], lr: 0.01000\tTime 0.049 (0.066)\tData 0.007 (0.011)\tLoss 0.2969 (0.3410)\tPrec@1 91.406 (88.653)\tPrec@5 99.219 (99.577)\n",
            "Epoch: [24][70/97], lr: 0.01000\tTime 0.055 (0.065)\tData 0.005 (0.010)\tLoss 0.3204 (0.3419)\tPrec@1 89.844 (88.655)\tPrec@5 100.000 (99.593)\n",
            "Epoch: [24][80/97], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.010)\tLoss 0.3621 (0.3435)\tPrec@1 88.281 (88.657)\tPrec@5 99.219 (99.605)\n",
            "Epoch: [24][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.3560 (0.3467)\tPrec@1 87.500 (88.504)\tPrec@5 100.000 (99.605)\n",
            "Test: [0/100]\tTime 0.277 (0.277)\tLoss 1.3265 (1.3265)\tPrec@1 59.000 (59.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 1.1107 (1.4235)\tPrec@1 70.000 (60.000)\tPrec@5 96.000 (95.545)\n",
            "Test: [20/100]\tTime 0.032 (0.039)\tLoss 1.2083 (1.3775)\tPrec@1 61.000 (59.905)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/100]\tTime 0.039 (0.036)\tLoss 1.3438 (1.3943)\tPrec@1 63.000 (59.742)\tPrec@5 93.000 (95.774)\n",
            "Test: [40/100]\tTime 0.019 (0.033)\tLoss 1.5615 (1.4156)\tPrec@1 56.000 (59.463)\tPrec@5 96.000 (95.732)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.5563 (1.4144)\tPrec@1 55.000 (59.471)\tPrec@5 94.000 (95.824)\n",
            "Test: [60/100]\tTime 0.011 (0.030)\tLoss 1.3156 (1.4259)\tPrec@1 61.000 (59.066)\tPrec@5 98.000 (95.951)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 1.4602 (1.4343)\tPrec@1 60.000 (58.930)\tPrec@5 97.000 (95.831)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 1.2517 (1.4325)\tPrec@1 65.000 (58.741)\tPrec@5 95.000 (95.877)\n",
            "Test: [90/100]\tTime 0.042 (0.029)\tLoss 1.1806 (1.4418)\tPrec@1 66.000 (58.527)\tPrec@5 96.000 (95.791)\n",
            "val Results: Prec@1 58.490 Prec@5 95.750 Loss 1.44272\n",
            "val Class Accuracy: [0.924,0.969,0.828,0.434,0.796,0.242,0.609,0.258,0.357,0.432]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [25][0/97], lr: 0.01000\tTime 0.405 (0.405)\tData 0.313 (0.313)\tLoss 0.3782 (0.3782)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [25][10/97], lr: 0.01000\tTime 0.050 (0.102)\tData 0.003 (0.034)\tLoss 0.2581 (0.3121)\tPrec@1 92.969 (90.057)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [25][20/97], lr: 0.01000\tTime 0.075 (0.082)\tData 0.013 (0.021)\tLoss 0.2616 (0.3086)\tPrec@1 89.844 (90.104)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [25][30/97], lr: 0.01000\tTime 0.058 (0.073)\tData 0.000 (0.015)\tLoss 0.2983 (0.3019)\tPrec@1 92.969 (90.197)\tPrec@5 99.219 (99.723)\n",
            "Epoch: [25][40/97], lr: 0.01000\tTime 0.044 (0.070)\tData 0.001 (0.013)\tLoss 0.2479 (0.3128)\tPrec@1 90.625 (89.634)\tPrec@5 100.000 (99.676)\n",
            "Epoch: [25][50/97], lr: 0.01000\tTime 0.042 (0.068)\tData 0.000 (0.011)\tLoss 0.3723 (0.3201)\tPrec@1 91.406 (89.445)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [25][60/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.000 (0.010)\tLoss 0.4600 (0.3266)\tPrec@1 82.031 (89.050)\tPrec@5 100.000 (99.641)\n",
            "Epoch: [25][70/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.006 (0.009)\tLoss 0.3717 (0.3310)\tPrec@1 86.719 (88.853)\tPrec@5 100.000 (99.659)\n",
            "Epoch: [25][80/97], lr: 0.01000\tTime 0.043 (0.064)\tData 0.003 (0.009)\tLoss 0.2641 (0.3347)\tPrec@1 91.406 (88.783)\tPrec@5 100.000 (99.595)\n",
            "Epoch: [25][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.008)\tLoss 0.3157 (0.3396)\tPrec@1 85.938 (88.650)\tPrec@5 100.000 (99.596)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 2.2695 (2.2695)\tPrec@1 39.000 (39.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.026 (0.056)\tLoss 1.7127 (2.1287)\tPrec@1 52.000 (48.273)\tPrec@5 95.000 (93.364)\n",
            "Test: [20/100]\tTime 0.021 (0.039)\tLoss 1.6598 (2.0651)\tPrec@1 53.000 (47.952)\tPrec@5 97.000 (94.095)\n",
            "Test: [30/100]\tTime 0.036 (0.036)\tLoss 1.8893 (2.0850)\tPrec@1 46.000 (48.258)\tPrec@5 94.000 (93.097)\n",
            "Test: [40/100]\tTime 0.033 (0.033)\tLoss 2.2520 (2.0930)\tPrec@1 44.000 (48.341)\tPrec@5 94.000 (93.244)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 2.1816 (2.0825)\tPrec@1 44.000 (48.569)\tPrec@5 90.000 (93.157)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 1.6563 (2.0990)\tPrec@1 56.000 (47.852)\tPrec@5 96.000 (93.262)\n",
            "Test: [70/100]\tTime 0.031 (0.029)\tLoss 1.8282 (2.1020)\tPrec@1 53.000 (47.930)\tPrec@5 95.000 (93.254)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 1.9344 (2.0878)\tPrec@1 57.000 (48.185)\tPrec@5 88.000 (93.210)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 2.0226 (2.1119)\tPrec@1 53.000 (47.956)\tPrec@5 89.000 (92.989)\n",
            "val Results: Prec@1 47.950 Prec@5 92.950 Loss 2.11144\n",
            "val Class Accuracy: [0.880,0.926,0.876,0.681,0.360,0.426,0.087,0.172,0.331,0.056]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [26][0/97], lr: 0.01000\tTime 0.433 (0.433)\tData 0.338 (0.338)\tLoss 0.4286 (0.4286)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [26][10/97], lr: 0.01000\tTime 0.046 (0.102)\tData 0.000 (0.034)\tLoss 0.3437 (0.3393)\tPrec@1 85.156 (88.494)\tPrec@5 99.219 (99.645)\n",
            "Epoch: [26][20/97], lr: 0.01000\tTime 0.038 (0.080)\tData 0.000 (0.021)\tLoss 0.2528 (0.3184)\tPrec@1 92.188 (89.881)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [26][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.005 (0.016)\tLoss 0.3440 (0.3349)\tPrec@1 89.062 (88.785)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [26][40/97], lr: 0.01000\tTime 0.070 (0.070)\tData 0.007 (0.014)\tLoss 0.3438 (0.3317)\tPrec@1 89.062 (88.777)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [26][50/97], lr: 0.01000\tTime 0.074 (0.068)\tData 0.007 (0.012)\tLoss 0.3030 (0.3276)\tPrec@1 91.406 (89.185)\tPrec@5 99.219 (99.709)\n",
            "Epoch: [26][60/97], lr: 0.01000\tTime 0.073 (0.066)\tData 0.010 (0.011)\tLoss 0.3777 (0.3228)\tPrec@1 87.500 (89.139)\tPrec@5 99.219 (99.705)\n",
            "Epoch: [26][70/97], lr: 0.01000\tTime 0.082 (0.065)\tData 0.000 (0.010)\tLoss 0.2835 (0.3286)\tPrec@1 88.281 (88.842)\tPrec@5 100.000 (99.692)\n",
            "Epoch: [26][80/97], lr: 0.01000\tTime 0.047 (0.064)\tData 0.000 (0.009)\tLoss 0.4504 (0.3282)\tPrec@1 85.156 (88.860)\tPrec@5 99.219 (99.672)\n",
            "Epoch: [26][90/97], lr: 0.01000\tTime 0.037 (0.063)\tData 0.000 (0.009)\tLoss 0.2904 (0.3260)\tPrec@1 89.062 (88.856)\tPrec@5 100.000 (99.682)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 1.5063 (1.5063)\tPrec@1 57.000 (57.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.028 (0.054)\tLoss 1.1288 (1.4024)\tPrec@1 70.000 (59.545)\tPrec@5 97.000 (95.818)\n",
            "Test: [20/100]\tTime 0.032 (0.040)\tLoss 1.2364 (1.4120)\tPrec@1 58.000 (58.952)\tPrec@5 97.000 (95.429)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.4136 (1.4690)\tPrec@1 63.000 (58.774)\tPrec@5 93.000 (94.806)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 1.6471 (1.4831)\tPrec@1 56.000 (58.634)\tPrec@5 95.000 (94.902)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.5890 (1.4705)\tPrec@1 60.000 (58.902)\tPrec@5 93.000 (94.922)\n",
            "Test: [60/100]\tTime 0.035 (0.030)\tLoss 1.2897 (1.4822)\tPrec@1 64.000 (58.525)\tPrec@5 98.000 (95.082)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 1.3955 (1.4838)\tPrec@1 62.000 (58.563)\tPrec@5 95.000 (95.056)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.4769 (1.4730)\tPrec@1 62.000 (58.741)\tPrec@5 95.000 (95.099)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.4046 (1.4860)\tPrec@1 57.000 (58.560)\tPrec@5 96.000 (95.099)\n",
            "val Results: Prec@1 58.620 Prec@5 95.020 Loss 1.49480\n",
            "val Class Accuracy: [0.945,0.934,0.774,0.717,0.797,0.225,0.565,0.244,0.390,0.271]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [27][0/97], lr: 0.01000\tTime 0.503 (0.503)\tData 0.406 (0.406)\tLoss 0.1587 (0.1587)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [27][10/97], lr: 0.01000\tTime 0.041 (0.101)\tData 0.000 (0.041)\tLoss 0.3533 (0.2818)\tPrec@1 87.500 (90.696)\tPrec@5 99.219 (99.858)\n",
            "Epoch: [27][20/97], lr: 0.01000\tTime 0.060 (0.083)\tData 0.005 (0.024)\tLoss 0.3677 (0.2930)\tPrec@1 86.719 (89.881)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [27][30/97], lr: 0.01000\tTime 0.093 (0.077)\tData 0.004 (0.017)\tLoss 0.3048 (0.3164)\tPrec@1 92.188 (89.138)\tPrec@5 99.219 (99.622)\n",
            "Epoch: [27][40/97], lr: 0.01000\tTime 0.053 (0.073)\tData 0.005 (0.014)\tLoss 0.2349 (0.3142)\tPrec@1 93.750 (89.043)\tPrec@5 100.000 (99.619)\n",
            "Epoch: [27][50/97], lr: 0.01000\tTime 0.045 (0.071)\tData 0.000 (0.013)\tLoss 0.2874 (0.3089)\tPrec@1 89.062 (89.124)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [27][60/97], lr: 0.01000\tTime 0.061 (0.069)\tData 0.006 (0.011)\tLoss 0.3335 (0.3150)\tPrec@1 88.281 (89.088)\tPrec@5 100.000 (99.654)\n",
            "Epoch: [27][70/97], lr: 0.01000\tTime 0.051 (0.067)\tData 0.006 (0.011)\tLoss 0.3025 (0.3181)\tPrec@1 89.062 (88.985)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [27][80/97], lr: 0.01000\tTime 0.072 (0.066)\tData 0.000 (0.010)\tLoss 0.3711 (0.3200)\tPrec@1 89.844 (88.985)\tPrec@5 100.000 (99.643)\n",
            "Epoch: [27][90/97], lr: 0.01000\tTime 0.032 (0.065)\tData 0.000 (0.009)\tLoss 0.2517 (0.3193)\tPrec@1 92.188 (88.985)\tPrec@5 100.000 (99.648)\n",
            "Test: [0/100]\tTime 0.286 (0.286)\tLoss 2.1156 (2.1156)\tPrec@1 52.000 (52.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.022 (0.053)\tLoss 1.6908 (1.8639)\tPrec@1 60.000 (54.818)\tPrec@5 98.000 (96.273)\n",
            "Test: [20/100]\tTime 0.043 (0.040)\tLoss 1.6846 (1.9453)\tPrec@1 59.000 (53.000)\tPrec@5 94.000 (95.143)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 1.8626 (1.9981)\tPrec@1 58.000 (52.774)\tPrec@5 94.000 (94.871)\n",
            "Test: [40/100]\tTime 0.035 (0.033)\tLoss 1.8335 (1.9920)\tPrec@1 61.000 (52.927)\tPrec@5 91.000 (94.634)\n",
            "Test: [50/100]\tTime 0.016 (0.032)\tLoss 1.9395 (1.9871)\tPrec@1 54.000 (52.863)\tPrec@5 94.000 (94.824)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 1.8791 (1.9904)\tPrec@1 50.000 (52.770)\tPrec@5 94.000 (94.770)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 2.2113 (2.0039)\tPrec@1 54.000 (52.366)\tPrec@5 97.000 (94.831)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.6825 (1.9879)\tPrec@1 66.000 (52.531)\tPrec@5 95.000 (94.728)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.9653 (2.0069)\tPrec@1 52.000 (52.341)\tPrec@5 94.000 (94.714)\n",
            "val Results: Prec@1 52.390 Prec@5 94.750 Loss 2.01081\n",
            "val Class Accuracy: [0.979,0.939,0.464,0.412,0.273,0.239,0.726,0.554,0.204,0.449]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [28][0/97], lr: 0.01000\tTime 0.484 (0.484)\tData 0.395 (0.395)\tLoss 0.2820 (0.2820)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [28][10/97], lr: 0.01000\tTime 0.060 (0.103)\tData 0.000 (0.040)\tLoss 0.2910 (0.2876)\tPrec@1 89.844 (89.631)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [28][20/97], lr: 0.01000\tTime 0.068 (0.081)\tData 0.005 (0.024)\tLoss 0.3734 (0.2895)\tPrec@1 87.500 (90.216)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [28][30/97], lr: 0.01000\tTime 0.066 (0.073)\tData 0.000 (0.018)\tLoss 0.3042 (0.2879)\tPrec@1 90.625 (90.096)\tPrec@5 98.438 (99.698)\n",
            "Epoch: [28][40/97], lr: 0.01000\tTime 0.055 (0.069)\tData 0.005 (0.014)\tLoss 0.3955 (0.2863)\tPrec@1 85.938 (90.015)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [28][50/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.005 (0.012)\tLoss 0.3301 (0.2937)\tPrec@1 89.062 (89.645)\tPrec@5 100.000 (99.755)\n",
            "Epoch: [28][60/97], lr: 0.01000\tTime 0.059 (0.065)\tData 0.007 (0.011)\tLoss 0.3252 (0.2948)\tPrec@1 91.406 (89.728)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [28][70/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 0.3115 (0.2964)\tPrec@1 88.281 (89.657)\tPrec@5 99.219 (99.780)\n",
            "Epoch: [28][80/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.001 (0.009)\tLoss 0.2843 (0.3008)\tPrec@1 90.625 (89.516)\tPrec@5 100.000 (99.749)\n",
            "Epoch: [28][90/97], lr: 0.01000\tTime 0.036 (0.062)\tData 0.000 (0.009)\tLoss 0.4434 (0.3072)\tPrec@1 85.156 (89.354)\tPrec@5 100.000 (99.742)\n",
            "Test: [0/100]\tTime 0.272 (0.272)\tLoss 1.4635 (1.4635)\tPrec@1 55.000 (55.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.027 (0.057)\tLoss 1.0780 (1.4116)\tPrec@1 74.000 (60.000)\tPrec@5 97.000 (96.091)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.1370 (1.4037)\tPrec@1 66.000 (59.714)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 1.3632 (1.4290)\tPrec@1 64.000 (59.387)\tPrec@5 94.000 (95.452)\n",
            "Test: [40/100]\tTime 0.041 (0.033)\tLoss 1.6281 (1.4368)\tPrec@1 58.000 (59.122)\tPrec@5 93.000 (95.220)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 1.4792 (1.4253)\tPrec@1 62.000 (59.392)\tPrec@5 95.000 (95.392)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.0662 (1.4292)\tPrec@1 65.000 (59.262)\tPrec@5 98.000 (95.393)\n",
            "Test: [70/100]\tTime 0.014 (0.030)\tLoss 1.4554 (1.4288)\tPrec@1 55.000 (58.944)\tPrec@5 95.000 (95.479)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 1.2999 (1.4169)\tPrec@1 68.000 (59.111)\tPrec@5 94.000 (95.519)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.2625 (1.4269)\tPrec@1 61.000 (58.802)\tPrec@5 97.000 (95.495)\n",
            "val Results: Prec@1 58.630 Prec@5 95.420 Loss 1.43465\n",
            "val Class Accuracy: [0.953,0.975,0.766,0.733,0.484,0.362,0.620,0.308,0.426,0.236]\n",
            "Best Prec@1: 60.150\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [29][0/97], lr: 0.01000\tTime 0.366 (0.366)\tData 0.288 (0.288)\tLoss 0.4709 (0.4709)\tPrec@1 85.156 (85.156)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [29][10/97], lr: 0.01000\tTime 0.077 (0.102)\tData 0.000 (0.036)\tLoss 0.4340 (0.2773)\tPrec@1 85.156 (90.057)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [29][20/97], lr: 0.01000\tTime 0.063 (0.082)\tData 0.000 (0.021)\tLoss 0.4079 (0.2792)\tPrec@1 85.938 (90.141)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [29][30/97], lr: 0.01000\tTime 0.068 (0.073)\tData 0.006 (0.016)\tLoss 0.2235 (0.2797)\tPrec@1 91.406 (90.222)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [29][40/97], lr: 0.01000\tTime 0.072 (0.070)\tData 0.008 (0.013)\tLoss 0.3103 (0.2761)\tPrec@1 90.625 (90.415)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [29][50/97], lr: 0.01000\tTime 0.053 (0.067)\tData 0.007 (0.012)\tLoss 0.2762 (0.2789)\tPrec@1 89.062 (90.456)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [29][60/97], lr: 0.01000\tTime 0.054 (0.066)\tData 0.000 (0.010)\tLoss 0.2542 (0.2772)\tPrec@1 92.969 (90.663)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [29][70/97], lr: 0.01000\tTime 0.045 (0.065)\tData 0.000 (0.009)\tLoss 0.3343 (0.2798)\tPrec@1 91.406 (90.438)\tPrec@5 99.219 (99.725)\n",
            "Epoch: [29][80/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.005 (0.009)\tLoss 0.3316 (0.2830)\tPrec@1 89.062 (90.336)\tPrec@5 99.219 (99.711)\n",
            "Epoch: [29][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.008)\tLoss 0.2762 (0.2853)\tPrec@1 92.188 (90.316)\tPrec@5 100.000 (99.717)\n",
            "Test: [0/100]\tTime 0.278 (0.278)\tLoss 1.6888 (1.6888)\tPrec@1 56.000 (56.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.027 (0.054)\tLoss 1.0125 (1.4392)\tPrec@1 76.000 (62.636)\tPrec@5 97.000 (96.455)\n",
            "Test: [20/100]\tTime 0.037 (0.039)\tLoss 1.1453 (1.4115)\tPrec@1 69.000 (63.810)\tPrec@5 96.000 (96.476)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.3083 (1.4281)\tPrec@1 68.000 (62.935)\tPrec@5 95.000 (96.194)\n",
            "Test: [40/100]\tTime 0.028 (0.034)\tLoss 1.3336 (1.4222)\tPrec@1 67.000 (62.780)\tPrec@5 97.000 (96.390)\n",
            "Test: [50/100]\tTime 0.019 (0.031)\tLoss 1.3225 (1.4037)\tPrec@1 65.000 (63.078)\tPrec@5 97.000 (96.510)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 1.1645 (1.4099)\tPrec@1 67.000 (62.705)\tPrec@5 96.000 (96.590)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 1.4603 (1.4140)\tPrec@1 59.000 (62.366)\tPrec@5 98.000 (96.718)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 1.1213 (1.4103)\tPrec@1 69.000 (62.543)\tPrec@5 97.000 (96.802)\n",
            "Test: [90/100]\tTime 0.017 (0.029)\tLoss 1.2981 (1.4296)\tPrec@1 67.000 (62.154)\tPrec@5 98.000 (96.835)\n",
            "val Results: Prec@1 62.090 Prec@5 96.780 Loss 1.43828\n",
            "val Class Accuracy: [0.949,0.980,0.756,0.720,0.657,0.526,0.462,0.421,0.356,0.382]\n",
            "Best Prec@1: 62.090\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [30][0/97], lr: 0.01000\tTime 0.474 (0.474)\tData 0.387 (0.387)\tLoss 0.1908 (0.1908)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [30][10/97], lr: 0.01000\tTime 0.063 (0.104)\tData 0.012 (0.039)\tLoss 0.2992 (0.2581)\tPrec@1 89.062 (91.477)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [30][20/97], lr: 0.01000\tTime 0.068 (0.080)\tData 0.007 (0.023)\tLoss 0.3134 (0.2676)\tPrec@1 89.844 (90.997)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [30][30/97], lr: 0.01000\tTime 0.044 (0.073)\tData 0.005 (0.017)\tLoss 0.3556 (0.2884)\tPrec@1 85.938 (90.096)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [30][40/97], lr: 0.01000\tTime 0.057 (0.069)\tData 0.000 (0.014)\tLoss 0.2185 (0.2981)\tPrec@1 91.406 (89.710)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [30][50/97], lr: 0.01000\tTime 0.063 (0.067)\tData 0.006 (0.012)\tLoss 0.1573 (0.2963)\tPrec@1 95.312 (89.828)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [30][60/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.001 (0.011)\tLoss 0.4330 (0.2960)\tPrec@1 85.938 (89.818)\tPrec@5 100.000 (99.757)\n",
            "Epoch: [30][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.012 (0.010)\tLoss 0.3063 (0.2912)\tPrec@1 88.281 (89.899)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [30][80/97], lr: 0.01000\tTime 0.060 (0.064)\tData 0.011 (0.010)\tLoss 0.3280 (0.2934)\tPrec@1 85.938 (89.815)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [30][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.009)\tLoss 0.2604 (0.2915)\tPrec@1 90.625 (89.887)\tPrec@5 100.000 (99.768)\n",
            "Test: [0/100]\tTime 0.262 (0.262)\tLoss 1.8307 (1.8307)\tPrec@1 55.000 (55.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.032 (0.052)\tLoss 1.4743 (1.6436)\tPrec@1 68.000 (58.000)\tPrec@5 91.000 (95.636)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 1.3748 (1.6136)\tPrec@1 56.000 (58.143)\tPrec@5 98.000 (95.905)\n",
            "Test: [30/100]\tTime 0.016 (0.037)\tLoss 1.4067 (1.5879)\tPrec@1 61.000 (58.000)\tPrec@5 96.000 (95.806)\n",
            "Test: [40/100]\tTime 0.036 (0.034)\tLoss 1.7385 (1.5893)\tPrec@1 59.000 (58.049)\tPrec@5 96.000 (96.073)\n",
            "Test: [50/100]\tTime 0.011 (0.032)\tLoss 1.5100 (1.5696)\tPrec@1 57.000 (58.471)\tPrec@5 94.000 (96.078)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 1.1647 (1.5659)\tPrec@1 65.000 (58.377)\tPrec@5 97.000 (96.066)\n",
            "Test: [70/100]\tTime 0.035 (0.030)\tLoss 1.6934 (1.5748)\tPrec@1 56.000 (57.958)\tPrec@5 99.000 (96.085)\n",
            "Test: [80/100]\tTime 0.034 (0.030)\tLoss 1.4207 (1.5614)\tPrec@1 71.000 (58.333)\tPrec@5 95.000 (96.222)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.3457 (1.5760)\tPrec@1 52.000 (58.132)\tPrec@5 96.000 (96.154)\n",
            "val Results: Prec@1 57.980 Prec@5 96.100 Loss 1.58401\n",
            "val Class Accuracy: [0.948,0.970,0.746,0.743,0.746,0.266,0.443,0.434,0.174,0.328]\n",
            "Best Prec@1: 62.090\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [31][0/97], lr: 0.01000\tTime 0.474 (0.474)\tData 0.384 (0.384)\tLoss 0.3299 (0.3299)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [31][10/97], lr: 0.01000\tTime 0.072 (0.101)\tData 0.000 (0.038)\tLoss 0.3318 (0.2743)\tPrec@1 88.281 (90.838)\tPrec@5 99.219 (99.645)\n",
            "Epoch: [31][20/97], lr: 0.01000\tTime 0.052 (0.081)\tData 0.000 (0.021)\tLoss 0.1813 (0.2821)\tPrec@1 91.406 (90.290)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [31][30/97], lr: 0.01000\tTime 0.044 (0.072)\tData 0.005 (0.015)\tLoss 0.3226 (0.2835)\tPrec@1 90.625 (90.247)\tPrec@5 98.438 (99.672)\n",
            "Epoch: [31][40/97], lr: 0.01000\tTime 0.057 (0.069)\tData 0.006 (0.013)\tLoss 0.3408 (0.2887)\tPrec@1 85.938 (90.072)\tPrec@5 99.219 (99.676)\n",
            "Epoch: [31][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.007 (0.011)\tLoss 0.3138 (0.2886)\tPrec@1 89.062 (89.905)\tPrec@5 99.219 (99.663)\n",
            "Epoch: [31][60/97], lr: 0.01000\tTime 0.066 (0.065)\tData 0.006 (0.010)\tLoss 0.3379 (0.2874)\tPrec@1 88.281 (90.087)\tPrec@5 99.219 (99.680)\n",
            "Epoch: [31][70/97], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.010)\tLoss 0.2947 (0.2900)\tPrec@1 92.969 (90.020)\tPrec@5 99.219 (99.681)\n",
            "Epoch: [31][80/97], lr: 0.01000\tTime 0.056 (0.063)\tData 0.006 (0.009)\tLoss 0.3340 (0.2915)\tPrec@1 88.281 (89.959)\tPrec@5 97.656 (99.624)\n",
            "Epoch: [31][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.009)\tLoss 0.2398 (0.2916)\tPrec@1 90.625 (89.878)\tPrec@5 100.000 (99.657)\n",
            "Test: [0/100]\tTime 0.361 (0.361)\tLoss 1.9189 (1.9189)\tPrec@1 55.000 (55.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.040 (0.050)\tLoss 1.2390 (1.7383)\tPrec@1 63.000 (54.000)\tPrec@5 96.000 (96.455)\n",
            "Test: [20/100]\tTime 0.013 (0.039)\tLoss 1.6195 (1.6761)\tPrec@1 56.000 (54.762)\tPrec@5 97.000 (96.286)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.4852 (1.7052)\tPrec@1 58.000 (54.774)\tPrec@5 95.000 (96.065)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 1.7337 (1.7127)\tPrec@1 54.000 (55.049)\tPrec@5 96.000 (96.049)\n",
            "Test: [50/100]\tTime 0.034 (0.032)\tLoss 1.7781 (1.6868)\tPrec@1 57.000 (55.608)\tPrec@5 96.000 (96.255)\n",
            "Test: [60/100]\tTime 0.010 (0.031)\tLoss 1.3312 (1.6942)\tPrec@1 61.000 (55.295)\tPrec@5 98.000 (96.213)\n",
            "Test: [70/100]\tTime 0.029 (0.029)\tLoss 1.5373 (1.6882)\tPrec@1 58.000 (55.282)\tPrec@5 97.000 (96.296)\n",
            "Test: [80/100]\tTime 0.015 (0.029)\tLoss 1.6994 (1.6847)\tPrec@1 63.000 (55.457)\tPrec@5 93.000 (96.259)\n",
            "Test: [90/100]\tTime 0.041 (0.028)\tLoss 1.4856 (1.6959)\tPrec@1 55.000 (55.187)\tPrec@5 98.000 (96.352)\n",
            "val Results: Prec@1 55.120 Prec@5 96.310 Loss 1.70045\n",
            "val Class Accuracy: [0.946,0.974,0.677,0.900,0.423,0.216,0.415,0.308,0.295,0.358]\n",
            "Best Prec@1: 62.090\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [32][0/97], lr: 0.01000\tTime 0.441 (0.441)\tData 0.353 (0.353)\tLoss 0.3277 (0.3277)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [32][10/97], lr: 0.01000\tTime 0.046 (0.100)\tData 0.003 (0.037)\tLoss 0.1570 (0.2567)\tPrec@1 93.750 (92.116)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [32][20/97], lr: 0.01000\tTime 0.057 (0.081)\tData 0.007 (0.023)\tLoss 0.2507 (0.2715)\tPrec@1 92.188 (91.592)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [32][30/97], lr: 0.01000\tTime 0.042 (0.073)\tData 0.000 (0.017)\tLoss 0.2439 (0.2681)\tPrec@1 89.844 (91.457)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [32][40/97], lr: 0.01000\tTime 0.052 (0.069)\tData 0.007 (0.014)\tLoss 0.2461 (0.2731)\tPrec@1 92.188 (91.063)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [32][50/97], lr: 0.01000\tTime 0.072 (0.067)\tData 0.000 (0.012)\tLoss 0.2130 (0.2775)\tPrec@1 91.406 (90.824)\tPrec@5 100.000 (99.694)\n",
            "Epoch: [32][60/97], lr: 0.01000\tTime 0.039 (0.065)\tData 0.000 (0.011)\tLoss 0.1811 (0.2724)\tPrec@1 94.531 (91.022)\tPrec@5 99.219 (99.705)\n",
            "Epoch: [32][70/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 0.2411 (0.2775)\tPrec@1 91.406 (90.746)\tPrec@5 100.000 (99.703)\n",
            "Epoch: [32][80/97], lr: 0.01000\tTime 0.058 (0.063)\tData 0.000 (0.009)\tLoss 0.2794 (0.2819)\tPrec@1 89.844 (90.519)\tPrec@5 99.219 (99.691)\n",
            "Epoch: [32][90/97], lr: 0.01000\tTime 0.028 (0.062)\tData 0.000 (0.009)\tLoss 0.1973 (0.2817)\tPrec@1 93.750 (90.479)\tPrec@5 100.000 (99.708)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.3946 (1.3946)\tPrec@1 59.000 (59.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.035 (0.054)\tLoss 0.8810 (1.2437)\tPrec@1 77.000 (64.727)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/100]\tTime 0.049 (0.046)\tLoss 1.1333 (1.2518)\tPrec@1 61.000 (64.524)\tPrec@5 96.000 (96.714)\n",
            "Test: [30/100]\tTime 0.026 (0.041)\tLoss 1.1328 (1.2610)\tPrec@1 69.000 (64.129)\tPrec@5 95.000 (96.452)\n",
            "Test: [40/100]\tTime 0.056 (0.042)\tLoss 1.1236 (1.2782)\tPrec@1 65.000 (63.854)\tPrec@5 97.000 (96.415)\n",
            "Test: [50/100]\tTime 0.060 (0.042)\tLoss 1.2117 (1.2650)\tPrec@1 67.000 (64.157)\tPrec@5 98.000 (96.627)\n",
            "Test: [60/100]\tTime 0.043 (0.041)\tLoss 1.0293 (1.2677)\tPrec@1 69.000 (63.852)\tPrec@5 95.000 (96.475)\n",
            "Test: [70/100]\tTime 0.042 (0.041)\tLoss 1.2564 (1.2679)\tPrec@1 69.000 (63.845)\tPrec@5 99.000 (96.577)\n",
            "Test: [80/100]\tTime 0.032 (0.041)\tLoss 1.1315 (1.2628)\tPrec@1 70.000 (64.037)\tPrec@5 97.000 (96.654)\n",
            "Test: [90/100]\tTime 0.045 (0.040)\tLoss 1.1158 (1.2850)\tPrec@1 70.000 (63.670)\tPrec@5 97.000 (96.681)\n",
            "val Results: Prec@1 63.680 Prec@5 96.690 Loss 1.28889\n",
            "val Class Accuracy: [0.942,0.980,0.805,0.720,0.661,0.439,0.573,0.473,0.356,0.419]\n",
            "Best Prec@1: 63.680\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [33][0/97], lr: 0.01000\tTime 0.589 (0.589)\tData 0.517 (0.517)\tLoss 0.2821 (0.2821)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [33][10/97], lr: 0.01000\tTime 0.064 (0.111)\tData 0.006 (0.052)\tLoss 0.2510 (0.1973)\tPrec@1 92.969 (92.898)\tPrec@5 99.219 (99.858)\n",
            "Epoch: [33][20/97], lr: 0.01000\tTime 0.050 (0.085)\tData 0.000 (0.030)\tLoss 0.2892 (0.2204)\tPrec@1 89.844 (92.374)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [33][30/97], lr: 0.01000\tTime 0.043 (0.076)\tData 0.000 (0.022)\tLoss 0.3192 (0.2281)\tPrec@1 89.062 (92.314)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [33][40/97], lr: 0.01000\tTime 0.058 (0.072)\tData 0.013 (0.019)\tLoss 0.1345 (0.2261)\tPrec@1 96.094 (92.340)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [33][50/97], lr: 0.01000\tTime 0.056 (0.068)\tData 0.005 (0.016)\tLoss 0.3205 (0.2410)\tPrec@1 89.062 (91.820)\tPrec@5 99.219 (99.847)\n",
            "Epoch: [33][60/97], lr: 0.01000\tTime 0.069 (0.067)\tData 0.007 (0.014)\tLoss 0.2659 (0.2524)\tPrec@1 92.188 (91.342)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [33][70/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.007 (0.013)\tLoss 0.3212 (0.2577)\tPrec@1 89.062 (91.054)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [33][80/97], lr: 0.01000\tTime 0.058 (0.064)\tData 0.006 (0.012)\tLoss 0.2699 (0.2647)\tPrec@1 91.406 (90.818)\tPrec@5 100.000 (99.797)\n",
            "Epoch: [33][90/97], lr: 0.01000\tTime 0.024 (0.063)\tData 0.000 (0.011)\tLoss 0.2785 (0.2692)\tPrec@1 89.844 (90.728)\tPrec@5 99.219 (99.768)\n",
            "Test: [0/100]\tTime 0.258 (0.258)\tLoss 1.3355 (1.3355)\tPrec@1 61.000 (61.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.014 (0.052)\tLoss 1.1402 (1.3557)\tPrec@1 71.000 (63.091)\tPrec@5 96.000 (96.273)\n",
            "Test: [20/100]\tTime 0.025 (0.042)\tLoss 1.1336 (1.3079)\tPrec@1 63.000 (63.381)\tPrec@5 100.000 (96.429)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.3500 (1.3523)\tPrec@1 67.000 (63.226)\tPrec@5 93.000 (95.903)\n",
            "Test: [40/100]\tTime 0.046 (0.034)\tLoss 1.4283 (1.3689)\tPrec@1 59.000 (63.390)\tPrec@5 96.000 (95.902)\n",
            "Test: [50/100]\tTime 0.027 (0.033)\tLoss 1.4133 (1.3573)\tPrec@1 68.000 (63.882)\tPrec@5 95.000 (95.902)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.0566 (1.3617)\tPrec@1 73.000 (63.508)\tPrec@5 97.000 (95.869)\n",
            "Test: [70/100]\tTime 0.021 (0.031)\tLoss 1.4311 (1.3615)\tPrec@1 65.000 (63.338)\tPrec@5 98.000 (95.873)\n",
            "Test: [80/100]\tTime 0.042 (0.030)\tLoss 1.3739 (1.3612)\tPrec@1 65.000 (63.296)\tPrec@5 95.000 (95.840)\n",
            "Test: [90/100]\tTime 0.017 (0.030)\tLoss 1.2904 (1.3780)\tPrec@1 62.000 (62.912)\tPrec@5 97.000 (95.890)\n",
            "val Results: Prec@1 63.050 Prec@5 95.820 Loss 1.38170\n",
            "val Class Accuracy: [0.940,0.953,0.653,0.821,0.792,0.381,0.616,0.380,0.412,0.357]\n",
            "Best Prec@1: 63.680\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [34][0/97], lr: 0.01000\tTime 0.389 (0.389)\tData 0.301 (0.301)\tLoss 0.2183 (0.2183)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [34][10/97], lr: 0.01000\tTime 0.045 (0.101)\tData 0.000 (0.032)\tLoss 0.2865 (0.2650)\tPrec@1 90.625 (91.477)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [34][20/97], lr: 0.01000\tTime 0.038 (0.080)\tData 0.000 (0.018)\tLoss 0.1957 (0.2582)\tPrec@1 92.188 (91.592)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [34][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.007 (0.014)\tLoss 0.2540 (0.2620)\tPrec@1 91.406 (91.431)\tPrec@5 99.219 (99.698)\n",
            "Epoch: [34][40/97], lr: 0.01000\tTime 0.073 (0.070)\tData 0.007 (0.012)\tLoss 0.3142 (0.2626)\tPrec@1 89.062 (91.292)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [34][50/97], lr: 0.01000\tTime 0.058 (0.068)\tData 0.005 (0.011)\tLoss 0.2620 (0.2565)\tPrec@1 89.844 (91.437)\tPrec@5 100.000 (99.694)\n",
            "Epoch: [34][60/97], lr: 0.01000\tTime 0.053 (0.066)\tData 0.009 (0.010)\tLoss 0.2721 (0.2574)\tPrec@1 90.625 (91.470)\tPrec@5 100.000 (99.718)\n",
            "Epoch: [34][70/97], lr: 0.01000\tTime 0.063 (0.064)\tData 0.005 (0.009)\tLoss 0.3328 (0.2615)\tPrec@1 85.938 (91.252)\tPrec@5 100.000 (99.725)\n",
            "Epoch: [34][80/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.000 (0.009)\tLoss 0.3488 (0.2689)\tPrec@1 86.719 (90.914)\tPrec@5 98.438 (99.711)\n",
            "Epoch: [34][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.3457 (0.2731)\tPrec@1 86.719 (90.702)\tPrec@5 100.000 (99.700)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 1.3979 (1.3979)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.028 (0.057)\tLoss 1.0478 (1.2551)\tPrec@1 73.000 (63.636)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/100]\tTime 0.025 (0.038)\tLoss 1.0221 (1.2656)\tPrec@1 66.000 (64.381)\tPrec@5 99.000 (97.000)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 1.2276 (1.2795)\tPrec@1 65.000 (64.387)\tPrec@5 96.000 (96.710)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 1.3094 (1.2897)\tPrec@1 70.000 (64.024)\tPrec@5 95.000 (96.683)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.2770 (1.2735)\tPrec@1 64.000 (64.686)\tPrec@5 95.000 (96.784)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.0264 (1.2860)\tPrec@1 64.000 (64.377)\tPrec@5 98.000 (96.721)\n",
            "Test: [70/100]\tTime 0.037 (0.030)\tLoss 1.5955 (1.2802)\tPrec@1 65.000 (64.408)\tPrec@5 98.000 (96.789)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 1.0937 (1.2770)\tPrec@1 72.000 (64.494)\tPrec@5 99.000 (96.790)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.1896 (1.2946)\tPrec@1 61.000 (64.088)\tPrec@5 99.000 (96.747)\n",
            "val Results: Prec@1 64.060 Prec@5 96.680 Loss 1.29353\n",
            "val Class Accuracy: [0.922,0.851,0.681,0.590,0.644,0.547,0.467,0.384,0.784,0.536]\n",
            "Best Prec@1: 64.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [35][0/97], lr: 0.01000\tTime 0.443 (0.443)\tData 0.343 (0.343)\tLoss 0.2488 (0.2488)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [35][10/97], lr: 0.01000\tTime 0.047 (0.101)\tData 0.000 (0.034)\tLoss 0.1979 (0.2481)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [35][20/97], lr: 0.01000\tTime 0.048 (0.079)\tData 0.000 (0.021)\tLoss 0.2436 (0.2410)\tPrec@1 90.625 (91.592)\tPrec@5 99.219 (99.851)\n",
            "Epoch: [35][30/97], lr: 0.01000\tTime 0.040 (0.071)\tData 0.000 (0.016)\tLoss 0.2205 (0.2537)\tPrec@1 91.406 (91.079)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [35][40/97], lr: 0.01000\tTime 0.061 (0.069)\tData 0.000 (0.013)\tLoss 0.1541 (0.2581)\tPrec@1 95.312 (90.930)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [35][50/97], lr: 0.01000\tTime 0.054 (0.067)\tData 0.012 (0.011)\tLoss 0.2828 (0.2560)\tPrec@1 92.188 (91.100)\tPrec@5 99.219 (99.862)\n",
            "Epoch: [35][60/97], lr: 0.01000\tTime 0.047 (0.066)\tData 0.007 (0.010)\tLoss 0.3208 (0.2641)\tPrec@1 88.281 (90.779)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [35][70/97], lr: 0.01000\tTime 0.091 (0.065)\tData 0.004 (0.010)\tLoss 0.2699 (0.2690)\tPrec@1 92.188 (90.570)\tPrec@5 98.438 (99.769)\n",
            "Epoch: [35][80/97], lr: 0.01000\tTime 0.074 (0.064)\tData 0.012 (0.009)\tLoss 0.2442 (0.2685)\tPrec@1 92.188 (90.557)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [35][90/97], lr: 0.01000\tTime 0.043 (0.062)\tData 0.000 (0.009)\tLoss 0.3163 (0.2707)\tPrec@1 89.062 (90.453)\tPrec@5 100.000 (99.760)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 1.5288 (1.5288)\tPrec@1 58.000 (58.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.023 (0.055)\tLoss 1.1596 (1.4356)\tPrec@1 69.000 (61.545)\tPrec@5 95.000 (95.364)\n",
            "Test: [20/100]\tTime 0.034 (0.039)\tLoss 0.9230 (1.3444)\tPrec@1 72.000 (63.048)\tPrec@5 98.000 (95.905)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 1.2846 (1.3874)\tPrec@1 65.000 (62.613)\tPrec@5 95.000 (95.839)\n",
            "Test: [40/100]\tTime 0.028 (0.033)\tLoss 1.4514 (1.3914)\tPrec@1 65.000 (62.537)\tPrec@5 94.000 (95.927)\n",
            "Test: [50/100]\tTime 0.038 (0.031)\tLoss 1.4189 (1.3784)\tPrec@1 64.000 (62.863)\tPrec@5 98.000 (96.059)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 1.0710 (1.3774)\tPrec@1 68.000 (63.082)\tPrec@5 96.000 (96.049)\n",
            "Test: [70/100]\tTime 0.010 (0.028)\tLoss 1.2733 (1.3793)\tPrec@1 60.000 (62.620)\tPrec@5 97.000 (96.099)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 1.3044 (1.3685)\tPrec@1 67.000 (62.778)\tPrec@5 95.000 (96.210)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 1.3417 (1.3910)\tPrec@1 67.000 (62.396)\tPrec@5 97.000 (96.143)\n",
            "val Results: Prec@1 62.400 Prec@5 96.160 Loss 1.39144\n",
            "val Class Accuracy: [0.973,0.973,0.571,0.747,0.590,0.552,0.587,0.555,0.285,0.407]\n",
            "Best Prec@1: 64.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [36][0/97], lr: 0.01000\tTime 0.474 (0.474)\tData 0.375 (0.375)\tLoss 0.1551 (0.1551)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [36][10/97], lr: 0.01000\tTime 0.045 (0.100)\tData 0.000 (0.039)\tLoss 0.2485 (0.2471)\tPrec@1 89.062 (91.406)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [36][20/97], lr: 0.01000\tTime 0.045 (0.080)\tData 0.000 (0.023)\tLoss 0.1807 (0.2369)\tPrec@1 92.969 (91.667)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [36][30/97], lr: 0.01000\tTime 0.063 (0.073)\tData 0.009 (0.017)\tLoss 0.1988 (0.2371)\tPrec@1 92.188 (91.532)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [36][40/97], lr: 0.01000\tTime 0.076 (0.070)\tData 0.006 (0.015)\tLoss 0.1703 (0.2335)\tPrec@1 94.531 (91.864)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [36][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.001 (0.012)\tLoss 0.2828 (0.2410)\tPrec@1 89.844 (91.483)\tPrec@5 99.219 (99.847)\n",
            "Epoch: [36][60/97], lr: 0.01000\tTime 0.073 (0.066)\tData 0.017 (0.011)\tLoss 0.5885 (0.2521)\tPrec@1 79.688 (91.099)\tPrec@5 99.219 (99.821)\n",
            "Epoch: [36][70/97], lr: 0.01000\tTime 0.055 (0.065)\tData 0.000 (0.011)\tLoss 0.3195 (0.2634)\tPrec@1 89.062 (90.790)\tPrec@5 100.000 (99.802)\n",
            "Epoch: [36][80/97], lr: 0.01000\tTime 0.039 (0.064)\tData 0.000 (0.010)\tLoss 0.2322 (0.2657)\tPrec@1 88.281 (90.615)\tPrec@5 100.000 (99.797)\n",
            "Epoch: [36][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.2628 (0.2734)\tPrec@1 93.750 (90.290)\tPrec@5 99.219 (99.785)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 1.6827 (1.6827)\tPrec@1 54.000 (54.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.014 (0.052)\tLoss 1.2032 (1.4422)\tPrec@1 69.000 (59.636)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.025 (0.040)\tLoss 1.2531 (1.4667)\tPrec@1 64.000 (60.048)\tPrec@5 99.000 (96.238)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 1.4055 (1.5067)\tPrec@1 60.000 (59.387)\tPrec@5 92.000 (95.710)\n",
            "Test: [40/100]\tTime 0.038 (0.032)\tLoss 1.6367 (1.5352)\tPrec@1 57.000 (58.951)\tPrec@5 94.000 (95.610)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.4474 (1.5160)\tPrec@1 58.000 (59.294)\tPrec@5 95.000 (95.667)\n",
            "Test: [60/100]\tTime 0.021 (0.029)\tLoss 1.3055 (1.5231)\tPrec@1 66.000 (59.148)\tPrec@5 95.000 (95.492)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 1.5002 (1.5134)\tPrec@1 61.000 (59.197)\tPrec@5 97.000 (95.592)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 1.3239 (1.5194)\tPrec@1 63.000 (59.173)\tPrec@5 94.000 (95.617)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 1.4125 (1.5314)\tPrec@1 60.000 (59.286)\tPrec@5 94.000 (95.505)\n",
            "val Results: Prec@1 59.250 Prec@5 95.540 Loss 1.53001\n",
            "val Class Accuracy: [0.952,0.976,0.617,0.673,0.586,0.501,0.401,0.321,0.372,0.526]\n",
            "Best Prec@1: 64.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [37][0/97], lr: 0.01000\tTime 0.442 (0.442)\tData 0.346 (0.346)\tLoss 0.2196 (0.2196)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [37][10/97], lr: 0.01000\tTime 0.082 (0.100)\tData 0.000 (0.034)\tLoss 0.2318 (0.2476)\tPrec@1 91.406 (91.335)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [37][20/97], lr: 0.01000\tTime 0.058 (0.083)\tData 0.006 (0.021)\tLoss 0.2592 (0.2473)\tPrec@1 93.750 (91.555)\tPrec@5 98.438 (99.702)\n",
            "Epoch: [37][30/97], lr: 0.01000\tTime 0.061 (0.075)\tData 0.000 (0.015)\tLoss 0.2489 (0.2362)\tPrec@1 89.844 (91.809)\tPrec@5 100.000 (99.773)\n",
            "Epoch: [37][40/97], lr: 0.01000\tTime 0.062 (0.071)\tData 0.009 (0.013)\tLoss 0.3468 (0.2398)\tPrec@1 87.500 (91.711)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [37][50/97], lr: 0.01000\tTime 0.062 (0.068)\tData 0.011 (0.011)\tLoss 0.2788 (0.2431)\tPrec@1 91.406 (91.743)\tPrec@5 100.000 (99.786)\n",
            "Epoch: [37][60/97], lr: 0.01000\tTime 0.049 (0.066)\tData 0.000 (0.010)\tLoss 0.3227 (0.2530)\tPrec@1 88.281 (91.406)\tPrec@5 100.000 (99.782)\n",
            "Epoch: [37][70/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.000 (0.009)\tLoss 0.2964 (0.2581)\tPrec@1 89.062 (91.197)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [37][80/97], lr: 0.01000\tTime 0.049 (0.065)\tData 0.007 (0.008)\tLoss 0.1954 (0.2604)\tPrec@1 94.531 (91.078)\tPrec@5 100.000 (99.759)\n",
            "Epoch: [37][90/97], lr: 0.01000\tTime 0.033 (0.064)\tData 0.000 (0.008)\tLoss 0.1764 (0.2608)\tPrec@1 92.188 (90.960)\tPrec@5 100.000 (99.768)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 2.5884 (2.5884)\tPrec@1 44.000 (44.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.010 (0.057)\tLoss 1.8203 (2.3036)\tPrec@1 65.000 (50.364)\tPrec@5 95.000 (94.273)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 2.0784 (2.2864)\tPrec@1 50.000 (49.190)\tPrec@5 97.000 (94.810)\n",
            "Test: [30/100]\tTime 0.011 (0.036)\tLoss 1.9546 (2.2676)\tPrec@1 55.000 (49.452)\tPrec@5 92.000 (94.581)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 2.7682 (2.2676)\tPrec@1 42.000 (49.805)\tPrec@5 94.000 (94.659)\n",
            "Test: [50/100]\tTime 0.020 (0.032)\tLoss 2.5901 (2.2558)\tPrec@1 48.000 (50.216)\tPrec@5 96.000 (94.941)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.7233 (2.2557)\tPrec@1 59.000 (50.082)\tPrec@5 94.000 (94.984)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 2.5177 (2.2686)\tPrec@1 47.000 (50.014)\tPrec@5 96.000 (94.915)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 2.1005 (2.2562)\tPrec@1 56.000 (50.099)\tPrec@5 92.000 (94.926)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 2.1070 (2.2880)\tPrec@1 53.000 (49.747)\tPrec@5 96.000 (94.890)\n",
            "val Results: Prec@1 49.700 Prec@5 94.910 Loss 2.29747\n",
            "val Class Accuracy: [0.963,0.918,0.891,0.538,0.489,0.356,0.332,0.271,0.044,0.168]\n",
            "Best Prec@1: 64.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [38][0/97], lr: 0.01000\tTime 0.405 (0.405)\tData 0.312 (0.312)\tLoss 0.2685 (0.2685)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [38][10/97], lr: 0.01000\tTime 0.051 (0.101)\tData 0.005 (0.033)\tLoss 0.2663 (0.2523)\tPrec@1 90.625 (91.690)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [38][20/97], lr: 0.01000\tTime 0.057 (0.080)\tData 0.000 (0.020)\tLoss 0.1889 (0.2361)\tPrec@1 95.312 (92.374)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [38][30/97], lr: 0.01000\tTime 0.062 (0.072)\tData 0.006 (0.015)\tLoss 0.2760 (0.2527)\tPrec@1 89.844 (91.608)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [38][40/97], lr: 0.01000\tTime 0.067 (0.069)\tData 0.000 (0.012)\tLoss 0.3268 (0.2511)\tPrec@1 86.719 (91.502)\tPrec@5 99.219 (99.848)\n",
            "Epoch: [38][50/97], lr: 0.01000\tTime 0.062 (0.066)\tData 0.013 (0.011)\tLoss 0.2243 (0.2591)\tPrec@1 92.188 (91.161)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [38][60/97], lr: 0.01000\tTime 0.070 (0.065)\tData 0.005 (0.010)\tLoss 0.2357 (0.2591)\tPrec@1 92.188 (91.201)\tPrec@5 100.000 (99.808)\n",
            "Epoch: [38][70/97], lr: 0.01000\tTime 0.053 (0.064)\tData 0.005 (0.009)\tLoss 0.2383 (0.2561)\tPrec@1 89.062 (91.252)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [38][80/97], lr: 0.01000\tTime 0.037 (0.063)\tData 0.000 (0.008)\tLoss 0.2195 (0.2560)\tPrec@1 92.188 (91.223)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [38][90/97], lr: 0.01000\tTime 0.038 (0.062)\tData 0.000 (0.008)\tLoss 0.2309 (0.2558)\tPrec@1 90.625 (91.209)\tPrec@5 100.000 (99.811)\n",
            "Test: [0/100]\tTime 0.273 (0.273)\tLoss 1.1742 (1.1742)\tPrec@1 66.000 (66.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.017 (0.054)\tLoss 0.7973 (1.1037)\tPrec@1 77.000 (68.364)\tPrec@5 100.000 (97.636)\n",
            "Test: [20/100]\tTime 0.038 (0.041)\tLoss 0.8398 (1.0945)\tPrec@1 74.000 (68.762)\tPrec@5 97.000 (97.286)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.2151 (1.1174)\tPrec@1 66.000 (67.839)\tPrec@5 94.000 (97.097)\n",
            "Test: [40/100]\tTime 0.016 (0.033)\tLoss 1.3826 (1.1352)\tPrec@1 60.000 (67.683)\tPrec@5 96.000 (96.902)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.2859 (1.1234)\tPrec@1 70.000 (68.098)\tPrec@5 96.000 (97.000)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 1.1079 (1.1373)\tPrec@1 66.000 (67.738)\tPrec@5 96.000 (96.967)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 1.2991 (1.1429)\tPrec@1 67.000 (67.535)\tPrec@5 98.000 (96.986)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 0.9268 (1.1307)\tPrec@1 77.000 (67.790)\tPrec@5 98.000 (97.000)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.1715 (1.1436)\tPrec@1 64.000 (67.451)\tPrec@5 98.000 (97.000)\n",
            "val Results: Prec@1 67.370 Prec@5 96.940 Loss 1.14776\n",
            "val Class Accuracy: [0.959,0.944,0.713,0.740,0.701,0.502,0.627,0.380,0.546,0.625]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [39][0/97], lr: 0.01000\tTime 0.481 (0.481)\tData 0.391 (0.391)\tLoss 0.1714 (0.1714)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [39][10/97], lr: 0.01000\tTime 0.038 (0.103)\tData 0.000 (0.041)\tLoss 0.3809 (0.2475)\tPrec@1 85.156 (91.548)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [39][20/97], lr: 0.01000\tTime 0.041 (0.081)\tData 0.000 (0.024)\tLoss 0.3171 (0.2430)\tPrec@1 89.844 (91.592)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [39][30/97], lr: 0.01000\tTime 0.041 (0.074)\tData 0.000 (0.017)\tLoss 0.2553 (0.2413)\tPrec@1 91.406 (91.557)\tPrec@5 99.219 (99.874)\n",
            "Epoch: [39][40/97], lr: 0.01000\tTime 0.055 (0.070)\tData 0.000 (0.014)\tLoss 0.2137 (0.2472)\tPrec@1 92.188 (91.387)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [39][50/97], lr: 0.01000\tTime 0.073 (0.068)\tData 0.001 (0.012)\tLoss 0.2839 (0.2444)\tPrec@1 89.062 (91.544)\tPrec@5 98.438 (99.801)\n",
            "Epoch: [39][60/97], lr: 0.01000\tTime 0.080 (0.066)\tData 0.007 (0.011)\tLoss 0.2735 (0.2405)\tPrec@1 90.625 (91.688)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [39][70/97], lr: 0.01000\tTime 0.057 (0.065)\tData 0.007 (0.010)\tLoss 0.1706 (0.2352)\tPrec@1 94.531 (91.868)\tPrec@5 100.000 (99.813)\n",
            "Epoch: [39][80/97], lr: 0.01000\tTime 0.076 (0.065)\tData 0.005 (0.009)\tLoss 0.2318 (0.2393)\tPrec@1 89.844 (91.705)\tPrec@5 100.000 (99.817)\n",
            "Epoch: [39][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 0.2125 (0.2383)\tPrec@1 93.750 (91.690)\tPrec@5 100.000 (99.820)\n",
            "Test: [0/100]\tTime 0.330 (0.330)\tLoss 2.5712 (2.5712)\tPrec@1 51.000 (51.000)\tPrec@5 88.000 (88.000)\n",
            "Test: [10/100]\tTime 0.018 (0.056)\tLoss 2.1330 (2.3654)\tPrec@1 58.000 (53.091)\tPrec@5 91.000 (92.273)\n",
            "Test: [20/100]\tTime 0.036 (0.042)\tLoss 1.9218 (2.3265)\tPrec@1 52.000 (52.571)\tPrec@5 93.000 (92.762)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 2.1670 (2.2945)\tPrec@1 56.000 (53.065)\tPrec@5 94.000 (92.645)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 2.4140 (2.2691)\tPrec@1 51.000 (53.220)\tPrec@5 90.000 (92.951)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 2.3854 (2.2438)\tPrec@1 51.000 (53.686)\tPrec@5 94.000 (93.176)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 1.8874 (2.2589)\tPrec@1 60.000 (53.295)\tPrec@5 95.000 (93.213)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 2.3265 (2.2718)\tPrec@1 53.000 (53.155)\tPrec@5 96.000 (93.225)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.5340 (2.2466)\tPrec@1 64.000 (53.333)\tPrec@5 96.000 (93.395)\n",
            "Test: [90/100]\tTime 0.046 (0.029)\tLoss 1.8834 (2.2714)\tPrec@1 58.000 (53.066)\tPrec@5 95.000 (93.297)\n",
            "val Results: Prec@1 52.910 Prec@5 93.330 Loss 2.27611\n",
            "val Class Accuracy: [0.897,0.961,0.892,0.556,0.782,0.323,0.065,0.279,0.208,0.328]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [40][0/97], lr: 0.01000\tTime 0.493 (0.493)\tData 0.419 (0.419)\tLoss 0.3054 (0.3054)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [40][10/97], lr: 0.01000\tTime 0.041 (0.102)\tData 0.000 (0.044)\tLoss 0.3125 (0.2352)\tPrec@1 88.281 (91.690)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [40][20/97], lr: 0.01000\tTime 0.061 (0.082)\tData 0.013 (0.026)\tLoss 0.2411 (0.2303)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.814)\n",
            "Epoch: [40][30/97], lr: 0.01000\tTime 0.068 (0.074)\tData 0.001 (0.019)\tLoss 0.2061 (0.2298)\tPrec@1 93.750 (92.188)\tPrec@5 99.219 (99.824)\n",
            "Epoch: [40][40/97], lr: 0.01000\tTime 0.054 (0.070)\tData 0.000 (0.015)\tLoss 0.2799 (0.2453)\tPrec@1 90.625 (91.482)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [40][50/97], lr: 0.01000\tTime 0.036 (0.068)\tData 0.000 (0.013)\tLoss 0.2669 (0.2500)\tPrec@1 92.188 (91.452)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [40][60/97], lr: 0.01000\tTime 0.058 (0.066)\tData 0.000 (0.012)\tLoss 0.2516 (0.2502)\tPrec@1 89.062 (91.432)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [40][70/97], lr: 0.01000\tTime 0.061 (0.065)\tData 0.006 (0.011)\tLoss 0.1925 (0.2460)\tPrec@1 94.531 (91.615)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [40][80/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.005 (0.010)\tLoss 0.1303 (0.2440)\tPrec@1 96.875 (91.696)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [40][90/97], lr: 0.01000\tTime 0.026 (0.063)\tData 0.000 (0.009)\tLoss 0.2129 (0.2410)\tPrec@1 91.406 (91.715)\tPrec@5 100.000 (99.845)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 1.8969 (1.8969)\tPrec@1 52.000 (52.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.013 (0.055)\tLoss 1.1550 (1.7118)\tPrec@1 71.000 (59.545)\tPrec@5 97.000 (96.364)\n",
            "Test: [20/100]\tTime 0.042 (0.042)\tLoss 1.4697 (1.6940)\tPrec@1 59.000 (58.952)\tPrec@5 96.000 (96.238)\n",
            "Test: [30/100]\tTime 0.029 (0.036)\tLoss 1.6155 (1.7255)\tPrec@1 55.000 (57.935)\tPrec@5 94.000 (95.581)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 1.7101 (1.7266)\tPrec@1 56.000 (58.146)\tPrec@5 97.000 (95.780)\n",
            "Test: [50/100]\tTime 0.034 (0.032)\tLoss 1.6604 (1.7124)\tPrec@1 60.000 (58.490)\tPrec@5 95.000 (95.941)\n",
            "Test: [60/100]\tTime 0.032 (0.031)\tLoss 1.2851 (1.7048)\tPrec@1 61.000 (58.295)\tPrec@5 94.000 (95.869)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 2.0099 (1.7106)\tPrec@1 55.000 (58.296)\tPrec@5 96.000 (95.845)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.6483 (1.7000)\tPrec@1 62.000 (58.469)\tPrec@5 94.000 (95.877)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 1.6271 (1.7229)\tPrec@1 63.000 (58.132)\tPrec@5 96.000 (95.791)\n",
            "val Results: Prec@1 58.200 Prec@5 95.760 Loss 1.71996\n",
            "val Class Accuracy: [0.957,0.979,0.785,0.733,0.540,0.361,0.562,0.473,0.184,0.246]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [41][0/97], lr: 0.01000\tTime 0.481 (0.481)\tData 0.408 (0.408)\tLoss 0.3557 (0.3557)\tPrec@1 89.062 (89.062)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [41][10/97], lr: 0.01000\tTime 0.050 (0.101)\tData 0.006 (0.043)\tLoss 0.2049 (0.2361)\tPrec@1 94.531 (92.045)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [41][20/97], lr: 0.01000\tTime 0.047 (0.081)\tData 0.007 (0.025)\tLoss 0.1471 (0.2469)\tPrec@1 96.094 (91.704)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [41][30/97], lr: 0.01000\tTime 0.059 (0.073)\tData 0.007 (0.019)\tLoss 0.2871 (0.2517)\tPrec@1 88.281 (91.457)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [41][40/97], lr: 0.01000\tTime 0.058 (0.069)\tData 0.000 (0.016)\tLoss 0.2599 (0.2547)\tPrec@1 90.625 (91.425)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [41][50/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.005 (0.014)\tLoss 0.1824 (0.2533)\tPrec@1 92.188 (91.314)\tPrec@5 100.000 (99.755)\n",
            "Epoch: [41][60/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.012)\tLoss 0.1822 (0.2545)\tPrec@1 91.406 (91.253)\tPrec@5 100.000 (99.757)\n",
            "Epoch: [41][70/97], lr: 0.01000\tTime 0.088 (0.064)\tData 0.007 (0.011)\tLoss 0.2912 (0.2562)\tPrec@1 89.062 (91.120)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [41][80/97], lr: 0.01000\tTime 0.058 (0.063)\tData 0.005 (0.010)\tLoss 0.3225 (0.2569)\tPrec@1 88.281 (91.088)\tPrec@5 100.000 (99.749)\n",
            "Epoch: [41][90/97], lr: 0.01000\tTime 0.033 (0.062)\tData 0.000 (0.010)\tLoss 0.2489 (0.2570)\tPrec@1 92.188 (91.106)\tPrec@5 100.000 (99.751)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 1.6027 (1.6027)\tPrec@1 62.000 (62.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.015 (0.056)\tLoss 1.1979 (1.5263)\tPrec@1 70.000 (60.545)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/100]\tTime 0.010 (0.041)\tLoss 1.5428 (1.4900)\tPrec@1 65.000 (62.190)\tPrec@5 98.000 (97.333)\n",
            "Test: [30/100]\tTime 0.040 (0.035)\tLoss 1.5455 (1.4949)\tPrec@1 65.000 (62.387)\tPrec@5 94.000 (96.871)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.6378 (1.4884)\tPrec@1 55.000 (62.146)\tPrec@5 96.000 (96.829)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.4079 (1.4669)\tPrec@1 67.000 (62.765)\tPrec@5 95.000 (96.765)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 1.1976 (1.4722)\tPrec@1 68.000 (62.082)\tPrec@5 98.000 (96.738)\n",
            "Test: [70/100]\tTime 0.041 (0.030)\tLoss 1.7117 (1.4716)\tPrec@1 63.000 (61.915)\tPrec@5 99.000 (96.761)\n",
            "Test: [80/100]\tTime 0.031 (0.030)\tLoss 1.0112 (1.4608)\tPrec@1 75.000 (62.099)\tPrec@5 95.000 (96.728)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.2829 (1.4784)\tPrec@1 63.000 (61.615)\tPrec@5 96.000 (96.593)\n",
            "val Results: Prec@1 61.620 Prec@5 96.490 Loss 1.48430\n",
            "val Class Accuracy: [0.950,0.985,0.761,0.573,0.839,0.514,0.264,0.410,0.389,0.477]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [42][0/97], lr: 0.01000\tTime 0.412 (0.412)\tData 0.323 (0.323)\tLoss 0.2810 (0.2810)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [42][10/97], lr: 0.01000\tTime 0.043 (0.102)\tData 0.000 (0.032)\tLoss 0.3707 (0.2339)\tPrec@1 89.062 (92.401)\tPrec@5 99.219 (99.787)\n",
            "Epoch: [42][20/97], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.019)\tLoss 0.2033 (0.2356)\tPrec@1 92.188 (92.299)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [42][30/97], lr: 0.01000\tTime 0.072 (0.074)\tData 0.006 (0.014)\tLoss 0.2137 (0.2413)\tPrec@1 92.969 (91.759)\tPrec@5 99.219 (99.773)\n",
            "Epoch: [42][40/97], lr: 0.01000\tTime 0.057 (0.069)\tData 0.000 (0.011)\tLoss 0.2434 (0.2357)\tPrec@1 91.406 (91.978)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [42][50/97], lr: 0.01000\tTime 0.044 (0.067)\tData 0.000 (0.010)\tLoss 0.2092 (0.2336)\tPrec@1 94.531 (92.034)\tPrec@5 99.219 (99.801)\n",
            "Epoch: [42][60/97], lr: 0.01000\tTime 0.067 (0.066)\tData 0.007 (0.009)\tLoss 0.2366 (0.2331)\tPrec@1 91.406 (92.008)\tPrec@5 100.000 (99.808)\n",
            "Epoch: [42][70/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.007 (0.008)\tLoss 0.1573 (0.2334)\tPrec@1 96.875 (91.923)\tPrec@5 100.000 (99.791)\n",
            "Epoch: [42][80/97], lr: 0.01000\tTime 0.070 (0.064)\tData 0.007 (0.008)\tLoss 0.1977 (0.2348)\tPrec@1 92.969 (91.946)\tPrec@5 99.219 (99.778)\n",
            "Epoch: [42][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.007)\tLoss 0.3212 (0.2323)\tPrec@1 89.062 (91.947)\tPrec@5 100.000 (99.777)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 1.4003 (1.4003)\tPrec@1 64.000 (64.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.010 (0.052)\tLoss 1.1253 (1.5303)\tPrec@1 70.000 (62.636)\tPrec@5 98.000 (96.091)\n",
            "Test: [20/100]\tTime 0.032 (0.040)\tLoss 1.3569 (1.4858)\tPrec@1 61.000 (64.619)\tPrec@5 97.000 (96.333)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 1.5808 (1.5609)\tPrec@1 64.000 (63.935)\tPrec@5 93.000 (95.903)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.5036 (1.5770)\tPrec@1 61.000 (63.415)\tPrec@5 98.000 (95.927)\n",
            "Test: [50/100]\tTime 0.016 (0.031)\tLoss 1.5929 (1.5400)\tPrec@1 65.000 (63.824)\tPrec@5 96.000 (95.980)\n",
            "Test: [60/100]\tTime 0.043 (0.030)\tLoss 1.4700 (1.5463)\tPrec@1 65.000 (63.492)\tPrec@5 97.000 (95.984)\n",
            "Test: [70/100]\tTime 0.028 (0.029)\tLoss 1.7711 (1.5373)\tPrec@1 64.000 (63.592)\tPrec@5 96.000 (96.028)\n",
            "Test: [80/100]\tTime 0.037 (0.029)\tLoss 1.4906 (1.5320)\tPrec@1 64.000 (63.667)\tPrec@5 96.000 (96.062)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 1.6048 (1.5452)\tPrec@1 63.000 (63.582)\tPrec@5 95.000 (96.022)\n",
            "val Results: Prec@1 63.580 Prec@5 95.970 Loss 1.54932\n",
            "val Class Accuracy: [0.899,0.941,0.703,0.849,0.753,0.371,0.655,0.205,0.587,0.395]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [43][0/97], lr: 0.01000\tTime 0.442 (0.442)\tData 0.348 (0.348)\tLoss 0.2814 (0.2814)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [43][10/97], lr: 0.01000\tTime 0.051 (0.104)\tData 0.000 (0.038)\tLoss 0.1587 (0.2100)\tPrec@1 96.875 (93.395)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [43][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.008 (0.023)\tLoss 0.1570 (0.1933)\tPrec@1 93.750 (93.601)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [43][30/97], lr: 0.01000\tTime 0.083 (0.074)\tData 0.006 (0.017)\tLoss 0.3099 (0.2077)\tPrec@1 89.844 (92.893)\tPrec@5 99.219 (99.899)\n",
            "Epoch: [43][40/97], lr: 0.01000\tTime 0.061 (0.070)\tData 0.000 (0.013)\tLoss 0.1815 (0.2082)\tPrec@1 92.969 (92.912)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [43][50/97], lr: 0.01000\tTime 0.068 (0.068)\tData 0.004 (0.011)\tLoss 0.2738 (0.2182)\tPrec@1 91.406 (92.601)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [43][60/97], lr: 0.01000\tTime 0.052 (0.067)\tData 0.007 (0.011)\tLoss 0.2781 (0.2232)\tPrec@1 89.844 (92.380)\tPrec@5 100.000 (99.821)\n",
            "Epoch: [43][70/97], lr: 0.01000\tTime 0.063 (0.065)\tData 0.010 (0.010)\tLoss 0.2592 (0.2283)\tPrec@1 88.281 (92.055)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [43][80/97], lr: 0.01000\tTime 0.062 (0.064)\tData 0.001 (0.009)\tLoss 0.1893 (0.2290)\tPrec@1 92.188 (92.062)\tPrec@5 100.000 (99.826)\n",
            "Epoch: [43][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.009)\tLoss 0.3235 (0.2343)\tPrec@1 92.188 (91.853)\tPrec@5 98.438 (99.820)\n",
            "Test: [0/100]\tTime 0.263 (0.263)\tLoss 2.2280 (2.2280)\tPrec@1 46.000 (46.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.017 (0.055)\tLoss 2.0439 (2.3403)\tPrec@1 57.000 (50.000)\tPrec@5 96.000 (95.364)\n",
            "Test: [20/100]\tTime 0.034 (0.042)\tLoss 2.1853 (2.2997)\tPrec@1 56.000 (50.476)\tPrec@5 98.000 (95.095)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 2.0126 (2.2650)\tPrec@1 55.000 (50.871)\tPrec@5 97.000 (95.065)\n",
            "Test: [40/100]\tTime 0.026 (0.032)\tLoss 2.5151 (2.2698)\tPrec@1 46.000 (50.951)\tPrec@5 92.000 (95.098)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 2.4599 (2.2541)\tPrec@1 52.000 (51.196)\tPrec@5 97.000 (95.294)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 1.7234 (2.2416)\tPrec@1 56.000 (50.754)\tPrec@5 95.000 (95.328)\n",
            "Test: [70/100]\tTime 0.044 (0.030)\tLoss 2.0777 (2.2449)\tPrec@1 52.000 (50.648)\tPrec@5 98.000 (95.254)\n",
            "Test: [80/100]\tTime 0.024 (0.030)\tLoss 2.0232 (2.2442)\tPrec@1 54.000 (50.716)\tPrec@5 95.000 (95.309)\n",
            "Test: [90/100]\tTime 0.043 (0.029)\tLoss 2.3137 (2.2615)\tPrec@1 45.000 (50.275)\tPrec@5 94.000 (95.264)\n",
            "val Results: Prec@1 50.290 Prec@5 95.270 Loss 2.26512\n",
            "val Class Accuracy: [0.900,0.982,0.885,0.450,0.413,0.412,0.220,0.407,0.192,0.168]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [44][0/97], lr: 0.01000\tTime 0.481 (0.481)\tData 0.392 (0.392)\tLoss 0.2461 (0.2461)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [44][10/97], lr: 0.01000\tTime 0.073 (0.105)\tData 0.012 (0.040)\tLoss 0.1546 (0.2466)\tPrec@1 94.531 (91.548)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [44][20/97], lr: 0.01000\tTime 0.060 (0.083)\tData 0.004 (0.024)\tLoss 0.2362 (0.2323)\tPrec@1 92.188 (92.374)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [44][30/97], lr: 0.01000\tTime 0.077 (0.076)\tData 0.000 (0.017)\tLoss 0.1360 (0.2213)\tPrec@1 96.875 (92.465)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [44][40/97], lr: 0.01000\tTime 0.068 (0.071)\tData 0.007 (0.015)\tLoss 0.2705 (0.2223)\tPrec@1 89.062 (92.359)\tPrec@5 100.000 (99.809)\n",
            "Epoch: [44][50/97], lr: 0.01000\tTime 0.069 (0.069)\tData 0.007 (0.013)\tLoss 0.1483 (0.2229)\tPrec@1 96.875 (92.264)\tPrec@5 100.000 (99.801)\n",
            "Epoch: [44][60/97], lr: 0.01000\tTime 0.049 (0.066)\tData 0.008 (0.011)\tLoss 0.2148 (0.2220)\tPrec@1 90.625 (92.303)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [44][70/97], lr: 0.01000\tTime 0.049 (0.065)\tData 0.000 (0.010)\tLoss 0.3616 (0.2245)\tPrec@1 85.938 (92.077)\tPrec@5 99.219 (99.769)\n",
            "Epoch: [44][80/97], lr: 0.01000\tTime 0.047 (0.064)\tData 0.007 (0.010)\tLoss 0.2276 (0.2270)\tPrec@1 92.969 (91.946)\tPrec@5 100.000 (99.788)\n",
            "Epoch: [44][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 0.3064 (0.2289)\tPrec@1 92.188 (91.939)\tPrec@5 98.438 (99.794)\n",
            "Test: [0/100]\tTime 0.366 (0.366)\tLoss 1.3351 (1.3351)\tPrec@1 59.000 (59.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.052)\tLoss 1.2995 (1.5073)\tPrec@1 69.000 (62.000)\tPrec@5 93.000 (95.364)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 1.2771 (1.5079)\tPrec@1 63.000 (62.190)\tPrec@5 96.000 (95.667)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 1.4743 (1.5313)\tPrec@1 68.000 (62.000)\tPrec@5 95.000 (95.387)\n",
            "Test: [40/100]\tTime 0.024 (0.032)\tLoss 1.7068 (1.5228)\tPrec@1 59.000 (61.951)\tPrec@5 97.000 (95.732)\n",
            "Test: [50/100]\tTime 0.038 (0.030)\tLoss 1.3099 (1.5135)\tPrec@1 64.000 (62.569)\tPrec@5 97.000 (95.745)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.2776 (1.5113)\tPrec@1 67.000 (62.541)\tPrec@5 94.000 (95.689)\n",
            "Test: [70/100]\tTime 0.024 (0.029)\tLoss 1.3642 (1.5113)\tPrec@1 68.000 (62.521)\tPrec@5 99.000 (95.704)\n",
            "Test: [80/100]\tTime 0.039 (0.029)\tLoss 1.3474 (1.5027)\tPrec@1 70.000 (62.815)\tPrec@5 95.000 (95.741)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 1.5707 (1.5264)\tPrec@1 64.000 (62.396)\tPrec@5 95.000 (95.648)\n",
            "val Results: Prec@1 62.320 Prec@5 95.670 Loss 1.53191\n",
            "val Class Accuracy: [0.948,0.939,0.798,0.676,0.679,0.546,0.512,0.600,0.210,0.324]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [45][0/97], lr: 0.01000\tTime 0.408 (0.408)\tData 0.328 (0.328)\tLoss 0.2050 (0.2050)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [45][10/97], lr: 0.01000\tTime 0.067 (0.104)\tData 0.007 (0.033)\tLoss 0.3438 (0.2062)\tPrec@1 88.281 (93.253)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [45][20/97], lr: 0.01000\tTime 0.054 (0.080)\tData 0.000 (0.019)\tLoss 0.3445 (0.2182)\tPrec@1 88.281 (92.746)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [45][30/97], lr: 0.01000\tTime 0.061 (0.073)\tData 0.004 (0.014)\tLoss 0.1953 (0.2207)\tPrec@1 94.531 (92.767)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [45][40/97], lr: 0.01000\tTime 0.040 (0.069)\tData 0.000 (0.012)\tLoss 0.2121 (0.2219)\tPrec@1 92.969 (92.550)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [45][50/97], lr: 0.01000\tTime 0.079 (0.067)\tData 0.007 (0.010)\tLoss 0.2372 (0.2242)\tPrec@1 92.969 (92.479)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [45][60/97], lr: 0.01000\tTime 0.069 (0.065)\tData 0.000 (0.009)\tLoss 0.2188 (0.2246)\tPrec@1 92.188 (92.405)\tPrec@5 100.000 (99.872)\n",
            "Epoch: [45][70/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.008)\tLoss 0.4087 (0.2249)\tPrec@1 89.062 (92.364)\tPrec@5 98.438 (99.857)\n",
            "Epoch: [45][80/97], lr: 0.01000\tTime 0.047 (0.063)\tData 0.000 (0.008)\tLoss 0.2928 (0.2280)\tPrec@1 91.406 (92.332)\tPrec@5 99.219 (99.826)\n",
            "Epoch: [45][90/97], lr: 0.01000\tTime 0.032 (0.062)\tData 0.000 (0.007)\tLoss 0.1775 (0.2289)\tPrec@1 93.750 (92.308)\tPrec@5 100.000 (99.828)\n",
            "Test: [0/100]\tTime 0.259 (0.259)\tLoss 4.1122 (4.1122)\tPrec@1 35.000 (35.000)\tPrec@5 87.000 (87.000)\n",
            "Test: [10/100]\tTime 0.039 (0.054)\tLoss 2.9457 (3.4950)\tPrec@1 57.000 (43.636)\tPrec@5 93.000 (93.091)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 2.5187 (3.4916)\tPrec@1 56.000 (43.429)\tPrec@5 96.000 (93.810)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 3.2082 (3.4880)\tPrec@1 46.000 (43.065)\tPrec@5 93.000 (93.323)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 3.8350 (3.4873)\tPrec@1 44.000 (42.829)\tPrec@5 95.000 (93.585)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 3.2655 (3.4456)\tPrec@1 45.000 (43.490)\tPrec@5 97.000 (93.843)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 2.6548 (3.4092)\tPrec@1 52.000 (43.689)\tPrec@5 93.000 (93.787)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 3.5236 (3.4097)\tPrec@1 44.000 (43.859)\tPrec@5 96.000 (93.746)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 2.7221 (3.3802)\tPrec@1 52.000 (44.198)\tPrec@5 97.000 (93.975)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 3.2080 (3.4203)\tPrec@1 44.000 (43.692)\tPrec@5 97.000 (94.022)\n",
            "val Results: Prec@1 43.610 Prec@5 93.960 Loss 3.44528\n",
            "val Class Accuracy: [0.994,0.894,0.569,0.335,0.525,0.450,0.202,0.271,0.040,0.081]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [46][0/97], lr: 0.01000\tTime 0.413 (0.413)\tData 0.345 (0.345)\tLoss 0.1508 (0.1508)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [46][10/97], lr: 0.01000\tTime 0.058 (0.104)\tData 0.012 (0.040)\tLoss 0.1499 (0.2047)\tPrec@1 96.094 (92.969)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [46][20/97], lr: 0.01000\tTime 0.039 (0.082)\tData 0.000 (0.023)\tLoss 0.2285 (0.2220)\tPrec@1 93.750 (91.778)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [46][30/97], lr: 0.01000\tTime 0.065 (0.074)\tData 0.007 (0.017)\tLoss 0.2079 (0.2212)\tPrec@1 89.844 (91.835)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [46][40/97], lr: 0.01000\tTime 0.083 (0.071)\tData 0.015 (0.014)\tLoss 0.1927 (0.2221)\tPrec@1 92.969 (91.921)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [46][50/97], lr: 0.01000\tTime 0.062 (0.068)\tData 0.006 (0.012)\tLoss 0.1466 (0.2163)\tPrec@1 94.531 (92.341)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [46][60/97], lr: 0.01000\tTime 0.087 (0.066)\tData 0.007 (0.010)\tLoss 0.3645 (0.2173)\tPrec@1 88.281 (92.380)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [46][70/97], lr: 0.01000\tTime 0.046 (0.065)\tData 0.013 (0.010)\tLoss 0.1531 (0.2137)\tPrec@1 94.531 (92.408)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [46][80/97], lr: 0.01000\tTime 0.050 (0.064)\tData 0.007 (0.009)\tLoss 0.3132 (0.2196)\tPrec@1 89.844 (92.197)\tPrec@5 99.219 (99.855)\n",
            "Epoch: [46][90/97], lr: 0.01000\tTime 0.032 (0.063)\tData 0.000 (0.009)\tLoss 0.2535 (0.2225)\tPrec@1 91.406 (92.248)\tPrec@5 99.219 (99.828)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 2.0120 (2.0120)\tPrec@1 60.000 (60.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.017 (0.048)\tLoss 1.4425 (1.9846)\tPrec@1 68.000 (58.909)\tPrec@5 95.000 (91.818)\n",
            "Test: [20/100]\tTime 0.034 (0.039)\tLoss 1.5754 (1.9473)\tPrec@1 62.000 (59.476)\tPrec@5 95.000 (91.333)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.7102 (1.9493)\tPrec@1 61.000 (59.129)\tPrec@5 93.000 (90.935)\n",
            "Test: [40/100]\tTime 0.033 (0.033)\tLoss 1.9641 (1.9424)\tPrec@1 53.000 (58.976)\tPrec@5 93.000 (91.000)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 1.9417 (1.9206)\tPrec@1 57.000 (59.196)\tPrec@5 91.000 (91.137)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 1.3512 (1.9095)\tPrec@1 68.000 (59.131)\tPrec@5 92.000 (91.197)\n",
            "Test: [70/100]\tTime 0.025 (0.028)\tLoss 1.8836 (1.9243)\tPrec@1 59.000 (58.986)\tPrec@5 90.000 (90.972)\n",
            "Test: [80/100]\tTime 0.022 (0.028)\tLoss 1.9732 (1.9222)\tPrec@1 61.000 (59.099)\tPrec@5 91.000 (91.074)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 1.7229 (1.9369)\tPrec@1 61.000 (58.956)\tPrec@5 94.000 (91.077)\n",
            "val Results: Prec@1 58.940 Prec@5 91.010 Loss 1.94034\n",
            "val Class Accuracy: [0.738,0.934,0.838,0.735,0.756,0.273,0.742,0.494,0.305,0.079]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [47][0/97], lr: 0.01000\tTime 0.414 (0.414)\tData 0.317 (0.317)\tLoss 0.2658 (0.2658)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [47][10/97], lr: 0.01000\tTime 0.069 (0.100)\tData 0.012 (0.032)\tLoss 0.1999 (0.2117)\tPrec@1 92.969 (93.182)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [47][20/97], lr: 0.01000\tTime 0.040 (0.079)\tData 0.000 (0.018)\tLoss 0.2557 (0.2146)\tPrec@1 93.750 (92.820)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [47][30/97], lr: 0.01000\tTime 0.066 (0.073)\tData 0.000 (0.014)\tLoss 0.3111 (0.2264)\tPrec@1 88.281 (92.314)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [47][40/97], lr: 0.01000\tTime 0.063 (0.069)\tData 0.005 (0.011)\tLoss 0.1295 (0.2207)\tPrec@1 95.312 (92.397)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [47][50/97], lr: 0.01000\tTime 0.075 (0.068)\tData 0.000 (0.010)\tLoss 0.3036 (0.2227)\tPrec@1 89.844 (92.433)\tPrec@5 99.219 (99.908)\n",
            "Epoch: [47][60/97], lr: 0.01000\tTime 0.039 (0.066)\tData 0.000 (0.009)\tLoss 0.2209 (0.2256)\tPrec@1 92.969 (92.290)\tPrec@5 100.000 (99.910)\n",
            "Epoch: [47][70/97], lr: 0.01000\tTime 0.064 (0.065)\tData 0.000 (0.008)\tLoss 0.1257 (0.2255)\tPrec@1 96.875 (92.276)\tPrec@5 100.000 (99.912)\n",
            "Epoch: [47][80/97], lr: 0.01000\tTime 0.050 (0.064)\tData 0.005 (0.008)\tLoss 0.2878 (0.2287)\tPrec@1 88.281 (92.197)\tPrec@5 100.000 (99.913)\n",
            "Epoch: [47][90/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.007)\tLoss 0.1494 (0.2286)\tPrec@1 95.312 (92.196)\tPrec@5 99.219 (99.897)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 2.5892 (2.5892)\tPrec@1 56.000 (56.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.038 (0.057)\tLoss 1.7146 (2.2785)\tPrec@1 69.000 (57.273)\tPrec@5 98.000 (96.273)\n",
            "Test: [20/100]\tTime 0.036 (0.041)\tLoss 1.7229 (2.3054)\tPrec@1 58.000 (56.667)\tPrec@5 94.000 (95.571)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 2.3306 (2.3307)\tPrec@1 58.000 (56.387)\tPrec@5 94.000 (95.258)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 2.4802 (2.3345)\tPrec@1 54.000 (56.341)\tPrec@5 92.000 (94.902)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 2.1921 (2.3000)\tPrec@1 56.000 (56.902)\tPrec@5 94.000 (94.961)\n",
            "Test: [60/100]\tTime 0.046 (0.031)\tLoss 1.9101 (2.2873)\tPrec@1 61.000 (56.639)\tPrec@5 94.000 (94.934)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 2.5307 (2.2826)\tPrec@1 57.000 (56.817)\tPrec@5 97.000 (94.901)\n",
            "Test: [80/100]\tTime 0.019 (0.030)\tLoss 1.9715 (2.2604)\tPrec@1 66.000 (57.111)\tPrec@5 92.000 (94.926)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.8780 (2.2861)\tPrec@1 61.000 (56.703)\tPrec@5 93.000 (94.758)\n",
            "val Results: Prec@1 56.730 Prec@5 94.800 Loss 2.28528\n",
            "val Class Accuracy: [0.983,0.987,0.709,0.529,0.569,0.440,0.711,0.408,0.035,0.302]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [48][0/97], lr: 0.01000\tTime 0.377 (0.377)\tData 0.304 (0.304)\tLoss 0.2239 (0.2239)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [48][10/97], lr: 0.01000\tTime 0.052 (0.099)\tData 0.000 (0.037)\tLoss 0.2518 (0.1920)\tPrec@1 92.188 (93.679)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [48][20/97], lr: 0.01000\tTime 0.048 (0.079)\tData 0.000 (0.022)\tLoss 0.2343 (0.2086)\tPrec@1 92.969 (93.043)\tPrec@5 99.219 (99.963)\n",
            "Epoch: [48][30/97], lr: 0.01000\tTime 0.058 (0.072)\tData 0.005 (0.017)\tLoss 0.2465 (0.2152)\tPrec@1 92.969 (92.717)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [48][40/97], lr: 0.01000\tTime 0.069 (0.068)\tData 0.010 (0.014)\tLoss 0.1471 (0.2124)\tPrec@1 93.750 (92.854)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [48][50/97], lr: 0.01000\tTime 0.080 (0.066)\tData 0.000 (0.012)\tLoss 0.1461 (0.2084)\tPrec@1 92.188 (92.816)\tPrec@5 100.000 (99.831)\n",
            "Epoch: [48][60/97], lr: 0.01000\tTime 0.055 (0.065)\tData 0.000 (0.010)\tLoss 0.1293 (0.2072)\tPrec@1 95.312 (92.918)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [48][70/97], lr: 0.01000\tTime 0.068 (0.063)\tData 0.000 (0.010)\tLoss 0.1666 (0.2089)\tPrec@1 95.312 (92.815)\tPrec@5 100.000 (99.857)\n",
            "Epoch: [48][80/97], lr: 0.01000\tTime 0.053 (0.063)\tData 0.000 (0.009)\tLoss 0.1375 (0.2063)\tPrec@1 93.750 (92.901)\tPrec@5 100.000 (99.865)\n",
            "Epoch: [48][90/97], lr: 0.01000\tTime 0.036 (0.062)\tData 0.000 (0.009)\tLoss 0.2620 (0.2107)\tPrec@1 90.625 (92.711)\tPrec@5 100.000 (99.863)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 2.5432 (2.5432)\tPrec@1 46.000 (46.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.014 (0.054)\tLoss 1.9696 (2.3214)\tPrec@1 65.000 (54.091)\tPrec@5 94.000 (95.364)\n",
            "Test: [20/100]\tTime 0.023 (0.039)\tLoss 1.7633 (2.2938)\tPrec@1 57.000 (54.667)\tPrec@5 96.000 (94.952)\n",
            "Test: [30/100]\tTime 0.012 (0.034)\tLoss 2.0320 (2.3010)\tPrec@1 61.000 (55.032)\tPrec@5 96.000 (95.355)\n",
            "Test: [40/100]\tTime 0.038 (0.032)\tLoss 2.4952 (2.2720)\tPrec@1 47.000 (55.098)\tPrec@5 95.000 (95.366)\n",
            "Test: [50/100]\tTime 0.033 (0.031)\tLoss 2.1168 (2.2483)\tPrec@1 59.000 (55.549)\tPrec@5 95.000 (95.412)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 1.6165 (2.2295)\tPrec@1 66.000 (55.639)\tPrec@5 93.000 (95.344)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 2.1910 (2.2343)\tPrec@1 54.000 (55.662)\tPrec@5 97.000 (95.296)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.9866 (2.2211)\tPrec@1 61.000 (55.840)\tPrec@5 96.000 (95.346)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 2.2683 (2.2530)\tPrec@1 55.000 (55.505)\tPrec@5 95.000 (95.209)\n",
            "val Results: Prec@1 55.350 Prec@5 95.120 Loss 2.26037\n",
            "val Class Accuracy: [0.961,0.945,0.794,0.732,0.741,0.436,0.231,0.421,0.037,0.237]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [49][0/97], lr: 0.01000\tTime 0.433 (0.433)\tData 0.336 (0.336)\tLoss 0.2123 (0.2123)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [49][10/97], lr: 0.01000\tTime 0.056 (0.101)\tData 0.006 (0.033)\tLoss 0.1602 (0.1957)\tPrec@1 96.875 (92.969)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [49][20/97], lr: 0.01000\tTime 0.041 (0.081)\tData 0.000 (0.020)\tLoss 0.1260 (0.2107)\tPrec@1 95.312 (92.485)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [49][30/97], lr: 0.01000\tTime 0.072 (0.074)\tData 0.007 (0.015)\tLoss 0.2011 (0.2159)\tPrec@1 92.188 (92.238)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [49][40/97], lr: 0.01000\tTime 0.057 (0.070)\tData 0.006 (0.012)\tLoss 0.1541 (0.2069)\tPrec@1 95.312 (92.607)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [49][50/97], lr: 0.01000\tTime 0.048 (0.067)\tData 0.003 (0.011)\tLoss 0.2279 (0.2045)\tPrec@1 92.969 (92.739)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [49][60/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.010)\tLoss 0.1505 (0.2098)\tPrec@1 93.750 (92.597)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [49][70/97], lr: 0.01000\tTime 0.068 (0.065)\tData 0.005 (0.009)\tLoss 0.2238 (0.2132)\tPrec@1 91.406 (92.485)\tPrec@5 100.000 (99.846)\n",
            "Epoch: [49][80/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.011 (0.009)\tLoss 0.2048 (0.2146)\tPrec@1 90.625 (92.448)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [49][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.008)\tLoss 0.1448 (0.2142)\tPrec@1 95.312 (92.488)\tPrec@5 100.000 (99.828)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 1.6864 (1.6864)\tPrec@1 59.000 (59.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.041 (0.058)\tLoss 0.9144 (1.6213)\tPrec@1 76.000 (62.455)\tPrec@5 98.000 (95.091)\n",
            "Test: [20/100]\tTime 0.022 (0.038)\tLoss 1.3093 (1.5948)\tPrec@1 71.000 (63.333)\tPrec@5 97.000 (94.905)\n",
            "Test: [30/100]\tTime 0.036 (0.035)\tLoss 1.5279 (1.6300)\tPrec@1 63.000 (62.742)\tPrec@5 92.000 (94.161)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.7156 (1.6621)\tPrec@1 65.000 (62.390)\tPrec@5 95.000 (93.951)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.6965 (1.6513)\tPrec@1 60.000 (62.431)\tPrec@5 94.000 (94.059)\n",
            "Test: [60/100]\tTime 0.014 (0.030)\tLoss 1.3383 (1.6470)\tPrec@1 70.000 (62.180)\tPrec@5 94.000 (94.000)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 1.8310 (1.6394)\tPrec@1 62.000 (62.394)\tPrec@5 94.000 (93.958)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.4165 (1.6369)\tPrec@1 63.000 (62.494)\tPrec@5 93.000 (94.037)\n",
            "Test: [90/100]\tTime 0.025 (0.028)\tLoss 1.3821 (1.6437)\tPrec@1 62.000 (62.264)\tPrec@5 96.000 (94.099)\n",
            "val Results: Prec@1 62.190 Prec@5 94.000 Loss 1.65258\n",
            "val Class Accuracy: [0.895,0.965,0.741,0.733,0.720,0.455,0.719,0.216,0.633,0.142]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [50][0/97], lr: 0.01000\tTime 0.479 (0.479)\tData 0.393 (0.393)\tLoss 0.1256 (0.1256)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [50][10/97], lr: 0.01000\tTime 0.057 (0.101)\tData 0.009 (0.040)\tLoss 0.2729 (0.1720)\tPrec@1 89.844 (94.247)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [50][20/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.009 (0.023)\tLoss 0.1737 (0.1897)\tPrec@1 95.312 (93.713)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [50][30/97], lr: 0.01000\tTime 0.061 (0.072)\tData 0.005 (0.016)\tLoss 0.1656 (0.1996)\tPrec@1 93.750 (93.095)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [50][40/97], lr: 0.01000\tTime 0.070 (0.068)\tData 0.000 (0.013)\tLoss 0.2256 (0.1967)\tPrec@1 91.406 (93.083)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [50][50/97], lr: 0.01000\tTime 0.066 (0.068)\tData 0.006 (0.012)\tLoss 0.2354 (0.1934)\tPrec@1 90.625 (93.153)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [50][60/97], lr: 0.01000\tTime 0.041 (0.065)\tData 0.000 (0.010)\tLoss 0.2651 (0.2026)\tPrec@1 92.188 (92.905)\tPrec@5 100.000 (99.910)\n",
            "Epoch: [50][70/97], lr: 0.01000\tTime 0.042 (0.064)\tData 0.000 (0.010)\tLoss 0.2115 (0.2100)\tPrec@1 94.531 (92.661)\tPrec@5 100.000 (99.901)\n",
            "Epoch: [50][80/97], lr: 0.01000\tTime 0.048 (0.064)\tData 0.000 (0.009)\tLoss 0.2672 (0.2168)\tPrec@1 91.406 (92.544)\tPrec@5 100.000 (99.894)\n",
            "Epoch: [50][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.008)\tLoss 0.2537 (0.2160)\tPrec@1 92.969 (92.548)\tPrec@5 100.000 (99.897)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 1.9257 (1.9257)\tPrec@1 57.000 (57.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.038 (0.054)\tLoss 1.4285 (1.8936)\tPrec@1 64.000 (58.545)\tPrec@5 94.000 (96.364)\n",
            "Test: [20/100]\tTime 0.017 (0.040)\tLoss 1.2811 (1.8676)\tPrec@1 65.000 (58.762)\tPrec@5 96.000 (96.095)\n",
            "Test: [30/100]\tTime 0.029 (0.036)\tLoss 1.6869 (1.8991)\tPrec@1 58.000 (57.871)\tPrec@5 97.000 (95.871)\n",
            "Test: [40/100]\tTime 0.041 (0.033)\tLoss 1.7447 (1.8834)\tPrec@1 57.000 (57.951)\tPrec@5 99.000 (96.073)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 1.8330 (1.8582)\tPrec@1 57.000 (58.510)\tPrec@5 96.000 (96.235)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 1.5278 (1.8659)\tPrec@1 64.000 (58.213)\tPrec@5 95.000 (96.066)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 1.9533 (1.8636)\tPrec@1 59.000 (58.225)\tPrec@5 99.000 (96.070)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.7159 (1.8568)\tPrec@1 59.000 (58.383)\tPrec@5 98.000 (96.136)\n",
            "Test: [90/100]\tTime 0.019 (0.028)\tLoss 1.7388 (1.8722)\tPrec@1 51.000 (57.989)\tPrec@5 96.000 (96.077)\n",
            "val Results: Prec@1 58.030 Prec@5 96.030 Loss 1.87867\n",
            "val Class Accuracy: [0.950,0.986,0.640,0.870,0.631,0.419,0.301,0.463,0.354,0.189]\n",
            "Best Prec@1: 67.370\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [51][0/97], lr: 0.01000\tTime 0.507 (0.507)\tData 0.449 (0.449)\tLoss 0.3179 (0.3179)\tPrec@1 84.375 (84.375)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [51][10/97], lr: 0.01000\tTime 0.087 (0.105)\tData 0.012 (0.046)\tLoss 0.1151 (0.1761)\tPrec@1 96.094 (93.324)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [51][20/97], lr: 0.01000\tTime 0.074 (0.083)\tData 0.006 (0.027)\tLoss 0.2350 (0.1758)\tPrec@1 91.406 (93.638)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [51][30/97], lr: 0.01000\tTime 0.053 (0.074)\tData 0.007 (0.020)\tLoss 0.2297 (0.1743)\tPrec@1 91.406 (93.800)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [51][40/97], lr: 0.01000\tTime 0.070 (0.070)\tData 0.007 (0.016)\tLoss 0.2749 (0.1783)\tPrec@1 88.281 (93.674)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [51][50/97], lr: 0.01000\tTime 0.064 (0.068)\tData 0.006 (0.014)\tLoss 0.1560 (0.1875)\tPrec@1 94.531 (93.336)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [51][60/97], lr: 0.01000\tTime 0.056 (0.066)\tData 0.000 (0.012)\tLoss 0.2129 (0.1895)\tPrec@1 92.188 (93.276)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [51][70/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.000 (0.011)\tLoss 0.1926 (0.1897)\tPrec@1 93.750 (93.255)\tPrec@5 99.219 (99.879)\n",
            "Epoch: [51][80/97], lr: 0.01000\tTime 0.060 (0.064)\tData 0.005 (0.010)\tLoss 0.2896 (0.1929)\tPrec@1 89.844 (93.152)\tPrec@5 100.000 (99.884)\n",
            "Epoch: [51][90/97], lr: 0.01000\tTime 0.032 (0.063)\tData 0.000 (0.010)\tLoss 0.1702 (0.1945)\tPrec@1 93.750 (93.098)\tPrec@5 100.000 (99.880)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 0.8449 (0.8449)\tPrec@1 72.000 (72.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.034 (0.057)\tLoss 0.8669 (1.1514)\tPrec@1 77.000 (70.636)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/100]\tTime 0.021 (0.040)\tLoss 0.9059 (1.1213)\tPrec@1 69.000 (71.000)\tPrec@5 98.000 (97.429)\n",
            "Test: [30/100]\tTime 0.038 (0.036)\tLoss 1.1380 (1.1303)\tPrec@1 70.000 (70.323)\tPrec@5 95.000 (97.032)\n",
            "Test: [40/100]\tTime 0.046 (0.034)\tLoss 1.0648 (1.1473)\tPrec@1 69.000 (69.732)\tPrec@5 97.000 (97.073)\n",
            "Test: [50/100]\tTime 0.020 (0.032)\tLoss 1.1564 (1.1480)\tPrec@1 69.000 (69.902)\tPrec@5 96.000 (97.235)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 1.0303 (1.1501)\tPrec@1 71.000 (69.738)\tPrec@5 96.000 (97.230)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 1.2386 (1.1490)\tPrec@1 68.000 (69.535)\tPrec@5 100.000 (97.268)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.0516 (1.1471)\tPrec@1 74.000 (69.605)\tPrec@5 98.000 (97.333)\n",
            "Test: [90/100]\tTime 0.041 (0.029)\tLoss 1.1702 (1.1564)\tPrec@1 69.000 (69.176)\tPrec@5 97.000 (97.341)\n",
            "val Results: Prec@1 69.040 Prec@5 97.320 Loss 1.16793\n",
            "val Class Accuracy: [0.921,0.968,0.789,0.597,0.768,0.667,0.667,0.648,0.517,0.362]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [52][0/97], lr: 0.01000\tTime 0.752 (0.752)\tData 0.650 (0.650)\tLoss 0.1807 (0.1807)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [52][10/97], lr: 0.01000\tTime 0.088 (0.162)\tData 0.006 (0.063)\tLoss 0.1329 (0.2001)\tPrec@1 94.531 (92.472)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [52][20/97], lr: 0.01000\tTime 0.076 (0.127)\tData 0.008 (0.039)\tLoss 0.2066 (0.1821)\tPrec@1 92.188 (93.415)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [52][30/97], lr: 0.01000\tTime 0.059 (0.116)\tData 0.006 (0.030)\tLoss 0.1372 (0.1819)\tPrec@1 96.875 (93.574)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [52][40/97], lr: 0.01000\tTime 0.051 (0.104)\tData 0.000 (0.024)\tLoss 0.2353 (0.1931)\tPrec@1 91.406 (93.255)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [52][50/97], lr: 0.01000\tTime 0.041 (0.095)\tData 0.000 (0.020)\tLoss 0.1717 (0.1959)\tPrec@1 92.188 (93.061)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [52][60/97], lr: 0.01000\tTime 0.054 (0.089)\tData 0.005 (0.018)\tLoss 0.1454 (0.1997)\tPrec@1 93.750 (92.930)\tPrec@5 100.000 (99.859)\n",
            "Epoch: [52][70/97], lr: 0.01000\tTime 0.063 (0.085)\tData 0.000 (0.016)\tLoss 0.3603 (0.2070)\tPrec@1 87.500 (92.716)\tPrec@5 99.219 (99.846)\n",
            "Epoch: [52][80/97], lr: 0.01000\tTime 0.053 (0.082)\tData 0.012 (0.014)\tLoss 0.1253 (0.2074)\tPrec@1 96.094 (92.622)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [52][90/97], lr: 0.01000\tTime 0.030 (0.079)\tData 0.000 (0.013)\tLoss 0.1905 (0.2116)\tPrec@1 94.531 (92.574)\tPrec@5 100.000 (99.837)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 2.1157 (2.1157)\tPrec@1 50.000 (50.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.011 (0.056)\tLoss 1.5842 (2.0749)\tPrec@1 69.000 (56.545)\tPrec@5 96.000 (95.000)\n",
            "Test: [20/100]\tTime 0.055 (0.041)\tLoss 1.7792 (2.0570)\tPrec@1 52.000 (55.048)\tPrec@5 98.000 (95.143)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 1.7348 (2.0405)\tPrec@1 56.000 (55.516)\tPrec@5 93.000 (94.968)\n",
            "Test: [40/100]\tTime 0.027 (0.035)\tLoss 1.9018 (2.0589)\tPrec@1 49.000 (54.951)\tPrec@5 96.000 (95.244)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 1.9412 (2.0526)\tPrec@1 58.000 (55.373)\tPrec@5 95.000 (95.235)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.4845 (2.0319)\tPrec@1 68.000 (55.279)\tPrec@5 92.000 (95.180)\n",
            "Test: [70/100]\tTime 0.020 (0.031)\tLoss 2.1248 (2.0289)\tPrec@1 53.000 (55.141)\tPrec@5 98.000 (95.183)\n",
            "Test: [80/100]\tTime 0.017 (0.030)\tLoss 1.7842 (2.0250)\tPrec@1 60.000 (55.358)\tPrec@5 96.000 (95.160)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 2.0665 (2.0388)\tPrec@1 55.000 (55.187)\tPrec@5 97.000 (95.121)\n",
            "val Results: Prec@1 55.270 Prec@5 95.090 Loss 2.04427\n",
            "val Class Accuracy: [0.943,0.988,0.758,0.790,0.497,0.324,0.455,0.524,0.182,0.066]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [53][0/97], lr: 0.01000\tTime 0.527 (0.527)\tData 0.439 (0.439)\tLoss 0.2141 (0.2141)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [53][10/97], lr: 0.01000\tTime 0.076 (0.105)\tData 0.007 (0.043)\tLoss 0.2243 (0.2123)\tPrec@1 92.969 (93.111)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [53][20/97], lr: 0.01000\tTime 0.073 (0.081)\tData 0.010 (0.025)\tLoss 0.1864 (0.1985)\tPrec@1 94.531 (93.452)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [53][30/97], lr: 0.01000\tTime 0.070 (0.073)\tData 0.007 (0.019)\tLoss 0.1639 (0.1900)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [53][40/97], lr: 0.01000\tTime 0.041 (0.068)\tData 0.003 (0.015)\tLoss 0.2284 (0.1940)\tPrec@1 92.188 (93.540)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [53][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.005 (0.013)\tLoss 0.2523 (0.2021)\tPrec@1 91.406 (93.275)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [53][60/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.011 (0.012)\tLoss 0.2146 (0.1995)\tPrec@1 91.406 (93.238)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [53][70/97], lr: 0.01000\tTime 0.062 (0.064)\tData 0.006 (0.011)\tLoss 0.1893 (0.2006)\tPrec@1 93.750 (93.200)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [53][80/97], lr: 0.01000\tTime 0.043 (0.063)\tData 0.000 (0.011)\tLoss 0.2503 (0.1991)\tPrec@1 91.406 (93.210)\tPrec@5 100.000 (99.932)\n",
            "Epoch: [53][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.010)\tLoss 0.1687 (0.1995)\tPrec@1 92.969 (93.166)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/100]\tTime 0.284 (0.284)\tLoss 1.9254 (1.9254)\tPrec@1 58.000 (58.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.014 (0.054)\tLoss 1.3455 (1.7388)\tPrec@1 71.000 (60.636)\tPrec@5 96.000 (96.364)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 1.6426 (1.7323)\tPrec@1 58.000 (60.714)\tPrec@5 97.000 (96.381)\n",
            "Test: [30/100]\tTime 0.016 (0.036)\tLoss 1.5448 (1.7383)\tPrec@1 62.000 (61.097)\tPrec@5 96.000 (96.065)\n",
            "Test: [40/100]\tTime 0.038 (0.034)\tLoss 2.0723 (1.7504)\tPrec@1 60.000 (61.220)\tPrec@5 95.000 (96.220)\n",
            "Test: [50/100]\tTime 0.034 (0.032)\tLoss 1.5243 (1.7320)\tPrec@1 65.000 (61.745)\tPrec@5 96.000 (96.412)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 1.3015 (1.7209)\tPrec@1 70.000 (61.885)\tPrec@5 95.000 (96.361)\n",
            "Test: [70/100]\tTime 0.027 (0.031)\tLoss 1.5471 (1.7131)\tPrec@1 66.000 (61.915)\tPrec@5 100.000 (96.423)\n",
            "Test: [80/100]\tTime 0.027 (0.030)\tLoss 1.4960 (1.7061)\tPrec@1 66.000 (61.914)\tPrec@5 97.000 (96.494)\n",
            "Test: [90/100]\tTime 0.024 (0.030)\tLoss 1.5647 (1.7329)\tPrec@1 61.000 (61.396)\tPrec@5 97.000 (96.418)\n",
            "val Results: Prec@1 61.200 Prec@5 96.470 Loss 1.73789\n",
            "val Class Accuracy: [0.972,0.926,0.769,0.710,0.732,0.320,0.626,0.419,0.142,0.504]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [54][0/97], lr: 0.01000\tTime 0.503 (0.503)\tData 0.413 (0.413)\tLoss 0.1983 (0.1983)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [54][10/97], lr: 0.01000\tTime 0.051 (0.102)\tData 0.007 (0.040)\tLoss 0.1963 (0.1768)\tPrec@1 92.969 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [54][20/97], lr: 0.01000\tTime 0.066 (0.083)\tData 0.010 (0.023)\tLoss 0.2034 (0.1761)\tPrec@1 92.188 (94.122)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [54][30/97], lr: 0.01000\tTime 0.072 (0.075)\tData 0.011 (0.018)\tLoss 0.1696 (0.1797)\tPrec@1 92.969 (94.002)\tPrec@5 99.219 (99.924)\n",
            "Epoch: [54][40/97], lr: 0.01000\tTime 0.043 (0.071)\tData 0.001 (0.015)\tLoss 0.1941 (0.1883)\tPrec@1 94.531 (93.674)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [54][50/97], lr: 0.01000\tTime 0.054 (0.068)\tData 0.000 (0.013)\tLoss 0.2464 (0.1925)\tPrec@1 92.188 (93.367)\tPrec@5 99.219 (99.877)\n",
            "Epoch: [54][60/97], lr: 0.01000\tTime 0.065 (0.067)\tData 0.000 (0.011)\tLoss 0.1361 (0.1910)\tPrec@1 96.094 (93.366)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [54][70/97], lr: 0.01000\tTime 0.052 (0.065)\tData 0.006 (0.011)\tLoss 0.1711 (0.1971)\tPrec@1 94.531 (93.134)\tPrec@5 100.000 (99.901)\n",
            "Epoch: [54][80/97], lr: 0.01000\tTime 0.046 (0.064)\tData 0.000 (0.010)\tLoss 0.3466 (0.2035)\tPrec@1 87.500 (92.892)\tPrec@5 100.000 (99.904)\n",
            "Epoch: [54][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.2021 (0.2039)\tPrec@1 93.750 (92.857)\tPrec@5 100.000 (99.906)\n",
            "Test: [0/100]\tTime 0.336 (0.336)\tLoss 1.5512 (1.5512)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.027 (0.055)\tLoss 1.0898 (1.4432)\tPrec@1 72.000 (65.636)\tPrec@5 98.000 (95.818)\n",
            "Test: [20/100]\tTime 0.010 (0.039)\tLoss 1.2511 (1.4403)\tPrec@1 67.000 (66.381)\tPrec@5 98.000 (96.048)\n",
            "Test: [30/100]\tTime 0.032 (0.035)\tLoss 1.4274 (1.4884)\tPrec@1 64.000 (65.387)\tPrec@5 97.000 (95.742)\n",
            "Test: [40/100]\tTime 0.032 (0.033)\tLoss 1.5584 (1.5167)\tPrec@1 69.000 (65.195)\tPrec@5 96.000 (95.683)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.4624 (1.4914)\tPrec@1 69.000 (65.863)\tPrec@5 97.000 (95.902)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.2513 (1.4864)\tPrec@1 66.000 (65.705)\tPrec@5 95.000 (95.984)\n",
            "Test: [70/100]\tTime 0.035 (0.029)\tLoss 1.5914 (1.4805)\tPrec@1 64.000 (65.845)\tPrec@5 97.000 (96.085)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 1.2235 (1.4697)\tPrec@1 70.000 (65.889)\tPrec@5 97.000 (96.099)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 1.3017 (1.4773)\tPrec@1 66.000 (65.747)\tPrec@5 99.000 (96.099)\n",
            "val Results: Prec@1 65.670 Prec@5 96.030 Loss 1.48647\n",
            "val Class Accuracy: [0.952,0.890,0.693,0.578,0.751,0.500,0.814,0.328,0.607,0.454]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [55][0/97], lr: 0.01000\tTime 0.494 (0.494)\tData 0.388 (0.388)\tLoss 0.1275 (0.1275)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [55][10/97], lr: 0.01000\tTime 0.065 (0.103)\tData 0.000 (0.039)\tLoss 0.1779 (0.2031)\tPrec@1 92.969 (93.253)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [55][20/97], lr: 0.01000\tTime 0.070 (0.083)\tData 0.014 (0.022)\tLoss 0.1924 (0.2131)\tPrec@1 92.969 (92.708)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [55][30/97], lr: 0.01000\tTime 0.057 (0.074)\tData 0.007 (0.017)\tLoss 0.1451 (0.2101)\tPrec@1 93.750 (92.893)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [55][40/97], lr: 0.01000\tTime 0.048 (0.070)\tData 0.005 (0.014)\tLoss 0.2516 (0.2091)\tPrec@1 90.625 (92.835)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [55][50/97], lr: 0.01000\tTime 0.051 (0.067)\tData 0.007 (0.013)\tLoss 0.1689 (0.2085)\tPrec@1 92.969 (92.846)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [55][60/97], lr: 0.01000\tTime 0.064 (0.067)\tData 0.007 (0.012)\tLoss 0.2594 (0.2032)\tPrec@1 89.844 (93.135)\tPrec@5 100.000 (99.898)\n",
            "Epoch: [55][70/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.000 (0.010)\tLoss 0.1868 (0.2010)\tPrec@1 94.531 (93.189)\tPrec@5 100.000 (99.912)\n",
            "Epoch: [55][80/97], lr: 0.01000\tTime 0.059 (0.064)\tData 0.001 (0.010)\tLoss 0.1360 (0.2002)\tPrec@1 95.312 (93.142)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [55][90/97], lr: 0.01000\tTime 0.032 (0.063)\tData 0.000 (0.009)\tLoss 0.1841 (0.1971)\tPrec@1 95.312 (93.243)\tPrec@5 100.000 (99.914)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 1.0842 (1.0842)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.036 (0.051)\tLoss 1.1498 (1.3193)\tPrec@1 75.000 (67.727)\tPrec@5 97.000 (96.455)\n",
            "Test: [20/100]\tTime 0.019 (0.042)\tLoss 1.2151 (1.2603)\tPrec@1 69.000 (68.571)\tPrec@5 99.000 (96.619)\n",
            "Test: [30/100]\tTime 0.021 (0.035)\tLoss 1.2948 (1.2713)\tPrec@1 65.000 (68.194)\tPrec@5 97.000 (96.484)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.1495 (1.2656)\tPrec@1 67.000 (67.780)\tPrec@5 100.000 (96.634)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.3730 (1.2536)\tPrec@1 63.000 (67.863)\tPrec@5 99.000 (96.745)\n",
            "Test: [60/100]\tTime 0.012 (0.030)\tLoss 1.2868 (1.2735)\tPrec@1 60.000 (67.246)\tPrec@5 98.000 (96.656)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 1.4444 (1.2822)\tPrec@1 61.000 (67.155)\tPrec@5 98.000 (96.577)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.1600 (1.2772)\tPrec@1 70.000 (66.975)\tPrec@5 94.000 (96.642)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.0567 (1.2942)\tPrec@1 68.000 (66.516)\tPrec@5 100.000 (96.582)\n",
            "val Results: Prec@1 66.260 Prec@5 96.500 Loss 1.29849\n",
            "val Class Accuracy: [0.853,0.945,0.879,0.597,0.847,0.324,0.571,0.538,0.586,0.486]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [56][0/97], lr: 0.01000\tTime 0.384 (0.384)\tData 0.296 (0.296)\tLoss 0.2109 (0.2109)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [56][10/97], lr: 0.01000\tTime 0.055 (0.101)\tData 0.000 (0.034)\tLoss 0.2294 (0.1778)\tPrec@1 92.969 (93.963)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [56][20/97], lr: 0.01000\tTime 0.055 (0.080)\tData 0.007 (0.020)\tLoss 0.1860 (0.1596)\tPrec@1 92.969 (94.531)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [56][30/97], lr: 0.01000\tTime 0.060 (0.073)\tData 0.000 (0.014)\tLoss 0.1957 (0.1677)\tPrec@1 92.969 (94.254)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [56][40/97], lr: 0.01000\tTime 0.057 (0.069)\tData 0.001 (0.012)\tLoss 0.1727 (0.1832)\tPrec@1 95.312 (93.731)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [56][50/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.007 (0.011)\tLoss 0.2261 (0.1898)\tPrec@1 92.969 (93.444)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [56][60/97], lr: 0.01000\tTime 0.065 (0.066)\tData 0.005 (0.010)\tLoss 0.1980 (0.1891)\tPrec@1 93.750 (93.571)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [56][70/97], lr: 0.01000\tTime 0.065 (0.064)\tData 0.005 (0.009)\tLoss 0.2525 (0.1924)\tPrec@1 91.406 (93.486)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [56][80/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.008)\tLoss 0.1162 (0.1917)\tPrec@1 96.875 (93.538)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [56][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.008)\tLoss 0.2805 (0.1965)\tPrec@1 86.719 (93.338)\tPrec@5 99.219 (99.931)\n",
            "Test: [0/100]\tTime 0.311 (0.311)\tLoss 1.3610 (1.3610)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.031 (0.055)\tLoss 1.0222 (1.6719)\tPrec@1 74.000 (60.545)\tPrec@5 95.000 (94.545)\n",
            "Test: [20/100]\tTime 0.021 (0.039)\tLoss 1.1817 (1.6172)\tPrec@1 67.000 (61.571)\tPrec@5 97.000 (94.524)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 1.6660 (1.6353)\tPrec@1 59.000 (60.484)\tPrec@5 93.000 (94.516)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 1.5609 (1.6434)\tPrec@1 59.000 (60.220)\tPrec@5 97.000 (94.634)\n",
            "Test: [50/100]\tTime 0.026 (0.031)\tLoss 1.5514 (1.6251)\tPrec@1 62.000 (61.020)\tPrec@5 96.000 (94.608)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 1.3525 (1.6142)\tPrec@1 69.000 (61.049)\tPrec@5 95.000 (94.869)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 1.8304 (1.6094)\tPrec@1 57.000 (61.014)\tPrec@5 94.000 (94.761)\n",
            "Test: [80/100]\tTime 0.026 (0.028)\tLoss 1.3907 (1.6069)\tPrec@1 68.000 (61.148)\tPrec@5 92.000 (94.815)\n",
            "Test: [90/100]\tTime 0.021 (0.028)\tLoss 1.4624 (1.6238)\tPrec@1 67.000 (60.956)\tPrec@5 96.000 (94.780)\n",
            "val Results: Prec@1 61.000 Prec@5 94.670 Loss 1.62895\n",
            "val Class Accuracy: [0.875,0.962,0.694,0.750,0.638,0.614,0.729,0.375,0.298,0.165]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [57][0/97], lr: 0.01000\tTime 0.513 (0.513)\tData 0.439 (0.439)\tLoss 0.2434 (0.2434)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [57][10/97], lr: 0.01000\tTime 0.053 (0.104)\tData 0.003 (0.047)\tLoss 0.1830 (0.1767)\tPrec@1 94.531 (93.750)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [57][20/97], lr: 0.01000\tTime 0.054 (0.083)\tData 0.001 (0.027)\tLoss 0.1621 (0.1756)\tPrec@1 93.750 (93.824)\tPrec@5 99.219 (99.926)\n",
            "Epoch: [57][30/97], lr: 0.01000\tTime 0.074 (0.076)\tData 0.012 (0.021)\tLoss 0.2144 (0.1810)\tPrec@1 92.969 (93.775)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [57][40/97], lr: 0.01000\tTime 0.068 (0.071)\tData 0.007 (0.017)\tLoss 0.2875 (0.1780)\tPrec@1 89.844 (93.921)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [57][50/97], lr: 0.01000\tTime 0.067 (0.069)\tData 0.001 (0.015)\tLoss 0.2313 (0.1783)\tPrec@1 90.625 (93.857)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [57][60/97], lr: 0.01000\tTime 0.057 (0.067)\tData 0.008 (0.013)\tLoss 0.1599 (0.1787)\tPrec@1 94.531 (93.878)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [57][70/97], lr: 0.01000\tTime 0.042 (0.065)\tData 0.000 (0.012)\tLoss 0.2019 (0.1789)\tPrec@1 91.406 (93.926)\tPrec@5 99.219 (99.912)\n",
            "Epoch: [57][80/97], lr: 0.01000\tTime 0.071 (0.065)\tData 0.004 (0.011)\tLoss 0.1928 (0.1803)\tPrec@1 89.844 (93.962)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [57][90/97], lr: 0.01000\tTime 0.034 (0.064)\tData 0.000 (0.010)\tLoss 0.1330 (0.1791)\tPrec@1 93.750 (93.947)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 1.5028 (1.5028)\tPrec@1 64.000 (64.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.025 (0.058)\tLoss 1.1904 (1.6155)\tPrec@1 71.000 (63.273)\tPrec@5 99.000 (96.000)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 1.3422 (1.6127)\tPrec@1 66.000 (63.143)\tPrec@5 97.000 (96.095)\n",
            "Test: [30/100]\tTime 0.010 (0.036)\tLoss 1.5049 (1.6353)\tPrec@1 61.000 (63.226)\tPrec@5 97.000 (95.935)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 2.0656 (1.6499)\tPrec@1 61.000 (63.195)\tPrec@5 97.000 (96.000)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 1.7702 (1.6402)\tPrec@1 61.000 (63.157)\tPrec@5 96.000 (96.137)\n",
            "Test: [60/100]\tTime 0.048 (0.031)\tLoss 1.1666 (1.6460)\tPrec@1 72.000 (63.213)\tPrec@5 97.000 (96.000)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.9702 (1.6464)\tPrec@1 57.000 (63.000)\tPrec@5 98.000 (96.000)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.5024 (1.6379)\tPrec@1 65.000 (63.148)\tPrec@5 96.000 (96.099)\n",
            "Test: [90/100]\tTime 0.047 (0.029)\tLoss 1.2586 (1.6589)\tPrec@1 70.000 (62.813)\tPrec@5 99.000 (96.088)\n",
            "val Results: Prec@1 62.840 Prec@5 96.070 Loss 1.65650\n",
            "val Class Accuracy: [0.961,0.918,0.830,0.256,0.595,0.746,0.656,0.576,0.410,0.336]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [58][0/97], lr: 0.01000\tTime 0.356 (0.356)\tData 0.293 (0.293)\tLoss 0.1470 (0.1470)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [58][10/97], lr: 0.01000\tTime 0.069 (0.103)\tData 0.009 (0.042)\tLoss 0.1265 (0.1675)\tPrec@1 96.875 (94.744)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [58][20/97], lr: 0.01000\tTime 0.049 (0.081)\tData 0.000 (0.024)\tLoss 0.1690 (0.1582)\tPrec@1 93.750 (94.829)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [58][30/97], lr: 0.01000\tTime 0.050 (0.074)\tData 0.007 (0.019)\tLoss 0.1524 (0.1552)\tPrec@1 96.875 (95.060)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [58][40/97], lr: 0.01000\tTime 0.059 (0.070)\tData 0.003 (0.015)\tLoss 0.1586 (0.1606)\tPrec@1 92.969 (94.646)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [58][50/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.000 (0.013)\tLoss 0.1706 (0.1614)\tPrec@1 92.188 (94.593)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [58][60/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.007 (0.011)\tLoss 0.2242 (0.1626)\tPrec@1 90.625 (94.518)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [58][70/97], lr: 0.01000\tTime 0.062 (0.064)\tData 0.010 (0.010)\tLoss 0.2286 (0.1657)\tPrec@1 92.188 (94.355)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [58][80/97], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.010)\tLoss 0.1446 (0.1661)\tPrec@1 95.312 (94.367)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [58][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.009)\tLoss 0.3190 (0.1746)\tPrec@1 90.625 (94.059)\tPrec@5 100.000 (99.940)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 1.7398 (1.7398)\tPrec@1 62.000 (62.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.053)\tLoss 1.3547 (1.7076)\tPrec@1 69.000 (61.818)\tPrec@5 97.000 (96.091)\n",
            "Test: [20/100]\tTime 0.031 (0.039)\tLoss 1.6284 (1.6923)\tPrec@1 62.000 (62.429)\tPrec@5 98.000 (96.095)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 1.6254 (1.7531)\tPrec@1 66.000 (61.935)\tPrec@5 97.000 (95.516)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 2.2738 (1.7680)\tPrec@1 54.000 (61.537)\tPrec@5 94.000 (95.488)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 1.5071 (1.7224)\tPrec@1 67.000 (62.020)\tPrec@5 96.000 (95.588)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 1.4856 (1.7371)\tPrec@1 65.000 (61.623)\tPrec@5 95.000 (95.541)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 1.7604 (1.7488)\tPrec@1 62.000 (61.310)\tPrec@5 97.000 (95.563)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 1.5558 (1.7391)\tPrec@1 68.000 (61.481)\tPrec@5 94.000 (95.556)\n",
            "Test: [90/100]\tTime 0.021 (0.029)\tLoss 1.7317 (1.7584)\tPrec@1 59.000 (61.143)\tPrec@5 96.000 (95.505)\n",
            "val Results: Prec@1 60.970 Prec@5 95.450 Loss 1.76884\n",
            "val Class Accuracy: [0.953,0.948,0.619,0.777,0.795,0.602,0.404,0.214,0.443,0.342]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [59][0/97], lr: 0.01000\tTime 0.473 (0.473)\tData 0.380 (0.380)\tLoss 0.2427 (0.2427)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [59][10/97], lr: 0.01000\tTime 0.073 (0.102)\tData 0.009 (0.039)\tLoss 0.1352 (0.2002)\tPrec@1 94.531 (92.401)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [59][20/97], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.022)\tLoss 0.1462 (0.1892)\tPrec@1 97.656 (93.006)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [59][30/97], lr: 0.01000\tTime 0.050 (0.072)\tData 0.009 (0.017)\tLoss 0.1364 (0.1866)\tPrec@1 96.094 (93.347)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [59][40/97], lr: 0.01000\tTime 0.050 (0.069)\tData 0.000 (0.014)\tLoss 0.2491 (0.1868)\tPrec@1 92.969 (93.178)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [59][50/97], lr: 0.01000\tTime 0.066 (0.067)\tData 0.006 (0.012)\tLoss 0.3000 (0.1902)\tPrec@1 89.844 (93.122)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [59][60/97], lr: 0.01000\tTime 0.039 (0.065)\tData 0.000 (0.011)\tLoss 0.1486 (0.1906)\tPrec@1 96.094 (93.186)\tPrec@5 100.000 (99.910)\n",
            "Epoch: [59][70/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 0.2759 (0.1938)\tPrec@1 92.969 (93.178)\tPrec@5 100.000 (99.901)\n",
            "Epoch: [59][80/97], lr: 0.01000\tTime 0.045 (0.063)\tData 0.005 (0.009)\tLoss 0.2324 (0.1954)\tPrec@1 91.406 (93.065)\tPrec@5 100.000 (99.904)\n",
            "Epoch: [59][90/97], lr: 0.01000\tTime 0.029 (0.062)\tData 0.000 (0.008)\tLoss 0.2276 (0.1991)\tPrec@1 91.406 (92.943)\tPrec@5 100.000 (99.906)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 2.2134 (2.2134)\tPrec@1 54.000 (54.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.018 (0.055)\tLoss 1.5412 (1.8942)\tPrec@1 67.000 (56.909)\tPrec@5 95.000 (93.545)\n",
            "Test: [20/100]\tTime 0.024 (0.042)\tLoss 1.6113 (1.8143)\tPrec@1 64.000 (59.143)\tPrec@5 100.000 (93.952)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.9177 (1.8585)\tPrec@1 59.000 (58.677)\tPrec@5 94.000 (93.452)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 1.7699 (1.8725)\tPrec@1 66.000 (58.244)\tPrec@5 97.000 (93.659)\n",
            "Test: [50/100]\tTime 0.020 (0.030)\tLoss 1.6541 (1.8622)\tPrec@1 60.000 (58.549)\tPrec@5 93.000 (93.588)\n",
            "Test: [60/100]\tTime 0.039 (0.031)\tLoss 1.7382 (1.8691)\tPrec@1 60.000 (58.459)\tPrec@5 93.000 (93.787)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 1.9501 (1.8712)\tPrec@1 60.000 (58.507)\tPrec@5 94.000 (93.789)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 1.9753 (1.8645)\tPrec@1 59.000 (58.519)\tPrec@5 94.000 (93.827)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 1.7012 (1.8914)\tPrec@1 59.000 (58.088)\tPrec@5 93.000 (93.681)\n",
            "val Results: Prec@1 57.890 Prec@5 93.570 Loss 1.90180\n",
            "val Class Accuracy: [0.724,0.799,0.693,0.527,0.854,0.744,0.503,0.204,0.438,0.303]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [60][0/97], lr: 0.01000\tTime 0.452 (0.452)\tData 0.357 (0.357)\tLoss 0.2061 (0.2061)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [60][10/97], lr: 0.01000\tTime 0.040 (0.099)\tData 0.000 (0.037)\tLoss 0.1388 (0.2088)\tPrec@1 93.750 (92.614)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [60][20/97], lr: 0.01000\tTime 0.056 (0.080)\tData 0.005 (0.021)\tLoss 0.2222 (0.2023)\tPrec@1 91.406 (93.006)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [60][30/97], lr: 0.01000\tTime 0.061 (0.073)\tData 0.006 (0.016)\tLoss 0.1575 (0.1981)\tPrec@1 95.312 (93.422)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [60][40/97], lr: 0.01000\tTime 0.066 (0.069)\tData 0.006 (0.014)\tLoss 0.1643 (0.1931)\tPrec@1 97.656 (93.598)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [60][50/97], lr: 0.01000\tTime 0.049 (0.067)\tData 0.000 (0.012)\tLoss 0.2231 (0.1869)\tPrec@1 92.969 (93.750)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [60][60/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.002 (0.011)\tLoss 0.1505 (0.1834)\tPrec@1 94.531 (93.763)\tPrec@5 100.000 (99.910)\n",
            "Epoch: [60][70/97], lr: 0.01000\tTime 0.044 (0.064)\tData 0.000 (0.011)\tLoss 0.1584 (0.1856)\tPrec@1 93.750 (93.574)\tPrec@5 100.000 (99.912)\n",
            "Epoch: [60][80/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.000 (0.010)\tLoss 0.2241 (0.1919)\tPrec@1 89.844 (93.306)\tPrec@5 100.000 (99.913)\n",
            "Epoch: [60][90/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.3675 (0.1970)\tPrec@1 87.500 (93.123)\tPrec@5 100.000 (99.914)\n",
            "Test: [0/100]\tTime 0.288 (0.288)\tLoss 2.1215 (2.1215)\tPrec@1 53.000 (53.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.033 (0.054)\tLoss 1.5163 (1.9002)\tPrec@1 70.000 (59.273)\tPrec@5 93.000 (92.545)\n",
            "Test: [20/100]\tTime 0.026 (0.040)\tLoss 1.7063 (1.8751)\tPrec@1 58.000 (59.952)\tPrec@5 99.000 (93.095)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.8240 (1.8671)\tPrec@1 56.000 (59.710)\tPrec@5 94.000 (93.000)\n",
            "Test: [40/100]\tTime 0.032 (0.033)\tLoss 2.1502 (1.8493)\tPrec@1 58.000 (59.780)\tPrec@5 88.000 (93.122)\n",
            "Test: [50/100]\tTime 0.038 (0.032)\tLoss 1.6272 (1.8328)\tPrec@1 61.000 (59.922)\tPrec@5 93.000 (93.333)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 1.4272 (1.8206)\tPrec@1 68.000 (59.787)\tPrec@5 94.000 (93.410)\n",
            "Test: [70/100]\tTime 0.024 (0.029)\tLoss 1.8715 (1.8243)\tPrec@1 57.000 (59.915)\tPrec@5 95.000 (93.225)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 1.6036 (1.8073)\tPrec@1 70.000 (60.173)\tPrec@5 93.000 (93.259)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 1.6861 (1.8333)\tPrec@1 58.000 (59.648)\tPrec@5 91.000 (93.099)\n",
            "val Results: Prec@1 59.540 Prec@5 93.020 Loss 1.84151\n",
            "val Class Accuracy: [0.884,0.979,0.747,0.493,0.892,0.607,0.556,0.330,0.102,0.364]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [61][0/97], lr: 0.01000\tTime 0.399 (0.399)\tData 0.323 (0.323)\tLoss 0.1902 (0.1902)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [61][10/97], lr: 0.01000\tTime 0.056 (0.103)\tData 0.011 (0.039)\tLoss 0.2600 (0.1810)\tPrec@1 91.406 (93.253)\tPrec@5 99.219 (99.929)\n",
            "Epoch: [61][20/97], lr: 0.01000\tTime 0.044 (0.080)\tData 0.000 (0.023)\tLoss 0.2576 (0.1745)\tPrec@1 91.406 (93.973)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [61][30/97], lr: 0.01000\tTime 0.053 (0.074)\tData 0.005 (0.017)\tLoss 0.1744 (0.1779)\tPrec@1 94.531 (93.926)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [61][40/97], lr: 0.01000\tTime 0.046 (0.069)\tData 0.003 (0.015)\tLoss 0.1638 (0.1727)\tPrec@1 93.750 (94.131)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [61][50/97], lr: 0.01000\tTime 0.073 (0.068)\tData 0.000 (0.012)\tLoss 0.1850 (0.1792)\tPrec@1 93.750 (94.010)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [61][60/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.005 (0.011)\tLoss 0.1170 (0.1817)\tPrec@1 95.312 (93.993)\tPrec@5 100.000 (99.898)\n",
            "Epoch: [61][70/97], lr: 0.01000\tTime 0.039 (0.064)\tData 0.000 (0.010)\tLoss 0.2634 (0.1877)\tPrec@1 91.406 (93.673)\tPrec@5 99.219 (99.879)\n",
            "Epoch: [61][80/97], lr: 0.01000\tTime 0.067 (0.064)\tData 0.014 (0.009)\tLoss 0.2453 (0.1889)\tPrec@1 89.844 (93.634)\tPrec@5 100.000 (99.875)\n",
            "Epoch: [61][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.009)\tLoss 0.1584 (0.1900)\tPrec@1 95.312 (93.527)\tPrec@5 100.000 (99.880)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 2.2658 (2.2658)\tPrec@1 54.000 (54.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.046 (0.057)\tLoss 1.8900 (2.2723)\tPrec@1 63.000 (58.091)\tPrec@5 94.000 (93.000)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 1.9735 (2.2948)\tPrec@1 58.000 (57.667)\tPrec@5 96.000 (93.095)\n",
            "Test: [30/100]\tTime 0.037 (0.036)\tLoss 2.1390 (2.3334)\tPrec@1 57.000 (56.774)\tPrec@5 93.000 (93.000)\n",
            "Test: [40/100]\tTime 0.012 (0.034)\tLoss 2.2524 (2.3006)\tPrec@1 57.000 (56.366)\tPrec@5 93.000 (93.463)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 2.0404 (2.2579)\tPrec@1 59.000 (56.922)\tPrec@5 94.000 (93.373)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 1.7040 (2.2252)\tPrec@1 64.000 (57.213)\tPrec@5 93.000 (93.393)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 2.2172 (2.2451)\tPrec@1 53.000 (57.042)\tPrec@5 96.000 (93.197)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 2.2073 (2.2303)\tPrec@1 57.000 (57.173)\tPrec@5 95.000 (93.346)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 2.4344 (2.2595)\tPrec@1 56.000 (56.780)\tPrec@5 91.000 (93.187)\n",
            "val Results: Prec@1 56.760 Prec@5 93.140 Loss 2.27543\n",
            "val Class Accuracy: [0.985,0.896,0.471,0.716,0.654,0.560,0.541,0.646,0.040,0.167]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [62][0/97], lr: 0.01000\tTime 0.480 (0.480)\tData 0.357 (0.357)\tLoss 0.1445 (0.1445)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [62][10/97], lr: 0.01000\tTime 0.061 (0.103)\tData 0.012 (0.036)\tLoss 0.1376 (0.1653)\tPrec@1 95.312 (93.608)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [62][20/97], lr: 0.01000\tTime 0.056 (0.081)\tData 0.007 (0.021)\tLoss 0.1973 (0.1641)\tPrec@1 93.750 (94.345)\tPrec@5 99.219 (99.888)\n",
            "Epoch: [62][30/97], lr: 0.01000\tTime 0.049 (0.073)\tData 0.000 (0.016)\tLoss 0.1443 (0.1594)\tPrec@1 96.094 (94.405)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [62][40/97], lr: 0.01000\tTime 0.048 (0.070)\tData 0.000 (0.013)\tLoss 0.0852 (0.1569)\tPrec@1 95.312 (94.455)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [62][50/97], lr: 0.01000\tTime 0.047 (0.067)\tData 0.005 (0.012)\tLoss 0.1752 (0.1575)\tPrec@1 95.312 (94.562)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [62][60/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.010 (0.011)\tLoss 0.2116 (0.1605)\tPrec@1 92.188 (94.378)\tPrec@5 100.000 (99.936)\n",
            "Epoch: [62][70/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.007 (0.010)\tLoss 0.2459 (0.1631)\tPrec@1 89.844 (94.322)\tPrec@5 100.000 (99.934)\n",
            "Epoch: [62][80/97], lr: 0.01000\tTime 0.055 (0.064)\tData 0.013 (0.010)\tLoss 0.1292 (0.1672)\tPrec@1 96.094 (94.155)\tPrec@5 100.000 (99.932)\n",
            "Epoch: [62][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.2349 (0.1704)\tPrec@1 91.406 (93.965)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 2.1233 (2.1233)\tPrec@1 52.000 (52.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 1.4476 (2.2267)\tPrec@1 67.000 (55.545)\tPrec@5 96.000 (92.545)\n",
            "Test: [20/100]\tTime 0.027 (0.039)\tLoss 2.1143 (2.1863)\tPrec@1 49.000 (55.667)\tPrec@5 93.000 (92.095)\n",
            "Test: [30/100]\tTime 0.040 (0.036)\tLoss 1.8854 (2.1696)\tPrec@1 52.000 (55.742)\tPrec@5 91.000 (91.516)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 2.3336 (2.1908)\tPrec@1 50.000 (55.488)\tPrec@5 93.000 (91.537)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 2.2919 (2.1803)\tPrec@1 54.000 (55.490)\tPrec@5 93.000 (91.804)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 2.0664 (2.1782)\tPrec@1 59.000 (55.361)\tPrec@5 90.000 (91.738)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 2.3064 (2.1846)\tPrec@1 57.000 (55.211)\tPrec@5 86.000 (91.549)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 2.2968 (2.1836)\tPrec@1 54.000 (55.519)\tPrec@5 88.000 (91.568)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 2.3326 (2.1912)\tPrec@1 50.000 (55.418)\tPrec@5 94.000 (91.615)\n",
            "val Results: Prec@1 55.240 Prec@5 91.350 Loss 2.20658\n",
            "val Class Accuracy: [0.912,0.966,0.776,0.701,0.646,0.172,0.796,0.128,0.327,0.100]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [63][0/97], lr: 0.01000\tTime 0.393 (0.393)\tData 0.323 (0.323)\tLoss 0.2295 (0.2295)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [63][10/97], lr: 0.01000\tTime 0.052 (0.098)\tData 0.000 (0.036)\tLoss 0.1411 (0.1732)\tPrec@1 94.531 (93.750)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [63][20/97], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.021)\tLoss 0.1572 (0.1822)\tPrec@1 92.969 (93.378)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [63][30/97], lr: 0.01000\tTime 0.048 (0.074)\tData 0.000 (0.016)\tLoss 0.1885 (0.1815)\tPrec@1 92.969 (93.448)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [63][40/97], lr: 0.01000\tTime 0.062 (0.070)\tData 0.000 (0.013)\tLoss 0.1967 (0.1851)\tPrec@1 94.531 (93.426)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [63][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.013 (0.012)\tLoss 0.3144 (0.1864)\tPrec@1 90.625 (93.398)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [63][60/97], lr: 0.01000\tTime 0.047 (0.066)\tData 0.000 (0.011)\tLoss 0.1554 (0.1873)\tPrec@1 92.969 (93.315)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [63][70/97], lr: 0.01000\tTime 0.042 (0.064)\tData 0.000 (0.010)\tLoss 0.1935 (0.1911)\tPrec@1 93.750 (93.222)\tPrec@5 99.219 (99.934)\n",
            "Epoch: [63][80/97], lr: 0.01000\tTime 0.042 (0.064)\tData 0.000 (0.009)\tLoss 0.2047 (0.1868)\tPrec@1 89.062 (93.374)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [63][90/97], lr: 0.01000\tTime 0.028 (0.063)\tData 0.000 (0.009)\tLoss 0.3008 (0.1881)\tPrec@1 89.844 (93.312)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 1.5577 (1.5577)\tPrec@1 63.000 (63.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.039 (0.055)\tLoss 1.4092 (1.5964)\tPrec@1 68.000 (65.000)\tPrec@5 94.000 (97.091)\n",
            "Test: [20/100]\tTime 0.032 (0.042)\tLoss 1.1430 (1.6239)\tPrec@1 62.000 (64.476)\tPrec@5 100.000 (97.095)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 1.6023 (1.6449)\tPrec@1 64.000 (64.226)\tPrec@5 97.000 (96.645)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 1.5199 (1.6357)\tPrec@1 63.000 (64.439)\tPrec@5 98.000 (96.878)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 1.3547 (1.6210)\tPrec@1 71.000 (64.863)\tPrec@5 97.000 (96.961)\n",
            "Test: [60/100]\tTime 0.023 (0.031)\tLoss 1.2161 (1.6002)\tPrec@1 73.000 (65.115)\tPrec@5 95.000 (96.885)\n",
            "Test: [70/100]\tTime 0.013 (0.029)\tLoss 1.5674 (1.5985)\tPrec@1 67.000 (65.085)\tPrec@5 99.000 (96.887)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 1.5387 (1.5900)\tPrec@1 70.000 (65.247)\tPrec@5 97.000 (96.901)\n",
            "Test: [90/100]\tTime 0.013 (0.028)\tLoss 1.6514 (1.6091)\tPrec@1 62.000 (64.747)\tPrec@5 96.000 (96.912)\n",
            "val Results: Prec@1 64.630 Prec@5 96.920 Loss 1.61522\n",
            "val Class Accuracy: [0.963,0.969,0.582,0.739,0.606,0.681,0.424,0.739,0.217,0.543]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [64][0/97], lr: 0.01000\tTime 0.491 (0.491)\tData 0.401 (0.401)\tLoss 0.1781 (0.1781)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [64][10/97], lr: 0.01000\tTime 0.064 (0.104)\tData 0.012 (0.044)\tLoss 0.1567 (0.1818)\tPrec@1 96.094 (93.821)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [64][20/97], lr: 0.01000\tTime 0.045 (0.081)\tData 0.005 (0.025)\tLoss 0.2310 (0.1848)\tPrec@1 90.625 (93.490)\tPrec@5 99.219 (99.851)\n",
            "Epoch: [64][30/97], lr: 0.01000\tTime 0.047 (0.074)\tData 0.011 (0.019)\tLoss 0.1005 (0.1949)\tPrec@1 97.656 (93.196)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [64][40/97], lr: 0.01000\tTime 0.061 (0.070)\tData 0.006 (0.015)\tLoss 0.1442 (0.1922)\tPrec@1 94.531 (93.331)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [64][50/97], lr: 0.01000\tTime 0.072 (0.068)\tData 0.010 (0.013)\tLoss 0.1413 (0.1920)\tPrec@1 94.531 (93.321)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [64][60/97], lr: 0.01000\tTime 0.045 (0.066)\tData 0.006 (0.012)\tLoss 0.1080 (0.1890)\tPrec@1 95.312 (93.443)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [64][70/97], lr: 0.01000\tTime 0.072 (0.065)\tData 0.002 (0.011)\tLoss 0.1963 (0.1865)\tPrec@1 92.188 (93.530)\tPrec@5 100.000 (99.934)\n",
            "Epoch: [64][80/97], lr: 0.01000\tTime 0.068 (0.064)\tData 0.011 (0.010)\tLoss 0.2103 (0.1891)\tPrec@1 93.750 (93.451)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [64][90/97], lr: 0.01000\tTime 0.032 (0.062)\tData 0.000 (0.009)\tLoss 0.1740 (0.1885)\tPrec@1 95.312 (93.492)\tPrec@5 100.000 (99.940)\n",
            "Test: [0/100]\tTime 0.273 (0.273)\tLoss 1.6852 (1.6852)\tPrec@1 60.000 (60.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.026 (0.053)\tLoss 1.1860 (1.7593)\tPrec@1 74.000 (60.091)\tPrec@5 95.000 (93.818)\n",
            "Test: [20/100]\tTime 0.028 (0.038)\tLoss 1.4849 (1.7601)\tPrec@1 68.000 (60.905)\tPrec@5 95.000 (93.619)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.5735 (1.7717)\tPrec@1 60.000 (60.548)\tPrec@5 94.000 (93.581)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 2.0896 (1.7909)\tPrec@1 56.000 (60.341)\tPrec@5 93.000 (93.415)\n",
            "Test: [50/100]\tTime 0.020 (0.032)\tLoss 1.6859 (1.7707)\tPrec@1 64.000 (60.863)\tPrec@5 93.000 (93.471)\n",
            "Test: [60/100]\tTime 0.040 (0.031)\tLoss 1.5174 (1.7633)\tPrec@1 66.000 (60.705)\tPrec@5 91.000 (93.459)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 2.0820 (1.7703)\tPrec@1 57.000 (60.746)\tPrec@5 95.000 (93.352)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 1.8439 (1.7677)\tPrec@1 59.000 (60.802)\tPrec@5 93.000 (93.469)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 1.9907 (1.7945)\tPrec@1 58.000 (60.516)\tPrec@5 95.000 (93.484)\n",
            "val Results: Prec@1 60.320 Prec@5 93.410 Loss 1.80311\n",
            "val Class Accuracy: [0.945,0.977,0.756,0.552,0.782,0.405,0.802,0.218,0.390,0.205]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [65][0/97], lr: 0.01000\tTime 0.391 (0.391)\tData 0.314 (0.314)\tLoss 0.1644 (0.1644)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [65][10/97], lr: 0.01000\tTime 0.062 (0.101)\tData 0.000 (0.036)\tLoss 0.1432 (0.1897)\tPrec@1 94.531 (93.324)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [65][20/97], lr: 0.01000\tTime 0.071 (0.080)\tData 0.007 (0.021)\tLoss 0.1654 (0.1822)\tPrec@1 96.094 (93.676)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [65][30/97], lr: 0.01000\tTime 0.051 (0.073)\tData 0.009 (0.016)\tLoss 0.1838 (0.1834)\tPrec@1 93.750 (93.775)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [65][40/97], lr: 0.01000\tTime 0.053 (0.069)\tData 0.000 (0.013)\tLoss 0.2822 (0.1854)\tPrec@1 89.062 (93.617)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [65][50/97], lr: 0.01000\tTime 0.077 (0.067)\tData 0.005 (0.012)\tLoss 0.1735 (0.1864)\tPrec@1 95.312 (93.581)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [65][60/97], lr: 0.01000\tTime 0.054 (0.066)\tData 0.010 (0.011)\tLoss 0.0944 (0.1851)\tPrec@1 96.875 (93.532)\tPrec@5 100.000 (99.936)\n",
            "Epoch: [65][70/97], lr: 0.01000\tTime 0.066 (0.064)\tData 0.007 (0.010)\tLoss 0.1401 (0.1825)\tPrec@1 95.312 (93.607)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [65][80/97], lr: 0.01000\tTime 0.069 (0.064)\tData 0.007 (0.009)\tLoss 0.1563 (0.1866)\tPrec@1 95.312 (93.499)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [65][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.009)\tLoss 0.3002 (0.1899)\tPrec@1 90.625 (93.355)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 1.6673 (1.6673)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.030 (0.056)\tLoss 1.4307 (1.6814)\tPrec@1 72.000 (63.909)\tPrec@5 93.000 (96.364)\n",
            "Test: [20/100]\tTime 0.041 (0.042)\tLoss 1.3379 (1.6351)\tPrec@1 70.000 (63.667)\tPrec@5 97.000 (96.381)\n",
            "Test: [30/100]\tTime 0.029 (0.036)\tLoss 1.4903 (1.6595)\tPrec@1 64.000 (63.323)\tPrec@5 97.000 (96.258)\n",
            "Test: [40/100]\tTime 0.011 (0.033)\tLoss 1.5077 (1.6442)\tPrec@1 59.000 (63.244)\tPrec@5 97.000 (96.439)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.4694 (1.6258)\tPrec@1 70.000 (63.608)\tPrec@5 97.000 (96.608)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 1.1917 (1.6111)\tPrec@1 72.000 (63.721)\tPrec@5 94.000 (96.377)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 1.7204 (1.6043)\tPrec@1 59.000 (63.746)\tPrec@5 99.000 (96.408)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.4165 (1.5997)\tPrec@1 67.000 (63.840)\tPrec@5 95.000 (96.481)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.5319 (1.6215)\tPrec@1 67.000 (63.462)\tPrec@5 96.000 (96.385)\n",
            "val Results: Prec@1 63.320 Prec@5 96.390 Loss 1.63369\n",
            "val Class Accuracy: [0.939,0.964,0.697,0.583,0.573,0.789,0.431,0.706,0.215,0.435]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [66][0/97], lr: 0.01000\tTime 0.483 (0.483)\tData 0.393 (0.393)\tLoss 0.1999 (0.1999)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [66][10/97], lr: 0.01000\tTime 0.068 (0.102)\tData 0.007 (0.040)\tLoss 0.2496 (0.1845)\tPrec@1 89.844 (93.111)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [66][20/97], lr: 0.01000\tTime 0.050 (0.083)\tData 0.000 (0.023)\tLoss 0.1125 (0.1615)\tPrec@1 94.531 (93.899)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [66][30/97], lr: 0.01000\tTime 0.075 (0.075)\tData 0.017 (0.017)\tLoss 0.1225 (0.1626)\tPrec@1 97.656 (94.027)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [66][40/97], lr: 0.01000\tTime 0.061 (0.071)\tData 0.007 (0.014)\tLoss 0.1628 (0.1657)\tPrec@1 94.531 (94.074)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [66][50/97], lr: 0.01000\tTime 0.068 (0.069)\tData 0.002 (0.012)\tLoss 0.2117 (0.1696)\tPrec@1 91.406 (93.903)\tPrec@5 99.219 (99.923)\n",
            "Epoch: [66][60/97], lr: 0.01000\tTime 0.051 (0.067)\tData 0.009 (0.011)\tLoss 0.1915 (0.1706)\tPrec@1 92.969 (93.763)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [66][70/97], lr: 0.01000\tTime 0.064 (0.066)\tData 0.007 (0.010)\tLoss 0.2496 (0.1711)\tPrec@1 87.500 (93.728)\tPrec@5 99.219 (99.923)\n",
            "Epoch: [66][80/97], lr: 0.01000\tTime 0.063 (0.065)\tData 0.000 (0.010)\tLoss 0.1455 (0.1732)\tPrec@1 93.750 (93.692)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [66][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.2180 (0.1759)\tPrec@1 91.406 (93.578)\tPrec@5 100.000 (99.914)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 1.8761 (1.8761)\tPrec@1 63.000 (63.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.011 (0.057)\tLoss 1.2650 (1.5878)\tPrec@1 75.000 (66.273)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.039 (0.042)\tLoss 1.6210 (1.6615)\tPrec@1 62.000 (65.286)\tPrec@5 96.000 (96.524)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 1.4481 (1.7157)\tPrec@1 65.000 (64.548)\tPrec@5 96.000 (96.226)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.5742 (1.7215)\tPrec@1 65.000 (64.049)\tPrec@5 98.000 (96.732)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 1.8475 (1.6940)\tPrec@1 62.000 (64.353)\tPrec@5 95.000 (96.941)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 1.4313 (1.6901)\tPrec@1 70.000 (64.328)\tPrec@5 97.000 (96.885)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 1.8622 (1.6890)\tPrec@1 62.000 (64.268)\tPrec@5 97.000 (97.000)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 1.8428 (1.6890)\tPrec@1 64.000 (64.099)\tPrec@5 98.000 (97.111)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.6872 (1.7012)\tPrec@1 64.000 (63.736)\tPrec@5 99.000 (97.132)\n",
            "val Results: Prec@1 63.630 Prec@5 97.020 Loss 1.70503\n",
            "val Class Accuracy: [0.960,0.925,0.704,0.793,0.643,0.441,0.589,0.452,0.504,0.352]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [67][0/97], lr: 0.01000\tTime 0.440 (0.440)\tData 0.361 (0.361)\tLoss 0.1757 (0.1757)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [67][10/97], lr: 0.01000\tTime 0.074 (0.101)\tData 0.006 (0.038)\tLoss 0.1896 (0.1733)\tPrec@1 92.969 (93.892)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [67][20/97], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.022)\tLoss 0.1435 (0.1718)\tPrec@1 95.312 (94.010)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [67][30/97], lr: 0.01000\tTime 0.054 (0.073)\tData 0.000 (0.016)\tLoss 0.2051 (0.1792)\tPrec@1 91.406 (93.775)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [67][40/97], lr: 0.01000\tTime 0.040 (0.070)\tData 0.000 (0.013)\tLoss 0.1610 (0.1831)\tPrec@1 94.531 (93.788)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [67][50/97], lr: 0.01000\tTime 0.071 (0.067)\tData 0.009 (0.011)\tLoss 0.1894 (0.1826)\tPrec@1 93.750 (93.781)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [67][60/97], lr: 0.01000\tTime 0.060 (0.066)\tData 0.004 (0.011)\tLoss 0.1769 (0.1757)\tPrec@1 92.969 (93.878)\tPrec@5 100.000 (99.936)\n",
            "Epoch: [67][70/97], lr: 0.01000\tTime 0.052 (0.065)\tData 0.000 (0.010)\tLoss 0.1149 (0.1782)\tPrec@1 96.094 (93.827)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [67][80/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.003 (0.009)\tLoss 0.2088 (0.1787)\tPrec@1 92.188 (93.779)\tPrec@5 99.219 (99.932)\n",
            "Epoch: [67][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.008)\tLoss 0.2496 (0.1801)\tPrec@1 92.188 (93.716)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/100]\tTime 0.265 (0.265)\tLoss 1.7806 (1.7806)\tPrec@1 52.000 (52.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 1.3218 (1.9723)\tPrec@1 69.000 (57.091)\tPrec@5 95.000 (94.727)\n",
            "Test: [20/100]\tTime 0.013 (0.041)\tLoss 1.7577 (1.9803)\tPrec@1 61.000 (56.857)\tPrec@5 98.000 (94.571)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 1.9448 (1.9931)\tPrec@1 61.000 (56.581)\tPrec@5 94.000 (94.290)\n",
            "Test: [40/100]\tTime 0.044 (0.033)\tLoss 2.3324 (2.0148)\tPrec@1 53.000 (56.561)\tPrec@5 92.000 (94.244)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 1.9510 (2.0071)\tPrec@1 63.000 (57.000)\tPrec@5 94.000 (94.255)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 1.5071 (2.0082)\tPrec@1 68.000 (56.770)\tPrec@5 96.000 (94.361)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 2.2531 (2.0085)\tPrec@1 53.000 (56.690)\tPrec@5 97.000 (94.521)\n",
            "Test: [80/100]\tTime 0.013 (0.029)\tLoss 1.8729 (1.9982)\tPrec@1 56.000 (56.778)\tPrec@5 94.000 (94.679)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 2.0822 (2.0193)\tPrec@1 58.000 (56.440)\tPrec@5 96.000 (94.681)\n",
            "val Results: Prec@1 56.500 Prec@5 94.590 Loss 2.02176\n",
            "val Class Accuracy: [0.953,0.987,0.855,0.653,0.508,0.335,0.609,0.230,0.339,0.181]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [68][0/97], lr: 0.01000\tTime 0.454 (0.454)\tData 0.361 (0.361)\tLoss 0.1391 (0.1391)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [68][10/97], lr: 0.01000\tTime 0.048 (0.103)\tData 0.000 (0.038)\tLoss 0.2007 (0.1721)\tPrec@1 93.750 (93.892)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [68][20/97], lr: 0.01000\tTime 0.051 (0.081)\tData 0.007 (0.022)\tLoss 0.1480 (0.1550)\tPrec@1 96.094 (94.717)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [68][30/97], lr: 0.01000\tTime 0.060 (0.074)\tData 0.001 (0.017)\tLoss 0.0876 (0.1546)\tPrec@1 96.875 (94.632)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [68][40/97], lr: 0.01000\tTime 0.047 (0.069)\tData 0.000 (0.014)\tLoss 0.2319 (0.1555)\tPrec@1 91.406 (94.665)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [68][50/97], lr: 0.01000\tTime 0.036 (0.067)\tData 0.000 (0.012)\tLoss 0.2115 (0.1573)\tPrec@1 94.531 (94.562)\tPrec@5 99.219 (99.923)\n",
            "Epoch: [68][60/97], lr: 0.01000\tTime 0.076 (0.066)\tData 0.001 (0.011)\tLoss 0.1877 (0.1593)\tPrec@1 94.531 (94.403)\tPrec@5 100.000 (99.936)\n",
            "Epoch: [68][70/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.006 (0.010)\tLoss 0.1680 (0.1611)\tPrec@1 93.750 (94.366)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [68][80/97], lr: 0.01000\tTime 0.059 (0.064)\tData 0.004 (0.010)\tLoss 0.1551 (0.1653)\tPrec@1 92.969 (94.088)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [68][90/97], lr: 0.01000\tTime 0.033 (0.062)\tData 0.000 (0.009)\tLoss 0.1910 (0.1659)\tPrec@1 92.188 (94.076)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.275 (0.275)\tLoss 2.2939 (2.2939)\tPrec@1 53.000 (53.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.059 (0.054)\tLoss 1.5722 (2.2796)\tPrec@1 66.000 (57.455)\tPrec@5 97.000 (94.727)\n",
            "Test: [20/100]\tTime 0.019 (0.040)\tLoss 1.6547 (2.2850)\tPrec@1 59.000 (57.143)\tPrec@5 97.000 (95.000)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 2.5466 (2.3218)\tPrec@1 54.000 (56.484)\tPrec@5 93.000 (94.645)\n",
            "Test: [40/100]\tTime 0.043 (0.033)\tLoss 2.3987 (2.3223)\tPrec@1 53.000 (56.293)\tPrec@5 92.000 (94.732)\n",
            "Test: [50/100]\tTime 0.020 (0.032)\tLoss 2.3137 (2.2912)\tPrec@1 59.000 (57.333)\tPrec@5 97.000 (94.863)\n",
            "Test: [60/100]\tTime 0.035 (0.030)\tLoss 1.9037 (2.2756)\tPrec@1 63.000 (57.557)\tPrec@5 91.000 (94.787)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 2.1603 (2.2619)\tPrec@1 55.000 (57.493)\tPrec@5 93.000 (94.732)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 2.1428 (2.2545)\tPrec@1 63.000 (57.654)\tPrec@5 93.000 (94.716)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 2.5220 (2.2780)\tPrec@1 57.000 (57.418)\tPrec@5 92.000 (94.659)\n",
            "val Results: Prec@1 57.540 Prec@5 94.630 Loss 2.27500\n",
            "val Class Accuracy: [0.946,0.980,0.631,0.715,0.333,0.774,0.615,0.286,0.139,0.335]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [69][0/97], lr: 0.01000\tTime 0.389 (0.389)\tData 0.323 (0.323)\tLoss 0.1332 (0.1332)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [69][10/97], lr: 0.01000\tTime 0.070 (0.100)\tData 0.010 (0.037)\tLoss 0.1830 (0.1443)\tPrec@1 94.531 (95.170)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [69][20/97], lr: 0.01000\tTime 0.059 (0.080)\tData 0.000 (0.022)\tLoss 0.1258 (0.1527)\tPrec@1 95.312 (94.754)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [69][30/97], lr: 0.01000\tTime 0.057 (0.073)\tData 0.006 (0.016)\tLoss 0.1115 (0.1503)\tPrec@1 96.875 (94.859)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [69][40/97], lr: 0.01000\tTime 0.047 (0.069)\tData 0.004 (0.013)\tLoss 0.1437 (0.1480)\tPrec@1 94.531 (94.950)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [69][50/97], lr: 0.01000\tTime 0.070 (0.067)\tData 0.011 (0.012)\tLoss 0.1562 (0.1540)\tPrec@1 95.312 (94.761)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [69][60/97], lr: 0.01000\tTime 0.067 (0.065)\tData 0.007 (0.011)\tLoss 0.2189 (0.1513)\tPrec@1 92.969 (94.851)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [69][70/97], lr: 0.01000\tTime 0.057 (0.064)\tData 0.000 (0.010)\tLoss 0.1902 (0.1555)\tPrec@1 94.531 (94.586)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [69][80/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.1784 (0.1572)\tPrec@1 92.969 (94.531)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [69][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.009)\tLoss 0.2264 (0.1606)\tPrec@1 92.969 (94.411)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.4478 (1.4478)\tPrec@1 57.000 (57.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.026 (0.055)\tLoss 1.3230 (1.5953)\tPrec@1 73.000 (62.909)\tPrec@5 96.000 (96.000)\n",
            "Test: [20/100]\tTime 0.035 (0.040)\tLoss 1.3025 (1.5657)\tPrec@1 65.000 (63.238)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/100]\tTime 0.037 (0.035)\tLoss 1.4609 (1.6006)\tPrec@1 64.000 (62.710)\tPrec@5 94.000 (95.774)\n",
            "Test: [40/100]\tTime 0.014 (0.032)\tLoss 1.6561 (1.6210)\tPrec@1 57.000 (62.244)\tPrec@5 96.000 (95.707)\n",
            "Test: [50/100]\tTime 0.037 (0.031)\tLoss 1.5726 (1.6017)\tPrec@1 61.000 (62.157)\tPrec@5 95.000 (95.824)\n",
            "Test: [60/100]\tTime 0.011 (0.030)\tLoss 1.3250 (1.5995)\tPrec@1 68.000 (61.984)\tPrec@5 92.000 (95.738)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 1.6017 (1.6079)\tPrec@1 61.000 (61.662)\tPrec@5 98.000 (95.761)\n",
            "Test: [80/100]\tTime 0.013 (0.029)\tLoss 1.3995 (1.5943)\tPrec@1 66.000 (61.926)\tPrec@5 92.000 (95.815)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 1.5079 (1.6064)\tPrec@1 58.000 (61.703)\tPrec@5 98.000 (95.769)\n",
            "val Results: Prec@1 61.700 Prec@5 95.730 Loss 1.60619\n",
            "val Class Accuracy: [0.878,0.970,0.895,0.652,0.608,0.507,0.704,0.408,0.330,0.218]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [70][0/97], lr: 0.01000\tTime 0.469 (0.469)\tData 0.389 (0.389)\tLoss 0.1737 (0.1737)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [70][10/97], lr: 0.01000\tTime 0.057 (0.104)\tData 0.010 (0.041)\tLoss 0.3185 (0.1740)\tPrec@1 87.500 (94.105)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [70][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.005 (0.024)\tLoss 0.1772 (0.1603)\tPrec@1 95.312 (94.457)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [70][30/97], lr: 0.01000\tTime 0.084 (0.075)\tData 0.003 (0.018)\tLoss 0.1589 (0.1638)\tPrec@1 94.531 (94.153)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [70][40/97], lr: 0.01000\tTime 0.048 (0.071)\tData 0.000 (0.015)\tLoss 0.3338 (0.1593)\tPrec@1 89.062 (94.531)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [70][50/97], lr: 0.01000\tTime 0.044 (0.068)\tData 0.000 (0.014)\tLoss 0.2024 (0.1651)\tPrec@1 91.406 (94.347)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [70][60/97], lr: 0.01000\tTime 0.050 (0.066)\tData 0.000 (0.013)\tLoss 0.2363 (0.1718)\tPrec@1 92.188 (94.083)\tPrec@5 100.000 (99.910)\n",
            "Epoch: [70][70/97], lr: 0.01000\tTime 0.056 (0.065)\tData 0.000 (0.011)\tLoss 0.1283 (0.1721)\tPrec@1 95.312 (94.025)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [70][80/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.005 (0.011)\tLoss 0.1714 (0.1699)\tPrec@1 93.750 (94.049)\tPrec@5 100.000 (99.932)\n",
            "Epoch: [70][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.010)\tLoss 0.2198 (0.1706)\tPrec@1 92.188 (94.050)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/100]\tTime 0.268 (0.268)\tLoss 2.1758 (2.1758)\tPrec@1 52.000 (52.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.040 (0.056)\tLoss 1.8185 (2.2537)\tPrec@1 65.000 (57.818)\tPrec@5 97.000 (95.364)\n",
            "Test: [20/100]\tTime 0.026 (0.042)\tLoss 2.0662 (2.2886)\tPrec@1 56.000 (57.381)\tPrec@5 92.000 (94.286)\n",
            "Test: [30/100]\tTime 0.028 (0.036)\tLoss 1.9381 (2.2999)\tPrec@1 59.000 (56.935)\tPrec@5 93.000 (94.097)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 2.3017 (2.3031)\tPrec@1 53.000 (56.488)\tPrec@5 95.000 (94.195)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 1.9804 (2.2936)\tPrec@1 63.000 (56.686)\tPrec@5 91.000 (94.196)\n",
            "Test: [60/100]\tTime 0.015 (0.030)\tLoss 2.0908 (2.2823)\tPrec@1 62.000 (56.836)\tPrec@5 91.000 (93.869)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 2.3194 (2.2791)\tPrec@1 52.000 (56.859)\tPrec@5 94.000 (93.887)\n",
            "Test: [80/100]\tTime 0.011 (0.029)\tLoss 1.6476 (2.2663)\tPrec@1 65.000 (56.790)\tPrec@5 96.000 (94.148)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 2.2881 (2.2934)\tPrec@1 58.000 (56.527)\tPrec@5 93.000 (94.088)\n",
            "val Results: Prec@1 56.310 Prec@5 94.020 Loss 2.30479\n",
            "val Class Accuracy: [0.956,0.991,0.806,0.541,0.554,0.309,0.727,0.391,0.154,0.202]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [71][0/97], lr: 0.01000\tTime 0.505 (0.505)\tData 0.392 (0.392)\tLoss 0.0537 (0.0537)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [71][10/97], lr: 0.01000\tTime 0.064 (0.105)\tData 0.005 (0.041)\tLoss 0.1818 (0.1382)\tPrec@1 96.094 (95.028)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [71][20/97], lr: 0.01000\tTime 0.061 (0.082)\tData 0.005 (0.023)\tLoss 0.2331 (0.1592)\tPrec@1 92.188 (94.196)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [71][30/97], lr: 0.01000\tTime 0.043 (0.073)\tData 0.000 (0.016)\tLoss 0.2416 (0.1535)\tPrec@1 91.406 (94.304)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [71][40/97], lr: 0.01000\tTime 0.073 (0.072)\tData 0.008 (0.014)\tLoss 0.1899 (0.1578)\tPrec@1 93.750 (94.036)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [71][50/97], lr: 0.01000\tTime 0.090 (0.073)\tData 0.000 (0.012)\tLoss 0.1798 (0.1558)\tPrec@1 92.188 (94.026)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [71][60/97], lr: 0.01000\tTime 0.079 (0.076)\tData 0.005 (0.011)\tLoss 0.1332 (0.1562)\tPrec@1 93.750 (93.968)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [71][70/97], lr: 0.01000\tTime 0.081 (0.078)\tData 0.006 (0.011)\tLoss 0.2455 (0.1578)\tPrec@1 92.969 (94.003)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [71][80/97], lr: 0.01000\tTime 0.094 (0.079)\tData 0.008 (0.011)\tLoss 0.2210 (0.1601)\tPrec@1 90.625 (93.972)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [71][90/97], lr: 0.01000\tTime 0.029 (0.077)\tData 0.000 (0.010)\tLoss 0.1916 (0.1640)\tPrec@1 93.750 (93.870)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.350 (0.350)\tLoss 1.5963 (1.5963)\tPrec@1 56.000 (56.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.025 (0.058)\tLoss 1.2922 (1.5315)\tPrec@1 75.000 (65.455)\tPrec@5 96.000 (97.818)\n",
            "Test: [20/100]\tTime 0.029 (0.043)\tLoss 1.1785 (1.6098)\tPrec@1 69.000 (64.857)\tPrec@5 98.000 (97.143)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 1.6038 (1.6441)\tPrec@1 63.000 (64.226)\tPrec@5 97.000 (96.742)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 1.5206 (1.6402)\tPrec@1 63.000 (64.244)\tPrec@5 95.000 (96.805)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 1.5446 (1.6195)\tPrec@1 67.000 (65.176)\tPrec@5 94.000 (96.882)\n",
            "Test: [60/100]\tTime 0.015 (0.030)\tLoss 1.2598 (1.6249)\tPrec@1 68.000 (65.098)\tPrec@5 99.000 (96.902)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 1.6175 (1.6238)\tPrec@1 62.000 (65.113)\tPrec@5 96.000 (96.958)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.7182 (1.6130)\tPrec@1 68.000 (65.136)\tPrec@5 98.000 (96.988)\n",
            "Test: [90/100]\tTime 0.017 (0.029)\tLoss 1.3939 (1.6199)\tPrec@1 65.000 (65.066)\tPrec@5 99.000 (97.000)\n",
            "val Results: Prec@1 64.830 Prec@5 97.020 Loss 1.62670\n",
            "val Class Accuracy: [0.986,0.931,0.500,0.763,0.647,0.558,0.653,0.487,0.321,0.637]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [72][0/97], lr: 0.01000\tTime 0.496 (0.496)\tData 0.427 (0.427)\tLoss 0.1171 (0.1171)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [72][10/97], lr: 0.01000\tTime 0.051 (0.102)\tData 0.007 (0.044)\tLoss 0.1310 (0.1377)\tPrec@1 94.531 (94.673)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [72][20/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.005 (0.027)\tLoss 0.1055 (0.1471)\tPrec@1 93.750 (94.382)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [72][30/97], lr: 0.01000\tTime 0.054 (0.073)\tData 0.000 (0.019)\tLoss 0.1375 (0.1552)\tPrec@1 95.312 (94.178)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [72][40/97], lr: 0.01000\tTime 0.060 (0.070)\tData 0.001 (0.016)\tLoss 0.1421 (0.1576)\tPrec@1 95.312 (94.188)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [72][50/97], lr: 0.01000\tTime 0.067 (0.068)\tData 0.008 (0.014)\tLoss 0.1632 (0.1577)\tPrec@1 92.969 (94.256)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [72][60/97], lr: 0.01000\tTime 0.061 (0.066)\tData 0.000 (0.013)\tLoss 0.2295 (0.1630)\tPrec@1 92.188 (94.070)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [72][70/97], lr: 0.01000\tTime 0.072 (0.065)\tData 0.008 (0.012)\tLoss 0.1794 (0.1674)\tPrec@1 92.969 (93.948)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [72][80/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.006 (0.011)\tLoss 0.1219 (0.1655)\tPrec@1 96.094 (94.059)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [72][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.011)\tLoss 0.1041 (0.1649)\tPrec@1 96.094 (94.093)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.6921 (1.6921)\tPrec@1 59.000 (59.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.011 (0.049)\tLoss 1.3161 (1.7649)\tPrec@1 73.000 (65.727)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/100]\tTime 0.017 (0.039)\tLoss 1.4120 (1.7310)\tPrec@1 68.000 (66.048)\tPrec@5 97.000 (96.476)\n",
            "Test: [30/100]\tTime 0.021 (0.037)\tLoss 1.3936 (1.7436)\tPrec@1 70.000 (65.903)\tPrec@5 98.000 (96.387)\n",
            "Test: [40/100]\tTime 0.017 (0.034)\tLoss 1.5325 (1.7573)\tPrec@1 68.000 (65.463)\tPrec@5 97.000 (96.463)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 1.5388 (1.7495)\tPrec@1 65.000 (65.588)\tPrec@5 96.000 (96.569)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 1.3246 (1.7275)\tPrec@1 74.000 (65.639)\tPrec@5 97.000 (96.607)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 1.8518 (1.7288)\tPrec@1 63.000 (65.338)\tPrec@5 98.000 (96.577)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 1.6681 (1.7262)\tPrec@1 69.000 (65.247)\tPrec@5 96.000 (96.667)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 1.6712 (1.7386)\tPrec@1 66.000 (64.978)\tPrec@5 98.000 (96.692)\n",
            "val Results: Prec@1 64.770 Prec@5 96.650 Loss 1.74947\n",
            "val Class Accuracy: [0.952,0.955,0.731,0.639,0.650,0.398,0.727,0.827,0.481,0.117]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [73][0/97], lr: 0.01000\tTime 0.469 (0.469)\tData 0.377 (0.377)\tLoss 0.0770 (0.0770)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [73][10/97], lr: 0.01000\tTime 0.052 (0.101)\tData 0.000 (0.037)\tLoss 0.1142 (0.1393)\tPrec@1 95.312 (94.815)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [73][20/97], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.021)\tLoss 0.1989 (0.1527)\tPrec@1 94.531 (94.494)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [73][30/97], lr: 0.01000\tTime 0.051 (0.074)\tData 0.002 (0.015)\tLoss 0.1248 (0.1517)\tPrec@1 95.312 (94.657)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [73][40/97], lr: 0.01000\tTime 0.043 (0.069)\tData 0.000 (0.013)\tLoss 0.1511 (0.1520)\tPrec@1 95.312 (94.741)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [73][50/97], lr: 0.01000\tTime 0.057 (0.068)\tData 0.007 (0.011)\tLoss 0.1805 (0.1512)\tPrec@1 95.312 (94.746)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [73][60/97], lr: 0.01000\tTime 0.056 (0.067)\tData 0.007 (0.010)\tLoss 0.2248 (0.1526)\tPrec@1 92.969 (94.723)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [73][70/97], lr: 0.01000\tTime 0.072 (0.065)\tData 0.007 (0.010)\tLoss 0.1913 (0.1559)\tPrec@1 94.531 (94.630)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [73][80/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.000 (0.009)\tLoss 0.2400 (0.1570)\tPrec@1 92.969 (94.599)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [73][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 0.2690 (0.1650)\tPrec@1 91.406 (94.325)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.293 (0.293)\tLoss 1.4483 (1.4483)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.030 (0.053)\tLoss 1.5597 (1.6540)\tPrec@1 65.000 (61.818)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.028 (0.040)\tLoss 1.6435 (1.7401)\tPrec@1 64.000 (61.571)\tPrec@5 99.000 (96.952)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 1.8203 (1.7377)\tPrec@1 59.000 (62.032)\tPrec@5 97.000 (96.774)\n",
            "Test: [40/100]\tTime 0.025 (0.034)\tLoss 1.6028 (1.7120)\tPrec@1 58.000 (62.463)\tPrec@5 99.000 (96.829)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.7104 (1.6853)\tPrec@1 65.000 (62.745)\tPrec@5 96.000 (96.882)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 1.2985 (1.6943)\tPrec@1 71.000 (62.475)\tPrec@5 96.000 (96.738)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 1.6499 (1.6999)\tPrec@1 64.000 (62.366)\tPrec@5 99.000 (96.761)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.3799 (1.6896)\tPrec@1 66.000 (62.531)\tPrec@5 98.000 (96.840)\n",
            "Test: [90/100]\tTime 0.041 (0.029)\tLoss 1.7022 (1.7091)\tPrec@1 65.000 (62.187)\tPrec@5 97.000 (96.835)\n",
            "val Results: Prec@1 62.190 Prec@5 96.820 Loss 1.70954\n",
            "val Class Accuracy: [0.937,0.976,0.880,0.685,0.588,0.262,0.455,0.522,0.397,0.517]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [74][0/97], lr: 0.01000\tTime 0.498 (0.498)\tData 0.398 (0.398)\tLoss 0.0963 (0.0963)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [74][10/97], lr: 0.01000\tTime 0.063 (0.104)\tData 0.006 (0.040)\tLoss 0.1802 (0.1302)\tPrec@1 93.750 (95.170)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [74][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.008 (0.023)\tLoss 0.1923 (0.1477)\tPrec@1 94.531 (94.754)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [74][30/97], lr: 0.01000\tTime 0.072 (0.074)\tData 0.000 (0.017)\tLoss 0.1052 (0.1528)\tPrec@1 96.094 (94.556)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [74][40/97], lr: 0.01000\tTime 0.067 (0.071)\tData 0.017 (0.015)\tLoss 0.1935 (0.1507)\tPrec@1 93.750 (94.607)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [74][50/97], lr: 0.01000\tTime 0.060 (0.069)\tData 0.006 (0.012)\tLoss 0.1577 (0.1543)\tPrec@1 96.875 (94.531)\tPrec@5 99.219 (99.939)\n",
            "Epoch: [74][60/97], lr: 0.01000\tTime 0.056 (0.067)\tData 0.017 (0.011)\tLoss 0.1098 (0.1544)\tPrec@1 97.656 (94.531)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [74][70/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.006 (0.010)\tLoss 0.1157 (0.1563)\tPrec@1 96.094 (94.443)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [74][80/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.002 (0.010)\tLoss 0.1492 (0.1571)\tPrec@1 91.406 (94.387)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [74][90/97], lr: 0.01000\tTime 0.037 (0.063)\tData 0.000 (0.009)\tLoss 0.1365 (0.1576)\tPrec@1 96.875 (94.368)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.304 (0.304)\tLoss 1.4818 (1.4818)\tPrec@1 59.000 (59.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.040 (0.057)\tLoss 1.4563 (1.7344)\tPrec@1 70.000 (63.182)\tPrec@5 95.000 (96.091)\n",
            "Test: [20/100]\tTime 0.017 (0.042)\tLoss 1.9135 (1.6802)\tPrec@1 60.000 (63.762)\tPrec@5 98.000 (96.095)\n",
            "Test: [30/100]\tTime 0.017 (0.034)\tLoss 1.4722 (1.6836)\tPrec@1 65.000 (63.613)\tPrec@5 95.000 (95.968)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 1.8314 (1.7141)\tPrec@1 65.000 (63.415)\tPrec@5 95.000 (95.927)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.8704 (1.6833)\tPrec@1 58.000 (63.863)\tPrec@5 97.000 (96.216)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 1.2193 (1.6695)\tPrec@1 73.000 (63.869)\tPrec@5 93.000 (96.262)\n",
            "Test: [70/100]\tTime 0.035 (0.030)\tLoss 1.9047 (1.6535)\tPrec@1 58.000 (63.958)\tPrec@5 95.000 (96.324)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 1.2737 (1.6455)\tPrec@1 74.000 (64.025)\tPrec@5 97.000 (96.420)\n",
            "Test: [90/100]\tTime 0.017 (0.030)\tLoss 1.4784 (1.6603)\tPrec@1 59.000 (63.912)\tPrec@5 100.000 (96.418)\n",
            "val Results: Prec@1 63.940 Prec@5 96.310 Loss 1.66378\n",
            "val Class Accuracy: [0.891,0.981,0.791,0.800,0.736,0.399,0.611,0.350,0.585,0.250]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [75][0/97], lr: 0.01000\tTime 0.412 (0.412)\tData 0.322 (0.322)\tLoss 0.0941 (0.0941)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][10/97], lr: 0.01000\tTime 0.062 (0.104)\tData 0.004 (0.035)\tLoss 0.1348 (0.1207)\tPrec@1 96.094 (95.881)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][20/97], lr: 0.01000\tTime 0.066 (0.084)\tData 0.005 (0.020)\tLoss 0.2169 (0.1285)\tPrec@1 92.969 (95.387)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][30/97], lr: 0.01000\tTime 0.057 (0.076)\tData 0.007 (0.015)\tLoss 0.1297 (0.1277)\tPrec@1 93.750 (95.464)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][40/97], lr: 0.01000\tTime 0.046 (0.072)\tData 0.000 (0.013)\tLoss 0.2190 (0.1372)\tPrec@1 92.188 (95.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][50/97], lr: 0.01000\tTime 0.049 (0.069)\tData 0.000 (0.011)\tLoss 0.1682 (0.1358)\tPrec@1 92.969 (95.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][60/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.007 (0.011)\tLoss 0.1524 (0.1416)\tPrec@1 92.969 (94.979)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [75][70/97], lr: 0.01000\tTime 0.052 (0.066)\tData 0.006 (0.010)\tLoss 0.1389 (0.1456)\tPrec@1 96.875 (94.938)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [75][80/97], lr: 0.01000\tTime 0.077 (0.065)\tData 0.006 (0.010)\tLoss 0.1410 (0.1516)\tPrec@1 92.969 (94.763)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [75][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.2121 (0.1519)\tPrec@1 90.625 (94.643)\tPrec@5 99.219 (99.974)\n",
            "Test: [0/100]\tTime 0.285 (0.285)\tLoss 1.9573 (1.9573)\tPrec@1 60.000 (60.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.025 (0.054)\tLoss 1.3005 (1.9653)\tPrec@1 75.000 (60.000)\tPrec@5 97.000 (95.364)\n",
            "Test: [20/100]\tTime 0.025 (0.042)\tLoss 1.6674 (1.9872)\tPrec@1 61.000 (59.048)\tPrec@5 96.000 (95.381)\n",
            "Test: [30/100]\tTime 0.042 (0.036)\tLoss 1.9918 (1.9684)\tPrec@1 58.000 (58.677)\tPrec@5 96.000 (95.548)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 2.0905 (1.9480)\tPrec@1 55.000 (59.024)\tPrec@5 95.000 (95.707)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 1.9651 (1.9169)\tPrec@1 59.000 (59.824)\tPrec@5 95.000 (95.922)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 1.5933 (1.9060)\tPrec@1 66.000 (59.623)\tPrec@5 95.000 (95.902)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 1.7030 (1.8950)\tPrec@1 60.000 (59.465)\tPrec@5 96.000 (95.930)\n",
            "Test: [80/100]\tTime 0.022 (0.030)\tLoss 1.8799 (1.8851)\tPrec@1 64.000 (59.469)\tPrec@5 94.000 (96.123)\n",
            "Test: [90/100]\tTime 0.035 (0.029)\tLoss 1.9371 (1.8974)\tPrec@1 52.000 (59.253)\tPrec@5 96.000 (96.121)\n",
            "val Results: Prec@1 59.230 Prec@5 96.100 Loss 1.90429\n",
            "val Class Accuracy: [0.897,0.923,0.880,0.717,0.606,0.422,0.613,0.252,0.240,0.373]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [76][0/97], lr: 0.01000\tTime 0.484 (0.484)\tData 0.396 (0.396)\tLoss 0.1717 (0.1717)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [76][10/97], lr: 0.01000\tTime 0.060 (0.103)\tData 0.007 (0.041)\tLoss 0.1126 (0.1830)\tPrec@1 96.094 (93.466)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [76][20/97], lr: 0.01000\tTime 0.054 (0.083)\tData 0.000 (0.023)\tLoss 0.1304 (0.1733)\tPrec@1 95.312 (94.234)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [76][30/97], lr: 0.01000\tTime 0.068 (0.074)\tData 0.007 (0.018)\tLoss 0.1590 (0.1681)\tPrec@1 95.312 (94.405)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [76][40/97], lr: 0.01000\tTime 0.058 (0.071)\tData 0.006 (0.015)\tLoss 0.1473 (0.1686)\tPrec@1 93.750 (94.379)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [76][50/97], lr: 0.01000\tTime 0.046 (0.068)\tData 0.000 (0.013)\tLoss 0.1270 (0.1628)\tPrec@1 94.531 (94.424)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [76][60/97], lr: 0.01000\tTime 0.046 (0.066)\tData 0.000 (0.012)\tLoss 0.0863 (0.1643)\tPrec@1 96.875 (94.326)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [76][70/97], lr: 0.01000\tTime 0.083 (0.065)\tData 0.007 (0.011)\tLoss 0.1731 (0.1646)\tPrec@1 93.750 (94.278)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [76][80/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.010)\tLoss 0.2818 (0.1674)\tPrec@1 90.625 (94.194)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [76][90/97], lr: 0.01000\tTime 0.033 (0.062)\tData 0.000 (0.009)\tLoss 0.2052 (0.1686)\tPrec@1 92.188 (94.136)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 1.6229 (1.6229)\tPrec@1 59.000 (59.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.022 (0.057)\tLoss 1.5238 (1.8038)\tPrec@1 66.000 (58.909)\tPrec@5 94.000 (95.545)\n",
            "Test: [20/100]\tTime 0.010 (0.039)\tLoss 1.6010 (1.7461)\tPrec@1 63.000 (60.286)\tPrec@5 98.000 (95.524)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 1.5026 (1.7433)\tPrec@1 55.000 (59.806)\tPrec@5 97.000 (95.226)\n",
            "Test: [40/100]\tTime 0.017 (0.032)\tLoss 2.0261 (1.7747)\tPrec@1 55.000 (59.878)\tPrec@5 95.000 (95.317)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 1.8214 (1.7397)\tPrec@1 59.000 (60.039)\tPrec@5 97.000 (95.569)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 1.5631 (1.7308)\tPrec@1 61.000 (60.164)\tPrec@5 95.000 (95.623)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 2.1366 (1.7280)\tPrec@1 56.000 (60.085)\tPrec@5 96.000 (95.535)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 1.5409 (1.7180)\tPrec@1 62.000 (60.407)\tPrec@5 94.000 (95.605)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 1.5740 (1.7340)\tPrec@1 59.000 (59.978)\tPrec@5 96.000 (95.549)\n",
            "val Results: Prec@1 59.930 Prec@5 95.490 Loss 1.74174\n",
            "val Class Accuracy: [0.815,0.967,0.876,0.521,0.628,0.585,0.592,0.309,0.474,0.226]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [77][0/97], lr: 0.01000\tTime 0.407 (0.407)\tData 0.330 (0.330)\tLoss 0.1382 (0.1382)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][10/97], lr: 0.01000\tTime 0.062 (0.098)\tData 0.000 (0.032)\tLoss 0.1829 (0.1477)\tPrec@1 92.188 (94.531)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [77][20/97], lr: 0.01000\tTime 0.066 (0.080)\tData 0.007 (0.019)\tLoss 0.1715 (0.1477)\tPrec@1 92.188 (94.531)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [77][30/97], lr: 0.01000\tTime 0.053 (0.074)\tData 0.000 (0.014)\tLoss 0.1331 (0.1480)\tPrec@1 95.312 (94.657)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [77][40/97], lr: 0.01000\tTime 0.055 (0.070)\tData 0.008 (0.012)\tLoss 0.1234 (0.1516)\tPrec@1 96.875 (94.360)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [77][50/97], lr: 0.01000\tTime 0.056 (0.068)\tData 0.008 (0.010)\tLoss 0.1447 (0.1532)\tPrec@1 94.531 (94.256)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [77][60/97], lr: 0.01000\tTime 0.061 (0.066)\tData 0.005 (0.010)\tLoss 0.2007 (0.1536)\tPrec@1 90.625 (94.224)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [77][70/97], lr: 0.01000\tTime 0.057 (0.065)\tData 0.004 (0.009)\tLoss 0.1559 (0.1536)\tPrec@1 93.750 (94.212)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [77][80/97], lr: 0.01000\tTime 0.059 (0.064)\tData 0.006 (0.009)\tLoss 0.1398 (0.1570)\tPrec@1 93.750 (94.117)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [77][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.008)\tLoss 0.2207 (0.1597)\tPrec@1 91.406 (94.085)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 1.4220 (1.4220)\tPrec@1 68.000 (68.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.023 (0.055)\tLoss 1.2461 (1.3878)\tPrec@1 73.000 (67.091)\tPrec@5 95.000 (96.545)\n",
            "Test: [20/100]\tTime 0.027 (0.042)\tLoss 1.2222 (1.4552)\tPrec@1 68.000 (65.571)\tPrec@5 96.000 (96.190)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 1.4324 (1.4852)\tPrec@1 60.000 (64.710)\tPrec@5 95.000 (95.903)\n",
            "Test: [40/100]\tTime 0.027 (0.032)\tLoss 1.6262 (1.4819)\tPrec@1 66.000 (64.732)\tPrec@5 96.000 (96.024)\n",
            "Test: [50/100]\tTime 0.045 (0.032)\tLoss 1.6042 (1.4739)\tPrec@1 67.000 (65.118)\tPrec@5 93.000 (96.059)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 1.1748 (1.4764)\tPrec@1 72.000 (65.033)\tPrec@5 96.000 (96.049)\n",
            "Test: [70/100]\tTime 0.037 (0.030)\tLoss 1.5967 (1.4720)\tPrec@1 65.000 (65.282)\tPrec@5 97.000 (96.085)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 1.5956 (1.4720)\tPrec@1 67.000 (65.370)\tPrec@5 97.000 (96.259)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 1.3317 (1.4830)\tPrec@1 70.000 (65.187)\tPrec@5 97.000 (96.209)\n",
            "val Results: Prec@1 65.080 Prec@5 96.230 Loss 1.48840\n",
            "val Class Accuracy: [0.943,0.972,0.682,0.707,0.664,0.714,0.392,0.391,0.580,0.463]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [78][0/97], lr: 0.01000\tTime 0.459 (0.459)\tData 0.365 (0.365)\tLoss 0.1380 (0.1380)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][10/97], lr: 0.01000\tTime 0.071 (0.104)\tData 0.002 (0.038)\tLoss 0.1976 (0.1546)\tPrec@1 92.969 (94.602)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][20/97], lr: 0.01000\tTime 0.056 (0.082)\tData 0.007 (0.023)\tLoss 0.1540 (0.1461)\tPrec@1 93.750 (94.940)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [78][30/97], lr: 0.01000\tTime 0.046 (0.074)\tData 0.004 (0.018)\tLoss 0.1492 (0.1496)\tPrec@1 95.312 (94.859)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [78][40/97], lr: 0.01000\tTime 0.063 (0.070)\tData 0.000 (0.015)\tLoss 0.2107 (0.1515)\tPrec@1 92.969 (94.817)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [78][50/97], lr: 0.01000\tTime 0.062 (0.068)\tData 0.013 (0.013)\tLoss 0.2259 (0.1518)\tPrec@1 93.750 (94.792)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [78][60/97], lr: 0.01000\tTime 0.066 (0.066)\tData 0.000 (0.011)\tLoss 0.1797 (0.1493)\tPrec@1 96.875 (94.954)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [78][70/97], lr: 0.01000\tTime 0.084 (0.065)\tData 0.004 (0.011)\tLoss 0.0957 (0.1498)\tPrec@1 96.094 (94.894)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [78][80/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.010)\tLoss 0.1168 (0.1491)\tPrec@1 94.531 (94.830)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [78][90/97], lr: 0.01000\tTime 0.026 (0.063)\tData 0.000 (0.009)\tLoss 0.1017 (0.1504)\tPrec@1 96.875 (94.832)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.262 (0.262)\tLoss 2.5797 (2.5797)\tPrec@1 45.000 (45.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.032 (0.053)\tLoss 2.0663 (2.5849)\tPrec@1 64.000 (52.909)\tPrec@5 96.000 (95.909)\n",
            "Test: [20/100]\tTime 0.035 (0.041)\tLoss 1.7562 (2.6069)\tPrec@1 58.000 (52.143)\tPrec@5 98.000 (95.381)\n",
            "Test: [30/100]\tTime 0.013 (0.033)\tLoss 2.3775 (2.6127)\tPrec@1 53.000 (52.387)\tPrec@5 96.000 (94.968)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 3.2200 (2.6152)\tPrec@1 43.000 (52.073)\tPrec@5 91.000 (95.049)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 2.2855 (2.5881)\tPrec@1 58.000 (52.745)\tPrec@5 95.000 (94.980)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 1.9783 (2.5720)\tPrec@1 63.000 (52.869)\tPrec@5 97.000 (95.033)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 2.5778 (2.5698)\tPrec@1 51.000 (52.718)\tPrec@5 97.000 (95.141)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 2.4992 (2.5465)\tPrec@1 59.000 (53.086)\tPrec@5 97.000 (95.284)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 2.5455 (2.5804)\tPrec@1 54.000 (53.000)\tPrec@5 97.000 (95.242)\n",
            "val Results: Prec@1 52.920 Prec@5 95.140 Loss 2.59690\n",
            "val Class Accuracy: [0.983,0.929,0.734,0.457,0.492,0.611,0.480,0.326,0.136,0.144]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [79][0/97], lr: 0.01000\tTime 0.483 (0.483)\tData 0.394 (0.394)\tLoss 0.1427 (0.1427)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][10/97], lr: 0.01000\tTime 0.063 (0.101)\tData 0.005 (0.040)\tLoss 0.1346 (0.1805)\tPrec@1 95.312 (94.034)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [79][20/97], lr: 0.01000\tTime 0.060 (0.082)\tData 0.005 (0.023)\tLoss 0.1013 (0.1627)\tPrec@1 96.094 (94.494)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [79][30/97], lr: 0.01000\tTime 0.074 (0.074)\tData 0.007 (0.018)\tLoss 0.1122 (0.1665)\tPrec@1 97.656 (94.405)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [79][40/97], lr: 0.01000\tTime 0.055 (0.070)\tData 0.009 (0.015)\tLoss 0.1432 (0.1619)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [79][50/97], lr: 0.01000\tTime 0.038 (0.068)\tData 0.000 (0.013)\tLoss 0.1185 (0.1580)\tPrec@1 96.094 (94.623)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [79][60/97], lr: 0.01000\tTime 0.061 (0.066)\tData 0.005 (0.012)\tLoss 0.1876 (0.1599)\tPrec@1 94.531 (94.454)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [79][70/97], lr: 0.01000\tTime 0.051 (0.066)\tData 0.000 (0.011)\tLoss 0.1987 (0.1607)\tPrec@1 94.531 (94.443)\tPrec@5 99.219 (99.945)\n",
            "Epoch: [79][80/97], lr: 0.01000\tTime 0.052 (0.065)\tData 0.000 (0.010)\tLoss 0.1727 (0.1589)\tPrec@1 93.750 (94.493)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [79][90/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.009)\tLoss 0.1046 (0.1573)\tPrec@1 96.875 (94.583)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 2.0217 (2.0217)\tPrec@1 57.000 (57.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.027 (0.059)\tLoss 1.9630 (2.1468)\tPrec@1 61.000 (58.636)\tPrec@5 96.000 (97.091)\n",
            "Test: [20/100]\tTime 0.026 (0.042)\tLoss 1.6470 (2.0890)\tPrec@1 64.000 (59.095)\tPrec@5 98.000 (96.619)\n",
            "Test: [30/100]\tTime 0.027 (0.036)\tLoss 1.8610 (2.0874)\tPrec@1 63.000 (59.129)\tPrec@5 97.000 (96.387)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 2.0625 (2.1045)\tPrec@1 66.000 (59.390)\tPrec@5 98.000 (96.512)\n",
            "Test: [50/100]\tTime 0.040 (0.032)\tLoss 2.0125 (2.0799)\tPrec@1 58.000 (59.412)\tPrec@5 97.000 (96.745)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.8050 (2.0805)\tPrec@1 61.000 (59.148)\tPrec@5 96.000 (96.705)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 2.0726 (2.0617)\tPrec@1 57.000 (59.352)\tPrec@5 96.000 (96.662)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.5994 (2.0396)\tPrec@1 65.000 (59.716)\tPrec@5 97.000 (96.679)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 2.0938 (2.0614)\tPrec@1 57.000 (59.374)\tPrec@5 98.000 (96.681)\n",
            "val Results: Prec@1 59.280 Prec@5 96.660 Loss 2.05802\n",
            "val Class Accuracy: [0.815,0.991,0.862,0.810,0.471,0.566,0.312,0.418,0.464,0.219]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [80][0/97], lr: 0.01000\tTime 0.513 (0.513)\tData 0.435 (0.435)\tLoss 0.2503 (0.2503)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][10/97], lr: 0.01000\tTime 0.062 (0.103)\tData 0.001 (0.044)\tLoss 0.1646 (0.1274)\tPrec@1 91.406 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][20/97], lr: 0.01000\tTime 0.053 (0.081)\tData 0.000 (0.025)\tLoss 0.0520 (0.1221)\tPrec@1 98.438 (95.796)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][30/97], lr: 0.01000\tTime 0.053 (0.074)\tData 0.008 (0.018)\tLoss 0.1778 (0.1215)\tPrec@1 92.969 (95.842)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][40/97], lr: 0.01000\tTime 0.070 (0.071)\tData 0.011 (0.015)\tLoss 0.1549 (0.1269)\tPrec@1 92.969 (95.598)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][50/97], lr: 0.01000\tTime 0.038 (0.067)\tData 0.000 (0.013)\tLoss 0.1774 (0.1305)\tPrec@1 95.312 (95.512)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [80][60/97], lr: 0.01000\tTime 0.065 (0.066)\tData 0.007 (0.012)\tLoss 0.0947 (0.1322)\tPrec@1 96.094 (95.389)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [80][70/97], lr: 0.01000\tTime 0.057 (0.065)\tData 0.007 (0.011)\tLoss 0.1128 (0.1311)\tPrec@1 95.312 (95.401)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [80][80/97], lr: 0.01000\tTime 0.037 (0.064)\tData 0.000 (0.010)\tLoss 0.3034 (0.1405)\tPrec@1 89.062 (95.062)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [80][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.010)\tLoss 0.1229 (0.1449)\tPrec@1 94.531 (94.892)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.275 (0.275)\tLoss 1.6932 (1.6932)\tPrec@1 60.000 (60.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.011 (0.055)\tLoss 1.5866 (1.9473)\tPrec@1 71.000 (63.455)\tPrec@5 92.000 (92.273)\n",
            "Test: [20/100]\tTime 0.028 (0.040)\tLoss 1.4255 (1.8811)\tPrec@1 70.000 (64.190)\tPrec@5 94.000 (93.095)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 1.6453 (1.8903)\tPrec@1 66.000 (63.742)\tPrec@5 94.000 (93.226)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 1.9177 (1.8899)\tPrec@1 62.000 (63.463)\tPrec@5 96.000 (93.439)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 1.5917 (1.8834)\tPrec@1 68.000 (63.647)\tPrec@5 97.000 (93.412)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 1.5090 (1.8540)\tPrec@1 64.000 (63.590)\tPrec@5 93.000 (93.639)\n",
            "Test: [70/100]\tTime 0.044 (0.030)\tLoss 1.7239 (1.8510)\tPrec@1 63.000 (63.423)\tPrec@5 96.000 (93.606)\n",
            "Test: [80/100]\tTime 0.034 (0.030)\tLoss 1.4080 (1.8403)\tPrec@1 70.000 (63.556)\tPrec@5 93.000 (93.741)\n",
            "Test: [90/100]\tTime 0.021 (0.029)\tLoss 1.9243 (1.8694)\tPrec@1 58.000 (63.154)\tPrec@5 93.000 (93.505)\n",
            "val Results: Prec@1 62.960 Prec@5 93.570 Loss 1.87253\n",
            "val Class Accuracy: [0.921,0.965,0.647,0.647,0.742,0.641,0.645,0.742,0.158,0.188]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [81][0/97], lr: 0.01000\tTime 0.441 (0.441)\tData 0.324 (0.324)\tLoss 0.1215 (0.1215)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][10/97], lr: 0.01000\tTime 0.068 (0.104)\tData 0.003 (0.035)\tLoss 0.1552 (0.1437)\tPrec@1 94.531 (94.815)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][20/97], lr: 0.01000\tTime 0.045 (0.081)\tData 0.000 (0.021)\tLoss 0.1616 (0.1393)\tPrec@1 93.750 (94.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][30/97], lr: 0.01000\tTime 0.060 (0.074)\tData 0.007 (0.016)\tLoss 0.1452 (0.1494)\tPrec@1 93.750 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][40/97], lr: 0.01000\tTime 0.034 (0.070)\tData 0.000 (0.013)\tLoss 0.1114 (0.1513)\tPrec@1 96.094 (94.722)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][50/97], lr: 0.01000\tTime 0.059 (0.068)\tData 0.000 (0.011)\tLoss 0.1844 (0.1553)\tPrec@1 90.625 (94.562)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [81][60/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.000 (0.010)\tLoss 0.1076 (0.1540)\tPrec@1 96.094 (94.493)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [81][70/97], lr: 0.01000\tTime 0.071 (0.065)\tData 0.005 (0.010)\tLoss 0.1496 (0.1575)\tPrec@1 94.531 (94.388)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [81][80/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.004 (0.009)\tLoss 0.2293 (0.1597)\tPrec@1 92.188 (94.309)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [81][90/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.009)\tLoss 0.1303 (0.1603)\tPrec@1 94.531 (94.299)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.4525 (1.4525)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.021 (0.055)\tLoss 1.4060 (1.8194)\tPrec@1 73.000 (62.818)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/100]\tTime 0.017 (0.038)\tLoss 1.5554 (1.7889)\tPrec@1 64.000 (63.905)\tPrec@5 97.000 (96.524)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 1.9187 (1.8018)\tPrec@1 65.000 (63.097)\tPrec@5 92.000 (96.065)\n",
            "Test: [40/100]\tTime 0.039 (0.033)\tLoss 1.9119 (1.7882)\tPrec@1 56.000 (62.829)\tPrec@5 99.000 (96.268)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 1.4663 (1.7720)\tPrec@1 65.000 (63.118)\tPrec@5 98.000 (96.275)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 1.5302 (1.7712)\tPrec@1 68.000 (63.066)\tPrec@5 97.000 (96.246)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 1.7818 (1.7716)\tPrec@1 64.000 (63.000)\tPrec@5 97.000 (96.254)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.5960 (1.7574)\tPrec@1 68.000 (62.914)\tPrec@5 93.000 (96.309)\n",
            "Test: [90/100]\tTime 0.013 (0.028)\tLoss 1.6408 (1.7887)\tPrec@1 65.000 (62.352)\tPrec@5 97.000 (96.264)\n",
            "val Results: Prec@1 62.260 Prec@5 96.080 Loss 1.80037\n",
            "val Class Accuracy: [0.894,0.937,0.844,0.605,0.837,0.420,0.650,0.521,0.149,0.369]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [82][0/97], lr: 0.01000\tTime 0.384 (0.384)\tData 0.301 (0.301)\tLoss 0.1626 (0.1626)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][10/97], lr: 0.01000\tTime 0.068 (0.103)\tData 0.010 (0.032)\tLoss 0.1258 (0.1297)\tPrec@1 96.094 (95.526)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][20/97], lr: 0.01000\tTime 0.044 (0.079)\tData 0.000 (0.019)\tLoss 0.1351 (0.1284)\tPrec@1 94.531 (95.350)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][30/97], lr: 0.01000\tTime 0.042 (0.072)\tData 0.000 (0.014)\tLoss 0.1073 (0.1345)\tPrec@1 97.656 (95.237)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][40/97], lr: 0.01000\tTime 0.051 (0.069)\tData 0.000 (0.011)\tLoss 0.1357 (0.1340)\tPrec@1 95.312 (95.255)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][50/97], lr: 0.01000\tTime 0.049 (0.067)\tData 0.000 (0.010)\tLoss 0.1451 (0.1329)\tPrec@1 95.312 (95.282)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][60/97], lr: 0.01000\tTime 0.056 (0.065)\tData 0.000 (0.009)\tLoss 0.0879 (0.1298)\tPrec@1 96.094 (95.377)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [82][70/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.000 (0.008)\tLoss 0.1141 (0.1315)\tPrec@1 94.531 (95.191)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [82][80/97], lr: 0.01000\tTime 0.052 (0.063)\tData 0.007 (0.008)\tLoss 0.1277 (0.1334)\tPrec@1 95.312 (95.177)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [82][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.007)\tLoss 0.1492 (0.1361)\tPrec@1 92.969 (95.089)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.4868 (1.4868)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.032 (0.055)\tLoss 1.4737 (1.9510)\tPrec@1 71.000 (63.636)\tPrec@5 97.000 (95.818)\n",
            "Test: [20/100]\tTime 0.025 (0.040)\tLoss 1.7899 (1.9222)\tPrec@1 63.000 (63.619)\tPrec@5 95.000 (95.619)\n",
            "Test: [30/100]\tTime 0.013 (0.035)\tLoss 1.6586 (1.9580)\tPrec@1 67.000 (63.323)\tPrec@5 94.000 (95.226)\n",
            "Test: [40/100]\tTime 0.034 (0.032)\tLoss 1.7377 (1.9369)\tPrec@1 59.000 (63.195)\tPrec@5 98.000 (95.268)\n",
            "Test: [50/100]\tTime 0.012 (0.030)\tLoss 1.8134 (1.9091)\tPrec@1 61.000 (63.235)\tPrec@5 98.000 (95.412)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 1.9254 (1.9047)\tPrec@1 69.000 (63.098)\tPrec@5 96.000 (95.590)\n",
            "Test: [70/100]\tTime 0.013 (0.030)\tLoss 1.8764 (1.9026)\tPrec@1 60.000 (63.042)\tPrec@5 96.000 (95.549)\n",
            "Test: [80/100]\tTime 0.040 (0.029)\tLoss 1.4039 (1.8713)\tPrec@1 68.000 (63.086)\tPrec@5 97.000 (95.679)\n",
            "Test: [90/100]\tTime 0.026 (0.028)\tLoss 1.5729 (1.8920)\tPrec@1 64.000 (62.714)\tPrec@5 95.000 (95.593)\n",
            "val Results: Prec@1 62.480 Prec@5 95.620 Loss 1.90428\n",
            "val Class Accuracy: [0.888,0.914,0.896,0.554,0.610,0.517,0.692,0.521,0.314,0.342]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [83][0/97], lr: 0.01000\tTime 0.381 (0.381)\tData 0.313 (0.313)\tLoss 0.1332 (0.1332)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][10/97], lr: 0.01000\tTime 0.069 (0.101)\tData 0.000 (0.036)\tLoss 0.1105 (0.1457)\tPrec@1 95.312 (95.241)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][20/97], lr: 0.01000\tTime 0.050 (0.082)\tData 0.000 (0.020)\tLoss 0.1184 (0.1536)\tPrec@1 96.094 (94.866)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][30/97], lr: 0.01000\tTime 0.066 (0.075)\tData 0.005 (0.016)\tLoss 0.2031 (0.1543)\tPrec@1 92.969 (94.556)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [83][40/97], lr: 0.01000\tTime 0.049 (0.071)\tData 0.003 (0.013)\tLoss 0.1797 (0.1502)\tPrec@1 91.406 (94.684)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [83][50/97], lr: 0.01000\tTime 0.050 (0.068)\tData 0.007 (0.012)\tLoss 0.1122 (0.1494)\tPrec@1 96.094 (94.838)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [83][60/97], lr: 0.01000\tTime 0.067 (0.067)\tData 0.007 (0.011)\tLoss 0.2000 (0.1466)\tPrec@1 92.188 (94.839)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [83][70/97], lr: 0.01000\tTime 0.068 (0.065)\tData 0.000 (0.010)\tLoss 0.2062 (0.1519)\tPrec@1 91.406 (94.630)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [83][80/97], lr: 0.01000\tTime 0.085 (0.065)\tData 0.006 (0.009)\tLoss 0.1323 (0.1521)\tPrec@1 95.312 (94.618)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [83][90/97], lr: 0.01000\tTime 0.049 (0.064)\tData 0.000 (0.008)\tLoss 0.1807 (0.1554)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.285 (0.285)\tLoss 1.4265 (1.4265)\tPrec@1 68.000 (68.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.021 (0.057)\tLoss 1.3515 (1.6811)\tPrec@1 73.000 (65.364)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/100]\tTime 0.031 (0.041)\tLoss 1.0491 (1.6315)\tPrec@1 73.000 (66.381)\tPrec@5 99.000 (97.190)\n",
            "Test: [30/100]\tTime 0.033 (0.037)\tLoss 1.4302 (1.6183)\tPrec@1 68.000 (66.484)\tPrec@5 97.000 (97.097)\n",
            "Test: [40/100]\tTime 0.027 (0.034)\tLoss 1.4496 (1.6173)\tPrec@1 66.000 (66.585)\tPrec@5 98.000 (97.244)\n",
            "Test: [50/100]\tTime 0.021 (0.032)\tLoss 1.8747 (1.6100)\tPrec@1 63.000 (66.667)\tPrec@5 96.000 (97.196)\n",
            "Test: [60/100]\tTime 0.010 (0.031)\tLoss 1.3696 (1.5981)\tPrec@1 74.000 (66.738)\tPrec@5 100.000 (97.180)\n",
            "Test: [70/100]\tTime 0.013 (0.029)\tLoss 1.7753 (1.5910)\tPrec@1 66.000 (67.028)\tPrec@5 97.000 (97.155)\n",
            "Test: [80/100]\tTime 0.012 (0.029)\tLoss 1.4138 (1.5829)\tPrec@1 70.000 (67.148)\tPrec@5 95.000 (97.222)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.3016 (1.6068)\tPrec@1 70.000 (66.571)\tPrec@5 98.000 (97.220)\n",
            "val Results: Prec@1 66.530 Prec@5 97.210 Loss 1.61186\n",
            "val Class Accuracy: [0.913,0.991,0.831,0.668,0.646,0.448,0.620,0.715,0.463,0.358]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [84][0/97], lr: 0.01000\tTime 0.465 (0.465)\tData 0.391 (0.391)\tLoss 0.1601 (0.1601)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][10/97], lr: 0.01000\tTime 0.056 (0.102)\tData 0.000 (0.041)\tLoss 0.1305 (0.1367)\tPrec@1 95.312 (95.099)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][20/97], lr: 0.01000\tTime 0.057 (0.080)\tData 0.011 (0.024)\tLoss 0.1454 (0.1420)\tPrec@1 95.312 (94.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][30/97], lr: 0.01000\tTime 0.046 (0.074)\tData 0.001 (0.018)\tLoss 0.1171 (0.1418)\tPrec@1 96.875 (94.934)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][40/97], lr: 0.01000\tTime 0.051 (0.070)\tData 0.006 (0.015)\tLoss 0.3000 (0.1497)\tPrec@1 87.500 (94.627)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][50/97], lr: 0.01000\tTime 0.050 (0.067)\tData 0.004 (0.013)\tLoss 0.1194 (0.1491)\tPrec@1 96.094 (94.684)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [84][60/97], lr: 0.01000\tTime 0.064 (0.066)\tData 0.006 (0.012)\tLoss 0.2112 (0.1566)\tPrec@1 92.969 (94.442)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [84][70/97], lr: 0.01000\tTime 0.044 (0.065)\tData 0.000 (0.011)\tLoss 0.0978 (0.1586)\tPrec@1 96.094 (94.443)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [84][80/97], lr: 0.01000\tTime 0.055 (0.064)\tData 0.006 (0.010)\tLoss 0.1970 (0.1577)\tPrec@1 93.750 (94.416)\tPrec@5 99.219 (99.942)\n",
            "Epoch: [84][90/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.1600 (0.1574)\tPrec@1 96.094 (94.497)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 1.6236 (1.6236)\tPrec@1 61.000 (61.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.030 (0.056)\tLoss 1.4254 (1.8023)\tPrec@1 73.000 (63.000)\tPrec@5 92.000 (93.182)\n",
            "Test: [20/100]\tTime 0.030 (0.041)\tLoss 1.4376 (1.7611)\tPrec@1 64.000 (63.857)\tPrec@5 95.000 (93.286)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 1.7306 (1.7779)\tPrec@1 61.000 (63.194)\tPrec@5 97.000 (93.613)\n",
            "Test: [40/100]\tTime 0.009 (0.033)\tLoss 1.9115 (1.7765)\tPrec@1 60.000 (63.024)\tPrec@5 95.000 (94.073)\n",
            "Test: [50/100]\tTime 0.026 (0.031)\tLoss 1.6367 (1.7617)\tPrec@1 64.000 (63.549)\tPrec@5 98.000 (94.157)\n",
            "Test: [60/100]\tTime 0.036 (0.031)\tLoss 1.6112 (1.7471)\tPrec@1 69.000 (63.639)\tPrec@5 92.000 (94.230)\n",
            "Test: [70/100]\tTime 0.013 (0.030)\tLoss 1.7001 (1.7453)\tPrec@1 65.000 (63.775)\tPrec@5 96.000 (94.239)\n",
            "Test: [80/100]\tTime 0.035 (0.029)\tLoss 1.3695 (1.7209)\tPrec@1 73.000 (64.074)\tPrec@5 95.000 (94.346)\n",
            "Test: [90/100]\tTime 0.038 (0.028)\tLoss 1.4772 (1.7328)\tPrec@1 66.000 (63.791)\tPrec@5 94.000 (94.286)\n",
            "val Results: Prec@1 63.720 Prec@5 94.240 Loss 1.73879\n",
            "val Class Accuracy: [0.898,0.956,0.764,0.765,0.652,0.584,0.660,0.526,0.144,0.423]\n",
            "Best Prec@1: 69.040\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [85][0/97], lr: 0.01000\tTime 0.445 (0.445)\tData 0.353 (0.353)\tLoss 0.1601 (0.1601)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][10/97], lr: 0.01000\tTime 0.040 (0.100)\tData 0.000 (0.039)\tLoss 0.1167 (0.1302)\tPrec@1 95.312 (95.739)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][20/97], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.022)\tLoss 0.1236 (0.1323)\tPrec@1 96.875 (95.499)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][30/97], lr: 0.01000\tTime 0.042 (0.072)\tData 0.000 (0.017)\tLoss 0.1778 (0.1402)\tPrec@1 92.969 (95.161)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [85][40/97], lr: 0.01000\tTime 0.058 (0.068)\tData 0.000 (0.014)\tLoss 0.1402 (0.1416)\tPrec@1 94.531 (95.084)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [85][50/97], lr: 0.01000\tTime 0.053 (0.066)\tData 0.000 (0.012)\tLoss 0.1586 (0.1425)\tPrec@1 93.750 (94.945)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [85][60/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.014 (0.011)\tLoss 0.1247 (0.1439)\tPrec@1 94.531 (94.800)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [85][70/97], lr: 0.01000\tTime 0.065 (0.064)\tData 0.004 (0.010)\tLoss 0.1574 (0.1449)\tPrec@1 95.312 (94.850)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [85][80/97], lr: 0.01000\tTime 0.056 (0.063)\tData 0.006 (0.010)\tLoss 0.0928 (0.1450)\tPrec@1 96.094 (94.859)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [85][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.009)\tLoss 0.1403 (0.1451)\tPrec@1 95.312 (94.840)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.292 (0.292)\tLoss 1.1380 (1.1380)\tPrec@1 66.000 (66.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.035 (0.052)\tLoss 1.0908 (1.3012)\tPrec@1 76.000 (69.273)\tPrec@5 95.000 (97.727)\n",
            "Test: [20/100]\tTime 0.016 (0.039)\tLoss 1.2768 (1.3359)\tPrec@1 68.000 (69.667)\tPrec@5 98.000 (97.286)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 1.3367 (1.3443)\tPrec@1 70.000 (69.677)\tPrec@5 96.000 (97.226)\n",
            "Test: [40/100]\tTime 0.020 (0.033)\tLoss 1.1990 (1.3350)\tPrec@1 75.000 (70.000)\tPrec@5 99.000 (97.293)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 1.1501 (1.3318)\tPrec@1 75.000 (70.294)\tPrec@5 98.000 (97.275)\n",
            "Test: [60/100]\tTime 0.045 (0.031)\tLoss 1.1197 (1.3284)\tPrec@1 72.000 (70.344)\tPrec@5 98.000 (97.279)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 1.4574 (1.3177)\tPrec@1 71.000 (70.408)\tPrec@5 96.000 (97.296)\n",
            "Test: [80/100]\tTime 0.042 (0.029)\tLoss 1.0321 (1.3086)\tPrec@1 78.000 (70.556)\tPrec@5 97.000 (97.309)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.0654 (1.3165)\tPrec@1 72.000 (70.242)\tPrec@5 97.000 (97.308)\n",
            "val Results: Prec@1 70.010 Prec@5 97.220 Loss 1.32344\n",
            "val Class Accuracy: [0.914,0.950,0.666,0.597,0.820,0.788,0.652,0.582,0.378,0.654]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [86][0/97], lr: 0.01000\tTime 0.486 (0.486)\tData 0.404 (0.404)\tLoss 0.1932 (0.1932)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][10/97], lr: 0.01000\tTime 0.052 (0.100)\tData 0.001 (0.040)\tLoss 0.0793 (0.1116)\tPrec@1 97.656 (96.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][20/97], lr: 0.01000\tTime 0.049 (0.079)\tData 0.000 (0.022)\tLoss 0.1025 (0.1132)\tPrec@1 96.094 (95.833)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][30/97], lr: 0.01000\tTime 0.047 (0.073)\tData 0.000 (0.017)\tLoss 0.0937 (0.1191)\tPrec@1 96.875 (95.691)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [86][40/97], lr: 0.01000\tTime 0.069 (0.069)\tData 0.000 (0.014)\tLoss 0.0815 (0.1167)\tPrec@1 96.875 (95.865)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [86][50/97], lr: 0.01000\tTime 0.042 (0.066)\tData 0.000 (0.012)\tLoss 0.1052 (0.1239)\tPrec@1 96.875 (95.588)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [86][60/97], lr: 0.01000\tTime 0.041 (0.065)\tData 0.000 (0.010)\tLoss 0.0498 (0.1285)\tPrec@1 98.438 (95.428)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [86][70/97], lr: 0.01000\tTime 0.070 (0.064)\tData 0.000 (0.010)\tLoss 0.1463 (0.1306)\tPrec@1 92.969 (95.357)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [86][80/97], lr: 0.01000\tTime 0.049 (0.063)\tData 0.007 (0.009)\tLoss 0.1083 (0.1348)\tPrec@1 94.531 (95.235)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [86][90/97], lr: 0.01000\tTime 0.031 (0.062)\tData 0.000 (0.009)\tLoss 0.2062 (0.1422)\tPrec@1 92.969 (95.012)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 1.9059 (1.9059)\tPrec@1 61.000 (61.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.032 (0.055)\tLoss 1.7241 (2.1315)\tPrec@1 70.000 (62.182)\tPrec@5 97.000 (95.091)\n",
            "Test: [20/100]\tTime 0.011 (0.039)\tLoss 1.6446 (2.0880)\tPrec@1 61.000 (61.857)\tPrec@5 96.000 (95.190)\n",
            "Test: [30/100]\tTime 0.026 (0.034)\tLoss 1.6613 (2.1166)\tPrec@1 64.000 (61.645)\tPrec@5 97.000 (94.806)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 1.8868 (2.1399)\tPrec@1 63.000 (61.317)\tPrec@5 97.000 (95.000)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 1.9588 (2.1204)\tPrec@1 68.000 (61.745)\tPrec@5 94.000 (94.843)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 1.7027 (2.1081)\tPrec@1 69.000 (61.754)\tPrec@5 93.000 (94.770)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 2.0525 (2.1000)\tPrec@1 59.000 (61.803)\tPrec@5 96.000 (94.845)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 2.0746 (2.0898)\tPrec@1 65.000 (61.938)\tPrec@5 97.000 (95.012)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 2.2821 (2.1020)\tPrec@1 63.000 (61.835)\tPrec@5 95.000 (95.033)\n",
            "val Results: Prec@1 61.700 Prec@5 94.940 Loss 2.11022\n",
            "val Class Accuracy: [0.966,0.901,0.631,0.677,0.797,0.623,0.793,0.456,0.273,0.053]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [87][0/97], lr: 0.01000\tTime 0.407 (0.407)\tData 0.302 (0.302)\tLoss 0.1376 (0.1376)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][10/97], lr: 0.01000\tTime 0.064 (0.105)\tData 0.000 (0.036)\tLoss 0.1333 (0.1305)\tPrec@1 95.312 (95.170)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][20/97], lr: 0.01000\tTime 0.051 (0.081)\tData 0.000 (0.021)\tLoss 0.2032 (0.1508)\tPrec@1 91.406 (94.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][30/97], lr: 0.01000\tTime 0.057 (0.073)\tData 0.001 (0.017)\tLoss 0.1821 (0.1469)\tPrec@1 92.969 (94.859)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][40/97], lr: 0.01000\tTime 0.043 (0.070)\tData 0.000 (0.014)\tLoss 0.1262 (0.1465)\tPrec@1 96.094 (94.874)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][50/97], lr: 0.01000\tTime 0.081 (0.068)\tData 0.000 (0.013)\tLoss 0.1808 (0.1440)\tPrec@1 94.531 (94.822)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][60/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.005 (0.011)\tLoss 0.1211 (0.1412)\tPrec@1 95.312 (94.877)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [87][70/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.007 (0.011)\tLoss 0.1933 (0.1437)\tPrec@1 92.188 (94.773)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [87][80/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.007 (0.010)\tLoss 0.1088 (0.1432)\tPrec@1 96.094 (94.763)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [87][90/97], lr: 0.01000\tTime 0.032 (0.062)\tData 0.000 (0.010)\tLoss 0.2209 (0.1462)\tPrec@1 92.969 (94.626)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 1.5823 (1.5823)\tPrec@1 59.000 (59.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.021 (0.057)\tLoss 1.7583 (1.6993)\tPrec@1 61.000 (62.364)\tPrec@5 94.000 (94.273)\n",
            "Test: [20/100]\tTime 0.023 (0.042)\tLoss 1.5791 (1.6571)\tPrec@1 59.000 (63.286)\tPrec@5 97.000 (94.476)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 1.7588 (1.6859)\tPrec@1 68.000 (63.097)\tPrec@5 92.000 (94.387)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 1.6311 (1.6766)\tPrec@1 64.000 (63.415)\tPrec@5 94.000 (94.659)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 1.1391 (1.6652)\tPrec@1 70.000 (63.863)\tPrec@5 96.000 (94.647)\n",
            "Test: [60/100]\tTime 0.023 (0.031)\tLoss 1.7913 (1.6554)\tPrec@1 65.000 (63.852)\tPrec@5 93.000 (94.689)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 1.8759 (1.6901)\tPrec@1 66.000 (63.577)\tPrec@5 96.000 (94.437)\n",
            "Test: [80/100]\tTime 0.015 (0.030)\tLoss 1.3583 (1.6752)\tPrec@1 72.000 (63.938)\tPrec@5 97.000 (94.543)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.3317 (1.6755)\tPrec@1 67.000 (63.571)\tPrec@5 95.000 (94.462)\n",
            "val Results: Prec@1 63.420 Prec@5 94.510 Loss 1.67818\n",
            "val Class Accuracy: [0.819,0.902,0.735,0.497,0.559,0.484,0.664,0.897,0.253,0.532]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [88][0/97], lr: 0.01000\tTime 0.417 (0.417)\tData 0.311 (0.311)\tLoss 0.0799 (0.0799)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][10/97], lr: 0.01000\tTime 0.062 (0.101)\tData 0.002 (0.038)\tLoss 0.2015 (0.1342)\tPrec@1 93.750 (95.312)\tPrec@5 99.219 (99.858)\n",
            "Epoch: [88][20/97], lr: 0.01000\tTime 0.046 (0.081)\tData 0.000 (0.022)\tLoss 0.2824 (0.1449)\tPrec@1 88.281 (94.978)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [88][30/97], lr: 0.01000\tTime 0.042 (0.074)\tData 0.000 (0.016)\tLoss 0.1647 (0.1466)\tPrec@1 94.531 (94.909)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [88][40/97], lr: 0.01000\tTime 0.072 (0.070)\tData 0.008 (0.014)\tLoss 0.3037 (0.1527)\tPrec@1 89.062 (94.684)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [88][50/97], lr: 0.01000\tTime 0.046 (0.067)\tData 0.002 (0.012)\tLoss 0.1148 (0.1561)\tPrec@1 97.656 (94.593)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [88][60/97], lr: 0.01000\tTime 0.078 (0.066)\tData 0.003 (0.011)\tLoss 0.1558 (0.1564)\tPrec@1 92.969 (94.595)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [88][70/97], lr: 0.01000\tTime 0.047 (0.065)\tData 0.011 (0.010)\tLoss 0.1828 (0.1598)\tPrec@1 94.531 (94.542)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [88][80/97], lr: 0.01000\tTime 0.065 (0.065)\tData 0.007 (0.009)\tLoss 0.0959 (0.1580)\tPrec@1 95.312 (94.541)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [88][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.0890 (0.1544)\tPrec@1 97.656 (94.694)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.319 (0.319)\tLoss 1.7049 (1.7049)\tPrec@1 63.000 (63.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.016 (0.053)\tLoss 1.2541 (1.8004)\tPrec@1 72.000 (62.727)\tPrec@5 96.000 (96.000)\n",
            "Test: [20/100]\tTime 0.038 (0.042)\tLoss 1.4088 (1.7801)\tPrec@1 66.000 (64.143)\tPrec@5 98.000 (95.762)\n",
            "Test: [30/100]\tTime 0.033 (0.036)\tLoss 1.8020 (1.8323)\tPrec@1 63.000 (63.097)\tPrec@5 94.000 (95.194)\n",
            "Test: [40/100]\tTime 0.015 (0.033)\tLoss 1.7672 (1.8373)\tPrec@1 63.000 (62.805)\tPrec@5 95.000 (95.171)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 1.4962 (1.8011)\tPrec@1 66.000 (63.608)\tPrec@5 98.000 (95.255)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.2859 (1.7916)\tPrec@1 72.000 (63.852)\tPrec@5 94.000 (95.164)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.5766 (1.7823)\tPrec@1 61.000 (63.746)\tPrec@5 96.000 (95.197)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.6052 (1.7662)\tPrec@1 66.000 (63.889)\tPrec@5 97.000 (95.222)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.7604 (1.7799)\tPrec@1 64.000 (63.692)\tPrec@5 94.000 (95.176)\n",
            "val Results: Prec@1 63.530 Prec@5 95.120 Loss 1.79464\n",
            "val Class Accuracy: [0.949,0.966,0.590,0.785,0.718,0.702,0.689,0.424,0.286,0.244]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [89][0/97], lr: 0.01000\tTime 0.459 (0.459)\tData 0.371 (0.371)\tLoss 0.1534 (0.1534)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][10/97], lr: 0.01000\tTime 0.057 (0.102)\tData 0.000 (0.038)\tLoss 0.1091 (0.1110)\tPrec@1 96.094 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][20/97], lr: 0.01000\tTime 0.057 (0.081)\tData 0.005 (0.022)\tLoss 0.1251 (0.1157)\tPrec@1 94.531 (95.610)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][30/97], lr: 0.01000\tTime 0.040 (0.074)\tData 0.000 (0.017)\tLoss 0.0803 (0.1159)\tPrec@1 97.656 (95.766)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][40/97], lr: 0.01000\tTime 0.064 (0.070)\tData 0.000 (0.014)\tLoss 0.1175 (0.1195)\tPrec@1 95.312 (95.732)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][50/97], lr: 0.01000\tTime 0.069 (0.068)\tData 0.006 (0.012)\tLoss 0.0765 (0.1216)\tPrec@1 96.094 (95.604)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [89][60/97], lr: 0.01000\tTime 0.066 (0.066)\tData 0.001 (0.010)\tLoss 0.1388 (0.1256)\tPrec@1 93.750 (95.492)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [89][70/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.000 (0.009)\tLoss 0.2796 (0.1319)\tPrec@1 91.406 (95.368)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [89][80/97], lr: 0.01000\tTime 0.066 (0.064)\tData 0.005 (0.009)\tLoss 0.0964 (0.1351)\tPrec@1 96.094 (95.158)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [89][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.1724 (0.1391)\tPrec@1 94.531 (95.046)\tPrec@5 99.219 (99.948)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 1.6688 (1.6688)\tPrec@1 60.000 (60.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.018 (0.049)\tLoss 1.6238 (1.7424)\tPrec@1 70.000 (61.000)\tPrec@5 92.000 (95.727)\n",
            "Test: [20/100]\tTime 0.046 (0.042)\tLoss 1.5458 (1.7946)\tPrec@1 62.000 (60.714)\tPrec@5 95.000 (95.190)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 2.0558 (1.8314)\tPrec@1 52.000 (59.710)\tPrec@5 93.000 (95.161)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 2.1259 (1.8192)\tPrec@1 53.000 (60.171)\tPrec@5 95.000 (95.244)\n",
            "Test: [50/100]\tTime 0.035 (0.031)\tLoss 1.9313 (1.7918)\tPrec@1 62.000 (60.451)\tPrec@5 96.000 (95.471)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 1.5079 (1.8025)\tPrec@1 60.000 (60.131)\tPrec@5 95.000 (95.328)\n",
            "Test: [70/100]\tTime 0.017 (0.030)\tLoss 1.8370 (1.7899)\tPrec@1 58.000 (60.141)\tPrec@5 98.000 (95.310)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 1.9021 (1.7744)\tPrec@1 65.000 (60.407)\tPrec@5 95.000 (95.444)\n",
            "Test: [90/100]\tTime 0.017 (0.028)\tLoss 1.4268 (1.7900)\tPrec@1 60.000 (60.066)\tPrec@5 98.000 (95.549)\n",
            "val Results: Prec@1 59.940 Prec@5 95.430 Loss 1.79738\n",
            "val Class Accuracy: [0.969,0.966,0.747,0.700,0.434,0.698,0.290,0.291,0.354,0.545]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [90][0/97], lr: 0.01000\tTime 0.473 (0.473)\tData 0.406 (0.406)\tLoss 0.2551 (0.2551)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][10/97], lr: 0.01000\tTime 0.077 (0.104)\tData 0.007 (0.043)\tLoss 0.1022 (0.1216)\tPrec@1 96.094 (95.881)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][20/97], lr: 0.01000\tTime 0.060 (0.082)\tData 0.008 (0.025)\tLoss 0.1046 (0.1209)\tPrec@1 96.875 (95.833)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][30/97], lr: 0.01000\tTime 0.050 (0.075)\tData 0.000 (0.018)\tLoss 0.0957 (0.1151)\tPrec@1 96.875 (96.069)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [90][40/97], lr: 0.01000\tTime 0.098 (0.072)\tData 0.000 (0.015)\tLoss 0.1962 (0.1226)\tPrec@1 91.406 (95.732)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [90][50/97], lr: 0.01000\tTime 0.083 (0.072)\tData 0.000 (0.013)\tLoss 0.1339 (0.1329)\tPrec@1 94.531 (95.328)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [90][60/97], lr: 0.01000\tTime 0.078 (0.075)\tData 0.000 (0.012)\tLoss 0.2064 (0.1400)\tPrec@1 92.969 (95.056)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [90][70/97], lr: 0.01000\tTime 0.094 (0.077)\tData 0.011 (0.012)\tLoss 0.2264 (0.1464)\tPrec@1 88.281 (94.806)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [90][80/97], lr: 0.01000\tTime 0.081 (0.077)\tData 0.000 (0.011)\tLoss 0.1560 (0.1487)\tPrec@1 94.531 (94.686)\tPrec@5 99.219 (99.932)\n",
            "Epoch: [90][90/97], lr: 0.01000\tTime 0.030 (0.078)\tData 0.000 (0.010)\tLoss 0.2554 (0.1508)\tPrec@1 89.844 (94.626)\tPrec@5 100.000 (99.940)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 1.6666 (1.6666)\tPrec@1 63.000 (63.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 1.9108 (1.7959)\tPrec@1 66.000 (63.455)\tPrec@5 95.000 (97.545)\n",
            "Test: [20/100]\tTime 0.033 (0.039)\tLoss 1.4428 (1.8515)\tPrec@1 65.000 (62.952)\tPrec@5 96.000 (96.381)\n",
            "Test: [30/100]\tTime 0.016 (0.035)\tLoss 1.9941 (1.8671)\tPrec@1 59.000 (62.387)\tPrec@5 95.000 (96.355)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 1.8674 (1.8465)\tPrec@1 61.000 (62.585)\tPrec@5 96.000 (96.439)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 1.7207 (1.8206)\tPrec@1 64.000 (63.137)\tPrec@5 96.000 (96.510)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 1.7155 (1.8224)\tPrec@1 67.000 (62.721)\tPrec@5 99.000 (96.574)\n",
            "Test: [70/100]\tTime 0.012 (0.030)\tLoss 2.1489 (1.8234)\tPrec@1 61.000 (62.662)\tPrec@5 95.000 (96.507)\n",
            "Test: [80/100]\tTime 0.018 (0.030)\tLoss 1.6639 (1.8127)\tPrec@1 68.000 (62.827)\tPrec@5 94.000 (96.605)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.6444 (1.8293)\tPrec@1 60.000 (62.637)\tPrec@5 97.000 (96.538)\n",
            "val Results: Prec@1 62.440 Prec@5 96.480 Loss 1.83516\n",
            "val Class Accuracy: [0.948,0.992,0.790,0.554,0.579,0.462,0.601,0.385,0.433,0.500]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [91][0/97], lr: 0.01000\tTime 0.489 (0.489)\tData 0.408 (0.408)\tLoss 0.1608 (0.1608)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][10/97], lr: 0.01000\tTime 0.068 (0.104)\tData 0.009 (0.042)\tLoss 0.0868 (0.1485)\tPrec@1 97.656 (94.744)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][20/97], lr: 0.01000\tTime 0.079 (0.083)\tData 0.000 (0.025)\tLoss 0.1404 (0.1413)\tPrec@1 95.312 (95.126)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][30/97], lr: 0.01000\tTime 0.085 (0.075)\tData 0.002 (0.018)\tLoss 0.2051 (0.1445)\tPrec@1 93.750 (95.060)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][40/97], lr: 0.01000\tTime 0.048 (0.071)\tData 0.000 (0.015)\tLoss 0.1628 (0.1424)\tPrec@1 94.531 (95.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][50/97], lr: 0.01000\tTime 0.073 (0.069)\tData 0.009 (0.013)\tLoss 0.2038 (0.1465)\tPrec@1 92.969 (94.868)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [91][60/97], lr: 0.01000\tTime 0.065 (0.067)\tData 0.004 (0.011)\tLoss 0.1498 (0.1415)\tPrec@1 93.750 (94.979)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [91][70/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.011)\tLoss 0.1272 (0.1391)\tPrec@1 95.312 (95.059)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [91][80/97], lr: 0.01000\tTime 0.053 (0.065)\tData 0.006 (0.010)\tLoss 0.1200 (0.1393)\tPrec@1 96.094 (95.100)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [91][90/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.1833 (0.1411)\tPrec@1 93.750 (95.012)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.4833 (1.4833)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.059)\tLoss 1.2958 (1.6898)\tPrec@1 69.000 (63.909)\tPrec@5 98.000 (96.455)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 1.7177 (1.6590)\tPrec@1 63.000 (65.095)\tPrec@5 96.000 (96.286)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 1.3645 (1.6680)\tPrec@1 62.000 (64.806)\tPrec@5 96.000 (96.129)\n",
            "Test: [40/100]\tTime 0.042 (0.033)\tLoss 1.2924 (1.6766)\tPrec@1 69.000 (64.707)\tPrec@5 97.000 (96.073)\n",
            "Test: [50/100]\tTime 0.016 (0.032)\tLoss 1.1251 (1.6445)\tPrec@1 70.000 (65.255)\tPrec@5 99.000 (96.176)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.3956 (1.6319)\tPrec@1 68.000 (65.311)\tPrec@5 96.000 (96.197)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 1.5919 (1.6245)\tPrec@1 67.000 (65.366)\tPrec@5 97.000 (96.155)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.3817 (1.6179)\tPrec@1 70.000 (65.407)\tPrec@5 94.000 (96.296)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.4440 (1.6403)\tPrec@1 67.000 (65.033)\tPrec@5 98.000 (96.231)\n",
            "val Results: Prec@1 64.620 Prec@5 96.110 Loss 1.65795\n",
            "val Class Accuracy: [0.938,0.969,0.685,0.643,0.864,0.383,0.790,0.596,0.288,0.306]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [92][0/97], lr: 0.01000\tTime 0.430 (0.430)\tData 0.342 (0.342)\tLoss 0.0927 (0.0927)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [92][10/97], lr: 0.01000\tTime 0.064 (0.102)\tData 0.006 (0.038)\tLoss 0.1165 (0.1186)\tPrec@1 95.312 (96.094)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [92][20/97], lr: 0.01000\tTime 0.048 (0.082)\tData 0.000 (0.023)\tLoss 0.1526 (0.1201)\tPrec@1 96.094 (95.908)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [92][30/97], lr: 0.01000\tTime 0.047 (0.073)\tData 0.005 (0.017)\tLoss 0.0814 (0.1151)\tPrec@1 96.875 (96.018)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [92][40/97], lr: 0.01000\tTime 0.057 (0.070)\tData 0.009 (0.014)\tLoss 0.0957 (0.1189)\tPrec@1 97.656 (95.922)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [92][50/97], lr: 0.01000\tTime 0.039 (0.067)\tData 0.000 (0.012)\tLoss 0.1220 (0.1159)\tPrec@1 93.750 (95.895)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [92][60/97], lr: 0.01000\tTime 0.046 (0.066)\tData 0.007 (0.012)\tLoss 0.1580 (0.1210)\tPrec@1 94.531 (95.671)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [92][70/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.005 (0.011)\tLoss 0.1528 (0.1286)\tPrec@1 93.750 (95.335)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [92][80/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.010)\tLoss 0.1866 (0.1344)\tPrec@1 93.750 (95.206)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [92][90/97], lr: 0.01000\tTime 0.024 (0.063)\tData 0.000 (0.009)\tLoss 0.2351 (0.1399)\tPrec@1 89.844 (95.038)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.331 (0.331)\tLoss 2.0590 (2.0590)\tPrec@1 55.000 (55.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.011 (0.048)\tLoss 1.8055 (2.0750)\tPrec@1 66.000 (60.273)\tPrec@5 94.000 (95.182)\n",
            "Test: [20/100]\tTime 0.025 (0.039)\tLoss 1.5969 (2.0904)\tPrec@1 64.000 (60.714)\tPrec@5 97.000 (95.048)\n",
            "Test: [30/100]\tTime 0.025 (0.035)\tLoss 2.0066 (2.0789)\tPrec@1 59.000 (60.484)\tPrec@5 93.000 (95.065)\n",
            "Test: [40/100]\tTime 0.015 (0.032)\tLoss 2.1344 (2.0847)\tPrec@1 59.000 (60.634)\tPrec@5 97.000 (95.293)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.7824 (2.0396)\tPrec@1 62.000 (61.373)\tPrec@5 97.000 (95.549)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 1.5213 (2.0430)\tPrec@1 71.000 (61.459)\tPrec@5 96.000 (95.344)\n",
            "Test: [70/100]\tTime 0.029 (0.029)\tLoss 2.3292 (2.0576)\tPrec@1 55.000 (61.296)\tPrec@5 97.000 (95.423)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 1.8860 (2.0367)\tPrec@1 65.000 (61.605)\tPrec@5 95.000 (95.556)\n",
            "Test: [90/100]\tTime 0.052 (0.028)\tLoss 1.7962 (2.0590)\tPrec@1 63.000 (61.451)\tPrec@5 96.000 (95.615)\n",
            "val Results: Prec@1 61.180 Prec@5 95.510 Loss 2.07513\n",
            "val Class Accuracy: [0.974,0.960,0.660,0.680,0.773,0.549,0.446,0.508,0.207,0.361]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [93][0/97], lr: 0.01000\tTime 0.481 (0.481)\tData 0.404 (0.404)\tLoss 0.1110 (0.1110)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][10/97], lr: 0.01000\tTime 0.062 (0.106)\tData 0.000 (0.041)\tLoss 0.1430 (0.1179)\tPrec@1 96.094 (95.952)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][20/97], lr: 0.01000\tTime 0.056 (0.082)\tData 0.005 (0.025)\tLoss 0.2310 (0.1187)\tPrec@1 91.406 (95.982)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [93][30/97], lr: 0.01000\tTime 0.065 (0.075)\tData 0.002 (0.019)\tLoss 0.1549 (0.1224)\tPrec@1 94.531 (95.716)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [93][40/97], lr: 0.01000\tTime 0.067 (0.071)\tData 0.005 (0.015)\tLoss 0.1130 (0.1205)\tPrec@1 95.312 (95.770)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [93][50/97], lr: 0.01000\tTime 0.047 (0.068)\tData 0.000 (0.013)\tLoss 0.2573 (0.1266)\tPrec@1 95.312 (95.619)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [93][60/97], lr: 0.01000\tTime 0.047 (0.066)\tData 0.007 (0.012)\tLoss 0.1120 (0.1269)\tPrec@1 95.312 (95.594)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [93][70/97], lr: 0.01000\tTime 0.059 (0.065)\tData 0.008 (0.011)\tLoss 0.2141 (0.1326)\tPrec@1 92.969 (95.368)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [93][80/97], lr: 0.01000\tTime 0.064 (0.065)\tData 0.001 (0.011)\tLoss 0.1022 (0.1338)\tPrec@1 96.875 (95.351)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [93][90/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.010)\tLoss 0.2251 (0.1358)\tPrec@1 92.969 (95.312)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 1.4335 (1.4335)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.055)\tLoss 1.5182 (1.7316)\tPrec@1 68.000 (62.091)\tPrec@5 95.000 (96.909)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 1.1535 (1.7012)\tPrec@1 71.000 (63.619)\tPrec@5 97.000 (96.810)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.6078 (1.7161)\tPrec@1 64.000 (63.774)\tPrec@5 95.000 (96.484)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 1.6683 (1.7033)\tPrec@1 63.000 (64.073)\tPrec@5 97.000 (96.659)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 1.7684 (1.6922)\tPrec@1 64.000 (64.255)\tPrec@5 97.000 (96.627)\n",
            "Test: [60/100]\tTime 0.041 (0.030)\tLoss 1.5426 (1.6919)\tPrec@1 65.000 (64.033)\tPrec@5 93.000 (96.557)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 1.7974 (1.6902)\tPrec@1 62.000 (63.944)\tPrec@5 97.000 (96.549)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.4936 (1.6706)\tPrec@1 63.000 (64.099)\tPrec@5 96.000 (96.630)\n",
            "Test: [90/100]\tTime 0.029 (0.028)\tLoss 1.4898 (1.6800)\tPrec@1 65.000 (63.967)\tPrec@5 95.000 (96.571)\n",
            "val Results: Prec@1 64.100 Prec@5 96.520 Loss 1.68278\n",
            "val Class Accuracy: [0.925,0.980,0.813,0.729,0.569,0.625,0.382,0.600,0.424,0.363]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [94][0/97], lr: 0.01000\tTime 0.444 (0.444)\tData 0.370 (0.370)\tLoss 0.1747 (0.1747)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][10/97], lr: 0.01000\tTime 0.041 (0.101)\tData 0.000 (0.037)\tLoss 0.1267 (0.1388)\tPrec@1 96.875 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][20/97], lr: 0.01000\tTime 0.047 (0.081)\tData 0.000 (0.022)\tLoss 0.0757 (0.1397)\tPrec@1 97.656 (94.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][30/97], lr: 0.01000\tTime 0.043 (0.073)\tData 0.000 (0.016)\tLoss 0.1891 (0.1438)\tPrec@1 94.531 (94.909)\tPrec@5 99.219 (99.975)\n",
            "Epoch: [94][40/97], lr: 0.01000\tTime 0.043 (0.069)\tData 0.000 (0.013)\tLoss 0.0724 (0.1355)\tPrec@1 96.875 (95.293)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [94][50/97], lr: 0.01000\tTime 0.070 (0.066)\tData 0.000 (0.011)\tLoss 0.1235 (0.1342)\tPrec@1 93.750 (95.282)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [94][60/97], lr: 0.01000\tTime 0.055 (0.066)\tData 0.007 (0.011)\tLoss 0.1593 (0.1312)\tPrec@1 93.750 (95.377)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [94][70/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.005 (0.010)\tLoss 0.1723 (0.1318)\tPrec@1 93.750 (95.357)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [94][80/97], lr: 0.01000\tTime 0.049 (0.064)\tData 0.002 (0.009)\tLoss 0.1414 (0.1346)\tPrec@1 95.312 (95.235)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [94][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.008)\tLoss 0.0969 (0.1354)\tPrec@1 96.875 (95.244)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.263 (0.263)\tLoss 1.7792 (1.7792)\tPrec@1 63.000 (63.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.030 (0.053)\tLoss 1.7917 (1.5911)\tPrec@1 65.000 (65.545)\tPrec@5 90.000 (93.545)\n",
            "Test: [20/100]\tTime 0.041 (0.040)\tLoss 1.4263 (1.5495)\tPrec@1 68.000 (66.143)\tPrec@5 98.000 (94.381)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.3978 (1.5606)\tPrec@1 67.000 (66.032)\tPrec@5 95.000 (94.355)\n",
            "Test: [40/100]\tTime 0.011 (0.033)\tLoss 1.6780 (1.5523)\tPrec@1 67.000 (66.341)\tPrec@5 96.000 (94.659)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 1.5894 (1.5594)\tPrec@1 69.000 (66.510)\tPrec@5 96.000 (94.706)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.8353 (1.5723)\tPrec@1 63.000 (66.311)\tPrec@5 93.000 (94.574)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 1.7758 (1.5755)\tPrec@1 66.000 (66.310)\tPrec@5 98.000 (94.451)\n",
            "Test: [80/100]\tTime 0.042 (0.029)\tLoss 1.1129 (1.5744)\tPrec@1 73.000 (66.346)\tPrec@5 96.000 (94.420)\n",
            "Test: [90/100]\tTime 0.047 (0.029)\tLoss 1.5495 (1.5915)\tPrec@1 71.000 (66.077)\tPrec@5 94.000 (94.341)\n",
            "val Results: Prec@1 65.960 Prec@5 94.260 Loss 1.60155\n",
            "val Class Accuracy: [0.919,0.950,0.702,0.624,0.841,0.700,0.202,0.687,0.553,0.418]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [95][0/97], lr: 0.01000\tTime 0.480 (0.480)\tData 0.380 (0.380)\tLoss 0.0883 (0.0883)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][10/97], lr: 0.01000\tTime 0.071 (0.102)\tData 0.000 (0.040)\tLoss 0.1400 (0.1227)\tPrec@1 92.188 (95.526)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][20/97], lr: 0.01000\tTime 0.071 (0.081)\tData 0.012 (0.025)\tLoss 0.1033 (0.1235)\tPrec@1 96.094 (95.573)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][30/97], lr: 0.01000\tTime 0.051 (0.073)\tData 0.005 (0.018)\tLoss 0.2196 (0.1272)\tPrec@1 92.969 (95.363)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][40/97], lr: 0.01000\tTime 0.048 (0.069)\tData 0.005 (0.015)\tLoss 0.1109 (0.1320)\tPrec@1 96.094 (95.332)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][50/97], lr: 0.01000\tTime 0.061 (0.067)\tData 0.013 (0.013)\tLoss 0.1612 (0.1312)\tPrec@1 93.750 (95.374)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][60/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.003 (0.012)\tLoss 0.1769 (0.1309)\tPrec@1 94.531 (95.261)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.003 (0.011)\tLoss 0.2623 (0.1344)\tPrec@1 89.062 (95.202)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [95][80/97], lr: 0.01000\tTime 0.057 (0.063)\tData 0.007 (0.010)\tLoss 0.1267 (0.1371)\tPrec@1 94.531 (95.042)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [95][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.010)\tLoss 0.1397 (0.1400)\tPrec@1 94.531 (94.943)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 1.9870 (1.9870)\tPrec@1 55.000 (55.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.019 (0.054)\tLoss 1.5494 (1.9195)\tPrec@1 70.000 (61.818)\tPrec@5 93.000 (95.818)\n",
            "Test: [20/100]\tTime 0.024 (0.039)\tLoss 1.7586 (1.9280)\tPrec@1 65.000 (61.571)\tPrec@5 99.000 (96.095)\n",
            "Test: [30/100]\tTime 0.013 (0.035)\tLoss 2.3673 (1.9672)\tPrec@1 58.000 (60.968)\tPrec@5 92.000 (95.774)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 1.9717 (1.9560)\tPrec@1 56.000 (61.244)\tPrec@5 99.000 (96.024)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 1.8797 (1.9288)\tPrec@1 67.000 (61.667)\tPrec@5 96.000 (96.000)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 1.5269 (1.9239)\tPrec@1 67.000 (61.639)\tPrec@5 94.000 (95.934)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 1.9811 (1.9246)\tPrec@1 61.000 (61.634)\tPrec@5 97.000 (95.845)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 1.6978 (1.9119)\tPrec@1 67.000 (61.568)\tPrec@5 95.000 (95.901)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.6576 (1.9241)\tPrec@1 65.000 (61.495)\tPrec@5 96.000 (95.780)\n",
            "val Results: Prec@1 61.410 Prec@5 95.740 Loss 1.93899\n",
            "val Class Accuracy: [0.928,0.919,0.729,0.733,0.837,0.545,0.474,0.402,0.227,0.347]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [96][0/97], lr: 0.01000\tTime 0.408 (0.408)\tData 0.318 (0.318)\tLoss 0.0781 (0.0781)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][10/97], lr: 0.01000\tTime 0.070 (0.101)\tData 0.000 (0.038)\tLoss 0.2057 (0.1413)\tPrec@1 92.969 (94.815)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][20/97], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.022)\tLoss 0.1893 (0.1457)\tPrec@1 91.406 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][30/97], lr: 0.01000\tTime 0.076 (0.074)\tData 0.010 (0.016)\tLoss 0.2911 (0.1553)\tPrec@1 91.406 (94.279)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][40/97], lr: 0.01000\tTime 0.061 (0.070)\tData 0.007 (0.013)\tLoss 0.1695 (0.1502)\tPrec@1 93.750 (94.627)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [96][50/97], lr: 0.01000\tTime 0.072 (0.068)\tData 0.014 (0.012)\tLoss 0.1747 (0.1475)\tPrec@1 94.531 (94.700)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [96][60/97], lr: 0.01000\tTime 0.063 (0.066)\tData 0.007 (0.011)\tLoss 0.1627 (0.1450)\tPrec@1 94.531 (94.890)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [96][70/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.015 (0.010)\tLoss 0.0790 (0.1394)\tPrec@1 97.656 (95.158)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [96][80/97], lr: 0.01000\tTime 0.067 (0.064)\tData 0.001 (0.009)\tLoss 0.1644 (0.1396)\tPrec@1 92.188 (95.091)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [96][90/97], lr: 0.01000\tTime 0.026 (0.063)\tData 0.000 (0.009)\tLoss 0.1210 (0.1441)\tPrec@1 94.531 (94.978)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 1.3555 (1.3555)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.026 (0.056)\tLoss 1.2330 (1.6152)\tPrec@1 71.000 (61.727)\tPrec@5 98.000 (96.545)\n",
            "Test: [20/100]\tTime 0.020 (0.038)\tLoss 1.3399 (1.6764)\tPrec@1 66.000 (62.238)\tPrec@5 98.000 (95.762)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.7755 (1.7015)\tPrec@1 63.000 (62.516)\tPrec@5 95.000 (95.387)\n",
            "Test: [40/100]\tTime 0.040 (0.034)\tLoss 1.5987 (1.6854)\tPrec@1 65.000 (62.634)\tPrec@5 92.000 (95.561)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 1.8693 (1.6540)\tPrec@1 65.000 (63.529)\tPrec@5 93.000 (95.745)\n",
            "Test: [60/100]\tTime 0.020 (0.030)\tLoss 1.4144 (1.6594)\tPrec@1 67.000 (63.459)\tPrec@5 98.000 (95.639)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 1.9839 (1.6589)\tPrec@1 57.000 (63.282)\tPrec@5 96.000 (95.648)\n",
            "Test: [80/100]\tTime 0.015 (0.029)\tLoss 1.4555 (1.6547)\tPrec@1 69.000 (63.358)\tPrec@5 97.000 (95.741)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.6292 (1.6716)\tPrec@1 63.000 (63.264)\tPrec@5 94.000 (95.659)\n",
            "val Results: Prec@1 63.300 Prec@5 95.660 Loss 1.66997\n",
            "val Class Accuracy: [0.959,0.983,0.669,0.746,0.498,0.538,0.538,0.437,0.381,0.581]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [97][0/97], lr: 0.01000\tTime 0.506 (0.506)\tData 0.429 (0.429)\tLoss 0.1145 (0.1145)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][10/97], lr: 0.01000\tTime 0.057 (0.102)\tData 0.000 (0.042)\tLoss 0.1286 (0.1400)\tPrec@1 94.531 (94.673)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][20/97], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.024)\tLoss 0.0566 (0.1275)\tPrec@1 99.219 (95.461)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][30/97], lr: 0.01000\tTime 0.059 (0.074)\tData 0.000 (0.018)\tLoss 0.1696 (0.1268)\tPrec@1 93.750 (95.413)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][40/97], lr: 0.01000\tTime 0.059 (0.070)\tData 0.007 (0.015)\tLoss 0.1177 (0.1263)\tPrec@1 95.312 (95.427)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][50/97], lr: 0.01000\tTime 0.054 (0.068)\tData 0.009 (0.013)\tLoss 0.1182 (0.1213)\tPrec@1 96.875 (95.772)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][60/97], lr: 0.01000\tTime 0.046 (0.066)\tData 0.000 (0.011)\tLoss 0.1334 (0.1212)\tPrec@1 94.531 (95.786)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [97][70/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.007 (0.010)\tLoss 0.0651 (0.1231)\tPrec@1 98.438 (95.720)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [97][80/97], lr: 0.01000\tTime 0.065 (0.064)\tData 0.000 (0.009)\tLoss 0.1250 (0.1265)\tPrec@1 96.875 (95.563)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [97][90/97], lr: 0.01000\tTime 0.027 (0.064)\tData 0.000 (0.009)\tLoss 0.0969 (0.1277)\tPrec@1 95.312 (95.527)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 2.1079 (2.1079)\tPrec@1 54.000 (54.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.027 (0.054)\tLoss 1.6418 (2.0631)\tPrec@1 65.000 (61.364)\tPrec@5 96.000 (96.455)\n",
            "Test: [20/100]\tTime 0.018 (0.039)\tLoss 1.4866 (2.0699)\tPrec@1 69.000 (61.429)\tPrec@5 96.000 (96.000)\n",
            "Test: [30/100]\tTime 0.022 (0.034)\tLoss 1.9047 (2.1003)\tPrec@1 65.000 (61.290)\tPrec@5 95.000 (95.806)\n",
            "Test: [40/100]\tTime 0.033 (0.032)\tLoss 1.7059 (2.0729)\tPrec@1 69.000 (61.220)\tPrec@5 99.000 (96.000)\n",
            "Test: [50/100]\tTime 0.014 (0.031)\tLoss 1.7301 (2.0482)\tPrec@1 66.000 (61.843)\tPrec@5 97.000 (96.078)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 1.4715 (2.0257)\tPrec@1 67.000 (61.820)\tPrec@5 95.000 (96.131)\n",
            "Test: [70/100]\tTime 0.037 (0.030)\tLoss 1.7676 (2.0247)\tPrec@1 59.000 (61.789)\tPrec@5 100.000 (96.042)\n",
            "Test: [80/100]\tTime 0.040 (0.029)\tLoss 1.5458 (1.9922)\tPrec@1 68.000 (62.123)\tPrec@5 96.000 (96.099)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 1.9296 (2.0125)\tPrec@1 64.000 (61.725)\tPrec@5 95.000 (96.022)\n",
            "val Results: Prec@1 61.540 Prec@5 96.020 Loss 2.01095\n",
            "val Class Accuracy: [0.964,0.933,0.707,0.617,0.641,0.617,0.413,0.728,0.235,0.299]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/97], lr: 0.01000\tTime 0.476 (0.476)\tData 0.404 (0.404)\tLoss 0.1256 (0.1256)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][10/97], lr: 0.01000\tTime 0.058 (0.102)\tData 0.000 (0.040)\tLoss 0.0879 (0.1174)\tPrec@1 96.094 (95.526)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][20/97], lr: 0.01000\tTime 0.045 (0.081)\tData 0.000 (0.024)\tLoss 0.1311 (0.1093)\tPrec@1 96.875 (96.057)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][30/97], lr: 0.01000\tTime 0.077 (0.075)\tData 0.010 (0.018)\tLoss 0.0807 (0.1164)\tPrec@1 96.094 (95.968)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][40/97], lr: 0.01000\tTime 0.087 (0.071)\tData 0.007 (0.015)\tLoss 0.0682 (0.1225)\tPrec@1 98.438 (95.789)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][50/97], lr: 0.01000\tTime 0.046 (0.068)\tData 0.000 (0.013)\tLoss 0.1732 (0.1306)\tPrec@1 93.750 (95.512)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][60/97], lr: 0.01000\tTime 0.074 (0.066)\tData 0.000 (0.011)\tLoss 0.1325 (0.1369)\tPrec@1 96.094 (95.377)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [98][70/97], lr: 0.01000\tTime 0.040 (0.065)\tData 0.001 (0.011)\tLoss 0.2269 (0.1391)\tPrec@1 92.969 (95.301)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [98][80/97], lr: 0.01000\tTime 0.052 (0.064)\tData 0.006 (0.010)\tLoss 0.1629 (0.1412)\tPrec@1 92.969 (95.216)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [98][90/97], lr: 0.01000\tTime 0.025 (0.063)\tData 0.000 (0.010)\tLoss 0.0922 (0.1384)\tPrec@1 98.438 (95.312)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 2.2420 (2.2420)\tPrec@1 56.000 (56.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.027 (0.056)\tLoss 1.4295 (1.9809)\tPrec@1 72.000 (62.545)\tPrec@5 98.000 (97.273)\n",
            "Test: [20/100]\tTime 0.023 (0.038)\tLoss 1.6440 (2.0245)\tPrec@1 60.000 (61.476)\tPrec@5 97.000 (96.810)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 1.7209 (2.0452)\tPrec@1 64.000 (61.290)\tPrec@5 97.000 (96.323)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 1.7357 (2.0259)\tPrec@1 61.000 (61.122)\tPrec@5 99.000 (96.415)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.5106 (1.9858)\tPrec@1 68.000 (61.824)\tPrec@5 98.000 (96.412)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.6323 (1.9686)\tPrec@1 64.000 (62.033)\tPrec@5 95.000 (96.377)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 1.8323 (1.9695)\tPrec@1 59.000 (61.944)\tPrec@5 97.000 (96.408)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.5940 (1.9455)\tPrec@1 70.000 (62.198)\tPrec@5 97.000 (96.407)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 1.7200 (1.9799)\tPrec@1 60.000 (61.670)\tPrec@5 96.000 (96.418)\n",
            "val Results: Prec@1 61.570 Prec@5 96.340 Loss 1.98258\n",
            "val Class Accuracy: [0.967,0.964,0.800,0.692,0.752,0.379,0.693,0.521,0.176,0.213]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/97], lr: 0.01000\tTime 0.462 (0.462)\tData 0.365 (0.365)\tLoss 0.1528 (0.1528)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][10/97], lr: 0.01000\tTime 0.055 (0.099)\tData 0.000 (0.036)\tLoss 0.1877 (0.1238)\tPrec@1 92.188 (95.739)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][20/97], lr: 0.01000\tTime 0.042 (0.078)\tData 0.005 (0.021)\tLoss 0.0708 (0.1291)\tPrec@1 98.438 (95.722)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [99][30/97], lr: 0.01000\tTime 0.057 (0.073)\tData 0.007 (0.016)\tLoss 0.1396 (0.1294)\tPrec@1 94.531 (95.615)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [99][40/97], lr: 0.01000\tTime 0.068 (0.069)\tData 0.006 (0.013)\tLoss 0.0558 (0.1287)\tPrec@1 97.656 (95.484)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [99][50/97], lr: 0.01000\tTime 0.048 (0.067)\tData 0.007 (0.011)\tLoss 0.0711 (0.1275)\tPrec@1 97.656 (95.374)\tPrec@5 99.219 (99.969)\n",
            "Epoch: [99][60/97], lr: 0.01000\tTime 0.051 (0.065)\tData 0.012 (0.010)\tLoss 0.1173 (0.1304)\tPrec@1 94.531 (95.197)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [99][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.007 (0.010)\tLoss 0.1581 (0.1337)\tPrec@1 94.531 (95.103)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [99][80/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.1571 (0.1331)\tPrec@1 94.531 (95.197)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [99][90/97], lr: 0.01000\tTime 0.022 (0.062)\tData 0.000 (0.008)\tLoss 0.1174 (0.1350)\tPrec@1 96.094 (95.149)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.352 (0.352)\tLoss 1.5333 (1.5333)\tPrec@1 58.000 (58.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.054)\tLoss 1.6623 (1.7013)\tPrec@1 65.000 (63.818)\tPrec@5 95.000 (96.545)\n",
            "Test: [20/100]\tTime 0.030 (0.040)\tLoss 1.8136 (1.7220)\tPrec@1 60.000 (63.476)\tPrec@5 96.000 (96.190)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 1.7579 (1.7194)\tPrec@1 60.000 (63.516)\tPrec@5 98.000 (96.129)\n",
            "Test: [40/100]\tTime 0.030 (0.034)\tLoss 1.6420 (1.7097)\tPrec@1 64.000 (63.854)\tPrec@5 96.000 (96.171)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 1.5299 (1.6849)\tPrec@1 68.000 (64.608)\tPrec@5 98.000 (96.137)\n",
            "Test: [60/100]\tTime 0.035 (0.031)\tLoss 1.5283 (1.6976)\tPrec@1 65.000 (64.410)\tPrec@5 96.000 (96.262)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 1.5042 (1.6905)\tPrec@1 67.000 (64.577)\tPrec@5 99.000 (96.310)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.4040 (1.6698)\tPrec@1 73.000 (64.889)\tPrec@5 98.000 (96.321)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.2175 (1.6821)\tPrec@1 67.000 (64.692)\tPrec@5 96.000 (96.253)\n",
            "val Results: Prec@1 64.600 Prec@5 96.250 Loss 1.68653\n",
            "val Class Accuracy: [0.949,0.958,0.794,0.806,0.746,0.319,0.670,0.472,0.151,0.595]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [100][0/97], lr: 0.01000\tTime 0.446 (0.446)\tData 0.374 (0.374)\tLoss 0.1510 (0.1510)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][10/97], lr: 0.01000\tTime 0.069 (0.103)\tData 0.012 (0.037)\tLoss 0.0963 (0.1007)\tPrec@1 95.312 (96.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][20/97], lr: 0.01000\tTime 0.063 (0.083)\tData 0.012 (0.022)\tLoss 0.0720 (0.1112)\tPrec@1 98.438 (95.796)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][30/97], lr: 0.01000\tTime 0.060 (0.074)\tData 0.000 (0.017)\tLoss 0.1145 (0.1216)\tPrec@1 96.875 (95.615)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][40/97], lr: 0.01000\tTime 0.064 (0.071)\tData 0.014 (0.014)\tLoss 0.1297 (0.1205)\tPrec@1 96.094 (95.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][50/97], lr: 0.01000\tTime 0.066 (0.068)\tData 0.005 (0.012)\tLoss 0.2328 (0.1226)\tPrec@1 92.969 (95.695)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][60/97], lr: 0.01000\tTime 0.065 (0.066)\tData 0.005 (0.011)\tLoss 0.0753 (0.1238)\tPrec@1 97.656 (95.645)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [100][70/97], lr: 0.01000\tTime 0.065 (0.065)\tData 0.005 (0.010)\tLoss 0.1318 (0.1255)\tPrec@1 94.531 (95.621)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [100][80/97], lr: 0.01000\tTime 0.068 (0.064)\tData 0.007 (0.010)\tLoss 0.1299 (0.1230)\tPrec@1 93.750 (95.660)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [100][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.0910 (0.1266)\tPrec@1 97.656 (95.544)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.348 (0.348)\tLoss 1.8719 (1.8719)\tPrec@1 60.000 (60.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.016 (0.056)\tLoss 1.9598 (1.8913)\tPrec@1 60.000 (61.455)\tPrec@5 94.000 (95.182)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 1.6745 (1.8031)\tPrec@1 63.000 (62.429)\tPrec@5 98.000 (95.667)\n",
            "Test: [30/100]\tTime 0.014 (0.036)\tLoss 1.7405 (1.8348)\tPrec@1 65.000 (62.161)\tPrec@5 97.000 (95.806)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.9551 (1.8241)\tPrec@1 60.000 (62.122)\tPrec@5 95.000 (96.000)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 1.7352 (1.8197)\tPrec@1 65.000 (62.706)\tPrec@5 97.000 (96.157)\n",
            "Test: [60/100]\tTime 0.041 (0.031)\tLoss 1.7890 (1.8066)\tPrec@1 64.000 (62.770)\tPrec@5 95.000 (96.344)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 1.8987 (1.8025)\tPrec@1 61.000 (62.662)\tPrec@5 98.000 (96.225)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.5632 (1.7888)\tPrec@1 69.000 (62.852)\tPrec@5 97.000 (96.259)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.7864 (1.8079)\tPrec@1 64.000 (62.330)\tPrec@5 95.000 (96.154)\n",
            "val Results: Prec@1 62.280 Prec@5 96.190 Loss 1.80533\n",
            "val Class Accuracy: [0.861,0.966,0.780,0.559,0.889,0.601,0.346,0.472,0.266,0.488]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [101][0/97], lr: 0.01000\tTime 0.469 (0.469)\tData 0.390 (0.390)\tLoss 0.1100 (0.1100)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][10/97], lr: 0.01000\tTime 0.072 (0.104)\tData 0.000 (0.040)\tLoss 0.2126 (0.1250)\tPrec@1 92.969 (95.810)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [101][20/97], lr: 0.01000\tTime 0.049 (0.081)\tData 0.005 (0.023)\tLoss 0.0836 (0.1213)\tPrec@1 96.875 (95.871)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [101][30/97], lr: 0.01000\tTime 0.056 (0.073)\tData 0.006 (0.017)\tLoss 0.1641 (0.1165)\tPrec@1 95.312 (95.892)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [101][40/97], lr: 0.01000\tTime 0.051 (0.069)\tData 0.002 (0.015)\tLoss 0.1074 (0.1149)\tPrec@1 95.312 (95.922)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [101][50/97], lr: 0.01000\tTime 0.072 (0.067)\tData 0.007 (0.012)\tLoss 0.1500 (0.1242)\tPrec@1 93.750 (95.496)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [101][60/97], lr: 0.01000\tTime 0.060 (0.065)\tData 0.006 (0.011)\tLoss 0.1145 (0.1296)\tPrec@1 94.531 (95.274)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [101][70/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.007 (0.010)\tLoss 0.0827 (0.1304)\tPrec@1 97.656 (95.224)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [101][80/97], lr: 0.01000\tTime 0.045 (0.063)\tData 0.001 (0.010)\tLoss 0.1669 (0.1352)\tPrec@1 94.531 (95.062)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [101][90/97], lr: 0.01000\tTime 0.038 (0.062)\tData 0.000 (0.009)\tLoss 0.2283 (0.1369)\tPrec@1 92.969 (95.029)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.273 (0.273)\tLoss 1.5263 (1.5263)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.024 (0.056)\tLoss 1.1702 (1.7503)\tPrec@1 72.000 (65.091)\tPrec@5 96.000 (96.364)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 1.6611 (1.7608)\tPrec@1 69.000 (65.857)\tPrec@5 94.000 (96.286)\n",
            "Test: [30/100]\tTime 0.021 (0.037)\tLoss 1.3243 (1.7569)\tPrec@1 63.000 (65.387)\tPrec@5 97.000 (96.129)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 1.6987 (1.7777)\tPrec@1 66.000 (65.244)\tPrec@5 94.000 (96.073)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.4220 (1.7636)\tPrec@1 72.000 (65.431)\tPrec@5 97.000 (96.098)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 1.8263 (1.7618)\tPrec@1 65.000 (65.033)\tPrec@5 93.000 (96.033)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.8187 (1.7477)\tPrec@1 64.000 (65.225)\tPrec@5 95.000 (96.014)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 1.3934 (1.7360)\tPrec@1 75.000 (65.444)\tPrec@5 98.000 (96.247)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 1.4717 (1.7476)\tPrec@1 67.000 (65.000)\tPrec@5 95.000 (96.253)\n",
            "val Results: Prec@1 64.970 Prec@5 96.210 Loss 1.75692\n",
            "val Class Accuracy: [0.904,0.994,0.781,0.441,0.885,0.545,0.828,0.446,0.429,0.244]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [102][0/97], lr: 0.01000\tTime 0.479 (0.479)\tData 0.384 (0.384)\tLoss 0.1422 (0.1422)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][10/97], lr: 0.01000\tTime 0.070 (0.104)\tData 0.000 (0.041)\tLoss 0.1209 (0.1181)\tPrec@1 94.531 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][20/97], lr: 0.01000\tTime 0.048 (0.081)\tData 0.002 (0.024)\tLoss 0.1245 (0.1194)\tPrec@1 95.312 (95.685)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][30/97], lr: 0.01000\tTime 0.061 (0.073)\tData 0.007 (0.018)\tLoss 0.0969 (0.1210)\tPrec@1 97.656 (95.590)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][40/97], lr: 0.01000\tTime 0.041 (0.069)\tData 0.000 (0.014)\tLoss 0.1345 (0.1238)\tPrec@1 93.750 (95.427)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][50/97], lr: 0.01000\tTime 0.039 (0.067)\tData 0.000 (0.013)\tLoss 0.0885 (0.1244)\tPrec@1 97.656 (95.619)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][60/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.000 (0.012)\tLoss 0.1246 (0.1251)\tPrec@1 94.531 (95.492)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.005 (0.011)\tLoss 0.1261 (0.1271)\tPrec@1 95.312 (95.379)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][80/97], lr: 0.01000\tTime 0.055 (0.063)\tData 0.001 (0.010)\tLoss 0.1316 (0.1272)\tPrec@1 96.094 (95.390)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][90/97], lr: 0.01000\tTime 0.038 (0.062)\tData 0.000 (0.009)\tLoss 0.2900 (0.1305)\tPrec@1 90.625 (95.270)\tPrec@5 99.219 (99.991)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 1.7350 (1.7350)\tPrec@1 60.000 (60.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.028 (0.055)\tLoss 1.3152 (1.9583)\tPrec@1 73.000 (63.545)\tPrec@5 98.000 (95.818)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 1.3022 (1.9164)\tPrec@1 65.000 (63.048)\tPrec@5 100.000 (96.095)\n",
            "Test: [30/100]\tTime 0.014 (0.035)\tLoss 1.5917 (1.9102)\tPrec@1 63.000 (62.161)\tPrec@5 98.000 (95.774)\n",
            "Test: [40/100]\tTime 0.034 (0.031)\tLoss 1.6737 (1.9180)\tPrec@1 61.000 (61.829)\tPrec@5 95.000 (95.805)\n",
            "Test: [50/100]\tTime 0.016 (0.030)\tLoss 2.0403 (1.9143)\tPrec@1 59.000 (62.137)\tPrec@5 95.000 (95.784)\n",
            "Test: [60/100]\tTime 0.046 (0.030)\tLoss 1.3931 (1.9024)\tPrec@1 67.000 (61.984)\tPrec@5 96.000 (95.689)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 1.7638 (1.8880)\tPrec@1 63.000 (61.958)\tPrec@5 97.000 (95.634)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.9713 (1.8905)\tPrec@1 62.000 (62.247)\tPrec@5 93.000 (95.580)\n",
            "Test: [90/100]\tTime 0.028 (0.028)\tLoss 1.8963 (1.9049)\tPrec@1 58.000 (61.901)\tPrec@5 96.000 (95.670)\n",
            "val Results: Prec@1 61.740 Prec@5 95.730 Loss 1.91694\n",
            "val Class Accuracy: [0.942,0.971,0.761,0.725,0.434,0.585,0.749,0.648,0.278,0.081]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [103][0/97], lr: 0.01000\tTime 0.527 (0.527)\tData 0.453 (0.453)\tLoss 0.0985 (0.0985)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][10/97], lr: 0.01000\tTime 0.064 (0.101)\tData 0.007 (0.046)\tLoss 0.1840 (0.1394)\tPrec@1 92.969 (95.526)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [103][20/97], lr: 0.01000\tTime 0.037 (0.080)\tData 0.000 (0.026)\tLoss 0.1252 (0.1340)\tPrec@1 96.875 (95.722)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [103][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.003 (0.020)\tLoss 0.1102 (0.1309)\tPrec@1 96.094 (95.489)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [103][40/97], lr: 0.01000\tTime 0.045 (0.070)\tData 0.002 (0.016)\tLoss 0.0751 (0.1223)\tPrec@1 96.875 (95.713)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [103][50/97], lr: 0.01000\tTime 0.050 (0.067)\tData 0.006 (0.014)\tLoss 0.0679 (0.1215)\tPrec@1 96.875 (95.695)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [103][60/97], lr: 0.01000\tTime 0.037 (0.065)\tData 0.000 (0.013)\tLoss 0.0783 (0.1226)\tPrec@1 97.656 (95.671)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [103][70/97], lr: 0.01000\tTime 0.053 (0.064)\tData 0.007 (0.012)\tLoss 0.2743 (0.1254)\tPrec@1 91.406 (95.610)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [103][80/97], lr: 0.01000\tTime 0.088 (0.063)\tData 0.006 (0.011)\tLoss 0.1260 (0.1271)\tPrec@1 94.531 (95.554)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [103][90/97], lr: 0.01000\tTime 0.039 (0.062)\tData 0.000 (0.011)\tLoss 0.1224 (0.1287)\tPrec@1 94.531 (95.493)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.4439 (1.4439)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.040 (0.056)\tLoss 1.5619 (1.5762)\tPrec@1 69.000 (66.818)\tPrec@5 96.000 (97.091)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.1959 (1.5743)\tPrec@1 70.000 (66.667)\tPrec@5 99.000 (97.286)\n",
            "Test: [30/100]\tTime 0.036 (0.035)\tLoss 1.5175 (1.5798)\tPrec@1 69.000 (67.000)\tPrec@5 95.000 (97.000)\n",
            "Test: [40/100]\tTime 0.033 (0.034)\tLoss 1.5193 (1.5950)\tPrec@1 69.000 (66.854)\tPrec@5 96.000 (97.195)\n",
            "Test: [50/100]\tTime 0.034 (0.032)\tLoss 1.3661 (1.5826)\tPrec@1 71.000 (67.196)\tPrec@5 97.000 (97.137)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 1.3778 (1.5805)\tPrec@1 68.000 (67.098)\tPrec@5 94.000 (97.000)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 2.0166 (1.5810)\tPrec@1 61.000 (67.211)\tPrec@5 99.000 (97.028)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 1.5441 (1.5557)\tPrec@1 71.000 (67.753)\tPrec@5 96.000 (97.111)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.2357 (1.5710)\tPrec@1 68.000 (67.308)\tPrec@5 98.000 (97.099)\n",
            "val Results: Prec@1 67.200 Prec@5 97.120 Loss 1.57436\n",
            "val Class Accuracy: [0.966,0.930,0.788,0.587,0.767,0.709,0.592,0.617,0.232,0.532]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [104][0/97], lr: 0.01000\tTime 0.452 (0.452)\tData 0.353 (0.353)\tLoss 0.1061 (0.1061)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [104][10/97], lr: 0.01000\tTime 0.044 (0.100)\tData 0.000 (0.034)\tLoss 0.0950 (0.1363)\tPrec@1 96.875 (95.739)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [104][20/97], lr: 0.01000\tTime 0.047 (0.078)\tData 0.000 (0.021)\tLoss 0.1047 (0.1329)\tPrec@1 96.875 (95.424)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [104][30/97], lr: 0.01000\tTime 0.058 (0.073)\tData 0.008 (0.016)\tLoss 0.0997 (0.1308)\tPrec@1 96.875 (95.439)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [104][40/97], lr: 0.01000\tTime 0.070 (0.069)\tData 0.006 (0.013)\tLoss 0.1034 (0.1324)\tPrec@1 96.875 (95.370)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [104][50/97], lr: 0.01000\tTime 0.058 (0.068)\tData 0.000 (0.011)\tLoss 0.1418 (0.1350)\tPrec@1 96.875 (95.297)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [104][60/97], lr: 0.01000\tTime 0.061 (0.066)\tData 0.005 (0.010)\tLoss 0.1566 (0.1388)\tPrec@1 95.312 (95.197)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [104][70/97], lr: 0.01000\tTime 0.061 (0.065)\tData 0.000 (0.009)\tLoss 0.1333 (0.1440)\tPrec@1 94.531 (94.949)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [104][80/97], lr: 0.01000\tTime 0.066 (0.064)\tData 0.000 (0.008)\tLoss 0.1673 (0.1432)\tPrec@1 95.312 (94.994)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [104][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.008)\tLoss 0.1805 (0.1443)\tPrec@1 93.750 (94.935)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 2.2295 (2.2295)\tPrec@1 53.000 (53.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.021 (0.056)\tLoss 1.6644 (2.1784)\tPrec@1 69.000 (58.636)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.039 (0.038)\tLoss 1.4754 (2.2367)\tPrec@1 64.000 (57.143)\tPrec@5 98.000 (97.095)\n",
            "Test: [30/100]\tTime 0.033 (0.035)\tLoss 2.1257 (2.2239)\tPrec@1 58.000 (57.516)\tPrec@5 96.000 (96.806)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 2.0615 (2.1910)\tPrec@1 58.000 (57.683)\tPrec@5 97.000 (96.854)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 2.2284 (2.1697)\tPrec@1 61.000 (58.196)\tPrec@5 95.000 (96.804)\n",
            "Test: [60/100]\tTime 0.029 (0.030)\tLoss 1.7487 (2.1783)\tPrec@1 59.000 (57.869)\tPrec@5 97.000 (96.656)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 2.1474 (2.1602)\tPrec@1 58.000 (58.056)\tPrec@5 96.000 (96.662)\n",
            "Test: [80/100]\tTime 0.021 (0.029)\tLoss 1.8796 (2.1445)\tPrec@1 61.000 (58.259)\tPrec@5 98.000 (96.704)\n",
            "Test: [90/100]\tTime 0.040 (0.029)\tLoss 2.2009 (2.1684)\tPrec@1 53.000 (57.791)\tPrec@5 96.000 (96.692)\n",
            "val Results: Prec@1 57.770 Prec@5 96.640 Loss 2.17367\n",
            "val Class Accuracy: [0.989,0.975,0.648,0.626,0.507,0.604,0.414,0.513,0.223,0.278]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [105][0/97], lr: 0.01000\tTime 0.427 (0.427)\tData 0.340 (0.340)\tLoss 0.1508 (0.1508)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][10/97], lr: 0.01000\tTime 0.050 (0.101)\tData 0.004 (0.035)\tLoss 0.1425 (0.1179)\tPrec@1 94.531 (95.526)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][20/97], lr: 0.01000\tTime 0.066 (0.082)\tData 0.006 (0.020)\tLoss 0.1390 (0.1297)\tPrec@1 96.094 (95.499)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][30/97], lr: 0.01000\tTime 0.076 (0.073)\tData 0.004 (0.014)\tLoss 0.1195 (0.1361)\tPrec@1 94.531 (95.186)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [105][40/97], lr: 0.01000\tTime 0.037 (0.069)\tData 0.000 (0.012)\tLoss 0.1128 (0.1357)\tPrec@1 96.875 (95.179)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [105][50/97], lr: 0.01000\tTime 0.041 (0.067)\tData 0.000 (0.010)\tLoss 0.1963 (0.1378)\tPrec@1 92.188 (95.067)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [105][60/97], lr: 0.01000\tTime 0.074 (0.066)\tData 0.007 (0.009)\tLoss 0.0767 (0.1333)\tPrec@1 98.438 (95.325)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [105][70/97], lr: 0.01000\tTime 0.045 (0.065)\tData 0.002 (0.009)\tLoss 0.1795 (0.1384)\tPrec@1 93.750 (95.147)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [105][80/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.003 (0.008)\tLoss 0.1409 (0.1344)\tPrec@1 95.312 (95.303)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [105][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.008)\tLoss 0.1079 (0.1314)\tPrec@1 95.312 (95.338)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.314 (0.314)\tLoss 1.6764 (1.6764)\tPrec@1 62.000 (62.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.028 (0.052)\tLoss 1.6097 (1.5307)\tPrec@1 69.000 (66.545)\tPrec@5 94.000 (96.727)\n",
            "Test: [20/100]\tTime 0.017 (0.041)\tLoss 1.2255 (1.5033)\tPrec@1 70.000 (66.095)\tPrec@5 96.000 (96.667)\n",
            "Test: [30/100]\tTime 0.040 (0.036)\tLoss 1.4472 (1.5150)\tPrec@1 68.000 (66.226)\tPrec@5 96.000 (96.645)\n",
            "Test: [40/100]\tTime 0.014 (0.032)\tLoss 1.3506 (1.4929)\tPrec@1 69.000 (66.561)\tPrec@5 98.000 (96.732)\n",
            "Test: [50/100]\tTime 0.033 (0.031)\tLoss 1.5439 (1.4915)\tPrec@1 70.000 (67.314)\tPrec@5 96.000 (96.725)\n",
            "Test: [60/100]\tTime 0.011 (0.030)\tLoss 1.4008 (1.5113)\tPrec@1 70.000 (66.885)\tPrec@5 97.000 (96.557)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 1.6497 (1.5136)\tPrec@1 66.000 (66.845)\tPrec@5 98.000 (96.577)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.1935 (1.5011)\tPrec@1 74.000 (66.975)\tPrec@5 97.000 (96.654)\n",
            "Test: [90/100]\tTime 0.014 (0.029)\tLoss 0.9084 (1.5147)\tPrec@1 75.000 (66.725)\tPrec@5 97.000 (96.714)\n",
            "val Results: Prec@1 66.590 Prec@5 96.590 Loss 1.52348\n",
            "val Class Accuracy: [0.956,0.934,0.812,0.615,0.805,0.541,0.486,0.411,0.313,0.786]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [106][0/97], lr: 0.01000\tTime 0.479 (0.479)\tData 0.390 (0.390)\tLoss 0.0693 (0.0693)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][10/97], lr: 0.01000\tTime 0.051 (0.102)\tData 0.007 (0.039)\tLoss 0.0500 (0.1133)\tPrec@1 99.219 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][20/97], lr: 0.01000\tTime 0.046 (0.081)\tData 0.000 (0.022)\tLoss 0.1665 (0.1166)\tPrec@1 93.750 (95.685)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][30/97], lr: 0.01000\tTime 0.064 (0.073)\tData 0.010 (0.017)\tLoss 0.1412 (0.1151)\tPrec@1 96.875 (95.766)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][40/97], lr: 0.01000\tTime 0.042 (0.069)\tData 0.000 (0.014)\tLoss 0.1638 (0.1251)\tPrec@1 92.969 (95.446)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [106][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.006 (0.012)\tLoss 0.1058 (0.1268)\tPrec@1 96.875 (95.466)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [106][60/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.007 (0.011)\tLoss 0.0685 (0.1247)\tPrec@1 96.875 (95.556)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [106][70/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.007 (0.010)\tLoss 0.1487 (0.1253)\tPrec@1 92.969 (95.489)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [106][80/97], lr: 0.01000\tTime 0.055 (0.064)\tData 0.006 (0.010)\tLoss 0.1075 (0.1269)\tPrec@1 95.312 (95.476)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [106][90/97], lr: 0.01000\tTime 0.045 (0.062)\tData 0.000 (0.009)\tLoss 0.0903 (0.1256)\tPrec@1 96.875 (95.544)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.8234 (1.8234)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.054)\tLoss 1.4079 (1.7244)\tPrec@1 72.000 (66.727)\tPrec@5 95.000 (96.182)\n",
            "Test: [20/100]\tTime 0.011 (0.040)\tLoss 1.7505 (1.7227)\tPrec@1 62.000 (66.048)\tPrec@5 98.000 (96.333)\n",
            "Test: [30/100]\tTime 0.044 (0.036)\tLoss 1.6629 (1.7125)\tPrec@1 69.000 (65.742)\tPrec@5 95.000 (96.323)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 1.4867 (1.6869)\tPrec@1 69.000 (65.805)\tPrec@5 96.000 (96.463)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.4571 (1.6684)\tPrec@1 68.000 (66.118)\tPrec@5 97.000 (96.412)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 1.4287 (1.6556)\tPrec@1 68.000 (66.131)\tPrec@5 95.000 (96.410)\n",
            "Test: [70/100]\tTime 0.035 (0.030)\tLoss 1.7195 (1.6565)\tPrec@1 65.000 (66.197)\tPrec@5 96.000 (96.507)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.3483 (1.6444)\tPrec@1 73.000 (66.432)\tPrec@5 98.000 (96.593)\n",
            "Test: [90/100]\tTime 0.013 (0.029)\tLoss 1.4136 (1.6516)\tPrec@1 69.000 (66.231)\tPrec@5 98.000 (96.593)\n",
            "val Results: Prec@1 66.110 Prec@5 96.540 Loss 1.65604\n",
            "val Class Accuracy: [0.909,0.969,0.734,0.793,0.860,0.392,0.577,0.629,0.239,0.509]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [107][0/97], lr: 0.01000\tTime 0.474 (0.474)\tData 0.385 (0.385)\tLoss 0.1095 (0.1095)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][10/97], lr: 0.01000\tTime 0.057 (0.102)\tData 0.014 (0.040)\tLoss 0.1679 (0.1014)\tPrec@1 94.531 (96.662)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.023)\tLoss 0.1381 (0.0988)\tPrec@1 94.531 (96.875)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [107][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.000 (0.017)\tLoss 0.0931 (0.1039)\tPrec@1 96.875 (96.522)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [107][40/97], lr: 0.01000\tTime 0.085 (0.070)\tData 0.007 (0.014)\tLoss 0.1499 (0.1060)\tPrec@1 94.531 (96.532)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [107][50/97], lr: 0.01000\tTime 0.072 (0.068)\tData 0.001 (0.012)\tLoss 0.0892 (0.1099)\tPrec@1 96.094 (96.278)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [107][60/97], lr: 0.01000\tTime 0.063 (0.066)\tData 0.016 (0.011)\tLoss 0.1295 (0.1150)\tPrec@1 95.312 (96.107)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [107][70/97], lr: 0.01000\tTime 0.053 (0.065)\tData 0.005 (0.010)\tLoss 0.1238 (0.1186)\tPrec@1 94.531 (95.951)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [107][80/97], lr: 0.01000\tTime 0.066 (0.063)\tData 0.000 (0.009)\tLoss 0.1073 (0.1227)\tPrec@1 96.875 (95.785)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [107][90/97], lr: 0.01000\tTime 0.038 (0.063)\tData 0.000 (0.008)\tLoss 0.1207 (0.1266)\tPrec@1 96.094 (95.699)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 2.0508 (2.0508)\tPrec@1 59.000 (59.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.017 (0.056)\tLoss 1.9452 (2.0742)\tPrec@1 66.000 (62.000)\tPrec@5 94.000 (96.455)\n",
            "Test: [20/100]\tTime 0.010 (0.042)\tLoss 1.6218 (2.1273)\tPrec@1 62.000 (61.238)\tPrec@5 97.000 (96.429)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 1.9284 (2.1344)\tPrec@1 63.000 (60.806)\tPrec@5 96.000 (96.032)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 1.9632 (2.1060)\tPrec@1 64.000 (60.927)\tPrec@5 97.000 (96.122)\n",
            "Test: [50/100]\tTime 0.037 (0.032)\tLoss 2.1149 (2.1095)\tPrec@1 61.000 (61.255)\tPrec@5 95.000 (96.118)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 1.6340 (2.1030)\tPrec@1 67.000 (61.033)\tPrec@5 95.000 (96.098)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 2.2602 (2.1086)\tPrec@1 62.000 (60.915)\tPrec@5 99.000 (96.113)\n",
            "Test: [80/100]\tTime 0.023 (0.030)\tLoss 1.3997 (2.0801)\tPrec@1 67.000 (61.012)\tPrec@5 97.000 (96.247)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.7542 (2.1142)\tPrec@1 64.000 (60.615)\tPrec@5 97.000 (96.275)\n",
            "val Results: Prec@1 60.680 Prec@5 96.290 Loss 2.11006\n",
            "val Class Accuracy: [0.968,0.914,0.855,0.403,0.655,0.613,0.487,0.529,0.171,0.473]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [108][0/97], lr: 0.01000\tTime 0.486 (0.486)\tData 0.395 (0.395)\tLoss 0.0972 (0.0972)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][10/97], lr: 0.01000\tTime 0.055 (0.102)\tData 0.007 (0.040)\tLoss 0.1108 (0.1289)\tPrec@1 94.531 (95.526)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][20/97], lr: 0.01000\tTime 0.043 (0.080)\tData 0.000 (0.022)\tLoss 0.0934 (0.1345)\tPrec@1 96.094 (95.275)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [108][30/97], lr: 0.01000\tTime 0.059 (0.073)\tData 0.010 (0.018)\tLoss 0.1109 (0.1341)\tPrec@1 96.094 (95.086)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [108][40/97], lr: 0.01000\tTime 0.054 (0.069)\tData 0.000 (0.014)\tLoss 0.1258 (0.1324)\tPrec@1 93.750 (95.122)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [108][50/97], lr: 0.01000\tTime 0.043 (0.066)\tData 0.000 (0.012)\tLoss 0.0848 (0.1321)\tPrec@1 96.875 (95.221)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [108][60/97], lr: 0.01000\tTime 0.059 (0.065)\tData 0.000 (0.011)\tLoss 0.0782 (0.1302)\tPrec@1 96.094 (95.377)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [108][70/97], lr: 0.01000\tTime 0.065 (0.064)\tData 0.000 (0.010)\tLoss 0.1816 (0.1346)\tPrec@1 92.188 (95.213)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [108][80/97], lr: 0.01000\tTime 0.075 (0.064)\tData 0.007 (0.009)\tLoss 0.0761 (0.1375)\tPrec@1 97.656 (95.120)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [108][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 0.0626 (0.1403)\tPrec@1 96.875 (95.038)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.9130 (1.9130)\tPrec@1 61.000 (61.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.038 (0.056)\tLoss 1.6164 (2.0839)\tPrec@1 67.000 (61.364)\tPrec@5 97.000 (96.455)\n",
            "Test: [20/100]\tTime 0.036 (0.040)\tLoss 1.7505 (2.0252)\tPrec@1 61.000 (61.762)\tPrec@5 97.000 (96.429)\n",
            "Test: [30/100]\tTime 0.028 (0.035)\tLoss 2.3885 (2.1043)\tPrec@1 59.000 (61.161)\tPrec@5 97.000 (96.484)\n",
            "Test: [40/100]\tTime 0.028 (0.032)\tLoss 1.8589 (2.1082)\tPrec@1 64.000 (60.902)\tPrec@5 98.000 (96.732)\n",
            "Test: [50/100]\tTime 0.010 (0.030)\tLoss 1.7696 (2.0623)\tPrec@1 59.000 (61.627)\tPrec@5 96.000 (96.765)\n",
            "Test: [60/100]\tTime 0.029 (0.029)\tLoss 1.8414 (2.0658)\tPrec@1 63.000 (61.574)\tPrec@5 97.000 (96.754)\n",
            "Test: [70/100]\tTime 0.032 (0.029)\tLoss 1.9243 (2.0518)\tPrec@1 55.000 (61.451)\tPrec@5 97.000 (96.690)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 2.1004 (2.0608)\tPrec@1 67.000 (61.506)\tPrec@5 96.000 (96.704)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 2.1890 (2.0776)\tPrec@1 61.000 (61.253)\tPrec@5 95.000 (96.681)\n",
            "val Results: Prec@1 61.090 Prec@5 96.640 Loss 2.08140\n",
            "val Class Accuracy: [0.862,0.896,0.430,0.779,0.762,0.688,0.459,0.351,0.320,0.562]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [109][0/97], lr: 0.01000\tTime 0.441 (0.441)\tData 0.336 (0.336)\tLoss 0.1622 (0.1622)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][10/97], lr: 0.01000\tTime 0.061 (0.104)\tData 0.005 (0.033)\tLoss 0.1073 (0.1251)\tPrec@1 96.875 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][20/97], lr: 0.01000\tTime 0.042 (0.081)\tData 0.000 (0.020)\tLoss 0.0860 (0.1258)\tPrec@1 96.875 (95.647)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][30/97], lr: 0.01000\tTime 0.058 (0.074)\tData 0.000 (0.015)\tLoss 0.1088 (0.1209)\tPrec@1 94.531 (95.917)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][40/97], lr: 0.01000\tTime 0.059 (0.070)\tData 0.005 (0.013)\tLoss 0.0738 (0.1173)\tPrec@1 98.438 (95.941)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][50/97], lr: 0.01000\tTime 0.055 (0.068)\tData 0.008 (0.012)\tLoss 0.1198 (0.1141)\tPrec@1 95.312 (96.032)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][60/97], lr: 0.01000\tTime 0.083 (0.067)\tData 0.007 (0.011)\tLoss 0.1027 (0.1141)\tPrec@1 96.875 (96.030)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][70/97], lr: 0.01000\tTime 0.093 (0.070)\tData 0.007 (0.010)\tLoss 0.0991 (0.1172)\tPrec@1 96.875 (95.885)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [109][80/97], lr: 0.01000\tTime 0.058 (0.072)\tData 0.000 (0.009)\tLoss 0.1021 (0.1176)\tPrec@1 96.875 (95.901)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [109][90/97], lr: 0.01000\tTime 0.065 (0.073)\tData 0.000 (0.008)\tLoss 0.2042 (0.1217)\tPrec@1 92.188 (95.742)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.558 (0.558)\tLoss 1.6755 (1.6755)\tPrec@1 65.000 (65.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.020 (0.073)\tLoss 1.3515 (1.6365)\tPrec@1 73.000 (66.273)\tPrec@5 97.000 (96.182)\n",
            "Test: [20/100]\tTime 0.033 (0.053)\tLoss 1.3460 (1.6338)\tPrec@1 70.000 (65.476)\tPrec@5 98.000 (95.714)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 1.7729 (1.6625)\tPrec@1 64.000 (65.161)\tPrec@5 96.000 (95.548)\n",
            "Test: [40/100]\tTime 0.021 (0.037)\tLoss 1.4656 (1.6376)\tPrec@1 65.000 (65.634)\tPrec@5 97.000 (95.537)\n",
            "Test: [50/100]\tTime 0.023 (0.035)\tLoss 1.4840 (1.6034)\tPrec@1 69.000 (66.255)\tPrec@5 96.000 (95.588)\n",
            "Test: [60/100]\tTime 0.033 (0.034)\tLoss 1.5628 (1.6103)\tPrec@1 72.000 (66.082)\tPrec@5 92.000 (95.410)\n",
            "Test: [70/100]\tTime 0.026 (0.033)\tLoss 1.8924 (1.6006)\tPrec@1 63.000 (66.239)\tPrec@5 95.000 (95.493)\n",
            "Test: [80/100]\tTime 0.038 (0.032)\tLoss 1.1947 (1.5764)\tPrec@1 76.000 (66.605)\tPrec@5 95.000 (95.642)\n",
            "Test: [90/100]\tTime 0.045 (0.032)\tLoss 1.3564 (1.5903)\tPrec@1 71.000 (66.495)\tPrec@5 97.000 (95.495)\n",
            "val Results: Prec@1 66.290 Prec@5 95.410 Loss 1.59796\n",
            "val Class Accuracy: [0.928,0.959,0.818,0.734,0.659,0.476,0.751,0.320,0.261,0.723]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [110][0/97], lr: 0.01000\tTime 0.467 (0.467)\tData 0.380 (0.380)\tLoss 0.1054 (0.1054)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][10/97], lr: 0.01000\tTime 0.053 (0.101)\tData 0.008 (0.040)\tLoss 0.0717 (0.1067)\tPrec@1 97.656 (96.165)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [110][20/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.005 (0.024)\tLoss 0.1137 (0.1148)\tPrec@1 95.312 (95.945)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [110][30/97], lr: 0.01000\tTime 0.057 (0.074)\tData 0.000 (0.018)\tLoss 0.1249 (0.1197)\tPrec@1 94.531 (95.817)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [110][40/97], lr: 0.01000\tTime 0.033 (0.069)\tData 0.000 (0.014)\tLoss 0.0901 (0.1225)\tPrec@1 97.656 (95.732)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [110][50/97], lr: 0.01000\tTime 0.039 (0.067)\tData 0.000 (0.013)\tLoss 0.1161 (0.1213)\tPrec@1 96.094 (95.757)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [110][60/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.007 (0.011)\tLoss 0.0956 (0.1234)\tPrec@1 98.438 (95.774)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [110][70/97], lr: 0.01000\tTime 0.066 (0.065)\tData 0.012 (0.010)\tLoss 0.1256 (0.1240)\tPrec@1 95.312 (95.709)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [110][80/97], lr: 0.01000\tTime 0.067 (0.064)\tData 0.001 (0.010)\tLoss 0.1168 (0.1215)\tPrec@1 95.312 (95.775)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [110][90/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.0677 (0.1240)\tPrec@1 98.438 (95.673)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.310 (0.310)\tLoss 1.9212 (1.9212)\tPrec@1 56.000 (56.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.034 (0.051)\tLoss 1.7925 (2.0330)\tPrec@1 71.000 (62.455)\tPrec@5 93.000 (95.818)\n",
            "Test: [20/100]\tTime 0.046 (0.040)\tLoss 1.5173 (2.0393)\tPrec@1 66.000 (61.000)\tPrec@5 98.000 (95.714)\n",
            "Test: [30/100]\tTime 0.018 (0.033)\tLoss 1.9260 (2.0479)\tPrec@1 60.000 (61.000)\tPrec@5 96.000 (95.613)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 1.5768 (2.0350)\tPrec@1 62.000 (61.000)\tPrec@5 96.000 (95.683)\n",
            "Test: [50/100]\tTime 0.032 (0.031)\tLoss 1.8636 (2.0240)\tPrec@1 67.000 (61.275)\tPrec@5 97.000 (95.804)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.7972 (2.0122)\tPrec@1 65.000 (61.459)\tPrec@5 94.000 (95.738)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 2.4112 (2.0060)\tPrec@1 59.000 (61.535)\tPrec@5 96.000 (95.690)\n",
            "Test: [80/100]\tTime 0.028 (0.028)\tLoss 1.4488 (1.9890)\tPrec@1 64.000 (61.852)\tPrec@5 96.000 (95.815)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 1.7238 (2.0142)\tPrec@1 61.000 (61.396)\tPrec@5 97.000 (95.758)\n",
            "val Results: Prec@1 61.290 Prec@5 95.760 Loss 2.02056\n",
            "val Class Accuracy: [0.968,0.964,0.797,0.376,0.737,0.765,0.586,0.487,0.270,0.179]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [111][0/97], lr: 0.01000\tTime 0.403 (0.403)\tData 0.314 (0.314)\tLoss 0.0874 (0.0874)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][10/97], lr: 0.01000\tTime 0.041 (0.102)\tData 0.000 (0.037)\tLoss 0.1119 (0.1425)\tPrec@1 94.531 (94.673)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [111][20/97], lr: 0.01000\tTime 0.064 (0.082)\tData 0.002 (0.023)\tLoss 0.1059 (0.1303)\tPrec@1 96.094 (95.238)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [111][30/97], lr: 0.01000\tTime 0.057 (0.074)\tData 0.000 (0.016)\tLoss 0.2626 (0.1290)\tPrec@1 91.406 (95.237)\tPrec@5 99.219 (99.950)\n",
            "Epoch: [111][40/97], lr: 0.01000\tTime 0.045 (0.070)\tData 0.006 (0.014)\tLoss 0.0525 (0.1282)\tPrec@1 99.219 (95.465)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [111][50/97], lr: 0.01000\tTime 0.055 (0.067)\tData 0.008 (0.012)\tLoss 0.1055 (0.1288)\tPrec@1 97.656 (95.527)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [111][60/97], lr: 0.01000\tTime 0.066 (0.066)\tData 0.009 (0.011)\tLoss 0.1052 (0.1263)\tPrec@1 96.875 (95.633)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [111][70/97], lr: 0.01000\tTime 0.043 (0.064)\tData 0.000 (0.010)\tLoss 0.1659 (0.1262)\tPrec@1 91.406 (95.665)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [111][80/97], lr: 0.01000\tTime 0.086 (0.063)\tData 0.004 (0.010)\tLoss 0.0661 (0.1236)\tPrec@1 98.438 (95.747)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [111][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.009)\tLoss 0.1090 (0.1234)\tPrec@1 96.875 (95.776)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 1.6973 (1.6973)\tPrec@1 65.000 (65.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.010 (0.054)\tLoss 1.1928 (1.8043)\tPrec@1 75.000 (65.182)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 1.6074 (1.8399)\tPrec@1 66.000 (64.476)\tPrec@5 98.000 (96.714)\n",
            "Test: [30/100]\tTime 0.030 (0.036)\tLoss 1.6299 (1.8643)\tPrec@1 66.000 (64.097)\tPrec@5 95.000 (96.516)\n",
            "Test: [40/100]\tTime 0.045 (0.034)\tLoss 1.9780 (1.8673)\tPrec@1 60.000 (63.829)\tPrec@5 97.000 (96.488)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 1.8403 (1.8397)\tPrec@1 64.000 (64.098)\tPrec@5 98.000 (96.588)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 1.3943 (1.8266)\tPrec@1 65.000 (64.115)\tPrec@5 94.000 (96.525)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 2.0014 (1.8155)\tPrec@1 64.000 (64.197)\tPrec@5 98.000 (96.535)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.5356 (1.8055)\tPrec@1 66.000 (64.222)\tPrec@5 95.000 (96.654)\n",
            "Test: [90/100]\tTime 0.039 (0.028)\tLoss 1.6368 (1.8234)\tPrec@1 67.000 (64.088)\tPrec@5 98.000 (96.681)\n",
            "val Results: Prec@1 64.000 Prec@5 96.550 Loss 1.83050\n",
            "val Class Accuracy: [0.976,0.955,0.779,0.763,0.766,0.397,0.671,0.394,0.414,0.285]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [112][0/97], lr: 0.01000\tTime 0.368 (0.368)\tData 0.302 (0.302)\tLoss 0.1016 (0.1016)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][10/97], lr: 0.01000\tTime 0.064 (0.103)\tData 0.010 (0.037)\tLoss 0.0482 (0.1009)\tPrec@1 99.219 (96.449)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][20/97], lr: 0.01000\tTime 0.048 (0.080)\tData 0.004 (0.022)\tLoss 0.0956 (0.0976)\tPrec@1 96.094 (96.429)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.010 (0.016)\tLoss 0.0995 (0.0959)\tPrec@1 96.094 (96.598)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][40/97], lr: 0.01000\tTime 0.061 (0.070)\tData 0.011 (0.014)\tLoss 0.0813 (0.0974)\tPrec@1 97.656 (96.665)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][50/97], lr: 0.01000\tTime 0.059 (0.067)\tData 0.007 (0.013)\tLoss 0.0834 (0.0979)\tPrec@1 96.094 (96.584)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][60/97], lr: 0.01000\tTime 0.050 (0.065)\tData 0.007 (0.012)\tLoss 0.1311 (0.0989)\tPrec@1 95.312 (96.606)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][70/97], lr: 0.01000\tTime 0.043 (0.064)\tData 0.000 (0.010)\tLoss 0.1256 (0.1016)\tPrec@1 95.312 (96.468)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][80/97], lr: 0.01000\tTime 0.044 (0.063)\tData 0.007 (0.010)\tLoss 0.1331 (0.1037)\tPrec@1 94.531 (96.373)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][90/97], lr: 0.01000\tTime 0.035 (0.062)\tData 0.000 (0.009)\tLoss 0.1071 (0.1104)\tPrec@1 98.438 (96.180)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.4010 (1.4010)\tPrec@1 70.000 (70.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 1.2940 (1.6303)\tPrec@1 72.000 (66.727)\tPrec@5 96.000 (97.091)\n",
            "Test: [20/100]\tTime 0.033 (0.041)\tLoss 1.4132 (1.7024)\tPrec@1 67.000 (65.476)\tPrec@5 95.000 (96.048)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 1.9331 (1.7187)\tPrec@1 63.000 (65.645)\tPrec@5 96.000 (95.613)\n",
            "Test: [40/100]\tTime 0.040 (0.033)\tLoss 1.8000 (1.7164)\tPrec@1 67.000 (65.878)\tPrec@5 95.000 (95.683)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 1.5142 (1.7279)\tPrec@1 69.000 (66.235)\tPrec@5 96.000 (95.745)\n",
            "Test: [60/100]\tTime 0.035 (0.030)\tLoss 1.4824 (1.7436)\tPrec@1 66.000 (65.852)\tPrec@5 97.000 (95.639)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 2.1662 (1.7199)\tPrec@1 61.000 (66.085)\tPrec@5 95.000 (95.775)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 1.1879 (1.6990)\tPrec@1 76.000 (66.346)\tPrec@5 98.000 (95.901)\n",
            "Test: [90/100]\tTime 0.018 (0.027)\tLoss 1.3560 (1.7120)\tPrec@1 68.000 (66.077)\tPrec@5 97.000 (95.890)\n",
            "val Results: Prec@1 65.900 Prec@5 95.840 Loss 1.70971\n",
            "val Class Accuracy: [0.978,0.930,0.680,0.570,0.687,0.579,0.561,0.344,0.565,0.696]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [113][0/97], lr: 0.01000\tTime 0.481 (0.481)\tData 0.398 (0.398)\tLoss 0.1800 (0.1800)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][10/97], lr: 0.01000\tTime 0.039 (0.100)\tData 0.000 (0.039)\tLoss 0.0929 (0.1092)\tPrec@1 98.438 (96.733)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [113][20/97], lr: 0.01000\tTime 0.065 (0.080)\tData 0.001 (0.022)\tLoss 0.1057 (0.1175)\tPrec@1 97.656 (96.391)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [113][30/97], lr: 0.01000\tTime 0.053 (0.073)\tData 0.005 (0.017)\tLoss 0.1343 (0.1153)\tPrec@1 96.094 (96.472)\tPrec@5 99.219 (99.924)\n",
            "Epoch: [113][40/97], lr: 0.01000\tTime 0.047 (0.068)\tData 0.000 (0.014)\tLoss 0.1023 (0.1200)\tPrec@1 95.312 (96.265)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [113][50/97], lr: 0.01000\tTime 0.054 (0.066)\tData 0.005 (0.012)\tLoss 0.0701 (0.1198)\tPrec@1 98.438 (96.232)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [113][60/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.002 (0.011)\tLoss 0.2128 (0.1222)\tPrec@1 92.969 (96.145)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [113][70/97], lr: 0.01000\tTime 0.038 (0.064)\tData 0.000 (0.010)\tLoss 0.0839 (0.1253)\tPrec@1 96.094 (96.028)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [113][80/97], lr: 0.01000\tTime 0.069 (0.064)\tData 0.006 (0.009)\tLoss 0.1313 (0.1245)\tPrec@1 95.312 (96.036)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [113][90/97], lr: 0.01000\tTime 0.031 (0.062)\tData 0.000 (0.009)\tLoss 0.1304 (0.1234)\tPrec@1 96.094 (96.068)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 1.7306 (1.7306)\tPrec@1 64.000 (64.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.042 (0.054)\tLoss 1.3369 (1.7351)\tPrec@1 74.000 (64.364)\tPrec@5 98.000 (97.182)\n",
            "Test: [20/100]\tTime 0.022 (0.040)\tLoss 1.6019 (1.7215)\tPrec@1 66.000 (64.810)\tPrec@5 96.000 (96.476)\n",
            "Test: [30/100]\tTime 0.048 (0.036)\tLoss 1.9325 (1.7532)\tPrec@1 63.000 (64.065)\tPrec@5 97.000 (96.516)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 1.4923 (1.7281)\tPrec@1 60.000 (64.390)\tPrec@5 96.000 (96.537)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.7926 (1.7285)\tPrec@1 64.000 (64.686)\tPrec@5 97.000 (96.412)\n",
            "Test: [60/100]\tTime 0.044 (0.030)\tLoss 1.5219 (1.7283)\tPrec@1 71.000 (64.541)\tPrec@5 94.000 (96.377)\n",
            "Test: [70/100]\tTime 0.013 (0.029)\tLoss 1.7762 (1.7188)\tPrec@1 62.000 (64.648)\tPrec@5 98.000 (96.324)\n",
            "Test: [80/100]\tTime 0.021 (0.028)\tLoss 1.4048 (1.7008)\tPrec@1 70.000 (65.000)\tPrec@5 97.000 (96.420)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.4043 (1.7134)\tPrec@1 65.000 (64.791)\tPrec@5 96.000 (96.363)\n",
            "val Results: Prec@1 64.650 Prec@5 96.380 Loss 1.71659\n",
            "val Class Accuracy: [0.945,0.953,0.683,0.850,0.763,0.502,0.555,0.365,0.268,0.581]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [114][0/97], lr: 0.01000\tTime 0.423 (0.423)\tData 0.342 (0.342)\tLoss 0.0851 (0.0851)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][10/97], lr: 0.01000\tTime 0.041 (0.099)\tData 0.000 (0.037)\tLoss 0.1376 (0.1382)\tPrec@1 94.531 (95.526)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [114][20/97], lr: 0.01000\tTime 0.041 (0.080)\tData 0.000 (0.022)\tLoss 0.0977 (0.1377)\tPrec@1 97.656 (95.685)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [114][30/97], lr: 0.01000\tTime 0.066 (0.072)\tData 0.009 (0.016)\tLoss 0.1461 (0.1362)\tPrec@1 94.531 (95.665)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [114][40/97], lr: 0.01000\tTime 0.053 (0.069)\tData 0.000 (0.013)\tLoss 0.1677 (0.1333)\tPrec@1 94.531 (95.732)\tPrec@5 99.219 (99.924)\n",
            "Epoch: [114][50/97], lr: 0.01000\tTime 0.055 (0.067)\tData 0.000 (0.012)\tLoss 0.0812 (0.1314)\tPrec@1 97.656 (95.726)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [114][60/97], lr: 0.01000\tTime 0.068 (0.065)\tData 0.006 (0.011)\tLoss 0.1481 (0.1322)\tPrec@1 95.312 (95.569)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [114][70/97], lr: 0.01000\tTime 0.044 (0.064)\tData 0.000 (0.010)\tLoss 0.0808 (0.1305)\tPrec@1 96.875 (95.555)\tPrec@5 100.000 (99.934)\n",
            "Epoch: [114][80/97], lr: 0.01000\tTime 0.052 (0.063)\tData 0.006 (0.009)\tLoss 0.1255 (0.1284)\tPrec@1 94.531 (95.611)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [114][90/97], lr: 0.01000\tTime 0.029 (0.062)\tData 0.000 (0.009)\tLoss 0.1578 (0.1286)\tPrec@1 91.406 (95.570)\tPrec@5 100.000 (99.940)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 1.7689 (1.7689)\tPrec@1 63.000 (63.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.032 (0.055)\tLoss 1.1304 (1.7305)\tPrec@1 74.000 (64.091)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.030 (0.039)\tLoss 1.2749 (1.7441)\tPrec@1 72.000 (63.952)\tPrec@5 96.000 (96.048)\n",
            "Test: [30/100]\tTime 0.020 (0.035)\tLoss 1.6107 (1.7717)\tPrec@1 65.000 (63.516)\tPrec@5 97.000 (96.226)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 1.6983 (1.7712)\tPrec@1 68.000 (63.732)\tPrec@5 97.000 (96.220)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 1.7094 (1.7323)\tPrec@1 66.000 (64.412)\tPrec@5 99.000 (96.333)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 1.5652 (1.7406)\tPrec@1 67.000 (64.295)\tPrec@5 96.000 (96.246)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 1.7659 (1.7138)\tPrec@1 66.000 (64.352)\tPrec@5 95.000 (96.197)\n",
            "Test: [80/100]\tTime 0.039 (0.029)\tLoss 1.4367 (1.6931)\tPrec@1 71.000 (64.691)\tPrec@5 99.000 (96.383)\n",
            "Test: [90/100]\tTime 0.021 (0.028)\tLoss 1.2729 (1.6919)\tPrec@1 71.000 (64.648)\tPrec@5 97.000 (96.374)\n",
            "val Results: Prec@1 64.610 Prec@5 96.360 Loss 1.68538\n",
            "val Class Accuracy: [0.903,0.971,0.732,0.774,0.514,0.721,0.621,0.399,0.398,0.428]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [115][0/97], lr: 0.01000\tTime 0.467 (0.467)\tData 0.381 (0.381)\tLoss 0.0809 (0.0809)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][10/97], lr: 0.01000\tTime 0.054 (0.104)\tData 0.007 (0.039)\tLoss 0.1637 (0.1343)\tPrec@1 93.750 (94.886)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [115][20/97], lr: 0.01000\tTime 0.059 (0.082)\tData 0.002 (0.023)\tLoss 0.1255 (0.1256)\tPrec@1 94.531 (95.499)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [115][30/97], lr: 0.01000\tTime 0.070 (0.073)\tData 0.000 (0.017)\tLoss 0.1765 (0.1303)\tPrec@1 94.531 (95.514)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [115][40/97], lr: 0.01000\tTime 0.056 (0.070)\tData 0.007 (0.015)\tLoss 0.0916 (0.1266)\tPrec@1 96.875 (95.446)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [115][50/97], lr: 0.01000\tTime 0.055 (0.068)\tData 0.006 (0.013)\tLoss 0.0455 (0.1293)\tPrec@1 99.219 (95.282)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [115][60/97], lr: 0.01000\tTime 0.052 (0.066)\tData 0.000 (0.011)\tLoss 0.1750 (0.1309)\tPrec@1 95.312 (95.351)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [115][70/97], lr: 0.01000\tTime 0.077 (0.065)\tData 0.000 (0.010)\tLoss 0.0579 (0.1302)\tPrec@1 97.656 (95.390)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [115][80/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.005 (0.009)\tLoss 0.1284 (0.1307)\tPrec@1 96.875 (95.428)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [115][90/97], lr: 0.01000\tTime 0.032 (0.063)\tData 0.000 (0.009)\tLoss 0.1143 (0.1322)\tPrec@1 96.094 (95.373)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 2.1887 (2.1887)\tPrec@1 56.000 (56.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.056)\tLoss 1.7707 (2.0985)\tPrec@1 64.000 (60.818)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/100]\tTime 0.029 (0.042)\tLoss 1.6974 (2.1309)\tPrec@1 62.000 (61.000)\tPrec@5 95.000 (96.476)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 1.8565 (2.0947)\tPrec@1 61.000 (61.000)\tPrec@5 93.000 (96.323)\n",
            "Test: [40/100]\tTime 0.013 (0.032)\tLoss 2.1215 (2.0698)\tPrec@1 55.000 (61.049)\tPrec@5 97.000 (96.244)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 1.9130 (2.0759)\tPrec@1 69.000 (61.157)\tPrec@5 96.000 (96.373)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.5962 (2.0573)\tPrec@1 69.000 (61.459)\tPrec@5 96.000 (96.361)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 2.5336 (2.0679)\tPrec@1 59.000 (61.423)\tPrec@5 96.000 (96.437)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 1.5252 (2.0497)\tPrec@1 68.000 (61.481)\tPrec@5 97.000 (96.556)\n",
            "Test: [90/100]\tTime 0.013 (0.029)\tLoss 1.7370 (2.0782)\tPrec@1 61.000 (60.978)\tPrec@5 98.000 (96.571)\n",
            "val Results: Prec@1 60.970 Prec@5 96.520 Loss 2.08261\n",
            "val Class Accuracy: [0.966,0.961,0.788,0.559,0.716,0.474,0.602,0.527,0.149,0.355]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [116][0/97], lr: 0.01000\tTime 0.474 (0.474)\tData 0.385 (0.385)\tLoss 0.1587 (0.1587)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [116][10/97], lr: 0.01000\tTime 0.057 (0.103)\tData 0.000 (0.038)\tLoss 0.0728 (0.0973)\tPrec@1 96.875 (96.591)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [116][20/97], lr: 0.01000\tTime 0.055 (0.080)\tData 0.000 (0.022)\tLoss 0.1506 (0.1043)\tPrec@1 94.531 (96.466)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [116][30/97], lr: 0.01000\tTime 0.050 (0.073)\tData 0.000 (0.016)\tLoss 0.1654 (0.1134)\tPrec@1 94.531 (96.169)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [116][40/97], lr: 0.01000\tTime 0.046 (0.068)\tData 0.006 (0.014)\tLoss 0.1880 (0.1153)\tPrec@1 92.969 (95.941)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [116][50/97], lr: 0.01000\tTime 0.044 (0.066)\tData 0.008 (0.012)\tLoss 0.1152 (0.1186)\tPrec@1 94.531 (95.711)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [116][60/97], lr: 0.01000\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.0423 (0.1171)\tPrec@1 98.438 (95.761)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [116][70/97], lr: 0.01000\tTime 0.055 (0.063)\tData 0.000 (0.010)\tLoss 0.1480 (0.1166)\tPrec@1 94.531 (95.830)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [116][80/97], lr: 0.01000\tTime 0.053 (0.063)\tData 0.007 (0.009)\tLoss 0.1356 (0.1176)\tPrec@1 95.312 (95.785)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [116][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.009)\tLoss 0.0543 (0.1174)\tPrec@1 98.438 (95.776)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 1.5997 (1.5997)\tPrec@1 67.000 (67.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.029 (0.052)\tLoss 1.2940 (1.5352)\tPrec@1 73.000 (67.000)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/100]\tTime 0.025 (0.039)\tLoss 1.2564 (1.5442)\tPrec@1 69.000 (67.476)\tPrec@5 99.000 (97.571)\n",
            "Test: [30/100]\tTime 0.022 (0.036)\tLoss 1.7273 (1.5765)\tPrec@1 71.000 (67.484)\tPrec@5 95.000 (97.161)\n",
            "Test: [40/100]\tTime 0.037 (0.034)\tLoss 1.3720 (1.5853)\tPrec@1 68.000 (67.244)\tPrec@5 98.000 (97.195)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 1.4338 (1.5708)\tPrec@1 67.000 (67.549)\tPrec@5 98.000 (97.353)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 1.3488 (1.5849)\tPrec@1 70.000 (67.230)\tPrec@5 95.000 (97.279)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 1.6935 (1.5773)\tPrec@1 66.000 (67.282)\tPrec@5 96.000 (97.268)\n",
            "Test: [80/100]\tTime 0.012 (0.030)\tLoss 1.2781 (1.5665)\tPrec@1 71.000 (67.679)\tPrec@5 99.000 (97.346)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 1.4334 (1.5783)\tPrec@1 73.000 (67.407)\tPrec@5 93.000 (97.242)\n",
            "val Results: Prec@1 67.400 Prec@5 97.220 Loss 1.57779\n",
            "val Class Accuracy: [0.934,0.979,0.488,0.401,0.639,0.866,0.705,0.532,0.525,0.671]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [117][0/97], lr: 0.01000\tTime 0.519 (0.519)\tData 0.450 (0.450)\tLoss 0.1241 (0.1241)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][10/97], lr: 0.01000\tTime 0.056 (0.102)\tData 0.000 (0.046)\tLoss 0.1231 (0.1312)\tPrec@1 96.094 (95.170)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][20/97], lr: 0.01000\tTime 0.037 (0.081)\tData 0.000 (0.026)\tLoss 0.1320 (0.1293)\tPrec@1 96.094 (95.499)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][30/97], lr: 0.01000\tTime 0.055 (0.073)\tData 0.007 (0.020)\tLoss 0.1844 (0.1308)\tPrec@1 96.094 (95.413)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [117][40/97], lr: 0.01000\tTime 0.047 (0.070)\tData 0.000 (0.016)\tLoss 0.0839 (0.1302)\tPrec@1 96.094 (95.351)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [117][50/97], lr: 0.01000\tTime 0.051 (0.067)\tData 0.004 (0.014)\tLoss 0.1161 (0.1291)\tPrec@1 95.312 (95.404)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [117][60/97], lr: 0.01000\tTime 0.063 (0.065)\tData 0.007 (0.013)\tLoss 0.0624 (0.1279)\tPrec@1 98.438 (95.441)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [117][70/97], lr: 0.01000\tTime 0.057 (0.064)\tData 0.005 (0.012)\tLoss 0.1421 (0.1289)\tPrec@1 93.750 (95.445)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [117][80/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.011)\tLoss 0.1194 (0.1280)\tPrec@1 96.875 (95.457)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [117][90/97], lr: 0.01000\tTime 0.038 (0.062)\tData 0.000 (0.010)\tLoss 0.1125 (0.1310)\tPrec@1 96.875 (95.433)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.333 (0.333)\tLoss 1.1945 (1.1945)\tPrec@1 70.000 (70.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.033 (0.052)\tLoss 1.2351 (1.3238)\tPrec@1 74.000 (68.455)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/100]\tTime 0.017 (0.041)\tLoss 1.0669 (1.3106)\tPrec@1 70.000 (69.333)\tPrec@5 98.000 (97.000)\n",
            "Test: [30/100]\tTime 0.043 (0.037)\tLoss 1.3654 (1.3358)\tPrec@1 67.000 (68.677)\tPrec@5 97.000 (97.000)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 1.4855 (1.3497)\tPrec@1 63.000 (68.415)\tPrec@5 97.000 (97.220)\n",
            "Test: [50/100]\tTime 0.039 (0.033)\tLoss 1.3922 (1.3433)\tPrec@1 70.000 (68.647)\tPrec@5 96.000 (97.176)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 1.1956 (1.3394)\tPrec@1 70.000 (68.607)\tPrec@5 96.000 (97.082)\n",
            "Test: [70/100]\tTime 0.040 (0.031)\tLoss 1.5665 (1.3324)\tPrec@1 66.000 (68.592)\tPrec@5 98.000 (97.042)\n",
            "Test: [80/100]\tTime 0.023 (0.030)\tLoss 0.9039 (1.3273)\tPrec@1 80.000 (68.716)\tPrec@5 96.000 (97.025)\n",
            "Test: [90/100]\tTime 0.025 (0.030)\tLoss 1.0306 (1.3276)\tPrec@1 75.000 (68.560)\tPrec@5 99.000 (97.143)\n",
            "val Results: Prec@1 68.520 Prec@5 97.040 Loss 1.33703\n",
            "val Class Accuracy: [0.936,0.969,0.715,0.589,0.790,0.720,0.750,0.433,0.627,0.323]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [118][0/97], lr: 0.01000\tTime 0.517 (0.517)\tData 0.441 (0.441)\tLoss 0.1354 (0.1354)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [118][10/97], lr: 0.01000\tTime 0.048 (0.101)\tData 0.000 (0.044)\tLoss 0.1009 (0.1234)\tPrec@1 97.656 (95.668)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [118][20/97], lr: 0.01000\tTime 0.051 (0.081)\tData 0.005 (0.025)\tLoss 0.0918 (0.1275)\tPrec@1 97.656 (95.499)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [118][30/97], lr: 0.01000\tTime 0.061 (0.073)\tData 0.006 (0.019)\tLoss 0.1104 (0.1285)\tPrec@1 97.656 (95.464)\tPrec@5 99.219 (99.950)\n",
            "Epoch: [118][40/97], lr: 0.01000\tTime 0.077 (0.069)\tData 0.000 (0.015)\tLoss 0.1366 (0.1311)\tPrec@1 93.750 (95.389)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [118][50/97], lr: 0.01000\tTime 0.033 (0.066)\tData 0.000 (0.013)\tLoss 0.1188 (0.1313)\tPrec@1 94.531 (95.205)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [118][60/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.007 (0.012)\tLoss 0.0867 (0.1358)\tPrec@1 96.875 (95.069)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [118][70/97], lr: 0.01000\tTime 0.071 (0.064)\tData 0.000 (0.010)\tLoss 0.2511 (0.1358)\tPrec@1 91.406 (95.037)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [118][80/97], lr: 0.01000\tTime 0.057 (0.063)\tData 0.001 (0.010)\tLoss 0.1139 (0.1365)\tPrec@1 96.875 (95.014)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [118][90/97], lr: 0.01000\tTime 0.031 (0.062)\tData 0.000 (0.009)\tLoss 0.0919 (0.1352)\tPrec@1 94.531 (95.038)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 2.0385 (2.0385)\tPrec@1 56.000 (56.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.019 (0.057)\tLoss 1.6035 (2.2580)\tPrec@1 71.000 (60.545)\tPrec@5 97.000 (96.273)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 1.8569 (2.2388)\tPrec@1 62.000 (59.952)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 2.0257 (2.2434)\tPrec@1 64.000 (60.097)\tPrec@5 97.000 (96.323)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 1.8065 (2.2540)\tPrec@1 67.000 (60.317)\tPrec@5 98.000 (96.463)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 1.7562 (2.2410)\tPrec@1 68.000 (60.765)\tPrec@5 99.000 (96.667)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 1.6505 (2.2239)\tPrec@1 65.000 (60.803)\tPrec@5 97.000 (96.525)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 2.1310 (2.1999)\tPrec@1 57.000 (61.056)\tPrec@5 97.000 (96.648)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 1.9644 (2.1872)\tPrec@1 70.000 (61.346)\tPrec@5 96.000 (96.667)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 2.2796 (2.1971)\tPrec@1 59.000 (61.187)\tPrec@5 99.000 (96.769)\n",
            "val Results: Prec@1 61.040 Prec@5 96.710 Loss 2.21220\n",
            "val Class Accuracy: [0.912,0.990,0.555,0.858,0.602,0.646,0.636,0.573,0.232,0.100]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [119][0/97], lr: 0.01000\tTime 0.530 (0.530)\tData 0.428 (0.428)\tLoss 0.1102 (0.1102)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][10/97], lr: 0.01000\tTime 0.043 (0.101)\tData 0.000 (0.047)\tLoss 0.1191 (0.1078)\tPrec@1 94.531 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][20/97], lr: 0.01000\tTime 0.057 (0.082)\tData 0.010 (0.028)\tLoss 0.0916 (0.1072)\tPrec@1 96.094 (96.280)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][30/97], lr: 0.01000\tTime 0.045 (0.074)\tData 0.000 (0.020)\tLoss 0.1518 (0.1075)\tPrec@1 94.531 (96.169)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][40/97], lr: 0.01000\tTime 0.057 (0.070)\tData 0.008 (0.017)\tLoss 0.0480 (0.1043)\tPrec@1 99.219 (96.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][50/97], lr: 0.01000\tTime 0.066 (0.068)\tData 0.006 (0.014)\tLoss 0.0399 (0.1019)\tPrec@1 99.219 (96.492)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][60/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.000 (0.012)\tLoss 0.0818 (0.1033)\tPrec@1 96.875 (96.478)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][70/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.005 (0.012)\tLoss 0.0883 (0.1026)\tPrec@1 96.875 (96.402)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][80/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.006 (0.011)\tLoss 0.1728 (0.1078)\tPrec@1 92.969 (96.161)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [119][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.010)\tLoss 0.1767 (0.1128)\tPrec@1 91.406 (96.016)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 1.9295 (1.9295)\tPrec@1 59.000 (59.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.043 (0.056)\tLoss 1.7141 (1.7118)\tPrec@1 66.000 (63.364)\tPrec@5 93.000 (94.909)\n",
            "Test: [20/100]\tTime 0.042 (0.041)\tLoss 1.9067 (1.7736)\tPrec@1 63.000 (62.857)\tPrec@5 93.000 (94.000)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 2.1419 (1.7963)\tPrec@1 58.000 (62.323)\tPrec@5 93.000 (93.774)\n",
            "Test: [40/100]\tTime 0.036 (0.033)\tLoss 1.8328 (1.7527)\tPrec@1 61.000 (62.659)\tPrec@5 95.000 (94.122)\n",
            "Test: [50/100]\tTime 0.056 (0.032)\tLoss 1.6747 (1.7357)\tPrec@1 64.000 (62.902)\tPrec@5 94.000 (94.196)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 1.8313 (1.7601)\tPrec@1 60.000 (62.590)\tPrec@5 92.000 (94.000)\n",
            "Test: [70/100]\tTime 0.025 (0.030)\tLoss 2.0252 (1.7500)\tPrec@1 61.000 (62.437)\tPrec@5 96.000 (94.070)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.4033 (1.7385)\tPrec@1 68.000 (62.654)\tPrec@5 96.000 (94.272)\n",
            "Test: [90/100]\tTime 0.014 (0.028)\tLoss 1.2224 (1.7561)\tPrec@1 70.000 (62.352)\tPrec@5 95.000 (94.242)\n",
            "val Results: Prec@1 62.300 Prec@5 94.300 Loss 1.75990\n",
            "val Class Accuracy: [0.936,0.923,0.817,0.711,0.704,0.444,0.179,0.306,0.391,0.819]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [120][0/97], lr: 0.01000\tTime 0.465 (0.465)\tData 0.392 (0.392)\tLoss 0.1550 (0.1550)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][10/97], lr: 0.01000\tTime 0.075 (0.102)\tData 0.012 (0.040)\tLoss 0.0948 (0.1299)\tPrec@1 97.656 (95.170)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.012 (0.024)\tLoss 0.1087 (0.1277)\tPrec@1 94.531 (95.387)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [120][30/97], lr: 0.01000\tTime 0.072 (0.074)\tData 0.004 (0.017)\tLoss 0.1223 (0.1211)\tPrec@1 94.531 (95.539)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [120][40/97], lr: 0.01000\tTime 0.050 (0.070)\tData 0.000 (0.014)\tLoss 0.1816 (0.1308)\tPrec@1 94.531 (95.236)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [120][50/97], lr: 0.01000\tTime 0.052 (0.068)\tData 0.007 (0.013)\tLoss 0.1386 (0.1352)\tPrec@1 95.312 (95.159)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [120][60/97], lr: 0.01000\tTime 0.058 (0.066)\tData 0.000 (0.012)\tLoss 0.0621 (0.1316)\tPrec@1 98.438 (95.287)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [120][70/97], lr: 0.01000\tTime 0.063 (0.065)\tData 0.000 (0.011)\tLoss 0.1899 (0.1314)\tPrec@1 92.188 (95.390)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [120][80/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.002 (0.010)\tLoss 0.0913 (0.1310)\tPrec@1 97.656 (95.419)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [120][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.010)\tLoss 0.0833 (0.1298)\tPrec@1 96.875 (95.433)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 1.9160 (1.9160)\tPrec@1 57.000 (57.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.050)\tLoss 1.7547 (1.9091)\tPrec@1 65.000 (60.455)\tPrec@5 94.000 (97.364)\n",
            "Test: [20/100]\tTime 0.030 (0.039)\tLoss 1.6392 (1.9343)\tPrec@1 65.000 (60.095)\tPrec@5 96.000 (97.000)\n",
            "Test: [30/100]\tTime 0.031 (0.033)\tLoss 1.7256 (1.9410)\tPrec@1 67.000 (60.161)\tPrec@5 96.000 (96.839)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 1.8966 (1.9265)\tPrec@1 61.000 (60.488)\tPrec@5 96.000 (96.805)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.6526 (1.9009)\tPrec@1 65.000 (61.118)\tPrec@5 98.000 (96.784)\n",
            "Test: [60/100]\tTime 0.013 (0.030)\tLoss 1.8031 (1.9026)\tPrec@1 65.000 (60.902)\tPrec@5 96.000 (96.738)\n",
            "Test: [70/100]\tTime 0.039 (0.030)\tLoss 1.8668 (1.9125)\tPrec@1 63.000 (60.803)\tPrec@5 96.000 (96.732)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 1.7193 (1.8894)\tPrec@1 66.000 (61.173)\tPrec@5 97.000 (96.716)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 1.4928 (1.9163)\tPrec@1 63.000 (60.813)\tPrec@5 99.000 (96.780)\n",
            "val Results: Prec@1 60.880 Prec@5 96.820 Loss 1.91897\n",
            "val Class Accuracy: [0.927,0.985,0.860,0.763,0.573,0.449,0.406,0.642,0.172,0.311]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [121][0/97], lr: 0.01000\tTime 0.445 (0.445)\tData 0.375 (0.375)\tLoss 0.1141 (0.1141)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][10/97], lr: 0.01000\tTime 0.066 (0.099)\tData 0.008 (0.038)\tLoss 0.1517 (0.1302)\tPrec@1 91.406 (94.886)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][20/97], lr: 0.01000\tTime 0.069 (0.080)\tData 0.005 (0.022)\tLoss 0.1379 (0.1213)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.963)\n",
            "Epoch: [121][30/97], lr: 0.01000\tTime 0.070 (0.074)\tData 0.008 (0.016)\tLoss 0.0924 (0.1217)\tPrec@1 97.656 (95.312)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [121][40/97], lr: 0.01000\tTime 0.047 (0.070)\tData 0.000 (0.013)\tLoss 0.0823 (0.1270)\tPrec@1 96.094 (95.255)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [121][50/97], lr: 0.01000\tTime 0.054 (0.067)\tData 0.000 (0.012)\tLoss 0.1872 (0.1258)\tPrec@1 92.188 (95.404)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [121][60/97], lr: 0.01000\tTime 0.051 (0.066)\tData 0.000 (0.011)\tLoss 0.1668 (0.1265)\tPrec@1 94.531 (95.312)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [121][70/97], lr: 0.01000\tTime 0.068 (0.065)\tData 0.006 (0.010)\tLoss 0.0891 (0.1284)\tPrec@1 96.875 (95.301)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [121][80/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.000 (0.009)\tLoss 0.1671 (0.1296)\tPrec@1 95.312 (95.341)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [121][90/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.009)\tLoss 0.0885 (0.1321)\tPrec@1 96.094 (95.252)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 2.3707 (2.3707)\tPrec@1 52.000 (52.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.036 (0.058)\tLoss 1.9898 (2.5261)\tPrec@1 67.000 (58.182)\tPrec@5 95.000 (93.273)\n",
            "Test: [20/100]\tTime 0.026 (0.041)\tLoss 1.9736 (2.4271)\tPrec@1 62.000 (58.429)\tPrec@5 97.000 (93.524)\n",
            "Test: [30/100]\tTime 0.018 (0.037)\tLoss 2.3002 (2.4338)\tPrec@1 60.000 (58.355)\tPrec@5 93.000 (93.032)\n",
            "Test: [40/100]\tTime 0.012 (0.034)\tLoss 2.6953 (2.4304)\tPrec@1 56.000 (58.341)\tPrec@5 93.000 (93.171)\n",
            "Test: [50/100]\tTime 0.035 (0.033)\tLoss 2.5290 (2.4021)\tPrec@1 56.000 (58.902)\tPrec@5 91.000 (93.255)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 2.3194 (2.4384)\tPrec@1 62.000 (58.279)\tPrec@5 91.000 (93.246)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 2.4758 (2.4283)\tPrec@1 55.000 (58.211)\tPrec@5 95.000 (93.366)\n",
            "Test: [80/100]\tTime 0.032 (0.030)\tLoss 2.0079 (2.3990)\tPrec@1 65.000 (58.444)\tPrec@5 93.000 (93.494)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 1.9745 (2.4097)\tPrec@1 58.000 (58.187)\tPrec@5 94.000 (93.527)\n",
            "val Results: Prec@1 58.170 Prec@5 93.540 Loss 2.40383\n",
            "val Class Accuracy: [0.868,0.960,0.865,0.738,0.724,0.438,0.572,0.171,0.286,0.195]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [122][0/97], lr: 0.01000\tTime 0.448 (0.448)\tData 0.354 (0.354)\tLoss 0.0856 (0.0856)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][10/97], lr: 0.01000\tTime 0.044 (0.101)\tData 0.006 (0.036)\tLoss 0.1895 (0.1136)\tPrec@1 94.531 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][20/97], lr: 0.01000\tTime 0.047 (0.080)\tData 0.000 (0.022)\tLoss 0.1174 (0.1048)\tPrec@1 94.531 (96.243)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][30/97], lr: 0.01000\tTime 0.050 (0.072)\tData 0.000 (0.016)\tLoss 0.1649 (0.1034)\tPrec@1 96.875 (96.270)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][40/97], lr: 0.01000\tTime 0.073 (0.070)\tData 0.012 (0.013)\tLoss 0.1144 (0.0971)\tPrec@1 94.531 (96.513)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][50/97], lr: 0.01000\tTime 0.064 (0.067)\tData 0.004 (0.011)\tLoss 0.1297 (0.1002)\tPrec@1 95.312 (96.477)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][60/97], lr: 0.01000\tTime 0.066 (0.066)\tData 0.000 (0.010)\tLoss 0.0942 (0.1042)\tPrec@1 95.312 (96.324)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][70/97], lr: 0.01000\tTime 0.049 (0.065)\tData 0.007 (0.009)\tLoss 0.1220 (0.1079)\tPrec@1 96.875 (96.248)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][80/97], lr: 0.01000\tTime 0.079 (0.064)\tData 0.004 (0.009)\tLoss 0.0689 (0.1114)\tPrec@1 96.875 (96.132)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [122][90/97], lr: 0.01000\tTime 0.028 (0.063)\tData 0.000 (0.008)\tLoss 0.1809 (0.1150)\tPrec@1 94.531 (96.094)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 1.8144 (1.8144)\tPrec@1 60.000 (60.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.026 (0.052)\tLoss 1.2835 (1.6206)\tPrec@1 76.000 (65.545)\tPrec@5 96.000 (96.182)\n",
            "Test: [20/100]\tTime 0.022 (0.039)\tLoss 1.6185 (1.6675)\tPrec@1 64.000 (64.905)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/100]\tTime 0.050 (0.035)\tLoss 1.2893 (1.6627)\tPrec@1 70.000 (64.903)\tPrec@5 98.000 (96.097)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 1.8747 (1.6677)\tPrec@1 67.000 (65.098)\tPrec@5 96.000 (96.122)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 1.5907 (1.6504)\tPrec@1 69.000 (65.569)\tPrec@5 99.000 (96.314)\n",
            "Test: [60/100]\tTime 0.038 (0.030)\tLoss 1.4046 (1.6619)\tPrec@1 71.000 (65.361)\tPrec@5 97.000 (96.377)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 1.7148 (1.6518)\tPrec@1 65.000 (65.493)\tPrec@5 96.000 (96.310)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.5146 (1.6296)\tPrec@1 69.000 (65.679)\tPrec@5 95.000 (96.358)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.2404 (1.6424)\tPrec@1 67.000 (65.319)\tPrec@5 97.000 (96.484)\n",
            "val Results: Prec@1 65.240 Prec@5 96.440 Loss 1.64360\n",
            "val Class Accuracy: [0.954,0.883,0.875,0.641,0.727,0.638,0.579,0.401,0.368,0.458]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [123][0/97], lr: 0.01000\tTime 0.411 (0.411)\tData 0.337 (0.337)\tLoss 0.1247 (0.1247)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][10/97], lr: 0.01000\tTime 0.045 (0.100)\tData 0.000 (0.036)\tLoss 0.0727 (0.1107)\tPrec@1 99.219 (95.668)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][20/97], lr: 0.01000\tTime 0.058 (0.080)\tData 0.000 (0.022)\tLoss 0.2082 (0.1269)\tPrec@1 92.188 (95.164)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [123][30/97], lr: 0.01000\tTime 0.043 (0.073)\tData 0.000 (0.016)\tLoss 0.1249 (0.1249)\tPrec@1 94.531 (95.439)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [123][40/97], lr: 0.01000\tTime 0.043 (0.070)\tData 0.000 (0.014)\tLoss 0.1404 (0.1229)\tPrec@1 93.750 (95.427)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [123][50/97], lr: 0.01000\tTime 0.065 (0.067)\tData 0.005 (0.012)\tLoss 0.1992 (0.1270)\tPrec@1 94.531 (95.450)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [123][60/97], lr: 0.01000\tTime 0.049 (0.066)\tData 0.000 (0.011)\tLoss 0.2131 (0.1285)\tPrec@1 92.969 (95.300)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [123][70/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.011 (0.010)\tLoss 0.1322 (0.1236)\tPrec@1 94.531 (95.544)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [123][80/97], lr: 0.01000\tTime 0.066 (0.064)\tData 0.005 (0.009)\tLoss 0.1001 (0.1239)\tPrec@1 96.094 (95.573)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [123][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.1347 (0.1239)\tPrec@1 94.531 (95.622)\tPrec@5 100.000 (99.957)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 1.4597 (1.4597)\tPrec@1 67.000 (67.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.016 (0.057)\tLoss 1.4365 (1.6995)\tPrec@1 74.000 (65.909)\tPrec@5 96.000 (96.818)\n",
            "Test: [20/100]\tTime 0.030 (0.043)\tLoss 1.2880 (1.7286)\tPrec@1 70.000 (65.048)\tPrec@5 93.000 (96.286)\n",
            "Test: [30/100]\tTime 0.016 (0.037)\tLoss 1.6443 (1.7302)\tPrec@1 60.000 (64.484)\tPrec@5 97.000 (96.161)\n",
            "Test: [40/100]\tTime 0.014 (0.034)\tLoss 1.8232 (1.7344)\tPrec@1 60.000 (64.024)\tPrec@5 97.000 (96.220)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.6664 (1.7370)\tPrec@1 68.000 (64.275)\tPrec@5 96.000 (96.294)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 1.5810 (1.7362)\tPrec@1 66.000 (64.230)\tPrec@5 92.000 (96.230)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 2.0031 (1.7212)\tPrec@1 59.000 (64.380)\tPrec@5 98.000 (96.268)\n",
            "Test: [80/100]\tTime 0.023 (0.030)\tLoss 1.4493 (1.7080)\tPrec@1 70.000 (64.358)\tPrec@5 95.000 (96.383)\n",
            "Test: [90/100]\tTime 0.023 (0.030)\tLoss 1.3306 (1.7062)\tPrec@1 67.000 (64.407)\tPrec@5 100.000 (96.407)\n",
            "val Results: Prec@1 64.320 Prec@5 96.360 Loss 1.71991\n",
            "val Class Accuracy: [0.975,0.968,0.632,0.460,0.627,0.679,0.779,0.439,0.575,0.298]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [124][0/97], lr: 0.01000\tTime 0.507 (0.507)\tData 0.419 (0.419)\tLoss 0.1243 (0.1243)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [124][10/97], lr: 0.01000\tTime 0.059 (0.104)\tData 0.002 (0.043)\tLoss 0.1271 (0.1058)\tPrec@1 96.094 (96.165)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [124][20/97], lr: 0.01000\tTime 0.048 (0.082)\tData 0.000 (0.026)\tLoss 0.1377 (0.1177)\tPrec@1 95.312 (95.833)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [124][30/97], lr: 0.01000\tTime 0.076 (0.075)\tData 0.000 (0.018)\tLoss 0.1010 (0.1137)\tPrec@1 96.094 (96.043)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [124][40/97], lr: 0.01000\tTime 0.056 (0.072)\tData 0.007 (0.015)\tLoss 0.1431 (0.1143)\tPrec@1 93.750 (96.056)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [124][50/97], lr: 0.01000\tTime 0.053 (0.069)\tData 0.006 (0.013)\tLoss 0.1130 (0.1138)\tPrec@1 95.312 (96.140)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [124][60/97], lr: 0.01000\tTime 0.060 (0.067)\tData 0.006 (0.012)\tLoss 0.1623 (0.1107)\tPrec@1 94.531 (96.183)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [124][70/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.007 (0.012)\tLoss 0.1389 (0.1127)\tPrec@1 95.312 (96.105)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [124][80/97], lr: 0.01000\tTime 0.051 (0.065)\tData 0.007 (0.011)\tLoss 0.1608 (0.1126)\tPrec@1 92.969 (96.113)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [124][90/97], lr: 0.01000\tTime 0.030 (0.064)\tData 0.000 (0.011)\tLoss 0.0691 (0.1097)\tPrec@1 97.656 (96.188)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 1.5629 (1.5629)\tPrec@1 60.000 (60.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.057 (0.055)\tLoss 1.9924 (1.9990)\tPrec@1 63.000 (64.273)\tPrec@5 93.000 (96.636)\n",
            "Test: [20/100]\tTime 0.010 (0.042)\tLoss 1.5763 (1.9913)\tPrec@1 65.000 (63.381)\tPrec@5 97.000 (96.476)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 1.7161 (2.0088)\tPrec@1 66.000 (63.290)\tPrec@5 93.000 (96.194)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 1.9833 (1.9777)\tPrec@1 61.000 (63.268)\tPrec@5 100.000 (96.366)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.4921 (1.9565)\tPrec@1 67.000 (63.510)\tPrec@5 99.000 (96.510)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 1.6374 (1.9250)\tPrec@1 63.000 (63.443)\tPrec@5 98.000 (96.590)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 1.9814 (1.9240)\tPrec@1 66.000 (63.479)\tPrec@5 99.000 (96.634)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 1.5136 (1.9076)\tPrec@1 72.000 (63.852)\tPrec@5 99.000 (96.778)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.6418 (1.9330)\tPrec@1 66.000 (63.484)\tPrec@5 100.000 (96.802)\n",
            "val Results: Prec@1 63.340 Prec@5 96.730 Loss 1.94828\n",
            "val Class Accuracy: [0.974,0.969,0.610,0.590,0.843,0.632,0.483,0.727,0.291,0.215]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [125][0/97], lr: 0.01000\tTime 0.466 (0.466)\tData 0.384 (0.384)\tLoss 0.1386 (0.1386)\tPrec@1 96.094 (96.094)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [125][10/97], lr: 0.01000\tTime 0.060 (0.101)\tData 0.000 (0.039)\tLoss 0.0446 (0.0986)\tPrec@1 98.438 (96.804)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [125][20/97], lr: 0.01000\tTime 0.050 (0.080)\tData 0.000 (0.022)\tLoss 0.0915 (0.1076)\tPrec@1 96.875 (96.354)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [125][30/97], lr: 0.01000\tTime 0.069 (0.074)\tData 0.007 (0.016)\tLoss 0.0916 (0.1065)\tPrec@1 96.875 (96.346)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [125][40/97], lr: 0.01000\tTime 0.062 (0.070)\tData 0.000 (0.013)\tLoss 0.0894 (0.1116)\tPrec@1 95.312 (95.979)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [125][50/97], lr: 0.01000\tTime 0.058 (0.067)\tData 0.012 (0.012)\tLoss 0.1448 (0.1127)\tPrec@1 93.750 (95.925)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [125][60/97], lr: 0.01000\tTime 0.039 (0.065)\tData 0.000 (0.011)\tLoss 0.1531 (0.1165)\tPrec@1 94.531 (95.876)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [125][70/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.000 (0.010)\tLoss 0.1049 (0.1164)\tPrec@1 96.094 (95.896)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [125][80/97], lr: 0.01000\tTime 0.064 (0.064)\tData 0.004 (0.010)\tLoss 0.0668 (0.1173)\tPrec@1 96.094 (95.862)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [125][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.1165 (0.1190)\tPrec@1 96.875 (95.853)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.347 (0.347)\tLoss 1.4735 (1.4735)\tPrec@1 60.000 (60.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.028 (0.057)\tLoss 1.4310 (1.6513)\tPrec@1 68.000 (65.182)\tPrec@5 96.000 (96.545)\n",
            "Test: [20/100]\tTime 0.026 (0.042)\tLoss 1.4132 (1.6244)\tPrec@1 70.000 (65.524)\tPrec@5 98.000 (96.571)\n",
            "Test: [30/100]\tTime 0.031 (0.037)\tLoss 1.3169 (1.6199)\tPrec@1 64.000 (65.903)\tPrec@5 97.000 (96.323)\n",
            "Test: [40/100]\tTime 0.012 (0.033)\tLoss 1.6778 (1.6270)\tPrec@1 68.000 (65.854)\tPrec@5 98.000 (96.341)\n",
            "Test: [50/100]\tTime 0.021 (0.032)\tLoss 1.5980 (1.6144)\tPrec@1 63.000 (65.980)\tPrec@5 98.000 (96.392)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 1.7311 (1.6210)\tPrec@1 71.000 (65.885)\tPrec@5 95.000 (96.443)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 1.5396 (1.6157)\tPrec@1 68.000 (65.746)\tPrec@5 97.000 (96.380)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 1.4739 (1.5933)\tPrec@1 69.000 (65.889)\tPrec@5 97.000 (96.580)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 1.6532 (1.6091)\tPrec@1 64.000 (65.549)\tPrec@5 99.000 (96.692)\n",
            "val Results: Prec@1 65.420 Prec@5 96.660 Loss 1.62182\n",
            "val Class Accuracy: [0.940,0.940,0.708,0.572,0.800,0.810,0.412,0.575,0.520,0.265]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [126][0/97], lr: 0.01000\tTime 0.424 (0.424)\tData 0.336 (0.336)\tLoss 0.1294 (0.1294)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][10/97], lr: 0.01000\tTime 0.069 (0.105)\tData 0.000 (0.036)\tLoss 0.1124 (0.1319)\tPrec@1 96.875 (94.957)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [126][20/97], lr: 0.01000\tTime 0.055 (0.084)\tData 0.007 (0.021)\tLoss 0.1487 (0.1292)\tPrec@1 95.312 (95.238)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [126][30/97], lr: 0.01000\tTime 0.060 (0.076)\tData 0.000 (0.016)\tLoss 0.0718 (0.1296)\tPrec@1 98.438 (95.111)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [126][40/97], lr: 0.01000\tTime 0.048 (0.072)\tData 0.007 (0.013)\tLoss 0.1103 (0.1263)\tPrec@1 96.094 (95.293)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [126][50/97], lr: 0.01000\tTime 0.055 (0.069)\tData 0.006 (0.011)\tLoss 0.0463 (0.1216)\tPrec@1 98.438 (95.512)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [126][60/97], lr: 0.01000\tTime 0.040 (0.067)\tData 0.000 (0.010)\tLoss 0.0645 (0.1137)\tPrec@1 96.094 (95.825)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [126][70/97], lr: 0.01000\tTime 0.067 (0.066)\tData 0.007 (0.009)\tLoss 0.1041 (0.1100)\tPrec@1 97.656 (95.951)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [126][80/97], lr: 0.01000\tTime 0.041 (0.064)\tData 0.007 (0.009)\tLoss 0.1463 (0.1109)\tPrec@1 94.531 (95.882)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [126][90/97], lr: 0.01000\tTime 0.037 (0.063)\tData 0.000 (0.009)\tLoss 0.0970 (0.1122)\tPrec@1 96.875 (95.853)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.344 (0.344)\tLoss 2.1232 (2.1232)\tPrec@1 58.000 (58.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.018 (0.053)\tLoss 1.9913 (2.1457)\tPrec@1 65.000 (61.364)\tPrec@5 95.000 (95.818)\n",
            "Test: [20/100]\tTime 0.017 (0.040)\tLoss 1.9858 (2.1061)\tPrec@1 63.000 (62.143)\tPrec@5 97.000 (95.810)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 2.1267 (2.1263)\tPrec@1 64.000 (61.935)\tPrec@5 96.000 (95.419)\n",
            "Test: [40/100]\tTime 0.035 (0.034)\tLoss 1.9214 (2.1220)\tPrec@1 60.000 (61.854)\tPrec@5 97.000 (95.390)\n",
            "Test: [50/100]\tTime 0.030 (0.032)\tLoss 1.9104 (2.1074)\tPrec@1 62.000 (62.216)\tPrec@5 96.000 (95.490)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 1.4887 (2.0891)\tPrec@1 66.000 (62.328)\tPrec@5 96.000 (95.557)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.9437 (2.0896)\tPrec@1 58.000 (62.099)\tPrec@5 97.000 (95.507)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 1.7790 (2.0748)\tPrec@1 71.000 (62.432)\tPrec@5 94.000 (95.741)\n",
            "Test: [90/100]\tTime 0.017 (0.030)\tLoss 1.7543 (2.0897)\tPrec@1 61.000 (62.198)\tPrec@5 96.000 (95.692)\n",
            "val Results: Prec@1 62.300 Prec@5 95.560 Loss 2.10078\n",
            "val Class Accuracy: [0.936,0.960,0.740,0.826,0.642,0.498,0.457,0.647,0.302,0.222]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [127][0/97], lr: 0.01000\tTime 0.516 (0.516)\tData 0.425 (0.425)\tLoss 0.0928 (0.0928)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][10/97], lr: 0.01000\tTime 0.068 (0.102)\tData 0.007 (0.043)\tLoss 0.1068 (0.1091)\tPrec@1 94.531 (96.165)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][20/97], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.025)\tLoss 0.0541 (0.1007)\tPrec@1 98.438 (96.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.007 (0.019)\tLoss 0.1624 (0.1088)\tPrec@1 92.188 (96.144)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [127][40/97], lr: 0.01000\tTime 0.054 (0.070)\tData 0.000 (0.015)\tLoss 0.0980 (0.1079)\tPrec@1 96.094 (96.208)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [127][50/97], lr: 0.01000\tTime 0.052 (0.067)\tData 0.000 (0.013)\tLoss 0.1595 (0.1160)\tPrec@1 95.312 (95.879)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [127][60/97], lr: 0.01000\tTime 0.067 (0.065)\tData 0.000 (0.012)\tLoss 0.1415 (0.1171)\tPrec@1 92.188 (95.774)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [127][70/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.004 (0.011)\tLoss 0.1044 (0.1155)\tPrec@1 96.875 (95.830)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [127][80/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.011 (0.010)\tLoss 0.1031 (0.1177)\tPrec@1 97.656 (95.814)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [127][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.010)\tLoss 0.0640 (0.1187)\tPrec@1 97.656 (95.785)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 1.6466 (1.6466)\tPrec@1 63.000 (63.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.026 (0.057)\tLoss 1.4911 (1.8709)\tPrec@1 71.000 (63.818)\tPrec@5 96.000 (95.364)\n",
            "Test: [20/100]\tTime 0.028 (0.042)\tLoss 1.6742 (1.8523)\tPrec@1 66.000 (63.714)\tPrec@5 96.000 (95.333)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.6650 (1.8765)\tPrec@1 66.000 (63.258)\tPrec@5 95.000 (95.194)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 2.0178 (1.8843)\tPrec@1 62.000 (63.098)\tPrec@5 94.000 (94.805)\n",
            "Test: [50/100]\tTime 0.048 (0.033)\tLoss 1.7655 (1.8616)\tPrec@1 66.000 (63.569)\tPrec@5 97.000 (94.980)\n",
            "Test: [60/100]\tTime 0.022 (0.032)\tLoss 1.4029 (1.8601)\tPrec@1 69.000 (63.328)\tPrec@5 94.000 (95.049)\n",
            "Test: [70/100]\tTime 0.039 (0.031)\tLoss 1.7902 (1.8538)\tPrec@1 62.000 (63.423)\tPrec@5 93.000 (94.944)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 1.7159 (1.8329)\tPrec@1 68.000 (63.432)\tPrec@5 95.000 (95.025)\n",
            "Test: [90/100]\tTime 0.020 (0.030)\tLoss 1.4342 (1.8532)\tPrec@1 71.000 (63.253)\tPrec@5 96.000 (95.055)\n",
            "val Results: Prec@1 62.980 Prec@5 95.060 Loss 1.86089\n",
            "val Class Accuracy: [0.933,0.944,0.753,0.831,0.708,0.485,0.619,0.473,0.276,0.276]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [128][0/97], lr: 0.01000\tTime 0.524 (0.524)\tData 0.440 (0.440)\tLoss 0.0488 (0.0488)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][10/97], lr: 0.01000\tTime 0.050 (0.105)\tData 0.000 (0.044)\tLoss 0.0692 (0.1067)\tPrec@1 97.656 (96.591)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][20/97], lr: 0.01000\tTime 0.049 (0.082)\tData 0.000 (0.024)\tLoss 0.0842 (0.1103)\tPrec@1 97.656 (96.280)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][30/97], lr: 0.01000\tTime 0.059 (0.074)\tData 0.007 (0.019)\tLoss 0.0736 (0.1036)\tPrec@1 97.656 (96.447)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [128][40/97], lr: 0.01000\tTime 0.074 (0.070)\tData 0.010 (0.016)\tLoss 0.0803 (0.1049)\tPrec@1 97.656 (96.341)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [128][50/97], lr: 0.01000\tTime 0.067 (0.068)\tData 0.001 (0.013)\tLoss 0.0998 (0.1095)\tPrec@1 97.656 (96.247)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [128][60/97], lr: 0.01000\tTime 0.058 (0.066)\tData 0.006 (0.012)\tLoss 0.1153 (0.1107)\tPrec@1 95.312 (96.209)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [128][70/97], lr: 0.01000\tTime 0.107 (0.066)\tData 0.007 (0.011)\tLoss 0.1465 (0.1138)\tPrec@1 96.094 (96.061)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [128][80/97], lr: 0.01000\tTime 0.051 (0.064)\tData 0.000 (0.010)\tLoss 0.1954 (0.1190)\tPrec@1 91.406 (95.824)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [128][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.010)\tLoss 0.1394 (0.1225)\tPrec@1 93.750 (95.673)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.283 (0.283)\tLoss 1.7988 (1.7988)\tPrec@1 64.000 (64.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.018 (0.056)\tLoss 1.7925 (1.9707)\tPrec@1 66.000 (63.727)\tPrec@5 94.000 (95.727)\n",
            "Test: [20/100]\tTime 0.012 (0.041)\tLoss 1.7066 (1.9233)\tPrec@1 66.000 (64.048)\tPrec@5 95.000 (95.952)\n",
            "Test: [30/100]\tTime 0.033 (0.040)\tLoss 1.7226 (1.9396)\tPrec@1 66.000 (64.452)\tPrec@5 97.000 (95.710)\n",
            "Test: [40/100]\tTime 0.066 (0.038)\tLoss 1.7628 (1.9341)\tPrec@1 65.000 (64.098)\tPrec@5 97.000 (95.805)\n",
            "Test: [50/100]\tTime 0.047 (0.039)\tLoss 1.5471 (1.9167)\tPrec@1 65.000 (64.118)\tPrec@5 97.000 (95.902)\n",
            "Test: [60/100]\tTime 0.032 (0.039)\tLoss 1.2937 (1.8933)\tPrec@1 75.000 (64.098)\tPrec@5 97.000 (96.016)\n",
            "Test: [70/100]\tTime 0.033 (0.039)\tLoss 2.0254 (1.8682)\tPrec@1 62.000 (64.028)\tPrec@5 95.000 (96.000)\n",
            "Test: [80/100]\tTime 0.026 (0.039)\tLoss 1.8358 (1.8487)\tPrec@1 67.000 (64.222)\tPrec@5 93.000 (96.037)\n",
            "Test: [90/100]\tTime 0.033 (0.039)\tLoss 1.5156 (1.8743)\tPrec@1 67.000 (63.802)\tPrec@5 97.000 (96.121)\n",
            "val Results: Prec@1 63.840 Prec@5 96.100 Loss 1.88213\n",
            "val Class Accuracy: [0.974,0.938,0.764,0.701,0.557,0.581,0.681,0.722,0.296,0.170]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [129][0/97], lr: 0.01000\tTime 0.644 (0.644)\tData 0.548 (0.548)\tLoss 0.2138 (0.2138)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [129][10/97], lr: 0.01000\tTime 0.063 (0.129)\tData 0.001 (0.054)\tLoss 0.1227 (0.1430)\tPrec@1 94.531 (94.815)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [129][20/97], lr: 0.01000\tTime 0.064 (0.096)\tData 0.005 (0.031)\tLoss 0.1246 (0.1284)\tPrec@1 96.875 (95.499)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [129][30/97], lr: 0.01000\tTime 0.055 (0.083)\tData 0.000 (0.022)\tLoss 0.0651 (0.1263)\tPrec@1 98.438 (95.590)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [129][40/97], lr: 0.01000\tTime 0.040 (0.076)\tData 0.000 (0.018)\tLoss 0.1478 (0.1284)\tPrec@1 93.750 (95.465)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [129][50/97], lr: 0.01000\tTime 0.052 (0.073)\tData 0.000 (0.015)\tLoss 0.1203 (0.1305)\tPrec@1 95.312 (95.435)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [129][60/97], lr: 0.01000\tTime 0.053 (0.070)\tData 0.000 (0.013)\tLoss 0.0865 (0.1298)\tPrec@1 97.656 (95.377)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [129][70/97], lr: 0.01000\tTime 0.078 (0.069)\tData 0.007 (0.012)\tLoss 0.0975 (0.1320)\tPrec@1 96.875 (95.335)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [129][80/97], lr: 0.01000\tTime 0.060 (0.068)\tData 0.001 (0.011)\tLoss 0.1137 (0.1318)\tPrec@1 96.094 (95.390)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [129][90/97], lr: 0.01000\tTime 0.027 (0.066)\tData 0.000 (0.010)\tLoss 0.0790 (0.1319)\tPrec@1 97.656 (95.364)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.284 (0.284)\tLoss 1.3726 (1.3726)\tPrec@1 65.000 (65.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 1.4917 (1.7008)\tPrec@1 62.000 (63.364)\tPrec@5 95.000 (96.545)\n",
            "Test: [20/100]\tTime 0.031 (0.041)\tLoss 1.7093 (1.6684)\tPrec@1 64.000 (65.000)\tPrec@5 98.000 (96.810)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 1.6024 (1.6934)\tPrec@1 63.000 (64.968)\tPrec@5 95.000 (96.645)\n",
            "Test: [40/100]\tTime 0.026 (0.032)\tLoss 1.6530 (1.7074)\tPrec@1 68.000 (64.732)\tPrec@5 97.000 (96.634)\n",
            "Test: [50/100]\tTime 0.034 (0.031)\tLoss 1.4236 (1.6860)\tPrec@1 66.000 (64.902)\tPrec@5 97.000 (96.745)\n",
            "Test: [60/100]\tTime 0.028 (0.030)\tLoss 1.6507 (1.6855)\tPrec@1 71.000 (64.770)\tPrec@5 95.000 (96.754)\n",
            "Test: [70/100]\tTime 0.030 (0.029)\tLoss 1.5264 (1.6851)\tPrec@1 70.000 (64.831)\tPrec@5 95.000 (96.704)\n",
            "Test: [80/100]\tTime 0.023 (0.028)\tLoss 1.5155 (1.6704)\tPrec@1 66.000 (64.802)\tPrec@5 98.000 (96.852)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 1.5980 (1.6946)\tPrec@1 62.000 (64.286)\tPrec@5 98.000 (96.835)\n",
            "val Results: Prec@1 64.060 Prec@5 96.790 Loss 1.71343\n",
            "val Class Accuracy: [0.931,0.957,0.756,0.752,0.873,0.421,0.530,0.631,0.297,0.258]\n",
            "Best Prec@1: 70.010\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [130][0/97], lr: 0.01000\tTime 0.477 (0.477)\tData 0.383 (0.383)\tLoss 0.1479 (0.1479)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][10/97], lr: 0.01000\tTime 0.061 (0.102)\tData 0.011 (0.040)\tLoss 0.0897 (0.1127)\tPrec@1 96.094 (95.952)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][20/97], lr: 0.01000\tTime 0.060 (0.081)\tData 0.007 (0.023)\tLoss 0.1103 (0.1115)\tPrec@1 97.656 (95.908)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][30/97], lr: 0.01000\tTime 0.046 (0.073)\tData 0.002 (0.018)\tLoss 0.0835 (0.1166)\tPrec@1 96.094 (95.968)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][40/97], lr: 0.01000\tTime 0.063 (0.070)\tData 0.001 (0.015)\tLoss 0.0883 (0.1152)\tPrec@1 95.312 (95.884)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][50/97], lr: 0.01000\tTime 0.054 (0.067)\tData 0.000 (0.013)\tLoss 0.0494 (0.1125)\tPrec@1 99.219 (95.987)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][60/97], lr: 0.01000\tTime 0.042 (0.065)\tData 0.000 (0.012)\tLoss 0.0917 (0.1150)\tPrec@1 96.094 (95.953)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][70/97], lr: 0.01000\tTime 0.058 (0.064)\tData 0.007 (0.011)\tLoss 0.1309 (0.1144)\tPrec@1 94.531 (95.929)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][80/97], lr: 0.01000\tTime 0.056 (0.063)\tData 0.008 (0.010)\tLoss 0.1961 (0.1158)\tPrec@1 94.531 (95.930)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][90/97], lr: 0.01000\tTime 0.034 (0.062)\tData 0.000 (0.010)\tLoss 0.1460 (0.1162)\tPrec@1 93.750 (95.888)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.297 (0.297)\tLoss 0.9032 (0.9032)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.034 (0.050)\tLoss 1.1273 (1.2186)\tPrec@1 77.000 (72.364)\tPrec@5 97.000 (97.909)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 1.2857 (1.2793)\tPrec@1 72.000 (71.429)\tPrec@5 97.000 (97.571)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 1.2261 (1.2898)\tPrec@1 72.000 (71.258)\tPrec@5 98.000 (97.516)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 1.1051 (1.2927)\tPrec@1 73.000 (71.317)\tPrec@5 97.000 (97.537)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 1.0235 (1.2634)\tPrec@1 76.000 (71.706)\tPrec@5 97.000 (97.529)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 1.0354 (1.2635)\tPrec@1 78.000 (71.590)\tPrec@5 98.000 (97.541)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 1.2875 (1.2683)\tPrec@1 76.000 (71.507)\tPrec@5 99.000 (97.676)\n",
            "Test: [80/100]\tTime 0.027 (0.030)\tLoss 1.0712 (1.2504)\tPrec@1 77.000 (71.753)\tPrec@5 96.000 (97.667)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 0.7784 (1.2624)\tPrec@1 80.000 (71.505)\tPrec@5 99.000 (97.725)\n",
            "val Results: Prec@1 71.520 Prec@5 97.660 Loss 1.26594\n",
            "val Class Accuracy: [0.952,0.903,0.792,0.602,0.810,0.466,0.764,0.626,0.500,0.737]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [131][0/97], lr: 0.01000\tTime 0.389 (0.389)\tData 0.307 (0.307)\tLoss 0.1675 (0.1675)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][10/97], lr: 0.01000\tTime 0.075 (0.106)\tData 0.014 (0.034)\tLoss 0.1689 (0.1365)\tPrec@1 93.750 (95.241)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][20/97], lr: 0.01000\tTime 0.059 (0.082)\tData 0.002 (0.020)\tLoss 0.0812 (0.1323)\tPrec@1 97.656 (95.126)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][30/97], lr: 0.01000\tTime 0.066 (0.074)\tData 0.007 (0.015)\tLoss 0.1255 (0.1348)\tPrec@1 95.312 (95.086)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][40/97], lr: 0.01000\tTime 0.057 (0.070)\tData 0.003 (0.013)\tLoss 0.1473 (0.1299)\tPrec@1 95.312 (95.274)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][50/97], lr: 0.01000\tTime 0.052 (0.068)\tData 0.007 (0.011)\tLoss 0.1946 (0.1273)\tPrec@1 92.188 (95.450)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][60/97], lr: 0.01000\tTime 0.065 (0.066)\tData 0.000 (0.010)\tLoss 0.0961 (0.1264)\tPrec@1 95.312 (95.505)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][70/97], lr: 0.01000\tTime 0.052 (0.065)\tData 0.000 (0.009)\tLoss 0.1937 (0.1285)\tPrec@1 92.969 (95.478)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][80/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.008 (0.008)\tLoss 0.1144 (0.1281)\tPrec@1 94.531 (95.592)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.008)\tLoss 0.0926 (0.1255)\tPrec@1 96.094 (95.673)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 1.4411 (1.4411)\tPrec@1 67.000 (67.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.024 (0.057)\tLoss 1.2432 (1.6624)\tPrec@1 75.000 (67.455)\tPrec@5 96.000 (97.000)\n",
            "Test: [20/100]\tTime 0.022 (0.043)\tLoss 1.8430 (1.6639)\tPrec@1 64.000 (67.667)\tPrec@5 95.000 (96.238)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 1.6977 (1.6949)\tPrec@1 68.000 (67.290)\tPrec@5 95.000 (96.000)\n",
            "Test: [40/100]\tTime 0.013 (0.034)\tLoss 1.4919 (1.7045)\tPrec@1 63.000 (66.927)\tPrec@5 97.000 (95.878)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 1.6297 (1.6953)\tPrec@1 69.000 (67.137)\tPrec@5 97.000 (95.961)\n",
            "Test: [60/100]\tTime 0.026 (0.032)\tLoss 1.5321 (1.6886)\tPrec@1 71.000 (67.049)\tPrec@5 96.000 (96.016)\n",
            "Test: [70/100]\tTime 0.029 (0.031)\tLoss 1.4354 (1.6930)\tPrec@1 72.000 (66.930)\tPrec@5 97.000 (96.014)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.2551 (1.6838)\tPrec@1 71.000 (66.938)\tPrec@5 97.000 (96.000)\n",
            "Test: [90/100]\tTime 0.045 (0.030)\tLoss 1.3397 (1.6859)\tPrec@1 67.000 (66.802)\tPrec@5 96.000 (96.077)\n",
            "val Results: Prec@1 66.740 Prec@5 96.040 Loss 1.69553\n",
            "val Class Accuracy: [0.943,0.931,0.679,0.714,0.812,0.177,0.842,0.791,0.302,0.483]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [132][0/97], lr: 0.01000\tTime 0.500 (0.500)\tData 0.414 (0.414)\tLoss 0.0596 (0.0596)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][10/97], lr: 0.01000\tTime 0.049 (0.104)\tData 0.000 (0.042)\tLoss 0.1024 (0.1135)\tPrec@1 96.094 (96.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][20/97], lr: 0.01000\tTime 0.046 (0.083)\tData 0.002 (0.024)\tLoss 0.0735 (0.1137)\tPrec@1 98.438 (96.205)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [132][30/97], lr: 0.01000\tTime 0.063 (0.077)\tData 0.003 (0.018)\tLoss 0.1775 (0.1199)\tPrec@1 94.531 (95.817)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [132][40/97], lr: 0.01000\tTime 0.053 (0.073)\tData 0.009 (0.015)\tLoss 0.1146 (0.1132)\tPrec@1 95.312 (95.979)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [132][50/97], lr: 0.01000\tTime 0.058 (0.070)\tData 0.012 (0.013)\tLoss 0.1068 (0.1133)\tPrec@1 94.531 (95.956)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [132][60/97], lr: 0.01000\tTime 0.046 (0.068)\tData 0.008 (0.012)\tLoss 0.0967 (0.1182)\tPrec@1 96.094 (95.812)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [132][70/97], lr: 0.01000\tTime 0.059 (0.066)\tData 0.001 (0.010)\tLoss 0.1695 (0.1182)\tPrec@1 92.188 (95.830)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [132][80/97], lr: 0.01000\tTime 0.068 (0.066)\tData 0.000 (0.010)\tLoss 0.0442 (0.1156)\tPrec@1 99.219 (95.949)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [132][90/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.009)\tLoss 0.0759 (0.1148)\tPrec@1 97.656 (95.956)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.326 (0.326)\tLoss 2.2943 (2.2943)\tPrec@1 55.000 (55.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.043 (0.064)\tLoss 1.9833 (2.3796)\tPrec@1 67.000 (61.636)\tPrec@5 95.000 (97.455)\n",
            "Test: [20/100]\tTime 0.025 (0.047)\tLoss 1.7072 (2.4389)\tPrec@1 65.000 (60.905)\tPrec@5 95.000 (95.952)\n",
            "Test: [30/100]\tTime 0.036 (0.041)\tLoss 2.3598 (2.4587)\tPrec@1 58.000 (60.226)\tPrec@5 95.000 (96.161)\n",
            "Test: [40/100]\tTime 0.020 (0.039)\tLoss 2.6219 (2.4642)\tPrec@1 56.000 (59.854)\tPrec@5 97.000 (96.512)\n",
            "Test: [50/100]\tTime 0.032 (0.037)\tLoss 2.4129 (2.4690)\tPrec@1 60.000 (60.333)\tPrec@5 96.000 (96.451)\n",
            "Test: [60/100]\tTime 0.010 (0.035)\tLoss 1.9313 (2.4306)\tPrec@1 65.000 (60.475)\tPrec@5 94.000 (96.377)\n",
            "Test: [70/100]\tTime 0.052 (0.036)\tLoss 2.4388 (2.4127)\tPrec@1 60.000 (60.521)\tPrec@5 97.000 (96.310)\n",
            "Test: [80/100]\tTime 0.054 (0.036)\tLoss 2.0324 (2.3878)\tPrec@1 66.000 (60.827)\tPrec@5 97.000 (96.407)\n",
            "Test: [90/100]\tTime 0.030 (0.035)\tLoss 2.4195 (2.4120)\tPrec@1 53.000 (60.495)\tPrec@5 99.000 (96.429)\n",
            "val Results: Prec@1 60.340 Prec@5 96.400 Loss 2.42226\n",
            "val Class Accuracy: [0.956,0.989,0.746,0.695,0.659,0.486,0.749,0.413,0.126,0.215]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [133][0/97], lr: 0.01000\tTime 0.539 (0.539)\tData 0.459 (0.459)\tLoss 0.0538 (0.0538)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][10/97], lr: 0.01000\tTime 0.062 (0.107)\tData 0.002 (0.049)\tLoss 0.1682 (0.1048)\tPrec@1 93.750 (95.881)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][20/97], lr: 0.01000\tTime 0.048 (0.084)\tData 0.000 (0.028)\tLoss 0.0949 (0.0932)\tPrec@1 96.875 (96.391)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][30/97], lr: 0.01000\tTime 0.043 (0.077)\tData 0.007 (0.022)\tLoss 0.0840 (0.0916)\tPrec@1 96.875 (96.673)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][40/97], lr: 0.01000\tTime 0.066 (0.072)\tData 0.000 (0.017)\tLoss 0.1155 (0.1035)\tPrec@1 96.094 (96.475)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][50/97], lr: 0.01000\tTime 0.060 (0.069)\tData 0.003 (0.015)\tLoss 0.0747 (0.1016)\tPrec@1 97.656 (96.553)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][60/97], lr: 0.01000\tTime 0.068 (0.067)\tData 0.005 (0.013)\tLoss 0.1004 (0.1044)\tPrec@1 95.312 (96.414)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][70/97], lr: 0.01000\tTime 0.062 (0.066)\tData 0.007 (0.012)\tLoss 0.1733 (0.1080)\tPrec@1 96.094 (96.325)\tPrec@5 99.219 (99.989)\n",
            "Epoch: [133][80/97], lr: 0.01000\tTime 0.083 (0.065)\tData 0.017 (0.011)\tLoss 0.1634 (0.1146)\tPrec@1 95.312 (96.074)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [133][90/97], lr: 0.01000\tTime 0.055 (0.063)\tData 0.000 (0.010)\tLoss 0.1582 (0.1184)\tPrec@1 95.312 (95.948)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.6243 (1.6243)\tPrec@1 64.000 (64.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.015 (0.057)\tLoss 1.7486 (1.8613)\tPrec@1 69.000 (62.455)\tPrec@5 97.000 (96.727)\n",
            "Test: [20/100]\tTime 0.045 (0.042)\tLoss 1.9429 (1.9975)\tPrec@1 62.000 (60.619)\tPrec@5 96.000 (96.190)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 2.1246 (2.0250)\tPrec@1 55.000 (60.355)\tPrec@5 94.000 (95.871)\n",
            "Test: [40/100]\tTime 0.024 (0.034)\tLoss 2.1936 (2.0203)\tPrec@1 64.000 (60.561)\tPrec@5 92.000 (95.756)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 1.9855 (2.0031)\tPrec@1 66.000 (61.431)\tPrec@5 95.000 (95.784)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 1.8847 (2.0054)\tPrec@1 58.000 (61.426)\tPrec@5 94.000 (95.607)\n",
            "Test: [70/100]\tTime 0.021 (0.030)\tLoss 2.2327 (1.9962)\tPrec@1 59.000 (61.324)\tPrec@5 98.000 (95.718)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.7351 (1.9793)\tPrec@1 69.000 (61.568)\tPrec@5 97.000 (95.716)\n",
            "Test: [90/100]\tTime 0.029 (0.028)\tLoss 1.5183 (1.9968)\tPrec@1 65.000 (61.330)\tPrec@5 97.000 (95.725)\n",
            "val Results: Prec@1 61.440 Prec@5 95.640 Loss 1.99907\n",
            "val Class Accuracy: [0.981,0.797,0.761,0.670,0.495,0.346,0.738,0.346,0.277,0.733]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [134][0/97], lr: 0.01000\tTime 0.441 (0.441)\tData 0.346 (0.346)\tLoss 0.1907 (0.1907)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][10/97], lr: 0.01000\tTime 0.060 (0.100)\tData 0.007 (0.035)\tLoss 0.1104 (0.1017)\tPrec@1 96.094 (96.733)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][20/97], lr: 0.01000\tTime 0.064 (0.080)\tData 0.007 (0.021)\tLoss 0.0665 (0.1088)\tPrec@1 98.438 (96.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][30/97], lr: 0.01000\tTime 0.058 (0.072)\tData 0.005 (0.016)\tLoss 0.0805 (0.1133)\tPrec@1 97.656 (96.321)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][40/97], lr: 0.01000\tTime 0.054 (0.069)\tData 0.000 (0.013)\tLoss 0.1661 (0.1131)\tPrec@1 94.531 (96.341)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [134][50/97], lr: 0.01000\tTime 0.048 (0.067)\tData 0.007 (0.011)\tLoss 0.1840 (0.1164)\tPrec@1 95.312 (96.078)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [134][60/97], lr: 0.01000\tTime 0.045 (0.065)\tData 0.000 (0.010)\tLoss 0.1540 (0.1182)\tPrec@1 94.531 (96.017)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [134][70/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.007 (0.010)\tLoss 0.1809 (0.1205)\tPrec@1 93.750 (95.940)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [134][80/97], lr: 0.01000\tTime 0.060 (0.063)\tData 0.000 (0.009)\tLoss 0.1183 (0.1246)\tPrec@1 96.094 (95.785)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [134][90/97], lr: 0.01000\tTime 0.031 (0.062)\tData 0.000 (0.008)\tLoss 0.1778 (0.1276)\tPrec@1 93.750 (95.639)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.285 (0.285)\tLoss 1.9895 (1.9895)\tPrec@1 60.000 (60.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.018 (0.055)\tLoss 1.8952 (2.2670)\tPrec@1 64.000 (61.000)\tPrec@5 96.000 (97.091)\n",
            "Test: [20/100]\tTime 0.015 (0.041)\tLoss 2.1020 (2.2855)\tPrec@1 61.000 (60.905)\tPrec@5 95.000 (96.238)\n",
            "Test: [30/100]\tTime 0.028 (0.036)\tLoss 1.7109 (2.2924)\tPrec@1 65.000 (60.774)\tPrec@5 98.000 (95.903)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 2.0547 (2.3219)\tPrec@1 62.000 (60.854)\tPrec@5 95.000 (95.707)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 2.2057 (2.3206)\tPrec@1 63.000 (60.961)\tPrec@5 97.000 (95.745)\n",
            "Test: [60/100]\tTime 0.016 (0.031)\tLoss 1.7435 (2.3232)\tPrec@1 67.000 (60.754)\tPrec@5 94.000 (95.557)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 2.2978 (2.3099)\tPrec@1 58.000 (60.592)\tPrec@5 98.000 (95.704)\n",
            "Test: [80/100]\tTime 0.009 (0.029)\tLoss 2.0340 (2.3049)\tPrec@1 61.000 (60.691)\tPrec@5 97.000 (95.827)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 2.0028 (2.3147)\tPrec@1 57.000 (60.341)\tPrec@5 98.000 (95.945)\n",
            "val Results: Prec@1 60.270 Prec@5 95.970 Loss 2.31658\n",
            "val Class Accuracy: [0.911,0.995,0.741,0.815,0.709,0.239,0.676,0.518,0.308,0.115]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [135][0/97], lr: 0.01000\tTime 0.483 (0.483)\tData 0.400 (0.400)\tLoss 0.0855 (0.0855)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [135][10/97], lr: 0.01000\tTime 0.062 (0.100)\tData 0.000 (0.040)\tLoss 0.1103 (0.0896)\tPrec@1 96.875 (97.301)\tPrec@5 99.219 (99.929)\n",
            "Epoch: [135][20/97], lr: 0.01000\tTime 0.062 (0.079)\tData 0.006 (0.023)\tLoss 0.0882 (0.1004)\tPrec@1 96.875 (96.763)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [135][30/97], lr: 0.01000\tTime 0.064 (0.072)\tData 0.006 (0.016)\tLoss 0.2302 (0.1045)\tPrec@1 92.188 (96.396)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [135][40/97], lr: 0.01000\tTime 0.041 (0.068)\tData 0.000 (0.013)\tLoss 0.0446 (0.0993)\tPrec@1 98.438 (96.475)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [135][50/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.000 (0.011)\tLoss 0.0815 (0.1036)\tPrec@1 96.875 (96.324)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [135][60/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.011 (0.010)\tLoss 0.0401 (0.1049)\tPrec@1 100.000 (96.299)\tPrec@5 100.000 (99.936)\n",
            "Epoch: [135][70/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.010)\tLoss 0.1125 (0.1054)\tPrec@1 96.094 (96.270)\tPrec@5 100.000 (99.945)\n",
            "Epoch: [135][80/97], lr: 0.01000\tTime 0.085 (0.063)\tData 0.002 (0.009)\tLoss 0.1499 (0.1067)\tPrec@1 93.750 (96.219)\tPrec@5 100.000 (99.942)\n",
            "Epoch: [135][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.008)\tLoss 0.1544 (0.1114)\tPrec@1 96.094 (96.068)\tPrec@5 100.000 (99.948)\n",
            "Test: [0/100]\tTime 0.363 (0.363)\tLoss 1.5152 (1.5152)\tPrec@1 66.000 (66.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.026 (0.057)\tLoss 1.3807 (1.6145)\tPrec@1 73.000 (67.636)\tPrec@5 97.000 (95.636)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 1.2846 (1.6498)\tPrec@1 70.000 (67.286)\tPrec@5 95.000 (94.810)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 1.7210 (1.6717)\tPrec@1 67.000 (67.000)\tPrec@5 95.000 (94.774)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 1.6569 (1.6902)\tPrec@1 69.000 (66.780)\tPrec@5 97.000 (95.195)\n",
            "Test: [50/100]\tTime 0.030 (0.032)\tLoss 1.5098 (1.6850)\tPrec@1 71.000 (67.196)\tPrec@5 95.000 (95.431)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.3761 (1.6925)\tPrec@1 71.000 (67.098)\tPrec@5 94.000 (95.443)\n",
            "Test: [70/100]\tTime 0.034 (0.030)\tLoss 1.7946 (1.6759)\tPrec@1 69.000 (67.282)\tPrec@5 95.000 (95.423)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 1.5589 (1.6607)\tPrec@1 64.000 (67.481)\tPrec@5 95.000 (95.506)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 1.5219 (1.6740)\tPrec@1 69.000 (67.209)\tPrec@5 96.000 (95.527)\n",
            "val Results: Prec@1 67.280 Prec@5 95.450 Loss 1.67570\n",
            "val Class Accuracy: [0.934,0.982,0.741,0.520,0.593,0.780,0.786,0.448,0.386,0.558]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [136][0/97], lr: 0.01000\tTime 0.467 (0.467)\tData 0.382 (0.382)\tLoss 0.0759 (0.0759)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][10/97], lr: 0.01000\tTime 0.076 (0.103)\tData 0.000 (0.042)\tLoss 0.1126 (0.0988)\tPrec@1 95.312 (96.449)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][20/97], lr: 0.01000\tTime 0.042 (0.081)\tData 0.000 (0.025)\tLoss 0.1777 (0.1168)\tPrec@1 92.969 (95.982)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.004 (0.019)\tLoss 0.1334 (0.1095)\tPrec@1 95.312 (96.144)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][40/97], lr: 0.01000\tTime 0.064 (0.070)\tData 0.006 (0.015)\tLoss 0.0618 (0.1092)\tPrec@1 97.656 (96.208)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [136][50/97], lr: 0.01000\tTime 0.045 (0.068)\tData 0.000 (0.013)\tLoss 0.0969 (0.1111)\tPrec@1 96.875 (96.094)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [136][60/97], lr: 0.01000\tTime 0.054 (0.066)\tData 0.006 (0.012)\tLoss 0.1443 (0.1131)\tPrec@1 93.750 (96.068)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [136][70/97], lr: 0.01000\tTime 0.059 (0.065)\tData 0.007 (0.011)\tLoss 0.1533 (0.1150)\tPrec@1 92.969 (95.962)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [136][80/97], lr: 0.01000\tTime 0.069 (0.064)\tData 0.006 (0.010)\tLoss 0.1134 (0.1192)\tPrec@1 95.312 (95.824)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [136][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.010)\tLoss 0.2360 (0.1234)\tPrec@1 90.625 (95.647)\tPrec@5 99.219 (99.966)\n",
            "Test: [0/100]\tTime 0.267 (0.267)\tLoss 2.0787 (2.0787)\tPrec@1 56.000 (56.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.028 (0.055)\tLoss 1.8582 (2.3578)\tPrec@1 69.000 (59.182)\tPrec@5 95.000 (95.818)\n",
            "Test: [20/100]\tTime 0.027 (0.042)\tLoss 2.0837 (2.3416)\tPrec@1 60.000 (59.190)\tPrec@5 97.000 (95.857)\n",
            "Test: [30/100]\tTime 0.016 (0.035)\tLoss 2.3104 (2.3489)\tPrec@1 62.000 (59.355)\tPrec@5 93.000 (95.258)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 2.2476 (2.3642)\tPrec@1 54.000 (59.268)\tPrec@5 98.000 (95.220)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 2.2138 (2.3254)\tPrec@1 56.000 (59.471)\tPrec@5 98.000 (95.196)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 2.0176 (2.3350)\tPrec@1 65.000 (59.197)\tPrec@5 95.000 (95.279)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 2.0383 (2.3335)\tPrec@1 65.000 (59.141)\tPrec@5 97.000 (95.282)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 2.1423 (2.3277)\tPrec@1 58.000 (59.185)\tPrec@5 95.000 (95.321)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 1.8428 (2.3493)\tPrec@1 59.000 (58.736)\tPrec@5 98.000 (95.220)\n",
            "val Results: Prec@1 58.680 Prec@5 95.110 Loss 2.35738\n",
            "val Class Accuracy: [0.871,0.952,0.902,0.778,0.571,0.144,0.603,0.502,0.310,0.235]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [137][0/97], lr: 0.01000\tTime 0.436 (0.436)\tData 0.369 (0.369)\tLoss 0.1050 (0.1050)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][10/97], lr: 0.01000\tTime 0.060 (0.103)\tData 0.007 (0.039)\tLoss 0.0871 (0.1072)\tPrec@1 98.438 (96.662)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][20/97], lr: 0.01000\tTime 0.036 (0.081)\tData 0.000 (0.023)\tLoss 0.1242 (0.1176)\tPrec@1 96.875 (96.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][30/97], lr: 0.01000\tTime 0.057 (0.073)\tData 0.007 (0.017)\tLoss 0.1047 (0.1098)\tPrec@1 96.875 (96.295)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [137][40/97], lr: 0.01000\tTime 0.064 (0.070)\tData 0.001 (0.014)\tLoss 0.0589 (0.1033)\tPrec@1 97.656 (96.551)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [137][50/97], lr: 0.01000\tTime 0.080 (0.068)\tData 0.006 (0.012)\tLoss 0.0719 (0.1029)\tPrec@1 97.656 (96.584)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [137][60/97], lr: 0.01000\tTime 0.056 (0.067)\tData 0.010 (0.011)\tLoss 0.0704 (0.1028)\tPrec@1 97.656 (96.606)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [137][70/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.010)\tLoss 0.1582 (0.1060)\tPrec@1 95.312 (96.457)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [137][80/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.000 (0.010)\tLoss 0.0460 (0.1051)\tPrec@1 98.438 (96.470)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [137][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.0855 (0.1050)\tPrec@1 97.656 (96.480)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.267 (0.267)\tLoss 1.5048 (1.5048)\tPrec@1 67.000 (67.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.033 (0.056)\tLoss 1.1234 (1.4153)\tPrec@1 75.000 (68.091)\tPrec@5 95.000 (96.818)\n",
            "Test: [20/100]\tTime 0.017 (0.039)\tLoss 1.2280 (1.4263)\tPrec@1 69.000 (68.286)\tPrec@5 97.000 (96.667)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 1.5946 (1.4577)\tPrec@1 69.000 (67.935)\tPrec@5 96.000 (96.613)\n",
            "Test: [40/100]\tTime 0.038 (0.032)\tLoss 1.3285 (1.4588)\tPrec@1 66.000 (68.122)\tPrec@5 97.000 (96.634)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.4604 (1.4405)\tPrec@1 70.000 (68.608)\tPrec@5 99.000 (96.843)\n",
            "Test: [60/100]\tTime 0.022 (0.029)\tLoss 1.4722 (1.4477)\tPrec@1 66.000 (68.377)\tPrec@5 96.000 (96.754)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 1.6769 (1.4502)\tPrec@1 67.000 (68.197)\tPrec@5 97.000 (96.775)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.2703 (1.4404)\tPrec@1 77.000 (68.494)\tPrec@5 97.000 (96.790)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 1.0839 (1.4502)\tPrec@1 71.000 (68.297)\tPrec@5 97.000 (96.857)\n",
            "val Results: Prec@1 68.110 Prec@5 96.850 Loss 1.45758\n",
            "val Class Accuracy: [0.931,0.970,0.857,0.566,0.615,0.637,0.606,0.497,0.586,0.546]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [138][0/97], lr: 0.01000\tTime 0.367 (0.367)\tData 0.302 (0.302)\tLoss 0.0790 (0.0790)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][10/97], lr: 0.01000\tTime 0.058 (0.105)\tData 0.008 (0.039)\tLoss 0.0628 (0.0951)\tPrec@1 98.438 (96.804)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][20/97], lr: 0.01000\tTime 0.048 (0.082)\tData 0.012 (0.024)\tLoss 0.0798 (0.1040)\tPrec@1 96.875 (96.577)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][30/97], lr: 0.01000\tTime 0.045 (0.073)\tData 0.000 (0.018)\tLoss 0.1300 (0.1034)\tPrec@1 94.531 (96.447)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][40/97], lr: 0.01000\tTime 0.040 (0.069)\tData 0.000 (0.015)\tLoss 0.0554 (0.1034)\tPrec@1 96.875 (96.322)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][50/97], lr: 0.01000\tTime 0.067 (0.068)\tData 0.007 (0.013)\tLoss 0.2254 (0.1078)\tPrec@1 94.531 (96.216)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][60/97], lr: 0.01000\tTime 0.043 (0.066)\tData 0.000 (0.011)\tLoss 0.0793 (0.1068)\tPrec@1 97.656 (96.324)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [138][70/97], lr: 0.01000\tTime 0.041 (0.065)\tData 0.000 (0.010)\tLoss 0.0967 (0.1070)\tPrec@1 96.875 (96.369)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [138][80/97], lr: 0.01000\tTime 0.058 (0.064)\tData 0.007 (0.010)\tLoss 0.1114 (0.1070)\tPrec@1 95.312 (96.393)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [138][90/97], lr: 0.01000\tTime 0.029 (0.063)\tData 0.000 (0.009)\tLoss 0.0781 (0.1068)\tPrec@1 97.656 (96.429)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.4606 (1.4606)\tPrec@1 63.000 (63.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.035 (0.054)\tLoss 1.3119 (1.6230)\tPrec@1 77.000 (66.909)\tPrec@5 95.000 (97.273)\n",
            "Test: [20/100]\tTime 0.030 (0.042)\tLoss 1.2711 (1.6019)\tPrec@1 66.000 (67.190)\tPrec@5 100.000 (96.952)\n",
            "Test: [30/100]\tTime 0.013 (0.034)\tLoss 1.6738 (1.6261)\tPrec@1 62.000 (67.065)\tPrec@5 97.000 (96.968)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.6976 (1.6396)\tPrec@1 63.000 (66.829)\tPrec@5 98.000 (97.220)\n",
            "Test: [50/100]\tTime 0.020 (0.031)\tLoss 1.4246 (1.6224)\tPrec@1 67.000 (67.078)\tPrec@5 98.000 (97.353)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 1.5543 (1.6281)\tPrec@1 71.000 (67.213)\tPrec@5 94.000 (97.246)\n",
            "Test: [70/100]\tTime 0.033 (0.031)\tLoss 1.9147 (1.6371)\tPrec@1 70.000 (67.099)\tPrec@5 97.000 (97.225)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 1.5500 (1.6275)\tPrec@1 70.000 (67.383)\tPrec@5 96.000 (97.247)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.4502 (1.6460)\tPrec@1 66.000 (67.110)\tPrec@5 99.000 (97.264)\n",
            "val Results: Prec@1 67.040 Prec@5 97.270 Loss 1.65226\n",
            "val Class Accuracy: [0.939,0.973,0.740,0.679,0.803,0.721,0.519,0.507,0.348,0.475]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [139][0/97], lr: 0.01000\tTime 0.516 (0.516)\tData 0.446 (0.446)\tLoss 0.0606 (0.0606)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][10/97], lr: 0.01000\tTime 0.053 (0.102)\tData 0.000 (0.045)\tLoss 0.1929 (0.0896)\tPrec@1 92.969 (97.372)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][20/97], lr: 0.01000\tTime 0.050 (0.082)\tData 0.000 (0.025)\tLoss 0.0735 (0.0868)\tPrec@1 97.656 (97.098)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][30/97], lr: 0.01000\tTime 0.044 (0.074)\tData 0.000 (0.019)\tLoss 0.0506 (0.1001)\tPrec@1 98.438 (96.573)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][40/97], lr: 0.01000\tTime 0.064 (0.069)\tData 0.005 (0.015)\tLoss 0.0537 (0.1008)\tPrec@1 98.438 (96.513)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][50/97], lr: 0.01000\tTime 0.044 (0.067)\tData 0.000 (0.013)\tLoss 0.0861 (0.1024)\tPrec@1 96.094 (96.446)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][60/97], lr: 0.01000\tTime 0.062 (0.066)\tData 0.007 (0.012)\tLoss 0.1252 (0.1046)\tPrec@1 95.312 (96.350)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.006 (0.011)\tLoss 0.0866 (0.1077)\tPrec@1 96.094 (96.248)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][80/97], lr: 0.01000\tTime 0.042 (0.064)\tData 0.000 (0.010)\tLoss 0.1515 (0.1105)\tPrec@1 93.750 (96.190)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][90/97], lr: 0.01000\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.0919 (0.1143)\tPrec@1 96.875 (96.008)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.263 (0.263)\tLoss 1.3720 (1.3720)\tPrec@1 71.000 (71.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.023 (0.054)\tLoss 1.0407 (1.3318)\tPrec@1 78.000 (69.909)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/100]\tTime 0.016 (0.041)\tLoss 1.5077 (1.2815)\tPrec@1 68.000 (70.952)\tPrec@5 98.000 (96.810)\n",
            "Test: [30/100]\tTime 0.019 (0.036)\tLoss 1.2661 (1.2929)\tPrec@1 70.000 (70.774)\tPrec@5 97.000 (96.774)\n",
            "Test: [40/100]\tTime 0.011 (0.034)\tLoss 1.1305 (1.2986)\tPrec@1 68.000 (70.976)\tPrec@5 98.000 (96.805)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 1.1642 (1.2830)\tPrec@1 74.000 (71.216)\tPrec@5 97.000 (96.804)\n",
            "Test: [60/100]\tTime 0.023 (0.031)\tLoss 1.1470 (1.2997)\tPrec@1 74.000 (70.918)\tPrec@5 97.000 (96.721)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 1.1649 (1.2876)\tPrec@1 67.000 (71.014)\tPrec@5 99.000 (96.718)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.2916 (1.2802)\tPrec@1 68.000 (70.926)\tPrec@5 96.000 (96.753)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 0.7735 (1.2893)\tPrec@1 77.000 (70.758)\tPrec@5 98.000 (96.780)\n",
            "val Results: Prec@1 70.630 Prec@5 96.800 Loss 1.29307\n",
            "val Class Accuracy: [0.847,0.921,0.818,0.634,0.851,0.585,0.750,0.435,0.589,0.633]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [140][0/97], lr: 0.01000\tTime 0.414 (0.414)\tData 0.317 (0.317)\tLoss 0.0833 (0.0833)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][10/97], lr: 0.01000\tTime 0.078 (0.104)\tData 0.003 (0.034)\tLoss 0.0357 (0.0960)\tPrec@1 100.000 (96.804)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [140][20/97], lr: 0.01000\tTime 0.066 (0.082)\tData 0.007 (0.021)\tLoss 0.1163 (0.1200)\tPrec@1 93.750 (95.647)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [140][30/97], lr: 0.01000\tTime 0.038 (0.075)\tData 0.002 (0.015)\tLoss 0.1056 (0.1210)\tPrec@1 96.875 (95.691)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [140][40/97], lr: 0.01000\tTime 0.074 (0.070)\tData 0.005 (0.013)\tLoss 0.1274 (0.1157)\tPrec@1 95.312 (95.903)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [140][50/97], lr: 0.01000\tTime 0.056 (0.068)\tData 0.007 (0.011)\tLoss 0.1257 (0.1142)\tPrec@1 92.969 (95.971)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [140][60/97], lr: 0.01000\tTime 0.057 (0.066)\tData 0.007 (0.010)\tLoss 0.1999 (0.1202)\tPrec@1 91.406 (95.774)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [140][70/97], lr: 0.01000\tTime 0.072 (0.065)\tData 0.000 (0.010)\tLoss 0.1023 (0.1239)\tPrec@1 96.094 (95.632)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [140][80/97], lr: 0.01000\tTime 0.069 (0.064)\tData 0.011 (0.009)\tLoss 0.0880 (0.1233)\tPrec@1 95.312 (95.631)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [140][90/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.008)\tLoss 0.0767 (0.1239)\tPrec@1 98.438 (95.682)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 2.4992 (2.4992)\tPrec@1 54.000 (54.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.053)\tLoss 1.9420 (2.3841)\tPrec@1 67.000 (58.364)\tPrec@5 99.000 (96.455)\n",
            "Test: [20/100]\tTime 0.018 (0.040)\tLoss 1.8055 (2.4200)\tPrec@1 63.000 (57.714)\tPrec@5 97.000 (96.667)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 2.3657 (2.3842)\tPrec@1 57.000 (57.710)\tPrec@5 98.000 (96.548)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 2.4991 (2.3827)\tPrec@1 54.000 (57.561)\tPrec@5 97.000 (96.415)\n",
            "Test: [50/100]\tTime 0.018 (0.033)\tLoss 1.9697 (2.3459)\tPrec@1 57.000 (57.961)\tPrec@5 97.000 (96.627)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 1.7539 (2.3426)\tPrec@1 63.000 (57.869)\tPrec@5 96.000 (96.508)\n",
            "Test: [70/100]\tTime 0.029 (0.030)\tLoss 2.6567 (2.3581)\tPrec@1 61.000 (57.845)\tPrec@5 97.000 (96.380)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 2.0142 (2.3296)\tPrec@1 69.000 (58.148)\tPrec@5 99.000 (96.457)\n",
            "Test: [90/100]\tTime 0.031 (0.029)\tLoss 2.0993 (2.3626)\tPrec@1 57.000 (57.615)\tPrec@5 97.000 (96.495)\n",
            "val Results: Prec@1 57.450 Prec@5 96.470 Loss 2.36811\n",
            "val Class Accuracy: [0.941,0.900,0.891,0.358,0.573,0.585,0.636,0.454,0.095,0.312]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [141][0/97], lr: 0.01000\tTime 0.513 (0.513)\tData 0.403 (0.403)\tLoss 0.0849 (0.0849)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [141][10/97], lr: 0.01000\tTime 0.036 (0.100)\tData 0.000 (0.040)\tLoss 0.0793 (0.1019)\tPrec@1 96.875 (96.236)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [141][20/97], lr: 0.01000\tTime 0.032 (0.079)\tData 0.000 (0.023)\tLoss 0.0585 (0.0949)\tPrec@1 98.438 (96.726)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [141][30/97], lr: 0.01000\tTime 0.060 (0.072)\tData 0.000 (0.017)\tLoss 0.1737 (0.0999)\tPrec@1 95.312 (96.598)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [141][40/97], lr: 0.01000\tTime 0.058 (0.069)\tData 0.005 (0.015)\tLoss 0.1017 (0.0983)\tPrec@1 96.875 (96.723)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [141][50/97], lr: 0.01000\tTime 0.074 (0.067)\tData 0.000 (0.013)\tLoss 0.0929 (0.0972)\tPrec@1 96.875 (96.661)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [141][60/97], lr: 0.01000\tTime 0.051 (0.066)\tData 0.007 (0.012)\tLoss 0.1954 (0.1037)\tPrec@1 92.188 (96.401)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [141][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.005 (0.010)\tLoss 0.0783 (0.1075)\tPrec@1 97.656 (96.281)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [141][80/97], lr: 0.01000\tTime 0.055 (0.063)\tData 0.003 (0.010)\tLoss 0.1127 (0.1100)\tPrec@1 96.094 (96.200)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [141][90/97], lr: 0.01000\tTime 0.051 (0.062)\tData 0.000 (0.009)\tLoss 0.0769 (0.1093)\tPrec@1 96.094 (96.171)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 2.4169 (2.4169)\tPrec@1 54.000 (54.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.020 (0.057)\tLoss 1.3921 (2.0569)\tPrec@1 74.000 (62.545)\tPrec@5 96.000 (96.273)\n",
            "Test: [20/100]\tTime 0.016 (0.041)\tLoss 1.7500 (2.0773)\tPrec@1 61.000 (61.714)\tPrec@5 94.000 (95.810)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 2.0156 (2.1014)\tPrec@1 61.000 (61.742)\tPrec@5 95.000 (95.419)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 2.1094 (2.1325)\tPrec@1 61.000 (61.439)\tPrec@5 96.000 (95.098)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.9016 (2.0874)\tPrec@1 68.000 (62.451)\tPrec@5 96.000 (95.196)\n",
            "Test: [60/100]\tTime 0.020 (0.031)\tLoss 1.5859 (2.0832)\tPrec@1 70.000 (62.328)\tPrec@5 95.000 (95.016)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 2.2679 (2.0710)\tPrec@1 61.000 (62.507)\tPrec@5 98.000 (95.183)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.7623 (2.0632)\tPrec@1 68.000 (62.543)\tPrec@5 93.000 (95.160)\n",
            "Test: [90/100]\tTime 0.031 (0.029)\tLoss 1.9512 (2.0758)\tPrec@1 62.000 (62.495)\tPrec@5 96.000 (95.143)\n",
            "val Results: Prec@1 62.350 Prec@5 95.130 Loss 2.07964\n",
            "val Class Accuracy: [0.943,0.980,0.730,0.801,0.656,0.444,0.841,0.358,0.192,0.290]\n",
            "Best Prec@1: 71.520\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [142][0/97], lr: 0.01000\tTime 0.500 (0.500)\tData 0.424 (0.424)\tLoss 0.1594 (0.1594)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][10/97], lr: 0.01000\tTime 0.049 (0.103)\tData 0.000 (0.043)\tLoss 0.0822 (0.0984)\tPrec@1 96.094 (96.023)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][20/97], lr: 0.01000\tTime 0.060 (0.082)\tData 0.008 (0.025)\tLoss 0.1381 (0.0964)\tPrec@1 96.094 (96.466)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][30/97], lr: 0.01000\tTime 0.045 (0.074)\tData 0.000 (0.018)\tLoss 0.1509 (0.0994)\tPrec@1 95.312 (96.447)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][40/97], lr: 0.01000\tTime 0.071 (0.070)\tData 0.007 (0.015)\tLoss 0.1595 (0.1000)\tPrec@1 94.531 (96.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][50/97], lr: 0.01000\tTime 0.041 (0.067)\tData 0.000 (0.012)\tLoss 0.1163 (0.0985)\tPrec@1 96.094 (96.523)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [142][60/97], lr: 0.01000\tTime 0.056 (0.066)\tData 0.000 (0.011)\tLoss 0.1638 (0.1000)\tPrec@1 95.312 (96.516)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [142][70/97], lr: 0.01000\tTime 0.035 (0.064)\tData 0.000 (0.010)\tLoss 0.1032 (0.1046)\tPrec@1 93.750 (96.237)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [142][80/97], lr: 0.01000\tTime 0.046 (0.063)\tData 0.000 (0.010)\tLoss 0.1648 (0.1069)\tPrec@1 93.750 (96.181)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [142][90/97], lr: 0.01000\tTime 0.036 (0.062)\tData 0.000 (0.009)\tLoss 0.1339 (0.1079)\tPrec@1 93.750 (96.128)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 1.1164 (1.1164)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.036 (0.055)\tLoss 1.2572 (1.1516)\tPrec@1 73.000 (72.727)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.021 (0.041)\tLoss 1.1142 (1.1867)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (97.952)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 1.4688 (1.1936)\tPrec@1 71.000 (72.323)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.023 (0.032)\tLoss 1.0497 (1.1945)\tPrec@1 75.000 (72.220)\tPrec@5 97.000 (97.976)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 0.9506 (1.1830)\tPrec@1 76.000 (72.647)\tPrec@5 97.000 (98.000)\n",
            "Test: [60/100]\tTime 0.011 (0.030)\tLoss 1.3432 (1.2020)\tPrec@1 69.000 (72.361)\tPrec@5 96.000 (97.820)\n",
            "Test: [70/100]\tTime 0.035 (0.029)\tLoss 1.2762 (1.1977)\tPrec@1 72.000 (72.282)\tPrec@5 98.000 (97.859)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 0.9457 (1.1877)\tPrec@1 80.000 (72.333)\tPrec@5 100.000 (97.938)\n",
            "Test: [90/100]\tTime 0.031 (0.028)\tLoss 0.7478 (1.2000)\tPrec@1 79.000 (72.132)\tPrec@5 100.000 (97.890)\n",
            "val Results: Prec@1 72.100 Prec@5 97.800 Loss 1.19984\n",
            "val Class Accuracy: [0.945,0.922,0.725,0.734,0.691,0.509,0.755,0.712,0.488,0.729]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [143][0/97], lr: 0.01000\tTime 0.508 (0.508)\tData 0.416 (0.416)\tLoss 0.1415 (0.1415)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][10/97], lr: 0.01000\tTime 0.077 (0.104)\tData 0.010 (0.042)\tLoss 0.0778 (0.0989)\tPrec@1 98.438 (96.733)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][20/97], lr: 0.01000\tTime 0.040 (0.081)\tData 0.000 (0.024)\tLoss 0.1184 (0.1039)\tPrec@1 95.312 (96.652)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [143][30/97], lr: 0.01000\tTime 0.049 (0.073)\tData 0.007 (0.019)\tLoss 0.1650 (0.1074)\tPrec@1 95.312 (96.472)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [143][40/97], lr: 0.01000\tTime 0.053 (0.070)\tData 0.007 (0.015)\tLoss 0.0385 (0.0996)\tPrec@1 99.219 (96.761)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [143][50/97], lr: 0.01000\tTime 0.047 (0.067)\tData 0.000 (0.013)\tLoss 0.1620 (0.1022)\tPrec@1 93.750 (96.553)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [143][60/97], lr: 0.01000\tTime 0.073 (0.066)\tData 0.018 (0.012)\tLoss 0.1225 (0.1033)\tPrec@1 96.094 (96.388)\tPrec@5 100.000 (99.949)\n",
            "Epoch: [143][70/97], lr: 0.01000\tTime 0.048 (0.064)\tData 0.002 (0.011)\tLoss 0.1443 (0.1067)\tPrec@1 96.094 (96.259)\tPrec@5 100.000 (99.956)\n",
            "Epoch: [143][80/97], lr: 0.01000\tTime 0.052 (0.064)\tData 0.004 (0.010)\tLoss 0.0973 (0.1066)\tPrec@1 96.094 (96.267)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [143][90/97], lr: 0.01000\tTime 0.033 (0.062)\tData 0.000 (0.009)\tLoss 0.0730 (0.1066)\tPrec@1 96.875 (96.205)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 2.4402 (2.4402)\tPrec@1 56.000 (56.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.035 (0.050)\tLoss 2.1159 (2.2681)\tPrec@1 68.000 (59.636)\tPrec@5 93.000 (96.273)\n",
            "Test: [20/100]\tTime 0.017 (0.039)\tLoss 1.7538 (2.2515)\tPrec@1 68.000 (60.286)\tPrec@5 95.000 (95.762)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 2.1076 (2.2234)\tPrec@1 62.000 (60.839)\tPrec@5 96.000 (95.677)\n",
            "Test: [40/100]\tTime 0.051 (0.034)\tLoss 2.1644 (2.2288)\tPrec@1 59.000 (60.732)\tPrec@5 97.000 (95.610)\n",
            "Test: [50/100]\tTime 0.034 (0.031)\tLoss 2.0530 (2.2100)\tPrec@1 66.000 (61.392)\tPrec@5 93.000 (95.686)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.7822 (2.2036)\tPrec@1 64.000 (60.984)\tPrec@5 96.000 (95.492)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 2.3767 (2.2108)\tPrec@1 62.000 (60.803)\tPrec@5 97.000 (95.507)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 1.7520 (2.1920)\tPrec@1 66.000 (60.889)\tPrec@5 98.000 (95.679)\n",
            "Test: [90/100]\tTime 0.038 (0.028)\tLoss 2.0031 (2.2220)\tPrec@1 64.000 (60.604)\tPrec@5 99.000 (95.637)\n",
            "val Results: Prec@1 60.670 Prec@5 95.590 Loss 2.22417\n",
            "val Class Accuracy: [0.978,0.931,0.657,0.771,0.836,0.448,0.227,0.557,0.272,0.390]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [144][0/97], lr: 0.01000\tTime 0.463 (0.463)\tData 0.386 (0.386)\tLoss 0.1766 (0.1766)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][10/97], lr: 0.01000\tTime 0.053 (0.101)\tData 0.007 (0.042)\tLoss 0.1332 (0.1126)\tPrec@1 93.750 (96.023)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][20/97], lr: 0.01000\tTime 0.057 (0.080)\tData 0.000 (0.023)\tLoss 0.0217 (0.1120)\tPrec@1 99.219 (96.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][30/97], lr: 0.01000\tTime 0.066 (0.074)\tData 0.000 (0.016)\tLoss 0.2033 (0.1123)\tPrec@1 93.750 (95.993)\tPrec@5 99.219 (99.975)\n",
            "Epoch: [144][40/97], lr: 0.01000\tTime 0.065 (0.070)\tData 0.000 (0.013)\tLoss 0.1295 (0.1134)\tPrec@1 94.531 (95.998)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [144][50/97], lr: 0.01000\tTime 0.083 (0.068)\tData 0.001 (0.012)\tLoss 0.1192 (0.1126)\tPrec@1 96.875 (95.987)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [144][60/97], lr: 0.01000\tTime 0.044 (0.066)\tData 0.000 (0.010)\tLoss 0.1194 (0.1152)\tPrec@1 95.312 (95.902)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [144][70/97], lr: 0.01000\tTime 0.053 (0.064)\tData 0.007 (0.009)\tLoss 0.0605 (0.1177)\tPrec@1 96.875 (95.819)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [144][80/97], lr: 0.01000\tTime 0.044 (0.063)\tData 0.003 (0.009)\tLoss 0.1557 (0.1198)\tPrec@1 95.312 (95.766)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [144][90/97], lr: 0.01000\tTime 0.037 (0.062)\tData 0.000 (0.008)\tLoss 0.1915 (0.1212)\tPrec@1 92.969 (95.699)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 2.4204 (2.4204)\tPrec@1 55.000 (55.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.040 (0.053)\tLoss 1.8592 (2.4549)\tPrec@1 67.000 (57.636)\tPrec@5 97.000 (96.091)\n",
            "Test: [20/100]\tTime 0.028 (0.043)\tLoss 2.0035 (2.5116)\tPrec@1 58.000 (57.429)\tPrec@5 94.000 (95.667)\n",
            "Test: [30/100]\tTime 0.041 (0.037)\tLoss 2.3318 (2.5313)\tPrec@1 53.000 (57.387)\tPrec@5 95.000 (95.645)\n",
            "Test: [40/100]\tTime 0.013 (0.034)\tLoss 2.1066 (2.5321)\tPrec@1 61.000 (57.098)\tPrec@5 95.000 (95.683)\n",
            "Test: [50/100]\tTime 0.052 (0.033)\tLoss 2.3478 (2.5256)\tPrec@1 64.000 (57.569)\tPrec@5 95.000 (95.725)\n",
            "Test: [60/100]\tTime 0.013 (0.031)\tLoss 1.9191 (2.5166)\tPrec@1 63.000 (57.361)\tPrec@5 95.000 (95.344)\n",
            "Test: [70/100]\tTime 0.011 (0.030)\tLoss 2.7552 (2.5044)\tPrec@1 53.000 (57.493)\tPrec@5 93.000 (95.268)\n",
            "Test: [80/100]\tTime 0.040 (0.030)\tLoss 2.5110 (2.4903)\tPrec@1 58.000 (57.543)\tPrec@5 95.000 (95.395)\n",
            "Test: [90/100]\tTime 0.037 (0.029)\tLoss 2.5388 (2.5055)\tPrec@1 60.000 (57.549)\tPrec@5 96.000 (95.374)\n",
            "val Results: Prec@1 57.380 Prec@5 95.350 Loss 2.51974\n",
            "val Class Accuracy: [0.983,0.975,0.595,0.623,0.464,0.481,0.842,0.404,0.308,0.063]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [145][0/97], lr: 0.01000\tTime 0.411 (0.411)\tData 0.319 (0.319)\tLoss 0.1069 (0.1069)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][10/97], lr: 0.01000\tTime 0.063 (0.102)\tData 0.000 (0.036)\tLoss 0.1481 (0.1165)\tPrec@1 94.531 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][20/97], lr: 0.01000\tTime 0.046 (0.082)\tData 0.002 (0.021)\tLoss 0.1574 (0.1274)\tPrec@1 93.750 (95.610)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][30/97], lr: 0.01000\tTime 0.052 (0.074)\tData 0.000 (0.016)\tLoss 0.1005 (0.1223)\tPrec@1 96.875 (95.741)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][40/97], lr: 0.01000\tTime 0.065 (0.070)\tData 0.000 (0.013)\tLoss 0.0720 (0.1176)\tPrec@1 99.219 (96.018)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][50/97], lr: 0.01000\tTime 0.046 (0.067)\tData 0.000 (0.011)\tLoss 0.1078 (0.1165)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][60/97], lr: 0.01000\tTime 0.065 (0.066)\tData 0.007 (0.010)\tLoss 0.2263 (0.1167)\tPrec@1 92.188 (96.030)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][70/97], lr: 0.01000\tTime 0.053 (0.064)\tData 0.006 (0.009)\tLoss 0.0784 (0.1154)\tPrec@1 96.094 (96.050)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [145][80/97], lr: 0.01000\tTime 0.045 (0.063)\tData 0.004 (0.009)\tLoss 0.1288 (0.1151)\tPrec@1 95.312 (96.084)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [145][90/97], lr: 0.01000\tTime 0.028 (0.062)\tData 0.000 (0.008)\tLoss 0.2279 (0.1168)\tPrec@1 92.188 (95.991)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.3459 (1.3459)\tPrec@1 71.000 (71.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.029 (0.056)\tLoss 1.4935 (1.8052)\tPrec@1 74.000 (65.909)\tPrec@5 95.000 (95.909)\n",
            "Test: [20/100]\tTime 0.028 (0.039)\tLoss 1.9138 (1.7972)\tPrec@1 64.000 (65.524)\tPrec@5 94.000 (95.667)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.8176 (1.8252)\tPrec@1 67.000 (65.290)\tPrec@5 92.000 (95.258)\n",
            "Test: [40/100]\tTime 0.035 (0.033)\tLoss 1.4874 (1.8321)\tPrec@1 66.000 (65.244)\tPrec@5 97.000 (95.146)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 1.8005 (1.8170)\tPrec@1 65.000 (65.392)\tPrec@5 97.000 (95.392)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 1.8170 (1.8407)\tPrec@1 64.000 (65.016)\tPrec@5 93.000 (95.197)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 2.0108 (1.8319)\tPrec@1 66.000 (64.944)\tPrec@5 95.000 (95.239)\n",
            "Test: [80/100]\tTime 0.032 (0.029)\tLoss 1.5656 (1.8227)\tPrec@1 72.000 (64.914)\tPrec@5 96.000 (95.358)\n",
            "Test: [90/100]\tTime 0.025 (0.028)\tLoss 1.2884 (1.8273)\tPrec@1 69.000 (64.758)\tPrec@5 98.000 (95.440)\n",
            "val Results: Prec@1 64.650 Prec@5 95.470 Loss 1.83684\n",
            "val Class Accuracy: [0.957,0.964,0.809,0.617,0.803,0.375,0.671,0.407,0.502,0.360]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [146][0/97], lr: 0.01000\tTime 0.490 (0.490)\tData 0.403 (0.403)\tLoss 0.1360 (0.1360)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [146][10/97], lr: 0.01000\tTime 0.064 (0.101)\tData 0.005 (0.041)\tLoss 0.0387 (0.0942)\tPrec@1 99.219 (96.520)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [146][20/97], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.024)\tLoss 0.1460 (0.1069)\tPrec@1 94.531 (96.354)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [146][30/97], lr: 0.01000\tTime 0.054 (0.072)\tData 0.000 (0.017)\tLoss 0.1065 (0.1055)\tPrec@1 96.094 (96.346)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [146][40/97], lr: 0.01000\tTime 0.046 (0.068)\tData 0.007 (0.015)\tLoss 0.0406 (0.1094)\tPrec@1 99.219 (96.341)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [146][50/97], lr: 0.01000\tTime 0.064 (0.066)\tData 0.000 (0.012)\tLoss 0.1475 (0.1123)\tPrec@1 93.750 (96.140)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [146][60/97], lr: 0.01000\tTime 0.066 (0.065)\tData 0.015 (0.012)\tLoss 0.0933 (0.1168)\tPrec@1 98.438 (95.991)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [146][70/97], lr: 0.01000\tTime 0.036 (0.064)\tData 0.000 (0.011)\tLoss 0.1212 (0.1176)\tPrec@1 94.531 (95.907)\tPrec@5 100.000 (99.967)\n",
            "Epoch: [146][80/97], lr: 0.01000\tTime 0.066 (0.064)\tData 0.011 (0.010)\tLoss 0.1740 (0.1234)\tPrec@1 92.969 (95.689)\tPrec@5 100.000 (99.961)\n",
            "Epoch: [146][90/97], lr: 0.01000\tTime 0.039 (0.062)\tData 0.000 (0.009)\tLoss 0.1092 (0.1245)\tPrec@1 96.094 (95.622)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 1.7904 (1.7904)\tPrec@1 58.000 (58.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.020 (0.055)\tLoss 1.6042 (1.7020)\tPrec@1 67.000 (63.182)\tPrec@5 94.000 (96.273)\n",
            "Test: [20/100]\tTime 0.033 (0.041)\tLoss 1.6435 (1.6338)\tPrec@1 66.000 (65.333)\tPrec@5 96.000 (96.048)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 1.8345 (1.6868)\tPrec@1 61.000 (65.000)\tPrec@5 93.000 (95.871)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 1.5163 (1.7019)\tPrec@1 68.000 (64.829)\tPrec@5 98.000 (96.073)\n",
            "Test: [50/100]\tTime 0.046 (0.031)\tLoss 1.3550 (1.6731)\tPrec@1 68.000 (65.137)\tPrec@5 97.000 (96.118)\n",
            "Test: [60/100]\tTime 0.047 (0.031)\tLoss 1.9094 (1.6905)\tPrec@1 61.000 (65.049)\tPrec@5 94.000 (96.049)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 1.8006 (1.6810)\tPrec@1 66.000 (65.028)\tPrec@5 98.000 (96.141)\n",
            "Test: [80/100]\tTime 0.032 (0.030)\tLoss 1.6945 (1.6687)\tPrec@1 64.000 (64.938)\tPrec@5 96.000 (96.198)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.6889 (1.6835)\tPrec@1 68.000 (64.560)\tPrec@5 98.000 (96.209)\n",
            "val Results: Prec@1 64.380 Prec@5 96.070 Loss 1.69826\n",
            "val Class Accuracy: [0.882,0.975,0.712,0.661,0.891,0.673,0.395,0.312,0.575,0.362]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [147][0/97], lr: 0.01000\tTime 0.521 (0.521)\tData 0.424 (0.424)\tLoss 0.1693 (0.1693)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][10/97], lr: 0.01000\tTime 0.070 (0.103)\tData 0.000 (0.042)\tLoss 0.0760 (0.1067)\tPrec@1 97.656 (96.591)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][20/97], lr: 0.01000\tTime 0.056 (0.080)\tData 0.002 (0.023)\tLoss 0.0881 (0.1107)\tPrec@1 97.656 (96.317)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [147][30/97], lr: 0.01000\tTime 0.060 (0.074)\tData 0.001 (0.017)\tLoss 0.1717 (0.1107)\tPrec@1 93.750 (96.421)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [147][40/97], lr: 0.01000\tTime 0.040 (0.069)\tData 0.000 (0.015)\tLoss 0.1007 (0.1028)\tPrec@1 96.875 (96.665)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [147][50/97], lr: 0.01000\tTime 0.051 (0.068)\tData 0.007 (0.013)\tLoss 0.1032 (0.1024)\tPrec@1 96.094 (96.569)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [147][60/97], lr: 0.01000\tTime 0.068 (0.066)\tData 0.000 (0.011)\tLoss 0.1637 (0.1014)\tPrec@1 96.094 (96.606)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [147][70/97], lr: 0.01000\tTime 0.058 (0.065)\tData 0.006 (0.010)\tLoss 0.0885 (0.0999)\tPrec@1 96.875 (96.633)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [147][80/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.005 (0.010)\tLoss 0.0655 (0.0986)\tPrec@1 98.438 (96.682)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [147][90/97], lr: 0.01000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.0949 (0.0975)\tPrec@1 97.656 (96.720)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.322 (0.322)\tLoss 1.6003 (1.6003)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.029 (0.053)\tLoss 1.6924 (1.7129)\tPrec@1 70.000 (66.364)\tPrec@5 93.000 (97.000)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 1.7291 (1.7803)\tPrec@1 62.000 (65.429)\tPrec@5 97.000 (96.762)\n",
            "Test: [30/100]\tTime 0.021 (0.034)\tLoss 1.8618 (1.8017)\tPrec@1 68.000 (65.194)\tPrec@5 93.000 (96.581)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 1.7336 (1.7950)\tPrec@1 67.000 (64.878)\tPrec@5 98.000 (96.805)\n",
            "Test: [50/100]\tTime 0.034 (0.031)\tLoss 1.6216 (1.7746)\tPrec@1 69.000 (65.529)\tPrec@5 98.000 (96.922)\n",
            "Test: [60/100]\tTime 0.030 (0.030)\tLoss 1.5829 (1.7907)\tPrec@1 71.000 (65.066)\tPrec@5 94.000 (96.820)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 1.7278 (1.7791)\tPrec@1 65.000 (64.930)\tPrec@5 97.000 (96.972)\n",
            "Test: [80/100]\tTime 0.018 (0.028)\tLoss 1.4121 (1.7482)\tPrec@1 73.000 (65.259)\tPrec@5 98.000 (97.037)\n",
            "Test: [90/100]\tTime 0.016 (0.028)\tLoss 1.3143 (1.7587)\tPrec@1 69.000 (65.121)\tPrec@5 98.000 (97.022)\n",
            "val Results: Prec@1 65.120 Prec@5 96.980 Loss 1.76625\n",
            "val Class Accuracy: [0.948,0.986,0.742,0.792,0.656,0.498,0.648,0.415,0.392,0.435]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [148][0/97], lr: 0.01000\tTime 0.508 (0.508)\tData 0.327 (0.327)\tLoss 0.0773 (0.0773)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][10/97], lr: 0.01000\tTime 0.132 (0.139)\tData 0.003 (0.041)\tLoss 0.0584 (0.0707)\tPrec@1 99.219 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][20/97], lr: 0.01000\tTime 0.047 (0.114)\tData 0.000 (0.025)\tLoss 0.1463 (0.0775)\tPrec@1 95.312 (97.321)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][30/97], lr: 0.01000\tTime 0.077 (0.105)\tData 0.013 (0.020)\tLoss 0.1947 (0.0855)\tPrec@1 94.531 (96.925)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][40/97], lr: 0.01000\tTime 0.075 (0.101)\tData 0.007 (0.017)\tLoss 0.1325 (0.0932)\tPrec@1 95.312 (96.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][50/97], lr: 0.01000\tTime 0.058 (0.094)\tData 0.005 (0.015)\tLoss 0.1832 (0.0970)\tPrec@1 94.531 (96.584)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][60/97], lr: 0.01000\tTime 0.070 (0.088)\tData 0.006 (0.013)\tLoss 0.0891 (0.1000)\tPrec@1 96.875 (96.542)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][70/97], lr: 0.01000\tTime 0.078 (0.084)\tData 0.010 (0.012)\tLoss 0.0789 (0.0995)\tPrec@1 96.875 (96.600)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][80/97], lr: 0.01000\tTime 0.058 (0.080)\tData 0.006 (0.011)\tLoss 0.1541 (0.1038)\tPrec@1 93.750 (96.373)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [148][90/97], lr: 0.01000\tTime 0.037 (0.077)\tData 0.000 (0.010)\tLoss 0.1343 (0.1092)\tPrec@1 94.531 (96.240)\tPrec@5 100.000 (99.966)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 2.3536 (2.3536)\tPrec@1 56.000 (56.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.025 (0.058)\tLoss 1.8803 (2.5400)\tPrec@1 71.000 (57.364)\tPrec@5 96.000 (96.727)\n",
            "Test: [20/100]\tTime 0.027 (0.043)\tLoss 1.7671 (2.5386)\tPrec@1 69.000 (57.000)\tPrec@5 98.000 (96.190)\n",
            "Test: [30/100]\tTime 0.019 (0.037)\tLoss 2.7951 (2.5812)\tPrec@1 52.000 (56.548)\tPrec@5 96.000 (96.032)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 2.6988 (2.5902)\tPrec@1 55.000 (56.171)\tPrec@5 95.000 (96.000)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 2.7899 (2.5671)\tPrec@1 54.000 (56.725)\tPrec@5 97.000 (96.157)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 2.0140 (2.5460)\tPrec@1 63.000 (56.820)\tPrec@5 98.000 (96.066)\n",
            "Test: [70/100]\tTime 0.013 (0.030)\tLoss 2.8285 (2.5200)\tPrec@1 56.000 (57.113)\tPrec@5 97.000 (96.155)\n",
            "Test: [80/100]\tTime 0.010 (0.030)\tLoss 2.2378 (2.5027)\tPrec@1 57.000 (57.247)\tPrec@5 96.000 (96.210)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 2.2103 (2.5235)\tPrec@1 56.000 (56.912)\tPrec@5 96.000 (96.165)\n",
            "val Results: Prec@1 56.860 Prec@5 96.050 Loss 2.52897\n",
            "val Class Accuracy: [0.955,0.972,0.655,0.716,0.327,0.769,0.386,0.359,0.252,0.295]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [149][0/97], lr: 0.01000\tTime 0.489 (0.489)\tData 0.389 (0.389)\tLoss 0.2285 (0.2285)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][10/97], lr: 0.01000\tTime 0.067 (0.100)\tData 0.000 (0.039)\tLoss 0.1387 (0.1354)\tPrec@1 92.969 (94.744)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [149][20/97], lr: 0.01000\tTime 0.048 (0.081)\tData 0.000 (0.023)\tLoss 0.0813 (0.1218)\tPrec@1 98.438 (95.275)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [149][30/97], lr: 0.01000\tTime 0.059 (0.073)\tData 0.009 (0.017)\tLoss 0.0877 (0.1187)\tPrec@1 97.656 (95.539)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [149][40/97], lr: 0.01000\tTime 0.055 (0.069)\tData 0.000 (0.014)\tLoss 0.0829 (0.1165)\tPrec@1 95.312 (95.713)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [149][50/97], lr: 0.01000\tTime 0.073 (0.067)\tData 0.000 (0.012)\tLoss 0.2233 (0.1154)\tPrec@1 94.531 (95.803)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [149][60/97], lr: 0.01000\tTime 0.056 (0.066)\tData 0.007 (0.011)\tLoss 0.0760 (0.1109)\tPrec@1 97.656 (95.966)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [149][70/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.000 (0.010)\tLoss 0.1098 (0.1065)\tPrec@1 96.094 (96.127)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [149][80/97], lr: 0.01000\tTime 0.054 (0.064)\tData 0.007 (0.009)\tLoss 0.1958 (0.1069)\tPrec@1 92.969 (96.152)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [149][90/97], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 0.0920 (0.1081)\tPrec@1 97.656 (96.171)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.276 (0.276)\tLoss 1.5373 (1.5373)\tPrec@1 60.000 (60.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.023 (0.055)\tLoss 1.1127 (1.6777)\tPrec@1 75.000 (64.182)\tPrec@5 98.000 (96.909)\n",
            "Test: [20/100]\tTime 0.030 (0.040)\tLoss 1.3902 (1.5972)\tPrec@1 65.000 (65.762)\tPrec@5 99.000 (96.476)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 1.4918 (1.5993)\tPrec@1 71.000 (65.774)\tPrec@5 97.000 (96.613)\n",
            "Test: [40/100]\tTime 0.019 (0.031)\tLoss 1.6224 (1.6126)\tPrec@1 61.000 (65.610)\tPrec@5 97.000 (96.707)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.7881 (1.6016)\tPrec@1 61.000 (65.529)\tPrec@5 93.000 (96.824)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 1.3814 (1.6151)\tPrec@1 66.000 (65.213)\tPrec@5 100.000 (96.770)\n",
            "Test: [70/100]\tTime 0.013 (0.029)\tLoss 1.6453 (1.5915)\tPrec@1 68.000 (65.493)\tPrec@5 96.000 (96.775)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.8399 (1.5900)\tPrec@1 64.000 (65.593)\tPrec@5 92.000 (96.852)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 1.5404 (1.5978)\tPrec@1 59.000 (65.385)\tPrec@5 98.000 (96.868)\n",
            "val Results: Prec@1 65.240 Prec@5 96.810 Loss 1.59879\n",
            "val Class Accuracy: [0.832,0.960,0.851,0.664,0.602,0.645,0.765,0.386,0.540,0.279]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [150][0/97], lr: 0.01000\tTime 0.432 (0.432)\tData 0.325 (0.325)\tLoss 0.1152 (0.1152)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][10/97], lr: 0.01000\tTime 0.062 (0.106)\tData 0.009 (0.037)\tLoss 0.1521 (0.1297)\tPrec@1 97.656 (95.810)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][20/97], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.022)\tLoss 0.1239 (0.1270)\tPrec@1 96.875 (95.908)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][30/97], lr: 0.01000\tTime 0.069 (0.075)\tData 0.010 (0.017)\tLoss 0.0882 (0.1211)\tPrec@1 97.656 (95.892)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][40/97], lr: 0.01000\tTime 0.050 (0.071)\tData 0.001 (0.014)\tLoss 0.2707 (0.1231)\tPrec@1 90.625 (95.789)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [150][50/97], lr: 0.01000\tTime 0.043 (0.068)\tData 0.000 (0.012)\tLoss 0.1033 (0.1216)\tPrec@1 96.094 (95.726)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [150][60/97], lr: 0.01000\tTime 0.072 (0.067)\tData 0.007 (0.011)\tLoss 0.2584 (0.1239)\tPrec@1 91.406 (95.671)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [150][70/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.000 (0.010)\tLoss 0.1090 (0.1237)\tPrec@1 96.875 (95.588)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [150][80/97], lr: 0.01000\tTime 0.054 (0.065)\tData 0.011 (0.009)\tLoss 0.0680 (0.1212)\tPrec@1 96.875 (95.708)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [150][90/97], lr: 0.01000\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.1106 (0.1215)\tPrec@1 97.656 (95.664)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.318 (0.318)\tLoss 1.0963 (1.0963)\tPrec@1 77.000 (77.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 1.1541 (1.1904)\tPrec@1 73.000 (71.364)\tPrec@5 97.000 (97.636)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.2304 (1.1892)\tPrec@1 71.000 (70.762)\tPrec@5 97.000 (97.571)\n",
            "Test: [30/100]\tTime 0.028 (0.034)\tLoss 1.3831 (1.2145)\tPrec@1 70.000 (70.452)\tPrec@5 95.000 (97.484)\n",
            "Test: [40/100]\tTime 0.035 (0.032)\tLoss 1.1439 (1.2196)\tPrec@1 69.000 (70.122)\tPrec@5 98.000 (97.512)\n",
            "Test: [50/100]\tTime 0.045 (0.032)\tLoss 1.0924 (1.2089)\tPrec@1 70.000 (70.510)\tPrec@5 95.000 (97.510)\n",
            "Test: [60/100]\tTime 0.022 (0.029)\tLoss 1.1582 (1.2145)\tPrec@1 70.000 (70.197)\tPrec@5 97.000 (97.426)\n",
            "Test: [70/100]\tTime 0.043 (0.029)\tLoss 1.2732 (1.2151)\tPrec@1 76.000 (70.296)\tPrec@5 97.000 (97.465)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.0172 (1.2157)\tPrec@1 73.000 (70.481)\tPrec@5 96.000 (97.481)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 0.9372 (1.2219)\tPrec@1 78.000 (70.275)\tPrec@5 98.000 (97.505)\n",
            "val Results: Prec@1 70.310 Prec@5 97.430 Loss 1.21952\n",
            "val Class Accuracy: [0.922,0.975,0.641,0.786,0.805,0.471,0.541,0.677,0.520,0.693]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [151][0/97], lr: 0.01000\tTime 0.469 (0.469)\tData 0.390 (0.390)\tLoss 0.0464 (0.0464)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][10/97], lr: 0.01000\tTime 0.057 (0.103)\tData 0.010 (0.040)\tLoss 0.0785 (0.0672)\tPrec@1 97.656 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][20/97], lr: 0.01000\tTime 0.038 (0.082)\tData 0.000 (0.023)\tLoss 0.0809 (0.0726)\tPrec@1 97.656 (97.619)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][30/97], lr: 0.01000\tTime 0.065 (0.075)\tData 0.017 (0.018)\tLoss 0.0485 (0.0733)\tPrec@1 98.438 (97.505)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][40/97], lr: 0.01000\tTime 0.065 (0.070)\tData 0.009 (0.014)\tLoss 0.0626 (0.0769)\tPrec@1 98.438 (97.351)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][50/97], lr: 0.01000\tTime 0.076 (0.068)\tData 0.000 (0.012)\tLoss 0.0922 (0.0772)\tPrec@1 96.094 (97.381)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][60/97], lr: 0.01000\tTime 0.054 (0.067)\tData 0.006 (0.011)\tLoss 0.1555 (0.0793)\tPrec@1 92.969 (97.387)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][70/97], lr: 0.01000\tTime 0.074 (0.065)\tData 0.000 (0.010)\tLoss 0.0416 (0.0836)\tPrec@1 98.438 (97.161)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [151][80/97], lr: 0.01000\tTime 0.069 (0.064)\tData 0.002 (0.009)\tLoss 0.1750 (0.0862)\tPrec@1 92.969 (97.000)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [151][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.1122 (0.0889)\tPrec@1 95.312 (96.892)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.267 (0.267)\tLoss 2.4222 (2.4222)\tPrec@1 59.000 (59.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.028 (0.052)\tLoss 1.8869 (2.1571)\tPrec@1 66.000 (61.909)\tPrec@5 95.000 (96.727)\n",
            "Test: [20/100]\tTime 0.021 (0.039)\tLoss 1.9408 (2.2403)\tPrec@1 63.000 (61.381)\tPrec@5 97.000 (95.810)\n",
            "Test: [30/100]\tTime 0.023 (0.034)\tLoss 2.4135 (2.2479)\tPrec@1 52.000 (60.774)\tPrec@5 96.000 (95.935)\n",
            "Test: [40/100]\tTime 0.022 (0.031)\tLoss 2.4353 (2.2576)\tPrec@1 59.000 (60.732)\tPrec@5 95.000 (95.951)\n",
            "Test: [50/100]\tTime 0.032 (0.031)\tLoss 2.4076 (2.2218)\tPrec@1 63.000 (61.608)\tPrec@5 94.000 (96.020)\n",
            "Test: [60/100]\tTime 0.016 (0.030)\tLoss 2.0935 (2.2493)\tPrec@1 64.000 (61.492)\tPrec@5 94.000 (95.820)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 2.5406 (2.2418)\tPrec@1 56.000 (61.606)\tPrec@5 96.000 (95.761)\n",
            "Test: [80/100]\tTime 0.033 (0.029)\tLoss 1.9684 (2.2230)\tPrec@1 64.000 (61.827)\tPrec@5 96.000 (95.840)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 2.0132 (2.2376)\tPrec@1 69.000 (61.659)\tPrec@5 96.000 (95.901)\n",
            "val Results: Prec@1 61.550 Prec@5 95.790 Loss 2.24574\n",
            "val Class Accuracy: [0.979,0.925,0.735,0.832,0.706,0.478,0.476,0.185,0.280,0.559]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [152][0/97], lr: 0.01000\tTime 0.508 (0.508)\tData 0.434 (0.434)\tLoss 0.0550 (0.0550)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][10/97], lr: 0.01000\tTime 0.056 (0.102)\tData 0.011 (0.045)\tLoss 0.1497 (0.0986)\tPrec@1 95.312 (96.591)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][20/97], lr: 0.01000\tTime 0.059 (0.082)\tData 0.006 (0.026)\tLoss 0.1677 (0.0992)\tPrec@1 95.312 (96.429)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][30/97], lr: 0.01000\tTime 0.069 (0.074)\tData 0.000 (0.020)\tLoss 0.1317 (0.1081)\tPrec@1 96.875 (96.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][40/97], lr: 0.01000\tTime 0.072 (0.070)\tData 0.012 (0.016)\tLoss 0.1240 (0.1128)\tPrec@1 95.312 (96.151)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][50/97], lr: 0.01000\tTime 0.066 (0.067)\tData 0.014 (0.014)\tLoss 0.1537 (0.1162)\tPrec@1 94.531 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][60/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.012)\tLoss 0.1458 (0.1171)\tPrec@1 95.312 (96.030)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][70/97], lr: 0.01000\tTime 0.061 (0.064)\tData 0.006 (0.011)\tLoss 0.0579 (0.1155)\tPrec@1 99.219 (96.039)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][80/97], lr: 0.01000\tTime 0.062 (0.063)\tData 0.006 (0.011)\tLoss 0.0560 (0.1148)\tPrec@1 99.219 (96.046)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][90/97], lr: 0.01000\tTime 0.043 (0.062)\tData 0.000 (0.010)\tLoss 0.0323 (0.1139)\tPrec@1 99.219 (96.016)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.363 (0.363)\tLoss 1.4533 (1.4533)\tPrec@1 66.000 (66.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.042 (0.055)\tLoss 1.4674 (1.6875)\tPrec@1 73.000 (64.091)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 1.4776 (1.7454)\tPrec@1 69.000 (63.810)\tPrec@5 98.000 (97.238)\n",
            "Test: [30/100]\tTime 0.013 (0.036)\tLoss 1.6466 (1.7304)\tPrec@1 66.000 (64.226)\tPrec@5 94.000 (97.258)\n",
            "Test: [40/100]\tTime 0.050 (0.034)\tLoss 1.6740 (1.7499)\tPrec@1 62.000 (63.976)\tPrec@5 96.000 (97.049)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 1.3613 (1.7283)\tPrec@1 68.000 (64.490)\tPrec@5 98.000 (97.000)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 1.4286 (1.7182)\tPrec@1 70.000 (64.557)\tPrec@5 98.000 (97.000)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 1.8106 (1.7113)\tPrec@1 63.000 (64.592)\tPrec@5 99.000 (96.958)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.4988 (1.6957)\tPrec@1 71.000 (64.988)\tPrec@5 98.000 (97.086)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.3038 (1.7159)\tPrec@1 67.000 (64.813)\tPrec@5 99.000 (97.044)\n",
            "val Results: Prec@1 64.860 Prec@5 97.040 Loss 1.71245\n",
            "val Class Accuracy: [0.931,0.978,0.841,0.794,0.661,0.457,0.668,0.453,0.301,0.402]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [153][0/97], lr: 0.01000\tTime 0.505 (0.505)\tData 0.408 (0.408)\tLoss 0.1197 (0.1197)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][10/97], lr: 0.01000\tTime 0.060 (0.106)\tData 0.002 (0.040)\tLoss 0.1183 (0.0814)\tPrec@1 95.312 (97.088)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][20/97], lr: 0.01000\tTime 0.051 (0.083)\tData 0.002 (0.023)\tLoss 0.0550 (0.0909)\tPrec@1 99.219 (96.912)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][30/97], lr: 0.01000\tTime 0.051 (0.075)\tData 0.007 (0.018)\tLoss 0.1157 (0.0983)\tPrec@1 93.750 (96.598)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][40/97], lr: 0.01000\tTime 0.050 (0.071)\tData 0.011 (0.015)\tLoss 0.1566 (0.1073)\tPrec@1 93.750 (96.284)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][50/97], lr: 0.01000\tTime 0.059 (0.068)\tData 0.006 (0.013)\tLoss 0.0666 (0.1073)\tPrec@1 98.438 (96.339)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][60/97], lr: 0.01000\tTime 0.068 (0.066)\tData 0.007 (0.011)\tLoss 0.0987 (0.1065)\tPrec@1 97.656 (96.286)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][70/97], lr: 0.01000\tTime 0.057 (0.065)\tData 0.000 (0.010)\tLoss 0.0631 (0.1048)\tPrec@1 98.438 (96.391)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][80/97], lr: 0.01000\tTime 0.047 (0.064)\tData 0.000 (0.010)\tLoss 0.1264 (0.1043)\tPrec@1 95.312 (96.412)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][90/97], lr: 0.01000\tTime 0.036 (0.063)\tData 0.000 (0.009)\tLoss 0.1008 (0.1043)\tPrec@1 94.531 (96.377)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.263 (0.263)\tLoss 1.5313 (1.5313)\tPrec@1 62.000 (62.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.034 (0.058)\tLoss 1.5711 (1.6142)\tPrec@1 72.000 (67.545)\tPrec@5 96.000 (97.727)\n",
            "Test: [20/100]\tTime 0.022 (0.039)\tLoss 1.1575 (1.6233)\tPrec@1 73.000 (67.095)\tPrec@5 97.000 (97.048)\n",
            "Test: [30/100]\tTime 0.050 (0.035)\tLoss 1.3424 (1.6188)\tPrec@1 69.000 (67.000)\tPrec@5 96.000 (96.903)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 1.2696 (1.6273)\tPrec@1 66.000 (66.537)\tPrec@5 96.000 (96.927)\n",
            "Test: [50/100]\tTime 0.042 (0.032)\tLoss 1.6433 (1.6162)\tPrec@1 68.000 (66.941)\tPrec@5 97.000 (96.922)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 1.5061 (1.6151)\tPrec@1 67.000 (66.836)\tPrec@5 94.000 (96.836)\n",
            "Test: [70/100]\tTime 0.035 (0.029)\tLoss 1.8753 (1.6073)\tPrec@1 63.000 (66.831)\tPrec@5 96.000 (96.817)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 1.3280 (1.5984)\tPrec@1 69.000 (66.963)\tPrec@5 96.000 (96.914)\n",
            "Test: [90/100]\tTime 0.021 (0.029)\tLoss 1.1318 (1.6128)\tPrec@1 72.000 (66.582)\tPrec@5 98.000 (96.934)\n",
            "val Results: Prec@1 66.510 Prec@5 96.910 Loss 1.62056\n",
            "val Class Accuracy: [0.944,0.988,0.801,0.640,0.659,0.628,0.601,0.664,0.385,0.341]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [154][0/97], lr: 0.01000\tTime 0.398 (0.398)\tData 0.312 (0.312)\tLoss 0.1757 (0.1757)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][10/97], lr: 0.01000\tTime 0.059 (0.103)\tData 0.005 (0.039)\tLoss 0.0535 (0.1137)\tPrec@1 97.656 (96.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][20/97], lr: 0.01000\tTime 0.069 (0.083)\tData 0.009 (0.022)\tLoss 0.1082 (0.1015)\tPrec@1 96.875 (96.689)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [154][30/97], lr: 0.01000\tTime 0.060 (0.075)\tData 0.007 (0.017)\tLoss 0.1459 (0.1043)\tPrec@1 93.750 (96.371)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [154][40/97], lr: 0.01000\tTime 0.073 (0.071)\tData 0.012 (0.014)\tLoss 0.0839 (0.1073)\tPrec@1 96.875 (96.208)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [154][50/97], lr: 0.01000\tTime 0.070 (0.068)\tData 0.000 (0.012)\tLoss 0.0644 (0.1041)\tPrec@1 98.438 (96.324)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [154][60/97], lr: 0.01000\tTime 0.063 (0.067)\tData 0.007 (0.011)\tLoss 0.2272 (0.1079)\tPrec@1 94.531 (96.260)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [154][70/97], lr: 0.01000\tTime 0.049 (0.065)\tData 0.000 (0.010)\tLoss 0.0977 (0.1071)\tPrec@1 93.750 (96.259)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [154][80/97], lr: 0.01000\tTime 0.062 (0.065)\tData 0.005 (0.010)\tLoss 0.0431 (0.1082)\tPrec@1 98.438 (96.219)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [154][90/97], lr: 0.01000\tTime 0.039 (0.063)\tData 0.000 (0.009)\tLoss 0.1932 (0.1104)\tPrec@1 94.531 (96.145)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.378 (0.378)\tLoss 1.7113 (1.7113)\tPrec@1 68.000 (68.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.059)\tLoss 1.5566 (1.8385)\tPrec@1 74.000 (64.545)\tPrec@5 96.000 (95.091)\n",
            "Test: [20/100]\tTime 0.010 (0.042)\tLoss 1.7591 (1.8745)\tPrec@1 67.000 (64.952)\tPrec@5 97.000 (94.667)\n",
            "Test: [30/100]\tTime 0.018 (0.037)\tLoss 1.8284 (1.8441)\tPrec@1 61.000 (64.774)\tPrec@5 97.000 (94.871)\n",
            "Test: [40/100]\tTime 0.027 (0.034)\tLoss 1.9573 (1.8508)\tPrec@1 60.000 (64.659)\tPrec@5 95.000 (94.902)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 1.7176 (1.8372)\tPrec@1 66.000 (64.588)\tPrec@5 99.000 (95.059)\n",
            "Test: [60/100]\tTime 0.029 (0.031)\tLoss 2.1069 (1.8534)\tPrec@1 66.000 (64.262)\tPrec@5 94.000 (95.082)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 1.9416 (1.8420)\tPrec@1 65.000 (64.338)\tPrec@5 94.000 (94.930)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 1.3916 (1.8217)\tPrec@1 68.000 (64.494)\tPrec@5 93.000 (94.926)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.2166 (1.8352)\tPrec@1 72.000 (64.198)\tPrec@5 93.000 (94.912)\n",
            "val Results: Prec@1 64.190 Prec@5 94.880 Loss 1.83419\n",
            "val Class Accuracy: [0.864,0.945,0.843,0.418,0.698,0.750,0.714,0.308,0.322,0.557]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [155][0/97], lr: 0.01000\tTime 0.476 (0.476)\tData 0.387 (0.387)\tLoss 0.0616 (0.0616)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][10/97], lr: 0.01000\tTime 0.056 (0.103)\tData 0.009 (0.041)\tLoss 0.0805 (0.1138)\tPrec@1 96.875 (95.384)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][20/97], lr: 0.01000\tTime 0.048 (0.082)\tData 0.000 (0.025)\tLoss 0.1491 (0.1168)\tPrec@1 93.750 (95.424)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][30/97], lr: 0.01000\tTime 0.055 (0.074)\tData 0.003 (0.018)\tLoss 0.0967 (0.1270)\tPrec@1 96.875 (95.338)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][40/97], lr: 0.01000\tTime 0.055 (0.069)\tData 0.006 (0.015)\tLoss 0.1146 (0.1238)\tPrec@1 95.312 (95.522)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [155][50/97], lr: 0.01000\tTime 0.070 (0.067)\tData 0.007 (0.013)\tLoss 0.1286 (0.1217)\tPrec@1 96.094 (95.695)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [155][60/97], lr: 0.01000\tTime 0.061 (0.065)\tData 0.000 (0.011)\tLoss 0.1584 (0.1234)\tPrec@1 95.312 (95.594)\tPrec@5 99.219 (99.974)\n",
            "Epoch: [155][70/97], lr: 0.01000\tTime 0.045 (0.064)\tData 0.005 (0.010)\tLoss 0.1577 (0.1224)\tPrec@1 95.312 (95.654)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [155][80/97], lr: 0.01000\tTime 0.066 (0.063)\tData 0.006 (0.010)\tLoss 0.1330 (0.1214)\tPrec@1 95.312 (95.679)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [155][90/97], lr: 0.01000\tTime 0.030 (0.062)\tData 0.000 (0.009)\tLoss 0.1454 (0.1211)\tPrec@1 93.750 (95.639)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.279 (0.279)\tLoss 2.1121 (2.1121)\tPrec@1 54.000 (54.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.026 (0.052)\tLoss 1.6091 (2.0926)\tPrec@1 71.000 (61.636)\tPrec@5 96.000 (96.636)\n",
            "Test: [20/100]\tTime 0.034 (0.038)\tLoss 1.6481 (2.1858)\tPrec@1 66.000 (60.905)\tPrec@5 96.000 (95.857)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 2.1195 (2.2111)\tPrec@1 59.000 (60.484)\tPrec@5 95.000 (95.710)\n",
            "Test: [40/100]\tTime 0.015 (0.033)\tLoss 2.0808 (2.2160)\tPrec@1 58.000 (60.220)\tPrec@5 97.000 (95.829)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 1.8810 (2.1920)\tPrec@1 63.000 (60.549)\tPrec@5 96.000 (95.804)\n",
            "Test: [60/100]\tTime 0.029 (0.030)\tLoss 1.5951 (2.1728)\tPrec@1 73.000 (60.525)\tPrec@5 95.000 (95.885)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 2.2411 (2.1543)\tPrec@1 59.000 (60.648)\tPrec@5 97.000 (95.887)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.8216 (2.1260)\tPrec@1 66.000 (60.951)\tPrec@5 94.000 (95.926)\n",
            "Test: [90/100]\tTime 0.010 (0.028)\tLoss 1.8173 (2.1435)\tPrec@1 63.000 (60.791)\tPrec@5 99.000 (95.978)\n",
            "val Results: Prec@1 60.610 Prec@5 95.920 Loss 2.15873\n",
            "val Class Accuracy: [0.962,0.957,0.789,0.676,0.612,0.555,0.731,0.382,0.204,0.193]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [156][0/97], lr: 0.01000\tTime 0.374 (0.374)\tData 0.310 (0.310)\tLoss 0.0588 (0.0588)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][10/97], lr: 0.01000\tTime 0.043 (0.101)\tData 0.000 (0.039)\tLoss 0.0770 (0.0966)\tPrec@1 97.656 (97.301)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [156][20/97], lr: 0.01000\tTime 0.063 (0.080)\tData 0.007 (0.023)\tLoss 0.1129 (0.1006)\tPrec@1 94.531 (96.689)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [156][30/97], lr: 0.01000\tTime 0.068 (0.072)\tData 0.014 (0.017)\tLoss 0.1415 (0.0958)\tPrec@1 95.312 (96.774)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [156][40/97], lr: 0.01000\tTime 0.054 (0.069)\tData 0.011 (0.015)\tLoss 0.0789 (0.0937)\tPrec@1 96.875 (96.742)\tPrec@5 99.219 (99.962)\n",
            "Epoch: [156][50/97], lr: 0.01000\tTime 0.040 (0.066)\tData 0.000 (0.013)\tLoss 0.0982 (0.0959)\tPrec@1 96.094 (96.691)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [156][60/97], lr: 0.01000\tTime 0.043 (0.065)\tData 0.007 (0.012)\tLoss 0.2126 (0.0984)\tPrec@1 90.625 (96.580)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [156][70/97], lr: 0.01000\tTime 0.073 (0.064)\tData 0.007 (0.011)\tLoss 0.1326 (0.0997)\tPrec@1 96.094 (96.523)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [156][80/97], lr: 0.01000\tTime 0.072 (0.063)\tData 0.006 (0.010)\tLoss 0.1222 (0.1046)\tPrec@1 94.531 (96.335)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [156][90/97], lr: 0.01000\tTime 0.025 (0.062)\tData 0.000 (0.009)\tLoss 0.0981 (0.1050)\tPrec@1 97.656 (96.377)\tPrec@5 100.000 (99.983)\n",
            "Test: [0/100]\tTime 0.318 (0.318)\tLoss 1.8900 (1.8900)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.046 (0.055)\tLoss 1.4976 (1.9884)\tPrec@1 74.000 (64.818)\tPrec@5 94.000 (96.000)\n",
            "Test: [20/100]\tTime 0.034 (0.040)\tLoss 1.4114 (1.9322)\tPrec@1 65.000 (64.857)\tPrec@5 96.000 (95.714)\n",
            "Test: [30/100]\tTime 0.029 (0.036)\tLoss 1.6074 (1.9353)\tPrec@1 67.000 (63.645)\tPrec@5 94.000 (95.548)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 1.9198 (1.9602)\tPrec@1 63.000 (63.561)\tPrec@5 93.000 (95.585)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 1.9239 (1.9316)\tPrec@1 65.000 (63.902)\tPrec@5 95.000 (95.549)\n",
            "Test: [60/100]\tTime 0.038 (0.030)\tLoss 1.9069 (1.9473)\tPrec@1 64.000 (63.590)\tPrec@5 95.000 (95.607)\n",
            "Test: [70/100]\tTime 0.025 (0.029)\tLoss 2.1620 (1.9458)\tPrec@1 63.000 (63.535)\tPrec@5 95.000 (95.592)\n",
            "Test: [80/100]\tTime 0.032 (0.028)\tLoss 1.5858 (1.9447)\tPrec@1 69.000 (63.407)\tPrec@5 97.000 (95.716)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 1.8177 (1.9498)\tPrec@1 63.000 (63.275)\tPrec@5 96.000 (95.791)\n",
            "val Results: Prec@1 63.110 Prec@5 95.800 Loss 1.95431\n",
            "val Class Accuracy: [0.915,0.986,0.860,0.615,0.777,0.439,0.685,0.338,0.525,0.171]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [157][0/97], lr: 0.01000\tTime 0.485 (0.485)\tData 0.385 (0.385)\tLoss 0.0667 (0.0667)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][10/97], lr: 0.01000\tTime 0.047 (0.105)\tData 0.000 (0.041)\tLoss 0.0739 (0.1021)\tPrec@1 98.438 (96.165)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][20/97], lr: 0.01000\tTime 0.037 (0.082)\tData 0.000 (0.024)\tLoss 0.0415 (0.1044)\tPrec@1 98.438 (96.131)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][30/97], lr: 0.01000\tTime 0.063 (0.074)\tData 0.000 (0.018)\tLoss 0.0563 (0.1022)\tPrec@1 97.656 (96.195)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][40/97], lr: 0.01000\tTime 0.055 (0.070)\tData 0.013 (0.015)\tLoss 0.0788 (0.1073)\tPrec@1 96.094 (95.998)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [157][50/97], lr: 0.01000\tTime 0.056 (0.067)\tData 0.007 (0.013)\tLoss 0.1070 (0.1144)\tPrec@1 96.875 (95.864)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [157][60/97], lr: 0.01000\tTime 0.058 (0.066)\tData 0.009 (0.012)\tLoss 0.1502 (0.1192)\tPrec@1 94.531 (95.671)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [157][70/97], lr: 0.01000\tTime 0.048 (0.065)\tData 0.001 (0.011)\tLoss 0.0960 (0.1204)\tPrec@1 96.094 (95.709)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [157][80/97], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.011)\tLoss 0.0697 (0.1209)\tPrec@1 96.875 (95.669)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [157][90/97], lr: 0.01000\tTime 0.027 (0.063)\tData 0.000 (0.010)\tLoss 0.1139 (0.1215)\tPrec@1 95.312 (95.630)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.358 (0.358)\tLoss 1.7918 (1.7918)\tPrec@1 60.000 (60.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.020 (0.059)\tLoss 1.3199 (1.8382)\tPrec@1 76.000 (63.091)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/100]\tTime 0.023 (0.042)\tLoss 1.6803 (1.8267)\tPrec@1 68.000 (63.810)\tPrec@5 98.000 (97.095)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 1.7655 (1.8626)\tPrec@1 69.000 (63.516)\tPrec@5 97.000 (97.129)\n",
            "Test: [40/100]\tTime 0.040 (0.033)\tLoss 1.6076 (1.8586)\tPrec@1 59.000 (63.122)\tPrec@5 97.000 (97.171)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 1.6504 (1.8330)\tPrec@1 68.000 (63.431)\tPrec@5 98.000 (97.196)\n",
            "Test: [60/100]\tTime 0.020 (0.031)\tLoss 1.4761 (1.8394)\tPrec@1 72.000 (63.311)\tPrec@5 95.000 (97.164)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 1.7009 (1.8202)\tPrec@1 65.000 (63.394)\tPrec@5 98.000 (97.239)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 1.6448 (1.8214)\tPrec@1 64.000 (63.407)\tPrec@5 97.000 (97.247)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 1.7480 (1.8337)\tPrec@1 66.000 (63.176)\tPrec@5 97.000 (97.253)\n",
            "val Results: Prec@1 63.180 Prec@5 97.250 Loss 1.82839\n",
            "val Class Accuracy: [0.834,0.993,0.589,0.766,0.674,0.789,0.551,0.318,0.520,0.284]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [158][0/97], lr: 0.01000\tTime 0.482 (0.482)\tData 0.392 (0.392)\tLoss 0.1978 (0.1978)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][10/97], lr: 0.01000\tTime 0.064 (0.107)\tData 0.000 (0.041)\tLoss 0.1067 (0.1386)\tPrec@1 96.875 (95.099)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][20/97], lr: 0.01000\tTime 0.048 (0.083)\tData 0.000 (0.023)\tLoss 0.1263 (0.1251)\tPrec@1 96.094 (95.610)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][30/97], lr: 0.01000\tTime 0.060 (0.075)\tData 0.002 (0.017)\tLoss 0.0897 (0.1143)\tPrec@1 97.656 (96.144)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][40/97], lr: 0.01000\tTime 0.075 (0.071)\tData 0.010 (0.014)\tLoss 0.1659 (0.1176)\tPrec@1 96.094 (95.979)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][50/97], lr: 0.01000\tTime 0.051 (0.068)\tData 0.003 (0.012)\tLoss 0.1616 (0.1155)\tPrec@1 95.312 (96.124)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][60/97], lr: 0.01000\tTime 0.041 (0.066)\tData 0.000 (0.011)\tLoss 0.0944 (0.1144)\tPrec@1 96.094 (96.145)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][70/97], lr: 0.01000\tTime 0.071 (0.065)\tData 0.000 (0.010)\tLoss 0.0813 (0.1147)\tPrec@1 97.656 (96.138)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [158][80/97], lr: 0.01000\tTime 0.056 (0.064)\tData 0.012 (0.009)\tLoss 0.0938 (0.1193)\tPrec@1 96.875 (95.968)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [158][90/97], lr: 0.01000\tTime 0.034 (0.063)\tData 0.000 (0.009)\tLoss 0.1012 (0.1172)\tPrec@1 96.875 (96.068)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 1.4470 (1.4470)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.038 (0.054)\tLoss 1.0229 (1.4101)\tPrec@1 73.000 (67.909)\tPrec@5 96.000 (97.818)\n",
            "Test: [20/100]\tTime 0.017 (0.039)\tLoss 1.1936 (1.3855)\tPrec@1 65.000 (67.381)\tPrec@5 98.000 (97.476)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 1.3744 (1.3935)\tPrec@1 61.000 (67.839)\tPrec@5 97.000 (97.194)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 1.5651 (1.3925)\tPrec@1 65.000 (67.512)\tPrec@5 96.000 (97.268)\n",
            "Test: [50/100]\tTime 0.014 (0.031)\tLoss 0.9946 (1.3802)\tPrec@1 81.000 (67.980)\tPrec@5 99.000 (97.510)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 1.2894 (1.3887)\tPrec@1 69.000 (68.049)\tPrec@5 96.000 (97.459)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 1.5661 (1.3834)\tPrec@1 63.000 (68.211)\tPrec@5 99.000 (97.507)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 1.2125 (1.3741)\tPrec@1 75.000 (68.259)\tPrec@5 99.000 (97.519)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.1918 (1.3956)\tPrec@1 75.000 (68.044)\tPrec@5 98.000 (97.495)\n",
            "val Results: Prec@1 67.970 Prec@5 97.420 Loss 1.39831\n",
            "val Class Accuracy: [0.962,0.964,0.629,0.481,0.894,0.647,0.655,0.561,0.430,0.574]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [159][0/97], lr: 0.01000\tTime 0.487 (0.487)\tData 0.404 (0.404)\tLoss 0.0930 (0.0930)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][10/97], lr: 0.01000\tTime 0.057 (0.106)\tData 0.007 (0.042)\tLoss 0.0918 (0.0934)\tPrec@1 96.875 (97.017)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][20/97], lr: 0.01000\tTime 0.049 (0.083)\tData 0.000 (0.025)\tLoss 0.1087 (0.0977)\tPrec@1 96.875 (96.838)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][30/97], lr: 0.01000\tTime 0.060 (0.076)\tData 0.007 (0.019)\tLoss 0.0468 (0.0963)\tPrec@1 100.000 (96.825)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [159][40/97], lr: 0.01000\tTime 0.071 (0.072)\tData 0.007 (0.017)\tLoss 0.1339 (0.0969)\tPrec@1 95.312 (96.780)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [159][50/97], lr: 0.01000\tTime 0.050 (0.069)\tData 0.000 (0.015)\tLoss 0.1572 (0.0997)\tPrec@1 92.188 (96.569)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [159][60/97], lr: 0.01000\tTime 0.057 (0.067)\tData 0.007 (0.013)\tLoss 0.1964 (0.1039)\tPrec@1 96.094 (96.427)\tPrec@5 100.000 (99.974)\n",
            "Epoch: [159][70/97], lr: 0.01000\tTime 0.060 (0.066)\tData 0.007 (0.012)\tLoss 0.1766 (0.1083)\tPrec@1 92.969 (96.314)\tPrec@5 100.000 (99.978)\n",
            "Epoch: [159][80/97], lr: 0.01000\tTime 0.063 (0.065)\tData 0.000 (0.011)\tLoss 0.1270 (0.1113)\tPrec@1 95.312 (96.113)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [159][90/97], lr: 0.01000\tTime 0.034 (0.064)\tData 0.000 (0.011)\tLoss 0.1456 (0.1154)\tPrec@1 95.312 (95.991)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 2.1415 (2.1415)\tPrec@1 62.000 (62.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.028 (0.054)\tLoss 2.2041 (2.5689)\tPrec@1 61.000 (59.636)\tPrec@5 95.000 (94.182)\n",
            "Test: [20/100]\tTime 0.051 (0.041)\tLoss 2.2608 (2.5486)\tPrec@1 55.000 (59.095)\tPrec@5 97.000 (94.429)\n",
            "Test: [30/100]\tTime 0.018 (0.036)\tLoss 2.4359 (2.5582)\tPrec@1 60.000 (58.419)\tPrec@5 96.000 (94.000)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 2.5388 (2.5596)\tPrec@1 60.000 (58.293)\tPrec@5 99.000 (93.732)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 1.6764 (2.5377)\tPrec@1 67.000 (58.549)\tPrec@5 97.000 (94.000)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 2.1272 (2.5119)\tPrec@1 65.000 (58.754)\tPrec@5 95.000 (94.082)\n",
            "Test: [70/100]\tTime 0.029 (0.029)\tLoss 2.7160 (2.5005)\tPrec@1 63.000 (58.732)\tPrec@5 94.000 (94.085)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 1.9304 (2.4994)\tPrec@1 66.000 (58.852)\tPrec@5 94.000 (94.123)\n",
            "Test: [90/100]\tTime 0.037 (0.028)\tLoss 2.4988 (2.5187)\tPrec@1 60.000 (58.560)\tPrec@5 94.000 (94.110)\n",
            "val Results: Prec@1 58.430 Prec@5 94.030 Loss 2.53486\n",
            "val Class Accuracy: [0.901,0.950,0.817,0.476,0.845,0.537,0.599,0.491,0.176,0.051]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [160][0/97], lr: 0.00010\tTime 0.375 (0.375)\tData 0.312 (0.312)\tLoss 0.1181 (0.1181)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][10/97], lr: 0.00010\tTime 0.056 (0.102)\tData 0.000 (0.039)\tLoss 0.1791 (0.1277)\tPrec@1 95.312 (95.881)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][20/97], lr: 0.00010\tTime 0.067 (0.080)\tData 0.000 (0.022)\tLoss 0.0873 (0.1138)\tPrec@1 96.875 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][30/97], lr: 0.00010\tTime 0.059 (0.073)\tData 0.010 (0.016)\tLoss 0.1941 (0.1127)\tPrec@1 95.312 (96.195)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][40/97], lr: 0.00010\tTime 0.059 (0.069)\tData 0.006 (0.014)\tLoss 0.1263 (0.1099)\tPrec@1 94.531 (96.284)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][50/97], lr: 0.00010\tTime 0.049 (0.067)\tData 0.000 (0.012)\tLoss 0.1074 (0.1093)\tPrec@1 96.094 (96.278)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][60/97], lr: 0.00010\tTime 0.039 (0.065)\tData 0.000 (0.011)\tLoss 0.1231 (0.1102)\tPrec@1 96.094 (96.247)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][70/97], lr: 0.00010\tTime 0.065 (0.064)\tData 0.000 (0.010)\tLoss 0.0415 (0.1046)\tPrec@1 98.438 (96.446)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][80/97], lr: 0.00010\tTime 0.058 (0.064)\tData 0.012 (0.009)\tLoss 0.1018 (0.1032)\tPrec@1 97.656 (96.480)\tPrec@5 99.219 (99.990)\n",
            "Epoch: [160][90/97], lr: 0.00010\tTime 0.028 (0.062)\tData 0.000 (0.009)\tLoss 0.0598 (0.1019)\tPrec@1 96.094 (96.514)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.363 (0.363)\tLoss 1.2954 (1.2954)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.054)\tLoss 1.2328 (1.5482)\tPrec@1 76.000 (69.364)\tPrec@5 97.000 (98.000)\n",
            "Test: [20/100]\tTime 0.014 (0.040)\tLoss 1.3670 (1.5558)\tPrec@1 69.000 (68.667)\tPrec@5 100.000 (97.476)\n",
            "Test: [30/100]\tTime 0.027 (0.033)\tLoss 1.4903 (1.5735)\tPrec@1 65.000 (68.516)\tPrec@5 98.000 (97.387)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 1.4363 (1.5802)\tPrec@1 70.000 (68.195)\tPrec@5 99.000 (97.463)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.1240 (1.5442)\tPrec@1 71.000 (68.490)\tPrec@5 99.000 (97.608)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 1.3606 (1.5404)\tPrec@1 71.000 (68.361)\tPrec@5 97.000 (97.672)\n",
            "Test: [70/100]\tTime 0.036 (0.029)\tLoss 1.7072 (1.5289)\tPrec@1 69.000 (68.225)\tPrec@5 98.000 (97.676)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.2000 (1.5300)\tPrec@1 75.000 (68.222)\tPrec@5 97.000 (97.728)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.4366 (1.5451)\tPrec@1 70.000 (67.901)\tPrec@5 100.000 (97.791)\n",
            "val Results: Prec@1 67.790 Prec@5 97.720 Loss 1.55551\n",
            "val Class Accuracy: [0.951,0.973,0.783,0.715,0.781,0.566,0.653,0.611,0.390,0.356]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [161][0/97], lr: 0.00010\tTime 0.465 (0.465)\tData 0.369 (0.369)\tLoss 0.0879 (0.0879)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][10/97], lr: 0.00010\tTime 0.073 (0.103)\tData 0.007 (0.038)\tLoss 0.0844 (0.1011)\tPrec@1 96.094 (96.946)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][20/97], lr: 0.00010\tTime 0.059 (0.081)\tData 0.011 (0.023)\tLoss 0.0914 (0.0833)\tPrec@1 96.094 (97.582)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [161][30/97], lr: 0.00010\tTime 0.061 (0.074)\tData 0.007 (0.017)\tLoss 0.0464 (0.0826)\tPrec@1 97.656 (97.530)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [161][40/97], lr: 0.00010\tTime 0.060 (0.068)\tData 0.005 (0.013)\tLoss 0.0973 (0.0837)\tPrec@1 96.875 (97.389)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [161][50/97], lr: 0.00010\tTime 0.065 (0.067)\tData 0.011 (0.012)\tLoss 0.0443 (0.0792)\tPrec@1 98.438 (97.472)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [161][60/97], lr: 0.00010\tTime 0.066 (0.066)\tData 0.004 (0.011)\tLoss 0.0250 (0.0789)\tPrec@1 100.000 (97.451)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [161][70/97], lr: 0.00010\tTime 0.054 (0.065)\tData 0.005 (0.010)\tLoss 0.0509 (0.0761)\tPrec@1 97.656 (97.557)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [161][80/97], lr: 0.00010\tTime 0.061 (0.065)\tData 0.007 (0.009)\tLoss 0.1059 (0.0764)\tPrec@1 96.094 (97.521)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [161][90/97], lr: 0.00010\tTime 0.027 (0.064)\tData 0.000 (0.009)\tLoss 0.1550 (0.0763)\tPrec@1 94.531 (97.570)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 1.3040 (1.3040)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.036 (0.056)\tLoss 1.2200 (1.5429)\tPrec@1 75.000 (70.000)\tPrec@5 97.000 (98.000)\n",
            "Test: [20/100]\tTime 0.024 (0.042)\tLoss 1.3559 (1.5557)\tPrec@1 69.000 (68.857)\tPrec@5 99.000 (97.619)\n",
            "Test: [30/100]\tTime 0.030 (0.034)\tLoss 1.4575 (1.5741)\tPrec@1 68.000 (68.806)\tPrec@5 98.000 (97.387)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 1.4149 (1.5787)\tPrec@1 71.000 (68.659)\tPrec@5 99.000 (97.537)\n",
            "Test: [50/100]\tTime 0.032 (0.032)\tLoss 1.1171 (1.5445)\tPrec@1 72.000 (68.961)\tPrec@5 99.000 (97.667)\n",
            "Test: [60/100]\tTime 0.039 (0.031)\tLoss 1.3139 (1.5394)\tPrec@1 71.000 (68.836)\tPrec@5 97.000 (97.672)\n",
            "Test: [70/100]\tTime 0.045 (0.030)\tLoss 1.7270 (1.5278)\tPrec@1 67.000 (68.803)\tPrec@5 98.000 (97.676)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 1.1850 (1.5274)\tPrec@1 75.000 (68.778)\tPrec@5 97.000 (97.728)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.4173 (1.5438)\tPrec@1 71.000 (68.495)\tPrec@5 100.000 (97.791)\n",
            "val Results: Prec@1 68.400 Prec@5 97.740 Loss 1.55421\n",
            "val Class Accuracy: [0.965,0.980,0.795,0.715,0.778,0.568,0.673,0.624,0.385,0.357]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [162][0/97], lr: 0.00010\tTime 0.482 (0.482)\tData 0.381 (0.381)\tLoss 0.0761 (0.0761)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][10/97], lr: 0.00010\tTime 0.066 (0.100)\tData 0.007 (0.038)\tLoss 0.0416 (0.0616)\tPrec@1 97.656 (97.727)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][20/97], lr: 0.00010\tTime 0.072 (0.079)\tData 0.000 (0.021)\tLoss 0.1183 (0.0675)\tPrec@1 95.312 (97.582)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][30/97], lr: 0.00010\tTime 0.066 (0.072)\tData 0.010 (0.016)\tLoss 0.0432 (0.0676)\tPrec@1 98.438 (97.732)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][40/97], lr: 0.00010\tTime 0.049 (0.068)\tData 0.000 (0.014)\tLoss 0.0989 (0.0700)\tPrec@1 95.312 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][50/97], lr: 0.00010\tTime 0.043 (0.066)\tData 0.000 (0.012)\tLoss 0.0752 (0.0697)\tPrec@1 96.875 (97.641)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][60/97], lr: 0.00010\tTime 0.062 (0.065)\tData 0.006 (0.011)\tLoss 0.0347 (0.0698)\tPrec@1 100.000 (97.682)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][70/97], lr: 0.00010\tTime 0.055 (0.064)\tData 0.006 (0.010)\tLoss 0.0879 (0.0688)\tPrec@1 96.875 (97.733)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][80/97], lr: 0.00010\tTime 0.071 (0.063)\tData 0.006 (0.009)\tLoss 0.0677 (0.0679)\tPrec@1 96.875 (97.753)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][90/97], lr: 0.00010\tTime 0.038 (0.062)\tData 0.000 (0.009)\tLoss 0.0286 (0.0677)\tPrec@1 99.219 (97.768)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 1.3219 (1.3219)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.052)\tLoss 1.1693 (1.5072)\tPrec@1 73.000 (70.091)\tPrec@5 98.000 (98.091)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.3688 (1.5202)\tPrec@1 69.000 (68.857)\tPrec@5 100.000 (97.762)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 1.4357 (1.5415)\tPrec@1 66.000 (68.774)\tPrec@5 96.000 (97.516)\n",
            "Test: [40/100]\tTime 0.045 (0.033)\tLoss 1.3972 (1.5493)\tPrec@1 70.000 (68.707)\tPrec@5 99.000 (97.585)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 1.0951 (1.5130)\tPrec@1 71.000 (69.020)\tPrec@5 99.000 (97.725)\n",
            "Test: [60/100]\tTime 0.012 (0.030)\tLoss 1.2891 (1.5103)\tPrec@1 73.000 (69.016)\tPrec@5 97.000 (97.738)\n",
            "Test: [70/100]\tTime 0.032 (0.029)\tLoss 1.6722 (1.4969)\tPrec@1 68.000 (68.986)\tPrec@5 99.000 (97.718)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 1.2007 (1.4967)\tPrec@1 75.000 (68.963)\tPrec@5 96.000 (97.778)\n",
            "Test: [90/100]\tTime 0.013 (0.028)\tLoss 1.3814 (1.5122)\tPrec@1 72.000 (68.692)\tPrec@5 100.000 (97.868)\n",
            "val Results: Prec@1 68.630 Prec@5 97.810 Loss 1.52134\n",
            "val Class Accuracy: [0.962,0.981,0.787,0.746,0.785,0.560,0.681,0.599,0.387,0.375]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [163][0/97], lr: 0.00010\tTime 0.434 (0.434)\tData 0.331 (0.331)\tLoss 0.0408 (0.0408)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][10/97], lr: 0.00010\tTime 0.060 (0.104)\tData 0.011 (0.036)\tLoss 0.0629 (0.0519)\tPrec@1 97.656 (98.722)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][20/97], lr: 0.00010\tTime 0.059 (0.083)\tData 0.011 (0.021)\tLoss 0.0798 (0.0573)\tPrec@1 96.094 (98.289)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][30/97], lr: 0.00010\tTime 0.055 (0.075)\tData 0.000 (0.016)\tLoss 0.0291 (0.0572)\tPrec@1 98.438 (98.261)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][40/97], lr: 0.00010\tTime 0.065 (0.071)\tData 0.009 (0.013)\tLoss 0.0553 (0.0556)\tPrec@1 98.438 (98.323)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][50/97], lr: 0.00010\tTime 0.064 (0.068)\tData 0.000 (0.011)\tLoss 0.0281 (0.0547)\tPrec@1 100.000 (98.392)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][60/97], lr: 0.00010\tTime 0.044 (0.066)\tData 0.000 (0.010)\tLoss 0.0479 (0.0569)\tPrec@1 97.656 (98.258)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][70/97], lr: 0.00010\tTime 0.066 (0.065)\tData 0.000 (0.009)\tLoss 0.0716 (0.0572)\tPrec@1 96.875 (98.151)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][80/97], lr: 0.00010\tTime 0.043 (0.063)\tData 0.000 (0.009)\tLoss 0.0394 (0.0578)\tPrec@1 99.219 (98.100)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][90/97], lr: 0.00010\tTime 0.032 (0.063)\tData 0.000 (0.008)\tLoss 0.0660 (0.0584)\tPrec@1 99.219 (98.128)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 1.2923 (1.2923)\tPrec@1 74.000 (74.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.019 (0.054)\tLoss 1.1256 (1.4647)\tPrec@1 74.000 (70.091)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.014 (0.039)\tLoss 1.3275 (1.4864)\tPrec@1 69.000 (69.381)\tPrec@5 99.000 (97.714)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 1.3857 (1.5070)\tPrec@1 66.000 (69.290)\tPrec@5 97.000 (97.516)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 1.3469 (1.5149)\tPrec@1 71.000 (69.341)\tPrec@5 99.000 (97.610)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 1.0876 (1.4807)\tPrec@1 72.000 (69.647)\tPrec@5 99.000 (97.745)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 1.2469 (1.4774)\tPrec@1 73.000 (69.639)\tPrec@5 97.000 (97.738)\n",
            "Test: [70/100]\tTime 0.030 (0.029)\tLoss 1.6424 (1.4628)\tPrec@1 68.000 (69.676)\tPrec@5 99.000 (97.732)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.1769 (1.4621)\tPrec@1 74.000 (69.605)\tPrec@5 96.000 (97.778)\n",
            "Test: [90/100]\tTime 0.015 (0.028)\tLoss 1.3338 (1.4766)\tPrec@1 72.000 (69.297)\tPrec@5 100.000 (97.868)\n",
            "val Results: Prec@1 69.210 Prec@5 97.830 Loss 1.48524\n",
            "val Class Accuracy: [0.960,0.983,0.796,0.741,0.775,0.588,0.690,0.601,0.406,0.381]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [164][0/97], lr: 0.00010\tTime 0.471 (0.471)\tData 0.391 (0.391)\tLoss 0.1019 (0.1019)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][10/97], lr: 0.00010\tTime 0.041 (0.100)\tData 0.000 (0.040)\tLoss 0.0272 (0.0669)\tPrec@1 100.000 (97.869)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][20/97], lr: 0.00010\tTime 0.060 (0.082)\tData 0.000 (0.023)\tLoss 0.0437 (0.0661)\tPrec@1 99.219 (98.028)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][30/97], lr: 0.00010\tTime 0.060 (0.074)\tData 0.007 (0.018)\tLoss 0.0513 (0.0623)\tPrec@1 98.438 (98.110)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][40/97], lr: 0.00010\tTime 0.033 (0.070)\tData 0.000 (0.015)\tLoss 0.0581 (0.0608)\tPrec@1 99.219 (98.133)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][50/97], lr: 0.00010\tTime 0.056 (0.068)\tData 0.000 (0.012)\tLoss 0.0514 (0.0609)\tPrec@1 98.438 (98.055)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][60/97], lr: 0.00010\tTime 0.056 (0.066)\tData 0.009 (0.012)\tLoss 0.0253 (0.0586)\tPrec@1 99.219 (98.104)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][70/97], lr: 0.00010\tTime 0.058 (0.065)\tData 0.012 (0.011)\tLoss 0.0464 (0.0567)\tPrec@1 97.656 (98.173)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][80/97], lr: 0.00010\tTime 0.056 (0.064)\tData 0.007 (0.010)\tLoss 0.0357 (0.0561)\tPrec@1 100.000 (98.216)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][90/97], lr: 0.00010\tTime 0.031 (0.062)\tData 0.000 (0.009)\tLoss 0.0297 (0.0558)\tPrec@1 99.219 (98.249)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.359 (0.359)\tLoss 1.2631 (1.2631)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.029 (0.052)\tLoss 1.1298 (1.4400)\tPrec@1 74.000 (70.000)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.030 (0.041)\tLoss 1.3319 (1.4677)\tPrec@1 68.000 (69.476)\tPrec@5 99.000 (97.619)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 1.4189 (1.4905)\tPrec@1 68.000 (69.484)\tPrec@5 96.000 (97.484)\n",
            "Test: [40/100]\tTime 0.025 (0.034)\tLoss 1.3233 (1.4942)\tPrec@1 70.000 (69.512)\tPrec@5 99.000 (97.634)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 1.0684 (1.4585)\tPrec@1 73.000 (69.980)\tPrec@5 99.000 (97.804)\n",
            "Test: [60/100]\tTime 0.014 (0.031)\tLoss 1.2174 (1.4576)\tPrec@1 73.000 (69.951)\tPrec@5 97.000 (97.803)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.6042 (1.4415)\tPrec@1 69.000 (69.972)\tPrec@5 99.000 (97.803)\n",
            "Test: [80/100]\tTime 0.021 (0.030)\tLoss 1.1706 (1.4391)\tPrec@1 74.000 (69.901)\tPrec@5 95.000 (97.864)\n",
            "Test: [90/100]\tTime 0.016 (0.029)\tLoss 1.2957 (1.4540)\tPrec@1 75.000 (69.615)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 69.520 Prec@5 97.890 Loss 1.46123\n",
            "val Class Accuracy: [0.965,0.981,0.797,0.760,0.772,0.581,0.664,0.594,0.408,0.430]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [165][0/97], lr: 0.00010\tTime 0.391 (0.391)\tData 0.306 (0.306)\tLoss 0.0491 (0.0491)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][10/97], lr: 0.00010\tTime 0.050 (0.100)\tData 0.005 (0.038)\tLoss 0.0622 (0.0495)\tPrec@1 98.438 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][20/97], lr: 0.00010\tTime 0.069 (0.080)\tData 0.000 (0.023)\tLoss 0.0249 (0.0438)\tPrec@1 100.000 (98.698)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][30/97], lr: 0.00010\tTime 0.050 (0.073)\tData 0.009 (0.017)\tLoss 0.0492 (0.0448)\tPrec@1 97.656 (98.664)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][40/97], lr: 0.00010\tTime 0.045 (0.069)\tData 0.000 (0.013)\tLoss 0.0641 (0.0451)\tPrec@1 97.656 (98.685)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][50/97], lr: 0.00010\tTime 0.063 (0.067)\tData 0.000 (0.011)\tLoss 0.0271 (0.0467)\tPrec@1 100.000 (98.683)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][60/97], lr: 0.00010\tTime 0.071 (0.065)\tData 0.004 (0.010)\tLoss 0.0330 (0.0468)\tPrec@1 100.000 (98.681)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][70/97], lr: 0.00010\tTime 0.066 (0.065)\tData 0.008 (0.010)\tLoss 0.0303 (0.0459)\tPrec@1 100.000 (98.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][80/97], lr: 0.00010\tTime 0.069 (0.064)\tData 0.000 (0.009)\tLoss 0.0390 (0.0466)\tPrec@1 98.438 (98.708)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][90/97], lr: 0.00010\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.0323 (0.0467)\tPrec@1 100.000 (98.712)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 1.2782 (1.2782)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.028 (0.058)\tLoss 1.1149 (1.4433)\tPrec@1 73.000 (70.273)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/100]\tTime 0.034 (0.042)\tLoss 1.3193 (1.4706)\tPrec@1 69.000 (69.667)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 1.3921 (1.4926)\tPrec@1 67.000 (69.645)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.041 (0.034)\tLoss 1.3348 (1.4977)\tPrec@1 70.000 (69.610)\tPrec@5 99.000 (97.732)\n",
            "Test: [50/100]\tTime 0.032 (0.031)\tLoss 1.0612 (1.4640)\tPrec@1 73.000 (70.039)\tPrec@5 99.000 (97.863)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.2125 (1.4609)\tPrec@1 73.000 (70.049)\tPrec@5 97.000 (97.869)\n",
            "Test: [70/100]\tTime 0.043 (0.030)\tLoss 1.6532 (1.4463)\tPrec@1 68.000 (70.014)\tPrec@5 99.000 (97.859)\n",
            "Test: [80/100]\tTime 0.026 (0.030)\tLoss 1.1716 (1.4438)\tPrec@1 74.000 (69.975)\tPrec@5 96.000 (97.914)\n",
            "Test: [90/100]\tTime 0.041 (0.029)\tLoss 1.3067 (1.4592)\tPrec@1 75.000 (69.780)\tPrec@5 100.000 (98.000)\n",
            "val Results: Prec@1 69.680 Prec@5 97.970 Loss 1.46649\n",
            "val Class Accuracy: [0.966,0.982,0.793,0.739,0.775,0.593,0.706,0.602,0.392,0.420]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [166][0/97], lr: 0.00010\tTime 0.445 (0.445)\tData 0.343 (0.343)\tLoss 0.0538 (0.0538)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][10/97], lr: 0.00010\tTime 0.037 (0.102)\tData 0.000 (0.035)\tLoss 0.0805 (0.0547)\tPrec@1 96.875 (98.011)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][20/97], lr: 0.00010\tTime 0.068 (0.082)\tData 0.007 (0.020)\tLoss 0.0568 (0.0511)\tPrec@1 97.656 (98.289)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][30/97], lr: 0.00010\tTime 0.058 (0.074)\tData 0.013 (0.015)\tLoss 0.0232 (0.0540)\tPrec@1 100.000 (98.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][40/97], lr: 0.00010\tTime 0.044 (0.070)\tData 0.000 (0.013)\tLoss 0.0411 (0.0514)\tPrec@1 99.219 (98.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][50/97], lr: 0.00010\tTime 0.049 (0.068)\tData 0.000 (0.011)\tLoss 0.0352 (0.0510)\tPrec@1 99.219 (98.407)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][60/97], lr: 0.00010\tTime 0.049 (0.067)\tData 0.007 (0.011)\tLoss 0.1068 (0.0503)\tPrec@1 95.312 (98.476)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][70/97], lr: 0.00010\tTime 0.062 (0.066)\tData 0.007 (0.010)\tLoss 0.0444 (0.0520)\tPrec@1 97.656 (98.360)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][80/97], lr: 0.00010\tTime 0.060 (0.065)\tData 0.000 (0.009)\tLoss 0.0586 (0.0510)\tPrec@1 98.438 (98.418)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][90/97], lr: 0.00010\tTime 0.033 (0.063)\tData 0.000 (0.009)\tLoss 0.0684 (0.0510)\tPrec@1 98.438 (98.420)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 1.2871 (1.2871)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.031 (0.054)\tLoss 1.1312 (1.4435)\tPrec@1 73.000 (69.909)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.010 (0.041)\tLoss 1.3463 (1.4705)\tPrec@1 69.000 (69.476)\tPrec@5 99.000 (97.619)\n",
            "Test: [30/100]\tTime 0.021 (0.033)\tLoss 1.3979 (1.4923)\tPrec@1 70.000 (69.548)\tPrec@5 97.000 (97.516)\n",
            "Test: [40/100]\tTime 0.039 (0.033)\tLoss 1.3345 (1.4964)\tPrec@1 70.000 (69.537)\tPrec@5 99.000 (97.683)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 1.0650 (1.4626)\tPrec@1 73.000 (69.980)\tPrec@5 99.000 (97.824)\n",
            "Test: [60/100]\tTime 0.035 (0.031)\tLoss 1.2060 (1.4615)\tPrec@1 75.000 (70.049)\tPrec@5 97.000 (97.836)\n",
            "Test: [70/100]\tTime 0.014 (0.030)\tLoss 1.6441 (1.4467)\tPrec@1 70.000 (70.056)\tPrec@5 99.000 (97.831)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 1.1738 (1.4438)\tPrec@1 74.000 (70.037)\tPrec@5 96.000 (97.901)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.3134 (1.4599)\tPrec@1 74.000 (69.758)\tPrec@5 100.000 (97.989)\n",
            "val Results: Prec@1 69.670 Prec@5 97.970 Loss 1.46697\n",
            "val Class Accuracy: [0.968,0.982,0.796,0.760,0.781,0.580,0.677,0.593,0.394,0.436]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [167][0/97], lr: 0.00010\tTime 0.463 (0.463)\tData 0.376 (0.376)\tLoss 0.0338 (0.0338)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][10/97], lr: 0.00010\tTime 0.050 (0.104)\tData 0.000 (0.038)\tLoss 0.0739 (0.0441)\tPrec@1 96.875 (98.580)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][20/97], lr: 0.00010\tTime 0.067 (0.082)\tData 0.008 (0.022)\tLoss 0.0625 (0.0414)\tPrec@1 96.875 (98.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][30/97], lr: 0.00010\tTime 0.059 (0.074)\tData 0.007 (0.018)\tLoss 0.0289 (0.0411)\tPrec@1 99.219 (98.715)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][40/97], lr: 0.00010\tTime 0.057 (0.070)\tData 0.000 (0.014)\tLoss 0.0671 (0.0417)\tPrec@1 99.219 (98.723)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][50/97], lr: 0.00010\tTime 0.104 (0.069)\tData 0.000 (0.012)\tLoss 0.0411 (0.0431)\tPrec@1 99.219 (98.790)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][60/97], lr: 0.00010\tTime 0.097 (0.073)\tData 0.000 (0.010)\tLoss 0.0409 (0.0418)\tPrec@1 99.219 (98.860)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][70/97], lr: 0.00010\tTime 0.059 (0.075)\tData 0.000 (0.010)\tLoss 0.0206 (0.0433)\tPrec@1 99.219 (98.801)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][80/97], lr: 0.00010\tTime 0.086 (0.077)\tData 0.012 (0.009)\tLoss 0.0185 (0.0432)\tPrec@1 100.000 (98.804)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][90/97], lr: 0.00010\tTime 0.047 (0.078)\tData 0.000 (0.009)\tLoss 0.0311 (0.0435)\tPrec@1 99.219 (98.815)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 1.2545 (1.2545)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.044 (0.058)\tLoss 1.0932 (1.4108)\tPrec@1 76.000 (71.000)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.3249 (1.4363)\tPrec@1 70.000 (70.238)\tPrec@5 98.000 (97.619)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.3667 (1.4600)\tPrec@1 70.000 (70.194)\tPrec@5 97.000 (97.516)\n",
            "Test: [40/100]\tTime 0.010 (0.033)\tLoss 1.3031 (1.4662)\tPrec@1 70.000 (70.049)\tPrec@5 99.000 (97.659)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.0495 (1.4343)\tPrec@1 73.000 (70.431)\tPrec@5 99.000 (97.804)\n",
            "Test: [60/100]\tTime 0.020 (0.030)\tLoss 1.1767 (1.4331)\tPrec@1 74.000 (70.459)\tPrec@5 97.000 (97.820)\n",
            "Test: [70/100]\tTime 0.014 (0.030)\tLoss 1.6128 (1.4183)\tPrec@1 69.000 (70.535)\tPrec@5 99.000 (97.817)\n",
            "Test: [80/100]\tTime 0.028 (0.030)\tLoss 1.1511 (1.4157)\tPrec@1 75.000 (70.494)\tPrec@5 95.000 (97.864)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.2884 (1.4311)\tPrec@1 76.000 (70.275)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 70.200 Prec@5 97.910 Loss 1.43856\n",
            "val Class Accuracy: [0.965,0.981,0.808,0.749,0.788,0.595,0.701,0.599,0.414,0.420]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [168][0/97], lr: 0.00010\tTime 0.505 (0.505)\tData 0.440 (0.440)\tLoss 0.0557 (0.0557)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][10/97], lr: 0.00010\tTime 0.052 (0.103)\tData 0.005 (0.046)\tLoss 0.0215 (0.0455)\tPrec@1 100.000 (98.651)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [168][20/97], lr: 0.00010\tTime 0.037 (0.081)\tData 0.000 (0.027)\tLoss 0.0444 (0.0443)\tPrec@1 98.438 (98.624)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [168][30/97], lr: 0.00010\tTime 0.046 (0.073)\tData 0.007 (0.020)\tLoss 0.0380 (0.0428)\tPrec@1 98.438 (98.715)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [168][40/97], lr: 0.00010\tTime 0.052 (0.070)\tData 0.013 (0.017)\tLoss 0.0265 (0.0448)\tPrec@1 99.219 (98.666)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [168][50/97], lr: 0.00010\tTime 0.057 (0.067)\tData 0.009 (0.015)\tLoss 0.0222 (0.0440)\tPrec@1 100.000 (98.790)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [168][60/97], lr: 0.00010\tTime 0.059 (0.066)\tData 0.006 (0.013)\tLoss 0.0306 (0.0429)\tPrec@1 99.219 (98.822)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [168][70/97], lr: 0.00010\tTime 0.057 (0.065)\tData 0.000 (0.012)\tLoss 0.0316 (0.0433)\tPrec@1 99.219 (98.768)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [168][80/97], lr: 0.00010\tTime 0.048 (0.064)\tData 0.000 (0.011)\tLoss 0.0364 (0.0432)\tPrec@1 99.219 (98.765)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [168][90/97], lr: 0.00010\tTime 0.030 (0.063)\tData 0.000 (0.010)\tLoss 0.0421 (0.0427)\tPrec@1 98.438 (98.772)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 1.2541 (1.2541)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.021 (0.055)\tLoss 1.0887 (1.4139)\tPrec@1 77.000 (71.273)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 1.3386 (1.4481)\tPrec@1 72.000 (70.476)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 1.3676 (1.4691)\tPrec@1 70.000 (70.355)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.039 (0.033)\tLoss 1.2975 (1.4733)\tPrec@1 70.000 (70.098)\tPrec@5 99.000 (97.805)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.0646 (1.4399)\tPrec@1 74.000 (70.569)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/100]\tTime 0.044 (0.031)\tLoss 1.1874 (1.4393)\tPrec@1 74.000 (70.541)\tPrec@5 97.000 (97.869)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 1.6091 (1.4230)\tPrec@1 70.000 (70.563)\tPrec@5 98.000 (97.845)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 1.1744 (1.4208)\tPrec@1 74.000 (70.481)\tPrec@5 97.000 (97.926)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.2858 (1.4357)\tPrec@1 75.000 (70.187)\tPrec@5 100.000 (98.011)\n",
            "val Results: Prec@1 70.110 Prec@5 97.960 Loss 1.44175\n",
            "val Class Accuracy: [0.968,0.985,0.811,0.767,0.770,0.584,0.699,0.583,0.404,0.440]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [169][0/97], lr: 0.00010\tTime 0.508 (0.508)\tData 0.443 (0.443)\tLoss 0.0148 (0.0148)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][10/97], lr: 0.00010\tTime 0.063 (0.103)\tData 0.006 (0.045)\tLoss 0.0157 (0.0413)\tPrec@1 100.000 (98.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][20/97], lr: 0.00010\tTime 0.066 (0.082)\tData 0.007 (0.025)\tLoss 0.0647 (0.0417)\tPrec@1 98.438 (98.847)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][30/97], lr: 0.00010\tTime 0.070 (0.075)\tData 0.000 (0.018)\tLoss 0.0215 (0.0388)\tPrec@1 100.000 (98.916)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][40/97], lr: 0.00010\tTime 0.080 (0.071)\tData 0.000 (0.015)\tLoss 0.0208 (0.0397)\tPrec@1 100.000 (98.952)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][50/97], lr: 0.00010\tTime 0.046 (0.069)\tData 0.006 (0.013)\tLoss 0.0741 (0.0386)\tPrec@1 97.656 (98.989)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][60/97], lr: 0.00010\tTime 0.059 (0.067)\tData 0.007 (0.012)\tLoss 0.0706 (0.0389)\tPrec@1 97.656 (98.988)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][70/97], lr: 0.00010\tTime 0.054 (0.066)\tData 0.006 (0.011)\tLoss 0.0253 (0.0387)\tPrec@1 100.000 (98.966)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][80/97], lr: 0.00010\tTime 0.044 (0.065)\tData 0.006 (0.010)\tLoss 0.0265 (0.0380)\tPrec@1 100.000 (99.007)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][90/97], lr: 0.00010\tTime 0.026 (0.064)\tData 0.000 (0.010)\tLoss 0.0362 (0.0387)\tPrec@1 99.219 (98.961)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.3017 (1.3017)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.053)\tLoss 1.1439 (1.4596)\tPrec@1 78.000 (70.545)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.025 (0.038)\tLoss 1.3604 (1.4941)\tPrec@1 70.000 (69.619)\tPrec@5 99.000 (97.714)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.4369 (1.5170)\tPrec@1 70.000 (69.645)\tPrec@5 95.000 (97.516)\n",
            "Test: [40/100]\tTime 0.025 (0.032)\tLoss 1.3686 (1.5220)\tPrec@1 69.000 (69.488)\tPrec@5 99.000 (97.683)\n",
            "Test: [50/100]\tTime 0.031 (0.031)\tLoss 1.1046 (1.4891)\tPrec@1 75.000 (70.020)\tPrec@5 98.000 (97.745)\n",
            "Test: [60/100]\tTime 0.018 (0.029)\tLoss 1.1935 (1.4868)\tPrec@1 74.000 (69.967)\tPrec@5 97.000 (97.787)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 1.6326 (1.4698)\tPrec@1 68.000 (69.901)\tPrec@5 99.000 (97.775)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.2361 (1.4670)\tPrec@1 74.000 (69.914)\tPrec@5 95.000 (97.827)\n",
            "Test: [90/100]\tTime 0.015 (0.028)\tLoss 1.3441 (1.4827)\tPrec@1 74.000 (69.560)\tPrec@5 100.000 (97.901)\n",
            "val Results: Prec@1 69.560 Prec@5 97.890 Loss 1.48871\n",
            "val Class Accuracy: [0.972,0.983,0.794,0.777,0.769,0.592,0.696,0.591,0.349,0.433]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [170][0/97], lr: 0.00010\tTime 0.478 (0.478)\tData 0.396 (0.396)\tLoss 0.0259 (0.0259)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][10/97], lr: 0.00010\tTime 0.058 (0.100)\tData 0.005 (0.041)\tLoss 0.0382 (0.0496)\tPrec@1 99.219 (98.793)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][20/97], lr: 0.00010\tTime 0.069 (0.081)\tData 0.011 (0.025)\tLoss 0.0796 (0.0413)\tPrec@1 96.094 (98.847)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][30/97], lr: 0.00010\tTime 0.065 (0.073)\tData 0.007 (0.020)\tLoss 0.0310 (0.0400)\tPrec@1 100.000 (98.967)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][40/97], lr: 0.00010\tTime 0.040 (0.069)\tData 0.006 (0.016)\tLoss 0.0836 (0.0390)\tPrec@1 97.656 (99.009)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][50/97], lr: 0.00010\tTime 0.060 (0.067)\tData 0.000 (0.014)\tLoss 0.0167 (0.0406)\tPrec@1 100.000 (98.958)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][60/97], lr: 0.00010\tTime 0.045 (0.066)\tData 0.005 (0.013)\tLoss 0.0370 (0.0393)\tPrec@1 99.219 (98.963)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][70/97], lr: 0.00010\tTime 0.053 (0.065)\tData 0.000 (0.012)\tLoss 0.0650 (0.0384)\tPrec@1 97.656 (98.988)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][80/97], lr: 0.00010\tTime 0.042 (0.064)\tData 0.000 (0.011)\tLoss 0.0326 (0.0375)\tPrec@1 98.438 (99.035)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][90/97], lr: 0.00010\tTime 0.040 (0.064)\tData 0.000 (0.010)\tLoss 0.0491 (0.0373)\tPrec@1 99.219 (99.073)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 1.2332 (1.2332)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.029 (0.054)\tLoss 1.0702 (1.3877)\tPrec@1 77.000 (72.091)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.017 (0.040)\tLoss 1.3401 (1.4189)\tPrec@1 71.000 (70.952)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.3639 (1.4434)\tPrec@1 70.000 (70.806)\tPrec@5 97.000 (97.710)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 1.2805 (1.4490)\tPrec@1 70.000 (70.659)\tPrec@5 99.000 (97.854)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 1.0405 (1.4168)\tPrec@1 74.000 (71.098)\tPrec@5 98.000 (97.941)\n",
            "Test: [60/100]\tTime 0.034 (0.030)\tLoss 1.1491 (1.4158)\tPrec@1 74.000 (71.082)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 1.5742 (1.3994)\tPrec@1 71.000 (71.113)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 1.1642 (1.3964)\tPrec@1 75.000 (71.099)\tPrec@5 95.000 (97.951)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.2646 (1.4115)\tPrec@1 76.000 (70.802)\tPrec@5 100.000 (98.022)\n",
            "val Results: Prec@1 70.760 Prec@5 98.010 Loss 1.41772\n",
            "val Class Accuracy: [0.969,0.984,0.811,0.767,0.786,0.599,0.702,0.592,0.417,0.449]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [171][0/97], lr: 0.00010\tTime 0.465 (0.465)\tData 0.392 (0.392)\tLoss 0.0351 (0.0351)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][10/97], lr: 0.00010\tTime 0.042 (0.100)\tData 0.000 (0.042)\tLoss 0.0422 (0.0377)\tPrec@1 98.438 (98.864)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][20/97], lr: 0.00010\tTime 0.049 (0.081)\tData 0.001 (0.025)\tLoss 0.0336 (0.0352)\tPrec@1 99.219 (99.107)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][30/97], lr: 0.00010\tTime 0.052 (0.073)\tData 0.005 (0.020)\tLoss 0.0222 (0.0358)\tPrec@1 100.000 (99.143)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][40/97], lr: 0.00010\tTime 0.071 (0.069)\tData 0.007 (0.016)\tLoss 0.0260 (0.0375)\tPrec@1 100.000 (99.028)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][50/97], lr: 0.00010\tTime 0.036 (0.067)\tData 0.000 (0.013)\tLoss 0.0307 (0.0368)\tPrec@1 99.219 (99.020)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][60/97], lr: 0.00010\tTime 0.072 (0.066)\tData 0.002 (0.012)\tLoss 0.0346 (0.0357)\tPrec@1 99.219 (99.065)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][70/97], lr: 0.00010\tTime 0.055 (0.065)\tData 0.007 (0.011)\tLoss 0.0307 (0.0359)\tPrec@1 99.219 (99.021)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][80/97], lr: 0.00010\tTime 0.047 (0.064)\tData 0.000 (0.011)\tLoss 0.0378 (0.0362)\tPrec@1 99.219 (98.987)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][90/97], lr: 0.00010\tTime 0.031 (0.063)\tData 0.000 (0.010)\tLoss 0.0671 (0.0377)\tPrec@1 97.656 (98.918)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.289 (0.289)\tLoss 1.2139 (1.2139)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.043 (0.056)\tLoss 1.0953 (1.3827)\tPrec@1 77.000 (72.182)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.021 (0.040)\tLoss 1.3389 (1.4155)\tPrec@1 70.000 (71.048)\tPrec@5 99.000 (98.048)\n",
            "Test: [30/100]\tTime 0.020 (0.038)\tLoss 1.3738 (1.4401)\tPrec@1 71.000 (71.000)\tPrec@5 96.000 (97.839)\n",
            "Test: [40/100]\tTime 0.021 (0.034)\tLoss 1.2712 (1.4450)\tPrec@1 71.000 (70.829)\tPrec@5 99.000 (97.976)\n",
            "Test: [50/100]\tTime 0.014 (0.032)\tLoss 1.0562 (1.4134)\tPrec@1 74.000 (71.216)\tPrec@5 98.000 (98.020)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 1.1391 (1.4129)\tPrec@1 75.000 (71.197)\tPrec@5 97.000 (98.016)\n",
            "Test: [70/100]\tTime 0.029 (0.031)\tLoss 1.5632 (1.3964)\tPrec@1 72.000 (71.254)\tPrec@5 99.000 (97.986)\n",
            "Test: [80/100]\tTime 0.018 (0.030)\tLoss 1.1609 (1.3932)\tPrec@1 75.000 (71.222)\tPrec@5 96.000 (98.049)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.2698 (1.4083)\tPrec@1 75.000 (70.901)\tPrec@5 100.000 (98.099)\n",
            "val Results: Prec@1 70.880 Prec@5 98.070 Loss 1.41414\n",
            "val Class Accuracy: [0.970,0.983,0.816,0.769,0.781,0.599,0.692,0.602,0.419,0.457]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [172][0/97], lr: 0.00010\tTime 0.498 (0.498)\tData 0.418 (0.418)\tLoss 0.0537 (0.0537)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][10/97], lr: 0.00010\tTime 0.047 (0.103)\tData 0.005 (0.044)\tLoss 0.0202 (0.0339)\tPrec@1 100.000 (98.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][20/97], lr: 0.00010\tTime 0.075 (0.083)\tData 0.012 (0.025)\tLoss 0.0220 (0.0348)\tPrec@1 99.219 (99.107)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][30/97], lr: 0.00010\tTime 0.068 (0.074)\tData 0.009 (0.019)\tLoss 0.0447 (0.0361)\tPrec@1 98.438 (98.967)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][40/97], lr: 0.00010\tTime 0.063 (0.070)\tData 0.010 (0.016)\tLoss 0.0187 (0.0355)\tPrec@1 100.000 (99.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][50/97], lr: 0.00010\tTime 0.041 (0.067)\tData 0.000 (0.014)\tLoss 0.0269 (0.0347)\tPrec@1 100.000 (99.112)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][60/97], lr: 0.00010\tTime 0.057 (0.066)\tData 0.007 (0.012)\tLoss 0.0329 (0.0351)\tPrec@1 98.438 (99.065)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][70/97], lr: 0.00010\tTime 0.061 (0.065)\tData 0.009 (0.011)\tLoss 0.0487 (0.0350)\tPrec@1 99.219 (99.087)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][80/97], lr: 0.00010\tTime 0.046 (0.064)\tData 0.000 (0.011)\tLoss 0.0530 (0.0352)\tPrec@1 96.875 (99.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][90/97], lr: 0.00010\tTime 0.043 (0.063)\tData 0.000 (0.010)\tLoss 0.0072 (0.0344)\tPrec@1 100.000 (99.124)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.337 (0.337)\tLoss 1.2677 (1.2677)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.043 (0.057)\tLoss 1.1352 (1.4326)\tPrec@1 79.000 (71.727)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.050 (0.044)\tLoss 1.3510 (1.4661)\tPrec@1 69.000 (70.857)\tPrec@5 100.000 (97.857)\n",
            "Test: [30/100]\tTime 0.026 (0.038)\tLoss 1.3952 (1.4893)\tPrec@1 69.000 (70.516)\tPrec@5 96.000 (97.645)\n",
            "Test: [40/100]\tTime 0.024 (0.036)\tLoss 1.3319 (1.4934)\tPrec@1 69.000 (70.220)\tPrec@5 99.000 (97.780)\n",
            "Test: [50/100]\tTime 0.031 (0.034)\tLoss 1.1110 (1.4628)\tPrec@1 71.000 (70.510)\tPrec@5 98.000 (97.804)\n",
            "Test: [60/100]\tTime 0.022 (0.033)\tLoss 1.1457 (1.4620)\tPrec@1 75.000 (70.459)\tPrec@5 97.000 (97.820)\n",
            "Test: [70/100]\tTime 0.030 (0.032)\tLoss 1.6262 (1.4454)\tPrec@1 70.000 (70.451)\tPrec@5 99.000 (97.817)\n",
            "Test: [80/100]\tTime 0.037 (0.031)\tLoss 1.2049 (1.4420)\tPrec@1 74.000 (70.469)\tPrec@5 95.000 (97.864)\n",
            "Test: [90/100]\tTime 0.031 (0.030)\tLoss 1.3278 (1.4584)\tPrec@1 74.000 (70.165)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 70.140 Prec@5 97.940 Loss 1.46507\n",
            "val Class Accuracy: [0.973,0.981,0.821,0.759,0.765,0.610,0.678,0.590,0.404,0.433]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [173][0/97], lr: 0.00010\tTime 0.393 (0.393)\tData 0.315 (0.315)\tLoss 0.0327 (0.0327)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][10/97], lr: 0.00010\tTime 0.047 (0.103)\tData 0.000 (0.038)\tLoss 0.0540 (0.0325)\tPrec@1 97.656 (99.006)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][20/97], lr: 0.00010\tTime 0.056 (0.080)\tData 0.000 (0.021)\tLoss 0.0789 (0.0330)\tPrec@1 96.875 (98.996)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][30/97], lr: 0.00010\tTime 0.051 (0.073)\tData 0.006 (0.017)\tLoss 0.0253 (0.0338)\tPrec@1 100.000 (99.042)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][40/97], lr: 0.00010\tTime 0.067 (0.070)\tData 0.004 (0.014)\tLoss 0.0399 (0.0347)\tPrec@1 98.438 (99.028)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][50/97], lr: 0.00010\tTime 0.061 (0.068)\tData 0.007 (0.012)\tLoss 0.0123 (0.0332)\tPrec@1 100.000 (99.035)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][60/97], lr: 0.00010\tTime 0.050 (0.066)\tData 0.005 (0.011)\tLoss 0.0482 (0.0344)\tPrec@1 98.438 (99.014)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][70/97], lr: 0.00010\tTime 0.071 (0.065)\tData 0.009 (0.010)\tLoss 0.0543 (0.0342)\tPrec@1 98.438 (99.021)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][80/97], lr: 0.00010\tTime 0.038 (0.064)\tData 0.000 (0.009)\tLoss 0.0219 (0.0332)\tPrec@1 100.000 (99.064)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][90/97], lr: 0.00010\tTime 0.039 (0.063)\tData 0.000 (0.008)\tLoss 0.0123 (0.0350)\tPrec@1 100.000 (98.987)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 1.2164 (1.2164)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.013 (0.053)\tLoss 1.0981 (1.3873)\tPrec@1 78.000 (72.000)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/100]\tTime 0.013 (0.042)\tLoss 1.3540 (1.4247)\tPrec@1 71.000 (71.333)\tPrec@5 99.000 (97.857)\n",
            "Test: [30/100]\tTime 0.039 (0.037)\tLoss 1.3604 (1.4469)\tPrec@1 71.000 (71.226)\tPrec@5 97.000 (97.710)\n",
            "Test: [40/100]\tTime 0.012 (0.033)\tLoss 1.2605 (1.4495)\tPrec@1 69.000 (70.951)\tPrec@5 99.000 (97.854)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 1.0605 (1.4186)\tPrec@1 74.000 (71.275)\tPrec@5 98.000 (97.902)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 1.1458 (1.4190)\tPrec@1 74.000 (71.197)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.5675 (1.4022)\tPrec@1 72.000 (71.239)\tPrec@5 98.000 (97.873)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 1.1683 (1.3991)\tPrec@1 75.000 (71.185)\tPrec@5 97.000 (97.951)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.2732 (1.4144)\tPrec@1 77.000 (70.945)\tPrec@5 100.000 (98.022)\n",
            "val Results: Prec@1 70.900 Prec@5 98.000 Loss 1.42019\n",
            "val Class Accuracy: [0.972,0.984,0.811,0.770,0.780,0.583,0.710,0.601,0.414,0.465]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [174][0/97], lr: 0.00010\tTime 0.439 (0.439)\tData 0.364 (0.364)\tLoss 0.0656 (0.0656)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][10/97], lr: 0.00010\tTime 0.052 (0.101)\tData 0.012 (0.038)\tLoss 0.0257 (0.0395)\tPrec@1 99.219 (98.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][20/97], lr: 0.00010\tTime 0.063 (0.080)\tData 0.010 (0.023)\tLoss 0.0322 (0.0353)\tPrec@1 99.219 (99.070)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][30/97], lr: 0.00010\tTime 0.045 (0.074)\tData 0.007 (0.018)\tLoss 0.0351 (0.0325)\tPrec@1 99.219 (99.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][40/97], lr: 0.00010\tTime 0.072 (0.071)\tData 0.001 (0.015)\tLoss 0.0414 (0.0319)\tPrec@1 99.219 (99.200)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][50/97], lr: 0.00010\tTime 0.052 (0.068)\tData 0.012 (0.013)\tLoss 0.0194 (0.0335)\tPrec@1 100.000 (99.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][60/97], lr: 0.00010\tTime 0.054 (0.066)\tData 0.007 (0.012)\tLoss 0.0312 (0.0334)\tPrec@1 98.438 (99.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][70/97], lr: 0.00010\tTime 0.055 (0.065)\tData 0.005 (0.011)\tLoss 0.0399 (0.0338)\tPrec@1 98.438 (99.076)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][80/97], lr: 0.00010\tTime 0.060 (0.064)\tData 0.000 (0.010)\tLoss 0.0385 (0.0339)\tPrec@1 98.438 (99.055)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][90/97], lr: 0.00010\tTime 0.032 (0.063)\tData 0.000 (0.009)\tLoss 0.0231 (0.0341)\tPrec@1 99.219 (99.056)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 1.2630 (1.2630)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.032 (0.057)\tLoss 1.1397 (1.4209)\tPrec@1 78.000 (71.909)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 1.3593 (1.4516)\tPrec@1 70.000 (70.952)\tPrec@5 100.000 (97.857)\n",
            "Test: [30/100]\tTime 0.020 (0.037)\tLoss 1.3812 (1.4737)\tPrec@1 72.000 (70.806)\tPrec@5 96.000 (97.645)\n",
            "Test: [40/100]\tTime 0.030 (0.034)\tLoss 1.3132 (1.4775)\tPrec@1 69.000 (70.512)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 1.0685 (1.4475)\tPrec@1 73.000 (70.902)\tPrec@5 98.000 (97.804)\n",
            "Test: [60/100]\tTime 0.018 (0.031)\tLoss 1.1487 (1.4473)\tPrec@1 75.000 (70.836)\tPrec@5 97.000 (97.820)\n",
            "Test: [70/100]\tTime 0.021 (0.030)\tLoss 1.6140 (1.4317)\tPrec@1 69.000 (70.803)\tPrec@5 99.000 (97.817)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 1.1916 (1.4283)\tPrec@1 75.000 (70.765)\tPrec@5 95.000 (97.877)\n",
            "Test: [90/100]\tTime 0.016 (0.029)\tLoss 1.3219 (1.4446)\tPrec@1 76.000 (70.516)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 70.450 Prec@5 97.940 Loss 1.45090\n",
            "val Class Accuracy: [0.971,0.985,0.815,0.767,0.786,0.605,0.689,0.601,0.382,0.444]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [175][0/97], lr: 0.00010\tTime 0.412 (0.412)\tData 0.321 (0.321)\tLoss 0.0416 (0.0416)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][10/97], lr: 0.00010\tTime 0.045 (0.104)\tData 0.000 (0.039)\tLoss 0.0169 (0.0256)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][20/97], lr: 0.00010\tTime 0.063 (0.081)\tData 0.007 (0.022)\tLoss 0.0386 (0.0267)\tPrec@1 98.438 (99.442)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][30/97], lr: 0.00010\tTime 0.060 (0.074)\tData 0.000 (0.016)\tLoss 0.0313 (0.0295)\tPrec@1 98.438 (99.269)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][40/97], lr: 0.00010\tTime 0.040 (0.069)\tData 0.004 (0.013)\tLoss 0.0456 (0.0294)\tPrec@1 98.438 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][50/97], lr: 0.00010\tTime 0.064 (0.068)\tData 0.007 (0.012)\tLoss 0.0171 (0.0305)\tPrec@1 100.000 (99.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][60/97], lr: 0.00010\tTime 0.047 (0.066)\tData 0.007 (0.011)\tLoss 0.0445 (0.0316)\tPrec@1 98.438 (99.155)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][70/97], lr: 0.00010\tTime 0.059 (0.065)\tData 0.000 (0.010)\tLoss 0.0414 (0.0320)\tPrec@1 97.656 (99.098)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][80/97], lr: 0.00010\tTime 0.082 (0.064)\tData 0.002 (0.009)\tLoss 0.0131 (0.0308)\tPrec@1 100.000 (99.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][90/97], lr: 0.00010\tTime 0.039 (0.063)\tData 0.000 (0.009)\tLoss 0.0398 (0.0301)\tPrec@1 99.219 (99.193)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 1.2572 (1.2572)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.011 (0.058)\tLoss 1.1150 (1.4084)\tPrec@1 78.000 (72.364)\tPrec@5 98.000 (98.182)\n",
            "Test: [20/100]\tTime 0.022 (0.039)\tLoss 1.3716 (1.4395)\tPrec@1 70.000 (71.429)\tPrec@5 99.000 (97.762)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.3555 (1.4608)\tPrec@1 72.000 (71.161)\tPrec@5 97.000 (97.613)\n",
            "Test: [40/100]\tTime 0.015 (0.034)\tLoss 1.2889 (1.4648)\tPrec@1 69.000 (70.902)\tPrec@5 98.000 (97.780)\n",
            "Test: [50/100]\tTime 0.029 (0.032)\tLoss 1.0584 (1.4363)\tPrec@1 73.000 (71.176)\tPrec@5 98.000 (97.824)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 1.1544 (1.4358)\tPrec@1 76.000 (71.082)\tPrec@5 97.000 (97.836)\n",
            "Test: [70/100]\tTime 0.025 (0.030)\tLoss 1.6052 (1.4198)\tPrec@1 72.000 (71.042)\tPrec@5 99.000 (97.803)\n",
            "Test: [80/100]\tTime 0.024 (0.030)\tLoss 1.1501 (1.4166)\tPrec@1 75.000 (71.000)\tPrec@5 96.000 (97.877)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.3108 (1.4330)\tPrec@1 76.000 (70.747)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 70.680 Prec@5 97.910 Loss 1.43999\n",
            "val Class Accuracy: [0.974,0.986,0.813,0.764,0.799,0.603,0.692,0.591,0.410,0.436]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [176][0/97], lr: 0.00010\tTime 0.405 (0.405)\tData 0.321 (0.321)\tLoss 0.0225 (0.0225)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][10/97], lr: 0.00010\tTime 0.045 (0.101)\tData 0.003 (0.035)\tLoss 0.0615 (0.0317)\tPrec@1 97.656 (99.077)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][20/97], lr: 0.00010\tTime 0.078 (0.081)\tData 0.006 (0.021)\tLoss 0.0197 (0.0321)\tPrec@1 99.219 (99.182)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][30/97], lr: 0.00010\tTime 0.067 (0.073)\tData 0.007 (0.015)\tLoss 0.0207 (0.0317)\tPrec@1 100.000 (99.294)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][40/97], lr: 0.00010\tTime 0.057 (0.070)\tData 0.007 (0.012)\tLoss 0.0193 (0.0319)\tPrec@1 99.219 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][50/97], lr: 0.00010\tTime 0.056 (0.067)\tData 0.000 (0.010)\tLoss 0.0233 (0.0321)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][60/97], lr: 0.00010\tTime 0.058 (0.065)\tData 0.005 (0.010)\tLoss 0.0250 (0.0312)\tPrec@1 99.219 (99.244)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][70/97], lr: 0.00010\tTime 0.073 (0.065)\tData 0.007 (0.009)\tLoss 0.0286 (0.0312)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][80/97], lr: 0.00010\tTime 0.070 (0.063)\tData 0.002 (0.009)\tLoss 0.0894 (0.0322)\tPrec@1 95.312 (99.151)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][90/97], lr: 0.00010\tTime 0.033 (0.062)\tData 0.000 (0.008)\tLoss 0.0213 (0.0326)\tPrec@1 100.000 (99.141)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.272 (0.272)\tLoss 1.2396 (1.2396)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.041 (0.056)\tLoss 1.1238 (1.4113)\tPrec@1 78.000 (72.000)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.018 (0.040)\tLoss 1.3690 (1.4475)\tPrec@1 73.000 (71.333)\tPrec@5 100.000 (97.952)\n",
            "Test: [30/100]\tTime 0.038 (0.036)\tLoss 1.3705 (1.4670)\tPrec@1 71.000 (71.226)\tPrec@5 96.000 (97.742)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 1.2992 (1.4695)\tPrec@1 69.000 (70.976)\tPrec@5 98.000 (97.854)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.0625 (1.4397)\tPrec@1 74.000 (71.216)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 1.1542 (1.4395)\tPrec@1 75.000 (71.180)\tPrec@5 97.000 (97.885)\n",
            "Test: [70/100]\tTime 0.010 (0.030)\tLoss 1.5864 (1.4230)\tPrec@1 71.000 (71.141)\tPrec@5 99.000 (97.873)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 1.1861 (1.4197)\tPrec@1 75.000 (71.074)\tPrec@5 96.000 (97.926)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 1.3174 (1.4354)\tPrec@1 76.000 (70.791)\tPrec@5 100.000 (97.989)\n",
            "val Results: Prec@1 70.750 Prec@5 97.990 Loss 1.44111\n",
            "val Class Accuracy: [0.972,0.985,0.815,0.773,0.782,0.586,0.709,0.608,0.379,0.466]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [177][0/97], lr: 0.00010\tTime 0.406 (0.406)\tData 0.336 (0.336)\tLoss 0.0310 (0.0310)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][10/97], lr: 0.00010\tTime 0.041 (0.100)\tData 0.000 (0.038)\tLoss 0.0319 (0.0293)\tPrec@1 99.219 (99.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][20/97], lr: 0.00010\tTime 0.042 (0.082)\tData 0.007 (0.022)\tLoss 0.0278 (0.0282)\tPrec@1 99.219 (99.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][30/97], lr: 0.00010\tTime 0.060 (0.073)\tData 0.000 (0.017)\tLoss 0.0406 (0.0287)\tPrec@1 99.219 (99.370)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][40/97], lr: 0.00010\tTime 0.049 (0.070)\tData 0.005 (0.014)\tLoss 0.0598 (0.0295)\tPrec@1 97.656 (99.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][50/97], lr: 0.00010\tTime 0.055 (0.068)\tData 0.000 (0.012)\tLoss 0.0306 (0.0296)\tPrec@1 99.219 (99.341)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][60/97], lr: 0.00010\tTime 0.059 (0.065)\tData 0.004 (0.011)\tLoss 0.0318 (0.0300)\tPrec@1 99.219 (99.308)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][70/97], lr: 0.00010\tTime 0.066 (0.065)\tData 0.005 (0.010)\tLoss 0.0298 (0.0297)\tPrec@1 99.219 (99.318)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][80/97], lr: 0.00010\tTime 0.062 (0.064)\tData 0.005 (0.009)\tLoss 0.0185 (0.0291)\tPrec@1 99.219 (99.306)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][90/97], lr: 0.00010\tTime 0.032 (0.062)\tData 0.000 (0.009)\tLoss 0.0192 (0.0297)\tPrec@1 100.000 (99.279)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 1.2916 (1.2916)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.023 (0.053)\tLoss 1.1416 (1.4461)\tPrec@1 78.000 (71.636)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/100]\tTime 0.016 (0.039)\tLoss 1.3901 (1.4771)\tPrec@1 71.000 (70.952)\tPrec@5 100.000 (97.905)\n",
            "Test: [30/100]\tTime 0.032 (0.035)\tLoss 1.3848 (1.4983)\tPrec@1 71.000 (70.677)\tPrec@5 97.000 (97.742)\n",
            "Test: [40/100]\tTime 0.039 (0.033)\tLoss 1.3562 (1.5035)\tPrec@1 69.000 (70.390)\tPrec@5 98.000 (97.854)\n",
            "Test: [50/100]\tTime 0.016 (0.031)\tLoss 1.1050 (1.4738)\tPrec@1 72.000 (70.706)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 1.1788 (1.4746)\tPrec@1 75.000 (70.607)\tPrec@5 97.000 (97.885)\n",
            "Test: [70/100]\tTime 0.029 (0.029)\tLoss 1.6348 (1.4571)\tPrec@1 71.000 (70.563)\tPrec@5 99.000 (97.859)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 1.2071 (1.4537)\tPrec@1 75.000 (70.506)\tPrec@5 96.000 (97.914)\n",
            "Test: [90/100]\tTime 0.021 (0.028)\tLoss 1.3418 (1.4698)\tPrec@1 75.000 (70.253)\tPrec@5 100.000 (97.967)\n",
            "val Results: Prec@1 70.260 Prec@5 97.930 Loss 1.47644\n",
            "val Class Accuracy: [0.976,0.985,0.813,0.779,0.788,0.586,0.699,0.571,0.401,0.428]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [178][0/97], lr: 0.00010\tTime 0.485 (0.485)\tData 0.391 (0.391)\tLoss 0.0591 (0.0591)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][10/97], lr: 0.00010\tTime 0.058 (0.103)\tData 0.013 (0.041)\tLoss 0.0340 (0.0295)\tPrec@1 98.438 (99.148)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][20/97], lr: 0.00010\tTime 0.058 (0.081)\tData 0.008 (0.023)\tLoss 0.0162 (0.0309)\tPrec@1 100.000 (99.070)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][30/97], lr: 0.00010\tTime 0.034 (0.072)\tData 0.000 (0.016)\tLoss 0.0289 (0.0274)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][40/97], lr: 0.00010\tTime 0.067 (0.069)\tData 0.007 (0.014)\tLoss 0.0311 (0.0295)\tPrec@1 98.438 (99.066)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][50/97], lr: 0.00010\tTime 0.050 (0.067)\tData 0.007 (0.012)\tLoss 0.0455 (0.0284)\tPrec@1 99.219 (99.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][60/97], lr: 0.00010\tTime 0.062 (0.066)\tData 0.014 (0.012)\tLoss 0.0475 (0.0292)\tPrec@1 97.656 (99.129)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][70/97], lr: 0.00010\tTime 0.042 (0.065)\tData 0.000 (0.011)\tLoss 0.0217 (0.0293)\tPrec@1 100.000 (99.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][80/97], lr: 0.00010\tTime 0.046 (0.064)\tData 0.004 (0.010)\tLoss 0.0228 (0.0288)\tPrec@1 100.000 (99.180)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][90/97], lr: 0.00010\tTime 0.043 (0.063)\tData 0.000 (0.010)\tLoss 0.0411 (0.0291)\tPrec@1 98.438 (99.159)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.316 (0.316)\tLoss 1.2036 (1.2036)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.015 (0.055)\tLoss 1.0595 (1.3700)\tPrec@1 79.000 (72.727)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.032 (0.040)\tLoss 1.3460 (1.4071)\tPrec@1 73.000 (72.143)\tPrec@5 100.000 (98.000)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 1.3403 (1.4281)\tPrec@1 73.000 (71.903)\tPrec@5 97.000 (97.871)\n",
            "Test: [40/100]\tTime 0.020 (0.033)\tLoss 1.2609 (1.4327)\tPrec@1 71.000 (71.659)\tPrec@5 98.000 (97.976)\n",
            "Test: [50/100]\tTime 0.028 (0.031)\tLoss 1.0506 (1.4034)\tPrec@1 74.000 (71.922)\tPrec@5 98.000 (98.000)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.1462 (1.4032)\tPrec@1 74.000 (71.803)\tPrec@5 97.000 (98.000)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 1.5508 (1.3850)\tPrec@1 72.000 (71.789)\tPrec@5 99.000 (97.986)\n",
            "Test: [80/100]\tTime 0.035 (0.029)\tLoss 1.1315 (1.3821)\tPrec@1 74.000 (71.716)\tPrec@5 97.000 (98.037)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 1.2759 (1.3964)\tPrec@1 77.000 (71.516)\tPrec@5 100.000 (98.099)\n",
            "val Results: Prec@1 71.450 Prec@5 98.080 Loss 1.40238\n",
            "val Class Accuracy: [0.968,0.987,0.812,0.770,0.785,0.617,0.716,0.595,0.431,0.464]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [179][0/97], lr: 0.00010\tTime 0.469 (0.469)\tData 0.365 (0.365)\tLoss 0.0408 (0.0408)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][10/97], lr: 0.00010\tTime 0.065 (0.101)\tData 0.006 (0.037)\tLoss 0.0273 (0.0358)\tPrec@1 99.219 (99.077)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][20/97], lr: 0.00010\tTime 0.056 (0.080)\tData 0.000 (0.021)\tLoss 0.0137 (0.0327)\tPrec@1 100.000 (99.107)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][30/97], lr: 0.00010\tTime 0.082 (0.073)\tData 0.016 (0.016)\tLoss 0.0168 (0.0316)\tPrec@1 99.219 (99.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][40/97], lr: 0.00010\tTime 0.061 (0.069)\tData 0.007 (0.014)\tLoss 0.0174 (0.0317)\tPrec@1 100.000 (99.200)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][50/97], lr: 0.00010\tTime 0.063 (0.067)\tData 0.007 (0.012)\tLoss 0.0220 (0.0304)\tPrec@1 99.219 (99.234)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][60/97], lr: 0.00010\tTime 0.060 (0.066)\tData 0.007 (0.011)\tLoss 0.0300 (0.0300)\tPrec@1 99.219 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][70/97], lr: 0.00010\tTime 0.065 (0.064)\tData 0.008 (0.010)\tLoss 0.0238 (0.0308)\tPrec@1 100.000 (99.263)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][80/97], lr: 0.00010\tTime 0.046 (0.063)\tData 0.004 (0.010)\tLoss 0.0186 (0.0302)\tPrec@1 100.000 (99.277)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][90/97], lr: 0.00010\tTime 0.030 (0.063)\tData 0.000 (0.009)\tLoss 0.0221 (0.0301)\tPrec@1 100.000 (99.279)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.366 (0.366)\tLoss 1.2180 (1.2180)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.030 (0.053)\tLoss 1.1081 (1.3850)\tPrec@1 78.000 (72.455)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.037 (0.041)\tLoss 1.3519 (1.4220)\tPrec@1 71.000 (71.524)\tPrec@5 99.000 (98.048)\n",
            "Test: [30/100]\tTime 0.037 (0.036)\tLoss 1.3599 (1.4441)\tPrec@1 72.000 (71.516)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.2815 (1.4471)\tPrec@1 69.000 (71.366)\tPrec@5 98.000 (97.927)\n",
            "Test: [50/100]\tTime 0.046 (0.032)\tLoss 1.0519 (1.4182)\tPrec@1 76.000 (71.706)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.012 (0.031)\tLoss 1.1275 (1.4177)\tPrec@1 75.000 (71.590)\tPrec@5 97.000 (97.934)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 1.5753 (1.4005)\tPrec@1 72.000 (71.549)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/100]\tTime 0.021 (0.029)\tLoss 1.1625 (1.3967)\tPrec@1 75.000 (71.481)\tPrec@5 97.000 (97.975)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 1.3040 (1.4129)\tPrec@1 77.000 (71.220)\tPrec@5 100.000 (98.033)\n",
            "val Results: Prec@1 71.150 Prec@5 98.010 Loss 1.41899\n",
            "val Class Accuracy: [0.976,0.986,0.808,0.775,0.788,0.603,0.701,0.608,0.407,0.463]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [180][0/97], lr: 0.00000\tTime 0.507 (0.507)\tData 0.426 (0.426)\tLoss 0.0240 (0.0240)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][10/97], lr: 0.00000\tTime 0.065 (0.101)\tData 0.000 (0.043)\tLoss 0.0145 (0.0314)\tPrec@1 100.000 (99.290)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][20/97], lr: 0.00000\tTime 0.039 (0.079)\tData 0.000 (0.025)\tLoss 0.0264 (0.0305)\tPrec@1 99.219 (99.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][30/97], lr: 0.00000\tTime 0.065 (0.072)\tData 0.000 (0.019)\tLoss 0.0128 (0.0287)\tPrec@1 100.000 (99.269)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][40/97], lr: 0.00000\tTime 0.071 (0.069)\tData 0.000 (0.015)\tLoss 0.0212 (0.0283)\tPrec@1 100.000 (99.276)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][50/97], lr: 0.00000\tTime 0.048 (0.066)\tData 0.005 (0.013)\tLoss 0.0248 (0.0284)\tPrec@1 99.219 (99.265)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][60/97], lr: 0.00000\tTime 0.056 (0.065)\tData 0.010 (0.012)\tLoss 0.0161 (0.0282)\tPrec@1 99.219 (99.296)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][70/97], lr: 0.00000\tTime 0.077 (0.064)\tData 0.012 (0.011)\tLoss 0.0296 (0.0288)\tPrec@1 99.219 (99.252)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][80/97], lr: 0.00000\tTime 0.064 (0.063)\tData 0.000 (0.010)\tLoss 0.0159 (0.0288)\tPrec@1 100.000 (99.267)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][90/97], lr: 0.00000\tTime 0.040 (0.062)\tData 0.000 (0.010)\tLoss 0.0430 (0.0291)\tPrec@1 97.656 (99.245)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.259 (0.259)\tLoss 1.2398 (1.2398)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.056)\tLoss 1.1228 (1.4048)\tPrec@1 78.000 (72.000)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.044 (0.042)\tLoss 1.3537 (1.4455)\tPrec@1 71.000 (71.286)\tPrec@5 100.000 (98.000)\n",
            "Test: [30/100]\tTime 0.041 (0.035)\tLoss 1.3835 (1.4654)\tPrec@1 71.000 (71.226)\tPrec@5 97.000 (97.806)\n",
            "Test: [40/100]\tTime 0.042 (0.033)\tLoss 1.3043 (1.4684)\tPrec@1 69.000 (71.000)\tPrec@5 98.000 (97.902)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 1.0998 (1.4392)\tPrec@1 73.000 (71.275)\tPrec@5 98.000 (97.941)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 1.1430 (1.4386)\tPrec@1 75.000 (71.164)\tPrec@5 97.000 (97.934)\n",
            "Test: [70/100]\tTime 0.033 (0.029)\tLoss 1.5810 (1.4201)\tPrec@1 71.000 (71.127)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 1.1884 (1.4169)\tPrec@1 74.000 (71.099)\tPrec@5 97.000 (97.988)\n",
            "Test: [90/100]\tTime 0.023 (0.028)\tLoss 1.3169 (1.4324)\tPrec@1 75.000 (70.802)\tPrec@5 100.000 (98.044)\n",
            "val Results: Prec@1 70.750 Prec@5 98.020 Loss 1.43820\n",
            "val Class Accuracy: [0.973,0.987,0.810,0.777,0.773,0.612,0.692,0.596,0.404,0.451]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [181][0/97], lr: 0.00000\tTime 0.363 (0.363)\tData 0.298 (0.298)\tLoss 0.0594 (0.0594)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][10/97], lr: 0.00000\tTime 0.044 (0.099)\tData 0.000 (0.037)\tLoss 0.0120 (0.0235)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][20/97], lr: 0.00000\tTime 0.061 (0.080)\tData 0.007 (0.022)\tLoss 0.0364 (0.0267)\tPrec@1 99.219 (99.368)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][30/97], lr: 0.00000\tTime 0.037 (0.072)\tData 0.000 (0.016)\tLoss 0.0339 (0.0281)\tPrec@1 99.219 (99.320)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][40/97], lr: 0.00000\tTime 0.064 (0.068)\tData 0.009 (0.013)\tLoss 0.0239 (0.0279)\tPrec@1 100.000 (99.333)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][50/97], lr: 0.00000\tTime 0.058 (0.067)\tData 0.007 (0.012)\tLoss 0.0564 (0.0295)\tPrec@1 96.094 (99.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][60/97], lr: 0.00000\tTime 0.064 (0.065)\tData 0.000 (0.011)\tLoss 0.0359 (0.0292)\tPrec@1 98.438 (99.206)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][70/97], lr: 0.00000\tTime 0.041 (0.065)\tData 0.000 (0.010)\tLoss 0.0289 (0.0291)\tPrec@1 98.438 (99.186)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][80/97], lr: 0.00000\tTime 0.049 (0.064)\tData 0.008 (0.009)\tLoss 0.0448 (0.0292)\tPrec@1 99.219 (99.199)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][90/97], lr: 0.00000\tTime 0.046 (0.063)\tData 0.000 (0.009)\tLoss 0.0194 (0.0289)\tPrec@1 100.000 (99.236)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 1.2383 (1.2383)\tPrec@1 73.000 (73.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.016 (0.053)\tLoss 1.1333 (1.4010)\tPrec@1 79.000 (72.000)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.010 (0.042)\tLoss 1.3763 (1.4394)\tPrec@1 70.000 (71.143)\tPrec@5 100.000 (98.095)\n",
            "Test: [30/100]\tTime 0.036 (0.035)\tLoss 1.3939 (1.4607)\tPrec@1 72.000 (71.097)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.3135 (1.4653)\tPrec@1 69.000 (70.902)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/100]\tTime 0.031 (0.032)\tLoss 1.1022 (1.4359)\tPrec@1 73.000 (71.235)\tPrec@5 98.000 (97.980)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 1.1395 (1.4363)\tPrec@1 76.000 (71.164)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 1.5650 (1.4173)\tPrec@1 71.000 (71.155)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.046 (0.030)\tLoss 1.1898 (1.4143)\tPrec@1 74.000 (71.086)\tPrec@5 96.000 (97.988)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 1.3074 (1.4297)\tPrec@1 76.000 (70.780)\tPrec@5 100.000 (98.033)\n",
            "val Results: Prec@1 70.770 Prec@5 98.020 Loss 1.43537\n",
            "val Class Accuracy: [0.976,0.986,0.806,0.782,0.776,0.615,0.671,0.596,0.419,0.450]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [182][0/97], lr: 0.00000\tTime 0.473 (0.473)\tData 0.390 (0.390)\tLoss 0.0141 (0.0141)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][10/97], lr: 0.00000\tTime 0.065 (0.103)\tData 0.000 (0.039)\tLoss 0.0140 (0.0276)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][20/97], lr: 0.00000\tTime 0.053 (0.081)\tData 0.000 (0.022)\tLoss 0.0287 (0.0268)\tPrec@1 98.438 (99.368)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][30/97], lr: 0.00000\tTime 0.039 (0.073)\tData 0.000 (0.017)\tLoss 0.0321 (0.0265)\tPrec@1 99.219 (99.395)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][40/97], lr: 0.00000\tTime 0.061 (0.069)\tData 0.002 (0.014)\tLoss 0.0479 (0.0283)\tPrec@1 98.438 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][50/97], lr: 0.00000\tTime 0.068 (0.067)\tData 0.000 (0.012)\tLoss 0.0482 (0.0278)\tPrec@1 97.656 (99.249)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][60/97], lr: 0.00000\tTime 0.056 (0.065)\tData 0.006 (0.011)\tLoss 0.0160 (0.0276)\tPrec@1 99.219 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][70/97], lr: 0.00000\tTime 0.054 (0.064)\tData 0.000 (0.010)\tLoss 0.0469 (0.0279)\tPrec@1 98.438 (99.263)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][80/97], lr: 0.00000\tTime 0.070 (0.063)\tData 0.006 (0.009)\tLoss 0.0114 (0.0278)\tPrec@1 100.000 (99.286)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][90/97], lr: 0.00000\tTime 0.050 (0.062)\tData 0.000 (0.008)\tLoss 0.0656 (0.0285)\tPrec@1 98.438 (99.253)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 1.2543 (1.2543)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.045 (0.055)\tLoss 1.1458 (1.4137)\tPrec@1 79.000 (72.364)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 1.3808 (1.4511)\tPrec@1 71.000 (71.524)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.3926 (1.4721)\tPrec@1 72.000 (71.290)\tPrec@5 97.000 (97.742)\n",
            "Test: [40/100]\tTime 0.019 (0.032)\tLoss 1.3179 (1.4754)\tPrec@1 69.000 (71.000)\tPrec@5 99.000 (97.878)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 1.0866 (1.4473)\tPrec@1 73.000 (71.137)\tPrec@5 98.000 (97.902)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 1.1495 (1.4481)\tPrec@1 77.000 (71.049)\tPrec@5 97.000 (97.885)\n",
            "Test: [70/100]\tTime 0.026 (0.029)\tLoss 1.6019 (1.4304)\tPrec@1 71.000 (71.014)\tPrec@5 99.000 (97.873)\n",
            "Test: [80/100]\tTime 0.020 (0.029)\tLoss 1.1537 (1.4258)\tPrec@1 75.000 (71.000)\tPrec@5 97.000 (97.938)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 1.3177 (1.4422)\tPrec@1 76.000 (70.736)\tPrec@5 100.000 (97.989)\n",
            "val Results: Prec@1 70.660 Prec@5 97.960 Loss 1.44809\n",
            "val Class Accuracy: [0.977,0.984,0.812,0.771,0.795,0.596,0.679,0.583,0.403,0.466]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [183][0/97], lr: 0.00000\tTime 0.470 (0.470)\tData 0.418 (0.418)\tLoss 0.0508 (0.0508)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][10/97], lr: 0.00000\tTime 0.062 (0.100)\tData 0.000 (0.041)\tLoss 0.0416 (0.0289)\tPrec@1 98.438 (99.148)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][20/97], lr: 0.00000\tTime 0.061 (0.080)\tData 0.007 (0.025)\tLoss 0.0419 (0.0316)\tPrec@1 99.219 (98.996)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][30/97], lr: 0.00000\tTime 0.063 (0.073)\tData 0.007 (0.018)\tLoss 0.0268 (0.0295)\tPrec@1 100.000 (99.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][40/97], lr: 0.00000\tTime 0.049 (0.069)\tData 0.014 (0.015)\tLoss 0.0242 (0.0294)\tPrec@1 99.219 (99.181)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][50/97], lr: 0.00000\tTime 0.067 (0.066)\tData 0.007 (0.013)\tLoss 0.0347 (0.0287)\tPrec@1 98.438 (99.203)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][60/97], lr: 0.00000\tTime 0.077 (0.065)\tData 0.008 (0.012)\tLoss 0.0370 (0.0283)\tPrec@1 97.656 (99.206)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][70/97], lr: 0.00000\tTime 0.090 (0.064)\tData 0.007 (0.011)\tLoss 0.0203 (0.0282)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][80/97], lr: 0.00000\tTime 0.061 (0.063)\tData 0.010 (0.010)\tLoss 0.0338 (0.0271)\tPrec@1 98.438 (99.277)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][90/97], lr: 0.00000\tTime 0.029 (0.062)\tData 0.000 (0.009)\tLoss 0.0232 (0.0275)\tPrec@1 100.000 (99.279)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 1.1744 (1.1744)\tPrec@1 74.000 (74.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.021 (0.050)\tLoss 1.1112 (1.3530)\tPrec@1 78.000 (72.909)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.028 (0.040)\tLoss 1.3171 (1.3932)\tPrec@1 71.000 (71.905)\tPrec@5 99.000 (98.000)\n",
            "Test: [30/100]\tTime 0.010 (0.036)\tLoss 1.3484 (1.4164)\tPrec@1 73.000 (71.871)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.019 (0.032)\tLoss 1.2533 (1.4192)\tPrec@1 71.000 (71.659)\tPrec@5 99.000 (97.927)\n",
            "Test: [50/100]\tTime 0.014 (0.031)\tLoss 1.0646 (1.3915)\tPrec@1 76.000 (72.020)\tPrec@5 99.000 (97.980)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 1.0970 (1.3917)\tPrec@1 78.000 (71.934)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.034 (0.030)\tLoss 1.5350 (1.3734)\tPrec@1 71.000 (71.873)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.1356 (1.3699)\tPrec@1 75.000 (71.840)\tPrec@5 96.000 (97.963)\n",
            "Test: [90/100]\tTime 0.024 (0.028)\tLoss 1.2762 (1.3853)\tPrec@1 76.000 (71.560)\tPrec@5 100.000 (98.011)\n",
            "val Results: Prec@1 71.550 Prec@5 98.000 Loss 1.39139\n",
            "val Class Accuracy: [0.976,0.984,0.812,0.774,0.778,0.622,0.671,0.619,0.456,0.463]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [184][0/97], lr: 0.00000\tTime 0.471 (0.471)\tData 0.375 (0.375)\tLoss 0.0183 (0.0183)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][10/97], lr: 0.00000\tTime 0.067 (0.103)\tData 0.000 (0.039)\tLoss 0.0490 (0.0344)\tPrec@1 97.656 (98.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][20/97], lr: 0.00000\tTime 0.049 (0.080)\tData 0.000 (0.023)\tLoss 0.0313 (0.0319)\tPrec@1 99.219 (98.996)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][30/97], lr: 0.00000\tTime 0.040 (0.073)\tData 0.000 (0.017)\tLoss 0.0380 (0.0337)\tPrec@1 97.656 (98.916)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][40/97], lr: 0.00000\tTime 0.066 (0.069)\tData 0.009 (0.014)\tLoss 0.0189 (0.0318)\tPrec@1 100.000 (99.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][50/97], lr: 0.00000\tTime 0.048 (0.067)\tData 0.000 (0.012)\tLoss 0.0186 (0.0294)\tPrec@1 99.219 (99.157)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][60/97], lr: 0.00000\tTime 0.081 (0.066)\tData 0.000 (0.011)\tLoss 0.0358 (0.0296)\tPrec@1 98.438 (99.129)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][70/97], lr: 0.00000\tTime 0.066 (0.065)\tData 0.000 (0.010)\tLoss 0.0241 (0.0302)\tPrec@1 100.000 (99.131)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][80/97], lr: 0.00000\tTime 0.061 (0.063)\tData 0.000 (0.009)\tLoss 0.0405 (0.0296)\tPrec@1 98.438 (99.132)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][90/97], lr: 0.00000\tTime 0.038 (0.063)\tData 0.000 (0.009)\tLoss 0.0746 (0.0296)\tPrec@1 98.438 (99.141)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.276 (0.276)\tLoss 1.2693 (1.2693)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.055)\tLoss 1.1705 (1.4278)\tPrec@1 78.000 (71.545)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.027 (0.040)\tLoss 1.3781 (1.4667)\tPrec@1 71.000 (70.952)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.033 (0.036)\tLoss 1.4132 (1.4859)\tPrec@1 72.000 (70.871)\tPrec@5 97.000 (97.774)\n",
            "Test: [40/100]\tTime 0.045 (0.034)\tLoss 1.3246 (1.4874)\tPrec@1 69.000 (70.585)\tPrec@5 99.000 (97.902)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.1044 (1.4595)\tPrec@1 73.000 (70.843)\tPrec@5 98.000 (97.941)\n",
            "Test: [60/100]\tTime 0.014 (0.031)\tLoss 1.1570 (1.4589)\tPrec@1 75.000 (70.754)\tPrec@5 97.000 (97.934)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 1.6120 (1.4418)\tPrec@1 70.000 (70.704)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 1.1844 (1.4379)\tPrec@1 74.000 (70.679)\tPrec@5 97.000 (97.988)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 1.3346 (1.4549)\tPrec@1 75.000 (70.352)\tPrec@5 100.000 (98.044)\n",
            "val Results: Prec@1 70.290 Prec@5 98.020 Loss 1.46066\n",
            "val Class Accuracy: [0.977,0.985,0.810,0.774,0.786,0.603,0.656,0.596,0.382,0.460]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [185][0/97], lr: 0.00000\tTime 0.387 (0.387)\tData 0.305 (0.305)\tLoss 0.0226 (0.0226)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][10/97], lr: 0.00000\tTime 0.054 (0.104)\tData 0.011 (0.034)\tLoss 0.0146 (0.0277)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][20/97], lr: 0.00000\tTime 0.042 (0.082)\tData 0.000 (0.020)\tLoss 0.0223 (0.0286)\tPrec@1 99.219 (99.256)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][30/97], lr: 0.00000\tTime 0.052 (0.074)\tData 0.006 (0.015)\tLoss 0.0181 (0.0286)\tPrec@1 100.000 (99.269)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][40/97], lr: 0.00000\tTime 0.057 (0.070)\tData 0.004 (0.013)\tLoss 0.0229 (0.0297)\tPrec@1 100.000 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][50/97], lr: 0.00000\tTime 0.039 (0.067)\tData 0.000 (0.011)\tLoss 0.0431 (0.0299)\tPrec@1 97.656 (99.265)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][60/97], lr: 0.00000\tTime 0.047 (0.066)\tData 0.001 (0.010)\tLoss 0.0291 (0.0287)\tPrec@1 98.438 (99.296)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][70/97], lr: 0.00000\tTime 0.060 (0.065)\tData 0.010 (0.010)\tLoss 0.0213 (0.0285)\tPrec@1 100.000 (99.307)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][80/97], lr: 0.00000\tTime 0.065 (0.064)\tData 0.002 (0.009)\tLoss 0.0192 (0.0301)\tPrec@1 100.000 (99.228)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][90/97], lr: 0.00000\tTime 0.032 (0.063)\tData 0.000 (0.009)\tLoss 0.0188 (0.0294)\tPrec@1 100.000 (99.253)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.274 (0.274)\tLoss 1.1648 (1.1648)\tPrec@1 74.000 (74.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.016 (0.053)\tLoss 1.0678 (1.3393)\tPrec@1 80.000 (73.364)\tPrec@5 98.000 (98.545)\n",
            "Test: [20/100]\tTime 0.027 (0.041)\tLoss 1.3146 (1.3810)\tPrec@1 71.000 (72.429)\tPrec@5 99.000 (98.048)\n",
            "Test: [30/100]\tTime 0.028 (0.037)\tLoss 1.3313 (1.4037)\tPrec@1 73.000 (72.161)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.028 (0.034)\tLoss 1.2386 (1.4054)\tPrec@1 70.000 (71.951)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 1.0207 (1.3778)\tPrec@1 74.000 (72.275)\tPrec@5 98.000 (97.980)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 1.1087 (1.3768)\tPrec@1 75.000 (72.197)\tPrec@5 97.000 (97.984)\n",
            "Test: [70/100]\tTime 0.034 (0.030)\tLoss 1.5281 (1.3592)\tPrec@1 72.000 (72.155)\tPrec@5 99.000 (97.972)\n",
            "Test: [80/100]\tTime 0.035 (0.030)\tLoss 1.1231 (1.3550)\tPrec@1 76.000 (72.123)\tPrec@5 97.000 (98.049)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 1.2537 (1.3697)\tPrec@1 77.000 (71.901)\tPrec@5 100.000 (98.110)\n",
            "val Results: Prec@1 71.790 Prec@5 98.090 Loss 1.37514\n",
            "val Class Accuracy: [0.974,0.986,0.811,0.766,0.790,0.630,0.712,0.599,0.418,0.493]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [186][0/97], lr: 0.00000\tTime 0.488 (0.488)\tData 0.403 (0.403)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][10/97], lr: 0.00000\tTime 0.079 (0.107)\tData 0.001 (0.040)\tLoss 0.0320 (0.0239)\tPrec@1 99.219 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][20/97], lr: 0.00000\tTime 0.044 (0.081)\tData 0.000 (0.023)\tLoss 0.0124 (0.0280)\tPrec@1 100.000 (99.405)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][30/97], lr: 0.00000\tTime 0.054 (0.075)\tData 0.007 (0.018)\tLoss 0.0390 (0.0288)\tPrec@1 98.438 (99.294)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][40/97], lr: 0.00000\tTime 0.049 (0.070)\tData 0.007 (0.015)\tLoss 0.0135 (0.0265)\tPrec@1 100.000 (99.428)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][50/97], lr: 0.00000\tTime 0.052 (0.068)\tData 0.000 (0.013)\tLoss 0.0275 (0.0268)\tPrec@1 99.219 (99.418)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][60/97], lr: 0.00000\tTime 0.054 (0.066)\tData 0.006 (0.012)\tLoss 0.0260 (0.0279)\tPrec@1 100.000 (99.385)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][70/97], lr: 0.00000\tTime 0.051 (0.065)\tData 0.007 (0.011)\tLoss 0.0170 (0.0278)\tPrec@1 100.000 (99.384)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][80/97], lr: 0.00000\tTime 0.049 (0.064)\tData 0.013 (0.011)\tLoss 0.0347 (0.0275)\tPrec@1 99.219 (99.383)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][90/97], lr: 0.00000\tTime 0.034 (0.063)\tData 0.000 (0.010)\tLoss 0.0341 (0.0277)\tPrec@1 98.438 (99.382)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.314 (0.314)\tLoss 1.2411 (1.2411)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.010 (0.055)\tLoss 1.1128 (1.4087)\tPrec@1 79.000 (72.455)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.016 (0.041)\tLoss 1.3508 (1.4483)\tPrec@1 72.000 (71.667)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.028 (0.037)\tLoss 1.3780 (1.4689)\tPrec@1 72.000 (71.484)\tPrec@5 97.000 (97.742)\n",
            "Test: [40/100]\tTime 0.010 (0.035)\tLoss 1.3062 (1.4714)\tPrec@1 69.000 (71.293)\tPrec@5 98.000 (97.854)\n",
            "Test: [50/100]\tTime 0.025 (0.033)\tLoss 1.0845 (1.4426)\tPrec@1 73.000 (71.529)\tPrec@5 98.000 (97.902)\n",
            "Test: [60/100]\tTime 0.040 (0.032)\tLoss 1.1534 (1.4417)\tPrec@1 75.000 (71.410)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/100]\tTime 0.023 (0.031)\tLoss 1.6027 (1.4242)\tPrec@1 72.000 (71.338)\tPrec@5 99.000 (97.887)\n",
            "Test: [80/100]\tTime 0.011 (0.030)\tLoss 1.1619 (1.4205)\tPrec@1 75.000 (71.321)\tPrec@5 97.000 (97.951)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 1.3201 (1.4366)\tPrec@1 77.000 (71.077)\tPrec@5 100.000 (98.011)\n",
            "val Results: Prec@1 70.980 Prec@5 97.990 Loss 1.44271\n",
            "val Class Accuracy: [0.975,0.985,0.813,0.768,0.782,0.615,0.698,0.598,0.405,0.459]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [187][0/97], lr: 0.00000\tTime 0.563 (0.563)\tData 0.460 (0.460)\tLoss 0.0155 (0.0155)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][10/97], lr: 0.00000\tTime 0.095 (0.145)\tData 0.016 (0.051)\tLoss 0.0188 (0.0279)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][20/97], lr: 0.00000\tTime 0.077 (0.118)\tData 0.008 (0.029)\tLoss 0.0345 (0.0328)\tPrec@1 99.219 (99.070)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][30/97], lr: 0.00000\tTime 0.084 (0.108)\tData 0.012 (0.024)\tLoss 0.0229 (0.0306)\tPrec@1 99.219 (99.093)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][40/97], lr: 0.00000\tTime 0.072 (0.103)\tData 0.008 (0.020)\tLoss 0.0296 (0.0286)\tPrec@1 98.438 (99.162)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][50/97], lr: 0.00000\tTime 0.060 (0.094)\tData 0.007 (0.017)\tLoss 0.0283 (0.0281)\tPrec@1 99.219 (99.203)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][60/97], lr: 0.00000\tTime 0.080 (0.088)\tData 0.011 (0.015)\tLoss 0.0299 (0.0289)\tPrec@1 100.000 (99.206)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][70/97], lr: 0.00000\tTime 0.062 (0.084)\tData 0.007 (0.014)\tLoss 0.0249 (0.0285)\tPrec@1 98.438 (99.252)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][80/97], lr: 0.00000\tTime 0.053 (0.080)\tData 0.003 (0.013)\tLoss 0.0251 (0.0287)\tPrec@1 100.000 (99.248)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][90/97], lr: 0.00000\tTime 0.030 (0.077)\tData 0.000 (0.012)\tLoss 0.0390 (0.0294)\tPrec@1 98.438 (99.159)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.281 (0.281)\tLoss 1.2466 (1.2466)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.019 (0.053)\tLoss 1.1461 (1.4262)\tPrec@1 78.000 (72.000)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 1.3461 (1.4606)\tPrec@1 71.000 (71.238)\tPrec@5 99.000 (97.905)\n",
            "Test: [30/100]\tTime 0.030 (0.036)\tLoss 1.3729 (1.4808)\tPrec@1 73.000 (71.065)\tPrec@5 96.000 (97.677)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 1.3304 (1.4836)\tPrec@1 69.000 (70.829)\tPrec@5 98.000 (97.780)\n",
            "Test: [50/100]\tTime 0.013 (0.032)\tLoss 1.0762 (1.4578)\tPrec@1 75.000 (71.196)\tPrec@5 98.000 (97.843)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 1.1388 (1.4546)\tPrec@1 75.000 (71.082)\tPrec@5 97.000 (97.852)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 1.6105 (1.4386)\tPrec@1 70.000 (70.958)\tPrec@5 99.000 (97.831)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 1.1770 (1.4345)\tPrec@1 75.000 (70.914)\tPrec@5 96.000 (97.901)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 1.3534 (1.4511)\tPrec@1 76.000 (70.681)\tPrec@5 100.000 (97.956)\n",
            "val Results: Prec@1 70.650 Prec@5 97.950 Loss 1.45803\n",
            "val Class Accuracy: [0.976,0.986,0.811,0.760,0.795,0.623,0.703,0.614,0.365,0.432]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [188][0/97], lr: 0.00000\tTime 0.483 (0.483)\tData 0.391 (0.391)\tLoss 0.0282 (0.0282)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][10/97], lr: 0.00000\tTime 0.041 (0.104)\tData 0.000 (0.041)\tLoss 0.0442 (0.0341)\tPrec@1 99.219 (99.148)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][20/97], lr: 0.00000\tTime 0.056 (0.083)\tData 0.007 (0.025)\tLoss 0.0528 (0.0334)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][30/97], lr: 0.00000\tTime 0.037 (0.074)\tData 0.000 (0.018)\tLoss 0.0129 (0.0299)\tPrec@1 100.000 (99.294)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][40/97], lr: 0.00000\tTime 0.045 (0.070)\tData 0.000 (0.015)\tLoss 0.0368 (0.0300)\tPrec@1 99.219 (99.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][50/97], lr: 0.00000\tTime 0.064 (0.067)\tData 0.006 (0.013)\tLoss 0.0357 (0.0283)\tPrec@1 99.219 (99.341)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][60/97], lr: 0.00000\tTime 0.065 (0.066)\tData 0.000 (0.011)\tLoss 0.0386 (0.0295)\tPrec@1 98.438 (99.283)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][70/97], lr: 0.00000\tTime 0.062 (0.065)\tData 0.007 (0.010)\tLoss 0.0354 (0.0293)\tPrec@1 99.219 (99.296)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][80/97], lr: 0.00000\tTime 0.061 (0.063)\tData 0.011 (0.010)\tLoss 0.0214 (0.0282)\tPrec@1 99.219 (99.334)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][90/97], lr: 0.00000\tTime 0.031 (0.062)\tData 0.000 (0.009)\tLoss 0.0416 (0.0283)\tPrec@1 99.219 (99.305)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 1.2399 (1.2399)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.026 (0.055)\tLoss 1.1074 (1.4051)\tPrec@1 78.000 (71.909)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.024 (0.040)\tLoss 1.3619 (1.4399)\tPrec@1 71.000 (71.381)\tPrec@5 99.000 (98.095)\n",
            "Test: [30/100]\tTime 0.021 (0.036)\tLoss 1.3625 (1.4604)\tPrec@1 71.000 (71.258)\tPrec@5 97.000 (97.871)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.3035 (1.4647)\tPrec@1 69.000 (71.000)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 1.0974 (1.4360)\tPrec@1 72.000 (71.216)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.014 (0.030)\tLoss 1.1426 (1.4358)\tPrec@1 75.000 (71.197)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.015 (0.030)\tLoss 1.5783 (1.4177)\tPrec@1 72.000 (71.155)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/100]\tTime 0.028 (0.029)\tLoss 1.1842 (1.4149)\tPrec@1 74.000 (71.074)\tPrec@5 96.000 (97.975)\n",
            "Test: [90/100]\tTime 0.038 (0.029)\tLoss 1.3206 (1.4303)\tPrec@1 76.000 (70.824)\tPrec@5 100.000 (98.033)\n",
            "val Results: Prec@1 70.830 Prec@5 98.020 Loss 1.43675\n",
            "val Class Accuracy: [0.973,0.986,0.811,0.781,0.778,0.599,0.707,0.598,0.421,0.429]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [189][0/97], lr: 0.00000\tTime 0.470 (0.470)\tData 0.381 (0.381)\tLoss 0.0819 (0.0819)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][10/97], lr: 0.00000\tTime 0.054 (0.102)\tData 0.005 (0.040)\tLoss 0.0434 (0.0354)\tPrec@1 99.219 (99.077)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][20/97], lr: 0.00000\tTime 0.064 (0.082)\tData 0.007 (0.024)\tLoss 0.0423 (0.0336)\tPrec@1 98.438 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][30/97], lr: 0.00000\tTime 0.065 (0.074)\tData 0.000 (0.018)\tLoss 0.0230 (0.0332)\tPrec@1 100.000 (99.244)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][40/97], lr: 0.00000\tTime 0.076 (0.070)\tData 0.001 (0.014)\tLoss 0.0344 (0.0314)\tPrec@1 99.219 (99.314)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][50/97], lr: 0.00000\tTime 0.050 (0.068)\tData 0.007 (0.013)\tLoss 0.0246 (0.0305)\tPrec@1 98.438 (99.326)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][60/97], lr: 0.00000\tTime 0.051 (0.066)\tData 0.002 (0.012)\tLoss 0.0370 (0.0314)\tPrec@1 98.438 (99.206)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][70/97], lr: 0.00000\tTime 0.060 (0.064)\tData 0.000 (0.011)\tLoss 0.0334 (0.0312)\tPrec@1 99.219 (99.208)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][80/97], lr: 0.00000\tTime 0.058 (0.064)\tData 0.007 (0.010)\tLoss 0.0334 (0.0318)\tPrec@1 99.219 (99.161)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][90/97], lr: 0.00000\tTime 0.038 (0.062)\tData 0.000 (0.009)\tLoss 0.0267 (0.0314)\tPrec@1 98.438 (99.167)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.342 (0.342)\tLoss 1.2571 (1.2571)\tPrec@1 73.000 (73.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.031 (0.054)\tLoss 1.1420 (1.4166)\tPrec@1 79.000 (72.000)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.016 (0.039)\tLoss 1.3599 (1.4525)\tPrec@1 70.000 (71.143)\tPrec@5 100.000 (98.000)\n",
            "Test: [30/100]\tTime 0.035 (0.036)\tLoss 1.3939 (1.4724)\tPrec@1 72.000 (71.097)\tPrec@5 97.000 (97.742)\n",
            "Test: [40/100]\tTime 0.022 (0.032)\tLoss 1.3164 (1.4757)\tPrec@1 69.000 (70.854)\tPrec@5 99.000 (97.902)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 1.1168 (1.4472)\tPrec@1 70.000 (71.078)\tPrec@5 98.000 (97.922)\n",
            "Test: [60/100]\tTime 0.019 (0.030)\tLoss 1.1492 (1.4468)\tPrec@1 76.000 (71.016)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 1.6025 (1.4292)\tPrec@1 71.000 (70.986)\tPrec@5 99.000 (97.887)\n",
            "Test: [80/100]\tTime 0.012 (0.029)\tLoss 1.1778 (1.4262)\tPrec@1 74.000 (70.889)\tPrec@5 96.000 (97.938)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.3269 (1.4424)\tPrec@1 75.000 (70.582)\tPrec@5 100.000 (98.000)\n",
            "val Results: Prec@1 70.540 Prec@5 98.000 Loss 1.44846\n",
            "val Class Accuracy: [0.975,0.986,0.816,0.774,0.780,0.621,0.657,0.595,0.410,0.440]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [190][0/97], lr: 0.00000\tTime 0.369 (0.369)\tData 0.299 (0.299)\tLoss 0.0276 (0.0276)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][10/97], lr: 0.00000\tTime 0.056 (0.102)\tData 0.007 (0.040)\tLoss 0.0236 (0.0219)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][20/97], lr: 0.00000\tTime 0.049 (0.080)\tData 0.007 (0.024)\tLoss 0.0468 (0.0259)\tPrec@1 98.438 (99.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][30/97], lr: 0.00000\tTime 0.066 (0.072)\tData 0.000 (0.018)\tLoss 0.0451 (0.0269)\tPrec@1 97.656 (99.294)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][40/97], lr: 0.00000\tTime 0.059 (0.069)\tData 0.002 (0.015)\tLoss 0.0404 (0.0302)\tPrec@1 97.656 (99.200)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [190][50/97], lr: 0.00000\tTime 0.056 (0.067)\tData 0.007 (0.013)\tLoss 0.0324 (0.0300)\tPrec@1 99.219 (99.203)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [190][60/97], lr: 0.00000\tTime 0.040 (0.065)\tData 0.000 (0.012)\tLoss 0.0117 (0.0295)\tPrec@1 100.000 (99.244)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [190][70/97], lr: 0.00000\tTime 0.062 (0.065)\tData 0.013 (0.011)\tLoss 0.0596 (0.0290)\tPrec@1 97.656 (99.241)\tPrec@5 100.000 (99.989)\n",
            "Epoch: [190][80/97], lr: 0.00000\tTime 0.052 (0.064)\tData 0.007 (0.011)\tLoss 0.0086 (0.0291)\tPrec@1 100.000 (99.257)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [190][90/97], lr: 0.00000\tTime 0.032 (0.063)\tData 0.000 (0.010)\tLoss 0.0179 (0.0290)\tPrec@1 99.219 (99.253)\tPrec@5 100.000 (99.991)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 1.2332 (1.2332)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.031 (0.055)\tLoss 1.1393 (1.4098)\tPrec@1 78.000 (72.364)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.010 (0.038)\tLoss 1.3574 (1.4511)\tPrec@1 71.000 (71.381)\tPrec@5 99.000 (98.000)\n",
            "Test: [30/100]\tTime 0.041 (0.035)\tLoss 1.3869 (1.4707)\tPrec@1 71.000 (71.290)\tPrec@5 97.000 (97.806)\n",
            "Test: [40/100]\tTime 0.035 (0.032)\tLoss 1.3045 (1.4725)\tPrec@1 69.000 (71.049)\tPrec@5 99.000 (97.927)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 1.0897 (1.4437)\tPrec@1 75.000 (71.392)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 1.1456 (1.4424)\tPrec@1 75.000 (71.295)\tPrec@5 97.000 (97.967)\n",
            "Test: [70/100]\tTime 0.012 (0.030)\tLoss 1.6000 (1.4246)\tPrec@1 71.000 (71.225)\tPrec@5 99.000 (97.944)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.1666 (1.4212)\tPrec@1 74.000 (71.235)\tPrec@5 97.000 (98.012)\n",
            "Test: [90/100]\tTime 0.026 (0.028)\tLoss 1.3316 (1.4371)\tPrec@1 76.000 (70.978)\tPrec@5 100.000 (98.066)\n",
            "val Results: Prec@1 70.920 Prec@5 98.040 Loss 1.44309\n",
            "val Class Accuracy: [0.977,0.985,0.808,0.774,0.779,0.613,0.689,0.605,0.403,0.459]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [191][0/97], lr: 0.00000\tTime 0.459 (0.459)\tData 0.365 (0.365)\tLoss 0.0337 (0.0337)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][10/97], lr: 0.00000\tTime 0.071 (0.102)\tData 0.008 (0.036)\tLoss 0.0234 (0.0229)\tPrec@1 99.219 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][20/97], lr: 0.00000\tTime 0.068 (0.082)\tData 0.007 (0.022)\tLoss 0.0258 (0.0216)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][30/97], lr: 0.00000\tTime 0.051 (0.073)\tData 0.008 (0.016)\tLoss 0.0335 (0.0252)\tPrec@1 99.219 (99.370)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][40/97], lr: 0.00000\tTime 0.063 (0.070)\tData 0.009 (0.014)\tLoss 0.0293 (0.0272)\tPrec@1 99.219 (99.314)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][50/97], lr: 0.00000\tTime 0.042 (0.068)\tData 0.000 (0.012)\tLoss 0.0324 (0.0274)\tPrec@1 99.219 (99.341)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][60/97], lr: 0.00000\tTime 0.048 (0.066)\tData 0.000 (0.011)\tLoss 0.0414 (0.0279)\tPrec@1 98.438 (99.283)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][70/97], lr: 0.00000\tTime 0.064 (0.066)\tData 0.000 (0.010)\tLoss 0.0837 (0.0288)\tPrec@1 97.656 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][80/97], lr: 0.00000\tTime 0.038 (0.064)\tData 0.003 (0.010)\tLoss 0.0204 (0.0295)\tPrec@1 100.000 (99.199)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][90/97], lr: 0.00000\tTime 0.031 (0.063)\tData 0.000 (0.009)\tLoss 0.0347 (0.0290)\tPrec@1 99.219 (99.253)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 1.1934 (1.1934)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.027 (0.057)\tLoss 1.0932 (1.3726)\tPrec@1 80.000 (72.818)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.043 (0.044)\tLoss 1.3494 (1.4098)\tPrec@1 71.000 (72.143)\tPrec@5 99.000 (98.000)\n",
            "Test: [30/100]\tTime 0.018 (0.037)\tLoss 1.3471 (1.4300)\tPrec@1 73.000 (71.968)\tPrec@5 97.000 (97.806)\n",
            "Test: [40/100]\tTime 0.017 (0.034)\tLoss 1.2540 (1.4324)\tPrec@1 70.000 (71.854)\tPrec@5 98.000 (97.927)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 1.0366 (1.4047)\tPrec@1 76.000 (72.176)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.024 (0.032)\tLoss 1.1292 (1.4031)\tPrec@1 75.000 (72.066)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.050 (0.031)\tLoss 1.5596 (1.3869)\tPrec@1 73.000 (71.986)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.023 (0.031)\tLoss 1.1386 (1.3839)\tPrec@1 75.000 (71.889)\tPrec@5 97.000 (98.000)\n",
            "Test: [90/100]\tTime 0.024 (0.030)\tLoss 1.2942 (1.3997)\tPrec@1 77.000 (71.648)\tPrec@5 100.000 (98.066)\n",
            "val Results: Prec@1 71.550 Prec@5 98.050 Loss 1.40580\n",
            "val Class Accuracy: [0.973,0.986,0.810,0.770,0.800,0.613,0.705,0.623,0.406,0.469]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [192][0/97], lr: 0.00000\tTime 0.504 (0.504)\tData 0.442 (0.442)\tLoss 0.0451 (0.0451)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][10/97], lr: 0.00000\tTime 0.067 (0.105)\tData 0.000 (0.045)\tLoss 0.0172 (0.0317)\tPrec@1 100.000 (99.077)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][20/97], lr: 0.00000\tTime 0.046 (0.081)\tData 0.001 (0.025)\tLoss 0.0461 (0.0311)\tPrec@1 99.219 (99.182)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][30/97], lr: 0.00000\tTime 0.053 (0.074)\tData 0.000 (0.019)\tLoss 0.0403 (0.0314)\tPrec@1 98.438 (99.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][40/97], lr: 0.00000\tTime 0.049 (0.070)\tData 0.005 (0.016)\tLoss 0.0601 (0.0306)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][50/97], lr: 0.00000\tTime 0.057 (0.068)\tData 0.006 (0.014)\tLoss 0.0155 (0.0304)\tPrec@1 100.000 (99.249)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][60/97], lr: 0.00000\tTime 0.051 (0.066)\tData 0.012 (0.012)\tLoss 0.0185 (0.0301)\tPrec@1 100.000 (99.257)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][70/97], lr: 0.00000\tTime 0.068 (0.065)\tData 0.005 (0.012)\tLoss 0.0052 (0.0298)\tPrec@1 100.000 (99.274)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][80/97], lr: 0.00000\tTime 0.059 (0.064)\tData 0.006 (0.011)\tLoss 0.0216 (0.0300)\tPrec@1 100.000 (99.267)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][90/97], lr: 0.00000\tTime 0.030 (0.063)\tData 0.000 (0.010)\tLoss 0.0151 (0.0296)\tPrec@1 100.000 (99.279)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 1.2553 (1.2553)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.031 (0.055)\tLoss 1.1298 (1.4132)\tPrec@1 78.000 (72.091)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/100]\tTime 0.013 (0.041)\tLoss 1.3830 (1.4499)\tPrec@1 70.000 (71.333)\tPrec@5 99.000 (97.952)\n",
            "Test: [30/100]\tTime 0.023 (0.036)\tLoss 1.3965 (1.4722)\tPrec@1 71.000 (71.000)\tPrec@5 97.000 (97.806)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 1.3198 (1.4760)\tPrec@1 70.000 (70.805)\tPrec@5 99.000 (97.902)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 1.1048 (1.4470)\tPrec@1 73.000 (71.059)\tPrec@5 98.000 (97.922)\n",
            "Test: [60/100]\tTime 0.032 (0.031)\tLoss 1.1565 (1.4481)\tPrec@1 75.000 (70.967)\tPrec@5 97.000 (97.918)\n",
            "Test: [70/100]\tTime 0.051 (0.030)\tLoss 1.6017 (1.4301)\tPrec@1 71.000 (70.930)\tPrec@5 99.000 (97.901)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 1.1839 (1.4268)\tPrec@1 74.000 (70.852)\tPrec@5 96.000 (97.938)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 1.3315 (1.4422)\tPrec@1 76.000 (70.593)\tPrec@5 100.000 (97.989)\n",
            "val Results: Prec@1 70.540 Prec@5 97.960 Loss 1.44862\n",
            "val Class Accuracy: [0.977,0.986,0.811,0.777,0.788,0.595,0.691,0.568,0.419,0.442]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [193][0/97], lr: 0.00000\tTime 0.464 (0.464)\tData 0.389 (0.389)\tLoss 0.0184 (0.0184)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][10/97], lr: 0.00000\tTime 0.067 (0.103)\tData 0.016 (0.041)\tLoss 0.0141 (0.0282)\tPrec@1 100.000 (99.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][20/97], lr: 0.00000\tTime 0.052 (0.080)\tData 0.000 (0.022)\tLoss 0.0449 (0.0294)\tPrec@1 98.438 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][30/97], lr: 0.00000\tTime 0.068 (0.073)\tData 0.006 (0.017)\tLoss 0.0190 (0.0298)\tPrec@1 99.219 (99.168)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][40/97], lr: 0.00000\tTime 0.062 (0.069)\tData 0.000 (0.014)\tLoss 0.0263 (0.0300)\tPrec@1 98.438 (99.162)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][50/97], lr: 0.00000\tTime 0.053 (0.067)\tData 0.007 (0.012)\tLoss 0.0344 (0.0297)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][60/97], lr: 0.00000\tTime 0.053 (0.065)\tData 0.007 (0.011)\tLoss 0.0188 (0.0286)\tPrec@1 100.000 (99.283)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][70/97], lr: 0.00000\tTime 0.043 (0.064)\tData 0.000 (0.010)\tLoss 0.0213 (0.0298)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][80/97], lr: 0.00000\tTime 0.066 (0.063)\tData 0.011 (0.009)\tLoss 0.0075 (0.0293)\tPrec@1 100.000 (99.238)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][90/97], lr: 0.00000\tTime 0.029 (0.062)\tData 0.000 (0.009)\tLoss 0.0180 (0.0291)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 1.2391 (1.2391)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.017 (0.056)\tLoss 1.1222 (1.4019)\tPrec@1 78.000 (72.182)\tPrec@5 98.000 (98.455)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 1.3700 (1.4400)\tPrec@1 71.000 (71.429)\tPrec@5 99.000 (98.048)\n",
            "Test: [30/100]\tTime 0.012 (0.036)\tLoss 1.3807 (1.4603)\tPrec@1 71.000 (71.258)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.043 (0.034)\tLoss 1.3014 (1.4633)\tPrec@1 69.000 (70.951)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/100]\tTime 0.038 (0.032)\tLoss 1.0857 (1.4349)\tPrec@1 73.000 (71.216)\tPrec@5 98.000 (97.961)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 1.1459 (1.4350)\tPrec@1 75.000 (71.148)\tPrec@5 97.000 (97.951)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 1.5696 (1.4170)\tPrec@1 71.000 (71.155)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.1732 (1.4140)\tPrec@1 75.000 (71.099)\tPrec@5 96.000 (97.988)\n",
            "Test: [90/100]\tTime 0.010 (0.029)\tLoss 1.3119 (1.4295)\tPrec@1 75.000 (70.835)\tPrec@5 100.000 (98.044)\n",
            "val Results: Prec@1 70.820 Prec@5 98.030 Loss 1.43517\n",
            "val Class Accuracy: [0.974,0.986,0.814,0.779,0.783,0.599,0.685,0.603,0.408,0.451]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [194][0/97], lr: 0.00000\tTime 0.477 (0.477)\tData 0.409 (0.409)\tLoss 0.0190 (0.0190)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][10/97], lr: 0.00000\tTime 0.064 (0.103)\tData 0.007 (0.040)\tLoss 0.0195 (0.0282)\tPrec@1 99.219 (99.077)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][20/97], lr: 0.00000\tTime 0.055 (0.082)\tData 0.007 (0.024)\tLoss 0.0176 (0.0286)\tPrec@1 99.219 (99.070)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][30/97], lr: 0.00000\tTime 0.052 (0.074)\tData 0.004 (0.018)\tLoss 0.0698 (0.0322)\tPrec@1 97.656 (98.992)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][40/97], lr: 0.00000\tTime 0.060 (0.070)\tData 0.000 (0.015)\tLoss 0.0414 (0.0318)\tPrec@1 98.438 (99.028)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][50/97], lr: 0.00000\tTime 0.052 (0.068)\tData 0.006 (0.013)\tLoss 0.0232 (0.0304)\tPrec@1 99.219 (99.081)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][60/97], lr: 0.00000\tTime 0.072 (0.066)\tData 0.010 (0.012)\tLoss 0.0236 (0.0299)\tPrec@1 99.219 (99.091)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][70/97], lr: 0.00000\tTime 0.053 (0.065)\tData 0.007 (0.011)\tLoss 0.0288 (0.0293)\tPrec@1 99.219 (99.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][80/97], lr: 0.00000\tTime 0.069 (0.064)\tData 0.001 (0.010)\tLoss 0.0140 (0.0285)\tPrec@1 100.000 (99.199)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][90/97], lr: 0.00000\tTime 0.028 (0.063)\tData 0.000 (0.009)\tLoss 0.0241 (0.0284)\tPrec@1 99.219 (99.236)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 1.1634 (1.1634)\tPrec@1 75.000 (75.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.039 (0.057)\tLoss 1.0913 (1.3450)\tPrec@1 79.000 (73.091)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.051 (0.043)\tLoss 1.3312 (1.3822)\tPrec@1 71.000 (72.238)\tPrec@5 99.000 (98.095)\n",
            "Test: [30/100]\tTime 0.017 (0.037)\tLoss 1.3310 (1.4065)\tPrec@1 73.000 (72.161)\tPrec@5 97.000 (97.903)\n",
            "Test: [40/100]\tTime 0.020 (0.034)\tLoss 1.2336 (1.4091)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (98.000)\n",
            "Test: [50/100]\tTime 0.040 (0.033)\tLoss 1.0241 (1.3817)\tPrec@1 76.000 (72.216)\tPrec@5 98.000 (98.020)\n",
            "Test: [60/100]\tTime 0.010 (0.032)\tLoss 1.1032 (1.3822)\tPrec@1 77.000 (72.131)\tPrec@5 97.000 (98.000)\n",
            "Test: [70/100]\tTime 0.056 (0.030)\tLoss 1.5273 (1.3644)\tPrec@1 72.000 (72.070)\tPrec@5 99.000 (97.972)\n",
            "Test: [80/100]\tTime 0.042 (0.031)\tLoss 1.1063 (1.3600)\tPrec@1 75.000 (71.988)\tPrec@5 97.000 (98.012)\n",
            "Test: [90/100]\tTime 0.044 (0.030)\tLoss 1.2650 (1.3755)\tPrec@1 77.000 (71.780)\tPrec@5 100.000 (98.066)\n",
            "val Results: Prec@1 71.760 Prec@5 98.040 Loss 1.38186\n",
            "val Class Accuracy: [0.976,0.985,0.805,0.772,0.798,0.600,0.699,0.613,0.447,0.481]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [195][0/97], lr: 0.00000\tTime 0.428 (0.428)\tData 0.325 (0.325)\tLoss 0.0171 (0.0171)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][10/97], lr: 0.00000\tTime 0.047 (0.105)\tData 0.000 (0.040)\tLoss 0.0141 (0.0253)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][20/97], lr: 0.00000\tTime 0.044 (0.082)\tData 0.003 (0.024)\tLoss 0.0251 (0.0237)\tPrec@1 99.219 (99.479)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][30/97], lr: 0.00000\tTime 0.065 (0.074)\tData 0.007 (0.018)\tLoss 0.0294 (0.0251)\tPrec@1 99.219 (99.446)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][40/97], lr: 0.00000\tTime 0.059 (0.070)\tData 0.000 (0.014)\tLoss 0.0224 (0.0254)\tPrec@1 99.219 (99.428)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][50/97], lr: 0.00000\tTime 0.063 (0.068)\tData 0.012 (0.013)\tLoss 0.0209 (0.0257)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][60/97], lr: 0.00000\tTime 0.070 (0.066)\tData 0.001 (0.011)\tLoss 0.0382 (0.0255)\tPrec@1 99.219 (99.436)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][70/97], lr: 0.00000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 0.0125 (0.0252)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][80/97], lr: 0.00000\tTime 0.057 (0.064)\tData 0.001 (0.010)\tLoss 0.0217 (0.0255)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][90/97], lr: 0.00000\tTime 0.047 (0.062)\tData 0.000 (0.009)\tLoss 0.0472 (0.0263)\tPrec@1 99.219 (99.408)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 1.2482 (1.2482)\tPrec@1 74.000 (74.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.019 (0.055)\tLoss 1.1133 (1.4079)\tPrec@1 79.000 (72.000)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 1.3635 (1.4483)\tPrec@1 72.000 (71.238)\tPrec@5 98.000 (97.810)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 1.3763 (1.4690)\tPrec@1 72.000 (71.226)\tPrec@5 97.000 (97.710)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 1.3037 (1.4719)\tPrec@1 70.000 (71.024)\tPrec@5 98.000 (97.829)\n",
            "Test: [50/100]\tTime 0.009 (0.030)\tLoss 1.0916 (1.4430)\tPrec@1 74.000 (71.314)\tPrec@5 97.000 (97.863)\n",
            "Test: [60/100]\tTime 0.021 (0.030)\tLoss 1.1537 (1.4422)\tPrec@1 75.000 (71.197)\tPrec@5 97.000 (97.885)\n",
            "Test: [70/100]\tTime 0.014 (0.029)\tLoss 1.5884 (1.4238)\tPrec@1 72.000 (71.183)\tPrec@5 99.000 (97.873)\n",
            "Test: [80/100]\tTime 0.011 (0.028)\tLoss 1.1845 (1.4205)\tPrec@1 74.000 (71.086)\tPrec@5 97.000 (97.975)\n",
            "Test: [90/100]\tTime 0.040 (0.028)\tLoss 1.3160 (1.4362)\tPrec@1 75.000 (70.813)\tPrec@5 100.000 (98.033)\n",
            "val Results: Prec@1 70.790 Prec@5 98.000 Loss 1.44232\n",
            "val Class Accuracy: [0.975,0.987,0.805,0.782,0.780,0.593,0.701,0.592,0.410,0.454]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [196][0/97], lr: 0.00000\tTime 0.414 (0.414)\tData 0.343 (0.343)\tLoss 0.0084 (0.0084)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][10/97], lr: 0.00000\tTime 0.076 (0.101)\tData 0.008 (0.035)\tLoss 0.0108 (0.0219)\tPrec@1 100.000 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][20/97], lr: 0.00000\tTime 0.065 (0.083)\tData 0.000 (0.020)\tLoss 0.0424 (0.0239)\tPrec@1 99.219 (99.516)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][30/97], lr: 0.00000\tTime 0.061 (0.074)\tData 0.008 (0.015)\tLoss 0.0161 (0.0252)\tPrec@1 100.000 (99.370)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][40/97], lr: 0.00000\tTime 0.058 (0.069)\tData 0.012 (0.013)\tLoss 0.0158 (0.0248)\tPrec@1 100.000 (99.409)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][50/97], lr: 0.00000\tTime 0.101 (0.067)\tData 0.007 (0.011)\tLoss 0.0627 (0.0266)\tPrec@1 97.656 (99.341)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][60/97], lr: 0.00000\tTime 0.038 (0.065)\tData 0.000 (0.010)\tLoss 0.0423 (0.0271)\tPrec@1 99.219 (99.360)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][70/97], lr: 0.00000\tTime 0.058 (0.064)\tData 0.012 (0.009)\tLoss 0.0189 (0.0267)\tPrec@1 100.000 (99.340)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][80/97], lr: 0.00000\tTime 0.049 (0.063)\tData 0.006 (0.009)\tLoss 0.0457 (0.0271)\tPrec@1 98.438 (99.325)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][90/97], lr: 0.00000\tTime 0.031 (0.062)\tData 0.000 (0.008)\tLoss 0.0523 (0.0274)\tPrec@1 97.656 (99.305)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.259 (0.259)\tLoss 1.2314 (1.2314)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.027 (0.054)\tLoss 1.1428 (1.4177)\tPrec@1 78.000 (71.727)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.034 (0.041)\tLoss 1.3651 (1.4534)\tPrec@1 71.000 (71.190)\tPrec@5 99.000 (97.857)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 1.3878 (1.4750)\tPrec@1 72.000 (71.065)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 1.3194 (1.4778)\tPrec@1 69.000 (70.878)\tPrec@5 98.000 (97.805)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 1.0885 (1.4495)\tPrec@1 74.000 (71.157)\tPrec@5 98.000 (97.843)\n",
            "Test: [60/100]\tTime 0.043 (0.031)\tLoss 1.1484 (1.4492)\tPrec@1 76.000 (71.098)\tPrec@5 97.000 (97.852)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 1.5926 (1.4320)\tPrec@1 71.000 (71.056)\tPrec@5 99.000 (97.859)\n",
            "Test: [80/100]\tTime 0.021 (0.029)\tLoss 1.1844 (1.4282)\tPrec@1 74.000 (70.975)\tPrec@5 96.000 (97.926)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.3466 (1.4441)\tPrec@1 75.000 (70.714)\tPrec@5 100.000 (97.978)\n",
            "val Results: Prec@1 70.710 Prec@5 97.970 Loss 1.45057\n",
            "val Class Accuracy: [0.976,0.984,0.812,0.776,0.788,0.597,0.684,0.608,0.401,0.445]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [197][0/97], lr: 0.00000\tTime 0.455 (0.455)\tData 0.362 (0.362)\tLoss 0.0238 (0.0238)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][10/97], lr: 0.00000\tTime 0.065 (0.099)\tData 0.007 (0.037)\tLoss 0.0150 (0.0289)\tPrec@1 100.000 (99.148)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][20/97], lr: 0.00000\tTime 0.057 (0.080)\tData 0.019 (0.022)\tLoss 0.0410 (0.0276)\tPrec@1 98.438 (99.293)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][30/97], lr: 0.00000\tTime 0.049 (0.072)\tData 0.000 (0.016)\tLoss 0.0266 (0.0286)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][40/97], lr: 0.00000\tTime 0.047 (0.068)\tData 0.003 (0.013)\tLoss 0.0395 (0.0271)\tPrec@1 99.219 (99.314)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][50/97], lr: 0.00000\tTime 0.054 (0.066)\tData 0.000 (0.011)\tLoss 0.0131 (0.0272)\tPrec@1 100.000 (99.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][60/97], lr: 0.00000\tTime 0.061 (0.065)\tData 0.000 (0.010)\tLoss 0.0795 (0.0280)\tPrec@1 98.438 (99.283)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][70/97], lr: 0.00000\tTime 0.053 (0.064)\tData 0.007 (0.010)\tLoss 0.0312 (0.0286)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][80/97], lr: 0.00000\tTime 0.080 (0.063)\tData 0.006 (0.009)\tLoss 0.0226 (0.0285)\tPrec@1 100.000 (99.228)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][90/97], lr: 0.00000\tTime 0.030 (0.062)\tData 0.000 (0.009)\tLoss 0.0448 (0.0294)\tPrec@1 98.438 (99.202)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 1.2506 (1.2506)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.042 (0.056)\tLoss 1.1508 (1.4181)\tPrec@1 78.000 (72.000)\tPrec@5 98.000 (98.364)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 1.3765 (1.4553)\tPrec@1 71.000 (71.190)\tPrec@5 100.000 (98.000)\n",
            "Test: [30/100]\tTime 0.014 (0.036)\tLoss 1.4008 (1.4761)\tPrec@1 71.000 (71.065)\tPrec@5 97.000 (97.806)\n",
            "Test: [40/100]\tTime 0.030 (0.033)\tLoss 1.3198 (1.4780)\tPrec@1 69.000 (70.854)\tPrec@5 98.000 (97.878)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 1.0986 (1.4487)\tPrec@1 74.000 (71.176)\tPrec@5 98.000 (97.902)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 1.1459 (1.4497)\tPrec@1 76.000 (71.098)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 1.6005 (1.4323)\tPrec@1 70.000 (71.127)\tPrec@5 99.000 (97.887)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 1.1902 (1.4275)\tPrec@1 74.000 (71.049)\tPrec@5 96.000 (97.938)\n",
            "Test: [90/100]\tTime 0.009 (0.028)\tLoss 1.3304 (1.4439)\tPrec@1 75.000 (70.747)\tPrec@5 100.000 (98.011)\n",
            "val Results: Prec@1 70.770 Prec@5 98.010 Loss 1.44933\n",
            "val Class Accuracy: [0.973,0.984,0.817,0.781,0.777,0.596,0.682,0.606,0.394,0.467]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [198][0/97], lr: 0.00000\tTime 0.484 (0.484)\tData 0.407 (0.407)\tLoss 0.0120 (0.0120)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][10/97], lr: 0.00000\tTime 0.058 (0.101)\tData 0.005 (0.041)\tLoss 0.0089 (0.0258)\tPrec@1 100.000 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][20/97], lr: 0.00000\tTime 0.059 (0.081)\tData 0.007 (0.024)\tLoss 0.0195 (0.0251)\tPrec@1 100.000 (99.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][30/97], lr: 0.00000\tTime 0.079 (0.074)\tData 0.006 (0.018)\tLoss 0.0124 (0.0261)\tPrec@1 100.000 (99.345)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][40/97], lr: 0.00000\tTime 0.068 (0.070)\tData 0.001 (0.014)\tLoss 0.0193 (0.0269)\tPrec@1 100.000 (99.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][50/97], lr: 0.00000\tTime 0.057 (0.067)\tData 0.005 (0.012)\tLoss 0.0367 (0.0278)\tPrec@1 98.438 (99.249)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][60/97], lr: 0.00000\tTime 0.080 (0.066)\tData 0.007 (0.011)\tLoss 0.0142 (0.0273)\tPrec@1 100.000 (99.308)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][70/97], lr: 0.00000\tTime 0.051 (0.065)\tData 0.010 (0.010)\tLoss 0.0185 (0.0277)\tPrec@1 100.000 (99.307)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][80/97], lr: 0.00000\tTime 0.057 (0.064)\tData 0.007 (0.010)\tLoss 0.0447 (0.0276)\tPrec@1 98.438 (99.296)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][90/97], lr: 0.00000\tTime 0.040 (0.062)\tData 0.000 (0.009)\tLoss 0.0607 (0.0278)\tPrec@1 98.438 (99.305)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 1.2643 (1.2643)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.018 (0.053)\tLoss 1.1215 (1.4198)\tPrec@1 79.000 (72.273)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 1.3985 (1.4514)\tPrec@1 70.000 (71.571)\tPrec@5 100.000 (98.143)\n",
            "Test: [30/100]\tTime 0.019 (0.035)\tLoss 1.4006 (1.4749)\tPrec@1 72.000 (71.323)\tPrec@5 97.000 (97.871)\n",
            "Test: [40/100]\tTime 0.043 (0.034)\tLoss 1.3320 (1.4803)\tPrec@1 69.000 (71.049)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/100]\tTime 0.048 (0.033)\tLoss 1.0898 (1.4518)\tPrec@1 72.000 (71.275)\tPrec@5 98.000 (97.941)\n",
            "Test: [60/100]\tTime 0.045 (0.031)\tLoss 1.1604 (1.4519)\tPrec@1 75.000 (71.164)\tPrec@5 97.000 (97.934)\n",
            "Test: [70/100]\tTime 0.035 (0.031)\tLoss 1.5927 (1.4343)\tPrec@1 72.000 (71.070)\tPrec@5 99.000 (97.887)\n",
            "Test: [80/100]\tTime 0.034 (0.030)\tLoss 1.1944 (1.4311)\tPrec@1 75.000 (71.025)\tPrec@5 96.000 (97.963)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 1.3410 (1.4462)\tPrec@1 75.000 (70.791)\tPrec@5 100.000 (98.022)\n",
            "val Results: Prec@1 70.750 Prec@5 97.980 Loss 1.45307\n",
            "val Class Accuracy: [0.973,0.986,0.806,0.776,0.801,0.605,0.702,0.585,0.405,0.436]\n",
            "Best Prec@1: 72.100\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [199][0/97], lr: 0.00000\tTime 0.523 (0.523)\tData 0.440 (0.440)\tLoss 0.0904 (0.0904)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][10/97], lr: 0.00000\tTime 0.040 (0.103)\tData 0.000 (0.047)\tLoss 0.0446 (0.0297)\tPrec@1 99.219 (99.290)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][20/97], lr: 0.00000\tTime 0.047 (0.082)\tData 0.006 (0.028)\tLoss 0.1034 (0.0293)\tPrec@1 96.094 (99.182)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][30/97], lr: 0.00000\tTime 0.045 (0.074)\tData 0.006 (0.021)\tLoss 0.0395 (0.0305)\tPrec@1 100.000 (99.244)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][40/97], lr: 0.00000\tTime 0.066 (0.071)\tData 0.007 (0.017)\tLoss 0.0528 (0.0304)\tPrec@1 97.656 (99.238)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][50/97], lr: 0.00000\tTime 0.064 (0.068)\tData 0.000 (0.014)\tLoss 0.0311 (0.0287)\tPrec@1 98.438 (99.311)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][60/97], lr: 0.00000\tTime 0.056 (0.066)\tData 0.008 (0.013)\tLoss 0.0117 (0.0278)\tPrec@1 100.000 (99.334)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][70/97], lr: 0.00000\tTime 0.048 (0.065)\tData 0.000 (0.012)\tLoss 0.0188 (0.0280)\tPrec@1 99.219 (99.329)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][80/97], lr: 0.00000\tTime 0.064 (0.064)\tData 0.000 (0.011)\tLoss 0.0214 (0.0279)\tPrec@1 100.000 (99.344)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][90/97], lr: 0.00000\tTime 0.029 (0.063)\tData 0.000 (0.010)\tLoss 0.0121 (0.0277)\tPrec@1 100.000 (99.305)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/100]\tTime 0.286 (0.286)\tLoss 1.2464 (1.2464)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.036 (0.057)\tLoss 1.1485 (1.4184)\tPrec@1 78.000 (71.909)\tPrec@5 98.000 (98.273)\n",
            "Test: [20/100]\tTime 0.019 (0.041)\tLoss 1.3650 (1.4550)\tPrec@1 71.000 (71.143)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.018 (0.034)\tLoss 1.3854 (1.4749)\tPrec@1 71.000 (70.968)\tPrec@5 97.000 (97.677)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 1.3163 (1.4786)\tPrec@1 70.000 (70.707)\tPrec@5 99.000 (97.805)\n",
            "Test: [50/100]\tTime 0.036 (0.032)\tLoss 1.1093 (1.4510)\tPrec@1 73.000 (70.922)\tPrec@5 98.000 (97.843)\n",
            "Test: [60/100]\tTime 0.026 (0.031)\tLoss 1.1502 (1.4509)\tPrec@1 76.000 (70.934)\tPrec@5 97.000 (97.836)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 1.5930 (1.4330)\tPrec@1 71.000 (70.915)\tPrec@5 99.000 (97.817)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 1.1610 (1.4301)\tPrec@1 75.000 (70.889)\tPrec@5 96.000 (97.877)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 1.3343 (1.4465)\tPrec@1 76.000 (70.659)\tPrec@5 100.000 (97.934)\n",
            "val Results: Prec@1 70.650 Prec@5 97.920 Loss 1.45299\n",
            "val Class Accuracy: [0.977,0.986,0.815,0.772,0.784,0.602,0.670,0.601,0.421,0.437]\n",
            "Best Prec@1: 72.100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test a pretrained checkpoint (on CIFAR-10)"
      ],
      "metadata": {
        "id": "ikf0bMupPAVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --resume '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_CE_None_exp_0.01_ss_pretrained/ckpt.best.pth.tar' -e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wei9BVrfCkJf",
        "outputId": "3ffe849c-0096-4e45-d3cc-4080dbd291ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_CE_None_exp_0.01_ss_pretrained/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/100]\tTime 2.152 (2.152)\tLoss 1.1164 (1.1164)\tPrec@1 75.000 (75.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.012 (0.215)\tLoss 1.2572 (1.1516)\tPrec@1 73.000 (72.727)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.017 (0.126)\tLoss 1.1142 (1.1867)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (97.952)\n",
            "Test: [30/100]\tTime 0.017 (0.093)\tLoss 1.4688 (1.1936)\tPrec@1 71.000 (72.323)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.037 (0.077)\tLoss 1.0497 (1.1945)\tPrec@1 75.000 (72.220)\tPrec@5 97.000 (97.976)\n",
            "Test: [50/100]\tTime 0.038 (0.067)\tLoss 0.9506 (1.1830)\tPrec@1 76.000 (72.647)\tPrec@5 97.000 (98.000)\n",
            "Test: [60/100]\tTime 0.010 (0.060)\tLoss 1.3432 (1.2020)\tPrec@1 69.000 (72.361)\tPrec@5 96.000 (97.820)\n",
            "Test: [70/100]\tTime 0.047 (0.055)\tLoss 1.2762 (1.1977)\tPrec@1 72.000 (72.282)\tPrec@5 98.000 (97.859)\n",
            "Test: [80/100]\tTime 0.010 (0.051)\tLoss 0.9457 (1.1877)\tPrec@1 80.000 (72.333)\tPrec@5 100.000 (97.938)\n",
            "Test: [90/100]\tTime 0.035 (0.049)\tLoss 0.7478 (1.2000)\tPrec@1 79.000 (72.132)\tPrec@5 100.000 (97.890)\n",
            "val Results: Prec@1 72.100 Prec@5 97.800 Loss 1.19984\n",
            "val Class Accuracy: [0.945,0.922,0.725,0.734,0.691,0.509,0.755,0.712,0.488,0.729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sM3_Slm07iWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function: LDAM**"
      ],
      "metadata": {
        "id": "KVkQnlf8O9zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-supervised pre-training (SSP)"
      ],
      "metadata": {
        "id": "s8Fs5wq9P5Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python pretrain_rot.py --dataset cifar10 --loss_type LDAM --imb_factor 0.02 --epochs=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_33XtM7sA9UQ",
        "outputId": "ca116173-0e8d-4b22-90f1-51d3a1bdedac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating folder: log/cifar10_resnet50_LDAM_None_exp_0.02_pretrain_rot\n",
            "Creating folder: ./checkpoint/cifar10_resnet50_LDAM_None_exp_0.02_pretrain_rot\n",
            "===> Creating model 'resnet50'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "cls num list:\n",
            "[5000, 3237, 2096, 1357, 878, 568, 368, 238, 154, 100]\n",
            "Epoch: [0][0/110], lr: 0.00200\tTime 7.442 (7.442)\tData 0.275 (0.275)\tLoss 1.5822 (1.5822)\tPrec@1 23.438 (23.438)\n",
            "Epoch: [0][10/110], lr: 0.00200\tTime 0.075 (0.741)\tData 0.004 (0.026)\tLoss 5.4359 (5.7492)\tPrec@1 25.000 (25.852)\n",
            "Epoch: [0][20/110], lr: 0.00200\tTime 0.063 (0.423)\tData 0.000 (0.016)\tLoss 2.0367 (4.7667)\tPrec@1 28.125 (25.446)\n",
            "Epoch: [0][30/110], lr: 0.00200\tTime 0.085 (0.310)\tData 0.012 (0.011)\tLoss 5.4737 (4.2105)\tPrec@1 26.562 (25.630)\n",
            "Epoch: [0][40/110], lr: 0.00200\tTime 0.072 (0.254)\tData 0.008 (0.009)\tLoss 3.7167 (3.9331)\tPrec@1 25.000 (25.534)\n",
            "Epoch: [0][50/110], lr: 0.00200\tTime 0.134 (0.227)\tData 0.007 (0.008)\tLoss 3.4115 (3.7089)\tPrec@1 25.781 (25.705)\n",
            "Epoch: [0][60/110], lr: 0.00200\tTime 0.117 (0.208)\tData 0.000 (0.007)\tLoss 2.1237 (3.4716)\tPrec@1 25.781 (25.832)\n",
            "Epoch: [0][70/110], lr: 0.00200\tTime 0.092 (0.194)\tData 0.000 (0.007)\tLoss 2.1047 (3.3119)\tPrec@1 27.344 (26.232)\n",
            "Epoch: [0][80/110], lr: 0.00200\tTime 0.066 (0.181)\tData 0.000 (0.006)\tLoss 1.3765 (3.1463)\tPrec@1 35.938 (26.900)\n",
            "Epoch: [0][90/110], lr: 0.00200\tTime 0.068 (0.169)\tData 0.000 (0.006)\tLoss 1.3704 (2.9855)\tPrec@1 32.031 (27.455)\n",
            "Epoch: [0][100/110], lr: 0.00200\tTime 0.069 (0.159)\tData 0.000 (0.006)\tLoss 1.4613 (2.8785)\tPrec@1 29.688 (27.692)\n",
            "Test: [0/100]\tTime 0.635 (0.635)\tLoss 6.6288 (6.6288)\tPrec@1 24.000 (24.000)\n",
            "Test: [10/100]\tTime 0.051 (0.086)\tLoss 15.1156 (13.1793)\tPrec@1 26.000 (24.545)\n",
            "Test: [20/100]\tTime 0.053 (0.059)\tLoss 13.1475 (14.9018)\tPrec@1 27.000 (25.000)\n",
            "Test: [30/100]\tTime 0.022 (0.050)\tLoss 10.2379 (14.7321)\tPrec@1 25.000 (25.065)\n",
            "Test: [40/100]\tTime 0.037 (0.046)\tLoss 11.0100 (14.5592)\tPrec@1 24.000 (25.122)\n",
            "Test: [50/100]\tTime 0.046 (0.043)\tLoss 12.2063 (15.1075)\tPrec@1 26.000 (25.118)\n",
            "Test: [60/100]\tTime 0.029 (0.041)\tLoss 12.1271 (14.9896)\tPrec@1 24.000 (25.098)\n",
            "Test: [70/100]\tTime 0.025 (0.040)\tLoss 10.4327 (15.0510)\tPrec@1 25.000 (25.113)\n",
            "Test: [80/100]\tTime 0.051 (0.039)\tLoss 18.7835 (15.0745)\tPrec@1 26.000 (25.123)\n",
            "Test: [90/100]\tTime 0.033 (0.038)\tLoss 20.6947 (14.9845)\tPrec@1 24.000 (25.110)\n",
            "val Results: Prec@1 25.150 Loss 14.76288\n",
            "Best Prec@1: 25.150\n",
            "\n",
            "Epoch: [1][0/110], lr: 0.00400\tTime 0.468 (0.468)\tData 0.231 (0.231)\tLoss 1.6353 (1.6353)\tPrec@1 23.438 (23.438)\n",
            "Epoch: [1][10/110], lr: 0.00400\tTime 0.077 (0.108)\tData 0.000 (0.022)\tLoss 2.0251 (3.3246)\tPrec@1 30.469 (30.398)\n",
            "Epoch: [1][20/110], lr: 0.00400\tTime 0.064 (0.101)\tData 0.000 (0.013)\tLoss 3.0092 (2.8164)\tPrec@1 31.250 (31.585)\n",
            "Epoch: [1][30/110], lr: 0.00400\tTime 0.078 (0.093)\tData 0.009 (0.010)\tLoss 1.6413 (2.4905)\tPrec@1 23.438 (30.544)\n",
            "Epoch: [1][40/110], lr: 0.00400\tTime 0.071 (0.087)\tData 0.007 (0.008)\tLoss 1.3218 (2.4200)\tPrec@1 39.844 (31.460)\n",
            "Epoch: [1][50/110], lr: 0.00400\tTime 0.072 (0.084)\tData 0.001 (0.007)\tLoss 2.8467 (2.4159)\tPrec@1 29.688 (31.250)\n",
            "Epoch: [1][60/110], lr: 0.00400\tTime 0.074 (0.083)\tData 0.003 (0.006)\tLoss 1.4359 (2.4623)\tPrec@1 34.375 (31.545)\n",
            "Epoch: [1][70/110], lr: 0.00400\tTime 0.069 (0.082)\tData 0.002 (0.006)\tLoss 1.4659 (2.3481)\tPrec@1 35.938 (31.646)\n",
            "Epoch: [1][80/110], lr: 0.00400\tTime 0.066 (0.081)\tData 0.000 (0.006)\tLoss 1.4144 (2.5858)\tPrec@1 33.594 (31.819)\n",
            "Epoch: [1][90/110], lr: 0.00400\tTime 0.067 (0.080)\tData 0.000 (0.005)\tLoss 1.3341 (2.4726)\tPrec@1 32.812 (31.877)\n",
            "Epoch: [1][100/110], lr: 0.00400\tTime 0.067 (0.080)\tData 0.000 (0.005)\tLoss 1.6507 (2.4180)\tPrec@1 28.906 (32.194)\n",
            "Test: [0/100]\tTime 0.402 (0.402)\tLoss 1827.3422 (1827.3422)\tPrec@1 23.000 (23.000)\n",
            "Test: [10/100]\tTime 0.064 (0.090)\tLoss 2464.2380 (2211.4558)\tPrec@1 22.000 (26.273)\n",
            "Test: [20/100]\tTime 0.048 (0.072)\tLoss 2044.6000 (2190.0746)\tPrec@1 23.000 (26.238)\n",
            "Test: [30/100]\tTime 0.035 (0.063)\tLoss 1933.7446 (2117.4451)\tPrec@1 24.000 (26.032)\n",
            "Test: [40/100]\tTime 0.023 (0.059)\tLoss 2150.6555 (2110.8019)\tPrec@1 27.000 (26.293)\n",
            "Test: [50/100]\tTime 0.054 (0.057)\tLoss 1396.0554 (2091.6498)\tPrec@1 28.000 (26.275)\n",
            "Test: [60/100]\tTime 0.033 (0.056)\tLoss 1780.7939 (2031.4978)\tPrec@1 25.000 (26.311)\n",
            "Test: [70/100]\tTime 0.039 (0.052)\tLoss 1842.5803 (2014.2324)\tPrec@1 28.000 (26.408)\n",
            "Test: [80/100]\tTime 0.048 (0.050)\tLoss 2102.3506 (2032.2073)\tPrec@1 25.000 (26.346)\n",
            "Test: [90/100]\tTime 0.031 (0.048)\tLoss 2927.6882 (2013.7932)\tPrec@1 28.000 (26.308)\n",
            "val Results: Prec@1 26.330 Loss 2009.84664\n",
            "Best Prec@1: 26.330\n",
            "\n",
            "Epoch: [2][0/110], lr: 0.00600\tTime 0.479 (0.479)\tData 0.302 (0.302)\tLoss 4.5641 (4.5641)\tPrec@1 25.781 (25.781)\n",
            "Epoch: [2][10/110], lr: 0.00600\tTime 0.064 (0.113)\tData 0.000 (0.029)\tLoss 2.5457 (2.8697)\tPrec@1 19.531 (26.776)\n",
            "Epoch: [2][20/110], lr: 0.00600\tTime 0.068 (0.095)\tData 0.001 (0.016)\tLoss 3.8840 (2.9269)\tPrec@1 24.219 (28.423)\n",
            "Epoch: [2][30/110], lr: 0.00600\tTime 0.066 (0.087)\tData 0.000 (0.011)\tLoss 11.3850 (3.5659)\tPrec@1 25.000 (28.427)\n",
            "Epoch: [2][40/110], lr: 0.00600\tTime 0.087 (0.085)\tData 0.000 (0.009)\tLoss 6.5214 (3.8072)\tPrec@1 24.219 (27.782)\n",
            "Epoch: [2][50/110], lr: 0.00600\tTime 0.066 (0.082)\tData 0.000 (0.007)\tLoss 5.1394 (3.6355)\tPrec@1 25.000 (27.313)\n",
            "Epoch: [2][60/110], lr: 0.00600\tTime 0.071 (0.081)\tData 0.000 (0.007)\tLoss 2.2560 (3.5402)\tPrec@1 25.000 (27.177)\n",
            "Epoch: [2][70/110], lr: 0.00600\tTime 0.067 (0.080)\tData 0.000 (0.006)\tLoss 1.4384 (3.4314)\tPrec@1 25.000 (27.168)\n",
            "Epoch: [2][80/110], lr: 0.00600\tTime 0.070 (0.079)\tData 0.006 (0.006)\tLoss 3.2047 (3.4668)\tPrec@1 27.344 (27.247)\n",
            "Epoch: [2][90/110], lr: 0.00600\tTime 0.063 (0.079)\tData 0.000 (0.005)\tLoss 1.4070 (3.5201)\tPrec@1 25.000 (27.206)\n",
            "Epoch: [2][100/110], lr: 0.00600\tTime 0.126 (0.079)\tData 0.000 (0.005)\tLoss 4.3941 (3.4407)\tPrec@1 26.562 (27.065)\n",
            "Test: [0/100]\tTime 0.242 (0.242)\tLoss 38.4359 (38.4359)\tPrec@1 31.000 (31.000)\n",
            "Test: [10/100]\tTime 0.061 (0.065)\tLoss 19.6767 (15.4179)\tPrec@1 25.000 (27.727)\n",
            "Test: [20/100]\tTime 0.060 (0.050)\tLoss 41.5541 (19.8220)\tPrec@1 28.000 (27.952)\n",
            "Test: [30/100]\tTime 0.057 (0.046)\tLoss 76.9896 (21.1103)\tPrec@1 25.000 (27.903)\n",
            "Test: [40/100]\tTime 0.040 (0.044)\tLoss 21.3127 (21.4553)\tPrec@1 27.000 (28.049)\n",
            "Test: [50/100]\tTime 0.024 (0.041)\tLoss 7.9608 (20.4222)\tPrec@1 32.000 (28.216)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.3884 (19.0666)\tPrec@1 26.000 (27.918)\n",
            "Test: [70/100]\tTime 0.026 (0.041)\tLoss 2.0985 (18.8801)\tPrec@1 24.000 (27.873)\n",
            "Test: [80/100]\tTime 0.038 (0.040)\tLoss 1.4467 (18.9007)\tPrec@1 23.000 (27.963)\n",
            "Test: [90/100]\tTime 0.023 (0.040)\tLoss 5.6749 (20.4856)\tPrec@1 27.000 (28.022)\n",
            "val Results: Prec@1 28.020 Loss 19.92029\n",
            "Best Prec@1: 28.020\n",
            "\n",
            "Epoch: [3][0/110], lr: 0.00800\tTime 0.393 (0.393)\tData 0.311 (0.311)\tLoss 6.0511 (6.0511)\tPrec@1 28.906 (28.906)\n",
            "Epoch: [3][10/110], lr: 0.00800\tTime 0.085 (0.116)\tData 0.000 (0.032)\tLoss 1.5510 (3.8275)\tPrec@1 23.438 (27.699)\n",
            "Epoch: [3][20/110], lr: 0.00800\tTime 0.067 (0.095)\tData 0.000 (0.017)\tLoss 1.3605 (3.6754)\tPrec@1 31.250 (27.604)\n",
            "Epoch: [3][30/110], lr: 0.00800\tTime 0.066 (0.088)\tData 0.000 (0.013)\tLoss 2.5297 (3.3588)\tPrec@1 31.250 (28.024)\n",
            "Epoch: [3][40/110], lr: 0.00800\tTime 0.105 (0.086)\tData 0.007 (0.010)\tLoss 1.3935 (3.0414)\tPrec@1 28.125 (28.468)\n",
            "Epoch: [3][50/110], lr: 0.00800\tTime 0.081 (0.084)\tData 0.007 (0.009)\tLoss 1.9671 (2.9994)\tPrec@1 32.812 (28.508)\n",
            "Epoch: [3][60/110], lr: 0.00800\tTime 0.067 (0.081)\tData 0.000 (0.008)\tLoss 5.0870 (2.9164)\tPrec@1 32.031 (28.573)\n",
            "Epoch: [3][70/110], lr: 0.00800\tTime 0.141 (0.084)\tData 0.012 (0.007)\tLoss 1.5319 (2.8012)\tPrec@1 27.344 (28.466)\n",
            "Epoch: [3][80/110], lr: 0.00800\tTime 0.124 (0.088)\tData 0.007 (0.007)\tLoss 1.3992 (2.7401)\tPrec@1 28.906 (28.492)\n",
            "Epoch: [3][90/110], lr: 0.00800\tTime 0.068 (0.089)\tData 0.000 (0.007)\tLoss 1.4497 (2.7080)\tPrec@1 26.562 (28.554)\n",
            "Epoch: [3][100/110], lr: 0.00800\tTime 0.125 (0.093)\tData 0.000 (0.006)\tLoss 1.8716 (2.6299)\tPrec@1 27.344 (28.844)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 1.3175 (1.3175)\tPrec@1 38.000 (38.000)\n",
            "Test: [10/100]\tTime 0.022 (0.084)\tLoss 2.0033 (2.7202)\tPrec@1 37.000 (32.818)\n",
            "Test: [20/100]\tTime 0.021 (0.059)\tLoss 1.5228 (2.1914)\tPrec@1 26.000 (32.095)\n",
            "Test: [30/100]\tTime 0.027 (0.053)\tLoss 1.4097 (2.2436)\tPrec@1 24.000 (31.452)\n",
            "Test: [40/100]\tTime 0.026 (0.048)\tLoss 3.7991 (2.4886)\tPrec@1 27.000 (31.390)\n",
            "Test: [50/100]\tTime 0.050 (0.046)\tLoss 1.3991 (2.3539)\tPrec@1 34.000 (31.275)\n",
            "Test: [60/100]\tTime 0.063 (0.045)\tLoss 1.3519 (2.2357)\tPrec@1 34.000 (31.459)\n",
            "Test: [70/100]\tTime 0.027 (0.044)\tLoss 4.4946 (2.1740)\tPrec@1 28.000 (31.423)\n",
            "Test: [80/100]\tTime 0.027 (0.043)\tLoss 1.4201 (2.2358)\tPrec@1 29.000 (31.185)\n",
            "Test: [90/100]\tTime 0.032 (0.042)\tLoss 1.4324 (2.1599)\tPrec@1 29.000 (31.132)\n",
            "val Results: Prec@1 31.020 Loss 2.16896\n",
            "Best Prec@1: 31.020\n",
            "\n",
            "Epoch: [4][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.349 (0.349)\tLoss 2.1778 (2.1778)\tPrec@1 26.562 (26.562)\n",
            "Epoch: [4][10/110], lr: 0.01000\tTime 0.071 (0.113)\tData 0.007 (0.035)\tLoss 1.7010 (1.7390)\tPrec@1 30.469 (29.190)\n",
            "Epoch: [4][20/110], lr: 0.01000\tTime 0.105 (0.094)\tData 0.000 (0.019)\tLoss 3.9001 (2.1526)\tPrec@1 26.562 (28.906)\n",
            "Epoch: [4][30/110], lr: 0.01000\tTime 0.078 (0.085)\tData 0.000 (0.013)\tLoss 2.6480 (2.3390)\tPrec@1 27.344 (28.301)\n",
            "Epoch: [4][40/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.009 (0.010)\tLoss 1.3721 (2.4734)\tPrec@1 26.562 (27.839)\n",
            "Epoch: [4][50/110], lr: 0.01000\tTime 0.088 (0.080)\tData 0.000 (0.008)\tLoss 1.3917 (2.3161)\tPrec@1 25.781 (27.589)\n",
            "Epoch: [4][60/110], lr: 0.01000\tTime 0.100 (0.079)\tData 0.008 (0.007)\tLoss 1.3974 (2.3828)\tPrec@1 28.906 (27.331)\n",
            "Epoch: [4][70/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.007)\tLoss 1.4233 (2.3563)\tPrec@1 24.219 (27.179)\n",
            "Epoch: [4][80/110], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.006)\tLoss 2.3014 (2.2781)\tPrec@1 26.562 (26.736)\n",
            "Epoch: [4][90/110], lr: 0.01000\tTime 0.082 (0.077)\tData 0.004 (0.006)\tLoss 3.5765 (2.2497)\tPrec@1 25.000 (26.597)\n",
            "Epoch: [4][100/110], lr: 0.01000\tTime 0.066 (0.076)\tData 0.000 (0.005)\tLoss 3.5660 (2.2241)\tPrec@1 24.219 (26.609)\n",
            "Test: [0/100]\tTime 0.398 (0.398)\tLoss 1.3767 (1.3767)\tPrec@1 27.000 (27.000)\n",
            "Test: [10/100]\tTime 0.025 (0.068)\tLoss 8.6750 (2.1024)\tPrec@1 27.000 (25.455)\n",
            "Test: [20/100]\tTime 0.022 (0.053)\tLoss 1.3924 (2.0762)\tPrec@1 26.000 (25.238)\n",
            "Test: [30/100]\tTime 0.031 (0.048)\tLoss 1.3914 (2.7108)\tPrec@1 25.000 (25.194)\n",
            "Test: [40/100]\tTime 0.041 (0.045)\tLoss 1.3822 (2.9538)\tPrec@1 26.000 (25.024)\n",
            "Test: [50/100]\tTime 0.026 (0.044)\tLoss 1.3710 (2.7623)\tPrec@1 25.000 (25.059)\n",
            "Test: [60/100]\tTime 0.050 (0.042)\tLoss 1.3840 (3.3306)\tPrec@1 26.000 (25.082)\n",
            "Test: [70/100]\tTime 0.039 (0.042)\tLoss 1.3813 (3.0764)\tPrec@1 25.000 (25.014)\n",
            "Test: [80/100]\tTime 0.029 (0.041)\tLoss 1.3815 (3.3939)\tPrec@1 25.000 (25.000)\n",
            "Test: [90/100]\tTime 0.028 (0.040)\tLoss 1.3824 (3.2434)\tPrec@1 25.000 (24.956)\n",
            "val Results: Prec@1 24.930 Loss 3.26285\n",
            "Best Prec@1: 31.020\n",
            "\n",
            "Epoch: [5][0/110], lr: 0.01000\tTime 0.523 (0.523)\tData 0.367 (0.367)\tLoss 2.0925 (2.0925)\tPrec@1 24.219 (24.219)\n",
            "Epoch: [5][10/110], lr: 0.01000\tTime 0.094 (0.113)\tData 0.007 (0.036)\tLoss 1.3577 (2.0610)\tPrec@1 28.125 (25.284)\n",
            "Epoch: [5][20/110], lr: 0.01000\tTime 0.071 (0.094)\tData 0.000 (0.020)\tLoss 1.3487 (2.0476)\tPrec@1 27.344 (26.823)\n",
            "Epoch: [5][30/110], lr: 0.01000\tTime 0.068 (0.087)\tData 0.004 (0.015)\tLoss 2.1871 (2.0710)\tPrec@1 25.000 (27.117)\n",
            "Epoch: [5][40/110], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.012)\tLoss 3.6796 (2.0239)\tPrec@1 27.344 (27.439)\n",
            "Epoch: [5][50/110], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.011)\tLoss 1.3750 (1.9724)\tPrec@1 26.562 (27.543)\n",
            "Epoch: [5][60/110], lr: 0.01000\tTime 0.075 (0.081)\tData 0.012 (0.010)\tLoss 1.6926 (1.9442)\tPrec@1 29.688 (27.395)\n",
            "Epoch: [5][70/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.009)\tLoss 1.3881 (1.9524)\tPrec@1 28.906 (27.564)\n",
            "Epoch: [5][80/110], lr: 0.01000\tTime 0.083 (0.079)\tData 0.007 (0.008)\tLoss 1.5532 (1.9148)\tPrec@1 28.906 (27.730)\n",
            "Epoch: [5][90/110], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.007)\tLoss 1.6986 (1.8932)\tPrec@1 29.688 (28.151)\n",
            "Epoch: [5][100/110], lr: 0.01000\tTime 0.077 (0.078)\tData 0.012 (0.007)\tLoss 1.3347 (1.8626)\tPrec@1 35.156 (28.450)\n",
            "Test: [0/100]\tTime 0.272 (0.272)\tLoss 1.3725 (1.3725)\tPrec@1 33.000 (33.000)\n",
            "Test: [10/100]\tTime 0.031 (0.060)\tLoss 4.0776 (2.1955)\tPrec@1 30.000 (29.364)\n",
            "Test: [20/100]\tTime 0.027 (0.045)\tLoss 1.4169 (1.8804)\tPrec@1 24.000 (28.810)\n",
            "Test: [30/100]\tTime 0.048 (0.043)\tLoss 1.3747 (1.9350)\tPrec@1 27.000 (29.387)\n",
            "Test: [40/100]\tTime 0.025 (0.040)\tLoss 1.3680 (1.8641)\tPrec@1 29.000 (29.195)\n",
            "Test: [50/100]\tTime 0.079 (0.041)\tLoss 1.3928 (1.8916)\tPrec@1 28.000 (29.118)\n",
            "Test: [60/100]\tTime 0.021 (0.041)\tLoss 1.3462 (1.9436)\tPrec@1 33.000 (28.951)\n",
            "Test: [70/100]\tTime 0.024 (0.040)\tLoss 3.8217 (1.8970)\tPrec@1 29.000 (29.014)\n",
            "Test: [80/100]\tTime 0.027 (0.040)\tLoss 3.2403 (1.9069)\tPrec@1 25.000 (29.025)\n",
            "Test: [90/100]\tTime 0.053 (0.040)\tLoss 1.3767 (1.8559)\tPrec@1 34.000 (29.110)\n",
            "val Results: Prec@1 29.020 Loss 1.89956\n",
            "Best Prec@1: 31.020\n",
            "\n",
            "Epoch: [6][0/110], lr: 0.01000\tTime 0.462 (0.462)\tData 0.267 (0.267)\tLoss 1.5950 (1.5950)\tPrec@1 28.125 (28.125)\n",
            "Epoch: [6][10/110], lr: 0.01000\tTime 0.079 (0.114)\tData 0.006 (0.028)\tLoss 1.7749 (1.5878)\tPrec@1 32.812 (28.906)\n",
            "Epoch: [6][20/110], lr: 0.01000\tTime 0.065 (0.093)\tData 0.001 (0.015)\tLoss 1.3369 (1.5579)\tPrec@1 28.906 (31.176)\n",
            "Epoch: [6][30/110], lr: 0.01000\tTime 0.080 (0.087)\tData 0.007 (0.011)\tLoss 1.4062 (1.5198)\tPrec@1 32.812 (31.300)\n",
            "Epoch: [6][40/110], lr: 0.01000\tTime 0.066 (0.083)\tData 0.000 (0.009)\tLoss 1.9235 (1.5331)\tPrec@1 36.719 (31.364)\n",
            "Epoch: [6][50/110], lr: 0.01000\tTime 0.072 (0.081)\tData 0.000 (0.008)\tLoss 1.4469 (1.5418)\tPrec@1 32.031 (31.771)\n",
            "Epoch: [6][60/110], lr: 0.01000\tTime 0.099 (0.080)\tData 0.011 (0.007)\tLoss 1.7622 (1.5548)\tPrec@1 25.781 (31.263)\n",
            "Epoch: [6][70/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.007)\tLoss 1.5645 (1.5430)\tPrec@1 28.125 (30.590)\n",
            "Epoch: [6][80/110], lr: 0.01000\tTime 0.092 (0.078)\tData 0.003 (0.006)\tLoss 1.4053 (1.5418)\tPrec@1 33.594 (30.421)\n",
            "Epoch: [6][90/110], lr: 0.01000\tTime 0.080 (0.079)\tData 0.007 (0.006)\tLoss 1.4710 (1.5384)\tPrec@1 34.375 (30.434)\n",
            "Epoch: [6][100/110], lr: 0.01000\tTime 0.082 (0.080)\tData 0.007 (0.006)\tLoss 1.7954 (1.5464)\tPrec@1 26.562 (30.067)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 174.6487 (174.6487)\tPrec@1 31.000 (31.000)\n",
            "Test: [10/100]\tTime 0.040 (0.066)\tLoss 235.1828 (222.0381)\tPrec@1 23.000 (27.455)\n",
            "Test: [20/100]\tTime 0.034 (0.054)\tLoss 67.6891 (237.3236)\tPrec@1 29.000 (25.905)\n",
            "Test: [30/100]\tTime 0.033 (0.053)\tLoss 236.5653 (254.7498)\tPrec@1 23.000 (25.677)\n",
            "Test: [40/100]\tTime 0.056 (0.056)\tLoss 277.2885 (266.6118)\tPrec@1 28.000 (25.244)\n",
            "Test: [50/100]\tTime 0.044 (0.055)\tLoss 237.6499 (277.0950)\tPrec@1 35.000 (25.706)\n",
            "Test: [60/100]\tTime 0.056 (0.056)\tLoss 320.1591 (272.9484)\tPrec@1 26.000 (25.951)\n",
            "Test: [70/100]\tTime 0.063 (0.055)\tLoss 218.9809 (270.7121)\tPrec@1 23.000 (26.113)\n",
            "Test: [80/100]\tTime 0.047 (0.055)\tLoss 361.4371 (275.6562)\tPrec@1 20.000 (26.198)\n",
            "Test: [90/100]\tTime 0.054 (0.055)\tLoss 199.7748 (274.8618)\tPrec@1 24.000 (25.923)\n",
            "val Results: Prec@1 26.020 Loss 279.92105\n",
            "Best Prec@1: 31.020\n",
            "\n",
            "Epoch: [7][0/110], lr: 0.01000\tTime 0.502 (0.502)\tData 0.291 (0.291)\tLoss 1.3687 (1.3687)\tPrec@1 28.125 (28.125)\n",
            "Epoch: [7][10/110], lr: 0.01000\tTime 0.067 (0.115)\tData 0.000 (0.028)\tLoss 1.5423 (1.5106)\tPrec@1 21.875 (24.432)\n",
            "Epoch: [7][20/110], lr: 0.01000\tTime 0.066 (0.096)\tData 0.000 (0.016)\tLoss 1.5448 (1.4768)\tPrec@1 32.031 (26.600)\n",
            "Epoch: [7][30/110], lr: 0.01000\tTime 0.098 (0.089)\tData 0.000 (0.011)\tLoss 1.8775 (1.4873)\tPrec@1 26.562 (26.941)\n",
            "Epoch: [7][40/110], lr: 0.01000\tTime 0.076 (0.086)\tData 0.000 (0.009)\tLoss 1.3982 (1.4670)\tPrec@1 28.906 (27.820)\n",
            "Epoch: [7][50/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.006 (0.008)\tLoss 1.3747 (1.4527)\tPrec@1 29.688 (28.493)\n",
            "Epoch: [7][60/110], lr: 0.01000\tTime 0.068 (0.083)\tData 0.000 (0.007)\tLoss 1.3736 (1.4419)\tPrec@1 30.469 (29.214)\n",
            "Epoch: [7][70/110], lr: 0.01000\tTime 0.078 (0.082)\tData 0.007 (0.007)\tLoss 1.5428 (1.4562)\tPrec@1 27.344 (29.247)\n",
            "Epoch: [7][80/110], lr: 0.01000\tTime 0.067 (0.082)\tData 0.001 (0.006)\tLoss 1.3101 (1.4451)\tPrec@1 42.188 (29.996)\n",
            "Epoch: [7][90/110], lr: 0.01000\tTime 0.062 (0.081)\tData 0.000 (0.006)\tLoss 1.3340 (1.4418)\tPrec@1 29.688 (30.460)\n",
            "Epoch: [7][100/110], lr: 0.01000\tTime 0.085 (0.083)\tData 0.008 (0.005)\tLoss 1.8068 (1.4413)\tPrec@1 25.781 (30.770)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 1.4058 (1.4058)\tPrec@1 41.000 (41.000)\n",
            "Test: [10/100]\tTime 0.025 (0.068)\tLoss 1.4207 (1.3452)\tPrec@1 27.000 (36.091)\n",
            "Test: [20/100]\tTime 0.026 (0.055)\tLoss 1.4194 (1.3509)\tPrec@1 26.000 (34.714)\n",
            "Test: [30/100]\tTime 0.025 (0.049)\tLoss 1.3305 (1.3502)\tPrec@1 36.000 (34.194)\n",
            "Test: [40/100]\tTime 0.024 (0.047)\tLoss 1.4013 (1.3633)\tPrec@1 36.000 (33.634)\n",
            "Test: [50/100]\tTime 0.029 (0.045)\tLoss 1.3208 (1.3638)\tPrec@1 37.000 (33.647)\n",
            "Test: [60/100]\tTime 0.043 (0.044)\tLoss 1.3352 (1.3614)\tPrec@1 34.000 (33.607)\n",
            "Test: [70/100]\tTime 0.025 (0.043)\tLoss 1.3715 (1.3621)\tPrec@1 34.000 (33.845)\n",
            "Test: [80/100]\tTime 0.031 (0.042)\tLoss 1.3652 (1.3605)\tPrec@1 33.000 (34.025)\n",
            "Test: [90/100]\tTime 0.028 (0.041)\tLoss 1.3635 (1.3628)\tPrec@1 32.000 (33.890)\n",
            "val Results: Prec@1 33.610 Loss 1.36512\n",
            "Best Prec@1: 33.610\n",
            "\n",
            "Epoch: [8][0/110], lr: 0.01000\tTime 0.448 (0.448)\tData 0.244 (0.244)\tLoss 1.3423 (1.3423)\tPrec@1 38.281 (38.281)\n",
            "Epoch: [8][10/110], lr: 0.01000\tTime 0.080 (0.115)\tData 0.000 (0.025)\tLoss 1.3037 (1.3761)\tPrec@1 39.062 (35.014)\n",
            "Epoch: [8][20/110], lr: 0.01000\tTime 0.073 (0.096)\tData 0.007 (0.015)\tLoss 1.3061 (1.3555)\tPrec@1 40.625 (36.049)\n",
            "Epoch: [8][30/110], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.011)\tLoss 1.3856 (1.3573)\tPrec@1 36.719 (35.257)\n",
            "Epoch: [8][40/110], lr: 0.01000\tTime 0.089 (0.085)\tData 0.007 (0.009)\tLoss 1.3556 (1.3567)\tPrec@1 38.281 (35.899)\n",
            "Epoch: [8][50/110], lr: 0.01000\tTime 0.073 (0.083)\tData 0.007 (0.008)\tLoss 1.2762 (1.3535)\tPrec@1 39.062 (36.443)\n",
            "Epoch: [8][60/110], lr: 0.01000\tTime 0.078 (0.082)\tData 0.007 (0.007)\tLoss 1.3087 (1.3602)\tPrec@1 41.406 (36.527)\n",
            "Epoch: [8][70/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.006)\tLoss 1.4820 (1.3549)\tPrec@1 37.500 (36.708)\n",
            "Epoch: [8][80/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.005)\tLoss 1.4745 (1.3599)\tPrec@1 40.625 (36.786)\n",
            "Epoch: [8][90/110], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.005)\tLoss 1.3440 (1.3557)\tPrec@1 35.156 (37.105)\n",
            "Epoch: [8][100/110], lr: 0.01000\tTime 0.069 (0.082)\tData 0.000 (0.005)\tLoss 1.3227 (1.3586)\tPrec@1 32.031 (36.959)\n",
            "Test: [0/100]\tTime 0.331 (0.331)\tLoss 1.2805 (1.2805)\tPrec@1 42.000 (42.000)\n",
            "Test: [10/100]\tTime 0.054 (0.070)\tLoss 1.3204 (1.3014)\tPrec@1 35.000 (38.909)\n",
            "Test: [20/100]\tTime 0.056 (0.056)\tLoss 1.3139 (1.3019)\tPrec@1 35.000 (37.857)\n",
            "Test: [30/100]\tTime 0.035 (0.049)\tLoss 1.2996 (1.3008)\tPrec@1 38.000 (38.355)\n",
            "Test: [40/100]\tTime 0.031 (0.046)\tLoss 1.3246 (1.3006)\tPrec@1 37.000 (38.439)\n",
            "Test: [50/100]\tTime 0.057 (0.044)\tLoss 1.3956 (1.3082)\tPrec@1 38.000 (38.039)\n",
            "Test: [60/100]\tTime 0.037 (0.043)\tLoss 1.3774 (1.3093)\tPrec@1 23.000 (37.836)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.2481 (1.3088)\tPrec@1 48.000 (38.254)\n",
            "Test: [80/100]\tTime 0.028 (0.041)\tLoss 1.3012 (1.3184)\tPrec@1 38.000 (38.062)\n",
            "Test: [90/100]\tTime 0.045 (0.040)\tLoss 1.3165 (1.3150)\tPrec@1 37.000 (38.209)\n",
            "val Results: Prec@1 37.950 Loss 1.31900\n",
            "Best Prec@1: 37.950\n",
            "\n",
            "Epoch: [9][0/110], lr: 0.01000\tTime 0.479 (0.479)\tData 0.321 (0.321)\tLoss 1.3189 (1.3189)\tPrec@1 39.844 (39.844)\n",
            "Epoch: [9][10/110], lr: 0.01000\tTime 0.068 (0.117)\tData 0.000 (0.033)\tLoss 1.2802 (1.3398)\tPrec@1 40.625 (38.991)\n",
            "Epoch: [9][20/110], lr: 0.01000\tTime 0.067 (0.097)\tData 0.000 (0.019)\tLoss 1.2880 (1.3365)\tPrec@1 42.188 (38.988)\n",
            "Epoch: [9][30/110], lr: 0.01000\tTime 0.070 (0.089)\tData 0.007 (0.014)\tLoss 1.2935 (1.3358)\tPrec@1 35.938 (38.785)\n",
            "Epoch: [9][40/110], lr: 0.01000\tTime 0.089 (0.086)\tData 0.000 (0.011)\tLoss 1.3962 (1.3290)\tPrec@1 33.594 (39.196)\n",
            "Epoch: [9][50/110], lr: 0.01000\tTime 0.070 (0.083)\tData 0.000 (0.010)\tLoss 1.3026 (1.3193)\tPrec@1 39.062 (39.537)\n",
            "Epoch: [9][60/110], lr: 0.01000\tTime 0.063 (0.081)\tData 0.000 (0.008)\tLoss 1.3574 (1.3215)\tPrec@1 32.031 (39.344)\n",
            "Epoch: [9][70/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.003 (0.007)\tLoss 1.3205 (1.3233)\tPrec@1 42.188 (39.118)\n",
            "Epoch: [9][80/110], lr: 0.01000\tTime 0.077 (0.079)\tData 0.006 (0.007)\tLoss 1.2778 (1.3172)\tPrec@1 37.500 (39.371)\n",
            "Epoch: [9][90/110], lr: 0.01000\tTime 0.069 (0.078)\tData 0.004 (0.007)\tLoss 1.2826 (1.3161)\tPrec@1 37.500 (39.457)\n",
            "Epoch: [9][100/110], lr: 0.01000\tTime 0.075 (0.078)\tData 0.011 (0.006)\tLoss 1.2899 (1.3156)\tPrec@1 39.062 (39.426)\n",
            "Test: [0/100]\tTime 0.286 (0.286)\tLoss 1.2660 (1.2660)\tPrec@1 50.000 (50.000)\n",
            "Test: [10/100]\tTime 0.033 (0.066)\tLoss 1.2763 (1.2740)\tPrec@1 36.000 (39.545)\n",
            "Test: [20/100]\tTime 0.023 (0.051)\tLoss 1.2932 (1.2802)\tPrec@1 39.000 (39.429)\n",
            "Test: [30/100]\tTime 0.031 (0.046)\tLoss 1.3037 (1.2820)\tPrec@1 38.000 (39.258)\n",
            "Test: [40/100]\tTime 0.026 (0.044)\tLoss 1.3527 (1.2819)\tPrec@1 41.000 (39.805)\n",
            "Test: [50/100]\tTime 0.065 (0.043)\tLoss 1.3161 (1.2866)\tPrec@1 50.000 (40.098)\n",
            "Test: [60/100]\tTime 0.040 (0.042)\tLoss 1.2819 (1.2867)\tPrec@1 40.000 (39.803)\n",
            "Test: [70/100]\tTime 0.034 (0.041)\tLoss 1.2171 (1.2827)\tPrec@1 43.000 (40.141)\n",
            "Test: [80/100]\tTime 0.028 (0.040)\tLoss 1.2906 (1.2827)\tPrec@1 43.000 (40.099)\n",
            "Test: [90/100]\tTime 0.075 (0.040)\tLoss 1.2807 (1.2841)\tPrec@1 40.000 (40.066)\n",
            "val Results: Prec@1 40.100 Loss 1.28181\n",
            "Best Prec@1: 40.100\n",
            "\n",
            "Epoch: [10][0/110], lr: 0.01000\tTime 0.499 (0.499)\tData 0.259 (0.259)\tLoss 1.3129 (1.3129)\tPrec@1 44.531 (44.531)\n",
            "Epoch: [10][10/110], lr: 0.01000\tTime 0.073 (0.166)\tData 0.000 (0.040)\tLoss 1.4361 (1.3201)\tPrec@1 38.281 (39.560)\n",
            "Epoch: [10][20/110], lr: 0.01000\tTime 0.067 (0.122)\tData 0.001 (0.022)\tLoss 1.3494 (1.3009)\tPrec@1 34.375 (39.918)\n",
            "Epoch: [10][30/110], lr: 0.01000\tTime 0.070 (0.106)\tData 0.000 (0.016)\tLoss 1.3350 (1.2884)\tPrec@1 40.625 (40.600)\n",
            "Epoch: [10][40/110], lr: 0.01000\tTime 0.083 (0.099)\tData 0.007 (0.013)\tLoss 1.2527 (1.2750)\tPrec@1 47.656 (41.502)\n",
            "Epoch: [10][50/110], lr: 0.01000\tTime 0.082 (0.094)\tData 0.000 (0.011)\tLoss 1.2370 (1.2802)\tPrec@1 43.750 (41.391)\n",
            "Epoch: [10][60/110], lr: 0.01000\tTime 0.068 (0.091)\tData 0.000 (0.010)\tLoss 1.1964 (1.2809)\tPrec@1 45.312 (41.662)\n",
            "Epoch: [10][70/110], lr: 0.01000\tTime 0.082 (0.089)\tData 0.007 (0.009)\tLoss 1.2117 (1.2790)\tPrec@1 39.844 (41.549)\n",
            "Epoch: [10][80/110], lr: 0.01000\tTime 0.091 (0.087)\tData 0.013 (0.008)\tLoss 1.1833 (1.2757)\tPrec@1 48.438 (41.609)\n",
            "Epoch: [10][90/110], lr: 0.01000\tTime 0.077 (0.085)\tData 0.000 (0.007)\tLoss 1.2321 (1.2719)\tPrec@1 42.969 (41.741)\n",
            "Epoch: [10][100/110], lr: 0.01000\tTime 0.108 (0.086)\tData 0.007 (0.007)\tLoss 1.2478 (1.2708)\tPrec@1 40.625 (41.793)\n",
            "Test: [0/100]\tTime 0.330 (0.330)\tLoss 1.1184 (1.1184)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.037 (0.071)\tLoss 1.2871 (1.2453)\tPrec@1 36.000 (42.273)\n",
            "Test: [20/100]\tTime 0.033 (0.053)\tLoss 1.3131 (1.2536)\tPrec@1 36.000 (41.762)\n",
            "Test: [30/100]\tTime 0.033 (0.049)\tLoss 1.2283 (1.2513)\tPrec@1 41.000 (42.000)\n",
            "Test: [40/100]\tTime 0.032 (0.045)\tLoss 1.1967 (1.2499)\tPrec@1 47.000 (42.220)\n",
            "Test: [50/100]\tTime 0.056 (0.044)\tLoss 1.2447 (1.2548)\tPrec@1 48.000 (42.157)\n",
            "Test: [60/100]\tTime 0.032 (0.042)\tLoss 1.3090 (1.2601)\tPrec@1 29.000 (41.525)\n",
            "Test: [70/100]\tTime 0.045 (0.042)\tLoss 1.1999 (1.2678)\tPrec@1 45.000 (41.521)\n",
            "Test: [80/100]\tTime 0.024 (0.041)\tLoss 1.2474 (1.2660)\tPrec@1 48.000 (41.543)\n",
            "Test: [90/100]\tTime 0.025 (0.040)\tLoss 1.2545 (1.2619)\tPrec@1 44.000 (41.912)\n",
            "val Results: Prec@1 41.840 Loss 1.26150\n",
            "Best Prec@1: 41.840\n",
            "\n",
            "Epoch: [11][0/110], lr: 0.01000\tTime 0.450 (0.450)\tData 0.267 (0.267)\tLoss 1.2249 (1.2249)\tPrec@1 39.062 (39.062)\n",
            "Epoch: [11][10/110], lr: 0.01000\tTime 0.066 (0.112)\tData 0.000 (0.026)\tLoss 1.2271 (1.2283)\tPrec@1 45.312 (42.898)\n",
            "Epoch: [11][20/110], lr: 0.01000\tTime 0.097 (0.095)\tData 0.000 (0.014)\tLoss 1.2331 (1.2329)\tPrec@1 39.062 (42.783)\n",
            "Epoch: [11][30/110], lr: 0.01000\tTime 0.062 (0.087)\tData 0.000 (0.010)\tLoss 1.2644 (1.2423)\tPrec@1 39.844 (42.742)\n",
            "Epoch: [11][40/110], lr: 0.01000\tTime 0.062 (0.083)\tData 0.000 (0.008)\tLoss 1.2674 (1.2505)\tPrec@1 38.281 (42.511)\n",
            "Epoch: [11][50/110], lr: 0.01000\tTime 0.079 (0.081)\tData 0.010 (0.007)\tLoss 1.2261 (1.2427)\tPrec@1 46.875 (43.076)\n",
            "Epoch: [11][60/110], lr: 0.01000\tTime 0.084 (0.080)\tData 0.011 (0.007)\tLoss 1.3485 (1.2525)\tPrec@1 32.031 (42.789)\n",
            "Epoch: [11][70/110], lr: 0.01000\tTime 0.068 (0.080)\tData 0.000 (0.006)\tLoss 1.1972 (1.2511)\tPrec@1 52.344 (42.881)\n",
            "Epoch: [11][80/110], lr: 0.01000\tTime 0.088 (0.079)\tData 0.013 (0.006)\tLoss 1.3351 (1.2516)\tPrec@1 40.625 (43.017)\n",
            "Epoch: [11][90/110], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.005)\tLoss 1.3835 (1.2473)\tPrec@1 37.500 (43.286)\n",
            "Epoch: [11][100/110], lr: 0.01000\tTime 0.074 (0.078)\tData 0.007 (0.005)\tLoss 1.1575 (1.2413)\tPrec@1 49.219 (43.735)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 1.0582 (1.0582)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.022 (0.057)\tLoss 1.2750 (1.2232)\tPrec@1 38.000 (43.000)\n",
            "Test: [20/100]\tTime 0.021 (0.044)\tLoss 1.2481 (1.2244)\tPrec@1 43.000 (43.429)\n",
            "Test: [30/100]\tTime 0.062 (0.043)\tLoss 1.2576 (1.2234)\tPrec@1 43.000 (43.581)\n",
            "Test: [40/100]\tTime 0.035 (0.042)\tLoss 1.1783 (1.2219)\tPrec@1 47.000 (44.098)\n",
            "Test: [50/100]\tTime 0.023 (0.038)\tLoss 1.1947 (1.2249)\tPrec@1 50.000 (43.941)\n",
            "Test: [60/100]\tTime 0.022 (0.039)\tLoss 1.3326 (1.2280)\tPrec@1 33.000 (43.590)\n",
            "Test: [70/100]\tTime 0.026 (0.038)\tLoss 1.2418 (1.2291)\tPrec@1 49.000 (43.761)\n",
            "Test: [80/100]\tTime 0.035 (0.039)\tLoss 1.1989 (1.2283)\tPrec@1 43.000 (43.728)\n",
            "Test: [90/100]\tTime 0.069 (0.039)\tLoss 1.2708 (1.2270)\tPrec@1 40.000 (43.758)\n",
            "val Results: Prec@1 43.850 Loss 1.22629\n",
            "Best Prec@1: 43.850\n",
            "\n",
            "Epoch: [12][0/110], lr: 0.01000\tTime 0.454 (0.454)\tData 0.301 (0.301)\tLoss 1.2521 (1.2521)\tPrec@1 42.969 (42.969)\n",
            "Epoch: [12][10/110], lr: 0.01000\tTime 0.074 (0.112)\tData 0.009 (0.029)\tLoss 1.2547 (1.2678)\tPrec@1 38.281 (39.702)\n",
            "Epoch: [12][20/110], lr: 0.01000\tTime 0.074 (0.095)\tData 0.009 (0.016)\tLoss 1.3294 (1.2403)\tPrec@1 38.281 (43.155)\n",
            "Epoch: [12][30/110], lr: 0.01000\tTime 0.064 (0.088)\tData 0.000 (0.011)\tLoss 1.2127 (1.2362)\tPrec@1 50.000 (43.674)\n",
            "Epoch: [12][40/110], lr: 0.01000\tTime 0.068 (0.083)\tData 0.000 (0.009)\tLoss 1.1619 (1.2346)\tPrec@1 50.781 (43.750)\n",
            "Epoch: [12][50/110], lr: 0.01000\tTime 0.062 (0.082)\tData 0.000 (0.008)\tLoss 1.2611 (1.2281)\tPrec@1 42.969 (44.286)\n",
            "Epoch: [12][60/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.009 (0.007)\tLoss 1.1242 (1.2323)\tPrec@1 50.781 (44.352)\n",
            "Epoch: [12][70/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.000 (0.007)\tLoss 1.2398 (1.2300)\tPrec@1 44.531 (44.553)\n",
            "Epoch: [12][80/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.006)\tLoss 1.3139 (1.2283)\tPrec@1 44.531 (44.686)\n",
            "Epoch: [12][90/110], lr: 0.01000\tTime 0.075 (0.081)\tData 0.000 (0.006)\tLoss 1.2119 (1.2278)\tPrec@1 45.312 (44.875)\n",
            "Epoch: [12][100/110], lr: 0.01000\tTime 0.081 (0.081)\tData 0.005 (0.006)\tLoss 1.2693 (1.2261)\tPrec@1 39.844 (44.964)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 1.0563 (1.0563)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.025 (0.065)\tLoss 1.2886 (1.1902)\tPrec@1 34.000 (46.273)\n",
            "Test: [20/100]\tTime 0.030 (0.051)\tLoss 1.2407 (1.1909)\tPrec@1 39.000 (46.000)\n",
            "Test: [30/100]\tTime 0.036 (0.045)\tLoss 1.2406 (1.1939)\tPrec@1 45.000 (45.484)\n",
            "Test: [40/100]\tTime 0.025 (0.041)\tLoss 1.2338 (1.1948)\tPrec@1 42.000 (45.634)\n",
            "Test: [50/100]\tTime 0.023 (0.039)\tLoss 1.1907 (1.1976)\tPrec@1 55.000 (45.980)\n",
            "Test: [60/100]\tTime 0.023 (0.038)\tLoss 1.2571 (1.2092)\tPrec@1 42.000 (45.590)\n",
            "Test: [70/100]\tTime 0.035 (0.038)\tLoss 1.2286 (1.2107)\tPrec@1 48.000 (45.620)\n",
            "Test: [80/100]\tTime 0.047 (0.038)\tLoss 1.1727 (1.2088)\tPrec@1 50.000 (45.580)\n",
            "Test: [90/100]\tTime 0.057 (0.038)\tLoss 1.2527 (1.2074)\tPrec@1 48.000 (45.604)\n",
            "val Results: Prec@1 45.600 Loss 1.20631\n",
            "Best Prec@1: 45.600\n",
            "\n",
            "Epoch: [13][0/110], lr: 0.01000\tTime 0.511 (0.511)\tData 0.325 (0.325)\tLoss 1.2117 (1.2117)\tPrec@1 49.219 (49.219)\n",
            "Epoch: [13][10/110], lr: 0.01000\tTime 0.121 (0.121)\tData 0.007 (0.032)\tLoss 1.2260 (1.1982)\tPrec@1 44.531 (49.148)\n",
            "Epoch: [13][20/110], lr: 0.01000\tTime 0.099 (0.114)\tData 0.010 (0.019)\tLoss 1.1746 (1.1815)\tPrec@1 50.000 (49.293)\n",
            "Epoch: [13][30/110], lr: 0.01000\tTime 0.088 (0.115)\tData 0.010 (0.015)\tLoss 1.1985 (1.2059)\tPrec@1 48.438 (47.404)\n",
            "Epoch: [13][40/110], lr: 0.01000\tTime 0.089 (0.116)\tData 0.000 (0.011)\tLoss 1.2238 (1.2002)\tPrec@1 45.312 (47.466)\n",
            "Epoch: [13][50/110], lr: 0.01000\tTime 0.064 (0.112)\tData 0.000 (0.010)\tLoss 1.1767 (1.1978)\tPrec@1 52.344 (47.488)\n",
            "Epoch: [13][60/110], lr: 0.01000\tTime 0.107 (0.106)\tData 0.000 (0.009)\tLoss 1.1788 (1.1996)\tPrec@1 50.000 (47.349)\n",
            "Epoch: [13][70/110], lr: 0.01000\tTime 0.065 (0.103)\tData 0.001 (0.008)\tLoss 1.1576 (1.1987)\tPrec@1 49.219 (47.084)\n",
            "Epoch: [13][80/110], lr: 0.01000\tTime 0.068 (0.100)\tData 0.000 (0.007)\tLoss 1.3098 (1.1982)\tPrec@1 37.500 (47.116)\n",
            "Epoch: [13][90/110], lr: 0.01000\tTime 0.075 (0.098)\tData 0.002 (0.007)\tLoss 1.2485 (1.1965)\tPrec@1 42.188 (47.167)\n",
            "Epoch: [13][100/110], lr: 0.01000\tTime 0.073 (0.096)\tData 0.000 (0.007)\tLoss 1.1969 (1.1925)\tPrec@1 50.781 (47.401)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 1.1053 (1.1053)\tPrec@1 47.000 (47.000)\n",
            "Test: [10/100]\tTime 0.037 (0.066)\tLoss 1.2592 (1.1799)\tPrec@1 40.000 (47.273)\n",
            "Test: [20/100]\tTime 0.044 (0.049)\tLoss 1.2364 (1.1823)\tPrec@1 45.000 (46.952)\n",
            "Test: [30/100]\tTime 0.026 (0.043)\tLoss 1.1517 (1.1864)\tPrec@1 46.000 (46.419)\n",
            "Test: [40/100]\tTime 0.038 (0.041)\tLoss 1.2016 (1.1835)\tPrec@1 45.000 (46.415)\n",
            "Test: [50/100]\tTime 0.028 (0.039)\tLoss 1.1772 (1.1870)\tPrec@1 49.000 (46.176)\n",
            "Test: [60/100]\tTime 0.023 (0.038)\tLoss 1.2054 (1.1934)\tPrec@1 41.000 (45.754)\n",
            "Test: [70/100]\tTime 0.029 (0.037)\tLoss 1.2092 (1.1942)\tPrec@1 42.000 (45.690)\n",
            "Test: [80/100]\tTime 0.028 (0.037)\tLoss 1.1212 (1.1924)\tPrec@1 49.000 (45.457)\n",
            "Test: [90/100]\tTime 0.026 (0.038)\tLoss 1.1810 (1.1896)\tPrec@1 49.000 (45.758)\n",
            "val Results: Prec@1 45.820 Loss 1.18866\n",
            "Best Prec@1: 45.820\n",
            "\n",
            "Epoch: [14][0/110], lr: 0.01000\tTime 0.483 (0.483)\tData 0.324 (0.324)\tLoss 1.1608 (1.1608)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [14][10/110], lr: 0.01000\tTime 0.077 (0.114)\tData 0.007 (0.032)\tLoss 1.2602 (1.2524)\tPrec@1 43.750 (44.105)\n",
            "Epoch: [14][20/110], lr: 0.01000\tTime 0.065 (0.093)\tData 0.000 (0.017)\tLoss 1.2595 (1.2408)\tPrec@1 42.969 (44.494)\n",
            "Epoch: [14][30/110], lr: 0.01000\tTime 0.069 (0.087)\tData 0.000 (0.012)\tLoss 1.2443 (1.2367)\tPrec@1 47.656 (44.481)\n",
            "Epoch: [14][40/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.009)\tLoss 1.3733 (1.2250)\tPrec@1 37.500 (45.465)\n",
            "Epoch: [14][50/110], lr: 0.01000\tTime 0.067 (0.082)\tData 0.001 (0.008)\tLoss 1.1290 (1.2254)\tPrec@1 53.906 (45.067)\n",
            "Epoch: [14][60/110], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.007)\tLoss 1.2433 (1.2212)\tPrec@1 35.938 (45.287)\n",
            "Epoch: [14][70/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.006)\tLoss 1.1625 (1.2166)\tPrec@1 44.531 (45.467)\n",
            "Epoch: [14][80/110], lr: 0.01000\tTime 0.096 (0.081)\tData 0.007 (0.006)\tLoss 1.1418 (1.2152)\tPrec@1 48.438 (45.573)\n",
            "Epoch: [14][90/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.006)\tLoss 1.2709 (1.2135)\tPrec@1 43.750 (45.544)\n",
            "Epoch: [14][100/110], lr: 0.01000\tTime 0.085 (0.081)\tData 0.000 (0.006)\tLoss 1.1727 (1.2126)\tPrec@1 50.781 (45.498)\n",
            "Test: [0/100]\tTime 0.338 (0.338)\tLoss 1.1461 (1.1461)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.022 (0.066)\tLoss 1.2883 (1.1854)\tPrec@1 36.000 (47.182)\n",
            "Test: [20/100]\tTime 0.024 (0.052)\tLoss 1.2612 (1.2095)\tPrec@1 39.000 (46.476)\n",
            "Test: [30/100]\tTime 0.034 (0.047)\tLoss 1.1604 (1.2107)\tPrec@1 43.000 (46.355)\n",
            "Test: [40/100]\tTime 0.037 (0.044)\tLoss 1.2112 (1.2057)\tPrec@1 45.000 (46.951)\n",
            "Test: [50/100]\tTime 0.043 (0.042)\tLoss 1.1839 (1.2062)\tPrec@1 46.000 (46.804)\n",
            "Test: [60/100]\tTime 0.054 (0.041)\tLoss 1.2397 (1.2057)\tPrec@1 35.000 (46.246)\n",
            "Test: [70/100]\tTime 0.037 (0.040)\tLoss 1.1524 (1.2076)\tPrec@1 49.000 (46.268)\n",
            "Test: [80/100]\tTime 0.023 (0.039)\tLoss 1.1189 (1.2079)\tPrec@1 52.000 (46.160)\n",
            "Test: [90/100]\tTime 0.024 (0.038)\tLoss 1.2096 (1.2037)\tPrec@1 53.000 (46.473)\n",
            "val Results: Prec@1 46.440 Loss 1.20177\n",
            "Best Prec@1: 46.440\n",
            "\n",
            "Epoch: [15][0/110], lr: 0.01000\tTime 0.524 (0.524)\tData 0.400 (0.400)\tLoss 1.1884 (1.1884)\tPrec@1 45.312 (45.312)\n",
            "Epoch: [15][10/110], lr: 0.01000\tTime 0.066 (0.117)\tData 0.000 (0.038)\tLoss 1.1208 (1.1948)\tPrec@1 48.438 (44.531)\n",
            "Epoch: [15][20/110], lr: 0.01000\tTime 0.073 (0.098)\tData 0.006 (0.021)\tLoss 1.4031 (1.2002)\tPrec@1 45.312 (45.201)\n",
            "Epoch: [15][30/110], lr: 0.01000\tTime 0.063 (0.091)\tData 0.000 (0.015)\tLoss 1.2164 (1.1941)\tPrec@1 46.094 (45.691)\n",
            "Epoch: [15][40/110], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.012)\tLoss 1.2158 (1.1895)\tPrec@1 45.312 (46.246)\n",
            "Epoch: [15][50/110], lr: 0.01000\tTime 0.081 (0.083)\tData 0.000 (0.010)\tLoss 1.1362 (1.1877)\tPrec@1 50.781 (46.569)\n",
            "Epoch: [15][60/110], lr: 0.01000\tTime 0.079 (0.082)\tData 0.000 (0.008)\tLoss 1.1649 (1.1914)\tPrec@1 46.875 (46.030)\n",
            "Epoch: [15][70/110], lr: 0.01000\tTime 0.072 (0.080)\tData 0.000 (0.007)\tLoss 1.1331 (1.1877)\tPrec@1 57.812 (46.292)\n",
            "Epoch: [15][80/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.007)\tLoss 1.1386 (1.1840)\tPrec@1 49.219 (46.451)\n",
            "Epoch: [15][90/110], lr: 0.01000\tTime 0.076 (0.081)\tData 0.001 (0.006)\tLoss 1.2168 (1.1819)\tPrec@1 45.312 (46.738)\n",
            "Epoch: [15][100/110], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.006)\tLoss 1.1807 (1.1810)\tPrec@1 44.531 (46.829)\n",
            "Test: [0/100]\tTime 0.278 (0.278)\tLoss 1.0816 (1.0816)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.034 (0.069)\tLoss 1.2531 (1.1687)\tPrec@1 39.000 (46.636)\n",
            "Test: [20/100]\tTime 0.024 (0.052)\tLoss 1.2092 (1.1728)\tPrec@1 42.000 (46.667)\n",
            "Test: [30/100]\tTime 0.025 (0.047)\tLoss 1.1588 (1.1744)\tPrec@1 46.000 (46.032)\n",
            "Test: [40/100]\tTime 0.045 (0.044)\tLoss 1.1916 (1.1719)\tPrec@1 44.000 (46.366)\n",
            "Test: [50/100]\tTime 0.028 (0.043)\tLoss 1.1294 (1.1730)\tPrec@1 54.000 (46.471)\n",
            "Test: [60/100]\tTime 0.034 (0.041)\tLoss 1.2535 (1.1787)\tPrec@1 37.000 (46.180)\n",
            "Test: [70/100]\tTime 0.065 (0.040)\tLoss 1.1652 (1.1823)\tPrec@1 53.000 (46.239)\n",
            "Test: [80/100]\tTime 0.024 (0.039)\tLoss 1.1927 (1.1843)\tPrec@1 48.000 (46.111)\n",
            "Test: [90/100]\tTime 0.046 (0.038)\tLoss 1.2026 (1.1824)\tPrec@1 52.000 (46.297)\n",
            "val Results: Prec@1 46.410 Loss 1.17916\n",
            "Best Prec@1: 46.440\n",
            "\n",
            "Epoch: [16][0/110], lr: 0.01000\tTime 0.614 (0.614)\tData 0.393 (0.393)\tLoss 1.1583 (1.1583)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [16][10/110], lr: 0.01000\tTime 0.091 (0.131)\tData 0.000 (0.037)\tLoss 1.1310 (1.1842)\tPrec@1 46.094 (47.656)\n",
            "Epoch: [16][20/110], lr: 0.01000\tTime 0.065 (0.110)\tData 0.000 (0.020)\tLoss 1.1056 (1.1583)\tPrec@1 48.438 (48.363)\n",
            "Epoch: [16][30/110], lr: 0.01000\tTime 0.068 (0.102)\tData 0.000 (0.015)\tLoss 1.1153 (1.1650)\tPrec@1 53.906 (48.488)\n",
            "Epoch: [16][40/110], lr: 0.01000\tTime 0.123 (0.101)\tData 0.014 (0.013)\tLoss 1.2548 (1.1633)\tPrec@1 42.188 (48.780)\n",
            "Epoch: [16][50/110], lr: 0.01000\tTime 0.116 (0.103)\tData 0.012 (0.012)\tLoss 1.1404 (1.1637)\tPrec@1 48.438 (48.729)\n",
            "Epoch: [16][60/110], lr: 0.01000\tTime 0.110 (0.109)\tData 0.007 (0.011)\tLoss 1.2299 (1.1603)\tPrec@1 42.188 (48.963)\n",
            "Epoch: [16][70/110], lr: 0.01000\tTime 0.074 (0.112)\tData 0.007 (0.010)\tLoss 1.0788 (1.1572)\tPrec@1 54.688 (48.889)\n",
            "Epoch: [16][80/110], lr: 0.01000\tTime 0.087 (0.109)\tData 0.000 (0.009)\tLoss 1.1482 (1.1591)\tPrec@1 46.875 (48.563)\n",
            "Epoch: [16][90/110], lr: 0.01000\tTime 0.135 (0.107)\tData 0.000 (0.008)\tLoss 1.1250 (1.1565)\tPrec@1 48.438 (48.738)\n",
            "Epoch: [16][100/110], lr: 0.01000\tTime 0.066 (0.104)\tData 0.000 (0.008)\tLoss 1.1819 (1.1552)\tPrec@1 50.781 (48.956)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 1.0405 (1.0405)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.022 (0.059)\tLoss 1.2288 (1.1438)\tPrec@1 41.000 (48.273)\n",
            "Test: [20/100]\tTime 0.048 (0.047)\tLoss 1.2363 (1.1531)\tPrec@1 42.000 (48.000)\n",
            "Test: [30/100]\tTime 0.025 (0.041)\tLoss 1.1926 (1.1598)\tPrec@1 44.000 (47.129)\n",
            "Test: [40/100]\tTime 0.035 (0.040)\tLoss 1.1757 (1.1584)\tPrec@1 51.000 (47.829)\n",
            "Test: [50/100]\tTime 0.025 (0.038)\tLoss 1.1211 (1.1636)\tPrec@1 49.000 (47.765)\n",
            "Test: [60/100]\tTime 0.026 (0.037)\tLoss 1.2637 (1.1707)\tPrec@1 40.000 (47.262)\n",
            "Test: [70/100]\tTime 0.036 (0.037)\tLoss 1.1217 (1.1705)\tPrec@1 52.000 (47.169)\n",
            "Test: [80/100]\tTime 0.039 (0.036)\tLoss 1.1289 (1.1672)\tPrec@1 51.000 (47.432)\n",
            "Test: [90/100]\tTime 0.051 (0.036)\tLoss 1.1796 (1.1646)\tPrec@1 48.000 (47.549)\n",
            "val Results: Prec@1 47.480 Loss 1.16403\n",
            "Best Prec@1: 47.480\n",
            "\n",
            "Epoch: [17][0/110], lr: 0.01000\tTime 0.466 (0.466)\tData 0.336 (0.336)\tLoss 1.0332 (1.0332)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [17][10/110], lr: 0.01000\tTime 0.066 (0.112)\tData 0.000 (0.033)\tLoss 1.1076 (1.1401)\tPrec@1 46.875 (49.361)\n",
            "Epoch: [17][20/110], lr: 0.01000\tTime 0.070 (0.093)\tData 0.000 (0.018)\tLoss 1.1961 (1.1491)\tPrec@1 48.438 (48.512)\n",
            "Epoch: [17][30/110], lr: 0.01000\tTime 0.082 (0.087)\tData 0.000 (0.013)\tLoss 1.1553 (1.1592)\tPrec@1 44.531 (47.807)\n",
            "Epoch: [17][40/110], lr: 0.01000\tTime 0.069 (0.084)\tData 0.007 (0.010)\tLoss 1.1452 (1.1556)\tPrec@1 50.000 (47.866)\n",
            "Epoch: [17][50/110], lr: 0.01000\tTime 0.075 (0.083)\tData 0.000 (0.009)\tLoss 1.1966 (1.1534)\tPrec@1 45.312 (47.917)\n",
            "Epoch: [17][60/110], lr: 0.01000\tTime 0.076 (0.082)\tData 0.000 (0.008)\tLoss 1.0832 (1.1560)\tPrec@1 57.031 (47.823)\n",
            "Epoch: [17][70/110], lr: 0.01000\tTime 0.070 (0.081)\tData 0.006 (0.007)\tLoss 1.1383 (1.1463)\tPrec@1 50.781 (48.404)\n",
            "Epoch: [17][80/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.007)\tLoss 1.1919 (1.1478)\tPrec@1 48.438 (48.409)\n",
            "Epoch: [17][90/110], lr: 0.01000\tTime 0.063 (0.079)\tData 0.000 (0.006)\tLoss 1.2382 (1.1499)\tPrec@1 42.969 (48.317)\n",
            "Epoch: [17][100/110], lr: 0.01000\tTime 0.130 (0.081)\tData 0.002 (0.006)\tLoss 1.1314 (1.1493)\tPrec@1 46.094 (48.484)\n",
            "Test: [0/100]\tTime 0.258 (0.258)\tLoss 1.0434 (1.0434)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.066 (0.066)\tLoss 1.3744 (1.1807)\tPrec@1 34.000 (47.636)\n",
            "Test: [20/100]\tTime 0.051 (0.051)\tLoss 1.2289 (1.1748)\tPrec@1 49.000 (47.810)\n",
            "Test: [30/100]\tTime 0.023 (0.045)\tLoss 1.1486 (1.1698)\tPrec@1 51.000 (47.774)\n",
            "Test: [40/100]\tTime 0.037 (0.044)\tLoss 1.1446 (1.1659)\tPrec@1 46.000 (48.024)\n",
            "Test: [50/100]\tTime 0.024 (0.042)\tLoss 1.1267 (1.1742)\tPrec@1 52.000 (48.078)\n",
            "Test: [60/100]\tTime 0.022 (0.041)\tLoss 1.2260 (1.1774)\tPrec@1 39.000 (47.607)\n",
            "Test: [70/100]\tTime 0.053 (0.041)\tLoss 1.1626 (1.1756)\tPrec@1 49.000 (47.535)\n",
            "Test: [80/100]\tTime 0.030 (0.039)\tLoss 1.1367 (1.1707)\tPrec@1 51.000 (47.654)\n",
            "Test: [90/100]\tTime 0.046 (0.039)\tLoss 1.1694 (1.1687)\tPrec@1 52.000 (47.857)\n",
            "val Results: Prec@1 47.880 Loss 1.16771\n",
            "Best Prec@1: 47.880\n",
            "\n",
            "Epoch: [18][0/110], lr: 0.01000\tTime 0.411 (0.411)\tData 0.267 (0.267)\tLoss 1.0558 (1.0558)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [18][10/110], lr: 0.01000\tTime 0.081 (0.115)\tData 0.000 (0.027)\tLoss 1.0843 (1.1218)\tPrec@1 52.344 (48.935)\n",
            "Epoch: [18][20/110], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.016)\tLoss 1.2815 (1.1332)\tPrec@1 45.312 (49.033)\n",
            "Epoch: [18][30/110], lr: 0.01000\tTime 0.079 (0.087)\tData 0.007 (0.012)\tLoss 1.1254 (1.1370)\tPrec@1 51.562 (48.891)\n",
            "Epoch: [18][40/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.009)\tLoss 1.0361 (1.1352)\tPrec@1 57.812 (49.028)\n",
            "Epoch: [18][50/110], lr: 0.01000\tTime 0.072 (0.081)\tData 0.000 (0.008)\tLoss 1.0497 (1.1306)\tPrec@1 52.344 (49.449)\n",
            "Epoch: [18][60/110], lr: 0.01000\tTime 0.069 (0.080)\tData 0.007 (0.007)\tLoss 1.1443 (1.1361)\tPrec@1 52.344 (49.232)\n",
            "Epoch: [18][70/110], lr: 0.01000\tTime 0.062 (0.079)\tData 0.000 (0.006)\tLoss 1.1329 (1.1336)\tPrec@1 50.000 (49.461)\n",
            "Epoch: [18][80/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.006)\tLoss 1.1581 (1.1335)\tPrec@1 49.219 (49.412)\n",
            "Epoch: [18][90/110], lr: 0.01000\tTime 0.075 (0.078)\tData 0.003 (0.006)\tLoss 1.1329 (1.1340)\tPrec@1 47.656 (49.425)\n",
            "Epoch: [18][100/110], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.005)\tLoss 1.1549 (1.1319)\tPrec@1 47.656 (49.629)\n",
            "Test: [0/100]\tTime 0.267 (0.267)\tLoss 1.0215 (1.0215)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.031 (0.065)\tLoss 1.1748 (1.1305)\tPrec@1 46.000 (48.909)\n",
            "Test: [20/100]\tTime 0.034 (0.051)\tLoss 1.1594 (1.1382)\tPrec@1 39.000 (48.524)\n",
            "Test: [30/100]\tTime 0.034 (0.045)\tLoss 1.1384 (1.1447)\tPrec@1 49.000 (48.226)\n",
            "Test: [40/100]\tTime 0.022 (0.042)\tLoss 1.1074 (1.1397)\tPrec@1 53.000 (48.512)\n",
            "Test: [50/100]\tTime 0.064 (0.042)\tLoss 1.1230 (1.1465)\tPrec@1 52.000 (48.216)\n",
            "Test: [60/100]\tTime 0.029 (0.041)\tLoss 1.1568 (1.1523)\tPrec@1 47.000 (47.984)\n",
            "Test: [70/100]\tTime 0.037 (0.040)\tLoss 1.1212 (1.1507)\tPrec@1 48.000 (47.859)\n",
            "Test: [80/100]\tTime 0.023 (0.040)\tLoss 1.1116 (1.1486)\tPrec@1 47.000 (47.852)\n",
            "Test: [90/100]\tTime 0.023 (0.039)\tLoss 1.1568 (1.1471)\tPrec@1 54.000 (48.165)\n",
            "val Results: Prec@1 48.220 Loss 1.14641\n",
            "Best Prec@1: 48.220\n",
            "\n",
            "Epoch: [19][0/110], lr: 0.01000\tTime 0.533 (0.533)\tData 0.339 (0.339)\tLoss 1.1184 (1.1184)\tPrec@1 47.656 (47.656)\n",
            "Epoch: [19][10/110], lr: 0.01000\tTime 0.063 (0.118)\tData 0.000 (0.034)\tLoss 1.0323 (1.1230)\tPrec@1 54.688 (49.716)\n",
            "Epoch: [19][20/110], lr: 0.01000\tTime 0.068 (0.096)\tData 0.001 (0.019)\tLoss 1.1453 (1.1382)\tPrec@1 50.781 (49.442)\n",
            "Epoch: [19][30/110], lr: 0.01000\tTime 0.073 (0.089)\tData 0.000 (0.013)\tLoss 1.0320 (1.1324)\tPrec@1 57.031 (49.471)\n",
            "Epoch: [19][40/110], lr: 0.01000\tTime 0.098 (0.085)\tData 0.000 (0.010)\tLoss 1.1004 (1.1272)\tPrec@1 46.875 (49.505)\n",
            "Epoch: [19][50/110], lr: 0.01000\tTime 0.066 (0.083)\tData 0.002 (0.009)\tLoss 1.0600 (1.1235)\tPrec@1 54.688 (49.862)\n",
            "Epoch: [19][60/110], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.008)\tLoss 1.1090 (1.1224)\tPrec@1 50.000 (50.256)\n",
            "Epoch: [19][70/110], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.007)\tLoss 1.1684 (1.1264)\tPrec@1 46.094 (49.967)\n",
            "Epoch: [19][80/110], lr: 0.01000\tTime 0.149 (0.081)\tData 0.006 (0.007)\tLoss 1.1330 (1.1272)\tPrec@1 47.656 (49.913)\n",
            "Epoch: [19][90/110], lr: 0.01000\tTime 0.119 (0.084)\tData 0.007 (0.007)\tLoss 0.9980 (1.1242)\tPrec@1 53.906 (49.991)\n",
            "Epoch: [19][100/110], lr: 0.01000\tTime 0.111 (0.087)\tData 0.007 (0.007)\tLoss 1.1976 (1.1234)\tPrec@1 42.969 (50.139)\n",
            "Test: [0/100]\tTime 0.531 (0.531)\tLoss 0.9975 (0.9975)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.040 (0.101)\tLoss 1.2168 (1.1486)\tPrec@1 37.000 (48.000)\n",
            "Test: [20/100]\tTime 0.035 (0.072)\tLoss 1.2521 (1.1521)\tPrec@1 38.000 (47.667)\n",
            "Test: [30/100]\tTime 0.025 (0.061)\tLoss 1.0832 (1.1478)\tPrec@1 53.000 (47.548)\n",
            "Test: [40/100]\tTime 0.024 (0.055)\tLoss 1.1206 (1.1433)\tPrec@1 46.000 (47.415)\n",
            "Test: [50/100]\tTime 0.032 (0.052)\tLoss 1.1148 (1.1480)\tPrec@1 53.000 (47.784)\n",
            "Test: [60/100]\tTime 0.023 (0.050)\tLoss 1.2097 (1.1535)\tPrec@1 41.000 (47.541)\n",
            "Test: [70/100]\tTime 0.025 (0.048)\tLoss 1.1301 (1.1528)\tPrec@1 50.000 (47.479)\n",
            "Test: [80/100]\tTime 0.058 (0.047)\tLoss 1.1111 (1.1483)\tPrec@1 45.000 (47.519)\n",
            "Test: [90/100]\tTime 0.063 (0.046)\tLoss 1.2034 (1.1469)\tPrec@1 48.000 (47.637)\n",
            "val Results: Prec@1 47.660 Loss 1.14473\n",
            "Best Prec@1: 48.220\n",
            "\n",
            "Epoch: [20][0/110], lr: 0.01000\tTime 0.471 (0.471)\tData 0.256 (0.256)\tLoss 1.0501 (1.0501)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [20][10/110], lr: 0.01000\tTime 0.069 (0.117)\tData 0.000 (0.026)\tLoss 1.0781 (1.0961)\tPrec@1 51.562 (51.634)\n",
            "Epoch: [20][20/110], lr: 0.01000\tTime 0.076 (0.108)\tData 0.000 (0.014)\tLoss 1.1978 (1.1069)\tPrec@1 44.531 (51.562)\n",
            "Epoch: [20][30/110], lr: 0.01000\tTime 0.120 (0.102)\tData 0.000 (0.011)\tLoss 1.1285 (1.1144)\tPrec@1 49.219 (50.630)\n",
            "Epoch: [20][40/110], lr: 0.01000\tTime 0.072 (0.097)\tData 0.000 (0.009)\tLoss 1.1661 (1.1257)\tPrec@1 46.094 (49.886)\n",
            "Epoch: [20][50/110], lr: 0.01000\tTime 0.067 (0.096)\tData 0.000 (0.007)\tLoss 1.1219 (1.1214)\tPrec@1 49.219 (49.923)\n",
            "Epoch: [20][60/110], lr: 0.01000\tTime 0.067 (0.093)\tData 0.000 (0.007)\tLoss 1.0937 (1.1167)\tPrec@1 50.000 (50.333)\n",
            "Epoch: [20][70/110], lr: 0.01000\tTime 0.072 (0.090)\tData 0.005 (0.006)\tLoss 1.1930 (1.1171)\tPrec@1 47.656 (50.121)\n",
            "Epoch: [20][80/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.006)\tLoss 1.1245 (1.1120)\tPrec@1 49.219 (50.338)\n",
            "Epoch: [20][90/110], lr: 0.01000\tTime 0.125 (0.089)\tData 0.004 (0.006)\tLoss 1.1842 (1.1122)\tPrec@1 42.188 (50.309)\n",
            "Epoch: [20][100/110], lr: 0.01000\tTime 0.079 (0.088)\tData 0.000 (0.005)\tLoss 1.1044 (1.1133)\tPrec@1 50.781 (50.255)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.9984 (0.9984)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.030 (0.068)\tLoss 1.1679 (1.1298)\tPrec@1 43.000 (48.455)\n",
            "Test: [20/100]\tTime 0.022 (0.052)\tLoss 1.2383 (1.1343)\tPrec@1 42.000 (48.476)\n",
            "Test: [30/100]\tTime 0.041 (0.047)\tLoss 1.1381 (1.1352)\tPrec@1 51.000 (48.355)\n",
            "Test: [40/100]\tTime 0.047 (0.044)\tLoss 1.0556 (1.1296)\tPrec@1 52.000 (49.024)\n",
            "Test: [50/100]\tTime 0.055 (0.043)\tLoss 1.1454 (1.1322)\tPrec@1 49.000 (49.275)\n",
            "Test: [60/100]\tTime 0.027 (0.041)\tLoss 1.2281 (1.1409)\tPrec@1 39.000 (48.721)\n",
            "Test: [70/100]\tTime 0.032 (0.040)\tLoss 1.1136 (1.1411)\tPrec@1 56.000 (48.817)\n",
            "Test: [80/100]\tTime 0.030 (0.039)\tLoss 1.0763 (1.1361)\tPrec@1 55.000 (48.852)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 1.1634 (1.1344)\tPrec@1 49.000 (48.857)\n",
            "val Results: Prec@1 48.840 Loss 1.13380\n",
            "Best Prec@1: 48.840\n",
            "\n",
            "Epoch: [21][0/110], lr: 0.01000\tTime 0.522 (0.522)\tData 0.258 (0.258)\tLoss 1.0836 (1.0836)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [21][10/110], lr: 0.01000\tTime 0.106 (0.116)\tData 0.008 (0.024)\tLoss 1.1084 (1.1015)\tPrec@1 53.906 (50.923)\n",
            "Epoch: [21][20/110], lr: 0.01000\tTime 0.079 (0.094)\tData 0.007 (0.015)\tLoss 1.0443 (1.0989)\tPrec@1 50.000 (50.521)\n",
            "Epoch: [21][30/110], lr: 0.01000\tTime 0.060 (0.087)\tData 0.000 (0.011)\tLoss 1.0471 (1.1070)\tPrec@1 51.562 (50.378)\n",
            "Epoch: [21][40/110], lr: 0.01000\tTime 0.077 (0.083)\tData 0.008 (0.010)\tLoss 1.0438 (1.1114)\tPrec@1 56.250 (50.267)\n",
            "Epoch: [21][50/110], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.008)\tLoss 1.1160 (1.1109)\tPrec@1 49.219 (50.368)\n",
            "Epoch: [21][60/110], lr: 0.01000\tTime 0.076 (0.080)\tData 0.006 (0.007)\tLoss 1.1380 (1.1065)\tPrec@1 49.219 (50.551)\n",
            "Epoch: [21][70/110], lr: 0.01000\tTime 0.069 (0.081)\tData 0.000 (0.007)\tLoss 1.1242 (1.1040)\tPrec@1 54.688 (50.737)\n",
            "Epoch: [21][80/110], lr: 0.01000\tTime 0.092 (0.082)\tData 0.000 (0.006)\tLoss 1.2640 (1.1042)\tPrec@1 43.750 (50.637)\n",
            "Epoch: [21][90/110], lr: 0.01000\tTime 0.088 (0.082)\tData 0.010 (0.006)\tLoss 1.0521 (1.1043)\tPrec@1 55.469 (50.610)\n",
            "Epoch: [21][100/110], lr: 0.01000\tTime 0.094 (0.082)\tData 0.000 (0.006)\tLoss 1.0254 (1.1025)\tPrec@1 57.031 (50.874)\n",
            "Test: [0/100]\tTime 0.258 (0.258)\tLoss 0.9445 (0.9445)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.025 (0.066)\tLoss 1.2118 (1.1269)\tPrec@1 48.000 (49.273)\n",
            "Test: [20/100]\tTime 0.024 (0.050)\tLoss 1.1881 (1.1243)\tPrec@1 40.000 (49.333)\n",
            "Test: [30/100]\tTime 0.023 (0.044)\tLoss 1.0655 (1.1191)\tPrec@1 54.000 (49.452)\n",
            "Test: [40/100]\tTime 0.029 (0.041)\tLoss 1.0578 (1.1166)\tPrec@1 51.000 (50.146)\n",
            "Test: [50/100]\tTime 0.025 (0.039)\tLoss 1.1580 (1.1206)\tPrec@1 51.000 (50.137)\n",
            "Test: [60/100]\tTime 0.030 (0.038)\tLoss 1.1959 (1.1254)\tPrec@1 42.000 (49.754)\n",
            "Test: [70/100]\tTime 0.053 (0.037)\tLoss 1.0813 (1.1247)\tPrec@1 57.000 (49.901)\n",
            "Test: [80/100]\tTime 0.095 (0.037)\tLoss 1.0503 (1.1246)\tPrec@1 60.000 (49.951)\n",
            "Test: [90/100]\tTime 0.064 (0.038)\tLoss 1.1441 (1.1240)\tPrec@1 53.000 (49.868)\n",
            "val Results: Prec@1 49.840 Loss 1.12156\n",
            "Best Prec@1: 49.840\n",
            "\n",
            "Epoch: [22][0/110], lr: 0.01000\tTime 0.455 (0.455)\tData 0.270 (0.270)\tLoss 0.9991 (0.9991)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [22][10/110], lr: 0.01000\tTime 0.062 (0.110)\tData 0.000 (0.027)\tLoss 1.0366 (1.0886)\tPrec@1 61.719 (52.699)\n",
            "Epoch: [22][20/110], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.015)\tLoss 1.0387 (1.0787)\tPrec@1 57.031 (53.199)\n",
            "Epoch: [22][30/110], lr: 0.01000\tTime 0.071 (0.088)\tData 0.000 (0.011)\tLoss 1.0017 (1.0761)\tPrec@1 62.500 (53.478)\n",
            "Epoch: [22][40/110], lr: 0.01000\tTime 0.077 (0.085)\tData 0.000 (0.009)\tLoss 1.1139 (1.0796)\tPrec@1 53.125 (53.106)\n",
            "Epoch: [22][50/110], lr: 0.01000\tTime 0.079 (0.083)\tData 0.002 (0.008)\tLoss 1.1018 (1.0899)\tPrec@1 51.562 (52.344)\n",
            "Epoch: [22][60/110], lr: 0.01000\tTime 0.075 (0.081)\tData 0.000 (0.007)\tLoss 1.0969 (1.0905)\tPrec@1 54.688 (52.267)\n",
            "Epoch: [22][70/110], lr: 0.01000\tTime 0.076 (0.082)\tData 0.000 (0.006)\tLoss 1.0626 (1.0940)\tPrec@1 50.781 (52.025)\n",
            "Epoch: [22][80/110], lr: 0.01000\tTime 0.122 (0.083)\tData 0.006 (0.006)\tLoss 1.1396 (1.0947)\tPrec@1 52.344 (51.987)\n",
            "Epoch: [22][90/110], lr: 0.01000\tTime 0.105 (0.084)\tData 0.000 (0.006)\tLoss 1.1736 (1.0939)\tPrec@1 52.344 (52.129)\n",
            "Epoch: [22][100/110], lr: 0.01000\tTime 0.073 (0.084)\tData 0.002 (0.005)\tLoss 1.0447 (1.0954)\tPrec@1 50.781 (52.050)\n",
            "Test: [0/100]\tTime 0.570 (0.570)\tLoss 1.0566 (1.0566)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.048 (0.105)\tLoss 1.1896 (1.1290)\tPrec@1 47.000 (48.364)\n",
            "Test: [20/100]\tTime 0.027 (0.077)\tLoss 1.2436 (1.1293)\tPrec@1 40.000 (48.667)\n",
            "Test: [30/100]\tTime 0.066 (0.070)\tLoss 1.1498 (1.1337)\tPrec@1 47.000 (48.226)\n",
            "Test: [40/100]\tTime 0.042 (0.065)\tLoss 1.0657 (1.1308)\tPrec@1 53.000 (48.805)\n",
            "Test: [50/100]\tTime 0.055 (0.067)\tLoss 1.1944 (1.1336)\tPrec@1 49.000 (49.255)\n",
            "Test: [60/100]\tTime 0.076 (0.067)\tLoss 1.2102 (1.1384)\tPrec@1 45.000 (48.918)\n",
            "Test: [70/100]\tTime 0.034 (0.063)\tLoss 1.0902 (1.1397)\tPrec@1 58.000 (48.972)\n",
            "Test: [80/100]\tTime 0.038 (0.060)\tLoss 1.0470 (1.1365)\tPrec@1 57.000 (49.025)\n",
            "Test: [90/100]\tTime 0.031 (0.058)\tLoss 1.1888 (1.1357)\tPrec@1 46.000 (49.044)\n",
            "val Results: Prec@1 49.070 Loss 1.13298\n",
            "Best Prec@1: 49.840\n",
            "\n",
            "Epoch: [23][0/110], lr: 0.01000\tTime 0.515 (0.515)\tData 0.399 (0.399)\tLoss 1.1094 (1.1094)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [23][10/110], lr: 0.01000\tTime 0.068 (0.118)\tData 0.000 (0.039)\tLoss 1.1489 (1.0866)\tPrec@1 46.094 (52.699)\n",
            "Epoch: [23][20/110], lr: 0.01000\tTime 0.073 (0.098)\tData 0.000 (0.021)\tLoss 1.0381 (1.0896)\tPrec@1 54.688 (51.637)\n",
            "Epoch: [23][30/110], lr: 0.01000\tTime 0.081 (0.098)\tData 0.010 (0.015)\tLoss 0.9985 (1.0817)\tPrec@1 54.688 (52.369)\n",
            "Epoch: [23][40/110], lr: 0.01000\tTime 0.107 (0.096)\tData 0.004 (0.012)\tLoss 1.0319 (1.0823)\tPrec@1 51.562 (52.153)\n",
            "Epoch: [23][50/110], lr: 0.01000\tTime 0.075 (0.095)\tData 0.007 (0.011)\tLoss 1.0450 (1.0883)\tPrec@1 59.375 (51.900)\n",
            "Epoch: [23][60/110], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.009)\tLoss 0.9794 (1.0871)\tPrec@1 55.469 (51.998)\n",
            "Epoch: [23][70/110], lr: 0.01000\tTime 0.089 (0.092)\tData 0.000 (0.009)\tLoss 1.0582 (1.0839)\tPrec@1 54.688 (52.212)\n",
            "Epoch: [23][80/110], lr: 0.01000\tTime 0.061 (0.090)\tData 0.000 (0.008)\tLoss 1.1483 (1.0834)\tPrec@1 51.562 (52.296)\n",
            "Epoch: [23][90/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.008)\tLoss 1.0977 (1.0830)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [23][100/110], lr: 0.01000\tTime 0.078 (0.089)\tData 0.000 (0.007)\tLoss 1.0651 (1.0792)\tPrec@1 52.344 (52.529)\n",
            "Test: [0/100]\tTime 0.385 (0.385)\tLoss 1.0277 (1.0277)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.027 (0.068)\tLoss 1.2603 (1.1303)\tPrec@1 45.000 (50.091)\n",
            "Test: [20/100]\tTime 0.036 (0.054)\tLoss 1.2092 (1.1195)\tPrec@1 39.000 (49.143)\n",
            "Test: [30/100]\tTime 0.043 (0.049)\tLoss 1.1427 (1.1248)\tPrec@1 52.000 (49.129)\n",
            "Test: [40/100]\tTime 0.030 (0.046)\tLoss 1.0635 (1.1217)\tPrec@1 49.000 (49.537)\n",
            "Test: [50/100]\tTime 0.026 (0.044)\tLoss 1.1679 (1.1222)\tPrec@1 51.000 (49.863)\n",
            "Test: [60/100]\tTime 0.034 (0.043)\tLoss 1.2371 (1.1284)\tPrec@1 41.000 (49.574)\n",
            "Test: [70/100]\tTime 0.028 (0.042)\tLoss 1.0476 (1.1268)\tPrec@1 56.000 (49.817)\n",
            "Test: [80/100]\tTime 0.040 (0.041)\tLoss 1.0435 (1.1233)\tPrec@1 56.000 (49.716)\n",
            "Test: [90/100]\tTime 0.026 (0.040)\tLoss 1.1856 (1.1247)\tPrec@1 48.000 (49.615)\n",
            "val Results: Prec@1 49.600 Loss 1.12229\n",
            "Best Prec@1: 49.840\n",
            "\n",
            "Epoch: [24][0/110], lr: 0.01000\tTime 0.443 (0.443)\tData 0.246 (0.246)\tLoss 1.1079 (1.1079)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [24][10/110], lr: 0.01000\tTime 0.067 (0.110)\tData 0.001 (0.026)\tLoss 1.1017 (1.0848)\tPrec@1 55.469 (51.136)\n",
            "Epoch: [24][20/110], lr: 0.01000\tTime 0.062 (0.091)\tData 0.000 (0.014)\tLoss 1.0907 (1.0755)\tPrec@1 55.469 (52.902)\n",
            "Epoch: [24][30/110], lr: 0.01000\tTime 0.094 (0.086)\tData 0.006 (0.010)\tLoss 1.0950 (1.0821)\tPrec@1 52.344 (52.571)\n",
            "Epoch: [24][40/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.008 (0.008)\tLoss 1.1462 (1.0861)\tPrec@1 47.656 (52.058)\n",
            "Epoch: [24][50/110], lr: 0.01000\tTime 0.071 (0.081)\tData 0.001 (0.007)\tLoss 1.1239 (1.0859)\tPrec@1 55.469 (52.359)\n",
            "Epoch: [24][60/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.007)\tLoss 1.0752 (1.0799)\tPrec@1 53.906 (52.613)\n",
            "Epoch: [24][70/110], lr: 0.01000\tTime 0.073 (0.079)\tData 0.000 (0.006)\tLoss 1.1668 (1.0787)\tPrec@1 46.875 (52.773)\n",
            "Epoch: [24][80/110], lr: 0.01000\tTime 0.071 (0.080)\tData 0.001 (0.006)\tLoss 0.9443 (1.0788)\tPrec@1 60.156 (52.778)\n",
            "Epoch: [24][90/110], lr: 0.01000\tTime 0.106 (0.081)\tData 0.000 (0.005)\tLoss 1.0163 (1.0762)\tPrec@1 57.031 (52.867)\n",
            "Epoch: [24][100/110], lr: 0.01000\tTime 0.083 (0.081)\tData 0.008 (0.005)\tLoss 0.9964 (1.0752)\tPrec@1 54.688 (52.885)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 1.0355 (1.0355)\tPrec@1 49.000 (49.000)\n",
            "Test: [10/100]\tTime 0.039 (0.072)\tLoss 1.1964 (1.1465)\tPrec@1 46.000 (48.818)\n",
            "Test: [20/100]\tTime 0.071 (0.056)\tLoss 1.1977 (1.1342)\tPrec@1 38.000 (50.190)\n",
            "Test: [30/100]\tTime 0.029 (0.051)\tLoss 1.1760 (1.1426)\tPrec@1 49.000 (49.806)\n",
            "Test: [40/100]\tTime 0.028 (0.046)\tLoss 1.0619 (1.1303)\tPrec@1 57.000 (50.415)\n",
            "Test: [50/100]\tTime 0.025 (0.044)\tLoss 1.2025 (1.1320)\tPrec@1 49.000 (50.373)\n",
            "Test: [60/100]\tTime 0.023 (0.042)\tLoss 1.1192 (1.1367)\tPrec@1 49.000 (49.967)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.0771 (1.1348)\tPrec@1 50.000 (50.014)\n",
            "Test: [80/100]\tTime 0.022 (0.040)\tLoss 1.0596 (1.1312)\tPrec@1 54.000 (50.173)\n",
            "Test: [90/100]\tTime 0.032 (0.039)\tLoss 1.1390 (1.1297)\tPrec@1 49.000 (50.099)\n",
            "val Results: Prec@1 50.090 Loss 1.12690\n",
            "Best Prec@1: 50.090\n",
            "\n",
            "Epoch: [25][0/110], lr: 0.01000\tTime 0.479 (0.479)\tData 0.294 (0.294)\tLoss 1.1519 (1.1519)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [25][10/110], lr: 0.01000\tTime 0.066 (0.115)\tData 0.000 (0.031)\tLoss 0.9717 (1.0549)\tPrec@1 58.594 (54.616)\n",
            "Epoch: [25][20/110], lr: 0.01000\tTime 0.079 (0.094)\tData 0.007 (0.017)\tLoss 1.1496 (1.0589)\tPrec@1 51.562 (53.274)\n",
            "Epoch: [25][30/110], lr: 0.01000\tTime 0.081 (0.087)\tData 0.007 (0.012)\tLoss 1.0852 (1.0663)\tPrec@1 49.219 (53.377)\n",
            "Epoch: [25][40/110], lr: 0.01000\tTime 0.077 (0.083)\tData 0.007 (0.010)\tLoss 1.1136 (1.0693)\tPrec@1 48.438 (53.049)\n",
            "Epoch: [25][50/110], lr: 0.01000\tTime 0.068 (0.081)\tData 0.005 (0.009)\tLoss 1.0902 (1.0697)\tPrec@1 50.781 (52.895)\n",
            "Epoch: [25][60/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.006 (0.008)\tLoss 1.0099 (1.0666)\tPrec@1 60.156 (52.997)\n",
            "Epoch: [25][70/110], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 1.0822 (1.0657)\tPrec@1 52.344 (53.235)\n",
            "Epoch: [25][80/110], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.007)\tLoss 1.0516 (1.0665)\tPrec@1 53.906 (53.366)\n",
            "Epoch: [25][90/110], lr: 0.01000\tTime 0.090 (0.080)\tData 0.007 (0.006)\tLoss 1.0983 (1.0657)\tPrec@1 46.875 (53.305)\n",
            "Epoch: [25][100/110], lr: 0.01000\tTime 0.071 (0.080)\tData 0.000 (0.006)\tLoss 1.0332 (1.0663)\tPrec@1 52.344 (53.264)\n",
            "Test: [0/100]\tTime 0.413 (0.413)\tLoss 0.9985 (0.9985)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.038 (0.073)\tLoss 1.1289 (1.1172)\tPrec@1 51.000 (50.273)\n",
            "Test: [20/100]\tTime 0.036 (0.059)\tLoss 1.1615 (1.1078)\tPrec@1 44.000 (50.619)\n",
            "Test: [30/100]\tTime 0.060 (0.053)\tLoss 1.1404 (1.1132)\tPrec@1 49.000 (50.097)\n",
            "Test: [40/100]\tTime 0.082 (0.053)\tLoss 1.0932 (1.1094)\tPrec@1 49.000 (50.390)\n",
            "Test: [50/100]\tTime 0.063 (0.052)\tLoss 1.1388 (1.1096)\tPrec@1 47.000 (50.392)\n",
            "Test: [60/100]\tTime 0.067 (0.052)\tLoss 1.1241 (1.1133)\tPrec@1 49.000 (50.246)\n",
            "Test: [70/100]\tTime 0.056 (0.053)\tLoss 1.0659 (1.1136)\tPrec@1 53.000 (50.324)\n",
            "Test: [80/100]\tTime 0.051 (0.056)\tLoss 1.0671 (1.1129)\tPrec@1 53.000 (50.235)\n",
            "Test: [90/100]\tTime 0.093 (0.057)\tLoss 1.0852 (1.1114)\tPrec@1 57.000 (50.396)\n",
            "val Results: Prec@1 50.530 Loss 1.10954\n",
            "Best Prec@1: 50.530\n",
            "\n",
            "Epoch: [26][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.341 (0.341)\tLoss 1.0613 (1.0613)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [26][10/110], lr: 0.01000\tTime 0.068 (0.116)\tData 0.000 (0.032)\tLoss 1.1936 (1.0805)\tPrec@1 49.219 (53.622)\n",
            "Epoch: [26][20/110], lr: 0.01000\tTime 0.067 (0.095)\tData 0.000 (0.018)\tLoss 1.0620 (1.0588)\tPrec@1 54.688 (53.460)\n",
            "Epoch: [26][30/110], lr: 0.01000\tTime 0.073 (0.089)\tData 0.000 (0.013)\tLoss 0.9600 (1.0570)\tPrec@1 53.906 (53.604)\n",
            "Epoch: [26][40/110], lr: 0.01000\tTime 0.070 (0.086)\tData 0.000 (0.010)\tLoss 1.0867 (1.0571)\tPrec@1 51.562 (53.563)\n",
            "Epoch: [26][50/110], lr: 0.01000\tTime 0.077 (0.083)\tData 0.000 (0.008)\tLoss 1.0888 (1.0571)\tPrec@1 52.344 (53.523)\n",
            "Epoch: [26][60/110], lr: 0.01000\tTime 0.112 (0.083)\tData 0.000 (0.007)\tLoss 0.9987 (1.0554)\tPrec@1 56.250 (53.471)\n",
            "Epoch: [26][70/110], lr: 0.01000\tTime 0.060 (0.084)\tData 0.000 (0.007)\tLoss 1.1382 (1.0530)\tPrec@1 50.000 (53.609)\n",
            "Epoch: [26][80/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.006)\tLoss 1.0797 (1.0530)\tPrec@1 53.125 (53.733)\n",
            "Epoch: [26][90/110], lr: 0.01000\tTime 0.071 (0.084)\tData 0.000 (0.006)\tLoss 0.9740 (1.0523)\tPrec@1 53.906 (53.657)\n",
            "Epoch: [26][100/110], lr: 0.01000\tTime 0.086 (0.085)\tData 0.000 (0.005)\tLoss 1.0694 (1.0533)\tPrec@1 50.781 (53.504)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 1.0915 (1.0915)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.022 (0.057)\tLoss 1.1488 (1.1273)\tPrec@1 50.000 (50.364)\n",
            "Test: [20/100]\tTime 0.030 (0.046)\tLoss 1.1949 (1.1140)\tPrec@1 43.000 (50.238)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.1836 (1.1174)\tPrec@1 46.000 (50.032)\n",
            "Test: [40/100]\tTime 0.044 (0.040)\tLoss 1.0998 (1.1084)\tPrec@1 53.000 (51.073)\n",
            "Test: [50/100]\tTime 0.023 (0.041)\tLoss 1.1102 (1.1074)\tPrec@1 53.000 (51.294)\n",
            "Test: [60/100]\tTime 0.045 (0.040)\tLoss 1.1788 (1.1127)\tPrec@1 50.000 (51.213)\n",
            "Test: [70/100]\tTime 0.025 (0.039)\tLoss 1.0416 (1.1132)\tPrec@1 53.000 (50.972)\n",
            "Test: [80/100]\tTime 0.052 (0.039)\tLoss 1.0768 (1.1102)\tPrec@1 53.000 (50.914)\n",
            "Test: [90/100]\tTime 0.024 (0.039)\tLoss 1.1677 (1.1081)\tPrec@1 50.000 (50.912)\n",
            "val Results: Prec@1 50.740 Loss 1.10796\n",
            "Best Prec@1: 50.740\n",
            "\n",
            "Epoch: [27][0/110], lr: 0.01000\tTime 0.499 (0.499)\tData 0.301 (0.301)\tLoss 1.1307 (1.1307)\tPrec@1 45.312 (45.312)\n",
            "Epoch: [27][10/110], lr: 0.01000\tTime 0.066 (0.116)\tData 0.001 (0.030)\tLoss 0.9760 (1.0477)\tPrec@1 57.812 (54.972)\n",
            "Epoch: [27][20/110], lr: 0.01000\tTime 0.065 (0.097)\tData 0.000 (0.017)\tLoss 1.0774 (1.0452)\tPrec@1 51.562 (55.060)\n",
            "Epoch: [27][30/110], lr: 0.01000\tTime 0.085 (0.089)\tData 0.000 (0.012)\tLoss 1.1376 (1.0509)\tPrec@1 44.531 (54.385)\n",
            "Epoch: [27][40/110], lr: 0.01000\tTime 0.063 (0.084)\tData 0.000 (0.009)\tLoss 1.0735 (1.0535)\tPrec@1 48.438 (54.059)\n",
            "Epoch: [27][50/110], lr: 0.01000\tTime 0.068 (0.082)\tData 0.003 (0.008)\tLoss 1.0210 (1.0533)\tPrec@1 57.031 (53.753)\n",
            "Epoch: [27][60/110], lr: 0.01000\tTime 0.083 (0.081)\tData 0.006 (0.007)\tLoss 1.1492 (1.0541)\tPrec@1 49.219 (53.689)\n",
            "Epoch: [27][70/110], lr: 0.01000\tTime 0.060 (0.081)\tData 0.000 (0.006)\tLoss 0.9989 (1.0508)\tPrec@1 53.906 (54.016)\n",
            "Epoch: [27][80/110], lr: 0.01000\tTime 0.105 (0.082)\tData 0.000 (0.006)\tLoss 1.1057 (1.0487)\tPrec@1 57.031 (54.109)\n",
            "Epoch: [27][90/110], lr: 0.01000\tTime 0.115 (0.083)\tData 0.009 (0.006)\tLoss 0.9432 (1.0457)\tPrec@1 60.156 (54.129)\n",
            "Epoch: [27][100/110], lr: 0.01000\tTime 0.084 (0.082)\tData 0.006 (0.005)\tLoss 0.9269 (1.0446)\tPrec@1 61.719 (54.401)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 1.0514 (1.0514)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.036 (0.069)\tLoss 1.1289 (1.1028)\tPrec@1 54.000 (50.182)\n",
            "Test: [20/100]\tTime 0.038 (0.053)\tLoss 1.1900 (1.0954)\tPrec@1 45.000 (51.524)\n",
            "Test: [30/100]\tTime 0.031 (0.046)\tLoss 1.1014 (1.1087)\tPrec@1 51.000 (51.097)\n",
            "Test: [40/100]\tTime 0.022 (0.042)\tLoss 1.0718 (1.1007)\tPrec@1 57.000 (51.317)\n",
            "Test: [50/100]\tTime 0.025 (0.041)\tLoss 1.1111 (1.1029)\tPrec@1 54.000 (51.510)\n",
            "Test: [60/100]\tTime 0.039 (0.039)\tLoss 1.1583 (1.1116)\tPrec@1 47.000 (51.000)\n",
            "Test: [70/100]\tTime 0.022 (0.038)\tLoss 1.0583 (1.1128)\tPrec@1 52.000 (50.761)\n",
            "Test: [80/100]\tTime 0.056 (0.038)\tLoss 1.0269 (1.1135)\tPrec@1 59.000 (50.630)\n",
            "Test: [90/100]\tTime 0.031 (0.038)\tLoss 1.1758 (1.1127)\tPrec@1 48.000 (50.648)\n",
            "val Results: Prec@1 50.710 Loss 1.11105\n",
            "Best Prec@1: 50.740\n",
            "\n",
            "Epoch: [28][0/110], lr: 0.01000\tTime 0.542 (0.542)\tData 0.288 (0.288)\tLoss 1.0804 (1.0804)\tPrec@1 47.656 (47.656)\n",
            "Epoch: [28][10/110], lr: 0.01000\tTime 0.087 (0.134)\tData 0.012 (0.030)\tLoss 1.0175 (1.0630)\tPrec@1 60.156 (53.196)\n",
            "Epoch: [28][20/110], lr: 0.01000\tTime 0.066 (0.111)\tData 0.000 (0.017)\tLoss 0.9011 (1.0568)\tPrec@1 63.281 (53.795)\n",
            "Epoch: [28][30/110], lr: 0.01000\tTime 0.071 (0.101)\tData 0.003 (0.012)\tLoss 1.0689 (1.0520)\tPrec@1 55.469 (54.083)\n",
            "Epoch: [28][40/110], lr: 0.01000\tTime 0.068 (0.094)\tData 0.002 (0.010)\tLoss 1.2403 (1.0473)\tPrec@1 42.188 (54.040)\n",
            "Epoch: [28][50/110], lr: 0.01000\tTime 0.063 (0.091)\tData 0.000 (0.008)\tLoss 1.0251 (1.0449)\tPrec@1 55.469 (54.059)\n",
            "Epoch: [28][60/110], lr: 0.01000\tTime 0.132 (0.091)\tData 0.001 (0.007)\tLoss 1.0469 (1.0424)\tPrec@1 50.000 (54.086)\n",
            "Epoch: [28][70/110], lr: 0.01000\tTime 0.068 (0.089)\tData 0.000 (0.007)\tLoss 1.1066 (1.0345)\tPrec@1 56.250 (54.445)\n",
            "Epoch: [28][80/110], lr: 0.01000\tTime 0.095 (0.089)\tData 0.008 (0.006)\tLoss 1.1379 (1.0395)\tPrec@1 50.781 (54.157)\n",
            "Epoch: [28][90/110], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.006)\tLoss 1.0357 (1.0392)\tPrec@1 55.469 (54.447)\n",
            "Epoch: [28][100/110], lr: 0.01000\tTime 0.078 (0.089)\tData 0.000 (0.006)\tLoss 1.0634 (1.0411)\tPrec@1 51.562 (54.394)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 1.0596 (1.0596)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.048 (0.058)\tLoss 1.1982 (1.1296)\tPrec@1 50.000 (50.636)\n",
            "Test: [20/100]\tTime 0.023 (0.045)\tLoss 1.2338 (1.1202)\tPrec@1 43.000 (50.571)\n",
            "Test: [30/100]\tTime 0.025 (0.043)\tLoss 1.1034 (1.1215)\tPrec@1 49.000 (50.194)\n",
            "Test: [40/100]\tTime 0.042 (0.044)\tLoss 1.0283 (1.1151)\tPrec@1 53.000 (50.244)\n",
            "Test: [50/100]\tTime 0.027 (0.043)\tLoss 1.0937 (1.1160)\tPrec@1 54.000 (50.314)\n",
            "Test: [60/100]\tTime 0.085 (0.042)\tLoss 1.1601 (1.1201)\tPrec@1 49.000 (50.098)\n",
            "Test: [70/100]\tTime 0.144 (0.046)\tLoss 1.1143 (1.1195)\tPrec@1 53.000 (50.014)\n",
            "Test: [80/100]\tTime 0.122 (0.048)\tLoss 1.0424 (1.1189)\tPrec@1 58.000 (50.086)\n",
            "Test: [90/100]\tTime 0.076 (0.050)\tLoss 1.1327 (1.1177)\tPrec@1 49.000 (50.044)\n",
            "val Results: Prec@1 50.190 Loss 1.11460\n",
            "Best Prec@1: 50.740\n",
            "\n",
            "Epoch: [29][0/110], lr: 0.01000\tTime 0.738 (0.738)\tData 0.489 (0.489)\tLoss 1.0172 (1.0172)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [29][10/110], lr: 0.01000\tTime 0.071 (0.145)\tData 0.000 (0.047)\tLoss 1.0637 (1.1020)\tPrec@1 49.219 (51.705)\n",
            "Epoch: [29][20/110], lr: 0.01000\tTime 0.080 (0.112)\tData 0.007 (0.026)\tLoss 0.9455 (1.0675)\tPrec@1 56.250 (52.939)\n",
            "Epoch: [29][30/110], lr: 0.01000\tTime 0.064 (0.100)\tData 0.000 (0.019)\tLoss 0.9565 (1.0612)\tPrec@1 58.594 (53.377)\n",
            "Epoch: [29][40/110], lr: 0.01000\tTime 0.078 (0.093)\tData 0.011 (0.015)\tLoss 0.9696 (1.0499)\tPrec@1 59.375 (53.982)\n",
            "Epoch: [29][50/110], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.013)\tLoss 0.9849 (1.0405)\tPrec@1 56.250 (54.626)\n",
            "Epoch: [29][60/110], lr: 0.01000\tTime 0.094 (0.087)\tData 0.000 (0.011)\tLoss 1.0362 (1.0437)\tPrec@1 55.469 (54.495)\n",
            "Epoch: [29][70/110], lr: 0.01000\tTime 0.068 (0.085)\tData 0.000 (0.010)\tLoss 1.0970 (1.0438)\tPrec@1 50.781 (54.357)\n",
            "Epoch: [29][80/110], lr: 0.01000\tTime 0.081 (0.086)\tData 0.000 (0.009)\tLoss 1.0246 (1.0388)\tPrec@1 52.344 (54.552)\n",
            "Epoch: [29][90/110], lr: 0.01000\tTime 0.078 (0.085)\tData 0.000 (0.008)\tLoss 0.9329 (1.0379)\tPrec@1 58.594 (54.584)\n",
            "Epoch: [29][100/110], lr: 0.01000\tTime 0.101 (0.086)\tData 0.000 (0.007)\tLoss 1.1363 (1.0402)\tPrec@1 47.656 (54.510)\n",
            "Test: [0/100]\tTime 0.294 (0.294)\tLoss 1.0166 (1.0166)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.037 (0.067)\tLoss 1.1256 (1.1134)\tPrec@1 52.000 (49.455)\n",
            "Test: [20/100]\tTime 0.037 (0.054)\tLoss 1.2391 (1.1134)\tPrec@1 44.000 (49.190)\n",
            "Test: [30/100]\tTime 0.023 (0.047)\tLoss 1.1972 (1.1206)\tPrec@1 48.000 (49.419)\n",
            "Test: [40/100]\tTime 0.022 (0.045)\tLoss 1.0425 (1.1148)\tPrec@1 56.000 (50.220)\n",
            "Test: [50/100]\tTime 0.025 (0.043)\tLoss 1.1218 (1.1114)\tPrec@1 49.000 (50.686)\n",
            "Test: [60/100]\tTime 0.023 (0.041)\tLoss 1.1708 (1.1145)\tPrec@1 51.000 (50.754)\n",
            "Test: [70/100]\tTime 0.022 (0.040)\tLoss 1.1178 (1.1150)\tPrec@1 53.000 (50.972)\n",
            "Test: [80/100]\tTime 0.050 (0.039)\tLoss 1.0268 (1.1147)\tPrec@1 55.000 (50.802)\n",
            "Test: [90/100]\tTime 0.023 (0.039)\tLoss 1.1577 (1.1168)\tPrec@1 46.000 (50.637)\n",
            "val Results: Prec@1 50.750 Loss 1.11456\n",
            "Best Prec@1: 50.750\n",
            "\n",
            "Epoch: [30][0/110], lr: 0.01000\tTime 0.454 (0.454)\tData 0.278 (0.278)\tLoss 0.9681 (0.9681)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [30][10/110], lr: 0.01000\tTime 0.065 (0.110)\tData 0.000 (0.028)\tLoss 1.0823 (1.0116)\tPrec@1 47.656 (56.463)\n",
            "Epoch: [30][20/110], lr: 0.01000\tTime 0.064 (0.092)\tData 0.000 (0.017)\tLoss 1.0468 (1.0179)\tPrec@1 57.031 (56.101)\n",
            "Epoch: [30][30/110], lr: 0.01000\tTime 0.075 (0.087)\tData 0.000 (0.012)\tLoss 1.1352 (1.0281)\tPrec@1 49.219 (54.914)\n",
            "Epoch: [30][40/110], lr: 0.01000\tTime 0.075 (0.083)\tData 0.006 (0.010)\tLoss 1.0609 (1.0286)\tPrec@1 50.781 (54.630)\n",
            "Epoch: [30][50/110], lr: 0.01000\tTime 0.069 (0.081)\tData 0.000 (0.009)\tLoss 1.0546 (1.0282)\tPrec@1 53.125 (54.442)\n",
            "Epoch: [30][60/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.005 (0.008)\tLoss 0.9289 (1.0277)\tPrec@1 64.062 (54.623)\n",
            "Epoch: [30][70/110], lr: 0.01000\tTime 0.081 (0.079)\tData 0.008 (0.008)\tLoss 1.0330 (1.0250)\tPrec@1 56.250 (54.875)\n",
            "Epoch: [30][80/110], lr: 0.01000\tTime 0.071 (0.078)\tData 0.000 (0.007)\tLoss 1.0996 (1.0226)\tPrec@1 49.219 (55.083)\n",
            "Epoch: [30][90/110], lr: 0.01000\tTime 0.094 (0.079)\tData 0.005 (0.007)\tLoss 1.0495 (1.0270)\tPrec@1 54.688 (54.885)\n",
            "Epoch: [30][100/110], lr: 0.01000\tTime 0.125 (0.080)\tData 0.000 (0.006)\tLoss 1.0461 (1.0297)\tPrec@1 44.531 (54.773)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 1.0262 (1.0262)\tPrec@1 51.000 (51.000)\n",
            "Test: [10/100]\tTime 0.024 (0.063)\tLoss 1.1045 (1.0847)\tPrec@1 53.000 (51.727)\n",
            "Test: [20/100]\tTime 0.030 (0.051)\tLoss 1.2262 (1.0819)\tPrec@1 39.000 (51.762)\n",
            "Test: [30/100]\tTime 0.032 (0.047)\tLoss 1.1493 (1.0932)\tPrec@1 47.000 (51.065)\n",
            "Test: [40/100]\tTime 0.023 (0.043)\tLoss 0.9887 (1.0870)\tPrec@1 56.000 (51.537)\n",
            "Test: [50/100]\tTime 0.026 (0.043)\tLoss 1.1017 (1.0871)\tPrec@1 51.000 (51.824)\n",
            "Test: [60/100]\tTime 0.048 (0.042)\tLoss 1.2045 (1.0937)\tPrec@1 42.000 (51.656)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 1.0657 (1.0961)\tPrec@1 52.000 (51.535)\n",
            "Test: [80/100]\tTime 0.025 (0.040)\tLoss 1.0477 (1.0950)\tPrec@1 57.000 (51.605)\n",
            "Test: [90/100]\tTime 0.027 (0.039)\tLoss 1.1430 (1.0939)\tPrec@1 48.000 (51.626)\n",
            "val Results: Prec@1 51.640 Loss 1.09079\n",
            "Best Prec@1: 51.640\n",
            "\n",
            "Epoch: [31][0/110], lr: 0.01000\tTime 0.475 (0.475)\tData 0.290 (0.290)\tLoss 0.9790 (0.9790)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [31][10/110], lr: 0.01000\tTime 0.070 (0.116)\tData 0.001 (0.029)\tLoss 1.0472 (1.0206)\tPrec@1 56.250 (56.392)\n",
            "Epoch: [31][20/110], lr: 0.01000\tTime 0.086 (0.096)\tData 0.000 (0.016)\tLoss 1.0097 (1.0292)\tPrec@1 52.344 (55.134)\n",
            "Epoch: [31][30/110], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.012)\tLoss 1.0276 (1.0383)\tPrec@1 55.469 (55.166)\n",
            "Epoch: [31][40/110], lr: 0.01000\tTime 0.062 (0.085)\tData 0.000 (0.009)\tLoss 1.0126 (1.0372)\tPrec@1 57.031 (55.240)\n",
            "Epoch: [31][50/110], lr: 0.01000\tTime 0.089 (0.083)\tData 0.000 (0.008)\tLoss 0.9735 (1.0334)\tPrec@1 57.031 (55.407)\n",
            "Epoch: [31][60/110], lr: 0.01000\tTime 0.105 (0.081)\tData 0.007 (0.007)\tLoss 1.0432 (1.0291)\tPrec@1 54.688 (55.392)\n",
            "Epoch: [31][70/110], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.006)\tLoss 1.0155 (1.0301)\tPrec@1 56.250 (55.282)\n",
            "Epoch: [31][80/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.006)\tLoss 1.0516 (1.0279)\tPrec@1 50.781 (55.285)\n",
            "Epoch: [31][90/110], lr: 0.01000\tTime 0.076 (0.078)\tData 0.006 (0.006)\tLoss 0.9518 (1.0273)\tPrec@1 55.469 (55.263)\n",
            "Epoch: [31][100/110], lr: 0.01000\tTime 0.063 (0.077)\tData 0.000 (0.005)\tLoss 0.9255 (1.0257)\tPrec@1 59.375 (55.353)\n",
            "Test: [0/100]\tTime 0.304 (0.304)\tLoss 1.0225 (1.0225)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.037 (0.066)\tLoss 1.1481 (1.1056)\tPrec@1 51.000 (49.727)\n",
            "Test: [20/100]\tTime 0.032 (0.053)\tLoss 1.2099 (1.0975)\tPrec@1 44.000 (50.952)\n",
            "Test: [30/100]\tTime 0.027 (0.047)\tLoss 1.0912 (1.1083)\tPrec@1 53.000 (50.742)\n",
            "Test: [40/100]\tTime 0.024 (0.044)\tLoss 1.0382 (1.1036)\tPrec@1 55.000 (51.049)\n",
            "Test: [50/100]\tTime 0.045 (0.043)\tLoss 1.1250 (1.1035)\tPrec@1 54.000 (51.235)\n",
            "Test: [60/100]\tTime 0.024 (0.042)\tLoss 1.1870 (1.1095)\tPrec@1 45.000 (50.869)\n",
            "Test: [70/100]\tTime 0.028 (0.041)\tLoss 1.0102 (1.1098)\tPrec@1 54.000 (50.718)\n",
            "Test: [80/100]\tTime 0.023 (0.041)\tLoss 1.0933 (1.1096)\tPrec@1 51.000 (50.778)\n",
            "Test: [90/100]\tTime 0.033 (0.041)\tLoss 1.1777 (1.1074)\tPrec@1 49.000 (50.923)\n",
            "val Results: Prec@1 51.040 Loss 1.10518\n",
            "Best Prec@1: 51.640\n",
            "\n",
            "Epoch: [32][0/110], lr: 0.01000\tTime 0.522 (0.522)\tData 0.389 (0.389)\tLoss 0.9411 (0.9411)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [32][10/110], lr: 0.01000\tTime 0.082 (0.119)\tData 0.000 (0.039)\tLoss 1.0446 (1.0160)\tPrec@1 51.562 (55.043)\n",
            "Epoch: [32][20/110], lr: 0.01000\tTime 0.079 (0.096)\tData 0.007 (0.022)\tLoss 0.9348 (1.0301)\tPrec@1 61.719 (55.320)\n",
            "Epoch: [32][30/110], lr: 0.01000\tTime 0.205 (0.107)\tData 0.000 (0.016)\tLoss 0.9898 (1.0309)\tPrec@1 49.219 (54.587)\n",
            "Epoch: [32][40/110], lr: 0.01000\tTime 0.180 (0.118)\tData 0.012 (0.013)\tLoss 0.9881 (1.0270)\tPrec@1 56.250 (54.573)\n",
            "Epoch: [32][50/110], lr: 0.01000\tTime 0.079 (0.123)\tData 0.000 (0.012)\tLoss 0.9319 (1.0221)\tPrec@1 60.156 (54.810)\n",
            "Epoch: [32][60/110], lr: 0.01000\tTime 0.075 (0.116)\tData 0.000 (0.010)\tLoss 0.9895 (1.0242)\tPrec@1 56.250 (54.969)\n",
            "Epoch: [32][70/110], lr: 0.01000\tTime 0.068 (0.110)\tData 0.002 (0.009)\tLoss 1.0446 (1.0237)\tPrec@1 55.469 (55.315)\n",
            "Epoch: [32][80/110], lr: 0.01000\tTime 0.077 (0.106)\tData 0.012 (0.009)\tLoss 1.0813 (1.0227)\tPrec@1 51.562 (55.421)\n",
            "Epoch: [32][90/110], lr: 0.01000\tTime 0.090 (0.105)\tData 0.007 (0.008)\tLoss 1.0276 (1.0222)\tPrec@1 54.688 (55.546)\n",
            "Epoch: [32][100/110], lr: 0.01000\tTime 0.135 (0.104)\tData 0.000 (0.008)\tLoss 1.0413 (1.0227)\tPrec@1 53.906 (55.391)\n",
            "Test: [0/100]\tTime 0.254 (0.254)\tLoss 1.0341 (1.0341)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.025 (0.067)\tLoss 1.1404 (1.1017)\tPrec@1 51.000 (51.364)\n",
            "Test: [20/100]\tTime 0.045 (0.053)\tLoss 1.1172 (1.0853)\tPrec@1 50.000 (52.476)\n",
            "Test: [30/100]\tTime 0.040 (0.049)\tLoss 1.1011 (1.0918)\tPrec@1 53.000 (52.645)\n",
            "Test: [40/100]\tTime 0.024 (0.045)\tLoss 1.0311 (1.0865)\tPrec@1 56.000 (52.854)\n",
            "Test: [50/100]\tTime 0.022 (0.042)\tLoss 1.1236 (1.0875)\tPrec@1 49.000 (52.294)\n",
            "Test: [60/100]\tTime 0.025 (0.041)\tLoss 1.1287 (1.0935)\tPrec@1 48.000 (51.967)\n",
            "Test: [70/100]\tTime 0.034 (0.040)\tLoss 1.0830 (1.0954)\tPrec@1 52.000 (51.761)\n",
            "Test: [80/100]\tTime 0.024 (0.039)\tLoss 1.0060 (1.0952)\tPrec@1 61.000 (51.741)\n",
            "Test: [90/100]\tTime 0.036 (0.038)\tLoss 1.0960 (1.0928)\tPrec@1 51.000 (51.725)\n",
            "val Results: Prec@1 51.630 Loss 1.09080\n",
            "Best Prec@1: 51.640\n",
            "\n",
            "Epoch: [33][0/110], lr: 0.01000\tTime 0.425 (0.425)\tData 0.232 (0.232)\tLoss 1.0199 (1.0199)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [33][10/110], lr: 0.01000\tTime 0.071 (0.111)\tData 0.000 (0.023)\tLoss 1.0506 (1.0133)\tPrec@1 50.781 (56.037)\n",
            "Epoch: [33][20/110], lr: 0.01000\tTime 0.081 (0.093)\tData 0.010 (0.014)\tLoss 0.9813 (1.0128)\tPrec@1 56.250 (55.692)\n",
            "Epoch: [33][30/110], lr: 0.01000\tTime 0.062 (0.087)\tData 0.000 (0.010)\tLoss 1.0591 (1.0159)\tPrec@1 53.125 (55.393)\n",
            "Epoch: [33][40/110], lr: 0.01000\tTime 0.067 (0.083)\tData 0.000 (0.008)\tLoss 1.0795 (1.0218)\tPrec@1 46.875 (54.916)\n",
            "Epoch: [33][50/110], lr: 0.01000\tTime 0.066 (0.082)\tData 0.001 (0.007)\tLoss 1.0281 (1.0210)\tPrec@1 53.125 (54.825)\n",
            "Epoch: [33][60/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.006)\tLoss 1.0515 (1.0205)\tPrec@1 53.906 (54.790)\n",
            "Epoch: [33][70/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.009 (0.006)\tLoss 1.0006 (1.0218)\tPrec@1 57.031 (54.853)\n",
            "Epoch: [33][80/110], lr: 0.01000\tTime 0.084 (0.078)\tData 0.000 (0.006)\tLoss 1.1414 (1.0245)\tPrec@1 48.438 (54.688)\n",
            "Epoch: [33][90/110], lr: 0.01000\tTime 0.067 (0.078)\tData 0.000 (0.005)\tLoss 1.0244 (1.0219)\tPrec@1 53.125 (54.894)\n",
            "Epoch: [33][100/110], lr: 0.01000\tTime 0.082 (0.078)\tData 0.010 (0.005)\tLoss 0.9949 (1.0224)\tPrec@1 51.562 (54.827)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 0.9976 (0.9976)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.022 (0.056)\tLoss 1.0833 (1.0962)\tPrec@1 58.000 (51.636)\n",
            "Test: [20/100]\tTime 0.042 (0.045)\tLoss 1.1819 (1.0884)\tPrec@1 48.000 (52.333)\n",
            "Test: [30/100]\tTime 0.049 (0.044)\tLoss 1.1413 (1.0954)\tPrec@1 53.000 (51.806)\n",
            "Test: [40/100]\tTime 0.023 (0.043)\tLoss 1.0143 (1.0905)\tPrec@1 58.000 (52.146)\n",
            "Test: [50/100]\tTime 0.026 (0.041)\tLoss 1.1304 (1.0861)\tPrec@1 49.000 (52.569)\n",
            "Test: [60/100]\tTime 0.025 (0.041)\tLoss 1.1388 (1.0891)\tPrec@1 43.000 (52.115)\n",
            "Test: [70/100]\tTime 0.049 (0.040)\tLoss 1.0381 (1.0890)\tPrec@1 54.000 (52.099)\n",
            "Test: [80/100]\tTime 0.031 (0.040)\tLoss 1.0480 (1.0895)\tPrec@1 56.000 (51.951)\n",
            "Test: [90/100]\tTime 0.063 (0.040)\tLoss 1.1075 (1.0891)\tPrec@1 58.000 (51.978)\n",
            "val Results: Prec@1 51.930 Loss 1.08787\n",
            "Best Prec@1: 51.930\n",
            "\n",
            "Epoch: [34][0/110], lr: 0.01000\tTime 0.423 (0.423)\tData 0.232 (0.232)\tLoss 1.0876 (1.0876)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [34][10/110], lr: 0.01000\tTime 0.065 (0.113)\tData 0.003 (0.026)\tLoss 1.0122 (1.0248)\tPrec@1 56.250 (54.048)\n",
            "Epoch: [34][20/110], lr: 0.01000\tTime 0.067 (0.096)\tData 0.000 (0.015)\tLoss 0.9774 (1.0248)\tPrec@1 55.469 (54.129)\n",
            "Epoch: [34][30/110], lr: 0.01000\tTime 0.090 (0.089)\tData 0.000 (0.011)\tLoss 0.9812 (1.0219)\tPrec@1 57.812 (54.688)\n",
            "Epoch: [34][40/110], lr: 0.01000\tTime 0.061 (0.084)\tData 0.000 (0.009)\tLoss 1.0802 (1.0192)\tPrec@1 52.344 (54.554)\n",
            "Epoch: [34][50/110], lr: 0.01000\tTime 0.065 (0.082)\tData 0.000 (0.008)\tLoss 1.0499 (1.0184)\tPrec@1 53.125 (54.856)\n",
            "Epoch: [34][60/110], lr: 0.01000\tTime 0.071 (0.081)\tData 0.005 (0.007)\tLoss 0.9763 (1.0167)\tPrec@1 59.375 (55.072)\n",
            "Epoch: [34][70/110], lr: 0.01000\tTime 0.063 (0.079)\tData 0.000 (0.006)\tLoss 0.9718 (1.0141)\tPrec@1 56.250 (55.249)\n",
            "Epoch: [34][80/110], lr: 0.01000\tTime 0.069 (0.079)\tData 0.007 (0.006)\tLoss 0.9257 (1.0143)\tPrec@1 60.938 (55.363)\n",
            "Epoch: [34][90/110], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.005)\tLoss 1.0331 (1.0132)\tPrec@1 55.469 (55.503)\n",
            "Epoch: [34][100/110], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.005)\tLoss 0.9216 (1.0126)\tPrec@1 57.812 (55.569)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 1.0249 (1.0249)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.029 (0.068)\tLoss 1.1128 (1.0857)\tPrec@1 54.000 (52.909)\n",
            "Test: [20/100]\tTime 0.029 (0.054)\tLoss 1.1666 (1.0815)\tPrec@1 46.000 (53.286)\n",
            "Test: [30/100]\tTime 0.030 (0.047)\tLoss 1.0860 (1.0889)\tPrec@1 53.000 (52.581)\n",
            "Test: [40/100]\tTime 0.034 (0.045)\tLoss 1.0846 (1.0807)\tPrec@1 56.000 (52.976)\n",
            "Test: [50/100]\tTime 0.040 (0.043)\tLoss 1.1275 (1.0839)\tPrec@1 47.000 (52.765)\n",
            "Test: [60/100]\tTime 0.030 (0.041)\tLoss 1.1152 (1.0892)\tPrec@1 51.000 (52.574)\n",
            "Test: [70/100]\tTime 0.022 (0.039)\tLoss 1.0856 (1.0891)\tPrec@1 49.000 (52.465)\n",
            "Test: [80/100]\tTime 0.032 (0.039)\tLoss 1.0730 (1.0887)\tPrec@1 51.000 (52.593)\n",
            "Test: [90/100]\tTime 0.022 (0.038)\tLoss 1.1000 (1.0885)\tPrec@1 50.000 (52.538)\n",
            "val Results: Prec@1 52.600 Loss 1.08601\n",
            "Best Prec@1: 52.600\n",
            "\n",
            "Epoch: [35][0/110], lr: 0.01000\tTime 0.435 (0.435)\tData 0.237 (0.237)\tLoss 1.0047 (1.0047)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [35][10/110], lr: 0.01000\tTime 0.077 (0.113)\tData 0.012 (0.025)\tLoss 0.9316 (0.9901)\tPrec@1 60.938 (56.605)\n",
            "Epoch: [35][20/110], lr: 0.01000\tTime 0.068 (0.094)\tData 0.000 (0.014)\tLoss 0.9985 (1.0028)\tPrec@1 55.469 (55.841)\n",
            "Epoch: [35][30/110], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.010)\tLoss 0.9262 (0.9972)\tPrec@1 58.594 (56.426)\n",
            "Epoch: [35][40/110], lr: 0.01000\tTime 0.066 (0.083)\tData 0.000 (0.008)\tLoss 1.0082 (1.0020)\tPrec@1 53.906 (56.421)\n",
            "Epoch: [35][50/110], lr: 0.01000\tTime 0.123 (0.084)\tData 0.000 (0.006)\tLoss 1.1016 (1.0139)\tPrec@1 46.094 (55.944)\n",
            "Epoch: [35][60/110], lr: 0.01000\tTime 0.089 (0.089)\tData 0.000 (0.006)\tLoss 1.0783 (1.0132)\tPrec@1 48.438 (55.840)\n",
            "Epoch: [35][70/110], lr: 0.01000\tTime 0.100 (0.096)\tData 0.007 (0.007)\tLoss 1.1028 (1.0159)\tPrec@1 49.219 (55.579)\n",
            "Epoch: [35][80/110], lr: 0.01000\tTime 0.129 (0.101)\tData 0.001 (0.006)\tLoss 0.9696 (1.0142)\tPrec@1 60.156 (55.777)\n",
            "Epoch: [35][90/110], lr: 0.01000\tTime 0.085 (0.099)\tData 0.007 (0.006)\tLoss 0.9850 (1.0147)\tPrec@1 53.906 (55.701)\n",
            "Epoch: [35][100/110], lr: 0.01000\tTime 0.088 (0.098)\tData 0.000 (0.005)\tLoss 0.9985 (1.0180)\tPrec@1 57.031 (55.585)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 0.9922 (0.9922)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.041 (0.058)\tLoss 1.0883 (1.0697)\tPrec@1 55.000 (53.182)\n",
            "Test: [20/100]\tTime 0.023 (0.046)\tLoss 1.1822 (1.0604)\tPrec@1 49.000 (54.048)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 1.0792 (1.0699)\tPrec@1 52.000 (53.097)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9929 (1.0650)\tPrec@1 63.000 (53.390)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 1.0828 (1.0633)\tPrec@1 51.000 (53.529)\n",
            "Test: [60/100]\tTime 0.026 (0.037)\tLoss 1.1300 (1.0689)\tPrec@1 52.000 (53.377)\n",
            "Test: [70/100]\tTime 0.042 (0.036)\tLoss 1.0491 (1.0699)\tPrec@1 53.000 (53.183)\n",
            "Test: [80/100]\tTime 0.022 (0.036)\tLoss 0.9954 (1.0686)\tPrec@1 58.000 (53.420)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 1.0875 (1.0681)\tPrec@1 55.000 (53.396)\n",
            "val Results: Prec@1 53.500 Loss 1.06463\n",
            "Best Prec@1: 53.500\n",
            "\n",
            "Epoch: [36][0/110], lr: 0.01000\tTime 0.482 (0.482)\tData 0.343 (0.343)\tLoss 0.9879 (0.9879)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [36][10/110], lr: 0.01000\tTime 0.080 (0.115)\tData 0.007 (0.034)\tLoss 1.0401 (1.0184)\tPrec@1 57.031 (54.545)\n",
            "Epoch: [36][20/110], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.019)\tLoss 1.0165 (1.0189)\tPrec@1 55.469 (54.650)\n",
            "Epoch: [36][30/110], lr: 0.01000\tTime 0.062 (0.087)\tData 0.000 (0.013)\tLoss 1.0233 (1.0175)\tPrec@1 59.375 (54.889)\n",
            "Epoch: [36][40/110], lr: 0.01000\tTime 0.066 (0.084)\tData 0.000 (0.011)\tLoss 0.9938 (1.0152)\tPrec@1 55.469 (55.297)\n",
            "Epoch: [36][50/110], lr: 0.01000\tTime 0.073 (0.081)\tData 0.000 (0.009)\tLoss 1.0004 (1.0124)\tPrec@1 60.156 (55.653)\n",
            "Epoch: [36][60/110], lr: 0.01000\tTime 0.096 (0.080)\tData 0.006 (0.008)\tLoss 0.9757 (1.0158)\tPrec@1 57.812 (55.366)\n",
            "Epoch: [36][70/110], lr: 0.01000\tTime 0.077 (0.079)\tData 0.005 (0.007)\tLoss 1.0292 (1.0121)\tPrec@1 52.344 (55.458)\n",
            "Epoch: [36][80/110], lr: 0.01000\tTime 0.073 (0.078)\tData 0.007 (0.006)\tLoss 1.1307 (1.0108)\tPrec@1 51.562 (55.681)\n",
            "Epoch: [36][90/110], lr: 0.01000\tTime 0.084 (0.078)\tData 0.007 (0.006)\tLoss 1.0271 (1.0109)\tPrec@1 49.219 (55.726)\n",
            "Epoch: [36][100/110], lr: 0.01000\tTime 0.060 (0.077)\tData 0.000 (0.006)\tLoss 0.9599 (1.0081)\tPrec@1 63.281 (55.894)\n",
            "Test: [0/100]\tTime 0.227 (0.227)\tLoss 1.0475 (1.0475)\tPrec@1 52.000 (52.000)\n",
            "Test: [10/100]\tTime 0.039 (0.058)\tLoss 1.0812 (1.0843)\tPrec@1 56.000 (51.909)\n",
            "Test: [20/100]\tTime 0.025 (0.044)\tLoss 1.1572 (1.0800)\tPrec@1 45.000 (52.429)\n",
            "Test: [30/100]\tTime 0.032 (0.040)\tLoss 1.0616 (1.0838)\tPrec@1 47.000 (52.000)\n",
            "Test: [40/100]\tTime 0.036 (0.038)\tLoss 1.0157 (1.0800)\tPrec@1 57.000 (52.829)\n",
            "Test: [50/100]\tTime 0.025 (0.037)\tLoss 1.0972 (1.0796)\tPrec@1 48.000 (52.765)\n",
            "Test: [60/100]\tTime 0.032 (0.036)\tLoss 1.1213 (1.0846)\tPrec@1 54.000 (52.508)\n",
            "Test: [70/100]\tTime 0.043 (0.035)\tLoss 1.0232 (1.0851)\tPrec@1 55.000 (52.620)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 1.0222 (1.0833)\tPrec@1 57.000 (52.469)\n",
            "Test: [90/100]\tTime 0.021 (0.035)\tLoss 1.0958 (1.0828)\tPrec@1 49.000 (52.341)\n",
            "val Results: Prec@1 52.550 Loss 1.07952\n",
            "Best Prec@1: 53.500\n",
            "\n",
            "Epoch: [37][0/110], lr: 0.01000\tTime 0.492 (0.492)\tData 0.351 (0.351)\tLoss 0.9572 (0.9572)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [37][10/110], lr: 0.01000\tTime 0.066 (0.112)\tData 0.000 (0.034)\tLoss 0.9227 (1.0057)\tPrec@1 59.375 (56.250)\n",
            "Epoch: [37][20/110], lr: 0.01000\tTime 0.072 (0.092)\tData 0.000 (0.019)\tLoss 0.9709 (0.9928)\tPrec@1 58.594 (57.068)\n",
            "Epoch: [37][30/110], lr: 0.01000\tTime 0.077 (0.086)\tData 0.001 (0.013)\tLoss 1.0694 (0.9891)\tPrec@1 46.875 (56.830)\n",
            "Epoch: [37][40/110], lr: 0.01000\tTime 0.090 (0.085)\tData 0.008 (0.011)\tLoss 1.0064 (0.9935)\tPrec@1 58.594 (56.841)\n",
            "Epoch: [37][50/110], lr: 0.01000\tTime 0.069 (0.082)\tData 0.000 (0.009)\tLoss 0.9058 (0.9934)\tPrec@1 64.062 (56.893)\n",
            "Epoch: [37][60/110], lr: 0.01000\tTime 0.076 (0.081)\tData 0.007 (0.008)\tLoss 1.1055 (0.9992)\tPrec@1 50.781 (56.852)\n",
            "Epoch: [37][70/110], lr: 0.01000\tTime 0.073 (0.080)\tData 0.007 (0.008)\tLoss 1.0480 (1.0063)\tPrec@1 55.469 (56.481)\n",
            "Epoch: [37][80/110], lr: 0.01000\tTime 0.073 (0.079)\tData 0.007 (0.007)\tLoss 0.9573 (1.0025)\tPrec@1 57.031 (56.790)\n",
            "Epoch: [37][90/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.003 (0.007)\tLoss 1.0254 (1.0041)\tPrec@1 52.344 (56.533)\n",
            "Epoch: [37][100/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.006)\tLoss 1.0083 (1.0016)\tPrec@1 52.344 (56.451)\n",
            "Test: [0/100]\tTime 0.285 (0.285)\tLoss 1.0352 (1.0352)\tPrec@1 53.000 (53.000)\n",
            "Test: [10/100]\tTime 0.045 (0.055)\tLoss 1.1419 (1.1197)\tPrec@1 54.000 (52.091)\n",
            "Test: [20/100]\tTime 0.027 (0.044)\tLoss 1.2043 (1.1149)\tPrec@1 48.000 (52.476)\n",
            "Test: [30/100]\tTime 0.023 (0.040)\tLoss 1.0519 (1.1204)\tPrec@1 52.000 (51.839)\n",
            "Test: [40/100]\tTime 0.035 (0.038)\tLoss 1.0327 (1.1191)\tPrec@1 54.000 (51.829)\n",
            "Test: [50/100]\tTime 0.026 (0.037)\tLoss 1.1313 (1.1228)\tPrec@1 52.000 (52.078)\n",
            "Test: [60/100]\tTime 0.026 (0.036)\tLoss 1.2229 (1.1254)\tPrec@1 45.000 (51.852)\n",
            "Test: [70/100]\tTime 0.029 (0.035)\tLoss 1.0940 (1.1261)\tPrec@1 50.000 (51.704)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 1.0403 (1.1252)\tPrec@1 57.000 (51.605)\n",
            "Test: [90/100]\tTime 0.038 (0.034)\tLoss 1.1508 (1.1244)\tPrec@1 51.000 (51.725)\n",
            "val Results: Prec@1 51.830 Loss 1.12065\n",
            "Best Prec@1: 53.500\n",
            "\n",
            "Epoch: [38][0/110], lr: 0.01000\tTime 0.506 (0.506)\tData 0.368 (0.368)\tLoss 1.0807 (1.0807)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [38][10/110], lr: 0.01000\tTime 0.070 (0.112)\tData 0.007 (0.036)\tLoss 1.0297 (1.0332)\tPrec@1 55.469 (54.048)\n",
            "Epoch: [38][20/110], lr: 0.01000\tTime 0.066 (0.094)\tData 0.000 (0.020)\tLoss 1.0460 (1.0272)\tPrec@1 53.906 (54.725)\n",
            "Epoch: [38][30/110], lr: 0.01000\tTime 0.067 (0.087)\tData 0.001 (0.014)\tLoss 1.0136 (1.0141)\tPrec@1 50.781 (55.318)\n",
            "Epoch: [38][40/110], lr: 0.01000\tTime 0.071 (0.084)\tData 0.005 (0.012)\tLoss 1.0835 (1.0120)\tPrec@1 54.688 (55.621)\n",
            "Epoch: [38][50/110], lr: 0.01000\tTime 0.072 (0.082)\tData 0.002 (0.011)\tLoss 0.9629 (1.0078)\tPrec@1 59.375 (55.836)\n",
            "Epoch: [38][60/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.004 (0.010)\tLoss 1.0427 (1.0023)\tPrec@1 57.031 (56.288)\n",
            "Epoch: [38][70/110], lr: 0.01000\tTime 0.078 (0.079)\tData 0.005 (0.009)\tLoss 1.0681 (1.0026)\tPrec@1 53.125 (56.217)\n",
            "Epoch: [38][80/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.007 (0.008)\tLoss 1.0364 (1.0017)\tPrec@1 54.688 (56.346)\n",
            "Epoch: [38][90/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.007)\tLoss 1.0177 (0.9999)\tPrec@1 50.781 (56.499)\n",
            "Epoch: [38][100/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.003 (0.007)\tLoss 1.0609 (1.0028)\tPrec@1 56.250 (56.343)\n",
            "Test: [0/100]\tTime 0.322 (0.322)\tLoss 1.0035 (1.0035)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.033 (0.067)\tLoss 1.0659 (1.0555)\tPrec@1 53.000 (53.727)\n",
            "Test: [20/100]\tTime 0.044 (0.053)\tLoss 1.1863 (1.0506)\tPrec@1 47.000 (53.905)\n",
            "Test: [30/100]\tTime 0.020 (0.048)\tLoss 1.1278 (1.0661)\tPrec@1 51.000 (53.226)\n",
            "Test: [40/100]\tTime 0.025 (0.051)\tLoss 0.9862 (1.0621)\tPrec@1 58.000 (53.317)\n",
            "Test: [50/100]\tTime 0.057 (0.054)\tLoss 1.0917 (1.0657)\tPrec@1 50.000 (53.392)\n",
            "Test: [60/100]\tTime 0.039 (0.056)\tLoss 1.1316 (1.0685)\tPrec@1 48.000 (53.279)\n",
            "Test: [70/100]\tTime 0.052 (0.057)\tLoss 1.0580 (1.0686)\tPrec@1 54.000 (53.141)\n",
            "Test: [80/100]\tTime 0.047 (0.058)\tLoss 1.0338 (1.0697)\tPrec@1 58.000 (53.025)\n",
            "Test: [90/100]\tTime 0.032 (0.057)\tLoss 1.0306 (1.0674)\tPrec@1 50.000 (52.967)\n",
            "val Results: Prec@1 53.050 Loss 1.06511\n",
            "Best Prec@1: 53.500\n",
            "\n",
            "Epoch: [39][0/110], lr: 0.01000\tTime 0.513 (0.513)\tData 0.384 (0.384)\tLoss 0.9306 (0.9306)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [39][10/110], lr: 0.01000\tTime 0.071 (0.114)\tData 0.000 (0.036)\tLoss 1.0303 (0.9717)\tPrec@1 54.688 (57.173)\n",
            "Epoch: [39][20/110], lr: 0.01000\tTime 0.081 (0.095)\tData 0.001 (0.019)\tLoss 0.9987 (0.9750)\tPrec@1 55.469 (57.664)\n",
            "Epoch: [39][30/110], lr: 0.01000\tTime 0.082 (0.088)\tData 0.007 (0.014)\tLoss 0.9841 (0.9840)\tPrec@1 56.250 (57.308)\n",
            "Epoch: [39][40/110], lr: 0.01000\tTime 0.066 (0.084)\tData 0.000 (0.012)\tLoss 0.8632 (0.9736)\tPrec@1 67.969 (58.060)\n",
            "Epoch: [39][50/110], lr: 0.01000\tTime 0.066 (0.082)\tData 0.000 (0.010)\tLoss 0.9788 (0.9747)\tPrec@1 60.156 (57.598)\n",
            "Epoch: [39][60/110], lr: 0.01000\tTime 0.085 (0.081)\tData 0.013 (0.009)\tLoss 1.0945 (0.9799)\tPrec@1 49.219 (57.236)\n",
            "Epoch: [39][70/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.008)\tLoss 1.0138 (0.9855)\tPrec@1 57.812 (57.229)\n",
            "Epoch: [39][80/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.008)\tLoss 1.0803 (0.9917)\tPrec@1 54.688 (57.079)\n",
            "Epoch: [39][90/110], lr: 0.01000\tTime 0.081 (0.079)\tData 0.011 (0.007)\tLoss 1.0064 (0.9936)\tPrec@1 57.812 (57.091)\n",
            "Epoch: [39][100/110], lr: 0.01000\tTime 0.073 (0.078)\tData 0.008 (0.007)\tLoss 0.9738 (0.9940)\tPrec@1 60.156 (56.892)\n",
            "Test: [0/100]\tTime 0.248 (0.248)\tLoss 1.0216 (1.0216)\tPrec@1 55.000 (55.000)\n",
            "Test: [10/100]\tTime 0.055 (0.058)\tLoss 1.0518 (1.0527)\tPrec@1 56.000 (54.273)\n",
            "Test: [20/100]\tTime 0.033 (0.045)\tLoss 1.1348 (1.0453)\tPrec@1 55.000 (55.905)\n",
            "Test: [30/100]\tTime 0.021 (0.040)\tLoss 1.1129 (1.0581)\tPrec@1 49.000 (54.387)\n",
            "Test: [40/100]\tTime 0.024 (0.038)\tLoss 1.0501 (1.0570)\tPrec@1 52.000 (53.854)\n",
            "Test: [50/100]\tTime 0.033 (0.038)\tLoss 1.1451 (1.0594)\tPrec@1 48.000 (53.745)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1209 (1.0652)\tPrec@1 49.000 (53.443)\n",
            "Test: [70/100]\tTime 0.051 (0.036)\tLoss 1.0445 (1.0658)\tPrec@1 55.000 (53.282)\n",
            "Test: [80/100]\tTime 0.029 (0.036)\tLoss 1.0139 (1.0652)\tPrec@1 54.000 (53.309)\n",
            "Test: [90/100]\tTime 0.022 (0.035)\tLoss 1.0433 (1.0638)\tPrec@1 54.000 (53.275)\n",
            "val Results: Prec@1 53.470 Loss 1.06104\n",
            "Best Prec@1: 53.500\n",
            "\n",
            "Epoch: [40][0/110], lr: 0.01000\tTime 0.486 (0.486)\tData 0.323 (0.323)\tLoss 1.0291 (1.0291)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [40][10/110], lr: 0.01000\tTime 0.063 (0.113)\tData 0.000 (0.032)\tLoss 1.0238 (0.9901)\tPrec@1 56.250 (57.315)\n",
            "Epoch: [40][20/110], lr: 0.01000\tTime 0.091 (0.094)\tData 0.000 (0.018)\tLoss 0.9809 (0.9770)\tPrec@1 60.938 (57.403)\n",
            "Epoch: [40][30/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.013)\tLoss 1.0547 (0.9837)\tPrec@1 52.344 (57.208)\n",
            "Epoch: [40][40/110], lr: 0.01000\tTime 0.059 (0.084)\tData 0.000 (0.010)\tLoss 0.9919 (0.9863)\tPrec@1 57.031 (57.203)\n",
            "Epoch: [40][50/110], lr: 0.01000\tTime 0.069 (0.082)\tData 0.000 (0.009)\tLoss 0.9432 (0.9905)\tPrec@1 56.250 (56.740)\n",
            "Epoch: [40][60/110], lr: 0.01000\tTime 0.078 (0.081)\tData 0.000 (0.008)\tLoss 0.9395 (0.9881)\tPrec@1 58.594 (56.826)\n",
            "Epoch: [40][70/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.007)\tLoss 0.8323 (0.9904)\tPrec@1 63.281 (56.811)\n",
            "Epoch: [40][80/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.000 (0.007)\tLoss 0.9858 (0.9904)\tPrec@1 60.156 (56.944)\n",
            "Epoch: [40][90/110], lr: 0.01000\tTime 0.075 (0.079)\tData 0.006 (0.006)\tLoss 1.0014 (0.9917)\tPrec@1 55.469 (56.885)\n",
            "Epoch: [40][100/110], lr: 0.01000\tTime 0.073 (0.078)\tData 0.008 (0.006)\tLoss 1.0383 (0.9918)\tPrec@1 60.156 (56.807)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 0.9697 (0.9697)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.058)\tLoss 1.0911 (1.0433)\tPrec@1 54.000 (54.091)\n",
            "Test: [20/100]\tTime 0.022 (0.045)\tLoss 1.1643 (1.0512)\tPrec@1 49.000 (55.048)\n",
            "Test: [30/100]\tTime 0.039 (0.041)\tLoss 1.0625 (1.0657)\tPrec@1 51.000 (54.290)\n",
            "Test: [40/100]\tTime 0.025 (0.039)\tLoss 1.0339 (1.0619)\tPrec@1 58.000 (54.268)\n",
            "Test: [50/100]\tTime 0.026 (0.037)\tLoss 1.1054 (1.0638)\tPrec@1 48.000 (54.137)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1530 (1.0702)\tPrec@1 47.000 (54.016)\n",
            "Test: [70/100]\tTime 0.037 (0.036)\tLoss 1.0302 (1.0668)\tPrec@1 57.000 (53.986)\n",
            "Test: [80/100]\tTime 0.039 (0.036)\tLoss 1.0279 (1.0663)\tPrec@1 55.000 (54.000)\n",
            "Test: [90/100]\tTime 0.026 (0.035)\tLoss 1.0630 (1.0661)\tPrec@1 50.000 (53.912)\n",
            "val Results: Prec@1 53.850 Loss 1.06456\n",
            "Best Prec@1: 53.850\n",
            "\n",
            "Epoch: [41][0/110], lr: 0.01000\tTime 0.465 (0.465)\tData 0.273 (0.273)\tLoss 0.8526 (0.8526)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [41][10/110], lr: 0.01000\tTime 0.075 (0.116)\tData 0.008 (0.027)\tLoss 1.0735 (1.0187)\tPrec@1 51.562 (55.114)\n",
            "Epoch: [41][20/110], lr: 0.01000\tTime 0.069 (0.094)\tData 0.001 (0.016)\tLoss 0.8865 (1.0065)\tPrec@1 64.062 (55.990)\n",
            "Epoch: [41][30/110], lr: 0.01000\tTime 0.069 (0.089)\tData 0.004 (0.012)\tLoss 0.9643 (1.0058)\tPrec@1 52.344 (55.847)\n",
            "Epoch: [41][40/110], lr: 0.01000\tTime 0.066 (0.085)\tData 0.000 (0.010)\tLoss 0.9432 (1.0022)\tPrec@1 56.250 (56.231)\n",
            "Epoch: [41][50/110], lr: 0.01000\tTime 0.072 (0.083)\tData 0.006 (0.009)\tLoss 0.9286 (1.0030)\tPrec@1 60.938 (56.173)\n",
            "Epoch: [41][60/110], lr: 0.01000\tTime 0.077 (0.081)\tData 0.007 (0.008)\tLoss 0.9696 (1.0028)\tPrec@1 59.375 (56.276)\n",
            "Epoch: [41][70/110], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.007)\tLoss 0.9300 (0.9987)\tPrec@1 65.625 (56.712)\n",
            "Epoch: [41][80/110], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.007)\tLoss 0.9045 (1.0010)\tPrec@1 66.406 (56.780)\n",
            "Epoch: [41][90/110], lr: 0.01000\tTime 0.082 (0.079)\tData 0.000 (0.007)\tLoss 0.9213 (0.9995)\tPrec@1 60.156 (56.799)\n",
            "Epoch: [41][100/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.004 (0.006)\tLoss 0.9445 (0.9934)\tPrec@1 55.469 (57.031)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 1.0427 (1.0427)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.024 (0.059)\tLoss 1.1175 (1.0622)\tPrec@1 52.000 (52.636)\n",
            "Test: [20/100]\tTime 0.025 (0.047)\tLoss 1.1879 (1.0634)\tPrec@1 46.000 (53.143)\n",
            "Test: [30/100]\tTime 0.038 (0.043)\tLoss 1.1179 (1.0684)\tPrec@1 49.000 (53.065)\n",
            "Test: [40/100]\tTime 0.031 (0.040)\tLoss 1.0455 (1.0671)\tPrec@1 49.000 (52.976)\n",
            "Test: [50/100]\tTime 0.036 (0.039)\tLoss 1.0803 (1.0704)\tPrec@1 49.000 (53.059)\n",
            "Test: [60/100]\tTime 0.030 (0.037)\tLoss 1.1187 (1.0754)\tPrec@1 45.000 (52.623)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 1.0228 (1.0745)\tPrec@1 52.000 (52.535)\n",
            "Test: [80/100]\tTime 0.023 (0.036)\tLoss 1.0565 (1.0749)\tPrec@1 54.000 (52.617)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 1.0949 (1.0752)\tPrec@1 55.000 (52.527)\n",
            "val Results: Prec@1 52.550 Loss 1.07288\n",
            "Best Prec@1: 53.850\n",
            "\n",
            "Epoch: [42][0/110], lr: 0.01000\tTime 0.497 (0.497)\tData 0.275 (0.275)\tLoss 0.9717 (0.9717)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [42][10/110], lr: 0.01000\tTime 0.072 (0.114)\tData 0.000 (0.028)\tLoss 1.0336 (1.0081)\tPrec@1 53.125 (56.321)\n",
            "Epoch: [42][20/110], lr: 0.01000\tTime 0.083 (0.111)\tData 0.000 (0.016)\tLoss 0.9693 (0.9814)\tPrec@1 57.812 (57.924)\n",
            "Epoch: [42][30/110], lr: 0.01000\tTime 0.089 (0.113)\tData 0.006 (0.013)\tLoss 1.1188 (0.9897)\tPrec@1 45.312 (57.434)\n",
            "Epoch: [42][40/110], lr: 0.01000\tTime 0.095 (0.112)\tData 0.011 (0.012)\tLoss 0.9993 (0.9817)\tPrec@1 53.906 (57.489)\n",
            "Epoch: [42][50/110], lr: 0.01000\tTime 0.062 (0.111)\tData 0.000 (0.010)\tLoss 0.9467 (0.9794)\tPrec@1 60.156 (57.996)\n",
            "Epoch: [42][60/110], lr: 0.01000\tTime 0.064 (0.105)\tData 0.000 (0.009)\tLoss 1.0174 (0.9769)\tPrec@1 54.688 (58.043)\n",
            "Epoch: [42][70/110], lr: 0.01000\tTime 0.076 (0.101)\tData 0.000 (0.008)\tLoss 0.8780 (0.9756)\tPrec@1 61.719 (57.890)\n",
            "Epoch: [42][80/110], lr: 0.01000\tTime 0.080 (0.097)\tData 0.007 (0.007)\tLoss 1.0530 (0.9823)\tPrec@1 57.031 (57.793)\n",
            "Epoch: [42][90/110], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.007)\tLoss 0.8879 (0.9794)\tPrec@1 60.156 (58.001)\n",
            "Epoch: [42][100/110], lr: 0.01000\tTime 0.084 (0.092)\tData 0.000 (0.006)\tLoss 0.9932 (0.9791)\tPrec@1 53.906 (57.936)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 0.9621 (0.9621)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.059)\tLoss 1.0769 (1.0545)\tPrec@1 53.000 (53.545)\n",
            "Test: [20/100]\tTime 0.027 (0.046)\tLoss 1.1644 (1.0569)\tPrec@1 46.000 (54.381)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0619 (1.0575)\tPrec@1 54.000 (54.194)\n",
            "Test: [40/100]\tTime 0.031 (0.040)\tLoss 1.0303 (1.0518)\tPrec@1 55.000 (54.341)\n",
            "Test: [50/100]\tTime 0.044 (0.038)\tLoss 1.0394 (1.0510)\tPrec@1 55.000 (54.333)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.0977 (1.0555)\tPrec@1 51.000 (54.311)\n",
            "Test: [70/100]\tTime 0.023 (0.036)\tLoss 1.0035 (1.0580)\tPrec@1 54.000 (53.930)\n",
            "Test: [80/100]\tTime 0.031 (0.036)\tLoss 1.0281 (1.0572)\tPrec@1 56.000 (53.938)\n",
            "Test: [90/100]\tTime 0.038 (0.036)\tLoss 1.0736 (1.0566)\tPrec@1 52.000 (53.846)\n",
            "val Results: Prec@1 53.890 Loss 1.05380\n",
            "Best Prec@1: 53.890\n",
            "\n",
            "Epoch: [43][0/110], lr: 0.01000\tTime 0.517 (0.517)\tData 0.381 (0.381)\tLoss 0.9323 (0.9323)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [43][10/110], lr: 0.01000\tTime 0.066 (0.118)\tData 0.000 (0.038)\tLoss 0.9622 (0.9723)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [43][20/110], lr: 0.01000\tTime 0.065 (0.096)\tData 0.000 (0.021)\tLoss 1.0275 (0.9950)\tPrec@1 58.594 (56.473)\n",
            "Epoch: [43][30/110], lr: 0.01000\tTime 0.075 (0.088)\tData 0.000 (0.015)\tLoss 1.0525 (0.9910)\tPrec@1 51.562 (56.326)\n",
            "Epoch: [43][40/110], lr: 0.01000\tTime 0.065 (0.085)\tData 0.000 (0.011)\tLoss 0.9299 (0.9798)\tPrec@1 60.938 (57.184)\n",
            "Epoch: [43][50/110], lr: 0.01000\tTime 0.081 (0.083)\tData 0.006 (0.010)\tLoss 1.1881 (0.9847)\tPrec@1 48.438 (57.108)\n",
            "Epoch: [43][60/110], lr: 0.01000\tTime 0.068 (0.081)\tData 0.004 (0.009)\tLoss 1.0276 (0.9838)\tPrec@1 56.250 (56.954)\n",
            "Epoch: [43][70/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.006 (0.008)\tLoss 0.9611 (0.9824)\tPrec@1 59.375 (57.064)\n",
            "Epoch: [43][80/110], lr: 0.01000\tTime 0.065 (0.079)\tData 0.001 (0.008)\tLoss 0.9404 (0.9806)\tPrec@1 54.688 (57.022)\n",
            "Epoch: [43][90/110], lr: 0.01000\tTime 0.081 (0.078)\tData 0.000 (0.007)\tLoss 0.9776 (0.9790)\tPrec@1 60.156 (57.229)\n",
            "Epoch: [43][100/110], lr: 0.01000\tTime 0.068 (0.077)\tData 0.005 (0.007)\tLoss 0.9318 (0.9799)\tPrec@1 62.500 (57.132)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 0.9604 (0.9604)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.023 (0.056)\tLoss 1.0950 (1.0396)\tPrec@1 57.000 (55.545)\n",
            "Test: [20/100]\tTime 0.037 (0.044)\tLoss 1.1309 (1.0432)\tPrec@1 48.000 (55.000)\n",
            "Test: [30/100]\tTime 0.022 (0.040)\tLoss 1.0799 (1.0484)\tPrec@1 50.000 (54.194)\n",
            "Test: [40/100]\tTime 0.033 (0.038)\tLoss 0.9543 (1.0430)\tPrec@1 58.000 (54.098)\n",
            "Test: [50/100]\tTime 0.026 (0.037)\tLoss 1.0786 (1.0425)\tPrec@1 55.000 (54.451)\n",
            "Test: [60/100]\tTime 0.053 (0.036)\tLoss 1.1061 (1.0482)\tPrec@1 52.000 (54.492)\n",
            "Test: [70/100]\tTime 0.036 (0.035)\tLoss 1.0132 (1.0473)\tPrec@1 57.000 (54.507)\n",
            "Test: [80/100]\tTime 0.049 (0.035)\tLoss 1.0180 (1.0485)\tPrec@1 54.000 (54.346)\n",
            "Test: [90/100]\tTime 0.025 (0.034)\tLoss 1.0342 (1.0477)\tPrec@1 50.000 (54.253)\n",
            "val Results: Prec@1 54.370 Loss 1.04505\n",
            "Best Prec@1: 54.370\n",
            "\n",
            "Epoch: [44][0/110], lr: 0.01000\tTime 0.446 (0.446)\tData 0.271 (0.271)\tLoss 1.0804 (1.0804)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [44][10/110], lr: 0.01000\tTime 0.075 (0.111)\tData 0.000 (0.028)\tLoss 1.0095 (0.9923)\tPrec@1 55.469 (56.818)\n",
            "Epoch: [44][20/110], lr: 0.01000\tTime 0.065 (0.092)\tData 0.000 (0.016)\tLoss 0.9124 (0.9808)\tPrec@1 60.938 (58.482)\n",
            "Epoch: [44][30/110], lr: 0.01000\tTime 0.073 (0.086)\tData 0.008 (0.012)\tLoss 0.9717 (0.9799)\tPrec@1 58.594 (58.216)\n",
            "Epoch: [44][40/110], lr: 0.01000\tTime 0.084 (0.083)\tData 0.007 (0.010)\tLoss 1.0186 (0.9771)\tPrec@1 57.812 (58.498)\n",
            "Epoch: [44][50/110], lr: 0.01000\tTime 0.069 (0.081)\tData 0.004 (0.009)\tLoss 0.9588 (0.9722)\tPrec@1 57.812 (58.624)\n",
            "Epoch: [44][60/110], lr: 0.01000\tTime 0.071 (0.080)\tData 0.007 (0.008)\tLoss 0.9470 (0.9765)\tPrec@1 60.156 (58.363)\n",
            "Epoch: [44][70/110], lr: 0.01000\tTime 0.065 (0.079)\tData 0.002 (0.007)\tLoss 0.9866 (0.9777)\tPrec@1 52.344 (58.220)\n",
            "Epoch: [44][80/110], lr: 0.01000\tTime 0.083 (0.078)\tData 0.000 (0.006)\tLoss 0.9208 (0.9750)\tPrec@1 57.812 (58.247)\n",
            "Epoch: [44][90/110], lr: 0.01000\tTime 0.070 (0.077)\tData 0.000 (0.006)\tLoss 0.8700 (0.9731)\tPrec@1 60.938 (58.147)\n",
            "Epoch: [44][100/110], lr: 0.01000\tTime 0.066 (0.077)\tData 0.000 (0.006)\tLoss 1.0884 (0.9696)\tPrec@1 47.656 (58.199)\n",
            "Test: [0/100]\tTime 0.241 (0.241)\tLoss 0.9593 (0.9593)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.045 (0.058)\tLoss 1.0197 (1.0363)\tPrec@1 56.000 (54.545)\n",
            "Test: [20/100]\tTime 0.055 (0.046)\tLoss 1.2163 (1.0434)\tPrec@1 48.000 (54.190)\n",
            "Test: [30/100]\tTime 0.023 (0.041)\tLoss 1.1154 (1.0576)\tPrec@1 48.000 (53.645)\n",
            "Test: [40/100]\tTime 0.027 (0.038)\tLoss 0.9819 (1.0535)\tPrec@1 60.000 (54.195)\n",
            "Test: [50/100]\tTime 0.035 (0.038)\tLoss 1.0713 (1.0521)\tPrec@1 53.000 (54.078)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.1352 (1.0573)\tPrec@1 47.000 (53.820)\n",
            "Test: [70/100]\tTime 0.025 (0.036)\tLoss 1.0199 (1.0568)\tPrec@1 54.000 (53.761)\n",
            "Test: [80/100]\tTime 0.030 (0.035)\tLoss 0.9708 (1.0565)\tPrec@1 58.000 (53.901)\n",
            "Test: [90/100]\tTime 0.029 (0.035)\tLoss 1.0491 (1.0557)\tPrec@1 54.000 (53.879)\n",
            "val Results: Prec@1 53.970 Loss 1.05292\n",
            "Best Prec@1: 54.370\n",
            "\n",
            "Epoch: [45][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.364 (0.364)\tLoss 1.0691 (1.0691)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [45][10/110], lr: 0.01000\tTime 0.065 (0.109)\tData 0.000 (0.034)\tLoss 0.9181 (0.9567)\tPrec@1 60.938 (59.730)\n",
            "Epoch: [45][20/110], lr: 0.01000\tTime 0.070 (0.092)\tData 0.000 (0.019)\tLoss 0.9142 (0.9428)\tPrec@1 59.375 (59.635)\n",
            "Epoch: [45][30/110], lr: 0.01000\tTime 0.065 (0.086)\tData 0.000 (0.014)\tLoss 0.9710 (0.9576)\tPrec@1 56.250 (59.173)\n",
            "Epoch: [45][40/110], lr: 0.01000\tTime 0.068 (0.083)\tData 0.004 (0.011)\tLoss 0.9233 (0.9606)\tPrec@1 55.469 (58.937)\n",
            "Epoch: [45][50/110], lr: 0.01000\tTime 0.075 (0.081)\tData 0.007 (0.010)\tLoss 0.9806 (0.9576)\tPrec@1 59.375 (58.732)\n",
            "Epoch: [45][60/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.002 (0.009)\tLoss 1.0102 (0.9578)\tPrec@1 58.594 (58.530)\n",
            "Epoch: [45][70/110], lr: 0.01000\tTime 0.084 (0.080)\tData 0.000 (0.008)\tLoss 0.9361 (0.9618)\tPrec@1 55.469 (58.385)\n",
            "Epoch: [45][80/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.008)\tLoss 0.8493 (0.9630)\tPrec@1 66.406 (58.459)\n",
            "Epoch: [45][90/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.007)\tLoss 1.0539 (0.9601)\tPrec@1 52.344 (58.611)\n",
            "Epoch: [45][100/110], lr: 0.01000\tTime 0.103 (0.080)\tData 0.010 (0.006)\tLoss 0.9032 (0.9609)\tPrec@1 57.812 (58.547)\n",
            "Test: [0/100]\tTime 0.420 (0.420)\tLoss 0.9936 (0.9936)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.053 (0.093)\tLoss 1.0543 (1.0463)\tPrec@1 62.000 (53.273)\n",
            "Test: [20/100]\tTime 0.057 (0.074)\tLoss 1.1138 (1.0389)\tPrec@1 52.000 (54.524)\n",
            "Test: [30/100]\tTime 0.138 (0.076)\tLoss 1.0427 (1.0442)\tPrec@1 52.000 (54.387)\n",
            "Test: [40/100]\tTime 0.046 (0.070)\tLoss 0.9861 (1.0425)\tPrec@1 60.000 (54.146)\n",
            "Test: [50/100]\tTime 0.027 (0.064)\tLoss 1.0815 (1.0410)\tPrec@1 50.000 (54.294)\n",
            "Test: [60/100]\tTime 0.040 (0.059)\tLoss 1.1356 (1.0462)\tPrec@1 50.000 (54.115)\n",
            "Test: [70/100]\tTime 0.059 (0.056)\tLoss 1.0076 (1.0459)\tPrec@1 56.000 (54.127)\n",
            "Test: [80/100]\tTime 0.028 (0.054)\tLoss 1.0168 (1.0460)\tPrec@1 59.000 (54.136)\n",
            "Test: [90/100]\tTime 0.064 (0.052)\tLoss 1.0095 (1.0454)\tPrec@1 55.000 (53.967)\n",
            "val Results: Prec@1 54.140 Loss 1.04154\n",
            "Best Prec@1: 54.370\n",
            "\n",
            "Epoch: [46][0/110], lr: 0.01000\tTime 0.546 (0.546)\tData 0.340 (0.340)\tLoss 0.9665 (0.9665)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [46][10/110], lr: 0.01000\tTime 0.067 (0.122)\tData 0.000 (0.032)\tLoss 1.0749 (0.9362)\tPrec@1 56.250 (61.080)\n",
            "Epoch: [46][20/110], lr: 0.01000\tTime 0.070 (0.101)\tData 0.006 (0.017)\tLoss 0.9881 (0.9611)\tPrec@1 56.250 (59.189)\n",
            "Epoch: [46][30/110], lr: 0.01000\tTime 0.086 (0.092)\tData 0.012 (0.013)\tLoss 1.0070 (0.9609)\tPrec@1 53.906 (58.695)\n",
            "Epoch: [46][40/110], lr: 0.01000\tTime 0.091 (0.093)\tData 0.000 (0.010)\tLoss 0.9449 (0.9635)\tPrec@1 58.594 (58.670)\n",
            "Epoch: [46][50/110], lr: 0.01000\tTime 0.104 (0.091)\tData 0.000 (0.009)\tLoss 0.9663 (0.9617)\tPrec@1 54.688 (58.624)\n",
            "Epoch: [46][60/110], lr: 0.01000\tTime 0.073 (0.090)\tData 0.000 (0.008)\tLoss 1.0390 (0.9667)\tPrec@1 57.812 (58.184)\n",
            "Epoch: [46][70/110], lr: 0.01000\tTime 0.066 (0.090)\tData 0.000 (0.007)\tLoss 1.0411 (0.9649)\tPrec@1 53.906 (57.956)\n",
            "Epoch: [46][80/110], lr: 0.01000\tTime 0.077 (0.089)\tData 0.007 (0.007)\tLoss 0.9294 (0.9611)\tPrec@1 59.375 (58.285)\n",
            "Epoch: [46][90/110], lr: 0.01000\tTime 0.070 (0.087)\tData 0.004 (0.006)\tLoss 1.0979 (0.9608)\tPrec@1 55.469 (58.456)\n",
            "Epoch: [46][100/110], lr: 0.01000\tTime 0.074 (0.086)\tData 0.007 (0.006)\tLoss 1.0184 (0.9624)\tPrec@1 56.250 (58.385)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 1.0256 (1.0256)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.057 (0.069)\tLoss 1.1188 (1.0494)\tPrec@1 52.000 (54.545)\n",
            "Test: [20/100]\tTime 0.024 (0.055)\tLoss 1.1051 (1.0399)\tPrec@1 46.000 (55.714)\n",
            "Test: [30/100]\tTime 0.023 (0.048)\tLoss 1.1153 (1.0526)\tPrec@1 52.000 (54.871)\n",
            "Test: [40/100]\tTime 0.035 (0.047)\tLoss 1.0183 (1.0498)\tPrec@1 58.000 (54.659)\n",
            "Test: [50/100]\tTime 0.026 (0.044)\tLoss 1.1303 (1.0506)\tPrec@1 47.000 (54.608)\n",
            "Test: [60/100]\tTime 0.034 (0.044)\tLoss 1.0996 (1.0580)\tPrec@1 47.000 (54.049)\n",
            "Test: [70/100]\tTime 0.031 (0.042)\tLoss 1.0074 (1.0578)\tPrec@1 57.000 (53.915)\n",
            "Test: [80/100]\tTime 0.028 (0.042)\tLoss 1.1037 (1.0587)\tPrec@1 53.000 (53.753)\n",
            "Test: [90/100]\tTime 0.051 (0.042)\tLoss 1.0350 (1.0575)\tPrec@1 51.000 (53.747)\n",
            "val Results: Prec@1 53.980 Loss 1.05191\n",
            "Best Prec@1: 54.370\n",
            "\n",
            "Epoch: [47][0/110], lr: 0.01000\tTime 0.501 (0.501)\tData 0.322 (0.322)\tLoss 1.1322 (1.1322)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [47][10/110], lr: 0.01000\tTime 0.065 (0.113)\tData 0.000 (0.033)\tLoss 0.9980 (0.9865)\tPrec@1 59.375 (56.605)\n",
            "Epoch: [47][20/110], lr: 0.01000\tTime 0.072 (0.094)\tData 0.007 (0.019)\tLoss 0.9269 (0.9742)\tPrec@1 63.281 (58.482)\n",
            "Epoch: [47][30/110], lr: 0.01000\tTime 0.067 (0.087)\tData 0.000 (0.014)\tLoss 0.8982 (0.9820)\tPrec@1 62.500 (58.317)\n",
            "Epoch: [47][40/110], lr: 0.01000\tTime 0.072 (0.085)\tData 0.008 (0.011)\tLoss 0.9593 (0.9781)\tPrec@1 54.688 (58.079)\n",
            "Epoch: [47][50/110], lr: 0.01000\tTime 0.082 (0.082)\tData 0.000 (0.009)\tLoss 0.9227 (0.9778)\tPrec@1 60.156 (57.874)\n",
            "Epoch: [47][60/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.008)\tLoss 0.9940 (0.9742)\tPrec@1 57.812 (58.133)\n",
            "Epoch: [47][70/110], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.007)\tLoss 0.9027 (0.9659)\tPrec@1 59.375 (58.286)\n",
            "Epoch: [47][80/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.007)\tLoss 0.9456 (0.9644)\tPrec@1 59.375 (58.304)\n",
            "Epoch: [47][90/110], lr: 0.01000\tTime 0.078 (0.079)\tData 0.000 (0.006)\tLoss 0.9385 (0.9637)\tPrec@1 60.156 (58.448)\n",
            "Epoch: [47][100/110], lr: 0.01000\tTime 0.113 (0.081)\tData 0.001 (0.006)\tLoss 0.9733 (0.9610)\tPrec@1 61.719 (58.810)\n",
            "Test: [0/100]\tTime 0.351 (0.351)\tLoss 0.9535 (0.9535)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.044 (0.069)\tLoss 1.0507 (1.0294)\tPrec@1 56.000 (55.818)\n",
            "Test: [20/100]\tTime 0.025 (0.054)\tLoss 1.1249 (1.0217)\tPrec@1 54.000 (56.333)\n",
            "Test: [30/100]\tTime 0.023 (0.049)\tLoss 1.0657 (1.0339)\tPrec@1 56.000 (55.452)\n",
            "Test: [40/100]\tTime 0.022 (0.046)\tLoss 0.9732 (1.0307)\tPrec@1 60.000 (55.537)\n",
            "Test: [50/100]\tTime 0.028 (0.044)\tLoss 1.0870 (1.0331)\tPrec@1 52.000 (55.373)\n",
            "Test: [60/100]\tTime 0.034 (0.043)\tLoss 1.1012 (1.0369)\tPrec@1 54.000 (55.361)\n",
            "Test: [70/100]\tTime 0.039 (0.042)\tLoss 1.0235 (1.0388)\tPrec@1 57.000 (55.211)\n",
            "Test: [80/100]\tTime 0.022 (0.041)\tLoss 1.0365 (1.0380)\tPrec@1 62.000 (55.259)\n",
            "Test: [90/100]\tTime 0.027 (0.040)\tLoss 1.0769 (1.0395)\tPrec@1 49.000 (54.989)\n",
            "val Results: Prec@1 55.100 Loss 1.03634\n",
            "Best Prec@1: 55.100\n",
            "\n",
            "Epoch: [48][0/110], lr: 0.01000\tTime 0.486 (0.486)\tData 0.274 (0.274)\tLoss 1.0256 (1.0256)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [48][10/110], lr: 0.01000\tTime 0.065 (0.114)\tData 0.000 (0.027)\tLoss 0.9844 (0.9384)\tPrec@1 59.375 (60.795)\n",
            "Epoch: [48][20/110], lr: 0.01000\tTime 0.076 (0.095)\tData 0.008 (0.015)\tLoss 1.0877 (0.9651)\tPrec@1 53.125 (59.003)\n",
            "Epoch: [48][30/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.012)\tLoss 0.8986 (0.9632)\tPrec@1 58.594 (58.795)\n",
            "Epoch: [48][40/110], lr: 0.01000\tTime 0.088 (0.085)\tData 0.007 (0.010)\tLoss 0.9623 (0.9737)\tPrec@1 60.156 (58.041)\n",
            "Epoch: [48][50/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.008)\tLoss 1.0250 (0.9632)\tPrec@1 52.344 (58.395)\n",
            "Epoch: [48][60/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.000 (0.007)\tLoss 1.0676 (0.9571)\tPrec@1 52.344 (58.773)\n",
            "Epoch: [48][70/110], lr: 0.01000\tTime 0.085 (0.080)\tData 0.008 (0.007)\tLoss 0.9470 (0.9588)\tPrec@1 60.156 (58.803)\n",
            "Epoch: [48][80/110], lr: 0.01000\tTime 0.083 (0.079)\tData 0.000 (0.006)\tLoss 0.9547 (0.9560)\tPrec@1 55.469 (58.951)\n",
            "Epoch: [48][90/110], lr: 0.01000\tTime 0.072 (0.080)\tData 0.009 (0.006)\tLoss 0.9958 (0.9557)\tPrec@1 53.906 (58.963)\n",
            "Epoch: [48][100/110], lr: 0.01000\tTime 0.087 (0.080)\tData 0.000 (0.006)\tLoss 0.9351 (0.9551)\tPrec@1 57.812 (58.888)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 0.9987 (0.9987)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.025 (0.068)\tLoss 1.1387 (1.0690)\tPrec@1 53.000 (55.364)\n",
            "Test: [20/100]\tTime 0.026 (0.053)\tLoss 1.1320 (1.0464)\tPrec@1 48.000 (56.095)\n",
            "Test: [30/100]\tTime 0.024 (0.047)\tLoss 1.1219 (1.0562)\tPrec@1 50.000 (54.903)\n",
            "Test: [40/100]\tTime 0.021 (0.045)\tLoss 0.9901 (1.0526)\tPrec@1 57.000 (55.098)\n",
            "Test: [50/100]\tTime 0.024 (0.043)\tLoss 1.1509 (1.0502)\tPrec@1 51.000 (55.294)\n",
            "Test: [60/100]\tTime 0.022 (0.040)\tLoss 1.1206 (1.0578)\tPrec@1 51.000 (55.115)\n",
            "Test: [70/100]\tTime 0.044 (0.040)\tLoss 0.9773 (1.0524)\tPrec@1 58.000 (55.324)\n",
            "Test: [80/100]\tTime 0.050 (0.039)\tLoss 1.0504 (1.0514)\tPrec@1 57.000 (55.444)\n",
            "Test: [90/100]\tTime 0.030 (0.038)\tLoss 1.0370 (1.0514)\tPrec@1 55.000 (55.363)\n",
            "val Results: Prec@1 55.370 Loss 1.04861\n",
            "Best Prec@1: 55.370\n",
            "\n",
            "Epoch: [49][0/110], lr: 0.01000\tTime 0.437 (0.437)\tData 0.276 (0.276)\tLoss 1.0948 (1.0948)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [49][10/110], lr: 0.01000\tTime 0.124 (0.120)\tData 0.005 (0.028)\tLoss 1.0457 (0.9742)\tPrec@1 56.250 (57.884)\n",
            "Epoch: [49][20/110], lr: 0.01000\tTime 0.108 (0.114)\tData 0.013 (0.019)\tLoss 0.9350 (0.9571)\tPrec@1 61.719 (59.375)\n",
            "Epoch: [49][30/110], lr: 0.01000\tTime 0.130 (0.112)\tData 0.005 (0.014)\tLoss 1.0552 (0.9517)\tPrec@1 53.125 (59.224)\n",
            "Epoch: [49][40/110], lr: 0.01000\tTime 0.098 (0.111)\tData 0.000 (0.011)\tLoss 0.9237 (0.9391)\tPrec@1 57.031 (59.470)\n",
            "Epoch: [49][50/110], lr: 0.01000\tTime 0.073 (0.111)\tData 0.006 (0.010)\tLoss 0.9003 (0.9426)\tPrec@1 57.031 (59.191)\n",
            "Epoch: [49][60/110], lr: 0.01000\tTime 0.067 (0.104)\tData 0.000 (0.009)\tLoss 0.8929 (0.9472)\tPrec@1 63.281 (59.170)\n",
            "Epoch: [49][70/110], lr: 0.01000\tTime 0.072 (0.100)\tData 0.007 (0.008)\tLoss 1.0026 (0.9487)\tPrec@1 62.500 (59.144)\n",
            "Epoch: [49][80/110], lr: 0.01000\tTime 0.077 (0.097)\tData 0.000 (0.007)\tLoss 0.9514 (0.9514)\tPrec@1 60.938 (59.269)\n",
            "Epoch: [49][90/110], lr: 0.01000\tTime 0.059 (0.094)\tData 0.000 (0.006)\tLoss 1.0235 (0.9506)\tPrec@1 60.156 (59.358)\n",
            "Epoch: [49][100/110], lr: 0.01000\tTime 0.072 (0.092)\tData 0.000 (0.006)\tLoss 1.1005 (0.9540)\tPrec@1 48.438 (59.104)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 0.9895 (0.9895)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.039 (0.059)\tLoss 1.0476 (1.0365)\tPrec@1 55.000 (56.091)\n",
            "Test: [20/100]\tTime 0.036 (0.046)\tLoss 1.0749 (1.0332)\tPrec@1 59.000 (56.381)\n",
            "Test: [30/100]\tTime 0.097 (0.043)\tLoss 1.0509 (1.0373)\tPrec@1 48.000 (55.806)\n",
            "Test: [40/100]\tTime 0.098 (0.044)\tLoss 0.9891 (1.0312)\tPrec@1 59.000 (55.732)\n",
            "Test: [50/100]\tTime 0.024 (0.042)\tLoss 1.0895 (1.0320)\tPrec@1 52.000 (56.000)\n",
            "Test: [60/100]\tTime 0.023 (0.042)\tLoss 1.1384 (1.0399)\tPrec@1 56.000 (55.393)\n",
            "Test: [70/100]\tTime 0.026 (0.040)\tLoss 0.9887 (1.0396)\tPrec@1 57.000 (55.296)\n",
            "Test: [80/100]\tTime 0.054 (0.041)\tLoss 1.0010 (1.0399)\tPrec@1 56.000 (55.111)\n",
            "Test: [90/100]\tTime 0.109 (0.041)\tLoss 1.0219 (1.0395)\tPrec@1 55.000 (55.000)\n",
            "val Results: Prec@1 54.850 Loss 1.03614\n",
            "Best Prec@1: 55.370\n",
            "\n",
            "Epoch: [50][0/110], lr: 0.01000\tTime 0.562 (0.562)\tData 0.325 (0.325)\tLoss 0.8561 (0.8561)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [50][10/110], lr: 0.01000\tTime 0.067 (0.121)\tData 0.000 (0.032)\tLoss 0.9251 (0.9449)\tPrec@1 58.594 (59.801)\n",
            "Epoch: [50][20/110], lr: 0.01000\tTime 0.085 (0.100)\tData 0.007 (0.019)\tLoss 1.0358 (0.9564)\tPrec@1 54.688 (59.003)\n",
            "Epoch: [50][30/110], lr: 0.01000\tTime 0.074 (0.091)\tData 0.007 (0.014)\tLoss 0.9300 (0.9500)\tPrec@1 60.156 (59.224)\n",
            "Epoch: [50][40/110], lr: 0.01000\tTime 0.075 (0.087)\tData 0.006 (0.011)\tLoss 0.9990 (0.9562)\tPrec@1 58.594 (59.604)\n",
            "Epoch: [50][50/110], lr: 0.01000\tTime 0.069 (0.084)\tData 0.000 (0.009)\tLoss 0.9011 (0.9535)\tPrec@1 65.625 (59.681)\n",
            "Epoch: [50][60/110], lr: 0.01000\tTime 0.077 (0.082)\tData 0.012 (0.008)\tLoss 0.9935 (0.9491)\tPrec@1 54.688 (59.580)\n",
            "Epoch: [50][70/110], lr: 0.01000\tTime 0.084 (0.083)\tData 0.007 (0.008)\tLoss 0.8494 (0.9437)\tPrec@1 66.406 (59.738)\n",
            "Epoch: [50][80/110], lr: 0.01000\tTime 0.121 (0.084)\tData 0.000 (0.007)\tLoss 0.8866 (0.9405)\tPrec@1 60.938 (59.915)\n",
            "Epoch: [50][90/110], lr: 0.01000\tTime 0.064 (0.084)\tData 0.000 (0.007)\tLoss 0.9064 (0.9389)\tPrec@1 65.625 (59.924)\n",
            "Epoch: [50][100/110], lr: 0.01000\tTime 0.114 (0.084)\tData 0.009 (0.006)\tLoss 0.9150 (0.9421)\tPrec@1 57.031 (59.700)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 0.9474 (0.9474)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.024 (0.058)\tLoss 1.0728 (1.0187)\tPrec@1 53.000 (56.091)\n",
            "Test: [20/100]\tTime 0.023 (0.046)\tLoss 1.0963 (1.0180)\tPrec@1 54.000 (56.286)\n",
            "Test: [30/100]\tTime 0.045 (0.042)\tLoss 1.0338 (1.0334)\tPrec@1 55.000 (55.452)\n",
            "Test: [40/100]\tTime 0.036 (0.040)\tLoss 0.9742 (1.0328)\tPrec@1 56.000 (55.683)\n",
            "Test: [50/100]\tTime 0.049 (0.039)\tLoss 1.1025 (1.0333)\tPrec@1 53.000 (55.569)\n",
            "Test: [60/100]\tTime 0.033 (0.037)\tLoss 1.1714 (1.0393)\tPrec@1 46.000 (55.230)\n",
            "Test: [70/100]\tTime 0.027 (0.037)\tLoss 0.9938 (1.0399)\tPrec@1 53.000 (55.127)\n",
            "Test: [80/100]\tTime 0.032 (0.036)\tLoss 0.9686 (1.0368)\tPrec@1 58.000 (55.049)\n",
            "Test: [90/100]\tTime 0.024 (0.036)\tLoss 1.0658 (1.0367)\tPrec@1 58.000 (55.044)\n",
            "val Results: Prec@1 55.050 Loss 1.03205\n",
            "Best Prec@1: 55.370\n",
            "\n",
            "Epoch: [51][0/110], lr: 0.01000\tTime 0.528 (0.528)\tData 0.339 (0.339)\tLoss 0.8737 (0.8737)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [51][10/110], lr: 0.01000\tTime 0.071 (0.116)\tData 0.002 (0.034)\tLoss 0.9763 (0.9306)\tPrec@1 53.906 (60.156)\n",
            "Epoch: [51][20/110], lr: 0.01000\tTime 0.068 (0.095)\tData 0.001 (0.018)\tLoss 0.8982 (0.9328)\tPrec@1 63.281 (59.784)\n",
            "Epoch: [51][30/110], lr: 0.01000\tTime 0.070 (0.088)\tData 0.000 (0.013)\tLoss 0.9359 (0.9269)\tPrec@1 60.938 (60.257)\n",
            "Epoch: [51][40/110], lr: 0.01000\tTime 0.084 (0.084)\tData 0.004 (0.011)\tLoss 0.9896 (0.9278)\tPrec@1 61.719 (60.480)\n",
            "Epoch: [51][50/110], lr: 0.01000\tTime 0.061 (0.081)\tData 0.000 (0.010)\tLoss 0.9173 (0.9350)\tPrec@1 62.500 (60.172)\n",
            "Epoch: [51][60/110], lr: 0.01000\tTime 0.084 (0.080)\tData 0.000 (0.009)\tLoss 0.9248 (0.9393)\tPrec@1 58.594 (59.823)\n",
            "Epoch: [51][70/110], lr: 0.01000\tTime 0.071 (0.080)\tData 0.001 (0.008)\tLoss 0.9695 (0.9388)\tPrec@1 54.688 (59.760)\n",
            "Epoch: [51][80/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.000 (0.007)\tLoss 0.9387 (0.9389)\tPrec@1 56.250 (59.635)\n",
            "Epoch: [51][90/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.007)\tLoss 1.0609 (0.9405)\tPrec@1 54.688 (59.435)\n",
            "Epoch: [51][100/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.004 (0.007)\tLoss 0.9899 (0.9447)\tPrec@1 53.125 (59.166)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 0.9536 (0.9536)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.041 (0.058)\tLoss 1.0871 (1.0397)\tPrec@1 59.000 (56.364)\n",
            "Test: [20/100]\tTime 0.044 (0.045)\tLoss 1.0862 (1.0333)\tPrec@1 51.000 (56.952)\n",
            "Test: [30/100]\tTime 0.022 (0.042)\tLoss 1.1626 (1.0406)\tPrec@1 49.000 (56.161)\n",
            "Test: [40/100]\tTime 0.035 (0.039)\tLoss 0.9665 (1.0411)\tPrec@1 57.000 (56.195)\n",
            "Test: [50/100]\tTime 0.024 (0.039)\tLoss 1.0705 (1.0384)\tPrec@1 55.000 (56.392)\n",
            "Test: [60/100]\tTime 0.031 (0.040)\tLoss 1.0445 (1.0447)\tPrec@1 54.000 (56.180)\n",
            "Test: [70/100]\tTime 0.039 (0.038)\tLoss 0.9114 (1.0444)\tPrec@1 61.000 (56.127)\n",
            "Test: [80/100]\tTime 0.027 (0.039)\tLoss 1.1170 (1.0460)\tPrec@1 49.000 (56.012)\n",
            "Test: [90/100]\tTime 0.050 (0.038)\tLoss 1.0423 (1.0456)\tPrec@1 56.000 (55.956)\n",
            "val Results: Prec@1 56.150 Loss 1.04175\n",
            "Best Prec@1: 56.150\n",
            "\n",
            "Epoch: [52][0/110], lr: 0.01000\tTime 0.563 (0.563)\tData 0.330 (0.330)\tLoss 0.8433 (0.8433)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [52][10/110], lr: 0.01000\tTime 0.068 (0.121)\tData 0.000 (0.032)\tLoss 1.0421 (0.9579)\tPrec@1 50.000 (59.020)\n",
            "Epoch: [52][20/110], lr: 0.01000\tTime 0.072 (0.098)\tData 0.007 (0.019)\tLoss 1.0709 (0.9571)\tPrec@1 49.219 (58.929)\n",
            "Epoch: [52][30/110], lr: 0.01000\tTime 0.069 (0.090)\tData 0.004 (0.014)\tLoss 0.9613 (0.9602)\tPrec@1 57.031 (58.795)\n",
            "Epoch: [52][40/110], lr: 0.01000\tTime 0.075 (0.087)\tData 0.000 (0.011)\tLoss 0.8419 (0.9574)\tPrec@1 66.406 (59.108)\n",
            "Epoch: [52][50/110], lr: 0.01000\tTime 0.108 (0.085)\tData 0.000 (0.009)\tLoss 0.9539 (0.9465)\tPrec@1 57.031 (59.498)\n",
            "Epoch: [52][60/110], lr: 0.01000\tTime 0.107 (0.086)\tData 0.002 (0.008)\tLoss 0.9553 (0.9439)\tPrec@1 57.812 (59.516)\n",
            "Epoch: [52][70/110], lr: 0.01000\tTime 0.143 (0.089)\tData 0.006 (0.008)\tLoss 0.8577 (0.9371)\tPrec@1 69.531 (59.914)\n",
            "Epoch: [52][80/110], lr: 0.01000\tTime 0.059 (0.091)\tData 0.000 (0.008)\tLoss 1.0016 (0.9375)\tPrec@1 56.250 (59.973)\n",
            "Epoch: [52][90/110], lr: 0.01000\tTime 0.118 (0.094)\tData 0.014 (0.008)\tLoss 0.8601 (0.9414)\tPrec@1 67.969 (59.744)\n",
            "Epoch: [52][100/110], lr: 0.01000\tTime 0.076 (0.093)\tData 0.011 (0.007)\tLoss 0.9424 (0.9445)\tPrec@1 58.594 (59.592)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 1.0199 (1.0199)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.056)\tLoss 1.0191 (1.0380)\tPrec@1 51.000 (55.818)\n",
            "Test: [20/100]\tTime 0.039 (0.046)\tLoss 1.0974 (1.0443)\tPrec@1 53.000 (55.857)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 1.0894 (1.0544)\tPrec@1 56.000 (55.387)\n",
            "Test: [40/100]\tTime 0.041 (0.039)\tLoss 0.9919 (1.0521)\tPrec@1 60.000 (55.805)\n",
            "Test: [50/100]\tTime 0.041 (0.038)\tLoss 1.0616 (1.0492)\tPrec@1 56.000 (55.647)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1464 (1.0568)\tPrec@1 47.000 (55.230)\n",
            "Test: [70/100]\tTime 0.054 (0.036)\tLoss 1.0492 (1.0551)\tPrec@1 53.000 (55.099)\n",
            "Test: [80/100]\tTime 0.033 (0.036)\tLoss 0.9833 (1.0551)\tPrec@1 56.000 (54.938)\n",
            "Test: [90/100]\tTime 0.027 (0.035)\tLoss 1.0050 (1.0537)\tPrec@1 56.000 (54.923)\n",
            "val Results: Prec@1 55.120 Loss 1.04890\n",
            "Best Prec@1: 56.150\n",
            "\n",
            "Epoch: [53][0/110], lr: 0.01000\tTime 0.520 (0.520)\tData 0.357 (0.357)\tLoss 0.9605 (0.9605)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [53][10/110], lr: 0.01000\tTime 0.064 (0.115)\tData 0.000 (0.034)\tLoss 0.9168 (0.9674)\tPrec@1 58.594 (59.304)\n",
            "Epoch: [53][20/110], lr: 0.01000\tTime 0.072 (0.096)\tData 0.007 (0.020)\tLoss 0.8411 (0.9535)\tPrec@1 63.281 (59.189)\n",
            "Epoch: [53][30/110], lr: 0.01000\tTime 0.074 (0.089)\tData 0.006 (0.014)\tLoss 1.0186 (0.9361)\tPrec@1 57.812 (60.106)\n",
            "Epoch: [53][40/110], lr: 0.01000\tTime 0.085 (0.085)\tData 0.008 (0.012)\tLoss 1.0124 (0.9368)\tPrec@1 56.250 (60.213)\n",
            "Epoch: [53][50/110], lr: 0.01000\tTime 0.071 (0.083)\tData 0.007 (0.010)\tLoss 0.9022 (0.9394)\tPrec@1 60.938 (60.187)\n",
            "Epoch: [53][60/110], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.009)\tLoss 1.0520 (0.9430)\tPrec@1 53.906 (59.823)\n",
            "Epoch: [53][70/110], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.008)\tLoss 0.8949 (0.9406)\tPrec@1 62.500 (60.090)\n",
            "Epoch: [53][80/110], lr: 0.01000\tTime 0.075 (0.079)\tData 0.000 (0.007)\tLoss 0.9103 (0.9411)\tPrec@1 60.156 (60.176)\n",
            "Epoch: [53][90/110], lr: 0.01000\tTime 0.073 (0.079)\tData 0.004 (0.007)\tLoss 0.8541 (0.9356)\tPrec@1 64.844 (60.397)\n",
            "Epoch: [53][100/110], lr: 0.01000\tTime 0.084 (0.078)\tData 0.000 (0.007)\tLoss 0.8570 (0.9301)\tPrec@1 60.938 (60.636)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 0.9665 (0.9665)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.023 (0.058)\tLoss 1.0686 (1.0554)\tPrec@1 53.000 (55.273)\n",
            "Test: [20/100]\tTime 0.024 (0.045)\tLoss 1.2282 (1.0603)\tPrec@1 47.000 (54.762)\n",
            "Test: [30/100]\tTime 0.026 (0.042)\tLoss 1.0069 (1.0600)\tPrec@1 55.000 (55.065)\n",
            "Test: [40/100]\tTime 0.034 (0.039)\tLoss 1.0096 (1.0556)\tPrec@1 58.000 (55.415)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.0065 (1.0516)\tPrec@1 55.000 (55.137)\n",
            "Test: [60/100]\tTime 0.038 (0.037)\tLoss 1.1961 (1.0563)\tPrec@1 51.000 (54.934)\n",
            "Test: [70/100]\tTime 0.056 (0.036)\tLoss 1.0339 (1.0562)\tPrec@1 55.000 (54.803)\n",
            "Test: [80/100]\tTime 0.031 (0.035)\tLoss 0.9638 (1.0550)\tPrec@1 55.000 (54.728)\n",
            "Test: [90/100]\tTime 0.033 (0.035)\tLoss 1.0421 (1.0561)\tPrec@1 55.000 (54.659)\n",
            "val Results: Prec@1 54.880 Loss 1.05281\n",
            "Best Prec@1: 56.150\n",
            "\n",
            "Epoch: [54][0/110], lr: 0.01000\tTime 0.455 (0.455)\tData 0.256 (0.256)\tLoss 0.9527 (0.9527)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [54][10/110], lr: 0.01000\tTime 0.083 (0.116)\tData 0.011 (0.026)\tLoss 0.9576 (0.9097)\tPrec@1 58.594 (61.293)\n",
            "Epoch: [54][20/110], lr: 0.01000\tTime 0.070 (0.096)\tData 0.000 (0.016)\tLoss 0.8477 (0.9198)\tPrec@1 64.062 (60.045)\n",
            "Epoch: [54][30/110], lr: 0.01000\tTime 0.076 (0.089)\tData 0.000 (0.011)\tLoss 0.8998 (0.9358)\tPrec@1 60.156 (59.501)\n",
            "Epoch: [54][40/110], lr: 0.01000\tTime 0.066 (0.086)\tData 0.000 (0.009)\tLoss 1.0895 (0.9377)\tPrec@1 53.906 (59.566)\n",
            "Epoch: [54][50/110], lr: 0.01000\tTime 0.068 (0.083)\tData 0.000 (0.008)\tLoss 1.0625 (0.9321)\tPrec@1 56.250 (60.110)\n",
            "Epoch: [54][60/110], lr: 0.01000\tTime 0.071 (0.082)\tData 0.006 (0.007)\tLoss 0.9919 (0.9358)\tPrec@1 57.031 (60.143)\n",
            "Epoch: [54][70/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.006)\tLoss 0.9346 (0.9388)\tPrec@1 59.375 (59.683)\n",
            "Epoch: [54][80/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.002 (0.006)\tLoss 0.9138 (0.9375)\tPrec@1 63.281 (59.703)\n",
            "Epoch: [54][90/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.006)\tLoss 0.9749 (0.9362)\tPrec@1 54.688 (59.873)\n",
            "Epoch: [54][100/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.001 (0.005)\tLoss 0.8662 (0.9381)\tPrec@1 59.375 (59.615)\n",
            "Test: [0/100]\tTime 0.248 (0.248)\tLoss 0.9315 (0.9315)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.036 (0.057)\tLoss 1.0090 (1.0064)\tPrec@1 57.000 (55.727)\n",
            "Test: [20/100]\tTime 0.033 (0.047)\tLoss 1.1196 (1.0081)\tPrec@1 53.000 (56.429)\n",
            "Test: [30/100]\tTime 0.032 (0.043)\tLoss 1.0405 (1.0176)\tPrec@1 57.000 (55.871)\n",
            "Test: [40/100]\tTime 0.044 (0.040)\tLoss 0.9680 (1.0122)\tPrec@1 57.000 (56.000)\n",
            "Test: [50/100]\tTime 0.029 (0.039)\tLoss 1.1732 (1.0148)\tPrec@1 49.000 (56.157)\n",
            "Test: [60/100]\tTime 0.037 (0.038)\tLoss 1.0641 (1.0178)\tPrec@1 54.000 (56.213)\n",
            "Test: [70/100]\tTime 0.047 (0.037)\tLoss 1.0188 (1.0184)\tPrec@1 59.000 (56.070)\n",
            "Test: [80/100]\tTime 0.042 (0.036)\tLoss 0.9734 (1.0174)\tPrec@1 57.000 (56.296)\n",
            "Test: [90/100]\tTime 0.028 (0.036)\tLoss 1.0546 (1.0167)\tPrec@1 54.000 (56.297)\n",
            "val Results: Prec@1 56.470 Loss 1.01295\n",
            "Best Prec@1: 56.470\n",
            "\n",
            "Epoch: [55][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.346 (0.346)\tLoss 0.8115 (0.8115)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [55][10/110], lr: 0.01000\tTime 0.073 (0.116)\tData 0.000 (0.035)\tLoss 1.0353 (0.9350)\tPrec@1 53.906 (59.233)\n",
            "Epoch: [55][20/110], lr: 0.01000\tTime 0.075 (0.097)\tData 0.007 (0.019)\tLoss 0.9629 (0.9499)\tPrec@1 59.375 (58.222)\n",
            "Epoch: [55][30/110], lr: 0.01000\tTime 0.070 (0.088)\tData 0.000 (0.014)\tLoss 0.9324 (0.9537)\tPrec@1 60.156 (58.871)\n",
            "Epoch: [55][40/110], lr: 0.01000\tTime 0.077 (0.085)\tData 0.005 (0.011)\tLoss 0.8517 (0.9418)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [55][50/110], lr: 0.01000\tTime 0.069 (0.083)\tData 0.000 (0.009)\tLoss 0.8895 (0.9320)\tPrec@1 65.625 (60.034)\n",
            "Epoch: [55][60/110], lr: 0.01000\tTime 0.070 (0.082)\tData 0.002 (0.008)\tLoss 0.9858 (0.9342)\tPrec@1 56.250 (59.746)\n",
            "Epoch: [55][70/110], lr: 0.01000\tTime 0.072 (0.081)\tData 0.000 (0.007)\tLoss 0.9012 (0.9319)\tPrec@1 57.812 (59.760)\n",
            "Epoch: [55][80/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.007)\tLoss 0.9608 (0.9272)\tPrec@1 61.719 (60.118)\n",
            "Epoch: [55][90/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.002 (0.006)\tLoss 1.1120 (0.9284)\tPrec@1 50.781 (60.148)\n",
            "Epoch: [55][100/110], lr: 0.01000\tTime 0.067 (0.078)\tData 0.000 (0.006)\tLoss 0.9955 (0.9303)\tPrec@1 53.125 (60.125)\n",
            "Test: [0/100]\tTime 0.264 (0.264)\tLoss 0.9852 (0.9852)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.039 (0.057)\tLoss 1.0067 (1.0012)\tPrec@1 58.000 (56.909)\n",
            "Test: [20/100]\tTime 0.076 (0.046)\tLoss 1.1741 (1.0081)\tPrec@1 50.000 (57.524)\n",
            "Test: [30/100]\tTime 0.041 (0.046)\tLoss 1.1082 (1.0161)\tPrec@1 54.000 (57.097)\n",
            "Test: [40/100]\tTime 0.027 (0.046)\tLoss 0.9507 (1.0135)\tPrec@1 56.000 (57.146)\n",
            "Test: [50/100]\tTime 0.045 (0.046)\tLoss 1.1061 (1.0136)\tPrec@1 54.000 (57.020)\n",
            "Test: [60/100]\tTime 0.057 (0.048)\tLoss 1.1839 (1.0239)\tPrec@1 48.000 (56.754)\n",
            "Test: [70/100]\tTime 0.056 (0.049)\tLoss 0.9555 (1.0210)\tPrec@1 59.000 (56.901)\n",
            "Test: [80/100]\tTime 0.032 (0.049)\tLoss 0.9738 (1.0208)\tPrec@1 58.000 (56.877)\n",
            "Test: [90/100]\tTime 0.069 (0.049)\tLoss 1.0143 (1.0192)\tPrec@1 59.000 (56.747)\n",
            "val Results: Prec@1 56.890 Loss 1.01501\n",
            "Best Prec@1: 56.890\n",
            "\n",
            "Epoch: [56][0/110], lr: 0.01000\tTime 0.575 (0.575)\tData 0.364 (0.364)\tLoss 0.8529 (0.8529)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [56][10/110], lr: 0.01000\tTime 0.067 (0.128)\tData 0.000 (0.034)\tLoss 0.9571 (0.9398)\tPrec@1 58.594 (60.653)\n",
            "Epoch: [56][20/110], lr: 0.01000\tTime 0.062 (0.102)\tData 0.000 (0.019)\tLoss 0.8997 (0.9516)\tPrec@1 64.844 (59.970)\n",
            "Epoch: [56][30/110], lr: 0.01000\tTime 0.075 (0.094)\tData 0.000 (0.013)\tLoss 0.8875 (0.9432)\tPrec@1 61.719 (60.156)\n",
            "Epoch: [56][40/110], lr: 0.01000\tTime 0.076 (0.090)\tData 0.007 (0.011)\tLoss 0.8513 (0.9312)\tPrec@1 63.281 (60.575)\n",
            "Epoch: [56][50/110], lr: 0.01000\tTime 0.106 (0.087)\tData 0.009 (0.009)\tLoss 0.9070 (0.9288)\tPrec@1 60.156 (60.723)\n",
            "Epoch: [56][60/110], lr: 0.01000\tTime 0.071 (0.085)\tData 0.000 (0.008)\tLoss 0.8974 (0.9297)\tPrec@1 56.250 (60.476)\n",
            "Epoch: [56][70/110], lr: 0.01000\tTime 0.073 (0.083)\tData 0.000 (0.007)\tLoss 0.8903 (0.9253)\tPrec@1 67.188 (60.629)\n",
            "Epoch: [56][80/110], lr: 0.01000\tTime 0.075 (0.082)\tData 0.007 (0.007)\tLoss 0.9844 (0.9263)\tPrec@1 60.156 (60.658)\n",
            "Epoch: [56][90/110], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.006)\tLoss 0.9450 (0.9265)\tPrec@1 60.938 (60.766)\n",
            "Epoch: [56][100/110], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.006)\tLoss 0.8528 (0.9260)\tPrec@1 60.156 (60.721)\n",
            "Test: [0/100]\tTime 0.282 (0.282)\tLoss 0.9218 (0.9218)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.033 (0.057)\tLoss 1.0474 (1.0083)\tPrec@1 59.000 (57.364)\n",
            "Test: [20/100]\tTime 0.027 (0.044)\tLoss 1.1422 (1.0118)\tPrec@1 53.000 (57.619)\n",
            "Test: [30/100]\tTime 0.023 (0.040)\tLoss 1.1146 (1.0135)\tPrec@1 53.000 (57.226)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 0.8757 (1.0065)\tPrec@1 63.000 (57.390)\n",
            "Test: [50/100]\tTime 0.066 (0.037)\tLoss 1.0420 (1.0078)\tPrec@1 57.000 (57.255)\n",
            "Test: [60/100]\tTime 0.036 (0.036)\tLoss 1.0479 (1.0146)\tPrec@1 53.000 (57.180)\n",
            "Test: [70/100]\tTime 0.024 (0.036)\tLoss 0.9851 (1.0153)\tPrec@1 60.000 (57.239)\n",
            "Test: [80/100]\tTime 0.024 (0.035)\tLoss 0.9854 (1.0159)\tPrec@1 58.000 (57.370)\n",
            "Test: [90/100]\tTime 0.040 (0.035)\tLoss 1.0177 (1.0129)\tPrec@1 55.000 (57.330)\n",
            "val Results: Prec@1 57.390 Loss 1.00945\n",
            "Best Prec@1: 57.390\n",
            "\n",
            "Epoch: [57][0/110], lr: 0.01000\tTime 0.492 (0.492)\tData 0.298 (0.298)\tLoss 0.8378 (0.8378)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [57][10/110], lr: 0.01000\tTime 0.077 (0.119)\tData 0.000 (0.030)\tLoss 0.8973 (0.9039)\tPrec@1 62.500 (62.358)\n",
            "Epoch: [57][20/110], lr: 0.01000\tTime 0.103 (0.097)\tData 0.000 (0.016)\tLoss 0.8925 (0.9215)\tPrec@1 62.500 (60.900)\n",
            "Epoch: [57][30/110], lr: 0.01000\tTime 0.068 (0.089)\tData 0.000 (0.012)\tLoss 0.9397 (0.9349)\tPrec@1 62.500 (60.207)\n",
            "Epoch: [57][40/110], lr: 0.01000\tTime 0.085 (0.086)\tData 0.007 (0.010)\tLoss 0.9933 (0.9336)\tPrec@1 53.125 (60.175)\n",
            "Epoch: [57][50/110], lr: 0.01000\tTime 0.064 (0.083)\tData 0.000 (0.008)\tLoss 0.9069 (0.9260)\tPrec@1 56.250 (60.524)\n",
            "Epoch: [57][60/110], lr: 0.01000\tTime 0.077 (0.082)\tData 0.007 (0.007)\tLoss 0.8619 (0.9267)\tPrec@1 67.188 (60.528)\n",
            "Epoch: [57][70/110], lr: 0.01000\tTime 0.085 (0.081)\tData 0.000 (0.007)\tLoss 1.0122 (0.9320)\tPrec@1 60.156 (60.508)\n",
            "Epoch: [57][80/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.006 (0.006)\tLoss 0.9315 (0.9313)\tPrec@1 63.281 (60.465)\n",
            "Epoch: [57][90/110], lr: 0.01000\tTime 0.078 (0.079)\tData 0.012 (0.006)\tLoss 0.9236 (0.9254)\tPrec@1 58.594 (60.749)\n",
            "Epoch: [57][100/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.005)\tLoss 0.9073 (0.9234)\tPrec@1 62.500 (60.760)\n",
            "Test: [0/100]\tTime 0.244 (0.244)\tLoss 1.0531 (1.0531)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.029 (0.057)\tLoss 1.0488 (1.0269)\tPrec@1 57.000 (57.091)\n",
            "Test: [20/100]\tTime 0.026 (0.045)\tLoss 1.1142 (1.0216)\tPrec@1 60.000 (57.333)\n",
            "Test: [30/100]\tTime 0.024 (0.041)\tLoss 1.0149 (1.0279)\tPrec@1 54.000 (56.548)\n",
            "Test: [40/100]\tTime 0.023 (0.039)\tLoss 0.9331 (1.0226)\tPrec@1 64.000 (56.927)\n",
            "Test: [50/100]\tTime 0.024 (0.038)\tLoss 1.0444 (1.0171)\tPrec@1 56.000 (57.412)\n",
            "Test: [60/100]\tTime 0.043 (0.037)\tLoss 1.1090 (1.0263)\tPrec@1 49.000 (57.066)\n",
            "Test: [70/100]\tTime 0.044 (0.036)\tLoss 0.9849 (1.0244)\tPrec@1 58.000 (57.197)\n",
            "Test: [80/100]\tTime 0.037 (0.036)\tLoss 0.9687 (1.0238)\tPrec@1 57.000 (57.198)\n",
            "Test: [90/100]\tTime 0.026 (0.036)\tLoss 1.0209 (1.0237)\tPrec@1 52.000 (57.110)\n",
            "val Results: Prec@1 57.300 Loss 1.01819\n",
            "Best Prec@1: 57.390\n",
            "\n",
            "Epoch: [58][0/110], lr: 0.01000\tTime 0.515 (0.515)\tData 0.318 (0.318)\tLoss 0.9729 (0.9729)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [58][10/110], lr: 0.01000\tTime 0.086 (0.116)\tData 0.007 (0.031)\tLoss 0.9760 (0.9636)\tPrec@1 57.812 (60.156)\n",
            "Epoch: [58][20/110], lr: 0.01000\tTime 0.066 (0.096)\tData 0.000 (0.017)\tLoss 0.8980 (0.9388)\tPrec@1 62.500 (60.863)\n",
            "Epoch: [58][30/110], lr: 0.01000\tTime 0.072 (0.089)\tData 0.000 (0.013)\tLoss 0.8139 (0.9352)\tPrec@1 66.406 (60.685)\n",
            "Epoch: [58][40/110], lr: 0.01000\tTime 0.064 (0.085)\tData 0.000 (0.011)\tLoss 0.9650 (0.9298)\tPrec@1 54.688 (60.690)\n",
            "Epoch: [58][50/110], lr: 0.01000\tTime 0.067 (0.084)\tData 0.000 (0.009)\tLoss 0.9510 (0.9345)\tPrec@1 59.375 (60.401)\n",
            "Epoch: [58][60/110], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.008)\tLoss 0.8642 (0.9278)\tPrec@1 63.281 (60.797)\n",
            "Epoch: [58][70/110], lr: 0.01000\tTime 0.084 (0.081)\tData 0.000 (0.007)\tLoss 0.7899 (0.9249)\tPrec@1 64.844 (60.949)\n",
            "Epoch: [58][80/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.007 (0.007)\tLoss 0.8340 (0.9232)\tPrec@1 66.406 (61.073)\n",
            "Epoch: [58][90/110], lr: 0.01000\tTime 0.084 (0.079)\tData 0.000 (0.006)\tLoss 0.8851 (0.9253)\tPrec@1 63.281 (61.006)\n",
            "Epoch: [58][100/110], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.006)\tLoss 0.9089 (0.9257)\tPrec@1 58.594 (60.976)\n",
            "Test: [0/100]\tTime 0.312 (0.312)\tLoss 0.9717 (0.9717)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.023 (0.057)\tLoss 0.9972 (1.0031)\tPrec@1 62.000 (57.455)\n",
            "Test: [20/100]\tTime 0.042 (0.046)\tLoss 1.0910 (0.9909)\tPrec@1 50.000 (57.619)\n",
            "Test: [30/100]\tTime 0.029 (0.041)\tLoss 1.0515 (0.9950)\tPrec@1 51.000 (57.355)\n",
            "Test: [40/100]\tTime 0.022 (0.038)\tLoss 0.9963 (0.9905)\tPrec@1 60.000 (57.390)\n",
            "Test: [50/100]\tTime 0.023 (0.037)\tLoss 1.0422 (0.9925)\tPrec@1 54.000 (57.412)\n",
            "Test: [60/100]\tTime 0.028 (0.036)\tLoss 1.0832 (1.0017)\tPrec@1 51.000 (57.016)\n",
            "Test: [70/100]\tTime 0.024 (0.036)\tLoss 0.9557 (1.0019)\tPrec@1 61.000 (56.972)\n",
            "Test: [80/100]\tTime 0.025 (0.035)\tLoss 0.9782 (1.0010)\tPrec@1 58.000 (57.148)\n",
            "Test: [90/100]\tTime 0.042 (0.034)\tLoss 1.0391 (1.0004)\tPrec@1 63.000 (57.308)\n",
            "val Results: Prec@1 57.390 Loss 0.99711\n",
            "Best Prec@1: 57.390\n",
            "\n",
            "Epoch: [59][0/110], lr: 0.01000\tTime 0.517 (0.517)\tData 0.277 (0.277)\tLoss 0.9296 (0.9296)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [59][10/110], lr: 0.01000\tTime 0.082 (0.118)\tData 0.009 (0.027)\tLoss 0.8733 (0.9286)\tPrec@1 58.594 (60.014)\n",
            "Epoch: [59][20/110], lr: 0.01000\tTime 0.066 (0.098)\tData 0.000 (0.015)\tLoss 0.9554 (0.9313)\tPrec@1 60.156 (60.082)\n",
            "Epoch: [59][30/110], lr: 0.01000\tTime 0.063 (0.090)\tData 0.000 (0.012)\tLoss 0.9634 (0.9300)\tPrec@1 60.156 (60.484)\n",
            "Epoch: [59][40/110], lr: 0.01000\tTime 0.134 (0.091)\tData 0.000 (0.010)\tLoss 0.9660 (0.9196)\tPrec@1 59.375 (60.747)\n",
            "Epoch: [59][50/110], lr: 0.01000\tTime 0.105 (0.094)\tData 0.000 (0.008)\tLoss 0.9751 (0.9184)\tPrec@1 53.906 (60.769)\n",
            "Epoch: [59][60/110], lr: 0.01000\tTime 0.135 (0.097)\tData 0.012 (0.008)\tLoss 0.9087 (0.9164)\tPrec@1 61.719 (60.873)\n",
            "Epoch: [59][70/110], lr: 0.01000\tTime 0.085 (0.098)\tData 0.000 (0.007)\tLoss 0.8285 (0.9145)\tPrec@1 63.281 (61.092)\n",
            "Epoch: [59][80/110], lr: 0.01000\tTime 0.072 (0.097)\tData 0.005 (0.007)\tLoss 1.0391 (0.9181)\tPrec@1 57.812 (60.918)\n",
            "Epoch: [59][90/110], lr: 0.01000\tTime 0.072 (0.094)\tData 0.004 (0.006)\tLoss 1.0229 (0.9171)\tPrec@1 56.250 (60.998)\n",
            "Epoch: [59][100/110], lr: 0.01000\tTime 0.074 (0.092)\tData 0.007 (0.006)\tLoss 0.9724 (0.9172)\tPrec@1 59.375 (60.961)\n",
            "Test: [0/100]\tTime 0.314 (0.314)\tLoss 0.8958 (0.8958)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.022 (0.057)\tLoss 1.0611 (0.9922)\tPrec@1 49.000 (57.182)\n",
            "Test: [20/100]\tTime 0.026 (0.046)\tLoss 1.0337 (0.9966)\tPrec@1 53.000 (57.857)\n",
            "Test: [30/100]\tTime 0.035 (0.041)\tLoss 0.9556 (1.0033)\tPrec@1 58.000 (57.258)\n",
            "Test: [40/100]\tTime 0.034 (0.039)\tLoss 0.9612 (0.9981)\tPrec@1 59.000 (57.463)\n",
            "Test: [50/100]\tTime 0.043 (0.038)\tLoss 1.0341 (0.9938)\tPrec@1 62.000 (57.863)\n",
            "Test: [60/100]\tTime 0.049 (0.037)\tLoss 1.0830 (1.0000)\tPrec@1 48.000 (57.705)\n",
            "Test: [70/100]\tTime 0.022 (0.036)\tLoss 0.9466 (0.9987)\tPrec@1 62.000 (57.690)\n",
            "Test: [80/100]\tTime 0.054 (0.035)\tLoss 0.9211 (0.9966)\tPrec@1 60.000 (57.963)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 0.9102 (0.9954)\tPrec@1 62.000 (58.055)\n",
            "val Results: Prec@1 58.250 Loss 0.99146\n",
            "Best Prec@1: 58.250\n",
            "\n",
            "Epoch: [60][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.283 (0.283)\tLoss 0.8271 (0.8271)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [60][10/110], lr: 0.01000\tTime 0.067 (0.117)\tData 0.000 (0.027)\tLoss 0.8172 (0.9013)\tPrec@1 64.844 (62.926)\n",
            "Epoch: [60][20/110], lr: 0.01000\tTime 0.083 (0.096)\tData 0.000 (0.015)\tLoss 0.9445 (0.9200)\tPrec@1 59.375 (61.347)\n",
            "Epoch: [60][30/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.011)\tLoss 1.0012 (0.9166)\tPrec@1 58.594 (61.366)\n",
            "Epoch: [60][40/110], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.009)\tLoss 0.9552 (0.9122)\tPrec@1 55.469 (61.261)\n",
            "Epoch: [60][50/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.008)\tLoss 0.9389 (0.9146)\tPrec@1 57.812 (61.183)\n",
            "Epoch: [60][60/110], lr: 0.01000\tTime 0.066 (0.081)\tData 0.005 (0.007)\tLoss 0.8339 (0.9137)\tPrec@1 65.625 (61.335)\n",
            "Epoch: [60][70/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.007 (0.007)\tLoss 1.0150 (0.9160)\tPrec@1 53.906 (61.246)\n",
            "Epoch: [60][80/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.009 (0.006)\tLoss 0.8933 (0.9093)\tPrec@1 64.844 (61.400)\n",
            "Epoch: [60][90/110], lr: 0.01000\tTime 0.076 (0.078)\tData 0.000 (0.006)\tLoss 0.9021 (0.9042)\tPrec@1 63.281 (61.504)\n",
            "Epoch: [60][100/110], lr: 0.01000\tTime 0.064 (0.079)\tData 0.000 (0.006)\tLoss 0.9543 (0.9042)\tPrec@1 57.031 (61.580)\n",
            "Test: [0/100]\tTime 0.403 (0.403)\tLoss 0.9496 (0.9496)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.033 (0.068)\tLoss 1.0151 (1.0026)\tPrec@1 63.000 (57.182)\n",
            "Test: [20/100]\tTime 0.023 (0.057)\tLoss 1.0949 (0.9926)\tPrec@1 56.000 (58.048)\n",
            "Test: [30/100]\tTime 0.031 (0.053)\tLoss 1.0601 (1.0032)\tPrec@1 54.000 (57.452)\n",
            "Test: [40/100]\tTime 0.022 (0.047)\tLoss 0.9292 (0.9986)\tPrec@1 63.000 (57.561)\n",
            "Test: [50/100]\tTime 0.022 (0.046)\tLoss 1.0505 (1.0013)\tPrec@1 54.000 (57.451)\n",
            "Test: [60/100]\tTime 0.027 (0.044)\tLoss 1.0941 (1.0075)\tPrec@1 52.000 (57.197)\n",
            "Test: [70/100]\tTime 0.028 (0.043)\tLoss 0.9180 (1.0077)\tPrec@1 61.000 (57.085)\n",
            "Test: [80/100]\tTime 0.024 (0.042)\tLoss 1.0083 (1.0094)\tPrec@1 58.000 (57.185)\n",
            "Test: [90/100]\tTime 0.023 (0.041)\tLoss 1.0173 (1.0084)\tPrec@1 56.000 (57.253)\n",
            "val Results: Prec@1 57.370 Loss 1.00169\n",
            "Best Prec@1: 58.250\n",
            "\n",
            "Epoch: [61][0/110], lr: 0.01000\tTime 0.485 (0.485)\tData 0.316 (0.316)\tLoss 0.8771 (0.8771)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [61][10/110], lr: 0.01000\tTime 0.100 (0.130)\tData 0.000 (0.032)\tLoss 1.0321 (0.9050)\tPrec@1 55.469 (62.926)\n",
            "Epoch: [61][20/110], lr: 0.01000\tTime 0.115 (0.110)\tData 0.000 (0.018)\tLoss 0.8985 (0.9124)\tPrec@1 59.375 (61.682)\n",
            "Epoch: [61][30/110], lr: 0.01000\tTime 0.070 (0.102)\tData 0.000 (0.013)\tLoss 1.0000 (0.9179)\tPrec@1 58.594 (61.416)\n",
            "Epoch: [61][40/110], lr: 0.01000\tTime 0.101 (0.099)\tData 0.000 (0.010)\tLoss 0.8551 (0.9054)\tPrec@1 65.625 (61.871)\n",
            "Epoch: [61][50/110], lr: 0.01000\tTime 0.114 (0.097)\tData 0.000 (0.009)\tLoss 0.9576 (0.9032)\tPrec@1 60.156 (61.566)\n",
            "Epoch: [61][60/110], lr: 0.01000\tTime 0.064 (0.094)\tData 0.000 (0.008)\tLoss 0.9337 (0.9035)\tPrec@1 58.594 (61.539)\n",
            "Epoch: [61][70/110], lr: 0.01000\tTime 0.074 (0.091)\tData 0.010 (0.007)\tLoss 0.9072 (0.9018)\tPrec@1 67.188 (61.708)\n",
            "Epoch: [61][80/110], lr: 0.01000\tTime 0.102 (0.091)\tData 0.000 (0.007)\tLoss 1.0440 (0.9087)\tPrec@1 60.156 (61.478)\n",
            "Epoch: [61][90/110], lr: 0.01000\tTime 0.123 (0.091)\tData 0.000 (0.006)\tLoss 1.1234 (0.9103)\tPrec@1 55.469 (61.513)\n",
            "Epoch: [61][100/110], lr: 0.01000\tTime 0.067 (0.090)\tData 0.000 (0.006)\tLoss 0.7827 (0.9091)\tPrec@1 65.625 (61.463)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.8984 (0.8984)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.024 (0.067)\tLoss 1.0141 (0.9859)\tPrec@1 60.000 (58.273)\n",
            "Test: [20/100]\tTime 0.032 (0.053)\tLoss 1.0499 (0.9780)\tPrec@1 58.000 (59.095)\n",
            "Test: [30/100]\tTime 0.022 (0.047)\tLoss 1.0270 (0.9837)\tPrec@1 58.000 (58.677)\n",
            "Test: [40/100]\tTime 0.049 (0.044)\tLoss 0.9363 (0.9806)\tPrec@1 56.000 (58.512)\n",
            "Test: [50/100]\tTime 0.024 (0.041)\tLoss 1.0433 (0.9835)\tPrec@1 51.000 (58.039)\n",
            "Test: [60/100]\tTime 0.046 (0.040)\tLoss 1.0694 (0.9906)\tPrec@1 52.000 (57.754)\n",
            "Test: [70/100]\tTime 0.032 (0.039)\tLoss 0.9509 (0.9887)\tPrec@1 64.000 (57.845)\n",
            "Test: [80/100]\tTime 0.021 (0.038)\tLoss 0.9143 (0.9873)\tPrec@1 61.000 (57.852)\n",
            "Test: [90/100]\tTime 0.022 (0.037)\tLoss 1.0403 (0.9880)\tPrec@1 57.000 (57.714)\n",
            "val Results: Prec@1 58.040 Loss 0.98206\n",
            "Best Prec@1: 58.250\n",
            "\n",
            "Epoch: [62][0/110], lr: 0.01000\tTime 0.615 (0.615)\tData 0.423 (0.423)\tLoss 0.8421 (0.8421)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [62][10/110], lr: 0.01000\tTime 0.124 (0.137)\tData 0.000 (0.040)\tLoss 0.9751 (0.9111)\tPrec@1 60.156 (61.009)\n",
            "Epoch: [62][20/110], lr: 0.01000\tTime 0.072 (0.114)\tData 0.006 (0.022)\tLoss 0.9234 (0.9198)\tPrec@1 57.812 (60.751)\n",
            "Epoch: [62][30/110], lr: 0.01000\tTime 0.065 (0.102)\tData 0.000 (0.016)\tLoss 0.9559 (0.9109)\tPrec@1 57.812 (61.442)\n",
            "Epoch: [62][40/110], lr: 0.01000\tTime 0.064 (0.095)\tData 0.000 (0.013)\tLoss 0.8901 (0.9233)\tPrec@1 59.375 (60.709)\n",
            "Epoch: [62][50/110], lr: 0.01000\tTime 0.069 (0.092)\tData 0.003 (0.011)\tLoss 1.0046 (0.9119)\tPrec@1 55.469 (61.152)\n",
            "Epoch: [62][60/110], lr: 0.01000\tTime 0.086 (0.089)\tData 0.006 (0.010)\tLoss 0.9547 (0.9092)\tPrec@1 59.375 (61.411)\n",
            "Epoch: [62][70/110], lr: 0.01000\tTime 0.075 (0.086)\tData 0.005 (0.009)\tLoss 0.8497 (0.9066)\tPrec@1 60.938 (61.609)\n",
            "Epoch: [62][80/110], lr: 0.01000\tTime 0.095 (0.085)\tData 0.000 (0.009)\tLoss 1.0406 (0.9058)\tPrec@1 56.250 (61.574)\n",
            "Epoch: [62][90/110], lr: 0.01000\tTime 0.130 (0.085)\tData 0.016 (0.008)\tLoss 0.8608 (0.9038)\tPrec@1 64.844 (61.504)\n",
            "Epoch: [62][100/110], lr: 0.01000\tTime 0.118 (0.088)\tData 0.007 (0.008)\tLoss 0.9578 (0.9002)\tPrec@1 63.281 (61.765)\n",
            "Test: [0/100]\tTime 0.462 (0.462)\tLoss 1.0132 (1.0132)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.066 (0.120)\tLoss 0.9977 (1.0177)\tPrec@1 59.000 (57.909)\n",
            "Test: [20/100]\tTime 0.039 (0.093)\tLoss 1.1008 (1.0028)\tPrec@1 58.000 (58.429)\n",
            "Test: [30/100]\tTime 0.047 (0.075)\tLoss 1.0497 (1.0049)\tPrec@1 59.000 (58.194)\n",
            "Test: [40/100]\tTime 0.026 (0.067)\tLoss 0.9425 (0.9977)\tPrec@1 66.000 (58.585)\n",
            "Test: [50/100]\tTime 0.040 (0.062)\tLoss 0.9486 (0.9985)\tPrec@1 61.000 (58.255)\n",
            "Test: [60/100]\tTime 0.022 (0.057)\tLoss 1.0686 (1.0079)\tPrec@1 46.000 (57.639)\n",
            "Test: [70/100]\tTime 0.026 (0.055)\tLoss 1.0594 (1.0098)\tPrec@1 55.000 (57.197)\n",
            "Test: [80/100]\tTime 0.022 (0.052)\tLoss 0.9715 (1.0090)\tPrec@1 57.000 (57.333)\n",
            "Test: [90/100]\tTime 0.022 (0.051)\tLoss 0.9909 (1.0070)\tPrec@1 58.000 (57.385)\n",
            "val Results: Prec@1 57.590 Loss 1.00202\n",
            "Best Prec@1: 58.250\n",
            "\n",
            "Epoch: [63][0/110], lr: 0.01000\tTime 0.502 (0.502)\tData 0.260 (0.260)\tLoss 0.8694 (0.8694)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [63][10/110], lr: 0.01000\tTime 0.064 (0.115)\tData 0.000 (0.027)\tLoss 0.9133 (0.9121)\tPrec@1 59.375 (61.364)\n",
            "Epoch: [63][20/110], lr: 0.01000\tTime 0.079 (0.094)\tData 0.000 (0.014)\tLoss 1.0331 (0.9108)\tPrec@1 57.812 (61.793)\n",
            "Epoch: [63][30/110], lr: 0.01000\tTime 0.068 (0.086)\tData 0.000 (0.011)\tLoss 0.9916 (0.9149)\tPrec@1 56.250 (61.568)\n",
            "Epoch: [63][40/110], lr: 0.01000\tTime 0.076 (0.083)\tData 0.007 (0.009)\tLoss 0.8312 (0.9129)\tPrec@1 63.281 (61.242)\n",
            "Epoch: [63][50/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.007 (0.008)\tLoss 0.9213 (0.9198)\tPrec@1 63.281 (60.738)\n",
            "Epoch: [63][60/110], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.007)\tLoss 0.9507 (0.9144)\tPrec@1 56.250 (60.809)\n",
            "Epoch: [63][70/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.007)\tLoss 0.8041 (0.9115)\tPrec@1 67.188 (61.070)\n",
            "Epoch: [63][80/110], lr: 0.01000\tTime 0.076 (0.078)\tData 0.007 (0.007)\tLoss 0.8176 (0.9116)\tPrec@1 66.406 (61.082)\n",
            "Epoch: [63][90/110], lr: 0.01000\tTime 0.068 (0.077)\tData 0.000 (0.006)\tLoss 0.8089 (0.9086)\tPrec@1 69.531 (61.221)\n",
            "Epoch: [63][100/110], lr: 0.01000\tTime 0.080 (0.077)\tData 0.007 (0.006)\tLoss 0.7916 (0.9055)\tPrec@1 62.500 (61.463)\n",
            "Test: [0/100]\tTime 0.385 (0.385)\tLoss 0.9148 (0.9148)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.030 (0.074)\tLoss 0.9906 (0.9869)\tPrec@1 58.000 (58.364)\n",
            "Test: [20/100]\tTime 0.036 (0.058)\tLoss 1.1375 (0.9822)\tPrec@1 58.000 (59.190)\n",
            "Test: [30/100]\tTime 0.031 (0.051)\tLoss 1.1014 (0.9979)\tPrec@1 50.000 (58.129)\n",
            "Test: [40/100]\tTime 0.037 (0.049)\tLoss 0.9727 (0.9974)\tPrec@1 60.000 (58.146)\n",
            "Test: [50/100]\tTime 0.027 (0.047)\tLoss 1.0480 (0.9981)\tPrec@1 52.000 (58.098)\n",
            "Test: [60/100]\tTime 0.030 (0.045)\tLoss 1.1382 (1.0048)\tPrec@1 49.000 (57.803)\n",
            "Test: [70/100]\tTime 0.038 (0.044)\tLoss 0.9169 (1.0026)\tPrec@1 60.000 (58.014)\n",
            "Test: [80/100]\tTime 0.044 (0.043)\tLoss 0.9610 (1.0025)\tPrec@1 57.000 (57.889)\n",
            "Test: [90/100]\tTime 0.049 (0.043)\tLoss 0.9453 (0.9981)\tPrec@1 64.000 (58.132)\n",
            "val Results: Prec@1 58.300 Loss 0.99691\n",
            "Best Prec@1: 58.300\n",
            "\n",
            "Epoch: [64][0/110], lr: 0.01000\tTime 0.493 (0.493)\tData 0.356 (0.356)\tLoss 0.8487 (0.8487)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [64][10/110], lr: 0.01000\tTime 0.078 (0.115)\tData 0.013 (0.036)\tLoss 0.9171 (0.9159)\tPrec@1 62.500 (62.358)\n",
            "Epoch: [64][20/110], lr: 0.01000\tTime 0.080 (0.095)\tData 0.007 (0.020)\tLoss 0.9984 (0.9092)\tPrec@1 56.250 (61.644)\n",
            "Epoch: [64][30/110], lr: 0.01000\tTime 0.065 (0.087)\tData 0.000 (0.015)\tLoss 0.8768 (0.8953)\tPrec@1 63.281 (62.273)\n",
            "Epoch: [64][40/110], lr: 0.01000\tTime 0.070 (0.084)\tData 0.007 (0.012)\tLoss 0.9255 (0.9022)\tPrec@1 59.375 (62.062)\n",
            "Epoch: [64][50/110], lr: 0.01000\tTime 0.061 (0.082)\tData 0.000 (0.011)\tLoss 0.9030 (0.9036)\tPrec@1 61.719 (61.918)\n",
            "Epoch: [64][60/110], lr: 0.01000\tTime 0.098 (0.081)\tData 0.000 (0.010)\tLoss 0.9413 (0.9016)\tPrec@1 57.812 (62.052)\n",
            "Epoch: [64][70/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.001 (0.009)\tLoss 0.8482 (0.9017)\tPrec@1 64.844 (61.895)\n",
            "Epoch: [64][80/110], lr: 0.01000\tTime 0.064 (0.081)\tData 0.000 (0.008)\tLoss 0.8883 (0.9018)\tPrec@1 60.938 (61.834)\n",
            "Epoch: [64][90/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.002 (0.008)\tLoss 0.8543 (0.9005)\tPrec@1 65.625 (61.684)\n",
            "Epoch: [64][100/110], lr: 0.01000\tTime 0.086 (0.082)\tData 0.000 (0.007)\tLoss 0.9857 (0.8996)\tPrec@1 59.375 (61.904)\n",
            "Test: [0/100]\tTime 0.331 (0.331)\tLoss 0.9198 (0.9198)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.043 (0.080)\tLoss 1.0839 (1.0157)\tPrec@1 51.000 (57.364)\n",
            "Test: [20/100]\tTime 0.056 (0.059)\tLoss 1.1022 (1.0099)\tPrec@1 61.000 (57.667)\n",
            "Test: [30/100]\tTime 0.022 (0.049)\tLoss 1.0392 (1.0172)\tPrec@1 57.000 (57.387)\n",
            "Test: [40/100]\tTime 0.025 (0.046)\tLoss 0.9051 (1.0085)\tPrec@1 65.000 (57.683)\n",
            "Test: [50/100]\tTime 0.020 (0.043)\tLoss 1.1024 (1.0083)\tPrec@1 51.000 (57.255)\n",
            "Test: [60/100]\tTime 0.036 (0.042)\tLoss 1.0898 (1.0186)\tPrec@1 51.000 (56.672)\n",
            "Test: [70/100]\tTime 0.034 (0.040)\tLoss 1.0179 (1.0184)\tPrec@1 59.000 (56.606)\n",
            "Test: [80/100]\tTime 0.030 (0.040)\tLoss 0.9559 (1.0154)\tPrec@1 56.000 (56.728)\n",
            "Test: [90/100]\tTime 0.021 (0.039)\tLoss 1.0330 (1.0136)\tPrec@1 60.000 (56.747)\n",
            "val Results: Prec@1 56.980 Loss 1.00713\n",
            "Best Prec@1: 58.300\n",
            "\n",
            "Epoch: [65][0/110], lr: 0.01000\tTime 0.631 (0.631)\tData 0.462 (0.462)\tLoss 0.8429 (0.8429)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [65][10/110], lr: 0.01000\tTime 0.149 (0.152)\tData 0.000 (0.045)\tLoss 0.9113 (0.9173)\tPrec@1 65.625 (62.287)\n",
            "Epoch: [65][20/110], lr: 0.01000\tTime 0.074 (0.119)\tData 0.005 (0.025)\tLoss 0.8046 (0.8994)\tPrec@1 65.625 (62.388)\n",
            "Epoch: [65][30/110], lr: 0.01000\tTime 0.069 (0.104)\tData 0.000 (0.018)\tLoss 0.8422 (0.8978)\tPrec@1 66.406 (62.298)\n",
            "Epoch: [65][40/110], lr: 0.01000\tTime 0.097 (0.097)\tData 0.011 (0.014)\tLoss 0.8963 (0.8973)\tPrec@1 60.938 (62.176)\n",
            "Epoch: [65][50/110], lr: 0.01000\tTime 0.081 (0.092)\tData 0.000 (0.012)\tLoss 0.8873 (0.8991)\tPrec@1 62.500 (61.903)\n",
            "Epoch: [65][60/110], lr: 0.01000\tTime 0.082 (0.089)\tData 0.012 (0.011)\tLoss 0.8784 (0.8968)\tPrec@1 60.938 (62.205)\n",
            "Epoch: [65][70/110], lr: 0.01000\tTime 0.092 (0.087)\tData 0.010 (0.010)\tLoss 0.8015 (0.8966)\tPrec@1 68.750 (62.335)\n",
            "Epoch: [65][80/110], lr: 0.01000\tTime 0.073 (0.085)\tData 0.007 (0.009)\tLoss 0.7788 (0.8924)\tPrec@1 67.188 (62.461)\n",
            "Epoch: [65][90/110], lr: 0.01000\tTime 0.080 (0.086)\tData 0.000 (0.008)\tLoss 0.8730 (0.8940)\tPrec@1 63.281 (62.388)\n",
            "Epoch: [65][100/110], lr: 0.01000\tTime 0.063 (0.085)\tData 0.000 (0.008)\tLoss 0.9743 (0.8967)\tPrec@1 55.469 (62.245)\n",
            "Test: [0/100]\tTime 0.269 (0.269)\tLoss 0.9135 (0.9135)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.029 (0.067)\tLoss 1.0788 (0.9968)\tPrec@1 54.000 (58.636)\n",
            "Test: [20/100]\tTime 0.039 (0.052)\tLoss 1.0891 (0.9893)\tPrec@1 55.000 (58.381)\n",
            "Test: [30/100]\tTime 0.128 (0.049)\tLoss 1.0745 (1.0008)\tPrec@1 56.000 (57.935)\n",
            "Test: [40/100]\tTime 0.032 (0.046)\tLoss 0.9448 (0.9973)\tPrec@1 59.000 (58.195)\n",
            "Test: [50/100]\tTime 0.053 (0.045)\tLoss 1.0523 (1.0014)\tPrec@1 56.000 (57.608)\n",
            "Test: [60/100]\tTime 0.051 (0.046)\tLoss 1.1487 (1.0081)\tPrec@1 58.000 (57.852)\n",
            "Test: [70/100]\tTime 0.056 (0.047)\tLoss 0.9480 (1.0073)\tPrec@1 56.000 (57.577)\n",
            "Test: [80/100]\tTime 0.062 (0.047)\tLoss 0.8968 (1.0071)\tPrec@1 58.000 (57.630)\n",
            "Test: [90/100]\tTime 0.049 (0.048)\tLoss 0.9585 (1.0047)\tPrec@1 61.000 (57.703)\n",
            "val Results: Prec@1 57.950 Loss 0.99807\n",
            "Best Prec@1: 58.300\n",
            "\n",
            "Epoch: [66][0/110], lr: 0.01000\tTime 0.764 (0.764)\tData 0.488 (0.488)\tLoss 0.7620 (0.7620)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [66][10/110], lr: 0.01000\tTime 0.077 (0.143)\tData 0.006 (0.047)\tLoss 1.0104 (0.8846)\tPrec@1 53.125 (62.571)\n",
            "Epoch: [66][20/110], lr: 0.01000\tTime 0.068 (0.110)\tData 0.003 (0.027)\tLoss 0.6906 (0.8824)\tPrec@1 75.781 (62.649)\n",
            "Epoch: [66][30/110], lr: 0.01000\tTime 0.072 (0.099)\tData 0.000 (0.019)\tLoss 0.8129 (0.8896)\tPrec@1 67.188 (62.223)\n",
            "Epoch: [66][40/110], lr: 0.01000\tTime 0.078 (0.094)\tData 0.007 (0.015)\tLoss 0.9545 (0.8913)\tPrec@1 57.031 (61.890)\n",
            "Epoch: [66][50/110], lr: 0.01000\tTime 0.082 (0.091)\tData 0.007 (0.013)\tLoss 0.8167 (0.8891)\tPrec@1 67.969 (62.194)\n",
            "Epoch: [66][60/110], lr: 0.01000\tTime 0.065 (0.088)\tData 0.000 (0.011)\tLoss 0.8747 (0.8929)\tPrec@1 57.031 (61.680)\n",
            "Epoch: [66][70/110], lr: 0.01000\tTime 0.075 (0.086)\tData 0.006 (0.010)\tLoss 0.7531 (0.8922)\tPrec@1 69.531 (61.862)\n",
            "Epoch: [66][80/110], lr: 0.01000\tTime 0.078 (0.084)\tData 0.012 (0.009)\tLoss 0.8537 (0.8872)\tPrec@1 64.844 (62.114)\n",
            "Epoch: [66][90/110], lr: 0.01000\tTime 0.082 (0.086)\tData 0.000 (0.009)\tLoss 0.8703 (0.8916)\tPrec@1 62.500 (61.942)\n",
            "Epoch: [66][100/110], lr: 0.01000\tTime 0.076 (0.086)\tData 0.003 (0.008)\tLoss 0.9624 (0.8957)\tPrec@1 56.250 (61.750)\n",
            "Test: [0/100]\tTime 0.379 (0.379)\tLoss 0.9150 (0.9150)\tPrec@1 58.000 (58.000)\n",
            "Test: [10/100]\tTime 0.023 (0.068)\tLoss 1.0850 (0.9953)\tPrec@1 53.000 (58.273)\n",
            "Test: [20/100]\tTime 0.059 (0.057)\tLoss 1.0862 (0.9880)\tPrec@1 54.000 (58.333)\n",
            "Test: [30/100]\tTime 0.024 (0.049)\tLoss 0.9774 (0.9931)\tPrec@1 57.000 (58.258)\n",
            "Test: [40/100]\tTime 0.043 (0.048)\tLoss 0.8831 (0.9868)\tPrec@1 64.000 (58.585)\n",
            "Test: [50/100]\tTime 0.030 (0.045)\tLoss 1.1310 (0.9900)\tPrec@1 56.000 (58.745)\n",
            "Test: [60/100]\tTime 0.045 (0.043)\tLoss 1.0499 (0.9954)\tPrec@1 53.000 (58.426)\n",
            "Test: [70/100]\tTime 0.025 (0.041)\tLoss 0.9220 (0.9951)\tPrec@1 57.000 (58.169)\n",
            "Test: [80/100]\tTime 0.025 (0.040)\tLoss 0.9771 (0.9972)\tPrec@1 59.000 (58.136)\n",
            "Test: [90/100]\tTime 0.024 (0.039)\tLoss 0.9846 (0.9927)\tPrec@1 56.000 (58.407)\n",
            "val Results: Prec@1 58.660 Loss 0.98691\n",
            "Best Prec@1: 58.660\n",
            "\n",
            "Epoch: [67][0/110], lr: 0.01000\tTime 0.460 (0.460)\tData 0.297 (0.297)\tLoss 0.8529 (0.8529)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [67][10/110], lr: 0.01000\tTime 0.070 (0.114)\tData 0.005 (0.029)\tLoss 0.9860 (0.9102)\tPrec@1 56.250 (62.287)\n",
            "Epoch: [67][20/110], lr: 0.01000\tTime 0.065 (0.094)\tData 0.001 (0.017)\tLoss 0.7844 (0.8851)\tPrec@1 65.625 (62.798)\n",
            "Epoch: [67][30/110], lr: 0.01000\tTime 0.076 (0.087)\tData 0.011 (0.012)\tLoss 0.8673 (0.8935)\tPrec@1 61.719 (62.424)\n",
            "Epoch: [67][40/110], lr: 0.01000\tTime 0.070 (0.084)\tData 0.000 (0.010)\tLoss 1.0433 (0.8843)\tPrec@1 59.375 (62.748)\n",
            "Epoch: [67][50/110], lr: 0.01000\tTime 0.065 (0.082)\tData 0.000 (0.009)\tLoss 0.7867 (0.8827)\tPrec@1 68.750 (62.914)\n",
            "Epoch: [67][60/110], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.008)\tLoss 0.8929 (0.8797)\tPrec@1 63.281 (63.102)\n",
            "Epoch: [67][70/110], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.007)\tLoss 1.0567 (0.8833)\tPrec@1 56.250 (63.072)\n",
            "Epoch: [67][80/110], lr: 0.01000\tTime 0.086 (0.079)\tData 0.000 (0.006)\tLoss 0.8893 (0.8882)\tPrec@1 62.500 (62.847)\n",
            "Epoch: [67][90/110], lr: 0.01000\tTime 0.119 (0.081)\tData 0.000 (0.006)\tLoss 0.8721 (0.8882)\tPrec@1 58.594 (62.723)\n",
            "Epoch: [67][100/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.006 (0.005)\tLoss 0.8145 (0.8881)\tPrec@1 67.969 (62.717)\n",
            "Test: [0/100]\tTime 0.355 (0.355)\tLoss 1.0072 (1.0072)\tPrec@1 57.000 (57.000)\n",
            "Test: [10/100]\tTime 0.024 (0.070)\tLoss 0.9632 (0.9860)\tPrec@1 63.000 (57.818)\n",
            "Test: [20/100]\tTime 0.065 (0.056)\tLoss 1.0204 (0.9734)\tPrec@1 56.000 (58.190)\n",
            "Test: [30/100]\tTime 0.023 (0.049)\tLoss 0.9998 (0.9828)\tPrec@1 54.000 (57.677)\n",
            "Test: [40/100]\tTime 0.036 (0.046)\tLoss 0.9172 (0.9787)\tPrec@1 60.000 (57.732)\n",
            "Test: [50/100]\tTime 0.023 (0.044)\tLoss 1.0572 (0.9770)\tPrec@1 53.000 (58.176)\n",
            "Test: [60/100]\tTime 0.045 (0.042)\tLoss 1.0498 (0.9815)\tPrec@1 52.000 (57.902)\n",
            "Test: [70/100]\tTime 0.028 (0.040)\tLoss 0.9657 (0.9807)\tPrec@1 59.000 (57.944)\n",
            "Test: [80/100]\tTime 0.040 (0.040)\tLoss 0.9453 (0.9800)\tPrec@1 61.000 (58.099)\n",
            "Test: [90/100]\tTime 0.023 (0.039)\tLoss 0.9939 (0.9783)\tPrec@1 61.000 (58.198)\n",
            "val Results: Prec@1 58.530 Loss 0.97228\n",
            "Best Prec@1: 58.660\n",
            "\n",
            "Epoch: [68][0/110], lr: 0.01000\tTime 0.568 (0.568)\tData 0.379 (0.379)\tLoss 0.7932 (0.7932)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [68][10/110], lr: 0.01000\tTime 0.073 (0.135)\tData 0.000 (0.037)\tLoss 0.8239 (0.8548)\tPrec@1 69.531 (64.489)\n",
            "Epoch: [68][20/110], lr: 0.01000\tTime 0.143 (0.114)\tData 0.007 (0.021)\tLoss 0.7831 (0.8681)\tPrec@1 70.312 (63.876)\n",
            "Epoch: [68][30/110], lr: 0.01000\tTime 0.096 (0.105)\tData 0.000 (0.015)\tLoss 0.9010 (0.8751)\tPrec@1 61.719 (63.533)\n",
            "Epoch: [68][40/110], lr: 0.01000\tTime 0.065 (0.099)\tData 0.000 (0.012)\tLoss 0.9452 (0.8738)\tPrec@1 58.594 (63.624)\n",
            "Epoch: [68][50/110], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.010)\tLoss 0.8358 (0.8768)\tPrec@1 64.844 (63.557)\n",
            "Epoch: [68][60/110], lr: 0.01000\tTime 0.067 (0.090)\tData 0.000 (0.009)\tLoss 0.8112 (0.8775)\tPrec@1 69.531 (63.627)\n",
            "Epoch: [68][70/110], lr: 0.01000\tTime 0.111 (0.090)\tData 0.007 (0.008)\tLoss 0.8592 (0.8835)\tPrec@1 64.844 (63.413)\n",
            "Epoch: [68][80/110], lr: 0.01000\tTime 0.144 (0.089)\tData 0.007 (0.007)\tLoss 0.8035 (0.8809)\tPrec@1 62.500 (63.387)\n",
            "Epoch: [68][90/110], lr: 0.01000\tTime 0.067 (0.089)\tData 0.000 (0.006)\tLoss 0.8161 (0.8805)\tPrec@1 66.406 (63.290)\n",
            "Epoch: [68][100/110], lr: 0.01000\tTime 0.068 (0.088)\tData 0.000 (0.006)\tLoss 0.9182 (0.8811)\tPrec@1 58.594 (63.165)\n",
            "Test: [0/100]\tTime 0.349 (0.349)\tLoss 0.8441 (0.8441)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.022 (0.065)\tLoss 1.0089 (0.9597)\tPrec@1 56.000 (60.182)\n",
            "Test: [20/100]\tTime 0.052 (0.052)\tLoss 1.0332 (0.9531)\tPrec@1 51.000 (60.810)\n",
            "Test: [30/100]\tTime 0.023 (0.044)\tLoss 1.0166 (0.9688)\tPrec@1 56.000 (59.065)\n",
            "Test: [40/100]\tTime 0.024 (0.042)\tLoss 0.9636 (0.9687)\tPrec@1 64.000 (58.976)\n",
            "Test: [50/100]\tTime 0.023 (0.040)\tLoss 1.0174 (0.9708)\tPrec@1 54.000 (58.863)\n",
            "Test: [60/100]\tTime 0.028 (0.039)\tLoss 1.0235 (0.9797)\tPrec@1 55.000 (58.607)\n",
            "Test: [70/100]\tTime 0.022 (0.038)\tLoss 0.9769 (0.9798)\tPrec@1 61.000 (58.451)\n",
            "Test: [80/100]\tTime 0.026 (0.038)\tLoss 0.9513 (0.9797)\tPrec@1 61.000 (58.679)\n",
            "Test: [90/100]\tTime 0.021 (0.037)\tLoss 1.0359 (0.9787)\tPrec@1 56.000 (58.747)\n",
            "val Results: Prec@1 59.030 Loss 0.97433\n",
            "Best Prec@1: 59.030\n",
            "\n",
            "Epoch: [69][0/110], lr: 0.01000\tTime 0.653 (0.653)\tData 0.434 (0.434)\tLoss 0.9547 (0.9547)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [69][10/110], lr: 0.01000\tTime 0.104 (0.181)\tData 0.007 (0.047)\tLoss 0.8386 (0.8752)\tPrec@1 63.281 (62.642)\n",
            "Epoch: [69][20/110], lr: 0.01000\tTime 0.084 (0.148)\tData 0.008 (0.028)\tLoss 0.8924 (0.8918)\tPrec@1 59.375 (62.314)\n",
            "Epoch: [69][30/110], lr: 0.01000\tTime 0.071 (0.126)\tData 0.000 (0.020)\tLoss 0.8451 (0.8907)\tPrec@1 65.625 (62.399)\n",
            "Epoch: [69][40/110], lr: 0.01000\tTime 0.067 (0.113)\tData 0.000 (0.016)\tLoss 0.8736 (0.8921)\tPrec@1 62.500 (62.462)\n",
            "Epoch: [69][50/110], lr: 0.01000\tTime 0.083 (0.106)\tData 0.004 (0.013)\tLoss 0.8263 (0.8919)\tPrec@1 64.844 (62.577)\n",
            "Epoch: [69][60/110], lr: 0.01000\tTime 0.071 (0.100)\tData 0.007 (0.012)\tLoss 0.8170 (0.8865)\tPrec@1 68.750 (62.884)\n",
            "Epoch: [69][70/110], lr: 0.01000\tTime 0.062 (0.096)\tData 0.000 (0.011)\tLoss 0.8523 (0.8811)\tPrec@1 64.062 (63.083)\n",
            "Epoch: [69][80/110], lr: 0.01000\tTime 0.075 (0.093)\tData 0.000 (0.009)\tLoss 0.8918 (0.8839)\tPrec@1 62.500 (63.059)\n",
            "Epoch: [69][90/110], lr: 0.01000\tTime 0.073 (0.091)\tData 0.007 (0.009)\tLoss 0.9770 (0.8839)\tPrec@1 57.031 (63.118)\n",
            "Epoch: [69][100/110], lr: 0.01000\tTime 0.129 (0.092)\tData 0.013 (0.008)\tLoss 0.7956 (0.8812)\tPrec@1 64.062 (63.297)\n",
            "Test: [0/100]\tTime 0.343 (0.343)\tLoss 0.9012 (0.9012)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.051 (0.065)\tLoss 0.9566 (0.9709)\tPrec@1 60.000 (58.727)\n",
            "Test: [20/100]\tTime 0.032 (0.055)\tLoss 1.0026 (0.9638)\tPrec@1 54.000 (58.810)\n",
            "Test: [30/100]\tTime 0.038 (0.049)\tLoss 0.9710 (0.9718)\tPrec@1 59.000 (58.871)\n",
            "Test: [40/100]\tTime 0.026 (0.046)\tLoss 0.8867 (0.9696)\tPrec@1 67.000 (58.732)\n",
            "Test: [50/100]\tTime 0.037 (0.045)\tLoss 1.0424 (0.9746)\tPrec@1 56.000 (58.529)\n",
            "Test: [60/100]\tTime 0.045 (0.044)\tLoss 1.0908 (0.9848)\tPrec@1 52.000 (58.164)\n",
            "Test: [70/100]\tTime 0.048 (0.043)\tLoss 0.8994 (0.9834)\tPrec@1 63.000 (58.141)\n",
            "Test: [80/100]\tTime 0.023 (0.042)\tLoss 0.9644 (0.9798)\tPrec@1 60.000 (58.457)\n",
            "Test: [90/100]\tTime 0.025 (0.040)\tLoss 0.9707 (0.9791)\tPrec@1 59.000 (58.451)\n",
            "val Results: Prec@1 58.810 Loss 0.97275\n",
            "Best Prec@1: 59.030\n",
            "\n",
            "Epoch: [70][0/110], lr: 0.01000\tTime 0.499 (0.499)\tData 0.309 (0.309)\tLoss 0.9391 (0.9391)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [70][10/110], lr: 0.01000\tTime 0.074 (0.139)\tData 0.006 (0.031)\tLoss 0.8243 (0.9233)\tPrec@1 68.750 (61.293)\n",
            "Epoch: [70][20/110], lr: 0.01000\tTime 0.079 (0.113)\tData 0.000 (0.017)\tLoss 0.8781 (0.9064)\tPrec@1 66.406 (62.128)\n",
            "Epoch: [70][30/110], lr: 0.01000\tTime 0.092 (0.104)\tData 0.000 (0.012)\tLoss 0.8535 (0.8971)\tPrec@1 66.406 (62.500)\n",
            "Epoch: [70][40/110], lr: 0.01000\tTime 0.065 (0.099)\tData 0.001 (0.009)\tLoss 0.7598 (0.8858)\tPrec@1 70.312 (62.919)\n",
            "Epoch: [70][50/110], lr: 0.01000\tTime 0.072 (0.096)\tData 0.000 (0.008)\tLoss 0.8390 (0.8775)\tPrec@1 64.844 (63.281)\n",
            "Epoch: [70][60/110], lr: 0.01000\tTime 0.068 (0.092)\tData 0.000 (0.007)\tLoss 0.9029 (0.8678)\tPrec@1 63.281 (63.845)\n",
            "Epoch: [70][70/110], lr: 0.01000\tTime 0.069 (0.089)\tData 0.005 (0.007)\tLoss 0.8260 (0.8742)\tPrec@1 58.594 (63.402)\n",
            "Epoch: [70][80/110], lr: 0.01000\tTime 0.077 (0.089)\tData 0.000 (0.007)\tLoss 0.9238 (0.8750)\tPrec@1 59.375 (63.281)\n",
            "Epoch: [70][90/110], lr: 0.01000\tTime 0.066 (0.089)\tData 0.000 (0.006)\tLoss 0.8036 (0.8754)\tPrec@1 63.281 (63.135)\n",
            "Epoch: [70][100/110], lr: 0.01000\tTime 0.067 (0.088)\tData 0.002 (0.006)\tLoss 1.0155 (0.8776)\tPrec@1 58.594 (62.949)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 0.9566 (0.9566)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.023 (0.070)\tLoss 0.9667 (0.9954)\tPrec@1 55.000 (58.909)\n",
            "Test: [20/100]\tTime 0.024 (0.055)\tLoss 1.0581 (0.9704)\tPrec@1 56.000 (60.000)\n",
            "Test: [30/100]\tTime 0.036 (0.049)\tLoss 0.9988 (0.9842)\tPrec@1 62.000 (59.323)\n",
            "Test: [40/100]\tTime 0.024 (0.044)\tLoss 0.9200 (0.9822)\tPrec@1 60.000 (59.463)\n",
            "Test: [50/100]\tTime 0.022 (0.042)\tLoss 1.0649 (0.9874)\tPrec@1 55.000 (59.333)\n",
            "Test: [60/100]\tTime 0.024 (0.040)\tLoss 1.0956 (0.9987)\tPrec@1 54.000 (59.049)\n",
            "Test: [70/100]\tTime 0.023 (0.039)\tLoss 0.8958 (0.9956)\tPrec@1 67.000 (58.986)\n",
            "Test: [80/100]\tTime 0.025 (0.039)\tLoss 0.9250 (0.9967)\tPrec@1 59.000 (59.062)\n",
            "Test: [90/100]\tTime 0.039 (0.038)\tLoss 0.9800 (0.9933)\tPrec@1 57.000 (59.077)\n",
            "val Results: Prec@1 59.160 Loss 0.98868\n",
            "Best Prec@1: 59.160\n",
            "\n",
            "Epoch: [71][0/110], lr: 0.01000\tTime 0.502 (0.502)\tData 0.369 (0.369)\tLoss 0.9313 (0.9313)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [71][10/110], lr: 0.01000\tTime 0.072 (0.117)\tData 0.007 (0.037)\tLoss 0.9747 (0.9073)\tPrec@1 58.594 (62.855)\n",
            "Epoch: [71][20/110], lr: 0.01000\tTime 0.062 (0.096)\tData 0.000 (0.021)\tLoss 1.0015 (0.8913)\tPrec@1 57.812 (62.760)\n",
            "Epoch: [71][30/110], lr: 0.01000\tTime 0.061 (0.088)\tData 0.000 (0.015)\tLoss 0.8566 (0.8920)\tPrec@1 64.062 (62.374)\n",
            "Epoch: [71][40/110], lr: 0.01000\tTime 0.080 (0.084)\tData 0.011 (0.012)\tLoss 0.8453 (0.8939)\tPrec@1 60.156 (62.062)\n",
            "Epoch: [71][50/110], lr: 0.01000\tTime 0.080 (0.081)\tData 0.000 (0.010)\tLoss 0.8775 (0.8913)\tPrec@1 67.188 (62.469)\n",
            "Epoch: [71][60/110], lr: 0.01000\tTime 0.063 (0.079)\tData 0.000 (0.009)\tLoss 0.9010 (0.8870)\tPrec@1 63.281 (62.846)\n",
            "Epoch: [71][70/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.006 (0.008)\tLoss 0.8799 (0.8849)\tPrec@1 62.500 (62.973)\n",
            "Epoch: [71][80/110], lr: 0.01000\tTime 0.084 (0.078)\tData 0.006 (0.008)\tLoss 0.8404 (0.8823)\tPrec@1 67.969 (63.117)\n",
            "Epoch: [71][90/110], lr: 0.01000\tTime 0.063 (0.078)\tData 0.000 (0.007)\tLoss 0.9480 (0.8845)\tPrec@1 57.812 (62.946)\n",
            "Epoch: [71][100/110], lr: 0.01000\tTime 0.068 (0.077)\tData 0.002 (0.007)\tLoss 0.9090 (0.8828)\tPrec@1 64.062 (63.080)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 0.9463 (0.9463)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.042 (0.059)\tLoss 0.9736 (1.0020)\tPrec@1 64.000 (58.545)\n",
            "Test: [20/100]\tTime 0.041 (0.049)\tLoss 1.0647 (1.0021)\tPrec@1 52.000 (58.286)\n",
            "Test: [30/100]\tTime 0.054 (0.047)\tLoss 1.0711 (1.0020)\tPrec@1 53.000 (57.935)\n",
            "Test: [40/100]\tTime 0.029 (0.045)\tLoss 0.9709 (0.9945)\tPrec@1 62.000 (57.732)\n",
            "Test: [50/100]\tTime 0.052 (0.043)\tLoss 1.0640 (0.9956)\tPrec@1 57.000 (58.176)\n",
            "Test: [60/100]\tTime 0.034 (0.043)\tLoss 1.0194 (0.9955)\tPrec@1 57.000 (58.180)\n",
            "Test: [70/100]\tTime 0.026 (0.041)\tLoss 1.0546 (0.9970)\tPrec@1 52.000 (57.901)\n",
            "Test: [80/100]\tTime 0.028 (0.041)\tLoss 0.9070 (0.9945)\tPrec@1 61.000 (58.111)\n",
            "Test: [90/100]\tTime 0.036 (0.040)\tLoss 0.9831 (0.9916)\tPrec@1 59.000 (58.341)\n",
            "val Results: Prec@1 58.610 Loss 0.98583\n",
            "Best Prec@1: 59.160\n",
            "\n",
            "Epoch: [72][0/110], lr: 0.01000\tTime 0.454 (0.454)\tData 0.268 (0.268)\tLoss 0.8777 (0.8777)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [72][10/110], lr: 0.01000\tTime 0.063 (0.114)\tData 0.000 (0.027)\tLoss 0.7901 (0.8520)\tPrec@1 65.625 (63.920)\n",
            "Epoch: [72][20/110], lr: 0.01000\tTime 0.090 (0.104)\tData 0.000 (0.015)\tLoss 0.8852 (0.8730)\tPrec@1 60.156 (63.393)\n",
            "Epoch: [72][30/110], lr: 0.01000\tTime 0.068 (0.098)\tData 0.000 (0.011)\tLoss 0.8910 (0.8767)\tPrec@1 61.719 (63.004)\n",
            "Epoch: [72][40/110], lr: 0.01000\tTime 0.072 (0.097)\tData 0.007 (0.010)\tLoss 0.8550 (0.8791)\tPrec@1 64.844 (63.186)\n",
            "Epoch: [72][50/110], lr: 0.01000\tTime 0.168 (0.105)\tData 0.002 (0.008)\tLoss 0.9152 (0.8837)\tPrec@1 60.938 (62.837)\n",
            "Epoch: [72][60/110], lr: 0.01000\tTime 0.113 (0.106)\tData 0.007 (0.008)\tLoss 0.9254 (0.8829)\tPrec@1 60.156 (62.935)\n",
            "Epoch: [72][70/110], lr: 0.01000\tTime 0.211 (0.112)\tData 0.012 (0.008)\tLoss 0.8999 (0.8778)\tPrec@1 63.281 (63.149)\n",
            "Epoch: [72][80/110], lr: 0.01000\tTime 0.077 (0.108)\tData 0.006 (0.007)\tLoss 0.7862 (0.8800)\tPrec@1 66.406 (63.185)\n",
            "Epoch: [72][90/110], lr: 0.01000\tTime 0.093 (0.105)\tData 0.009 (0.007)\tLoss 0.7053 (0.8783)\tPrec@1 72.656 (63.367)\n",
            "Epoch: [72][100/110], lr: 0.01000\tTime 0.075 (0.103)\tData 0.007 (0.007)\tLoss 0.8893 (0.8775)\tPrec@1 65.625 (63.451)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 0.9657 (0.9657)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.022 (0.065)\tLoss 1.0256 (0.9806)\tPrec@1 58.000 (59.000)\n",
            "Test: [20/100]\tTime 0.034 (0.052)\tLoss 1.0190 (0.9785)\tPrec@1 62.000 (59.048)\n",
            "Test: [30/100]\tTime 0.040 (0.046)\tLoss 0.9836 (0.9892)\tPrec@1 55.000 (58.258)\n",
            "Test: [40/100]\tTime 0.034 (0.043)\tLoss 0.9196 (0.9856)\tPrec@1 59.000 (58.098)\n",
            "Test: [50/100]\tTime 0.024 (0.041)\tLoss 1.0872 (0.9852)\tPrec@1 54.000 (57.980)\n",
            "Test: [60/100]\tTime 0.053 (0.039)\tLoss 0.9904 (0.9910)\tPrec@1 61.000 (58.049)\n",
            "Test: [70/100]\tTime 0.038 (0.038)\tLoss 0.9082 (0.9903)\tPrec@1 60.000 (58.028)\n",
            "Test: [80/100]\tTime 0.032 (0.038)\tLoss 0.9260 (0.9847)\tPrec@1 59.000 (58.259)\n",
            "Test: [90/100]\tTime 0.029 (0.037)\tLoss 1.0187 (0.9831)\tPrec@1 56.000 (58.297)\n",
            "val Results: Prec@1 58.470 Loss 0.97743\n",
            "Best Prec@1: 59.160\n",
            "\n",
            "Epoch: [73][0/110], lr: 0.01000\tTime 0.467 (0.467)\tData 0.267 (0.267)\tLoss 0.8761 (0.8761)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [73][10/110], lr: 0.01000\tTime 0.082 (0.114)\tData 0.007 (0.028)\tLoss 0.8611 (0.8815)\tPrec@1 60.938 (63.565)\n",
            "Epoch: [73][20/110], lr: 0.01000\tTime 0.073 (0.096)\tData 0.007 (0.016)\tLoss 0.7742 (0.8708)\tPrec@1 67.188 (63.802)\n",
            "Epoch: [73][30/110], lr: 0.01000\tTime 0.067 (0.088)\tData 0.000 (0.012)\tLoss 0.8133 (0.8593)\tPrec@1 62.500 (64.365)\n",
            "Epoch: [73][40/110], lr: 0.01000\tTime 0.071 (0.085)\tData 0.006 (0.010)\tLoss 0.8013 (0.8641)\tPrec@1 62.500 (63.815)\n",
            "Epoch: [73][50/110], lr: 0.01000\tTime 0.074 (0.084)\tData 0.012 (0.009)\tLoss 0.8226 (0.8699)\tPrec@1 61.719 (63.634)\n",
            "Epoch: [73][60/110], lr: 0.01000\tTime 0.068 (0.082)\tData 0.000 (0.008)\tLoss 0.7790 (0.8692)\tPrec@1 70.312 (63.768)\n",
            "Epoch: [73][70/110], lr: 0.01000\tTime 0.078 (0.081)\tData 0.000 (0.007)\tLoss 0.9144 (0.8731)\tPrec@1 65.625 (63.578)\n",
            "Epoch: [73][80/110], lr: 0.01000\tTime 0.082 (0.083)\tData 0.005 (0.007)\tLoss 0.8326 (0.8729)\tPrec@1 67.188 (63.648)\n",
            "Epoch: [73][90/110], lr: 0.01000\tTime 0.082 (0.083)\tData 0.000 (0.006)\tLoss 0.8151 (0.8695)\tPrec@1 60.938 (63.753)\n",
            "Epoch: [73][100/110], lr: 0.01000\tTime 0.085 (0.083)\tData 0.005 (0.006)\tLoss 0.9162 (0.8672)\tPrec@1 60.156 (63.892)\n",
            "Test: [0/100]\tTime 0.300 (0.300)\tLoss 0.8193 (0.8193)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.024 (0.062)\tLoss 0.9500 (0.9423)\tPrec@1 58.000 (59.727)\n",
            "Test: [20/100]\tTime 0.038 (0.051)\tLoss 1.0462 (0.9379)\tPrec@1 66.000 (60.952)\n",
            "Test: [30/100]\tTime 0.023 (0.045)\tLoss 1.0034 (0.9532)\tPrec@1 58.000 (60.226)\n",
            "Test: [40/100]\tTime 0.024 (0.042)\tLoss 0.9451 (0.9527)\tPrec@1 60.000 (60.220)\n",
            "Test: [50/100]\tTime 0.022 (0.040)\tLoss 1.0467 (0.9557)\tPrec@1 58.000 (60.235)\n",
            "Test: [60/100]\tTime 0.025 (0.039)\tLoss 1.0353 (0.9629)\tPrec@1 60.000 (59.967)\n",
            "Test: [70/100]\tTime 0.047 (0.038)\tLoss 0.9247 (0.9629)\tPrec@1 66.000 (60.000)\n",
            "Test: [80/100]\tTime 0.037 (0.037)\tLoss 0.8942 (0.9623)\tPrec@1 61.000 (59.840)\n",
            "Test: [90/100]\tTime 0.024 (0.037)\tLoss 0.9198 (0.9594)\tPrec@1 63.000 (59.912)\n",
            "val Results: Prec@1 59.950 Loss 0.95493\n",
            "Best Prec@1: 59.950\n",
            "\n",
            "Epoch: [74][0/110], lr: 0.01000\tTime 0.480 (0.480)\tData 0.295 (0.295)\tLoss 0.9841 (0.9841)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [74][10/110], lr: 0.01000\tTime 0.064 (0.113)\tData 0.000 (0.030)\tLoss 0.8528 (0.8600)\tPrec@1 60.938 (64.062)\n",
            "Epoch: [74][20/110], lr: 0.01000\tTime 0.067 (0.095)\tData 0.001 (0.017)\tLoss 0.8836 (0.9015)\tPrec@1 60.938 (61.905)\n",
            "Epoch: [74][30/110], lr: 0.01000\tTime 0.068 (0.088)\tData 0.000 (0.013)\tLoss 0.8508 (0.8956)\tPrec@1 62.500 (62.374)\n",
            "Epoch: [74][40/110], lr: 0.01000\tTime 0.083 (0.084)\tData 0.007 (0.010)\tLoss 0.7163 (0.8747)\tPrec@1 70.312 (63.167)\n",
            "Epoch: [74][50/110], lr: 0.01000\tTime 0.079 (0.082)\tData 0.006 (0.009)\tLoss 0.7307 (0.8674)\tPrec@1 70.312 (63.634)\n",
            "Epoch: [74][60/110], lr: 0.01000\tTime 0.068 (0.080)\tData 0.000 (0.008)\tLoss 0.8691 (0.8687)\tPrec@1 61.719 (63.384)\n",
            "Epoch: [74][70/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.008 (0.008)\tLoss 0.8014 (0.8717)\tPrec@1 66.406 (63.237)\n",
            "Epoch: [74][80/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.007)\tLoss 0.8083 (0.8743)\tPrec@1 65.625 (62.847)\n",
            "Epoch: [74][90/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.000 (0.006)\tLoss 0.8008 (0.8759)\tPrec@1 67.188 (62.672)\n",
            "Epoch: [74][100/110], lr: 0.01000\tTime 0.075 (0.081)\tData 0.008 (0.006)\tLoss 0.8902 (0.8719)\tPrec@1 64.062 (62.894)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 0.8847 (0.8847)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.055 (0.069)\tLoss 0.9101 (0.9192)\tPrec@1 56.000 (60.636)\n",
            "Test: [20/100]\tTime 0.025 (0.055)\tLoss 0.9700 (0.9245)\tPrec@1 59.000 (61.048)\n",
            "Test: [30/100]\tTime 0.047 (0.049)\tLoss 0.9334 (0.9318)\tPrec@1 61.000 (60.516)\n",
            "Test: [40/100]\tTime 0.069 (0.047)\tLoss 0.9024 (0.9359)\tPrec@1 59.000 (60.220)\n",
            "Test: [50/100]\tTime 0.023 (0.045)\tLoss 1.0725 (0.9406)\tPrec@1 51.000 (60.216)\n",
            "Test: [60/100]\tTime 0.023 (0.043)\tLoss 1.0534 (0.9481)\tPrec@1 58.000 (59.951)\n",
            "Test: [70/100]\tTime 0.030 (0.041)\tLoss 0.8940 (0.9486)\tPrec@1 66.000 (59.803)\n",
            "Test: [80/100]\tTime 0.024 (0.040)\tLoss 0.8712 (0.9454)\tPrec@1 65.000 (60.259)\n",
            "Test: [90/100]\tTime 0.062 (0.040)\tLoss 0.9001 (0.9417)\tPrec@1 64.000 (60.495)\n",
            "val Results: Prec@1 60.600 Loss 0.93630\n",
            "Best Prec@1: 60.600\n",
            "\n",
            "Epoch: [75][0/110], lr: 0.01000\tTime 0.577 (0.577)\tData 0.381 (0.381)\tLoss 0.8168 (0.8168)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [75][10/110], lr: 0.01000\tTime 0.072 (0.120)\tData 0.000 (0.037)\tLoss 0.8607 (0.8874)\tPrec@1 60.156 (62.003)\n",
            "Epoch: [75][20/110], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.020)\tLoss 0.8208 (0.8857)\tPrec@1 65.625 (62.463)\n",
            "Epoch: [75][30/110], lr: 0.01000\tTime 0.066 (0.091)\tData 0.000 (0.014)\tLoss 0.9624 (0.8891)\tPrec@1 59.375 (62.424)\n",
            "Epoch: [75][40/110], lr: 0.01000\tTime 0.083 (0.088)\tData 0.011 (0.011)\tLoss 0.8118 (0.8801)\tPrec@1 63.281 (62.290)\n",
            "Epoch: [75][50/110], lr: 0.01000\tTime 0.094 (0.085)\tData 0.000 (0.009)\tLoss 0.8601 (0.8774)\tPrec@1 61.719 (62.699)\n",
            "Epoch: [75][60/110], lr: 0.01000\tTime 0.071 (0.083)\tData 0.005 (0.008)\tLoss 0.7470 (0.8724)\tPrec@1 67.969 (63.102)\n",
            "Epoch: [75][70/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.007 (0.008)\tLoss 0.9796 (0.8714)\tPrec@1 55.469 (63.215)\n",
            "Epoch: [75][80/110], lr: 0.01000\tTime 0.166 (0.084)\tData 0.000 (0.007)\tLoss 0.8634 (0.8697)\tPrec@1 63.281 (63.301)\n",
            "Epoch: [75][90/110], lr: 0.01000\tTime 0.109 (0.090)\tData 0.000 (0.007)\tLoss 0.8564 (0.8668)\tPrec@1 65.625 (63.479)\n",
            "Epoch: [75][100/110], lr: 0.01000\tTime 0.129 (0.095)\tData 0.000 (0.007)\tLoss 0.8315 (0.8655)\tPrec@1 67.188 (63.537)\n",
            "Test: [0/100]\tTime 0.354 (0.354)\tLoss 0.8498 (0.8498)\tPrec@1 65.000 (65.000)\n",
            "Test: [10/100]\tTime 0.034 (0.069)\tLoss 0.9463 (0.9260)\tPrec@1 66.000 (61.818)\n",
            "Test: [20/100]\tTime 0.050 (0.053)\tLoss 0.9400 (0.9150)\tPrec@1 60.000 (61.571)\n",
            "Test: [30/100]\tTime 0.024 (0.047)\tLoss 0.9741 (0.9296)\tPrec@1 62.000 (60.548)\n",
            "Test: [40/100]\tTime 0.032 (0.043)\tLoss 0.9139 (0.9308)\tPrec@1 64.000 (60.415)\n",
            "Test: [50/100]\tTime 0.022 (0.041)\tLoss 0.9236 (0.9282)\tPrec@1 59.000 (60.706)\n",
            "Test: [60/100]\tTime 0.023 (0.040)\tLoss 1.1048 (0.9365)\tPrec@1 53.000 (60.590)\n",
            "Test: [70/100]\tTime 0.024 (0.039)\tLoss 0.9002 (0.9345)\tPrec@1 64.000 (60.803)\n",
            "Test: [80/100]\tTime 0.036 (0.038)\tLoss 0.8560 (0.9316)\tPrec@1 64.000 (60.988)\n",
            "Test: [90/100]\tTime 0.049 (0.039)\tLoss 0.9561 (0.9310)\tPrec@1 58.000 (61.187)\n",
            "val Results: Prec@1 61.410 Loss 0.92545\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [76][0/110], lr: 0.01000\tTime 0.478 (0.478)\tData 0.351 (0.351)\tLoss 0.7607 (0.7607)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [76][10/110], lr: 0.01000\tTime 0.068 (0.118)\tData 0.000 (0.034)\tLoss 0.9341 (0.8612)\tPrec@1 59.375 (64.062)\n",
            "Epoch: [76][20/110], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.019)\tLoss 0.9932 (0.8600)\tPrec@1 54.688 (64.062)\n",
            "Epoch: [76][30/110], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.013)\tLoss 0.8896 (0.8592)\tPrec@1 61.719 (63.911)\n",
            "Epoch: [76][40/110], lr: 0.01000\tTime 0.074 (0.085)\tData 0.007 (0.011)\tLoss 0.8923 (0.8596)\tPrec@1 61.719 (64.062)\n",
            "Epoch: [76][50/110], lr: 0.01000\tTime 0.063 (0.083)\tData 0.000 (0.009)\tLoss 0.9127 (0.8604)\tPrec@1 61.719 (63.802)\n",
            "Epoch: [76][60/110], lr: 0.01000\tTime 0.086 (0.082)\tData 0.006 (0.008)\tLoss 0.8551 (0.8613)\tPrec@1 67.969 (63.665)\n",
            "Epoch: [76][70/110], lr: 0.01000\tTime 0.077 (0.081)\tData 0.004 (0.008)\tLoss 0.8993 (0.8649)\tPrec@1 60.938 (63.479)\n",
            "Epoch: [76][80/110], lr: 0.01000\tTime 0.081 (0.081)\tData 0.000 (0.007)\tLoss 0.8492 (0.8674)\tPrec@1 67.969 (63.291)\n",
            "Epoch: [76][90/110], lr: 0.01000\tTime 0.079 (0.082)\tData 0.000 (0.007)\tLoss 0.9454 (0.8651)\tPrec@1 64.062 (63.316)\n",
            "Epoch: [76][100/110], lr: 0.01000\tTime 0.096 (0.082)\tData 0.000 (0.006)\tLoss 0.8096 (0.8636)\tPrec@1 65.625 (63.289)\n",
            "Test: [0/100]\tTime 0.390 (0.390)\tLoss 0.8919 (0.8919)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.024 (0.067)\tLoss 0.9817 (0.9482)\tPrec@1 58.000 (60.636)\n",
            "Test: [20/100]\tTime 0.026 (0.053)\tLoss 1.0823 (0.9532)\tPrec@1 51.000 (60.667)\n",
            "Test: [30/100]\tTime 0.037 (0.050)\tLoss 0.9547 (0.9693)\tPrec@1 59.000 (59.742)\n",
            "Test: [40/100]\tTime 0.023 (0.045)\tLoss 0.9012 (0.9649)\tPrec@1 62.000 (59.659)\n",
            "Test: [50/100]\tTime 0.032 (0.043)\tLoss 1.0133 (0.9652)\tPrec@1 60.000 (59.549)\n",
            "Test: [60/100]\tTime 0.038 (0.041)\tLoss 1.1134 (0.9713)\tPrec@1 54.000 (59.426)\n",
            "Test: [70/100]\tTime 0.033 (0.040)\tLoss 0.8593 (0.9691)\tPrec@1 68.000 (59.690)\n",
            "Test: [80/100]\tTime 0.026 (0.039)\tLoss 0.9482 (0.9695)\tPrec@1 60.000 (59.543)\n",
            "Test: [90/100]\tTime 0.032 (0.038)\tLoss 1.0225 (0.9674)\tPrec@1 56.000 (59.681)\n",
            "val Results: Prec@1 59.820 Loss 0.96230\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [77][0/110], lr: 0.01000\tTime 0.472 (0.472)\tData 0.305 (0.305)\tLoss 1.0362 (1.0362)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [77][10/110], lr: 0.01000\tTime 0.073 (0.111)\tData 0.000 (0.032)\tLoss 0.9508 (0.9037)\tPrec@1 60.156 (60.795)\n",
            "Epoch: [77][20/110], lr: 0.01000\tTime 0.060 (0.092)\tData 0.000 (0.018)\tLoss 0.9220 (0.8897)\tPrec@1 53.906 (60.975)\n",
            "Epoch: [77][30/110], lr: 0.01000\tTime 0.064 (0.085)\tData 0.000 (0.013)\tLoss 0.8528 (0.8819)\tPrec@1 64.844 (61.820)\n",
            "Epoch: [77][40/110], lr: 0.01000\tTime 0.065 (0.082)\tData 0.001 (0.011)\tLoss 0.8153 (0.8724)\tPrec@1 67.969 (62.557)\n",
            "Epoch: [77][50/110], lr: 0.01000\tTime 0.076 (0.081)\tData 0.006 (0.009)\tLoss 0.8395 (0.8706)\tPrec@1 63.281 (62.929)\n",
            "Epoch: [77][60/110], lr: 0.01000\tTime 0.101 (0.081)\tData 0.005 (0.009)\tLoss 0.8736 (0.8686)\tPrec@1 61.719 (63.307)\n",
            "Epoch: [77][70/110], lr: 0.01000\tTime 0.127 (0.084)\tData 0.007 (0.008)\tLoss 0.8333 (0.8667)\tPrec@1 60.938 (63.413)\n",
            "Epoch: [77][80/110], lr: 0.01000\tTime 0.077 (0.084)\tData 0.007 (0.007)\tLoss 0.9103 (0.8654)\tPrec@1 64.062 (63.522)\n",
            "Epoch: [77][90/110], lr: 0.01000\tTime 0.088 (0.085)\tData 0.007 (0.007)\tLoss 0.8530 (0.8669)\tPrec@1 65.625 (63.453)\n",
            "Epoch: [77][100/110], lr: 0.01000\tTime 0.073 (0.085)\tData 0.005 (0.006)\tLoss 0.9216 (0.8651)\tPrec@1 59.375 (63.451)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 0.8985 (0.8985)\tPrec@1 56.000 (56.000)\n",
            "Test: [10/100]\tTime 0.022 (0.056)\tLoss 0.9357 (0.9411)\tPrec@1 62.000 (60.273)\n",
            "Test: [20/100]\tTime 0.074 (0.046)\tLoss 0.9892 (0.9417)\tPrec@1 61.000 (60.571)\n",
            "Test: [30/100]\tTime 0.031 (0.040)\tLoss 1.0034 (0.9538)\tPrec@1 59.000 (59.581)\n",
            "Test: [40/100]\tTime 0.033 (0.038)\tLoss 0.8332 (0.9543)\tPrec@1 63.000 (59.537)\n",
            "Test: [50/100]\tTime 0.025 (0.037)\tLoss 1.0415 (0.9537)\tPrec@1 50.000 (59.373)\n",
            "Test: [60/100]\tTime 0.022 (0.036)\tLoss 1.0894 (0.9584)\tPrec@1 50.000 (59.246)\n",
            "Test: [70/100]\tTime 0.033 (0.036)\tLoss 0.9926 (0.9578)\tPrec@1 57.000 (59.183)\n",
            "Test: [80/100]\tTime 0.035 (0.035)\tLoss 0.9148 (0.9567)\tPrec@1 60.000 (59.358)\n",
            "Test: [90/100]\tTime 0.024 (0.035)\tLoss 0.9819 (0.9561)\tPrec@1 62.000 (59.560)\n",
            "val Results: Prec@1 59.880 Loss 0.95111\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [78][0/110], lr: 0.01000\tTime 0.472 (0.472)\tData 0.316 (0.316)\tLoss 0.8403 (0.8403)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [78][10/110], lr: 0.01000\tTime 0.068 (0.110)\tData 0.000 (0.032)\tLoss 0.7795 (0.8210)\tPrec@1 69.531 (65.980)\n",
            "Epoch: [78][20/110], lr: 0.01000\tTime 0.069 (0.092)\tData 0.000 (0.018)\tLoss 0.8096 (0.8264)\tPrec@1 70.312 (66.406)\n",
            "Epoch: [78][30/110], lr: 0.01000\tTime 0.063 (0.085)\tData 0.000 (0.013)\tLoss 0.9425 (0.8328)\tPrec@1 58.594 (65.297)\n",
            "Epoch: [78][40/110], lr: 0.01000\tTime 0.079 (0.082)\tData 0.007 (0.011)\tLoss 1.0345 (0.8472)\tPrec@1 51.562 (64.425)\n",
            "Epoch: [78][50/110], lr: 0.01000\tTime 0.085 (0.081)\tData 0.013 (0.009)\tLoss 0.9390 (0.8459)\tPrec@1 64.062 (64.782)\n",
            "Epoch: [78][60/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.001 (0.008)\tLoss 0.8627 (0.8474)\tPrec@1 63.281 (64.626)\n",
            "Epoch: [78][70/110], lr: 0.01000\tTime 0.069 (0.079)\tData 0.007 (0.007)\tLoss 0.8885 (0.8497)\tPrec@1 64.062 (64.657)\n",
            "Epoch: [78][80/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.006)\tLoss 0.7524 (0.8464)\tPrec@1 69.531 (64.776)\n",
            "Epoch: [78][90/110], lr: 0.01000\tTime 0.064 (0.077)\tData 0.000 (0.006)\tLoss 0.9071 (0.8493)\tPrec@1 60.938 (64.595)\n",
            "Epoch: [78][100/110], lr: 0.01000\tTime 0.065 (0.077)\tData 0.000 (0.005)\tLoss 0.8950 (0.8485)\tPrec@1 58.594 (64.650)\n",
            "Test: [0/100]\tTime 0.303 (0.303)\tLoss 0.9288 (0.9288)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.026 (0.057)\tLoss 0.9167 (0.9647)\tPrec@1 57.000 (58.182)\n",
            "Test: [20/100]\tTime 0.035 (0.046)\tLoss 1.0247 (0.9492)\tPrec@1 58.000 (59.476)\n",
            "Test: [30/100]\tTime 0.028 (0.041)\tLoss 0.9767 (0.9547)\tPrec@1 59.000 (59.419)\n",
            "Test: [40/100]\tTime 0.054 (0.043)\tLoss 0.8695 (0.9525)\tPrec@1 63.000 (59.512)\n",
            "Test: [50/100]\tTime 0.042 (0.044)\tLoss 0.9619 (0.9505)\tPrec@1 62.000 (59.882)\n",
            "Test: [60/100]\tTime 0.048 (0.045)\tLoss 1.0657 (0.9588)\tPrec@1 53.000 (59.672)\n",
            "Test: [70/100]\tTime 0.023 (0.046)\tLoss 0.9597 (0.9591)\tPrec@1 62.000 (59.676)\n",
            "Test: [80/100]\tTime 0.048 (0.046)\tLoss 0.8671 (0.9549)\tPrec@1 64.000 (60.086)\n",
            "Test: [90/100]\tTime 0.032 (0.047)\tLoss 0.9703 (0.9548)\tPrec@1 59.000 (60.110)\n",
            "val Results: Prec@1 60.300 Loss 0.94830\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [79][0/110], lr: 0.01000\tTime 0.491 (0.491)\tData 0.322 (0.322)\tLoss 0.8417 (0.8417)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [79][10/110], lr: 0.01000\tTime 0.098 (0.114)\tData 0.008 (0.031)\tLoss 1.0160 (0.8895)\tPrec@1 52.344 (62.003)\n",
            "Epoch: [79][20/110], lr: 0.01000\tTime 0.065 (0.094)\tData 0.000 (0.018)\tLoss 0.7672 (0.8703)\tPrec@1 67.969 (62.760)\n",
            "Epoch: [79][30/110], lr: 0.01000\tTime 0.068 (0.087)\tData 0.000 (0.012)\tLoss 0.9194 (0.8665)\tPrec@1 62.500 (63.256)\n",
            "Epoch: [79][40/110], lr: 0.01000\tTime 0.083 (0.084)\tData 0.013 (0.010)\tLoss 0.8869 (0.8504)\tPrec@1 61.719 (64.310)\n",
            "Epoch: [79][50/110], lr: 0.01000\tTime 0.077 (0.082)\tData 0.007 (0.009)\tLoss 0.8925 (0.8482)\tPrec@1 67.969 (64.231)\n",
            "Epoch: [79][60/110], lr: 0.01000\tTime 0.069 (0.081)\tData 0.005 (0.008)\tLoss 0.8377 (0.8478)\tPrec@1 63.281 (64.229)\n",
            "Epoch: [79][70/110], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.007)\tLoss 1.0485 (0.8540)\tPrec@1 62.500 (64.040)\n",
            "Epoch: [79][80/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.000 (0.007)\tLoss 0.8145 (0.8503)\tPrec@1 63.281 (64.140)\n",
            "Epoch: [79][90/110], lr: 0.01000\tTime 0.077 (0.078)\tData 0.007 (0.006)\tLoss 0.9599 (0.8510)\tPrec@1 62.500 (64.183)\n",
            "Epoch: [79][100/110], lr: 0.01000\tTime 0.074 (0.078)\tData 0.003 (0.006)\tLoss 0.8647 (0.8496)\tPrec@1 60.938 (64.418)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 0.9393 (0.9393)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.027 (0.059)\tLoss 0.9658 (0.9258)\tPrec@1 62.000 (62.636)\n",
            "Test: [20/100]\tTime 0.031 (0.047)\tLoss 0.9811 (0.9189)\tPrec@1 59.000 (61.905)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 0.9014 (0.9337)\tPrec@1 61.000 (60.323)\n",
            "Test: [40/100]\tTime 0.037 (0.040)\tLoss 0.8745 (0.9347)\tPrec@1 63.000 (60.098)\n",
            "Test: [50/100]\tTime 0.026 (0.038)\tLoss 1.0110 (0.9393)\tPrec@1 57.000 (60.039)\n",
            "Test: [60/100]\tTime 0.036 (0.038)\tLoss 0.9963 (0.9459)\tPrec@1 57.000 (59.967)\n",
            "Test: [70/100]\tTime 0.037 (0.037)\tLoss 0.8879 (0.9419)\tPrec@1 64.000 (60.099)\n",
            "Test: [80/100]\tTime 0.023 (0.036)\tLoss 0.9178 (0.9416)\tPrec@1 63.000 (60.160)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9136 (0.9388)\tPrec@1 63.000 (60.440)\n",
            "val Results: Prec@1 60.630 Loss 0.93232\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [80][0/110], lr: 0.01000\tTime 0.537 (0.537)\tData 0.404 (0.404)\tLoss 0.8272 (0.8272)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [80][10/110], lr: 0.01000\tTime 0.082 (0.117)\tData 0.000 (0.040)\tLoss 0.8573 (0.8622)\tPrec@1 64.062 (62.713)\n",
            "Epoch: [80][20/110], lr: 0.01000\tTime 0.075 (0.096)\tData 0.000 (0.021)\tLoss 0.8901 (0.8711)\tPrec@1 67.188 (63.504)\n",
            "Epoch: [80][30/110], lr: 0.01000\tTime 0.082 (0.090)\tData 0.005 (0.015)\tLoss 0.8360 (0.8679)\tPrec@1 64.844 (63.684)\n",
            "Epoch: [80][40/110], lr: 0.01000\tTime 0.076 (0.086)\tData 0.000 (0.012)\tLoss 0.8714 (0.8692)\tPrec@1 63.281 (63.643)\n",
            "Epoch: [80][50/110], lr: 0.01000\tTime 0.071 (0.083)\tData 0.000 (0.010)\tLoss 0.7889 (0.8658)\tPrec@1 70.312 (63.909)\n",
            "Epoch: [80][60/110], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.008)\tLoss 0.8548 (0.8635)\tPrec@1 67.188 (64.127)\n",
            "Epoch: [80][70/110], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.008)\tLoss 0.7666 (0.8562)\tPrec@1 67.188 (64.250)\n",
            "Epoch: [80][80/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.003 (0.007)\tLoss 0.8031 (0.8553)\tPrec@1 62.500 (64.149)\n",
            "Epoch: [80][90/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.001 (0.007)\tLoss 0.8553 (0.8522)\tPrec@1 63.281 (64.217)\n",
            "Epoch: [80][100/110], lr: 0.01000\tTime 0.066 (0.078)\tData 0.000 (0.006)\tLoss 0.8720 (0.8534)\tPrec@1 59.375 (64.032)\n",
            "Test: [0/100]\tTime 0.250 (0.250)\tLoss 0.8958 (0.8958)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.023 (0.057)\tLoss 0.9399 (0.9609)\tPrec@1 62.000 (62.091)\n",
            "Test: [20/100]\tTime 0.038 (0.046)\tLoss 0.9432 (0.9529)\tPrec@1 56.000 (61.714)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 0.9736 (0.9602)\tPrec@1 60.000 (60.871)\n",
            "Test: [40/100]\tTime 0.032 (0.039)\tLoss 0.8757 (0.9585)\tPrec@1 63.000 (60.756)\n",
            "Test: [50/100]\tTime 0.033 (0.038)\tLoss 0.9975 (0.9574)\tPrec@1 61.000 (61.020)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.0135 (0.9650)\tPrec@1 55.000 (60.672)\n",
            "Test: [70/100]\tTime 0.027 (0.037)\tLoss 0.8624 (0.9634)\tPrec@1 69.000 (60.662)\n",
            "Test: [80/100]\tTime 0.038 (0.036)\tLoss 0.9465 (0.9627)\tPrec@1 59.000 (60.802)\n",
            "Test: [90/100]\tTime 0.043 (0.036)\tLoss 0.9514 (0.9613)\tPrec@1 62.000 (60.868)\n",
            "val Results: Prec@1 61.060 Loss 0.95658\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [81][0/110], lr: 0.01000\tTime 0.492 (0.492)\tData 0.344 (0.344)\tLoss 0.8938 (0.8938)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [81][10/110], lr: 0.01000\tTime 0.071 (0.113)\tData 0.000 (0.034)\tLoss 0.8655 (0.8133)\tPrec@1 60.938 (65.980)\n",
            "Epoch: [81][20/110], lr: 0.01000\tTime 0.067 (0.094)\tData 0.000 (0.018)\tLoss 0.7582 (0.8233)\tPrec@1 72.656 (65.327)\n",
            "Epoch: [81][30/110], lr: 0.01000\tTime 0.084 (0.087)\tData 0.007 (0.013)\tLoss 0.8614 (0.8278)\tPrec@1 64.062 (64.945)\n",
            "Epoch: [81][40/110], lr: 0.01000\tTime 0.092 (0.084)\tData 0.007 (0.010)\tLoss 0.7333 (0.8342)\tPrec@1 66.406 (64.653)\n",
            "Epoch: [81][50/110], lr: 0.01000\tTime 0.074 (0.083)\tData 0.003 (0.009)\tLoss 0.8440 (0.8366)\tPrec@1 65.625 (64.828)\n",
            "Epoch: [81][60/110], lr: 0.01000\tTime 0.066 (0.081)\tData 0.001 (0.008)\tLoss 0.8559 (0.8422)\tPrec@1 61.719 (64.408)\n",
            "Epoch: [81][70/110], lr: 0.01000\tTime 0.074 (0.080)\tData 0.009 (0.007)\tLoss 0.9321 (0.8423)\tPrec@1 62.500 (64.503)\n",
            "Epoch: [81][80/110], lr: 0.01000\tTime 0.091 (0.080)\tData 0.007 (0.007)\tLoss 0.8927 (0.8417)\tPrec@1 63.281 (64.622)\n",
            "Epoch: [81][90/110], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.006)\tLoss 0.8956 (0.8401)\tPrec@1 61.719 (64.706)\n",
            "Epoch: [81][100/110], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.006)\tLoss 0.8542 (0.8421)\tPrec@1 58.594 (64.534)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.9313 (0.9313)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.029 (0.061)\tLoss 0.9704 (0.9489)\tPrec@1 60.000 (62.818)\n",
            "Test: [20/100]\tTime 0.026 (0.046)\tLoss 0.9818 (0.9560)\tPrec@1 55.000 (61.429)\n",
            "Test: [30/100]\tTime 0.026 (0.042)\tLoss 1.0136 (0.9646)\tPrec@1 57.000 (60.355)\n",
            "Test: [40/100]\tTime 0.042 (0.041)\tLoss 0.9071 (0.9572)\tPrec@1 66.000 (59.976)\n",
            "Test: [50/100]\tTime 0.051 (0.039)\tLoss 1.0349 (0.9575)\tPrec@1 57.000 (60.196)\n",
            "Test: [60/100]\tTime 0.026 (0.038)\tLoss 1.0603 (0.9618)\tPrec@1 52.000 (59.902)\n",
            "Test: [70/100]\tTime 0.053 (0.037)\tLoss 0.9564 (0.9623)\tPrec@1 64.000 (59.789)\n",
            "Test: [80/100]\tTime 0.024 (0.037)\tLoss 0.9218 (0.9618)\tPrec@1 63.000 (59.914)\n",
            "Test: [90/100]\tTime 0.033 (0.036)\tLoss 0.9927 (0.9606)\tPrec@1 65.000 (60.077)\n",
            "val Results: Prec@1 60.250 Loss 0.95425\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [82][0/110], lr: 0.01000\tTime 0.500 (0.500)\tData 0.391 (0.391)\tLoss 0.8418 (0.8418)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [82][10/110], lr: 0.01000\tTime 0.066 (0.117)\tData 0.000 (0.039)\tLoss 0.9523 (0.8664)\tPrec@1 57.812 (64.205)\n",
            "Epoch: [82][20/110], lr: 0.01000\tTime 0.065 (0.097)\tData 0.000 (0.023)\tLoss 0.9084 (0.8581)\tPrec@1 61.719 (64.360)\n",
            "Epoch: [82][30/110], lr: 0.01000\tTime 0.090 (0.089)\tData 0.000 (0.016)\tLoss 0.7929 (0.8338)\tPrec@1 65.625 (65.297)\n",
            "Epoch: [82][40/110], lr: 0.01000\tTime 0.066 (0.085)\tData 0.000 (0.013)\tLoss 0.6972 (0.8352)\tPrec@1 75.000 (65.130)\n",
            "Epoch: [82][50/110], lr: 0.01000\tTime 0.117 (0.089)\tData 0.007 (0.012)\tLoss 0.7410 (0.8359)\tPrec@1 67.188 (64.966)\n",
            "Epoch: [82][60/110], lr: 0.01000\tTime 0.124 (0.093)\tData 0.019 (0.011)\tLoss 0.9392 (0.8421)\tPrec@1 61.719 (64.767)\n",
            "Epoch: [82][70/110], lr: 0.01000\tTime 0.126 (0.096)\tData 0.007 (0.011)\tLoss 0.8597 (0.8477)\tPrec@1 64.844 (64.481)\n",
            "Epoch: [82][80/110], lr: 0.01000\tTime 0.066 (0.097)\tData 0.000 (0.010)\tLoss 0.8656 (0.8499)\tPrec@1 67.188 (64.660)\n",
            "Epoch: [82][90/110], lr: 0.01000\tTime 0.069 (0.094)\tData 0.000 (0.009)\tLoss 0.9245 (0.8516)\tPrec@1 60.938 (64.483)\n",
            "Epoch: [82][100/110], lr: 0.01000\tTime 0.075 (0.092)\tData 0.008 (0.009)\tLoss 0.7289 (0.8475)\tPrec@1 71.094 (64.720)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 0.9016 (0.9016)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.026 (0.058)\tLoss 0.9173 (0.9471)\tPrec@1 58.000 (59.636)\n",
            "Test: [20/100]\tTime 0.025 (0.047)\tLoss 1.0537 (0.9451)\tPrec@1 54.000 (60.000)\n",
            "Test: [30/100]\tTime 0.050 (0.042)\tLoss 0.9674 (0.9536)\tPrec@1 62.000 (59.710)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9058 (0.9572)\tPrec@1 61.000 (59.268)\n",
            "Test: [50/100]\tTime 0.034 (0.038)\tLoss 1.0594 (0.9585)\tPrec@1 55.000 (59.235)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.0563 (0.9657)\tPrec@1 56.000 (59.000)\n",
            "Test: [70/100]\tTime 0.026 (0.037)\tLoss 0.9561 (0.9628)\tPrec@1 58.000 (59.141)\n",
            "Test: [80/100]\tTime 0.043 (0.036)\tLoss 0.8755 (0.9612)\tPrec@1 63.000 (59.259)\n",
            "Test: [90/100]\tTime 0.052 (0.036)\tLoss 0.9435 (0.9572)\tPrec@1 64.000 (59.440)\n",
            "val Results: Prec@1 59.640 Loss 0.95105\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [83][0/110], lr: 0.01000\tTime 0.485 (0.485)\tData 0.279 (0.279)\tLoss 0.7969 (0.7969)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [83][10/110], lr: 0.01000\tTime 0.069 (0.115)\tData 0.000 (0.028)\tLoss 0.8413 (0.8604)\tPrec@1 66.406 (63.636)\n",
            "Epoch: [83][20/110], lr: 0.01000\tTime 0.066 (0.095)\tData 0.000 (0.016)\tLoss 0.8202 (0.8384)\tPrec@1 69.531 (65.439)\n",
            "Epoch: [83][30/110], lr: 0.01000\tTime 0.067 (0.088)\tData 0.000 (0.011)\tLoss 0.7682 (0.8455)\tPrec@1 69.531 (64.541)\n",
            "Epoch: [83][40/110], lr: 0.01000\tTime 0.062 (0.084)\tData 0.000 (0.009)\tLoss 0.8872 (0.8404)\tPrec@1 65.625 (64.806)\n",
            "Epoch: [83][50/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.007 (0.008)\tLoss 0.8403 (0.8387)\tPrec@1 62.500 (64.936)\n",
            "Epoch: [83][60/110], lr: 0.01000\tTime 0.084 (0.081)\tData 0.000 (0.007)\tLoss 0.9976 (0.8456)\tPrec@1 55.469 (64.383)\n",
            "Epoch: [83][70/110], lr: 0.01000\tTime 0.079 (0.080)\tData 0.012 (0.006)\tLoss 0.9478 (0.8454)\tPrec@1 62.500 (64.569)\n",
            "Epoch: [83][80/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.000 (0.006)\tLoss 0.8173 (0.8458)\tPrec@1 66.406 (64.419)\n",
            "Epoch: [83][90/110], lr: 0.01000\tTime 0.084 (0.079)\tData 0.012 (0.006)\tLoss 0.8535 (0.8441)\tPrec@1 64.844 (64.500)\n",
            "Epoch: [83][100/110], lr: 0.01000\tTime 0.072 (0.078)\tData 0.000 (0.005)\tLoss 0.8054 (0.8414)\tPrec@1 64.062 (64.689)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 0.8767 (0.8767)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.023 (0.057)\tLoss 0.9806 (0.9476)\tPrec@1 60.000 (61.364)\n",
            "Test: [20/100]\tTime 0.023 (0.046)\tLoss 1.1932 (0.9562)\tPrec@1 53.000 (60.667)\n",
            "Test: [30/100]\tTime 0.051 (0.042)\tLoss 0.8918 (0.9571)\tPrec@1 59.000 (60.387)\n",
            "Test: [40/100]\tTime 0.045 (0.040)\tLoss 0.9334 (0.9559)\tPrec@1 58.000 (59.976)\n",
            "Test: [50/100]\tTime 0.028 (0.038)\tLoss 1.0568 (0.9592)\tPrec@1 55.000 (59.765)\n",
            "Test: [60/100]\tTime 0.023 (0.037)\tLoss 1.1000 (0.9651)\tPrec@1 49.000 (59.607)\n",
            "Test: [70/100]\tTime 0.023 (0.037)\tLoss 0.9238 (0.9633)\tPrec@1 59.000 (59.437)\n",
            "Test: [80/100]\tTime 0.064 (0.036)\tLoss 0.8557 (0.9639)\tPrec@1 65.000 (59.457)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 1.0329 (0.9634)\tPrec@1 52.000 (59.374)\n",
            "val Results: Prec@1 59.520 Loss 0.95781\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [84][0/110], lr: 0.01000\tTime 0.477 (0.477)\tData 0.356 (0.356)\tLoss 0.8162 (0.8162)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [84][10/110], lr: 0.01000\tTime 0.073 (0.114)\tData 0.000 (0.034)\tLoss 0.7715 (0.8316)\tPrec@1 67.969 (65.128)\n",
            "Epoch: [84][20/110], lr: 0.01000\tTime 0.069 (0.094)\tData 0.000 (0.020)\tLoss 0.8684 (0.8610)\tPrec@1 59.375 (63.244)\n",
            "Epoch: [84][30/110], lr: 0.01000\tTime 0.071 (0.088)\tData 0.000 (0.014)\tLoss 0.9053 (0.8548)\tPrec@1 58.594 (63.987)\n",
            "Epoch: [84][40/110], lr: 0.01000\tTime 0.077 (0.085)\tData 0.000 (0.011)\tLoss 0.7814 (0.8473)\tPrec@1 65.625 (64.329)\n",
            "Epoch: [84][50/110], lr: 0.01000\tTime 0.065 (0.083)\tData 0.000 (0.009)\tLoss 0.8389 (0.8457)\tPrec@1 67.188 (64.660)\n",
            "Epoch: [84][60/110], lr: 0.01000\tTime 0.081 (0.082)\tData 0.007 (0.008)\tLoss 0.9206 (0.8445)\tPrec@1 60.938 (64.818)\n",
            "Epoch: [84][70/110], lr: 0.01000\tTime 0.072 (0.080)\tData 0.007 (0.008)\tLoss 0.8792 (0.8469)\tPrec@1 60.938 (64.646)\n",
            "Epoch: [84][80/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.007)\tLoss 0.8522 (0.8473)\tPrec@1 67.188 (64.554)\n",
            "Epoch: [84][90/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.007)\tLoss 0.8477 (0.8456)\tPrec@1 60.156 (64.638)\n",
            "Epoch: [84][100/110], lr: 0.01000\tTime 0.062 (0.078)\tData 0.000 (0.006)\tLoss 0.7379 (0.8413)\tPrec@1 67.969 (64.728)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 0.8628 (0.8628)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.026 (0.059)\tLoss 0.8995 (0.9189)\tPrec@1 62.000 (61.364)\n",
            "Test: [20/100]\tTime 0.025 (0.046)\tLoss 1.0942 (0.9225)\tPrec@1 63.000 (61.762)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9350 (0.9267)\tPrec@1 63.000 (61.387)\n",
            "Test: [40/100]\tTime 0.044 (0.040)\tLoss 0.9007 (0.9297)\tPrec@1 60.000 (60.927)\n",
            "Test: [50/100]\tTime 0.023 (0.038)\tLoss 1.0401 (0.9353)\tPrec@1 53.000 (60.667)\n",
            "Test: [60/100]\tTime 0.024 (0.037)\tLoss 1.1169 (0.9443)\tPrec@1 52.000 (60.443)\n",
            "Test: [70/100]\tTime 0.025 (0.037)\tLoss 0.8623 (0.9420)\tPrec@1 68.000 (60.577)\n",
            "Test: [80/100]\tTime 0.030 (0.036)\tLoss 0.8267 (0.9408)\tPrec@1 66.000 (60.642)\n",
            "Test: [90/100]\tTime 0.026 (0.035)\tLoss 0.9520 (0.9410)\tPrec@1 60.000 (60.549)\n",
            "val Results: Prec@1 60.820 Loss 0.93355\n",
            "Best Prec@1: 61.410\n",
            "\n",
            "Epoch: [85][0/110], lr: 0.01000\tTime 0.530 (0.530)\tData 0.307 (0.307)\tLoss 0.8712 (0.8712)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [85][10/110], lr: 0.01000\tTime 0.065 (0.117)\tData 0.000 (0.029)\tLoss 0.8037 (0.8383)\tPrec@1 70.312 (65.838)\n",
            "Epoch: [85][20/110], lr: 0.01000\tTime 0.087 (0.096)\tData 0.013 (0.016)\tLoss 0.8179 (0.8364)\tPrec@1 65.625 (65.699)\n",
            "Epoch: [85][30/110], lr: 0.01000\tTime 0.064 (0.090)\tData 0.000 (0.012)\tLoss 0.8774 (0.8372)\tPrec@1 60.156 (65.927)\n",
            "Epoch: [85][40/110], lr: 0.01000\tTime 0.072 (0.086)\tData 0.007 (0.009)\tLoss 0.8238 (0.8382)\tPrec@1 69.531 (65.796)\n",
            "Epoch: [85][50/110], lr: 0.01000\tTime 0.079 (0.083)\tData 0.000 (0.008)\tLoss 0.8579 (0.8412)\tPrec@1 59.375 (65.441)\n",
            "Epoch: [85][60/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.006 (0.007)\tLoss 0.7868 (0.8373)\tPrec@1 64.062 (65.574)\n",
            "Epoch: [85][70/110], lr: 0.01000\tTime 0.075 (0.080)\tData 0.008 (0.007)\tLoss 0.7638 (0.8343)\tPrec@1 69.531 (65.647)\n",
            "Epoch: [85][80/110], lr: 0.01000\tTime 0.067 (0.080)\tData 0.000 (0.006)\tLoss 0.8174 (0.8365)\tPrec@1 66.406 (65.557)\n",
            "Epoch: [85][90/110], lr: 0.01000\tTime 0.073 (0.079)\tData 0.007 (0.006)\tLoss 0.8777 (0.8376)\tPrec@1 60.156 (65.393)\n",
            "Epoch: [85][100/110], lr: 0.01000\tTime 0.067 (0.078)\tData 0.000 (0.006)\tLoss 0.7991 (0.8354)\tPrec@1 67.969 (65.370)\n",
            "Test: [0/100]\tTime 0.297 (0.297)\tLoss 0.9117 (0.9117)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.035 (0.058)\tLoss 0.8956 (0.9224)\tPrec@1 63.000 (61.909)\n",
            "Test: [20/100]\tTime 0.025 (0.045)\tLoss 1.0703 (0.9224)\tPrec@1 62.000 (62.190)\n",
            "Test: [30/100]\tTime 0.035 (0.042)\tLoss 0.9719 (0.9379)\tPrec@1 60.000 (61.226)\n",
            "Test: [40/100]\tTime 0.041 (0.039)\tLoss 0.8795 (0.9384)\tPrec@1 64.000 (60.561)\n",
            "Test: [50/100]\tTime 0.036 (0.038)\tLoss 1.0133 (0.9389)\tPrec@1 54.000 (60.510)\n",
            "Test: [60/100]\tTime 0.027 (0.038)\tLoss 1.0118 (0.9437)\tPrec@1 59.000 (60.410)\n",
            "Test: [70/100]\tTime 0.051 (0.040)\tLoss 0.9134 (0.9418)\tPrec@1 62.000 (60.563)\n",
            "Test: [80/100]\tTime 0.051 (0.042)\tLoss 0.8973 (0.9370)\tPrec@1 63.000 (60.926)\n",
            "Test: [90/100]\tTime 0.069 (0.044)\tLoss 0.9289 (0.9360)\tPrec@1 62.000 (61.066)\n",
            "val Results: Prec@1 61.420 Loss 0.92831\n",
            "Best Prec@1: 61.420\n",
            "\n",
            "Epoch: [86][0/110], lr: 0.01000\tTime 0.378 (0.378)\tData 0.244 (0.244)\tLoss 0.8095 (0.8095)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [86][10/110], lr: 0.01000\tTime 0.070 (0.112)\tData 0.007 (0.029)\tLoss 0.7500 (0.8061)\tPrec@1 67.188 (66.264)\n",
            "Epoch: [86][20/110], lr: 0.01000\tTime 0.083 (0.094)\tData 0.007 (0.017)\tLoss 0.7220 (0.8087)\tPrec@1 71.094 (66.257)\n",
            "Epoch: [86][30/110], lr: 0.01000\tTime 0.074 (0.087)\tData 0.000 (0.012)\tLoss 0.8848 (0.8197)\tPrec@1 62.500 (65.927)\n",
            "Epoch: [86][40/110], lr: 0.01000\tTime 0.085 (0.084)\tData 0.003 (0.010)\tLoss 0.8358 (0.8152)\tPrec@1 66.406 (66.273)\n",
            "Epoch: [86][50/110], lr: 0.01000\tTime 0.066 (0.082)\tData 0.000 (0.009)\tLoss 0.9041 (0.8154)\tPrec@1 61.719 (66.023)\n",
            "Epoch: [86][60/110], lr: 0.01000\tTime 0.082 (0.080)\tData 0.005 (0.008)\tLoss 0.8627 (0.8252)\tPrec@1 65.625 (65.561)\n",
            "Epoch: [86][70/110], lr: 0.01000\tTime 0.066 (0.079)\tData 0.000 (0.007)\tLoss 0.9869 (0.8296)\tPrec@1 58.594 (65.416)\n",
            "Epoch: [86][80/110], lr: 0.01000\tTime 0.086 (0.078)\tData 0.006 (0.006)\tLoss 0.8392 (0.8328)\tPrec@1 67.969 (65.258)\n",
            "Epoch: [86][90/110], lr: 0.01000\tTime 0.067 (0.078)\tData 0.000 (0.006)\tLoss 0.8088 (0.8312)\tPrec@1 66.406 (65.367)\n",
            "Epoch: [86][100/110], lr: 0.01000\tTime 0.071 (0.077)\tData 0.000 (0.006)\tLoss 0.9288 (0.8351)\tPrec@1 58.594 (65.200)\n",
            "Test: [0/100]\tTime 0.283 (0.283)\tLoss 0.9040 (0.9040)\tPrec@1 61.000 (61.000)\n",
            "Test: [10/100]\tTime 0.032 (0.058)\tLoss 0.9128 (0.9207)\tPrec@1 65.000 (62.636)\n",
            "Test: [20/100]\tTime 0.048 (0.047)\tLoss 1.0233 (0.9186)\tPrec@1 57.000 (61.857)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.9872 (0.9243)\tPrec@1 55.000 (60.484)\n",
            "Test: [40/100]\tTime 0.054 (0.040)\tLoss 0.8775 (0.9215)\tPrec@1 61.000 (60.317)\n",
            "Test: [50/100]\tTime 0.028 (0.039)\tLoss 0.9672 (0.9233)\tPrec@1 56.000 (60.157)\n",
            "Test: [60/100]\tTime 0.025 (0.037)\tLoss 1.0646 (0.9294)\tPrec@1 52.000 (60.328)\n",
            "Test: [70/100]\tTime 0.077 (0.037)\tLoss 0.8531 (0.9272)\tPrec@1 66.000 (60.507)\n",
            "Test: [80/100]\tTime 0.024 (0.036)\tLoss 0.8566 (0.9270)\tPrec@1 59.000 (60.531)\n",
            "Test: [90/100]\tTime 0.023 (0.036)\tLoss 0.8788 (0.9251)\tPrec@1 63.000 (60.593)\n",
            "val Results: Prec@1 60.850 Loss 0.91992\n",
            "Best Prec@1: 61.420\n",
            "\n",
            "Epoch: [87][0/110], lr: 0.01000\tTime 0.461 (0.461)\tData 0.268 (0.268)\tLoss 0.8009 (0.8009)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [87][10/110], lr: 0.01000\tTime 0.067 (0.115)\tData 0.000 (0.026)\tLoss 0.9052 (0.8276)\tPrec@1 63.281 (64.347)\n",
            "Epoch: [87][20/110], lr: 0.01000\tTime 0.069 (0.096)\tData 0.000 (0.014)\tLoss 0.8398 (0.8319)\tPrec@1 67.969 (64.397)\n",
            "Epoch: [87][30/110], lr: 0.01000\tTime 0.091 (0.089)\tData 0.000 (0.010)\tLoss 0.8541 (0.8285)\tPrec@1 58.594 (64.365)\n",
            "Epoch: [87][40/110], lr: 0.01000\tTime 0.072 (0.085)\tData 0.000 (0.008)\tLoss 0.9904 (0.8402)\tPrec@1 58.594 (64.158)\n",
            "Epoch: [87][50/110], lr: 0.01000\tTime 0.073 (0.083)\tData 0.007 (0.007)\tLoss 0.8600 (0.8324)\tPrec@1 64.844 (64.706)\n",
            "Epoch: [87][60/110], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.006)\tLoss 0.7477 (0.8294)\tPrec@1 71.875 (64.754)\n",
            "Epoch: [87][70/110], lr: 0.01000\tTime 0.089 (0.080)\tData 0.009 (0.006)\tLoss 0.9185 (0.8304)\tPrec@1 60.938 (64.767)\n",
            "Epoch: [87][80/110], lr: 0.01000\tTime 0.067 (0.079)\tData 0.000 (0.005)\tLoss 0.6829 (0.8255)\tPrec@1 75.781 (65.230)\n",
            "Epoch: [87][90/110], lr: 0.01000\tTime 0.079 (0.079)\tData 0.005 (0.005)\tLoss 0.7362 (0.8279)\tPrec@1 70.312 (65.084)\n",
            "Epoch: [87][100/110], lr: 0.01000\tTime 0.088 (0.078)\tData 0.000 (0.005)\tLoss 0.7715 (0.8283)\tPrec@1 71.094 (65.176)\n",
            "Test: [0/100]\tTime 0.253 (0.253)\tLoss 0.8582 (0.8582)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.042 (0.059)\tLoss 0.9106 (0.9047)\tPrec@1 66.000 (61.727)\n",
            "Test: [20/100]\tTime 0.029 (0.045)\tLoss 0.9713 (0.9044)\tPrec@1 61.000 (62.667)\n",
            "Test: [30/100]\tTime 0.031 (0.044)\tLoss 0.9094 (0.9138)\tPrec@1 64.000 (61.742)\n",
            "Test: [40/100]\tTime 0.034 (0.043)\tLoss 0.8255 (0.9118)\tPrec@1 65.000 (61.659)\n",
            "Test: [50/100]\tTime 0.030 (0.042)\tLoss 0.9622 (0.9152)\tPrec@1 62.000 (61.314)\n",
            "Test: [60/100]\tTime 0.034 (0.041)\tLoss 1.0508 (0.9238)\tPrec@1 55.000 (60.885)\n",
            "Test: [70/100]\tTime 0.023 (0.041)\tLoss 0.8622 (0.9233)\tPrec@1 62.000 (60.915)\n",
            "Test: [80/100]\tTime 0.054 (0.040)\tLoss 0.9010 (0.9210)\tPrec@1 57.000 (61.148)\n",
            "Test: [90/100]\tTime 0.026 (0.041)\tLoss 0.8761 (0.9178)\tPrec@1 64.000 (61.143)\n",
            "val Results: Prec@1 61.550 Loss 0.90986\n",
            "Best Prec@1: 61.550\n",
            "\n",
            "Epoch: [88][0/110], lr: 0.01000\tTime 0.458 (0.458)\tData 0.256 (0.256)\tLoss 0.7645 (0.7645)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [88][10/110], lr: 0.01000\tTime 0.070 (0.115)\tData 0.000 (0.026)\tLoss 0.7534 (0.7790)\tPrec@1 72.656 (67.969)\n",
            "Epoch: [88][20/110], lr: 0.01000\tTime 0.067 (0.097)\tData 0.000 (0.014)\tLoss 0.8890 (0.8252)\tPrec@1 61.719 (66.295)\n",
            "Epoch: [88][30/110], lr: 0.01000\tTime 0.071 (0.089)\tData 0.000 (0.011)\tLoss 0.9582 (0.8513)\tPrec@1 67.969 (65.045)\n",
            "Epoch: [88][40/110], lr: 0.01000\tTime 0.068 (0.085)\tData 0.000 (0.008)\tLoss 0.7372 (0.8474)\tPrec@1 71.094 (65.034)\n",
            "Epoch: [88][50/110], lr: 0.01000\tTime 0.065 (0.082)\tData 0.000 (0.007)\tLoss 0.7740 (0.8433)\tPrec@1 67.969 (65.135)\n",
            "Epoch: [88][60/110], lr: 0.01000\tTime 0.071 (0.081)\tData 0.000 (0.006)\tLoss 0.7551 (0.8420)\tPrec@1 71.875 (65.266)\n",
            "Epoch: [88][70/110], lr: 0.01000\tTime 0.062 (0.080)\tData 0.000 (0.005)\tLoss 0.8096 (0.8372)\tPrec@1 68.750 (65.438)\n",
            "Epoch: [88][80/110], lr: 0.01000\tTime 0.145 (0.081)\tData 0.008 (0.005)\tLoss 0.8292 (0.8371)\tPrec@1 65.625 (65.500)\n",
            "Epoch: [88][90/110], lr: 0.01000\tTime 0.091 (0.091)\tData 0.005 (0.005)\tLoss 0.8291 (0.8354)\tPrec@1 67.969 (65.548)\n",
            "Epoch: [88][100/110], lr: 0.01000\tTime 0.073 (0.090)\tData 0.007 (0.004)\tLoss 0.8533 (0.8321)\tPrec@1 64.844 (65.756)\n",
            "Test: [0/100]\tTime 0.348 (0.348)\tLoss 0.9519 (0.9519)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.034 (0.066)\tLoss 1.0110 (0.9384)\tPrec@1 66.000 (62.364)\n",
            "Test: [20/100]\tTime 0.023 (0.050)\tLoss 1.0049 (0.9438)\tPrec@1 56.000 (61.524)\n",
            "Test: [30/100]\tTime 0.022 (0.045)\tLoss 1.0106 (0.9529)\tPrec@1 57.000 (60.806)\n",
            "Test: [40/100]\tTime 0.025 (0.044)\tLoss 0.8912 (0.9594)\tPrec@1 62.000 (60.732)\n",
            "Test: [50/100]\tTime 0.027 (0.042)\tLoss 1.0606 (0.9560)\tPrec@1 57.000 (60.745)\n",
            "Test: [60/100]\tTime 0.039 (0.040)\tLoss 1.1372 (0.9596)\tPrec@1 55.000 (60.574)\n",
            "Test: [70/100]\tTime 0.024 (0.039)\tLoss 0.8912 (0.9536)\tPrec@1 67.000 (60.817)\n",
            "Test: [80/100]\tTime 0.025 (0.038)\tLoss 0.8730 (0.9534)\tPrec@1 62.000 (60.852)\n",
            "Test: [90/100]\tTime 0.032 (0.037)\tLoss 0.9388 (0.9540)\tPrec@1 63.000 (60.857)\n",
            "val Results: Prec@1 61.250 Loss 0.94541\n",
            "Best Prec@1: 61.550\n",
            "\n",
            "Epoch: [89][0/110], lr: 0.01000\tTime 0.491 (0.491)\tData 0.373 (0.373)\tLoss 0.7936 (0.7936)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [89][10/110], lr: 0.01000\tTime 0.063 (0.112)\tData 0.000 (0.037)\tLoss 0.7154 (0.8353)\tPrec@1 70.312 (65.767)\n",
            "Epoch: [89][20/110], lr: 0.01000\tTime 0.118 (0.101)\tData 0.009 (0.021)\tLoss 0.8308 (0.8272)\tPrec@1 63.281 (65.885)\n",
            "Epoch: [89][30/110], lr: 0.01000\tTime 0.115 (0.102)\tData 0.000 (0.015)\tLoss 0.9166 (0.8180)\tPrec@1 63.281 (66.028)\n",
            "Epoch: [89][40/110], lr: 0.01000\tTime 0.106 (0.105)\tData 0.000 (0.012)\tLoss 0.8159 (0.8184)\tPrec@1 64.844 (66.330)\n",
            "Epoch: [89][50/110], lr: 0.01000\tTime 0.139 (0.113)\tData 0.000 (0.011)\tLoss 0.7969 (0.8172)\tPrec@1 66.406 (66.207)\n",
            "Epoch: [89][60/110], lr: 0.01000\tTime 0.093 (0.110)\tData 0.007 (0.009)\tLoss 0.7341 (0.8181)\tPrec@1 68.750 (66.073)\n",
            "Epoch: [89][70/110], lr: 0.01000\tTime 0.067 (0.106)\tData 0.000 (0.009)\tLoss 0.7140 (0.8172)\tPrec@1 69.531 (66.076)\n",
            "Epoch: [89][80/110], lr: 0.01000\tTime 0.066 (0.104)\tData 0.000 (0.008)\tLoss 0.7972 (0.8200)\tPrec@1 70.312 (66.040)\n",
            "Epoch: [89][90/110], lr: 0.01000\tTime 0.089 (0.101)\tData 0.000 (0.007)\tLoss 0.7881 (0.8206)\tPrec@1 70.312 (66.011)\n",
            "Epoch: [89][100/110], lr: 0.01000\tTime 0.072 (0.098)\tData 0.006 (0.007)\tLoss 0.8195 (0.8215)\tPrec@1 69.531 (66.012)\n",
            "Test: [0/100]\tTime 0.248 (0.248)\tLoss 0.9448 (0.9448)\tPrec@1 62.000 (62.000)\n",
            "Test: [10/100]\tTime 0.023 (0.058)\tLoss 0.9223 (0.9508)\tPrec@1 62.000 (61.364)\n",
            "Test: [20/100]\tTime 0.033 (0.045)\tLoss 1.0295 (0.9491)\tPrec@1 57.000 (61.762)\n",
            "Test: [30/100]\tTime 0.022 (0.041)\tLoss 0.9641 (0.9513)\tPrec@1 54.000 (61.000)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.8807 (0.9519)\tPrec@1 59.000 (60.683)\n",
            "Test: [50/100]\tTime 0.038 (0.038)\tLoss 1.0303 (0.9508)\tPrec@1 59.000 (60.588)\n",
            "Test: [60/100]\tTime 0.034 (0.037)\tLoss 1.0632 (0.9542)\tPrec@1 51.000 (60.164)\n",
            "Test: [70/100]\tTime 0.028 (0.038)\tLoss 0.8369 (0.9549)\tPrec@1 69.000 (60.113)\n",
            "Test: [80/100]\tTime 0.028 (0.038)\tLoss 0.8419 (0.9511)\tPrec@1 62.000 (60.259)\n",
            "Test: [90/100]\tTime 0.024 (0.037)\tLoss 0.9714 (0.9486)\tPrec@1 58.000 (60.330)\n",
            "val Results: Prec@1 60.530 Loss 0.94032\n",
            "Best Prec@1: 61.550\n",
            "\n",
            "Epoch: [90][0/110], lr: 0.01000\tTime 0.610 (0.610)\tData 0.443 (0.443)\tLoss 0.7631 (0.7631)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [90][10/110], lr: 0.01000\tTime 0.065 (0.134)\tData 0.000 (0.044)\tLoss 0.7037 (0.8096)\tPrec@1 75.000 (66.264)\n",
            "Epoch: [90][20/110], lr: 0.01000\tTime 0.073 (0.110)\tData 0.005 (0.024)\tLoss 0.7982 (0.8239)\tPrec@1 67.969 (66.704)\n",
            "Epoch: [90][30/110], lr: 0.01000\tTime 0.062 (0.098)\tData 0.000 (0.017)\tLoss 0.7720 (0.8260)\tPrec@1 65.625 (66.280)\n",
            "Epoch: [90][40/110], lr: 0.01000\tTime 0.066 (0.091)\tData 0.000 (0.014)\tLoss 0.8137 (0.8245)\tPrec@1 67.969 (66.559)\n",
            "Epoch: [90][50/110], lr: 0.01000\tTime 0.067 (0.088)\tData 0.004 (0.012)\tLoss 0.8286 (0.8241)\tPrec@1 62.500 (66.437)\n",
            "Epoch: [90][60/110], lr: 0.01000\tTime 0.066 (0.085)\tData 0.000 (0.010)\tLoss 0.8932 (0.8287)\tPrec@1 62.500 (66.150)\n",
            "Epoch: [90][70/110], lr: 0.01000\tTime 0.082 (0.084)\tData 0.007 (0.009)\tLoss 0.8677 (0.8352)\tPrec@1 64.062 (65.757)\n",
            "Epoch: [90][80/110], lr: 0.01000\tTime 0.075 (0.083)\tData 0.000 (0.009)\tLoss 0.7738 (0.8302)\tPrec@1 69.531 (65.943)\n",
            "Epoch: [90][90/110], lr: 0.01000\tTime 0.088 (0.082)\tData 0.012 (0.008)\tLoss 0.6904 (0.8261)\tPrec@1 74.219 (66.192)\n",
            "Epoch: [90][100/110], lr: 0.01000\tTime 0.066 (0.081)\tData 0.000 (0.007)\tLoss 0.7453 (0.8275)\tPrec@1 69.531 (66.112)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 0.9027 (0.9027)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.087 (0.065)\tLoss 0.9400 (0.9078)\tPrec@1 59.000 (62.545)\n",
            "Test: [20/100]\tTime 0.039 (0.055)\tLoss 1.0133 (0.9115)\tPrec@1 59.000 (62.190)\n",
            "Test: [30/100]\tTime 0.025 (0.048)\tLoss 0.9319 (0.9143)\tPrec@1 68.000 (62.097)\n",
            "Test: [40/100]\tTime 0.023 (0.046)\tLoss 0.8377 (0.9099)\tPrec@1 66.000 (61.756)\n",
            "Test: [50/100]\tTime 0.050 (0.044)\tLoss 0.9574 (0.9108)\tPrec@1 57.000 (61.529)\n",
            "Test: [60/100]\tTime 0.028 (0.043)\tLoss 0.9758 (0.9157)\tPrec@1 58.000 (61.311)\n",
            "Test: [70/100]\tTime 0.047 (0.043)\tLoss 0.8183 (0.9137)\tPrec@1 70.000 (61.761)\n",
            "Test: [80/100]\tTime 0.069 (0.042)\tLoss 0.9114 (0.9145)\tPrec@1 62.000 (61.815)\n",
            "Test: [90/100]\tTime 0.035 (0.042)\tLoss 1.0114 (0.9132)\tPrec@1 60.000 (61.868)\n",
            "val Results: Prec@1 62.250 Loss 0.90589\n",
            "Best Prec@1: 62.250\n",
            "\n",
            "Epoch: [91][0/110], lr: 0.01000\tTime 0.493 (0.493)\tData 0.349 (0.349)\tLoss 0.7422 (0.7422)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [91][10/110], lr: 0.01000\tTime 0.082 (0.115)\tData 0.000 (0.033)\tLoss 0.9419 (0.8087)\tPrec@1 60.938 (66.477)\n",
            "Epoch: [91][20/110], lr: 0.01000\tTime 0.065 (0.097)\tData 0.000 (0.019)\tLoss 0.9097 (0.8130)\tPrec@1 57.812 (66.369)\n",
            "Epoch: [91][30/110], lr: 0.01000\tTime 0.074 (0.089)\tData 0.011 (0.014)\tLoss 0.8218 (0.8058)\tPrec@1 61.719 (66.532)\n",
            "Epoch: [91][40/110], lr: 0.01000\tTime 0.067 (0.085)\tData 0.003 (0.011)\tLoss 0.9221 (0.8152)\tPrec@1 62.500 (66.044)\n",
            "Epoch: [91][50/110], lr: 0.01000\tTime 0.075 (0.083)\tData 0.006 (0.010)\tLoss 0.8520 (0.8118)\tPrec@1 64.844 (66.115)\n",
            "Epoch: [91][60/110], lr: 0.01000\tTime 0.075 (0.082)\tData 0.008 (0.009)\tLoss 0.8192 (0.8181)\tPrec@1 67.188 (65.894)\n",
            "Epoch: [91][70/110], lr: 0.01000\tTime 0.073 (0.080)\tData 0.005 (0.008)\tLoss 0.7383 (0.8177)\tPrec@1 69.531 (65.933)\n",
            "Epoch: [91][80/110], lr: 0.01000\tTime 0.082 (0.080)\tData 0.008 (0.008)\tLoss 0.7676 (0.8177)\tPrec@1 63.281 (65.856)\n",
            "Epoch: [91][90/110], lr: 0.01000\tTime 0.071 (0.079)\tData 0.001 (0.007)\tLoss 0.7381 (0.8173)\tPrec@1 68.750 (65.968)\n",
            "Epoch: [91][100/110], lr: 0.01000\tTime 0.072 (0.079)\tData 0.002 (0.007)\tLoss 0.8165 (0.8198)\tPrec@1 66.406 (65.826)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 0.8845 (0.8845)\tPrec@1 64.000 (64.000)\n",
            "Test: [10/100]\tTime 0.050 (0.058)\tLoss 1.0028 (0.9618)\tPrec@1 59.000 (61.727)\n",
            "Test: [20/100]\tTime 0.027 (0.045)\tLoss 0.9765 (0.9499)\tPrec@1 65.000 (62.143)\n",
            "Test: [30/100]\tTime 0.037 (0.041)\tLoss 1.0385 (0.9543)\tPrec@1 55.000 (61.516)\n",
            "Test: [40/100]\tTime 0.034 (0.039)\tLoss 0.9466 (0.9543)\tPrec@1 60.000 (61.195)\n",
            "Test: [50/100]\tTime 0.047 (0.037)\tLoss 1.0490 (0.9542)\tPrec@1 53.000 (60.725)\n",
            "Test: [60/100]\tTime 0.022 (0.037)\tLoss 1.1450 (0.9613)\tPrec@1 55.000 (60.525)\n",
            "Test: [70/100]\tTime 0.029 (0.036)\tLoss 0.8686 (0.9599)\tPrec@1 66.000 (60.620)\n",
            "Test: [80/100]\tTime 0.029 (0.035)\tLoss 0.8735 (0.9586)\tPrec@1 62.000 (60.630)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9358 (0.9591)\tPrec@1 61.000 (60.593)\n",
            "val Results: Prec@1 60.770 Loss 0.95267\n",
            "Best Prec@1: 62.250\n",
            "\n",
            "Epoch: [92][0/110], lr: 0.01000\tTime 0.518 (0.518)\tData 0.325 (0.325)\tLoss 0.7651 (0.7651)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [92][10/110], lr: 0.01000\tTime 0.072 (0.114)\tData 0.007 (0.033)\tLoss 0.8691 (0.8204)\tPrec@1 64.844 (66.832)\n",
            "Epoch: [92][20/110], lr: 0.01000\tTime 0.090 (0.095)\tData 0.000 (0.019)\tLoss 0.8239 (0.8213)\tPrec@1 64.844 (65.960)\n",
            "Epoch: [92][30/110], lr: 0.01000\tTime 0.065 (0.089)\tData 0.000 (0.014)\tLoss 0.8514 (0.8250)\tPrec@1 67.188 (65.701)\n",
            "Epoch: [92][40/110], lr: 0.01000\tTime 0.068 (0.085)\tData 0.000 (0.011)\tLoss 0.7890 (0.8269)\tPrec@1 66.406 (65.320)\n",
            "Epoch: [92][50/110], lr: 0.01000\tTime 0.067 (0.082)\tData 0.000 (0.009)\tLoss 0.8174 (0.8301)\tPrec@1 66.406 (65.028)\n",
            "Epoch: [92][60/110], lr: 0.01000\tTime 0.061 (0.080)\tData 0.000 (0.008)\tLoss 0.8303 (0.8259)\tPrec@1 64.844 (65.279)\n",
            "Epoch: [92][70/110], lr: 0.01000\tTime 0.066 (0.080)\tData 0.000 (0.007)\tLoss 0.7893 (0.8248)\tPrec@1 69.531 (65.328)\n",
            "Epoch: [92][80/110], lr: 0.01000\tTime 0.127 (0.081)\tData 0.018 (0.007)\tLoss 0.8175 (0.8213)\tPrec@1 62.500 (65.432)\n",
            "Epoch: [92][90/110], lr: 0.01000\tTime 0.137 (0.084)\tData 0.007 (0.006)\tLoss 0.8564 (0.8208)\tPrec@1 67.188 (65.728)\n",
            "Epoch: [92][100/110], lr: 0.01000\tTime 0.099 (0.086)\tData 0.002 (0.006)\tLoss 0.7127 (0.8137)\tPrec@1 72.656 (66.035)\n",
            "Test: [0/100]\tTime 0.381 (0.381)\tLoss 0.9380 (0.9380)\tPrec@1 59.000 (59.000)\n",
            "Test: [10/100]\tTime 0.056 (0.095)\tLoss 0.8406 (0.9045)\tPrec@1 67.000 (62.909)\n",
            "Test: [20/100]\tTime 0.022 (0.066)\tLoss 0.9371 (0.9030)\tPrec@1 62.000 (62.524)\n",
            "Test: [30/100]\tTime 0.022 (0.055)\tLoss 0.9784 (0.9194)\tPrec@1 62.000 (62.161)\n",
            "Test: [40/100]\tTime 0.030 (0.049)\tLoss 0.8264 (0.9187)\tPrec@1 66.000 (61.878)\n",
            "Test: [50/100]\tTime 0.023 (0.046)\tLoss 1.0085 (0.9165)\tPrec@1 61.000 (61.765)\n",
            "Test: [60/100]\tTime 0.023 (0.044)\tLoss 0.9746 (0.9191)\tPrec@1 59.000 (61.770)\n",
            "Test: [70/100]\tTime 0.028 (0.042)\tLoss 0.8804 (0.9171)\tPrec@1 63.000 (62.000)\n",
            "Test: [80/100]\tTime 0.044 (0.041)\tLoss 0.8097 (0.9150)\tPrec@1 66.000 (62.198)\n",
            "Test: [90/100]\tTime 0.024 (0.040)\tLoss 0.9967 (0.9149)\tPrec@1 59.000 (62.253)\n",
            "val Results: Prec@1 62.480 Loss 0.90862\n",
            "Best Prec@1: 62.480\n",
            "\n",
            "Epoch: [93][0/110], lr: 0.01000\tTime 0.519 (0.519)\tData 0.385 (0.385)\tLoss 0.7726 (0.7726)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [93][10/110], lr: 0.01000\tTime 0.067 (0.116)\tData 0.000 (0.038)\tLoss 0.8110 (0.8035)\tPrec@1 64.062 (65.767)\n",
            "Epoch: [93][20/110], lr: 0.01000\tTime 0.079 (0.096)\tData 0.008 (0.021)\tLoss 0.8576 (0.8127)\tPrec@1 63.281 (65.885)\n",
            "Epoch: [93][30/110], lr: 0.01000\tTime 0.062 (0.087)\tData 0.000 (0.015)\tLoss 0.7370 (0.8139)\tPrec@1 71.094 (66.280)\n",
            "Epoch: [93][40/110], lr: 0.01000\tTime 0.077 (0.084)\tData 0.011 (0.012)\tLoss 0.8407 (0.8129)\tPrec@1 66.406 (66.502)\n",
            "Epoch: [93][50/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.000 (0.010)\tLoss 0.8121 (0.8092)\tPrec@1 66.406 (66.789)\n",
            "Epoch: [93][60/110], lr: 0.01000\tTime 0.064 (0.081)\tData 0.003 (0.009)\tLoss 0.7610 (0.8049)\tPrec@1 64.844 (66.790)\n",
            "Epoch: [93][70/110], lr: 0.01000\tTime 0.065 (0.079)\tData 0.000 (0.008)\tLoss 0.8656 (0.8072)\tPrec@1 64.844 (66.615)\n",
            "Epoch: [93][80/110], lr: 0.01000\tTime 0.065 (0.078)\tData 0.000 (0.007)\tLoss 0.7805 (0.8136)\tPrec@1 69.531 (66.464)\n",
            "Epoch: [93][90/110], lr: 0.01000\tTime 0.076 (0.078)\tData 0.006 (0.007)\tLoss 0.7681 (0.8104)\tPrec@1 67.188 (66.612)\n",
            "Epoch: [93][100/110], lr: 0.01000\tTime 0.075 (0.077)\tData 0.000 (0.006)\tLoss 0.8621 (0.8151)\tPrec@1 64.062 (66.368)\n",
            "Test: [0/100]\tTime 0.269 (0.269)\tLoss 0.9250 (0.9250)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.024 (0.057)\tLoss 0.8931 (0.8879)\tPrec@1 64.000 (64.818)\n",
            "Test: [20/100]\tTime 0.030 (0.045)\tLoss 0.9495 (0.8835)\tPrec@1 63.000 (63.857)\n",
            "Test: [30/100]\tTime 0.031 (0.041)\tLoss 0.9119 (0.8918)\tPrec@1 63.000 (63.452)\n",
            "Test: [40/100]\tTime 0.022 (0.039)\tLoss 0.9068 (0.8923)\tPrec@1 64.000 (63.561)\n",
            "Test: [50/100]\tTime 0.025 (0.037)\tLoss 0.9633 (0.8966)\tPrec@1 62.000 (62.980)\n",
            "Test: [60/100]\tTime 0.023 (0.036)\tLoss 0.9700 (0.8984)\tPrec@1 58.000 (62.787)\n",
            "Test: [70/100]\tTime 0.024 (0.036)\tLoss 0.8486 (0.8996)\tPrec@1 67.000 (62.634)\n",
            "Test: [80/100]\tTime 0.021 (0.035)\tLoss 0.8154 (0.9007)\tPrec@1 66.000 (62.383)\n",
            "Test: [90/100]\tTime 0.037 (0.035)\tLoss 0.9386 (0.9002)\tPrec@1 59.000 (62.451)\n",
            "val Results: Prec@1 62.760 Loss 0.89268\n",
            "Best Prec@1: 62.760\n",
            "\n",
            "Epoch: [94][0/110], lr: 0.01000\tTime 0.493 (0.493)\tData 0.344 (0.344)\tLoss 0.9524 (0.9524)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [94][10/110], lr: 0.01000\tTime 0.078 (0.115)\tData 0.007 (0.034)\tLoss 0.8731 (0.8527)\tPrec@1 64.844 (63.778)\n",
            "Epoch: [94][20/110], lr: 0.01000\tTime 0.092 (0.094)\tData 0.000 (0.018)\tLoss 0.7918 (0.8453)\tPrec@1 65.625 (64.695)\n",
            "Epoch: [94][30/110], lr: 0.01000\tTime 0.063 (0.087)\tData 0.000 (0.013)\tLoss 0.7437 (0.8385)\tPrec@1 70.312 (65.373)\n",
            "Epoch: [94][40/110], lr: 0.01000\tTime 0.066 (0.083)\tData 0.000 (0.011)\tLoss 0.7723 (0.8289)\tPrec@1 67.969 (65.796)\n",
            "Epoch: [94][50/110], lr: 0.01000\tTime 0.078 (0.081)\tData 0.005 (0.010)\tLoss 0.9145 (0.8202)\tPrec@1 62.500 (66.100)\n",
            "Epoch: [94][60/110], lr: 0.01000\tTime 0.064 (0.080)\tData 0.000 (0.009)\tLoss 0.8358 (0.8191)\tPrec@1 69.531 (65.958)\n",
            "Epoch: [94][70/110], lr: 0.01000\tTime 0.069 (0.079)\tData 0.007 (0.008)\tLoss 0.8109 (0.8165)\tPrec@1 66.406 (66.285)\n",
            "Epoch: [94][80/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.007)\tLoss 0.7846 (0.8181)\tPrec@1 66.406 (66.059)\n",
            "Epoch: [94][90/110], lr: 0.01000\tTime 0.075 (0.078)\tData 0.004 (0.007)\tLoss 0.8995 (0.8196)\tPrec@1 60.938 (65.925)\n",
            "Epoch: [94][100/110], lr: 0.01000\tTime 0.085 (0.077)\tData 0.015 (0.006)\tLoss 0.7585 (0.8162)\tPrec@1 64.844 (65.958)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 0.8436 (0.8436)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.033 (0.056)\tLoss 0.8722 (0.8811)\tPrec@1 65.000 (63.182)\n",
            "Test: [20/100]\tTime 0.027 (0.045)\tLoss 0.9375 (0.8750)\tPrec@1 61.000 (63.333)\n",
            "Test: [30/100]\tTime 0.047 (0.041)\tLoss 0.8742 (0.8806)\tPrec@1 63.000 (62.903)\n",
            "Test: [40/100]\tTime 0.050 (0.038)\tLoss 0.8506 (0.8813)\tPrec@1 65.000 (62.829)\n",
            "Test: [50/100]\tTime 0.040 (0.037)\tLoss 0.9300 (0.8774)\tPrec@1 59.000 (63.020)\n",
            "Test: [60/100]\tTime 0.026 (0.036)\tLoss 0.9399 (0.8835)\tPrec@1 61.000 (62.918)\n",
            "Test: [70/100]\tTime 0.026 (0.036)\tLoss 0.7483 (0.8829)\tPrec@1 71.000 (63.042)\n",
            "Test: [80/100]\tTime 0.036 (0.035)\tLoss 0.8327 (0.8799)\tPrec@1 66.000 (63.284)\n",
            "Test: [90/100]\tTime 0.023 (0.035)\tLoss 0.9094 (0.8779)\tPrec@1 63.000 (63.363)\n",
            "val Results: Prec@1 63.520 Loss 0.87316\n",
            "Best Prec@1: 63.520\n",
            "\n",
            "Epoch: [95][0/110], lr: 0.01000\tTime 0.508 (0.508)\tData 0.367 (0.367)\tLoss 0.7665 (0.7665)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [95][10/110], lr: 0.01000\tTime 0.069 (0.114)\tData 0.000 (0.036)\tLoss 0.7610 (0.8021)\tPrec@1 70.312 (66.903)\n",
            "Epoch: [95][20/110], lr: 0.01000\tTime 0.067 (0.094)\tData 0.000 (0.020)\tLoss 0.7770 (0.8136)\tPrec@1 66.406 (66.890)\n",
            "Epoch: [95][30/110], lr: 0.01000\tTime 0.087 (0.088)\tData 0.000 (0.014)\tLoss 0.7655 (0.8086)\tPrec@1 66.406 (67.061)\n",
            "Epoch: [95][40/110], lr: 0.01000\tTime 0.067 (0.085)\tData 0.000 (0.011)\tLoss 0.7673 (0.8077)\tPrec@1 66.406 (66.673)\n",
            "Epoch: [95][50/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.000 (0.009)\tLoss 0.7047 (0.8098)\tPrec@1 74.219 (66.253)\n",
            "Epoch: [95][60/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.009 (0.009)\tLoss 0.8123 (0.8101)\tPrec@1 60.938 (66.253)\n",
            "Epoch: [95][70/110], lr: 0.01000\tTime 0.070 (0.081)\tData 0.000 (0.008)\tLoss 0.7480 (0.8099)\tPrec@1 67.969 (66.318)\n",
            "Epoch: [95][80/110], lr: 0.01000\tTime 0.069 (0.080)\tData 0.007 (0.008)\tLoss 0.8867 (0.8152)\tPrec@1 60.156 (66.030)\n",
            "Epoch: [95][90/110], lr: 0.01000\tTime 0.070 (0.079)\tData 0.000 (0.007)\tLoss 0.7670 (0.8202)\tPrec@1 68.750 (66.003)\n",
            "Epoch: [95][100/110], lr: 0.01000\tTime 0.086 (0.079)\tData 0.000 (0.007)\tLoss 0.7825 (0.8165)\tPrec@1 70.312 (66.112)\n",
            "Test: [0/100]\tTime 0.313 (0.313)\tLoss 0.9085 (0.9085)\tPrec@1 67.000 (67.000)\n",
            "Test: [10/100]\tTime 0.044 (0.059)\tLoss 0.8983 (0.8947)\tPrec@1 61.000 (62.273)\n",
            "Test: [20/100]\tTime 0.033 (0.046)\tLoss 0.9183 (0.8862)\tPrec@1 66.000 (62.810)\n",
            "Test: [30/100]\tTime 0.028 (0.042)\tLoss 0.8412 (0.8878)\tPrec@1 64.000 (62.935)\n",
            "Test: [40/100]\tTime 0.023 (0.040)\tLoss 0.7818 (0.8864)\tPrec@1 66.000 (62.756)\n",
            "Test: [50/100]\tTime 0.022 (0.038)\tLoss 0.9686 (0.8845)\tPrec@1 60.000 (62.745)\n",
            "Test: [60/100]\tTime 0.074 (0.038)\tLoss 1.0413 (0.8915)\tPrec@1 60.000 (62.525)\n",
            "Test: [70/100]\tTime 0.041 (0.039)\tLoss 0.7598 (0.8879)\tPrec@1 69.000 (62.732)\n",
            "Test: [80/100]\tTime 0.052 (0.041)\tLoss 0.7800 (0.8856)\tPrec@1 70.000 (63.049)\n",
            "Test: [90/100]\tTime 0.055 (0.042)\tLoss 0.9282 (0.8864)\tPrec@1 64.000 (62.879)\n",
            "val Results: Prec@1 63.520 Loss 0.87692\n",
            "Best Prec@1: 63.520\n",
            "\n",
            "Epoch: [96][0/110], lr: 0.01000\tTime 0.769 (0.769)\tData 0.423 (0.423)\tLoss 0.7640 (0.7640)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [96][10/110], lr: 0.01000\tTime 0.068 (0.156)\tData 0.000 (0.042)\tLoss 0.8552 (0.8139)\tPrec@1 62.500 (66.619)\n",
            "Epoch: [96][20/110], lr: 0.01000\tTime 0.070 (0.118)\tData 0.005 (0.023)\tLoss 0.7416 (0.8187)\tPrec@1 71.875 (66.183)\n",
            "Epoch: [96][30/110], lr: 0.01000\tTime 0.085 (0.103)\tData 0.007 (0.017)\tLoss 0.8222 (0.8212)\tPrec@1 67.969 (65.877)\n",
            "Epoch: [96][40/110], lr: 0.01000\tTime 0.074 (0.096)\tData 0.000 (0.013)\tLoss 0.7748 (0.8154)\tPrec@1 65.625 (66.387)\n",
            "Epoch: [96][50/110], lr: 0.01000\tTime 0.094 (0.092)\tData 0.010 (0.011)\tLoss 0.7417 (0.8168)\tPrec@1 71.094 (66.161)\n",
            "Epoch: [96][60/110], lr: 0.01000\tTime 0.068 (0.089)\tData 0.004 (0.010)\tLoss 0.7955 (0.8155)\tPrec@1 64.844 (66.265)\n",
            "Epoch: [96][70/110], lr: 0.01000\tTime 0.069 (0.087)\tData 0.000 (0.009)\tLoss 0.8037 (0.8157)\tPrec@1 65.625 (66.164)\n",
            "Epoch: [96][80/110], lr: 0.01000\tTime 0.071 (0.086)\tData 0.000 (0.009)\tLoss 0.6836 (0.8148)\tPrec@1 75.000 (66.348)\n",
            "Epoch: [96][90/110], lr: 0.01000\tTime 0.074 (0.085)\tData 0.007 (0.008)\tLoss 0.9366 (0.8146)\tPrec@1 60.938 (66.346)\n",
            "Epoch: [96][100/110], lr: 0.01000\tTime 0.076 (0.084)\tData 0.007 (0.007)\tLoss 0.7641 (0.8161)\tPrec@1 63.281 (66.399)\n",
            "Test: [0/100]\tTime 0.263 (0.263)\tLoss 0.9125 (0.9125)\tPrec@1 66.000 (66.000)\n",
            "Test: [10/100]\tTime 0.023 (0.058)\tLoss 0.8743 (0.9244)\tPrec@1 65.000 (62.273)\n",
            "Test: [20/100]\tTime 0.040 (0.047)\tLoss 1.0733 (0.9210)\tPrec@1 57.000 (62.095)\n",
            "Test: [30/100]\tTime 0.025 (0.042)\tLoss 0.8849 (0.9319)\tPrec@1 66.000 (60.968)\n",
            "Test: [40/100]\tTime 0.026 (0.040)\tLoss 0.8552 (0.9370)\tPrec@1 63.000 (60.659)\n",
            "Test: [50/100]\tTime 0.038 (0.039)\tLoss 1.0411 (0.9413)\tPrec@1 60.000 (60.510)\n",
            "Test: [60/100]\tTime 0.038 (0.038)\tLoss 1.0263 (0.9482)\tPrec@1 58.000 (60.328)\n",
            "Test: [70/100]\tTime 0.028 (0.038)\tLoss 0.8910 (0.9477)\tPrec@1 66.000 (60.423)\n",
            "Test: [80/100]\tTime 0.026 (0.037)\tLoss 0.8249 (0.9428)\tPrec@1 65.000 (60.642)\n",
            "Test: [90/100]\tTime 0.048 (0.037)\tLoss 1.0408 (0.9426)\tPrec@1 61.000 (60.879)\n",
            "val Results: Prec@1 61.090 Loss 0.93802\n",
            "Best Prec@1: 63.520\n",
            "\n",
            "Epoch: [97][0/110], lr: 0.01000\tTime 0.475 (0.475)\tData 0.309 (0.309)\tLoss 0.7812 (0.7812)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [97][10/110], lr: 0.01000\tTime 0.070 (0.114)\tData 0.000 (0.032)\tLoss 0.9372 (0.8606)\tPrec@1 59.375 (64.347)\n",
            "Epoch: [97][20/110], lr: 0.01000\tTime 0.088 (0.095)\tData 0.010 (0.018)\tLoss 0.7442 (0.8307)\tPrec@1 69.531 (65.290)\n",
            "Epoch: [97][30/110], lr: 0.01000\tTime 0.088 (0.088)\tData 0.007 (0.013)\tLoss 0.7119 (0.8048)\tPrec@1 71.875 (66.683)\n",
            "Epoch: [97][40/110], lr: 0.01000\tTime 0.065 (0.084)\tData 0.000 (0.011)\tLoss 0.8995 (0.8056)\tPrec@1 64.062 (66.444)\n",
            "Epoch: [97][50/110], lr: 0.01000\tTime 0.087 (0.082)\tData 0.007 (0.009)\tLoss 0.7980 (0.8072)\tPrec@1 65.625 (66.513)\n",
            "Epoch: [97][60/110], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.008)\tLoss 0.8466 (0.8062)\tPrec@1 62.500 (66.381)\n",
            "Epoch: [97][70/110], lr: 0.01000\tTime 0.094 (0.081)\tData 0.000 (0.007)\tLoss 0.7992 (0.8065)\tPrec@1 67.969 (66.494)\n",
            "Epoch: [97][80/110], lr: 0.01000\tTime 0.076 (0.080)\tData 0.006 (0.007)\tLoss 0.7099 (0.8077)\tPrec@1 71.094 (66.483)\n",
            "Epoch: [97][90/110], lr: 0.01000\tTime 0.074 (0.079)\tData 0.011 (0.007)\tLoss 0.7729 (0.8080)\tPrec@1 69.531 (66.458)\n",
            "Epoch: [97][100/110], lr: 0.01000\tTime 0.068 (0.078)\tData 0.000 (0.006)\tLoss 0.8454 (0.8085)\tPrec@1 69.531 (66.460)\n",
            "Test: [0/100]\tTime 0.328 (0.328)\tLoss 0.9199 (0.9199)\tPrec@1 63.000 (63.000)\n",
            "Test: [10/100]\tTime 0.023 (0.060)\tLoss 0.8421 (0.8840)\tPrec@1 65.000 (64.091)\n",
            "Test: [20/100]\tTime 0.022 (0.047)\tLoss 0.9469 (0.8868)\tPrec@1 59.000 (63.476)\n",
            "Test: [30/100]\tTime 0.035 (0.042)\tLoss 0.9379 (0.9010)\tPrec@1 60.000 (62.419)\n",
            "Test: [40/100]\tTime 0.049 (0.040)\tLoss 0.8337 (0.9007)\tPrec@1 66.000 (62.317)\n",
            "Test: [50/100]\tTime 0.034 (0.039)\tLoss 0.9387 (0.8934)\tPrec@1 58.000 (62.490)\n",
            "Test: [60/100]\tTime 0.028 (0.038)\tLoss 1.0733 (0.8966)\tPrec@1 57.000 (62.639)\n",
            "Test: [70/100]\tTime 0.026 (0.037)\tLoss 0.8541 (0.8983)\tPrec@1 69.000 (62.634)\n",
            "Test: [80/100]\tTime 0.026 (0.037)\tLoss 0.8696 (0.8963)\tPrec@1 68.000 (62.753)\n",
            "Test: [90/100]\tTime 0.047 (0.036)\tLoss 0.9674 (0.8969)\tPrec@1 55.000 (62.692)\n",
            "val Results: Prec@1 62.910 Loss 0.88986\n",
            "Best Prec@1: 63.520\n",
            "\n",
            "Epoch: [98][0/110], lr: 0.01000\tTime 0.520 (0.520)\tData 0.340 (0.340)\tLoss 0.8894 (0.8894)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [98][10/110], lr: 0.01000\tTime 0.072 (0.118)\tData 0.007 (0.034)\tLoss 0.8426 (0.8135)\tPrec@1 62.500 (65.554)\n",
            "Epoch: [98][20/110], lr: 0.01000\tTime 0.064 (0.096)\tData 0.000 (0.018)\tLoss 0.8474 (0.8082)\tPrec@1 67.188 (66.853)\n",
            "Epoch: [98][30/110], lr: 0.01000\tTime 0.080 (0.090)\tData 0.000 (0.013)\tLoss 0.8317 (0.8135)\tPrec@1 64.844 (66.356)\n",
            "Epoch: [98][40/110], lr: 0.01000\tTime 0.064 (0.086)\tData 0.000 (0.010)\tLoss 0.8208 (0.8048)\tPrec@1 64.062 (66.654)\n",
            "Epoch: [98][50/110], lr: 0.01000\tTime 0.066 (0.083)\tData 0.000 (0.008)\tLoss 0.7269 (0.8043)\tPrec@1 71.094 (66.621)\n",
            "Epoch: [98][60/110], lr: 0.01000\tTime 0.074 (0.082)\tData 0.007 (0.008)\tLoss 0.7817 (0.8041)\tPrec@1 66.406 (66.496)\n",
            "Epoch: [98][70/110], lr: 0.01000\tTime 0.065 (0.081)\tData 0.000 (0.007)\tLoss 0.8969 (0.8049)\tPrec@1 63.281 (66.494)\n",
            "Epoch: [98][80/110], lr: 0.01000\tTime 0.065 (0.080)\tData 0.000 (0.006)\tLoss 0.7733 (0.8044)\tPrec@1 72.656 (66.782)\n",
            "Epoch: [98][90/110], lr: 0.01000\tTime 0.069 (0.079)\tData 0.000 (0.006)\tLoss 0.8041 (0.8020)\tPrec@1 67.188 (66.913)\n",
            "Epoch: [98][100/110], lr: 0.01000\tTime 0.069 (0.079)\tData 0.003 (0.005)\tLoss 0.8774 (0.8072)\tPrec@1 66.406 (66.662)\n",
            "Test: [0/100]\tTime 0.297 (0.297)\tLoss 0.9359 (0.9359)\tPrec@1 54.000 (54.000)\n",
            "Test: [10/100]\tTime 0.043 (0.056)\tLoss 0.8835 (0.8910)\tPrec@1 65.000 (63.818)\n",
            "Test: [20/100]\tTime 0.043 (0.046)\tLoss 0.9071 (0.8905)\tPrec@1 67.000 (63.381)\n",
            "Test: [30/100]\tTime 0.045 (0.042)\tLoss 0.9004 (0.8999)\tPrec@1 62.000 (62.935)\n",
            "Test: [40/100]\tTime 0.037 (0.039)\tLoss 0.8586 (0.9008)\tPrec@1 62.000 (62.585)\n",
            "Test: [50/100]\tTime 0.037 (0.038)\tLoss 1.0269 (0.9001)\tPrec@1 60.000 (62.569)\n",
            "Test: [60/100]\tTime 0.035 (0.037)\tLoss 1.0885 (0.9055)\tPrec@1 50.000 (62.459)\n",
            "Test: [70/100]\tTime 0.053 (0.036)\tLoss 0.8004 (0.9042)\tPrec@1 64.000 (62.338)\n",
            "Test: [80/100]\tTime 0.054 (0.036)\tLoss 0.8395 (0.9040)\tPrec@1 65.000 (62.506)\n",
            "Test: [90/100]\tTime 0.022 (0.036)\tLoss 1.0087 (0.9027)\tPrec@1 58.000 (62.418)\n",
            "val Results: Prec@1 62.700 Loss 0.89992\n",
            "Best Prec@1: 63.520\n",
            "\n",
            "Epoch: [99][0/110], lr: 0.01000\tTime 0.506 (0.506)\tData 0.367 (0.367)\tLoss 0.7970 (0.7970)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [99][10/110], lr: 0.01000\tTime 0.064 (0.115)\tData 0.000 (0.036)\tLoss 0.7057 (0.7926)\tPrec@1 72.656 (67.330)\n",
            "Epoch: [99][20/110], lr: 0.01000\tTime 0.090 (0.096)\tData 0.007 (0.020)\tLoss 0.8776 (0.8181)\tPrec@1 63.281 (66.034)\n",
            "Epoch: [99][30/110], lr: 0.01000\tTime 0.092 (0.090)\tData 0.007 (0.014)\tLoss 0.7602 (0.8077)\tPrec@1 67.188 (66.557)\n",
            "Epoch: [99][40/110], lr: 0.01000\tTime 0.084 (0.086)\tData 0.000 (0.011)\tLoss 0.8063 (0.8056)\tPrec@1 65.625 (66.425)\n",
            "Epoch: [99][50/110], lr: 0.01000\tTime 0.073 (0.084)\tData 0.005 (0.010)\tLoss 0.8503 (0.8116)\tPrec@1 67.969 (66.207)\n",
            "Epoch: [99][60/110], lr: 0.01000\tTime 0.098 (0.084)\tData 0.003 (0.009)\tLoss 0.8224 (0.8089)\tPrec@1 64.844 (66.265)\n",
            "Epoch: [99][70/110], lr: 0.01000\tTime 0.101 (0.087)\tData 0.008 (0.008)\tLoss 0.8619 (0.8114)\tPrec@1 64.844 (66.098)\n",
            "Epoch: [99][80/110], lr: 0.01000\tTime 0.116 (0.090)\tData 0.007 (0.007)\tLoss 0.7374 (0.8078)\tPrec@1 69.531 (66.146)\n",
            "Epoch: [99][90/110], lr: 0.01000\tTime 0.122 (0.093)\tData 0.008 (0.007)\tLoss 0.6436 (0.8033)\tPrec@1 71.875 (66.277)\n",
            "Epoch: [99][100/110], lr: 0.01000\tTime 0.072 (0.094)\tData 0.000 (0.007)\tLoss 0.8770 (0.8052)\tPrec@1 62.500 (66.313)\n",
            "Test: [0/100]\tTime 0.311 (0.311)\tLoss 0.9051 (0.9051)\tPrec@1 60.000 (60.000)\n",
            "Test: [10/100]\tTime 0.025 (0.059)\tLoss 0.9060 (0.9187)\tPrec@1 61.000 (61.182)\n",
            "Test: [20/100]\tTime 0.046 (0.047)\tLoss 0.9716 (0.9194)\tPrec@1 68.000 (61.952)\n",
            "Test: [30/100]\tTime 0.023 (0.042)\tLoss 0.9276 (0.9139)\tPrec@1 61.000 (62.516)\n",
            "Test: [40/100]\tTime 0.024 (0.040)\tLoss 0.8464 (0.9145)\tPrec@1 66.000 (62.171)\n",
            "Test: [50/100]\tTime 0.049 (0.039)\tLoss 0.9553 (0.9173)\tPrec@1 58.000 (61.784)\n",
            "Test: [60/100]\tTime 0.057 (0.038)\tLoss 1.0884 (0.9292)\tPrec@1 54.000 (61.262)\n",
            "Test: [70/100]\tTime 0.027 (0.037)\tLoss 0.8338 (0.9257)\tPrec@1 67.000 (61.380)\n",
            "Test: [80/100]\tTime 0.062 (0.037)\tLoss 0.8640 (0.9268)\tPrec@1 66.000 (61.494)\n",
            "Test: [90/100]\tTime 0.035 (0.037)\tLoss 0.9878 (0.9281)\tPrec@1 58.000 (61.582)\n",
            "val Results: Prec@1 61.880 Loss 0.92094\n",
            "Best Prec@1: 63.520\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network training with SSP models"
      ],
      "metadata": {
        "id": "5C8T9HnAPo91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --loss_type LDAM --imb_factor 0.02 --epochs=100 --pretrained_model '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet50_LDAM_None_exp_0.02_pretrain_rot/ckpt.best.pth.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRdFDHHWBC7a",
        "outputId": "4f4c2d12-2930-4fe8-b6e9-7e7b7e8c35a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Pretrained weights found in total: [319]\n",
            "===> Pre-trained model loaded: /content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet50_LDAM_None_exp_0.02_pretrain_rot/ckpt.best.pth.tar\n",
            "cls num list:\n",
            "[5000, 3237, 2096, 1357, 878, 568, 368, 238, 154, 100]\n",
            "/content/drive/.shortcut-targets-by-id/1CslK100MIylmBJU9zN4Vmh1BZXMZZloK/BDAProject/imbalanced-semi-self-master/losses.py:45: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  output = torch.where(index, x_m, x)\n",
            "Epoch: [0][0/110], lr: 0.00200\tTime 3.348 (3.348)\tData 0.243 (0.243)\tLoss 12.3476 (12.3476)\tPrec@1 7.812 (7.812)\tPrec@5 33.594 (33.594)\n",
            "Epoch: [0][10/110], lr: 0.00200\tTime 0.036 (0.355)\tData 0.000 (0.025)\tLoss 9.4605 (9.5865)\tPrec@1 39.844 (33.594)\tPrec@5 75.781 (77.060)\n",
            "Epoch: [0][20/110], lr: 0.00200\tTime 0.083 (0.217)\tData 0.000 (0.015)\tLoss 7.5933 (8.9270)\tPrec@1 54.688 (39.807)\tPrec@5 82.031 (80.060)\n",
            "Epoch: [0][30/110], lr: 0.00200\tTime 0.085 (0.170)\tData 0.000 (0.014)\tLoss 7.9232 (8.4387)\tPrec@1 47.656 (43.498)\tPrec@5 88.281 (82.686)\n",
            "Epoch: [0][40/110], lr: 0.00200\tTime 0.056 (0.143)\tData 0.000 (0.012)\tLoss 7.3706 (8.1208)\tPrec@1 59.375 (45.636)\tPrec@5 91.406 (84.737)\n",
            "Epoch: [0][50/110], lr: 0.00200\tTime 0.057 (0.126)\tData 0.012 (0.011)\tLoss 7.2805 (7.8344)\tPrec@1 55.469 (48.039)\tPrec@5 89.844 (86.014)\n",
            "Epoch: [0][60/110], lr: 0.00200\tTime 0.064 (0.115)\tData 0.002 (0.010)\tLoss 6.4966 (7.7220)\tPrec@1 55.469 (49.206)\tPrec@5 90.625 (86.808)\n",
            "Epoch: [0][70/110], lr: 0.00200\tTime 0.051 (0.106)\tData 0.000 (0.009)\tLoss 7.6582 (7.6326)\tPrec@1 49.219 (49.846)\tPrec@5 89.062 (86.983)\n",
            "Epoch: [0][80/110], lr: 0.00200\tTime 0.059 (0.100)\tData 0.006 (0.008)\tLoss 5.5068 (7.5123)\tPrec@1 66.406 (50.675)\tPrec@5 94.531 (87.404)\n",
            "Epoch: [0][90/110], lr: 0.00200\tTime 0.058 (0.095)\tData 0.007 (0.008)\tLoss 6.0520 (7.4011)\tPrec@1 58.594 (51.176)\tPrec@5 94.531 (87.989)\n",
            "Epoch: [0][100/110], lr: 0.00200\tTime 0.047 (0.092)\tData 0.008 (0.008)\tLoss 6.2719 (7.2978)\tPrec@1 56.250 (51.880)\tPrec@5 94.531 (88.405)\n",
            "Test: [0/100]\tTime 0.369 (0.369)\tLoss 15.1630 (15.1630)\tPrec@1 24.000 (24.000)\tPrec@5 70.000 (70.000)\n",
            "Test: [10/100]\tTime 0.031 (0.072)\tLoss 11.9210 (14.0879)\tPrec@1 37.000 (27.091)\tPrec@5 78.000 (73.000)\n",
            "Test: [20/100]\tTime 0.032 (0.050)\tLoss 12.9298 (14.1405)\tPrec@1 31.000 (26.714)\tPrec@5 82.000 (73.143)\n",
            "Test: [30/100]\tTime 0.029 (0.040)\tLoss 13.0798 (14.0663)\tPrec@1 29.000 (26.806)\tPrec@5 74.000 (73.355)\n",
            "Test: [40/100]\tTime 0.138 (0.039)\tLoss 14.9867 (14.0921)\tPrec@1 20.000 (26.488)\tPrec@5 76.000 (73.463)\n",
            "Test: [50/100]\tTime 0.046 (0.037)\tLoss 13.5131 (13.9938)\tPrec@1 29.000 (27.000)\tPrec@5 81.000 (73.686)\n",
            "Test: [60/100]\tTime 0.026 (0.037)\tLoss 12.9364 (13.9518)\tPrec@1 26.000 (26.607)\tPrec@5 76.000 (74.115)\n",
            "Test: [70/100]\tTime 0.045 (0.038)\tLoss 13.2907 (13.9487)\tPrec@1 30.000 (26.620)\tPrec@5 76.000 (73.845)\n",
            "Test: [80/100]\tTime 0.036 (0.038)\tLoss 12.2044 (13.8736)\tPrec@1 37.000 (27.012)\tPrec@5 74.000 (74.259)\n",
            "Test: [90/100]\tTime 0.037 (0.038)\tLoss 14.6025 (13.9499)\tPrec@1 24.000 (26.989)\tPrec@5 76.000 (74.000)\n",
            "val Results: Prec@1 27.060 Prec@5 73.890 Loss 13.96434\n",
            "val Class Accuracy: [0.665,0.886,0.334,0.821,0.000,0.000,0.000,0.000,0.000,0.000]\n",
            "Best Prec@1: 27.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [1][0/110], lr: 0.00400\tTime 0.762 (0.762)\tData 0.578 (0.578)\tLoss 7.0204 (7.0204)\tPrec@1 57.812 (57.812)\tPrec@5 92.188 (92.188)\n",
            "Epoch: [1][10/110], lr: 0.00400\tTime 0.096 (0.151)\tData 0.000 (0.061)\tLoss 6.2914 (6.7807)\tPrec@1 58.594 (55.895)\tPrec@5 92.969 (90.270)\n",
            "Epoch: [1][20/110], lr: 0.00400\tTime 0.054 (0.108)\tData 0.004 (0.035)\tLoss 6.9566 (6.7463)\tPrec@1 57.812 (55.692)\tPrec@5 89.844 (90.402)\n",
            "Epoch: [1][30/110], lr: 0.00400\tTime 0.071 (0.092)\tData 0.007 (0.025)\tLoss 6.3968 (6.5389)\tPrec@1 56.250 (56.653)\tPrec@5 97.656 (91.331)\n",
            "Epoch: [1][40/110], lr: 0.00400\tTime 0.077 (0.084)\tData 0.010 (0.020)\tLoss 6.8054 (6.5485)\tPrec@1 53.125 (56.402)\tPrec@5 91.406 (91.311)\n",
            "Epoch: [1][50/110], lr: 0.00400\tTime 0.070 (0.079)\tData 0.000 (0.017)\tLoss 5.7918 (6.4293)\tPrec@1 61.719 (57.384)\tPrec@5 88.281 (91.376)\n",
            "Epoch: [1][60/110], lr: 0.00400\tTime 0.093 (0.076)\tData 0.007 (0.015)\tLoss 5.5758 (6.4052)\tPrec@1 59.375 (57.608)\tPrec@5 94.531 (91.522)\n",
            "Epoch: [1][70/110], lr: 0.00400\tTime 0.057 (0.074)\tData 0.001 (0.013)\tLoss 6.4722 (6.3264)\tPrec@1 55.469 (58.132)\tPrec@5 94.531 (91.879)\n",
            "Epoch: [1][80/110], lr: 0.00400\tTime 0.041 (0.071)\tData 0.003 (0.012)\tLoss 5.1507 (6.2559)\tPrec@1 67.969 (58.719)\tPrec@5 92.969 (92.072)\n",
            "Epoch: [1][90/110], lr: 0.00400\tTime 0.059 (0.070)\tData 0.000 (0.011)\tLoss 5.8626 (6.2562)\tPrec@1 62.500 (58.808)\tPrec@5 91.406 (92.162)\n",
            "Epoch: [1][100/110], lr: 0.00400\tTime 0.078 (0.069)\tData 0.013 (0.011)\tLoss 5.7703 (6.1857)\tPrec@1 65.625 (59.375)\tPrec@5 93.750 (92.365)\n",
            "Test: [0/100]\tTime 0.341 (0.341)\tLoss 14.0655 (14.0655)\tPrec@1 25.000 (25.000)\tPrec@5 83.000 (83.000)\n",
            "Test: [10/100]\tTime 0.025 (0.052)\tLoss 12.3241 (13.2977)\tPrec@1 33.000 (28.273)\tPrec@5 74.000 (80.727)\n",
            "Test: [20/100]\tTime 0.025 (0.042)\tLoss 11.9118 (13.4546)\tPrec@1 34.000 (26.810)\tPrec@5 88.000 (82.048)\n",
            "Test: [30/100]\tTime 0.038 (0.037)\tLoss 12.5130 (13.4383)\tPrec@1 30.000 (26.839)\tPrec@5 80.000 (81.645)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 13.8095 (13.4649)\tPrec@1 24.000 (26.878)\tPrec@5 80.000 (81.683)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 13.0592 (13.3749)\tPrec@1 29.000 (27.196)\tPrec@5 86.000 (82.137)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 11.5571 (13.3241)\tPrec@1 32.000 (26.984)\tPrec@5 86.000 (82.148)\n",
            "Test: [70/100]\tTime 0.017 (0.031)\tLoss 12.7377 (13.2825)\tPrec@1 32.000 (27.183)\tPrec@5 79.000 (81.958)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 11.7367 (13.2340)\tPrec@1 36.000 (27.494)\tPrec@5 82.000 (82.160)\n",
            "Test: [90/100]\tTime 0.047 (0.030)\tLoss 12.8699 (13.2863)\tPrec@1 36.000 (27.363)\tPrec@5 85.000 (81.857)\n",
            "val Results: Prec@1 27.360 Prec@5 81.830 Loss 13.31552\n",
            "val Class Accuracy: [0.894,0.784,0.560,0.467,0.030,0.001,0.000,0.000,0.000,0.000]\n",
            "Best Prec@1: 27.360\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [2][0/110], lr: 0.00600\tTime 0.461 (0.461)\tData 0.378 (0.378)\tLoss 5.4498 (5.4498)\tPrec@1 67.188 (67.188)\tPrec@5 91.406 (91.406)\n",
            "Epoch: [2][10/110], lr: 0.00600\tTime 0.060 (0.101)\tData 0.005 (0.039)\tLoss 5.9411 (6.1104)\tPrec@1 62.500 (61.435)\tPrec@5 95.312 (91.051)\n",
            "Epoch: [2][20/110], lr: 0.00600\tTime 0.044 (0.080)\tData 0.000 (0.023)\tLoss 5.3238 (5.9320)\tPrec@1 65.625 (62.277)\tPrec@5 90.625 (91.443)\n",
            "Epoch: [2][30/110], lr: 0.00600\tTime 0.057 (0.073)\tData 0.014 (0.017)\tLoss 6.9093 (5.9086)\tPrec@1 51.562 (61.996)\tPrec@5 91.406 (92.087)\n",
            "Epoch: [2][40/110], lr: 0.00600\tTime 0.072 (0.069)\tData 0.009 (0.014)\tLoss 5.4613 (5.8585)\tPrec@1 65.625 (62.405)\tPrec@5 92.969 (92.626)\n",
            "Epoch: [2][50/110], lr: 0.00600\tTime 0.058 (0.067)\tData 0.009 (0.012)\tLoss 5.5523 (5.8292)\tPrec@1 67.969 (62.607)\tPrec@5 92.969 (92.555)\n",
            "Epoch: [2][60/110], lr: 0.00600\tTime 0.053 (0.065)\tData 0.004 (0.011)\tLoss 5.5834 (5.7683)\tPrec@1 65.625 (62.884)\tPrec@5 92.969 (92.853)\n",
            "Epoch: [2][70/110], lr: 0.00600\tTime 0.063 (0.064)\tData 0.000 (0.010)\tLoss 5.1784 (5.7658)\tPrec@1 67.188 (62.775)\tPrec@5 97.656 (92.936)\n",
            "Epoch: [2][80/110], lr: 0.00600\tTime 0.075 (0.064)\tData 0.000 (0.009)\tLoss 5.9220 (5.7426)\tPrec@1 64.062 (63.117)\tPrec@5 92.969 (93.027)\n",
            "Epoch: [2][90/110], lr: 0.00600\tTime 0.050 (0.064)\tData 0.007 (0.009)\tLoss 5.0814 (5.7298)\tPrec@1 70.312 (63.393)\tPrec@5 92.188 (93.063)\n",
            "Epoch: [2][100/110], lr: 0.00600\tTime 0.063 (0.063)\tData 0.000 (0.008)\tLoss 5.7126 (5.7030)\tPrec@1 64.844 (63.482)\tPrec@5 91.406 (93.123)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 12.8696 (12.8696)\tPrec@1 35.000 (35.000)\tPrec@5 85.000 (85.000)\n",
            "Test: [10/100]\tTime 0.037 (0.055)\tLoss 10.2353 (11.8978)\tPrec@1 45.000 (34.727)\tPrec@5 91.000 (85.000)\n",
            "Test: [20/100]\tTime 0.025 (0.039)\tLoss 10.9426 (12.0265)\tPrec@1 39.000 (34.333)\tPrec@5 85.000 (84.667)\n",
            "Test: [30/100]\tTime 0.025 (0.035)\tLoss 11.3216 (11.9706)\tPrec@1 35.000 (34.516)\tPrec@5 87.000 (84.613)\n",
            "Test: [40/100]\tTime 0.037 (0.032)\tLoss 12.4973 (12.0276)\tPrec@1 30.000 (34.146)\tPrec@5 83.000 (84.512)\n",
            "Test: [50/100]\tTime 0.036 (0.031)\tLoss 11.8705 (11.9396)\tPrec@1 35.000 (34.216)\tPrec@5 78.000 (84.784)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 10.3360 (11.8866)\tPrec@1 39.000 (34.066)\tPrec@5 89.000 (84.803)\n",
            "Test: [70/100]\tTime 0.029 (0.029)\tLoss 11.5112 (11.8508)\tPrec@1 37.000 (34.211)\tPrec@5 88.000 (84.662)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 10.7956 (11.8118)\tPrec@1 44.000 (34.617)\tPrec@5 84.000 (84.889)\n",
            "Test: [90/100]\tTime 0.018 (0.029)\tLoss 12.0177 (11.8640)\tPrec@1 35.000 (34.374)\tPrec@5 84.000 (84.868)\n",
            "val Results: Prec@1 34.250 Prec@5 84.680 Loss 11.88725\n",
            "val Class Accuracy: [0.895,0.897,0.584,0.506,0.000,0.000,0.543,0.000,0.000,0.000]\n",
            "Best Prec@1: 34.250\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [3][0/110], lr: 0.00800\tTime 0.470 (0.470)\tData 0.377 (0.377)\tLoss 4.5540 (4.5540)\tPrec@1 71.875 (71.875)\tPrec@5 96.094 (96.094)\n",
            "Epoch: [3][10/110], lr: 0.00800\tTime 0.066 (0.104)\tData 0.001 (0.039)\tLoss 5.3914 (5.4164)\tPrec@1 67.188 (65.483)\tPrec@5 92.188 (94.389)\n",
            "Epoch: [3][20/110], lr: 0.00800\tTime 0.041 (0.082)\tData 0.000 (0.023)\tLoss 5.6504 (5.4692)\tPrec@1 67.188 (65.290)\tPrec@5 93.750 (93.936)\n",
            "Epoch: [3][30/110], lr: 0.00800\tTime 0.061 (0.075)\tData 0.000 (0.017)\tLoss 5.7877 (5.4835)\tPrec@1 62.500 (65.146)\tPrec@5 93.750 (94.279)\n",
            "Epoch: [3][40/110], lr: 0.00800\tTime 0.061 (0.072)\tData 0.005 (0.013)\tLoss 4.5194 (5.3699)\tPrec@1 74.219 (65.930)\tPrec@5 96.094 (94.474)\n",
            "Epoch: [3][50/110], lr: 0.00800\tTime 0.043 (0.069)\tData 0.000 (0.012)\tLoss 5.4025 (5.3709)\tPrec@1 67.188 (66.039)\tPrec@5 94.531 (94.485)\n",
            "Epoch: [3][60/110], lr: 0.00800\tTime 0.060 (0.068)\tData 0.005 (0.010)\tLoss 6.3091 (5.3781)\tPrec@1 63.281 (66.124)\tPrec@5 94.531 (94.403)\n",
            "Epoch: [3][70/110], lr: 0.00800\tTime 0.042 (0.067)\tData 0.000 (0.009)\tLoss 5.9638 (5.3547)\tPrec@1 63.281 (66.351)\tPrec@5 95.312 (94.454)\n",
            "Epoch: [3][80/110], lr: 0.00800\tTime 0.050 (0.066)\tData 0.000 (0.008)\tLoss 5.4672 (5.3177)\tPrec@1 62.500 (66.426)\tPrec@5 95.312 (94.493)\n",
            "Epoch: [3][90/110], lr: 0.00800\tTime 0.074 (0.065)\tData 0.007 (0.008)\tLoss 5.1454 (5.3122)\tPrec@1 68.750 (66.423)\tPrec@5 96.875 (94.488)\n",
            "Epoch: [3][100/110], lr: 0.00800\tTime 0.058 (0.064)\tData 0.000 (0.008)\tLoss 6.0352 (5.3044)\tPrec@1 62.500 (66.545)\tPrec@5 93.750 (94.616)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 12.9233 (12.9233)\tPrec@1 25.000 (25.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.027 (0.050)\tLoss 10.2893 (11.9307)\tPrec@1 44.000 (31.909)\tPrec@5 84.000 (86.636)\n",
            "Test: [20/100]\tTime 0.021 (0.040)\tLoss 10.8610 (12.0837)\tPrec@1 40.000 (30.952)\tPrec@5 90.000 (87.238)\n",
            "Test: [30/100]\tTime 0.014 (0.034)\tLoss 11.4881 (12.0395)\tPrec@1 31.000 (31.097)\tPrec@5 89.000 (86.742)\n",
            "Test: [40/100]\tTime 0.011 (0.032)\tLoss 12.5531 (12.0806)\tPrec@1 32.000 (31.024)\tPrec@5 87.000 (86.732)\n",
            "Test: [50/100]\tTime 0.036 (0.031)\tLoss 11.4437 (11.9832)\tPrec@1 37.000 (31.824)\tPrec@5 87.000 (86.824)\n",
            "Test: [60/100]\tTime 0.041 (0.030)\tLoss 10.1274 (11.9195)\tPrec@1 37.000 (31.770)\tPrec@5 88.000 (86.639)\n",
            "Test: [70/100]\tTime 0.027 (0.029)\tLoss 11.3520 (11.8954)\tPrec@1 38.000 (31.930)\tPrec@5 88.000 (86.521)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 10.6640 (11.8609)\tPrec@1 43.000 (32.000)\tPrec@5 88.000 (86.691)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 11.9789 (11.9157)\tPrec@1 34.000 (31.791)\tPrec@5 90.000 (86.703)\n",
            "val Results: Prec@1 31.700 Prec@5 86.570 Loss 11.94516\n",
            "val Class Accuracy: [0.960,0.813,0.418,0.632,0.141,0.000,0.140,0.066,0.000,0.000]\n",
            "Best Prec@1: 34.250\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [4][0/110], lr: 0.01000\tTime 0.475 (0.475)\tData 0.391 (0.391)\tLoss 4.7167 (4.7167)\tPrec@1 74.219 (74.219)\tPrec@5 94.531 (94.531)\n",
            "Epoch: [4][10/110], lr: 0.01000\tTime 0.070 (0.101)\tData 0.004 (0.039)\tLoss 4.8862 (4.9426)\tPrec@1 67.969 (68.892)\tPrec@5 95.312 (95.028)\n",
            "Epoch: [4][20/110], lr: 0.01000\tTime 0.038 (0.079)\tData 0.000 (0.023)\tLoss 5.6173 (5.0276)\tPrec@1 65.625 (68.490)\tPrec@5 92.969 (95.461)\n",
            "Epoch: [4][30/110], lr: 0.01000\tTime 0.060 (0.073)\tData 0.007 (0.017)\tLoss 4.7022 (5.0201)\tPrec@1 68.750 (68.448)\tPrec@5 94.531 (95.262)\n",
            "Epoch: [4][40/110], lr: 0.01000\tTime 0.063 (0.069)\tData 0.007 (0.015)\tLoss 4.0883 (4.9596)\tPrec@1 75.781 (68.941)\tPrec@5 97.656 (95.351)\n",
            "Epoch: [4][50/110], lr: 0.01000\tTime 0.042 (0.067)\tData 0.000 (0.013)\tLoss 4.9469 (4.9565)\tPrec@1 69.531 (69.179)\tPrec@5 97.656 (95.190)\n",
            "Epoch: [4][60/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.000 (0.011)\tLoss 5.7903 (4.9791)\tPrec@1 65.625 (69.237)\tPrec@5 93.750 (95.082)\n",
            "Epoch: [4][70/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.006 (0.011)\tLoss 4.9075 (4.9814)\tPrec@1 68.750 (69.388)\tPrec@5 92.969 (95.081)\n",
            "Epoch: [4][80/110], lr: 0.01000\tTime 0.060 (0.064)\tData 0.000 (0.010)\tLoss 4.7142 (5.0051)\tPrec@1 71.094 (69.184)\tPrec@5 94.531 (95.110)\n",
            "Epoch: [4][90/110], lr: 0.01000\tTime 0.049 (0.064)\tData 0.000 (0.009)\tLoss 4.9792 (4.9905)\tPrec@1 70.312 (69.248)\tPrec@5 95.312 (95.175)\n",
            "Epoch: [4][100/110], lr: 0.01000\tTime 0.041 (0.063)\tData 0.000 (0.009)\tLoss 4.9492 (4.9626)\tPrec@1 70.312 (69.423)\tPrec@5 96.094 (95.289)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 12.6235 (12.6235)\tPrec@1 31.000 (31.000)\tPrec@5 87.000 (87.000)\n",
            "Test: [10/100]\tTime 0.024 (0.053)\tLoss 10.2298 (11.8152)\tPrec@1 45.000 (35.182)\tPrec@5 90.000 (87.818)\n",
            "Test: [20/100]\tTime 0.017 (0.038)\tLoss 10.8063 (11.8632)\tPrec@1 43.000 (35.143)\tPrec@5 88.000 (88.286)\n",
            "Test: [30/100]\tTime 0.018 (0.035)\tLoss 11.1761 (11.8166)\tPrec@1 35.000 (34.839)\tPrec@5 87.000 (87.968)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 12.3175 (11.8657)\tPrec@1 33.000 (34.756)\tPrec@5 87.000 (87.976)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 11.7724 (11.7690)\tPrec@1 37.000 (35.765)\tPrec@5 88.000 (87.765)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 10.4915 (11.7290)\tPrec@1 36.000 (35.770)\tPrec@5 88.000 (87.885)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 11.2183 (11.7085)\tPrec@1 37.000 (35.704)\tPrec@5 86.000 (87.775)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 10.5090 (11.6743)\tPrec@1 43.000 (35.765)\tPrec@5 88.000 (87.864)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 12.1970 (11.7314)\tPrec@1 34.000 (35.407)\tPrec@5 88.000 (87.901)\n",
            "val Results: Prec@1 35.320 Prec@5 87.750 Loss 11.75592\n",
            "val Class Accuracy: [0.915,0.961,0.265,0.486,0.711,0.000,0.193,0.001,0.000,0.000]\n",
            "Best Prec@1: 35.320\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [5][0/110], lr: 0.01000\tTime 0.489 (0.489)\tData 0.412 (0.412)\tLoss 4.7932 (4.7932)\tPrec@1 70.312 (70.312)\tPrec@5 96.875 (96.875)\n",
            "Epoch: [5][10/110], lr: 0.01000\tTime 0.067 (0.103)\tData 0.000 (0.041)\tLoss 4.6273 (4.8601)\tPrec@1 73.438 (70.597)\tPrec@5 97.656 (96.307)\n",
            "Epoch: [5][20/110], lr: 0.01000\tTime 0.075 (0.082)\tData 0.009 (0.023)\tLoss 4.6858 (4.7436)\tPrec@1 73.438 (71.429)\tPrec@5 95.312 (96.726)\n",
            "Epoch: [5][30/110], lr: 0.01000\tTime 0.041 (0.073)\tData 0.000 (0.017)\tLoss 5.2464 (4.8663)\tPrec@1 65.625 (70.943)\tPrec@5 95.312 (96.220)\n",
            "Epoch: [5][40/110], lr: 0.01000\tTime 0.064 (0.070)\tData 0.007 (0.014)\tLoss 4.7396 (4.8360)\tPrec@1 71.875 (70.941)\tPrec@5 96.875 (96.227)\n",
            "Epoch: [5][50/110], lr: 0.01000\tTime 0.055 (0.068)\tData 0.000 (0.012)\tLoss 4.4719 (4.8899)\tPrec@1 71.094 (70.435)\tPrec@5 93.750 (95.910)\n",
            "Epoch: [5][60/110], lr: 0.01000\tTime 0.052 (0.067)\tData 0.012 (0.011)\tLoss 4.6903 (4.8785)\tPrec@1 72.656 (70.466)\tPrec@5 94.531 (95.953)\n",
            "Epoch: [5][70/110], lr: 0.01000\tTime 0.061 (0.066)\tData 0.002 (0.010)\tLoss 4.7261 (4.8625)\tPrec@1 67.969 (70.610)\tPrec@5 94.531 (96.028)\n",
            "Epoch: [5][80/110], lr: 0.01000\tTime 0.100 (0.066)\tData 0.012 (0.010)\tLoss 4.2020 (4.8576)\tPrec@1 75.000 (70.689)\tPrec@5 98.438 (95.997)\n",
            "Epoch: [5][90/110], lr: 0.01000\tTime 0.178 (0.069)\tData 0.000 (0.009)\tLoss 4.8424 (4.8305)\tPrec@1 67.188 (70.785)\tPrec@5 97.656 (96.034)\n",
            "Epoch: [5][100/110], lr: 0.01000\tTime 0.076 (0.071)\tData 0.000 (0.009)\tLoss 4.4125 (4.8157)\tPrec@1 72.656 (70.978)\tPrec@5 97.656 (96.055)\n",
            "Test: [0/100]\tTime 0.428 (0.428)\tLoss 14.8740 (14.8740)\tPrec@1 25.000 (25.000)\tPrec@5 89.000 (89.000)\n",
            "Test: [10/100]\tTime 0.032 (0.080)\tLoss 11.2559 (13.4656)\tPrec@1 39.000 (29.455)\tPrec@5 86.000 (85.727)\n",
            "Test: [20/100]\tTime 0.043 (0.062)\tLoss 12.6435 (13.6723)\tPrec@1 33.000 (28.143)\tPrec@5 83.000 (84.667)\n",
            "Test: [30/100]\tTime 0.033 (0.053)\tLoss 13.2226 (13.5524)\tPrec@1 30.000 (28.774)\tPrec@5 84.000 (84.742)\n",
            "Test: [40/100]\tTime 0.033 (0.046)\tLoss 14.5983 (13.6657)\tPrec@1 24.000 (28.537)\tPrec@5 75.000 (84.390)\n",
            "Test: [50/100]\tTime 0.013 (0.042)\tLoss 13.0415 (13.5667)\tPrec@1 29.000 (28.882)\tPrec@5 83.000 (84.667)\n",
            "Test: [60/100]\tTime 0.038 (0.040)\tLoss 11.5070 (13.5520)\tPrec@1 35.000 (28.607)\tPrec@5 85.000 (84.754)\n",
            "Test: [70/100]\tTime 0.037 (0.038)\tLoss 13.4705 (13.5187)\tPrec@1 30.000 (28.789)\tPrec@5 90.000 (84.803)\n",
            "Test: [80/100]\tTime 0.022 (0.036)\tLoss 12.0287 (13.4571)\tPrec@1 41.000 (29.136)\tPrec@5 84.000 (84.975)\n",
            "Test: [90/100]\tTime 0.034 (0.035)\tLoss 12.8187 (13.5106)\tPrec@1 33.000 (28.813)\tPrec@5 86.000 (85.165)\n",
            "val Results: Prec@1 28.780 Prec@5 85.160 Loss 13.53708\n",
            "val Class Accuracy: [0.962,0.961,0.636,0.244,0.067,0.000,0.007,0.001,0.000,0.000]\n",
            "Best Prec@1: 35.320\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [6][0/110], lr: 0.01000\tTime 0.419 (0.419)\tData 0.318 (0.318)\tLoss 5.0123 (5.0123)\tPrec@1 71.875 (71.875)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [6][10/110], lr: 0.01000\tTime 0.060 (0.100)\tData 0.005 (0.033)\tLoss 4.2690 (4.6354)\tPrec@1 71.094 (71.662)\tPrec@5 96.094 (96.733)\n",
            "Epoch: [6][20/110], lr: 0.01000\tTime 0.038 (0.080)\tData 0.000 (0.019)\tLoss 5.3510 (4.7392)\tPrec@1 65.625 (71.019)\tPrec@5 96.094 (96.503)\n",
            "Epoch: [6][30/110], lr: 0.01000\tTime 0.047 (0.073)\tData 0.000 (0.015)\tLoss 4.2802 (4.7579)\tPrec@1 75.781 (71.169)\tPrec@5 96.094 (96.169)\n",
            "Epoch: [6][40/110], lr: 0.01000\tTime 0.065 (0.069)\tData 0.007 (0.012)\tLoss 5.7207 (4.7180)\tPrec@1 66.406 (71.684)\tPrec@5 96.094 (96.284)\n",
            "Epoch: [6][50/110], lr: 0.01000\tTime 0.081 (0.068)\tData 0.008 (0.011)\tLoss 4.6258 (4.6893)\tPrec@1 70.312 (72.028)\tPrec@5 97.656 (96.446)\n",
            "Epoch: [6][60/110], lr: 0.01000\tTime 0.068 (0.066)\tData 0.000 (0.009)\tLoss 4.6590 (4.6596)\tPrec@1 73.438 (72.208)\tPrec@5 97.656 (96.542)\n",
            "Epoch: [6][70/110], lr: 0.01000\tTime 0.047 (0.065)\tData 0.008 (0.009)\tLoss 4.3403 (4.6157)\tPrec@1 74.219 (72.480)\tPrec@5 96.875 (96.611)\n",
            "Epoch: [6][80/110], lr: 0.01000\tTime 0.060 (0.065)\tData 0.012 (0.009)\tLoss 5.3239 (4.6124)\tPrec@1 69.531 (72.444)\tPrec@5 96.875 (96.586)\n",
            "Epoch: [6][90/110], lr: 0.01000\tTime 0.042 (0.064)\tData 0.000 (0.009)\tLoss 4.4952 (4.5721)\tPrec@1 75.781 (72.879)\tPrec@5 96.875 (96.643)\n",
            "Epoch: [6][100/110], lr: 0.01000\tTime 0.055 (0.064)\tData 0.012 (0.009)\tLoss 4.8172 (4.5560)\tPrec@1 71.875 (72.997)\tPrec@5 95.312 (96.751)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 12.7493 (12.7493)\tPrec@1 29.000 (29.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.011 (0.056)\tLoss 10.1261 (11.5019)\tPrec@1 45.000 (37.909)\tPrec@5 86.000 (87.727)\n",
            "Test: [20/100]\tTime 0.010 (0.040)\tLoss 10.3790 (11.5099)\tPrec@1 44.000 (37.048)\tPrec@5 92.000 (88.429)\n",
            "Test: [30/100]\tTime 0.048 (0.036)\tLoss 11.2131 (11.4463)\tPrec@1 33.000 (37.290)\tPrec@5 92.000 (88.935)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 11.9280 (11.4730)\tPrec@1 37.000 (37.317)\tPrec@5 89.000 (89.000)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 11.0028 (11.3915)\tPrec@1 38.000 (37.882)\tPrec@5 93.000 (89.098)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 9.8721 (11.3911)\tPrec@1 42.000 (37.574)\tPrec@5 87.000 (88.902)\n",
            "Test: [70/100]\tTime 0.020 (0.030)\tLoss 10.5848 (11.3772)\tPrec@1 41.000 (37.803)\tPrec@5 92.000 (88.535)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 10.3365 (11.3339)\tPrec@1 49.000 (38.062)\tPrec@5 90.000 (88.642)\n",
            "Test: [90/100]\tTime 0.018 (0.028)\tLoss 11.3536 (11.4091)\tPrec@1 40.000 (37.692)\tPrec@5 89.000 (88.363)\n",
            "val Results: Prec@1 37.600 Prec@5 88.430 Loss 11.42586\n",
            "val Class Accuracy: [0.852,0.914,0.743,0.551,0.294,0.291,0.014,0.068,0.000,0.033]\n",
            "Best Prec@1: 37.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [7][0/110], lr: 0.01000\tTime 0.459 (0.459)\tData 0.353 (0.353)\tLoss 4.1709 (4.1709)\tPrec@1 74.219 (74.219)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [7][10/110], lr: 0.01000\tTime 0.049 (0.102)\tData 0.011 (0.038)\tLoss 3.9335 (4.5650)\tPrec@1 78.125 (72.372)\tPrec@5 98.438 (97.372)\n",
            "Epoch: [7][20/110], lr: 0.01000\tTime 0.045 (0.080)\tData 0.000 (0.023)\tLoss 4.0783 (4.4562)\tPrec@1 73.438 (73.289)\tPrec@5 96.875 (96.838)\n",
            "Epoch: [7][30/110], lr: 0.01000\tTime 0.056 (0.073)\tData 0.007 (0.018)\tLoss 4.1923 (4.3952)\tPrec@1 76.562 (73.891)\tPrec@5 97.656 (96.598)\n",
            "Epoch: [7][40/110], lr: 0.01000\tTime 0.051 (0.069)\tData 0.000 (0.014)\tLoss 4.1097 (4.3522)\tPrec@1 75.000 (74.314)\tPrec@5 98.438 (96.799)\n",
            "Epoch: [7][50/110], lr: 0.01000\tTime 0.037 (0.067)\tData 0.000 (0.013)\tLoss 4.7480 (4.3445)\tPrec@1 75.781 (74.525)\tPrec@5 96.094 (96.691)\n",
            "Epoch: [7][60/110], lr: 0.01000\tTime 0.062 (0.066)\tData 0.006 (0.011)\tLoss 4.7405 (4.3332)\tPrec@1 72.656 (74.590)\tPrec@5 96.875 (96.862)\n",
            "Epoch: [7][70/110], lr: 0.01000\tTime 0.059 (0.065)\tData 0.007 (0.010)\tLoss 4.0840 (4.3373)\tPrec@1 75.000 (74.571)\tPrec@5 96.094 (96.886)\n",
            "Epoch: [7][80/110], lr: 0.01000\tTime 0.038 (0.064)\tData 0.000 (0.010)\tLoss 3.5524 (4.3346)\tPrec@1 82.031 (74.711)\tPrec@5 99.219 (96.962)\n",
            "Epoch: [7][90/110], lr: 0.01000\tTime 0.041 (0.063)\tData 0.000 (0.009)\tLoss 4.0843 (4.3439)\tPrec@1 78.125 (74.657)\tPrec@5 99.219 (96.987)\n",
            "Epoch: [7][100/110], lr: 0.01000\tTime 0.059 (0.063)\tData 0.007 (0.009)\tLoss 5.0124 (4.3562)\tPrec@1 71.875 (74.606)\tPrec@5 99.219 (97.030)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 14.8329 (14.8329)\tPrec@1 24.000 (24.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/100]\tTime 0.048 (0.051)\tLoss 11.2819 (13.4321)\tPrec@1 41.000 (31.000)\tPrec@5 90.000 (89.182)\n",
            "Test: [20/100]\tTime 0.013 (0.039)\tLoss 11.9189 (13.4286)\tPrec@1 38.000 (31.333)\tPrec@5 93.000 (88.810)\n",
            "Test: [30/100]\tTime 0.044 (0.035)\tLoss 13.0470 (13.3396)\tPrec@1 28.000 (31.677)\tPrec@5 87.000 (88.968)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 14.2386 (13.3765)\tPrec@1 28.000 (31.659)\tPrec@5 89.000 (88.902)\n",
            "Test: [50/100]\tTime 0.041 (0.032)\tLoss 12.9162 (13.2708)\tPrec@1 35.000 (32.157)\tPrec@5 91.000 (89.000)\n",
            "Test: [60/100]\tTime 0.013 (0.031)\tLoss 11.3872 (13.3058)\tPrec@1 38.000 (31.525)\tPrec@5 90.000 (88.672)\n",
            "Test: [70/100]\tTime 0.018 (0.029)\tLoss 13.0785 (13.2879)\tPrec@1 34.000 (31.549)\tPrec@5 94.000 (88.690)\n",
            "Test: [80/100]\tTime 0.024 (0.030)\tLoss 11.2578 (13.2128)\tPrec@1 43.000 (31.963)\tPrec@5 94.000 (88.951)\n",
            "Test: [90/100]\tTime 0.013 (0.029)\tLoss 12.0925 (13.2977)\tPrec@1 38.000 (31.648)\tPrec@5 92.000 (88.791)\n",
            "val Results: Prec@1 31.620 Prec@5 88.870 Loss 13.31972\n",
            "val Class Accuracy: [0.912,0.987,0.743,0.204,0.047,0.161,0.055,0.053,0.000,0.000]\n",
            "Best Prec@1: 37.600\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [8][0/110], lr: 0.01000\tTime 0.354 (0.354)\tData 0.265 (0.265)\tLoss 4.2122 (4.2122)\tPrec@1 75.000 (75.000)\tPrec@5 96.094 (96.094)\n",
            "Epoch: [8][10/110], lr: 0.01000\tTime 0.051 (0.099)\tData 0.000 (0.031)\tLoss 3.7672 (4.3431)\tPrec@1 76.562 (74.787)\tPrec@5 99.219 (96.875)\n",
            "Epoch: [8][20/110], lr: 0.01000\tTime 0.064 (0.080)\tData 0.007 (0.018)\tLoss 4.0751 (4.3102)\tPrec@1 76.562 (75.484)\tPrec@5 97.656 (97.135)\n",
            "Epoch: [8][30/110], lr: 0.01000\tTime 0.039 (0.072)\tData 0.000 (0.014)\tLoss 4.8693 (4.3807)\tPrec@1 68.750 (74.698)\tPrec@5 97.656 (96.900)\n",
            "Epoch: [8][40/110], lr: 0.01000\tTime 0.071 (0.070)\tData 0.000 (0.011)\tLoss 3.2907 (4.2963)\tPrec@1 83.594 (75.171)\tPrec@5 98.438 (96.837)\n",
            "Epoch: [8][50/110], lr: 0.01000\tTime 0.050 (0.067)\tData 0.000 (0.010)\tLoss 3.7834 (4.2885)\tPrec@1 81.250 (75.322)\tPrec@5 99.219 (96.967)\n",
            "Epoch: [8][60/110], lr: 0.01000\tTime 0.072 (0.066)\tData 0.000 (0.009)\tLoss 3.6907 (4.2456)\tPrec@1 82.812 (75.538)\tPrec@5 97.656 (97.106)\n",
            "Epoch: [8][70/110], lr: 0.01000\tTime 0.066 (0.065)\tData 0.007 (0.008)\tLoss 2.9594 (4.2048)\tPrec@1 85.156 (75.814)\tPrec@5 99.219 (97.249)\n",
            "Epoch: [8][80/110], lr: 0.01000\tTime 0.054 (0.064)\tData 0.005 (0.008)\tLoss 3.6611 (4.1796)\tPrec@1 75.000 (75.965)\tPrec@5 96.094 (97.232)\n",
            "Epoch: [8][90/110], lr: 0.01000\tTime 0.048 (0.063)\tData 0.002 (0.007)\tLoss 3.1499 (4.1793)\tPrec@1 85.156 (76.004)\tPrec@5 98.438 (97.218)\n",
            "Epoch: [8][100/110], lr: 0.01000\tTime 0.060 (0.063)\tData 0.007 (0.007)\tLoss 5.1957 (4.1621)\tPrec@1 71.094 (76.207)\tPrec@5 99.219 (97.262)\n",
            "Test: [0/100]\tTime 0.299 (0.299)\tLoss 12.2901 (12.2901)\tPrec@1 38.000 (38.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.028 (0.055)\tLoss 9.1561 (11.2363)\tPrec@1 55.000 (42.636)\tPrec@5 92.000 (91.273)\n",
            "Test: [20/100]\tTime 0.010 (0.043)\tLoss 11.0470 (11.2218)\tPrec@1 40.000 (42.857)\tPrec@5 94.000 (91.810)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 10.7300 (11.1488)\tPrec@1 43.000 (43.581)\tPrec@5 91.000 (91.258)\n",
            "Test: [40/100]\tTime 0.028 (0.033)\tLoss 11.7200 (11.2029)\tPrec@1 39.000 (43.220)\tPrec@5 95.000 (91.537)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 11.2458 (11.1041)\tPrec@1 40.000 (43.588)\tPrec@5 90.000 (91.725)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 9.9041 (11.1260)\tPrec@1 45.000 (43.197)\tPrec@5 91.000 (91.869)\n",
            "Test: [70/100]\tTime 0.016 (0.030)\tLoss 10.0107 (11.1211)\tPrec@1 53.000 (43.197)\tPrec@5 95.000 (91.817)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 9.9317 (11.0789)\tPrec@1 56.000 (43.296)\tPrec@5 88.000 (91.815)\n",
            "Test: [90/100]\tTime 0.045 (0.029)\tLoss 11.1067 (11.1362)\tPrec@1 44.000 (42.901)\tPrec@5 90.000 (91.670)\n",
            "val Results: Prec@1 42.820 Prec@5 91.640 Loss 11.16076\n",
            "val Class Accuracy: [0.896,0.925,0.763,0.596,0.564,0.006,0.392,0.098,0.041,0.001]\n",
            "Best Prec@1: 42.820\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [9][0/110], lr: 0.01000\tTime 0.459 (0.459)\tData 0.354 (0.354)\tLoss 3.4300 (3.4300)\tPrec@1 78.125 (78.125)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [9][10/110], lr: 0.01000\tTime 0.043 (0.101)\tData 0.000 (0.038)\tLoss 4.3497 (4.1168)\tPrec@1 72.656 (75.497)\tPrec@5 99.219 (98.224)\n",
            "Epoch: [9][20/110], lr: 0.01000\tTime 0.069 (0.083)\tData 0.000 (0.021)\tLoss 4.5626 (4.0438)\tPrec@1 71.875 (76.860)\tPrec@5 97.656 (98.028)\n",
            "Epoch: [9][30/110], lr: 0.01000\tTime 0.047 (0.075)\tData 0.000 (0.016)\tLoss 3.2982 (3.9533)\tPrec@1 82.031 (77.445)\tPrec@5 99.219 (98.236)\n",
            "Epoch: [9][40/110], lr: 0.01000\tTime 0.041 (0.072)\tData 0.000 (0.013)\tLoss 4.1576 (3.9175)\tPrec@1 80.469 (77.858)\tPrec@5 97.656 (98.075)\n",
            "Epoch: [9][50/110], lr: 0.01000\tTime 0.060 (0.069)\tData 0.007 (0.012)\tLoss 3.9865 (3.9683)\tPrec@1 78.906 (77.405)\tPrec@5 96.875 (97.825)\n",
            "Epoch: [9][60/110], lr: 0.01000\tTime 0.068 (0.068)\tData 0.012 (0.011)\tLoss 4.7834 (3.9745)\tPrec@1 72.656 (77.305)\tPrec@5 94.531 (97.656)\n",
            "Epoch: [9][70/110], lr: 0.01000\tTime 0.072 (0.067)\tData 0.017 (0.010)\tLoss 3.7549 (4.0242)\tPrec@1 79.688 (77.080)\tPrec@5 99.219 (97.557)\n",
            "Epoch: [9][80/110], lr: 0.01000\tTime 0.068 (0.066)\tData 0.011 (0.009)\tLoss 3.4375 (4.0583)\tPrec@1 81.250 (76.958)\tPrec@5 98.438 (97.463)\n",
            "Epoch: [9][90/110], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.009)\tLoss 3.0252 (4.0252)\tPrec@1 81.250 (77.052)\tPrec@5 97.656 (97.459)\n",
            "Epoch: [9][100/110], lr: 0.01000\tTime 0.050 (0.065)\tData 0.000 (0.008)\tLoss 4.4976 (4.0475)\tPrec@1 74.219 (76.972)\tPrec@5 96.875 (97.494)\n",
            "Test: [0/100]\tTime 0.315 (0.315)\tLoss 12.1120 (12.1120)\tPrec@1 38.000 (38.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.027 (0.056)\tLoss 8.5252 (10.8734)\tPrec@1 54.000 (44.455)\tPrec@5 91.000 (92.727)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 9.9323 (11.0516)\tPrec@1 45.000 (42.381)\tPrec@5 95.000 (93.381)\n",
            "Test: [30/100]\tTime 0.029 (0.035)\tLoss 10.5349 (10.9969)\tPrec@1 49.000 (42.774)\tPrec@5 95.000 (93.323)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 11.3883 (11.0553)\tPrec@1 41.000 (42.878)\tPrec@5 95.000 (93.341)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 10.5670 (10.9486)\tPrec@1 46.000 (43.471)\tPrec@5 95.000 (93.529)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 9.7183 (10.9331)\tPrec@1 43.000 (43.311)\tPrec@5 94.000 (93.607)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 10.1545 (10.8965)\tPrec@1 50.000 (43.479)\tPrec@5 99.000 (93.577)\n",
            "Test: [80/100]\tTime 0.030 (0.029)\tLoss 9.5818 (10.8491)\tPrec@1 49.000 (43.642)\tPrec@5 92.000 (93.679)\n",
            "Test: [90/100]\tTime 0.029 (0.029)\tLoss 11.1494 (10.8907)\tPrec@1 39.000 (43.440)\tPrec@5 97.000 (93.560)\n",
            "val Results: Prec@1 43.510 Prec@5 93.680 Loss 10.89593\n",
            "val Class Accuracy: [0.939,0.965,0.599,0.823,0.332,0.124,0.305,0.245,0.007,0.012]\n",
            "Best Prec@1: 43.510\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [10][0/110], lr: 0.01000\tTime 0.491 (0.491)\tData 0.400 (0.400)\tLoss 3.3604 (3.3604)\tPrec@1 82.812 (82.812)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [10][10/110], lr: 0.01000\tTime 0.040 (0.101)\tData 0.000 (0.042)\tLoss 3.9323 (3.7873)\tPrec@1 78.125 (79.190)\tPrec@5 96.875 (98.011)\n",
            "Epoch: [10][20/110], lr: 0.01000\tTime 0.067 (0.086)\tData 0.007 (0.024)\tLoss 4.2245 (3.8787)\tPrec@1 78.125 (78.311)\tPrec@5 96.875 (97.991)\n",
            "Epoch: [10][30/110], lr: 0.01000\tTime 0.094 (0.086)\tData 0.015 (0.019)\tLoss 3.9649 (3.9089)\tPrec@1 77.344 (78.175)\tPrec@5 95.312 (97.757)\n",
            "Epoch: [10][40/110], lr: 0.01000\tTime 0.086 (0.087)\tData 0.011 (0.017)\tLoss 3.3928 (3.8938)\tPrec@1 83.594 (78.049)\tPrec@5 96.875 (97.771)\n",
            "Epoch: [10][50/110], lr: 0.01000\tTime 0.079 (0.088)\tData 0.006 (0.016)\tLoss 2.6485 (3.8917)\tPrec@1 89.844 (78.156)\tPrec@5 100.000 (97.702)\n",
            "Epoch: [10][60/110], lr: 0.01000\tTime 0.103 (0.088)\tData 0.011 (0.015)\tLoss 3.8850 (3.8823)\tPrec@1 77.344 (78.125)\tPrec@5 98.438 (97.656)\n",
            "Epoch: [10][70/110], lr: 0.01000\tTime 0.065 (0.087)\tData 0.009 (0.014)\tLoss 3.7390 (3.8740)\tPrec@1 80.469 (78.246)\tPrec@5 99.219 (97.689)\n",
            "Epoch: [10][80/110], lr: 0.01000\tTime 0.068 (0.083)\tData 0.014 (0.013)\tLoss 4.1649 (3.8614)\tPrec@1 76.562 (78.250)\tPrec@5 94.531 (97.714)\n",
            "Epoch: [10][90/110], lr: 0.01000\tTime 0.086 (0.081)\tData 0.000 (0.012)\tLoss 4.1277 (3.8601)\tPrec@1 74.219 (78.185)\tPrec@5 97.656 (97.734)\n",
            "Epoch: [10][100/110], lr: 0.01000\tTime 0.062 (0.079)\tData 0.006 (0.012)\tLoss 4.4010 (3.8668)\tPrec@1 74.219 (78.148)\tPrec@5 95.312 (97.718)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 11.7644 (11.7644)\tPrec@1 42.000 (42.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.034 (0.052)\tLoss 7.3309 (10.4692)\tPrec@1 66.000 (48.091)\tPrec@5 93.000 (93.909)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 9.9526 (10.5732)\tPrec@1 51.000 (48.000)\tPrec@5 98.000 (94.333)\n",
            "Test: [30/100]\tTime 0.025 (0.037)\tLoss 10.1634 (10.5737)\tPrec@1 49.000 (47.774)\tPrec@5 90.000 (94.065)\n",
            "Test: [40/100]\tTime 0.031 (0.035)\tLoss 11.5074 (10.6419)\tPrec@1 41.000 (47.317)\tPrec@5 93.000 (94.073)\n",
            "Test: [50/100]\tTime 0.017 (0.032)\tLoss 10.2560 (10.5235)\tPrec@1 49.000 (47.941)\tPrec@5 96.000 (94.176)\n",
            "Test: [60/100]\tTime 0.023 (0.031)\tLoss 9.2101 (10.4853)\tPrec@1 54.000 (48.082)\tPrec@5 96.000 (94.148)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 10.8717 (10.4910)\tPrec@1 48.000 (48.099)\tPrec@5 97.000 (93.887)\n",
            "Test: [80/100]\tTime 0.030 (0.030)\tLoss 8.8957 (10.4704)\tPrec@1 54.000 (48.000)\tPrec@5 91.000 (93.802)\n",
            "Test: [90/100]\tTime 0.010 (0.030)\tLoss 10.7679 (10.5194)\tPrec@1 48.000 (47.769)\tPrec@5 99.000 (93.802)\n",
            "val Results: Prec@1 47.710 Prec@5 93.730 Loss 10.53728\n",
            "val Class Accuracy: [0.948,0.969,0.628,0.473,0.591,0.315,0.696,0.134,0.000,0.017]\n",
            "Best Prec@1: 47.710\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [11][0/110], lr: 0.01000\tTime 0.408 (0.408)\tData 0.324 (0.324)\tLoss 3.5611 (3.5611)\tPrec@1 81.250 (81.250)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [11][10/110], lr: 0.01000\tTime 0.044 (0.101)\tData 0.000 (0.034)\tLoss 2.5823 (3.7254)\tPrec@1 88.281 (79.616)\tPrec@5 99.219 (98.438)\n",
            "Epoch: [11][20/110], lr: 0.01000\tTime 0.046 (0.083)\tData 0.000 (0.021)\tLoss 3.7253 (3.6496)\tPrec@1 79.688 (79.985)\tPrec@5 97.656 (98.028)\n",
            "Epoch: [11][30/110], lr: 0.01000\tTime 0.065 (0.076)\tData 0.008 (0.016)\tLoss 3.8574 (3.6716)\tPrec@1 78.125 (79.763)\tPrec@5 98.438 (97.984)\n",
            "Epoch: [11][40/110], lr: 0.01000\tTime 0.044 (0.071)\tData 0.000 (0.014)\tLoss 4.7578 (3.6790)\tPrec@1 72.656 (79.783)\tPrec@5 98.438 (98.037)\n",
            "Epoch: [11][50/110], lr: 0.01000\tTime 0.073 (0.070)\tData 0.001 (0.012)\tLoss 3.2723 (3.6612)\tPrec@1 84.375 (79.841)\tPrec@5 99.219 (98.024)\n",
            "Epoch: [11][60/110], lr: 0.01000\tTime 0.044 (0.068)\tData 0.000 (0.011)\tLoss 3.7630 (3.7102)\tPrec@1 75.000 (79.380)\tPrec@5 97.656 (97.874)\n",
            "Epoch: [11][70/110], lr: 0.01000\tTime 0.100 (0.067)\tData 0.013 (0.010)\tLoss 5.0076 (3.7558)\tPrec@1 72.656 (79.104)\tPrec@5 96.875 (97.843)\n",
            "Epoch: [11][80/110], lr: 0.01000\tTime 0.061 (0.066)\tData 0.010 (0.009)\tLoss 3.7162 (3.7350)\tPrec@1 78.125 (79.234)\tPrec@5 98.438 (97.878)\n",
            "Epoch: [11][90/110], lr: 0.01000\tTime 0.076 (0.065)\tData 0.009 (0.009)\tLoss 3.5873 (3.7319)\tPrec@1 81.250 (79.258)\tPrec@5 97.656 (97.914)\n",
            "Epoch: [11][100/110], lr: 0.01000\tTime 0.061 (0.065)\tData 0.004 (0.008)\tLoss 2.6399 (3.7025)\tPrec@1 85.938 (79.479)\tPrec@5 99.219 (97.881)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 11.1553 (11.1553)\tPrec@1 47.000 (47.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.037 (0.054)\tLoss 8.2383 (10.4064)\tPrec@1 58.000 (48.909)\tPrec@5 93.000 (93.636)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 10.3607 (10.5484)\tPrec@1 46.000 (48.333)\tPrec@5 95.000 (93.857)\n",
            "Test: [30/100]\tTime 0.025 (0.036)\tLoss 10.1994 (10.4661)\tPrec@1 52.000 (48.742)\tPrec@5 92.000 (93.290)\n",
            "Test: [40/100]\tTime 0.035 (0.034)\tLoss 11.3822 (10.5476)\tPrec@1 44.000 (48.293)\tPrec@5 94.000 (93.415)\n",
            "Test: [50/100]\tTime 0.015 (0.032)\tLoss 9.8302 (10.4515)\tPrec@1 53.000 (48.647)\tPrec@5 96.000 (93.745)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 9.3340 (10.4181)\tPrec@1 51.000 (48.738)\tPrec@5 92.000 (93.590)\n",
            "Test: [70/100]\tTime 0.021 (0.031)\tLoss 9.6660 (10.4169)\tPrec@1 56.000 (48.789)\tPrec@5 93.000 (93.296)\n",
            "Test: [80/100]\tTime 0.039 (0.030)\tLoss 8.9541 (10.3812)\tPrec@1 57.000 (48.975)\tPrec@5 90.000 (93.333)\n",
            "Test: [90/100]\tTime 0.021 (0.030)\tLoss 10.9564 (10.4509)\tPrec@1 48.000 (48.571)\tPrec@5 95.000 (93.341)\n",
            "val Results: Prec@1 48.480 Prec@5 93.300 Loss 10.48153\n",
            "val Class Accuracy: [0.944,0.933,0.695,0.517,0.740,0.132,0.630,0.236,0.002,0.019]\n",
            "Best Prec@1: 48.480\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [12][0/110], lr: 0.01000\tTime 0.487 (0.487)\tData 0.372 (0.372)\tLoss 3.7404 (3.7404)\tPrec@1 78.125 (78.125)\tPrec@5 96.875 (96.875)\n",
            "Epoch: [12][10/110], lr: 0.01000\tTime 0.052 (0.104)\tData 0.000 (0.038)\tLoss 2.6545 (3.6019)\tPrec@1 86.719 (79.403)\tPrec@5 100.000 (98.366)\n",
            "Epoch: [12][20/110], lr: 0.01000\tTime 0.059 (0.083)\tData 0.006 (0.023)\tLoss 3.5270 (3.5009)\tPrec@1 79.688 (80.320)\tPrec@5 98.438 (98.251)\n",
            "Epoch: [12][30/110], lr: 0.01000\tTime 0.067 (0.076)\tData 0.007 (0.017)\tLoss 3.4063 (3.5975)\tPrec@1 82.812 (79.889)\tPrec@5 97.656 (98.085)\n",
            "Epoch: [12][40/110], lr: 0.01000\tTime 0.061 (0.072)\tData 0.000 (0.013)\tLoss 4.0790 (3.6122)\tPrec@1 77.344 (79.973)\tPrec@5 97.656 (98.095)\n",
            "Epoch: [12][50/110], lr: 0.01000\tTime 0.067 (0.069)\tData 0.000 (0.012)\tLoss 3.4266 (3.6784)\tPrec@1 82.031 (79.534)\tPrec@5 97.656 (97.886)\n",
            "Epoch: [12][60/110], lr: 0.01000\tTime 0.050 (0.068)\tData 0.000 (0.010)\tLoss 3.8298 (3.6277)\tPrec@1 81.250 (79.790)\tPrec@5 97.656 (98.015)\n",
            "Epoch: [12][70/110], lr: 0.01000\tTime 0.049 (0.067)\tData 0.000 (0.010)\tLoss 4.8630 (3.6443)\tPrec@1 72.656 (79.842)\tPrec@5 96.094 (97.909)\n",
            "Epoch: [12][80/110], lr: 0.01000\tTime 0.055 (0.066)\tData 0.000 (0.009)\tLoss 3.0838 (3.6144)\tPrec@1 80.469 (80.054)\tPrec@5 99.219 (97.984)\n",
            "Epoch: [12][90/110], lr: 0.01000\tTime 0.044 (0.066)\tData 0.000 (0.009)\tLoss 3.9274 (3.6218)\tPrec@1 77.344 (79.902)\tPrec@5 100.000 (98.043)\n",
            "Epoch: [12][100/110], lr: 0.01000\tTime 0.059 (0.066)\tData 0.000 (0.008)\tLoss 3.3298 (3.6014)\tPrec@1 79.688 (80.020)\tPrec@5 98.438 (98.144)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 11.4285 (11.4285)\tPrec@1 47.000 (47.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.018 (0.055)\tLoss 8.6144 (10.5571)\tPrec@1 60.000 (47.545)\tPrec@5 94.000 (95.364)\n",
            "Test: [20/100]\tTime 0.021 (0.039)\tLoss 9.1799 (10.4514)\tPrec@1 55.000 (46.905)\tPrec@5 97.000 (95.143)\n",
            "Test: [30/100]\tTime 0.035 (0.036)\tLoss 9.7260 (10.3605)\tPrec@1 48.000 (47.258)\tPrec@5 97.000 (94.871)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 11.2634 (10.4717)\tPrec@1 42.000 (46.585)\tPrec@5 94.000 (94.829)\n",
            "Test: [50/100]\tTime 0.030 (0.032)\tLoss 9.5734 (10.3176)\tPrec@1 49.000 (47.588)\tPrec@5 97.000 (94.882)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 8.7281 (10.3074)\tPrec@1 54.000 (47.377)\tPrec@5 96.000 (94.820)\n",
            "Test: [70/100]\tTime 0.035 (0.031)\tLoss 9.5768 (10.2903)\tPrec@1 53.000 (47.465)\tPrec@5 96.000 (94.761)\n",
            "Test: [80/100]\tTime 0.021 (0.030)\tLoss 9.3764 (10.2527)\tPrec@1 52.000 (47.642)\tPrec@5 98.000 (94.877)\n",
            "Test: [90/100]\tTime 0.030 (0.029)\tLoss 10.2098 (10.2855)\tPrec@1 47.000 (47.505)\tPrec@5 94.000 (94.835)\n",
            "val Results: Prec@1 47.450 Prec@5 94.800 Loss 10.31712\n",
            "val Class Accuracy: [0.920,0.954,0.664,0.781,0.430,0.335,0.449,0.080,0.070,0.062]\n",
            "Best Prec@1: 48.480\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [13][0/110], lr: 0.01000\tTime 0.472 (0.472)\tData 0.381 (0.381)\tLoss 3.5601 (3.5601)\tPrec@1 82.031 (82.031)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [13][10/110], lr: 0.01000\tTime 0.041 (0.099)\tData 0.000 (0.039)\tLoss 3.4440 (3.6567)\tPrec@1 83.594 (79.830)\tPrec@5 99.219 (98.438)\n",
            "Epoch: [13][20/110], lr: 0.01000\tTime 0.093 (0.083)\tData 0.006 (0.022)\tLoss 3.5700 (3.6476)\tPrec@1 82.812 (80.022)\tPrec@5 100.000 (98.251)\n",
            "Epoch: [13][30/110], lr: 0.01000\tTime 0.068 (0.075)\tData 0.015 (0.017)\tLoss 2.8622 (3.5896)\tPrec@1 85.156 (80.292)\tPrec@5 99.219 (98.236)\n",
            "Epoch: [13][40/110], lr: 0.01000\tTime 0.041 (0.070)\tData 0.003 (0.014)\tLoss 2.3092 (3.5579)\tPrec@1 89.062 (80.716)\tPrec@5 100.000 (98.266)\n",
            "Epoch: [13][50/110], lr: 0.01000\tTime 0.062 (0.069)\tData 0.000 (0.012)\tLoss 2.9370 (3.4754)\tPrec@1 85.938 (81.219)\tPrec@5 98.438 (98.361)\n",
            "Epoch: [13][60/110], lr: 0.01000\tTime 0.046 (0.067)\tData 0.002 (0.011)\tLoss 2.4526 (3.4050)\tPrec@1 89.844 (81.634)\tPrec@5 98.438 (98.399)\n",
            "Epoch: [13][70/110], lr: 0.01000\tTime 0.058 (0.066)\tData 0.000 (0.010)\tLoss 2.7876 (3.3942)\tPrec@1 85.938 (81.657)\tPrec@5 99.219 (98.449)\n",
            "Epoch: [13][80/110], lr: 0.01000\tTime 0.049 (0.065)\tData 0.000 (0.009)\tLoss 3.2455 (3.4205)\tPrec@1 81.250 (81.414)\tPrec@5 100.000 (98.399)\n",
            "Epoch: [13][90/110], lr: 0.01000\tTime 0.040 (0.065)\tData 0.000 (0.009)\tLoss 3.3398 (3.4555)\tPrec@1 82.031 (81.181)\tPrec@5 98.438 (98.292)\n",
            "Epoch: [13][100/110], lr: 0.01000\tTime 0.064 (0.064)\tData 0.007 (0.008)\tLoss 3.7613 (3.4493)\tPrec@1 80.469 (81.204)\tPrec@5 100.000 (98.337)\n",
            "Test: [0/100]\tTime 0.346 (0.346)\tLoss 11.5136 (11.5136)\tPrec@1 45.000 (45.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.053)\tLoss 7.4594 (10.2732)\tPrec@1 70.000 (51.818)\tPrec@5 93.000 (95.000)\n",
            "Test: [20/100]\tTime 0.044 (0.041)\tLoss 9.4437 (10.0755)\tPrec@1 57.000 (52.810)\tPrec@5 94.000 (94.667)\n",
            "Test: [30/100]\tTime 0.032 (0.038)\tLoss 9.3883 (10.0325)\tPrec@1 54.000 (52.484)\tPrec@5 95.000 (94.581)\n",
            "Test: [40/100]\tTime 0.022 (0.035)\tLoss 10.4273 (10.1243)\tPrec@1 53.000 (52.146)\tPrec@5 95.000 (94.902)\n",
            "Test: [50/100]\tTime 0.017 (0.033)\tLoss 9.1126 (9.9921)\tPrec@1 59.000 (52.667)\tPrec@5 97.000 (95.137)\n",
            "Test: [60/100]\tTime 0.024 (0.032)\tLoss 8.6272 (9.9920)\tPrec@1 59.000 (52.639)\tPrec@5 94.000 (95.033)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 9.4552 (9.9785)\tPrec@1 56.000 (52.592)\tPrec@5 97.000 (95.028)\n",
            "Test: [80/100]\tTime 0.039 (0.030)\tLoss 9.0459 (9.9516)\tPrec@1 56.000 (52.815)\tPrec@5 96.000 (95.235)\n",
            "Test: [90/100]\tTime 0.030 (0.030)\tLoss 9.8136 (9.9862)\tPrec@1 56.000 (52.670)\tPrec@5 97.000 (95.165)\n",
            "val Results: Prec@1 52.770 Prec@5 95.130 Loss 10.00835\n",
            "val Class Accuracy: [0.894,0.990,0.717,0.610,0.762,0.547,0.518,0.095,0.140,0.004]\n",
            "Best Prec@1: 52.770\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [14][0/110], lr: 0.01000\tTime 0.397 (0.397)\tData 0.309 (0.309)\tLoss 3.0004 (3.0004)\tPrec@1 82.031 (82.031)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [14][10/110], lr: 0.01000\tTime 0.073 (0.104)\tData 0.014 (0.035)\tLoss 4.1109 (3.3093)\tPrec@1 78.906 (81.960)\tPrec@5 99.219 (99.077)\n",
            "Epoch: [14][20/110], lr: 0.01000\tTime 0.073 (0.083)\tData 0.011 (0.020)\tLoss 2.8485 (3.2078)\tPrec@1 85.156 (82.292)\tPrec@5 97.656 (98.884)\n",
            "Epoch: [14][30/110], lr: 0.01000\tTime 0.064 (0.075)\tData 0.000 (0.015)\tLoss 2.9556 (3.2695)\tPrec@1 85.938 (82.233)\tPrec@5 99.219 (98.690)\n",
            "Epoch: [14][40/110], lr: 0.01000\tTime 0.053 (0.071)\tData 0.007 (0.014)\tLoss 3.4937 (3.3426)\tPrec@1 81.250 (81.764)\tPrec@5 99.219 (98.514)\n",
            "Epoch: [14][50/110], lr: 0.01000\tTime 0.044 (0.069)\tData 0.000 (0.012)\tLoss 3.4896 (3.3724)\tPrec@1 82.812 (81.572)\tPrec@5 99.219 (98.591)\n",
            "Epoch: [14][60/110], lr: 0.01000\tTime 0.048 (0.067)\tData 0.000 (0.011)\tLoss 2.9809 (3.3710)\tPrec@1 81.250 (81.570)\tPrec@5 98.438 (98.604)\n",
            "Epoch: [14][70/110], lr: 0.01000\tTime 0.078 (0.066)\tData 0.007 (0.010)\tLoss 2.6186 (3.3445)\tPrec@1 86.719 (81.723)\tPrec@5 100.000 (98.636)\n",
            "Epoch: [14][80/110], lr: 0.01000\tTime 0.066 (0.066)\tData 0.012 (0.009)\tLoss 3.6708 (3.3751)\tPrec@1 81.250 (81.607)\tPrec@5 97.656 (98.524)\n",
            "Epoch: [14][90/110], lr: 0.01000\tTime 0.080 (0.065)\tData 0.000 (0.008)\tLoss 3.6021 (3.4115)\tPrec@1 80.469 (81.413)\tPrec@5 99.219 (98.523)\n",
            "Epoch: [14][100/110], lr: 0.01000\tTime 0.095 (0.068)\tData 0.012 (0.008)\tLoss 2.5021 (3.4055)\tPrec@1 85.156 (81.428)\tPrec@5 99.219 (98.476)\n",
            "Test: [0/100]\tTime 0.430 (0.430)\tLoss 12.9290 (12.9290)\tPrec@1 34.000 (34.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.052 (0.081)\tLoss 9.1343 (11.7336)\tPrec@1 58.000 (42.000)\tPrec@5 92.000 (93.727)\n",
            "Test: [20/100]\tTime 0.031 (0.062)\tLoss 10.2108 (11.8019)\tPrec@1 51.000 (42.143)\tPrec@5 91.000 (93.333)\n",
            "Test: [30/100]\tTime 0.045 (0.056)\tLoss 10.6198 (11.7574)\tPrec@1 45.000 (41.871)\tPrec@5 94.000 (93.032)\n",
            "Test: [40/100]\tTime 0.024 (0.054)\tLoss 12.5595 (11.8204)\tPrec@1 39.000 (41.561)\tPrec@5 94.000 (93.195)\n",
            "Test: [50/100]\tTime 0.022 (0.051)\tLoss 11.4472 (11.6681)\tPrec@1 47.000 (42.275)\tPrec@5 96.000 (93.588)\n",
            "Test: [60/100]\tTime 0.025 (0.048)\tLoss 9.5877 (11.6353)\tPrec@1 49.000 (42.410)\tPrec@5 94.000 (93.705)\n",
            "Test: [70/100]\tTime 0.034 (0.045)\tLoss 11.7050 (11.6318)\tPrec@1 38.000 (42.296)\tPrec@5 96.000 (93.606)\n",
            "Test: [80/100]\tTime 0.026 (0.043)\tLoss 10.3674 (11.5876)\tPrec@1 48.000 (42.481)\tPrec@5 95.000 (93.654)\n",
            "Test: [90/100]\tTime 0.036 (0.041)\tLoss 11.4630 (11.6352)\tPrec@1 42.000 (42.330)\tPrec@5 95.000 (93.659)\n",
            "val Results: Prec@1 42.290 Prec@5 93.620 Loss 11.65678\n",
            "val Class Accuracy: [0.991,0.892,0.542,0.511,0.290,0.247,0.427,0.241,0.074,0.014]\n",
            "Best Prec@1: 52.770\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [15][0/110], lr: 0.01000\tTime 0.518 (0.518)\tData 0.434 (0.434)\tLoss 3.4671 (3.4671)\tPrec@1 79.688 (79.688)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [15][10/110], lr: 0.01000\tTime 0.052 (0.108)\tData 0.000 (0.046)\tLoss 3.4756 (3.4713)\tPrec@1 82.031 (81.250)\tPrec@5 98.438 (98.509)\n",
            "Epoch: [15][20/110], lr: 0.01000\tTime 0.062 (0.086)\tData 0.000 (0.025)\tLoss 3.8886 (3.4012)\tPrec@1 76.562 (81.027)\tPrec@5 97.656 (98.475)\n",
            "Epoch: [15][30/110], lr: 0.01000\tTime 0.069 (0.078)\tData 0.010 (0.019)\tLoss 2.6026 (3.2811)\tPrec@1 88.281 (81.578)\tPrec@5 100.000 (98.639)\n",
            "Epoch: [15][40/110], lr: 0.01000\tTime 0.065 (0.074)\tData 0.005 (0.015)\tLoss 2.5045 (3.3188)\tPrec@1 89.844 (81.574)\tPrec@5 99.219 (98.514)\n",
            "Epoch: [15][50/110], lr: 0.01000\tTime 0.042 (0.071)\tData 0.000 (0.013)\tLoss 4.3954 (3.3378)\tPrec@1 78.125 (81.541)\tPrec@5 99.219 (98.560)\n",
            "Epoch: [15][60/110], lr: 0.01000\tTime 0.057 (0.070)\tData 0.007 (0.013)\tLoss 3.3648 (3.3031)\tPrec@1 83.594 (81.711)\tPrec@5 100.000 (98.617)\n",
            "Epoch: [15][70/110], lr: 0.01000\tTime 0.064 (0.069)\tData 0.007 (0.012)\tLoss 3.6612 (3.2834)\tPrec@1 80.469 (81.932)\tPrec@5 98.438 (98.592)\n",
            "Epoch: [15][80/110], lr: 0.01000\tTime 0.056 (0.068)\tData 0.000 (0.011)\tLoss 3.8470 (3.2645)\tPrec@1 78.125 (82.137)\tPrec@5 98.438 (98.611)\n",
            "Epoch: [15][90/110], lr: 0.01000\tTime 0.053 (0.067)\tData 0.014 (0.010)\tLoss 3.5015 (3.2430)\tPrec@1 81.250 (82.289)\tPrec@5 99.219 (98.661)\n",
            "Epoch: [15][100/110], lr: 0.01000\tTime 0.059 (0.066)\tData 0.007 (0.010)\tLoss 3.4770 (3.2449)\tPrec@1 83.594 (82.263)\tPrec@5 99.219 (98.700)\n",
            "Test: [0/100]\tTime 0.291 (0.291)\tLoss 14.1132 (14.1132)\tPrec@1 38.000 (38.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/100]\tTime 0.024 (0.053)\tLoss 9.7467 (12.9914)\tPrec@1 54.000 (42.273)\tPrec@5 93.000 (90.545)\n",
            "Test: [20/100]\tTime 0.041 (0.042)\tLoss 12.1471 (13.1397)\tPrec@1 42.000 (40.810)\tPrec@5 94.000 (90.810)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 12.7729 (13.1210)\tPrec@1 41.000 (41.194)\tPrec@5 90.000 (90.355)\n",
            "Test: [40/100]\tTime 0.029 (0.035)\tLoss 14.4198 (13.1923)\tPrec@1 34.000 (41.024)\tPrec@5 90.000 (89.976)\n",
            "Test: [50/100]\tTime 0.024 (0.033)\tLoss 13.5392 (13.1074)\tPrec@1 39.000 (41.216)\tPrec@5 92.000 (90.059)\n",
            "Test: [60/100]\tTime 0.022 (0.032)\tLoss 11.5291 (13.1719)\tPrec@1 46.000 (40.689)\tPrec@5 94.000 (90.230)\n",
            "Test: [70/100]\tTime 0.038 (0.031)\tLoss 12.2285 (13.1582)\tPrec@1 43.000 (40.662)\tPrec@5 93.000 (90.254)\n",
            "Test: [80/100]\tTime 0.037 (0.031)\tLoss 11.9000 (13.1265)\tPrec@1 48.000 (40.753)\tPrec@5 90.000 (90.235)\n",
            "Test: [90/100]\tTime 0.040 (0.031)\tLoss 12.7347 (13.1705)\tPrec@1 42.000 (40.440)\tPrec@5 90.000 (90.110)\n",
            "val Results: Prec@1 40.440 Prec@5 89.970 Loss 13.21017\n",
            "val Class Accuracy: [0.840,0.952,0.944,0.301,0.416,0.019,0.377,0.139,0.056,0.000]\n",
            "Best Prec@1: 52.770\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [16][0/110], lr: 0.01000\tTime 0.486 (0.486)\tData 0.400 (0.400)\tLoss 2.3715 (2.3715)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [16][10/110], lr: 0.01000\tTime 0.083 (0.102)\tData 0.001 (0.038)\tLoss 4.5815 (3.2181)\tPrec@1 72.656 (82.386)\tPrec@5 96.094 (98.438)\n",
            "Epoch: [16][20/110], lr: 0.01000\tTime 0.049 (0.081)\tData 0.000 (0.021)\tLoss 3.2922 (3.1858)\tPrec@1 80.469 (82.850)\tPrec@5 99.219 (98.661)\n",
            "Epoch: [16][30/110], lr: 0.01000\tTime 0.079 (0.074)\tData 0.010 (0.015)\tLoss 2.9012 (3.2097)\tPrec@1 84.375 (82.712)\tPrec@5 98.438 (98.513)\n",
            "Epoch: [16][40/110], lr: 0.01000\tTime 0.055 (0.070)\tData 0.005 (0.013)\tLoss 3.9703 (3.2490)\tPrec@1 78.125 (82.412)\tPrec@5 99.219 (98.571)\n",
            "Epoch: [16][50/110], lr: 0.01000\tTime 0.053 (0.068)\tData 0.006 (0.012)\tLoss 3.9401 (3.2890)\tPrec@1 78.125 (82.077)\tPrec@5 96.875 (98.514)\n",
            "Epoch: [16][60/110], lr: 0.01000\tTime 0.044 (0.067)\tData 0.000 (0.011)\tLoss 4.0213 (3.2831)\tPrec@1 75.781 (82.044)\tPrec@5 99.219 (98.553)\n",
            "Epoch: [16][70/110], lr: 0.01000\tTime 0.054 (0.066)\tData 0.007 (0.010)\tLoss 3.4153 (3.2469)\tPrec@1 81.250 (82.306)\tPrec@5 99.219 (98.592)\n",
            "Epoch: [16][80/110], lr: 0.01000\tTime 0.058 (0.065)\tData 0.007 (0.010)\tLoss 3.1891 (3.2488)\tPrec@1 84.375 (82.340)\tPrec@5 99.219 (98.621)\n",
            "Epoch: [16][90/110], lr: 0.01000\tTime 0.058 (0.065)\tData 0.000 (0.009)\tLoss 2.9343 (3.2270)\tPrec@1 82.031 (82.469)\tPrec@5 98.438 (98.609)\n",
            "Epoch: [16][100/110], lr: 0.01000\tTime 0.044 (0.064)\tData 0.001 (0.009)\tLoss 2.7053 (3.1873)\tPrec@1 85.938 (82.758)\tPrec@5 99.219 (98.662)\n",
            "Test: [0/100]\tTime 0.364 (0.364)\tLoss 11.6789 (11.6789)\tPrec@1 49.000 (49.000)\tPrec@5 89.000 (89.000)\n",
            "Test: [10/100]\tTime 0.032 (0.056)\tLoss 9.0301 (10.6781)\tPrec@1 56.000 (50.091)\tPrec@5 88.000 (89.091)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 9.7953 (10.6582)\tPrec@1 47.000 (49.571)\tPrec@5 92.000 (89.619)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 9.5639 (10.6606)\tPrec@1 53.000 (49.516)\tPrec@5 89.000 (89.484)\n",
            "Test: [40/100]\tTime 0.047 (0.034)\tLoss 10.8514 (10.6393)\tPrec@1 54.000 (49.512)\tPrec@5 90.000 (89.659)\n",
            "Test: [50/100]\tTime 0.029 (0.033)\tLoss 9.3301 (10.5543)\tPrec@1 59.000 (50.078)\tPrec@5 92.000 (89.902)\n",
            "Test: [60/100]\tTime 0.050 (0.032)\tLoss 10.0711 (10.4955)\tPrec@1 50.000 (50.361)\tPrec@5 85.000 (89.639)\n",
            "Test: [70/100]\tTime 0.030 (0.031)\tLoss 9.9533 (10.5352)\tPrec@1 57.000 (50.310)\tPrec@5 91.000 (89.451)\n",
            "Test: [80/100]\tTime 0.023 (0.031)\tLoss 8.6807 (10.4672)\tPrec@1 61.000 (50.556)\tPrec@5 93.000 (89.568)\n",
            "Test: [90/100]\tTime 0.031 (0.030)\tLoss 10.9446 (10.5540)\tPrec@1 49.000 (50.231)\tPrec@5 91.000 (89.297)\n",
            "val Results: Prec@1 50.270 Prec@5 89.360 Loss 10.56064\n",
            "val Class Accuracy: [0.935,0.983,0.504,0.353,0.665,0.433,0.214,0.768,0.012,0.160]\n",
            "Best Prec@1: 52.770\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [17][0/110], lr: 0.01000\tTime 0.489 (0.489)\tData 0.411 (0.411)\tLoss 2.6989 (2.6989)\tPrec@1 85.156 (85.156)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [17][10/110], lr: 0.01000\tTime 0.055 (0.104)\tData 0.006 (0.041)\tLoss 3.0703 (3.2401)\tPrec@1 83.594 (81.747)\tPrec@5 97.656 (98.935)\n",
            "Epoch: [17][20/110], lr: 0.01000\tTime 0.043 (0.083)\tData 0.000 (0.024)\tLoss 2.8629 (3.0806)\tPrec@1 81.250 (82.626)\tPrec@5 99.219 (98.884)\n",
            "Epoch: [17][30/110], lr: 0.01000\tTime 0.049 (0.076)\tData 0.000 (0.018)\tLoss 3.2394 (3.1055)\tPrec@1 78.906 (82.762)\tPrec@5 96.875 (98.715)\n",
            "Epoch: [17][40/110], lr: 0.01000\tTime 0.060 (0.072)\tData 0.007 (0.015)\tLoss 3.2841 (3.1147)\tPrec@1 82.031 (82.736)\tPrec@5 97.656 (98.704)\n",
            "Epoch: [17][50/110], lr: 0.01000\tTime 0.072 (0.070)\tData 0.006 (0.013)\tLoss 3.3190 (3.0782)\tPrec@1 80.469 (82.966)\tPrec@5 96.875 (98.560)\n",
            "Epoch: [17][60/110], lr: 0.01000\tTime 0.048 (0.068)\tData 0.002 (0.012)\tLoss 3.1491 (3.0608)\tPrec@1 82.812 (83.248)\tPrec@5 100.000 (98.566)\n",
            "Epoch: [17][70/110], lr: 0.01000\tTime 0.061 (0.067)\tData 0.007 (0.011)\tLoss 3.9042 (3.0866)\tPrec@1 78.125 (83.088)\tPrec@5 96.875 (98.614)\n",
            "Epoch: [17][80/110], lr: 0.01000\tTime 0.067 (0.067)\tData 0.000 (0.010)\tLoss 2.4478 (3.1113)\tPrec@1 88.281 (82.996)\tPrec@5 99.219 (98.650)\n",
            "Epoch: [17][90/110], lr: 0.01000\tTime 0.054 (0.066)\tData 0.006 (0.010)\tLoss 3.2823 (3.1265)\tPrec@1 83.594 (82.976)\tPrec@5 97.656 (98.583)\n",
            "Epoch: [17][100/110], lr: 0.01000\tTime 0.056 (0.066)\tData 0.007 (0.009)\tLoss 2.8955 (3.1223)\tPrec@1 85.156 (83.137)\tPrec@5 99.219 (98.569)\n",
            "Test: [0/100]\tTime 0.269 (0.269)\tLoss 9.8390 (9.8390)\tPrec@1 54.000 (54.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.035 (0.055)\tLoss 6.9161 (9.8452)\tPrec@1 67.000 (53.364)\tPrec@5 94.000 (93.909)\n",
            "Test: [20/100]\tTime 0.010 (0.036)\tLoss 10.3144 (9.8637)\tPrec@1 52.000 (53.714)\tPrec@5 97.000 (94.238)\n",
            "Test: [30/100]\tTime 0.037 (0.035)\tLoss 9.3550 (9.9622)\tPrec@1 54.000 (53.258)\tPrec@5 94.000 (93.968)\n",
            "Test: [40/100]\tTime 0.011 (0.031)\tLoss 11.4401 (10.1019)\tPrec@1 44.000 (52.439)\tPrec@5 89.000 (93.659)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 10.1466 (10.0134)\tPrec@1 52.000 (52.843)\tPrec@5 92.000 (93.706)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 8.8511 (9.9945)\tPrec@1 59.000 (52.721)\tPrec@5 93.000 (93.721)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 9.3907 (9.9793)\tPrec@1 56.000 (52.831)\tPrec@5 95.000 (93.676)\n",
            "Test: [80/100]\tTime 0.046 (0.030)\tLoss 9.1509 (9.9456)\tPrec@1 59.000 (53.123)\tPrec@5 94.000 (93.827)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 9.8574 (9.9703)\tPrec@1 54.000 (53.143)\tPrec@5 91.000 (93.747)\n",
            "val Results: Prec@1 53.220 Prec@5 93.660 Loss 9.97639\n",
            "val Class Accuracy: [0.880,0.970,0.594,0.569,0.744,0.215,0.854,0.222,0.228,0.046]\n",
            "Best Prec@1: 53.220\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [18][0/110], lr: 0.01000\tTime 0.490 (0.490)\tData 0.415 (0.415)\tLoss 2.7342 (2.7342)\tPrec@1 82.031 (82.031)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][10/110], lr: 0.01000\tTime 0.063 (0.103)\tData 0.001 (0.041)\tLoss 3.0553 (3.0063)\tPrec@1 83.594 (83.949)\tPrec@5 100.000 (99.148)\n",
            "Epoch: [18][20/110], lr: 0.01000\tTime 0.037 (0.082)\tData 0.000 (0.024)\tLoss 2.6622 (3.0678)\tPrec@1 83.594 (83.482)\tPrec@5 98.438 (98.847)\n",
            "Epoch: [18][30/110], lr: 0.01000\tTime 0.060 (0.075)\tData 0.003 (0.018)\tLoss 3.6128 (3.1375)\tPrec@1 78.125 (83.140)\tPrec@5 98.438 (98.765)\n",
            "Epoch: [18][40/110], lr: 0.01000\tTime 0.063 (0.071)\tData 0.000 (0.015)\tLoss 2.1739 (3.0373)\tPrec@1 86.719 (83.651)\tPrec@5 100.000 (98.800)\n",
            "Epoch: [18][50/110], lr: 0.01000\tTime 0.063 (0.068)\tData 0.007 (0.013)\tLoss 3.7365 (3.0732)\tPrec@1 79.688 (83.517)\tPrec@5 98.438 (98.790)\n",
            "Epoch: [18][60/110], lr: 0.01000\tTime 0.041 (0.067)\tData 0.000 (0.012)\tLoss 3.0640 (3.0826)\tPrec@1 82.812 (83.453)\tPrec@5 98.438 (98.783)\n",
            "Epoch: [18][70/110], lr: 0.01000\tTime 0.069 (0.066)\tData 0.015 (0.011)\tLoss 2.6797 (3.0815)\tPrec@1 85.938 (83.341)\tPrec@5 98.438 (98.735)\n",
            "Epoch: [18][80/110], lr: 0.01000\tTime 0.053 (0.065)\tData 0.008 (0.011)\tLoss 3.0851 (3.0654)\tPrec@1 85.938 (83.488)\tPrec@5 98.438 (98.708)\n",
            "Epoch: [18][90/110], lr: 0.01000\tTime 0.040 (0.064)\tData 0.000 (0.010)\tLoss 3.1216 (3.0531)\tPrec@1 81.250 (83.525)\tPrec@5 98.438 (98.695)\n",
            "Epoch: [18][100/110], lr: 0.01000\tTime 0.053 (0.064)\tData 0.000 (0.009)\tLoss 3.9291 (3.0703)\tPrec@1 81.250 (83.524)\tPrec@5 100.000 (98.708)\n",
            "Test: [0/100]\tTime 0.317 (0.317)\tLoss 9.2247 (9.2247)\tPrec@1 54.000 (54.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.017 (0.054)\tLoss 7.3855 (9.1048)\tPrec@1 62.000 (56.091)\tPrec@5 94.000 (94.455)\n",
            "Test: [20/100]\tTime 0.027 (0.042)\tLoss 7.7888 (8.9800)\tPrec@1 60.000 (56.762)\tPrec@5 100.000 (94.667)\n",
            "Test: [30/100]\tTime 0.034 (0.037)\tLoss 8.3683 (8.9865)\tPrec@1 59.000 (57.161)\tPrec@5 95.000 (94.194)\n",
            "Test: [40/100]\tTime 0.027 (0.034)\tLoss 9.0874 (9.0488)\tPrec@1 58.000 (56.927)\tPrec@5 96.000 (94.268)\n",
            "Test: [50/100]\tTime 0.039 (0.033)\tLoss 8.2674 (8.9363)\tPrec@1 63.000 (57.510)\tPrec@5 96.000 (94.412)\n",
            "Test: [60/100]\tTime 0.019 (0.032)\tLoss 8.5524 (8.9792)\tPrec@1 57.000 (57.197)\tPrec@5 94.000 (94.508)\n",
            "Test: [70/100]\tTime 0.034 (0.031)\tLoss 8.8804 (9.0171)\tPrec@1 58.000 (57.000)\tPrec@5 97.000 (94.352)\n",
            "Test: [80/100]\tTime 0.017 (0.030)\tLoss 8.4921 (8.9737)\tPrec@1 59.000 (57.296)\tPrec@5 92.000 (94.420)\n",
            "Test: [90/100]\tTime 0.021 (0.030)\tLoss 8.3982 (9.0395)\tPrec@1 63.000 (57.077)\tPrec@5 95.000 (94.363)\n",
            "val Results: Prec@1 56.960 Prec@5 94.390 Loss 9.06660\n",
            "val Class Accuracy: [0.931,0.982,0.783,0.570,0.707,0.310,0.594,0.495,0.257,0.067]\n",
            "Best Prec@1: 56.960\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [19][0/110], lr: 0.01000\tTime 0.557 (0.557)\tData 0.430 (0.430)\tLoss 2.1962 (2.1962)\tPrec@1 87.500 (87.500)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [19][10/110], lr: 0.01000\tTime 0.067 (0.141)\tData 0.000 (0.045)\tLoss 3.0897 (2.7210)\tPrec@1 84.375 (85.014)\tPrec@5 98.438 (98.651)\n",
            "Epoch: [19][20/110], lr: 0.01000\tTime 0.098 (0.117)\tData 0.013 (0.028)\tLoss 3.1422 (2.8985)\tPrec@1 82.812 (84.040)\tPrec@5 96.875 (98.512)\n",
            "Epoch: [19][30/110], lr: 0.01000\tTime 0.055 (0.110)\tData 0.000 (0.022)\tLoss 2.7674 (2.9514)\tPrec@1 85.156 (84.073)\tPrec@5 99.219 (98.488)\n",
            "Epoch: [19][40/110], lr: 0.01000\tTime 0.101 (0.105)\tData 0.000 (0.019)\tLoss 2.9073 (2.9469)\tPrec@1 83.594 (84.032)\tPrec@5 97.656 (98.495)\n",
            "Epoch: [19][50/110], lr: 0.01000\tTime 0.045 (0.098)\tData 0.000 (0.016)\tLoss 3.2471 (2.8946)\tPrec@1 85.156 (84.375)\tPrec@5 98.438 (98.591)\n",
            "Epoch: [19][60/110], lr: 0.01000\tTime 0.071 (0.092)\tData 0.005 (0.014)\tLoss 1.7607 (2.8896)\tPrec@1 91.406 (84.477)\tPrec@5 100.000 (98.642)\n",
            "Epoch: [19][70/110], lr: 0.01000\tTime 0.044 (0.087)\tData 0.000 (0.013)\tLoss 2.7614 (2.8977)\tPrec@1 86.719 (84.485)\tPrec@5 100.000 (98.735)\n",
            "Epoch: [19][80/110], lr: 0.01000\tTime 0.054 (0.084)\tData 0.000 (0.012)\tLoss 3.0696 (2.8995)\tPrec@1 82.812 (84.452)\tPrec@5 97.656 (98.746)\n",
            "Epoch: [19][90/110], lr: 0.01000\tTime 0.054 (0.081)\tData 0.000 (0.011)\tLoss 3.3414 (2.9272)\tPrec@1 81.250 (84.203)\tPrec@5 98.438 (98.781)\n",
            "Epoch: [19][100/110], lr: 0.01000\tTime 0.037 (0.079)\tData 0.001 (0.011)\tLoss 2.9401 (2.9210)\tPrec@1 83.594 (84.220)\tPrec@5 98.438 (98.793)\n",
            "Test: [0/100]\tTime 0.286 (0.286)\tLoss 9.0683 (9.0683)\tPrec@1 63.000 (63.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.024 (0.056)\tLoss 6.7432 (8.8379)\tPrec@1 67.000 (58.455)\tPrec@5 96.000 (97.364)\n",
            "Test: [20/100]\tTime 0.035 (0.042)\tLoss 8.2271 (8.7969)\tPrec@1 58.000 (58.333)\tPrec@5 99.000 (96.667)\n",
            "Test: [30/100]\tTime 0.048 (0.036)\tLoss 8.0184 (8.7869)\tPrec@1 59.000 (58.194)\tPrec@5 96.000 (96.452)\n",
            "Test: [40/100]\tTime 0.038 (0.034)\tLoss 9.3632 (8.8118)\tPrec@1 52.000 (57.878)\tPrec@5 94.000 (96.268)\n",
            "Test: [50/100]\tTime 0.037 (0.032)\tLoss 7.8458 (8.7366)\tPrec@1 67.000 (58.235)\tPrec@5 96.000 (96.333)\n",
            "Test: [60/100]\tTime 0.011 (0.031)\tLoss 8.5240 (8.7358)\tPrec@1 58.000 (58.344)\tPrec@5 96.000 (96.393)\n",
            "Test: [70/100]\tTime 0.045 (0.030)\tLoss 8.6635 (8.7672)\tPrec@1 60.000 (58.211)\tPrec@5 99.000 (96.437)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 7.1396 (8.7361)\tPrec@1 66.000 (58.272)\tPrec@5 97.000 (96.457)\n",
            "Test: [90/100]\tTime 0.046 (0.030)\tLoss 7.6213 (8.7666)\tPrec@1 67.000 (58.154)\tPrec@5 97.000 (96.352)\n",
            "val Results: Prec@1 58.080 Prec@5 96.320 Loss 8.80269\n",
            "val Class Accuracy: [0.924,0.961,0.779,0.497,0.790,0.350,0.547,0.521,0.220,0.219]\n",
            "Best Prec@1: 58.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [20][0/110], lr: 0.01000\tTime 0.466 (0.466)\tData 0.363 (0.363)\tLoss 2.5788 (2.5788)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [20][10/110], lr: 0.01000\tTime 0.044 (0.104)\tData 0.000 (0.039)\tLoss 2.9164 (2.9710)\tPrec@1 82.812 (83.594)\tPrec@5 100.000 (98.722)\n",
            "Epoch: [20][20/110], lr: 0.01000\tTime 0.060 (0.083)\tData 0.007 (0.022)\tLoss 1.7930 (2.9442)\tPrec@1 91.406 (83.817)\tPrec@5 100.000 (98.847)\n",
            "Epoch: [20][30/110], lr: 0.01000\tTime 0.062 (0.075)\tData 0.000 (0.017)\tLoss 2.1676 (2.8908)\tPrec@1 88.281 (83.997)\tPrec@5 98.438 (98.942)\n",
            "Epoch: [20][40/110], lr: 0.01000\tTime 0.083 (0.072)\tData 0.017 (0.014)\tLoss 2.7463 (2.8387)\tPrec@1 86.719 (84.394)\tPrec@5 98.438 (98.990)\n",
            "Epoch: [20][50/110], lr: 0.01000\tTime 0.047 (0.069)\tData 0.000 (0.012)\tLoss 4.0057 (2.8082)\tPrec@1 75.781 (84.666)\tPrec@5 99.219 (99.050)\n",
            "Epoch: [20][60/110], lr: 0.01000\tTime 0.050 (0.068)\tData 0.000 (0.010)\tLoss 3.4212 (2.8255)\tPrec@1 82.812 (84.618)\tPrec@5 98.438 (98.963)\n",
            "Epoch: [20][70/110], lr: 0.01000\tTime 0.035 (0.067)\tData 0.003 (0.010)\tLoss 2.3370 (2.8242)\tPrec@1 87.500 (84.639)\tPrec@5 100.000 (98.999)\n",
            "Epoch: [20][80/110], lr: 0.01000\tTime 0.042 (0.066)\tData 0.000 (0.009)\tLoss 2.9223 (2.8396)\tPrec@1 82.812 (84.500)\tPrec@5 98.438 (98.958)\n",
            "Epoch: [20][90/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.000 (0.009)\tLoss 3.1291 (2.8635)\tPrec@1 83.594 (84.418)\tPrec@5 97.656 (98.901)\n",
            "Epoch: [20][100/110], lr: 0.01000\tTime 0.075 (0.065)\tData 0.000 (0.008)\tLoss 3.3480 (2.8581)\tPrec@1 78.906 (84.352)\tPrec@5 97.656 (98.917)\n",
            "Test: [0/100]\tTime 0.319 (0.319)\tLoss 10.1618 (10.1618)\tPrec@1 56.000 (56.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.019 (0.053)\tLoss 6.8863 (9.3254)\tPrec@1 68.000 (58.091)\tPrec@5 97.000 (94.000)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 8.4936 (9.3054)\tPrec@1 59.000 (57.619)\tPrec@5 97.000 (94.238)\n",
            "Test: [30/100]\tTime 0.032 (0.036)\tLoss 8.5658 (9.3075)\tPrec@1 62.000 (57.032)\tPrec@5 93.000 (93.710)\n",
            "Test: [40/100]\tTime 0.038 (0.033)\tLoss 9.9145 (9.3676)\tPrec@1 56.000 (56.902)\tPrec@5 95.000 (93.707)\n",
            "Test: [50/100]\tTime 0.010 (0.033)\tLoss 8.0728 (9.2291)\tPrec@1 63.000 (57.549)\tPrec@5 96.000 (93.824)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 7.8595 (9.1971)\tPrec@1 66.000 (57.787)\tPrec@5 92.000 (93.885)\n",
            "Test: [70/100]\tTime 0.012 (0.031)\tLoss 8.2382 (9.1859)\tPrec@1 62.000 (57.859)\tPrec@5 98.000 (93.944)\n",
            "Test: [80/100]\tTime 0.026 (0.030)\tLoss 8.8304 (9.1473)\tPrec@1 59.000 (57.975)\tPrec@5 94.000 (93.914)\n",
            "Test: [90/100]\tTime 0.019 (0.030)\tLoss 8.9543 (9.2243)\tPrec@1 60.000 (57.758)\tPrec@5 95.000 (93.923)\n",
            "val Results: Prec@1 57.790 Prec@5 93.860 Loss 9.24057\n",
            "val Class Accuracy: [0.934,0.898,0.601,0.847,0.696,0.452,0.544,0.474,0.214,0.119]\n",
            "Best Prec@1: 58.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [21][0/110], lr: 0.01000\tTime 0.496 (0.496)\tData 0.394 (0.394)\tLoss 2.7605 (2.7605)\tPrec@1 83.594 (83.594)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [21][10/110], lr: 0.01000\tTime 0.063 (0.105)\tData 0.008 (0.040)\tLoss 2.4750 (2.7451)\tPrec@1 86.719 (85.369)\tPrec@5 99.219 (99.006)\n",
            "Epoch: [21][20/110], lr: 0.01000\tTime 0.056 (0.083)\tData 0.009 (0.024)\tLoss 2.6653 (2.7560)\tPrec@1 85.938 (85.268)\tPrec@5 97.656 (98.810)\n",
            "Epoch: [21][30/110], lr: 0.01000\tTime 0.069 (0.075)\tData 0.008 (0.018)\tLoss 2.3043 (2.8157)\tPrec@1 89.062 (85.030)\tPrec@5 98.438 (98.740)\n",
            "Epoch: [21][40/110], lr: 0.01000\tTime 0.063 (0.072)\tData 0.007 (0.014)\tLoss 2.1902 (2.7540)\tPrec@1 89.844 (85.290)\tPrec@5 99.219 (98.761)\n",
            "Epoch: [21][50/110], lr: 0.01000\tTime 0.059 (0.069)\tData 0.005 (0.012)\tLoss 3.7798 (2.8001)\tPrec@1 78.906 (85.049)\tPrec@5 99.219 (98.713)\n",
            "Epoch: [21][60/110], lr: 0.01000\tTime 0.067 (0.067)\tData 0.011 (0.011)\tLoss 2.3845 (2.8087)\tPrec@1 87.500 (84.964)\tPrec@5 99.219 (98.732)\n",
            "Epoch: [21][70/110], lr: 0.01000\tTime 0.070 (0.066)\tData 0.005 (0.010)\tLoss 3.5959 (2.8614)\tPrec@1 78.125 (84.485)\tPrec@5 99.219 (98.823)\n",
            "Epoch: [21][80/110], lr: 0.01000\tTime 0.066 (0.065)\tData 0.011 (0.009)\tLoss 3.9610 (2.8905)\tPrec@1 74.219 (84.336)\tPrec@5 98.438 (98.794)\n",
            "Epoch: [21][90/110], lr: 0.01000\tTime 0.071 (0.064)\tData 0.007 (0.008)\tLoss 2.6223 (2.8827)\tPrec@1 85.938 (84.444)\tPrec@5 98.438 (98.789)\n",
            "Epoch: [21][100/110], lr: 0.01000\tTime 0.069 (0.064)\tData 0.005 (0.008)\tLoss 2.8661 (2.8653)\tPrec@1 86.719 (84.522)\tPrec@5 99.219 (98.847)\n",
            "Test: [0/100]\tTime 0.265 (0.265)\tLoss 10.4007 (10.4007)\tPrec@1 53.000 (53.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.051)\tLoss 7.6352 (9.7851)\tPrec@1 66.000 (54.091)\tPrec@5 95.000 (96.818)\n",
            "Test: [20/100]\tTime 0.028 (0.039)\tLoss 9.4773 (9.8000)\tPrec@1 54.000 (54.429)\tPrec@5 99.000 (96.667)\n",
            "Test: [30/100]\tTime 0.036 (0.036)\tLoss 9.8188 (9.8479)\tPrec@1 55.000 (53.968)\tPrec@5 95.000 (96.323)\n",
            "Test: [40/100]\tTime 0.050 (0.034)\tLoss 10.9886 (9.9119)\tPrec@1 50.000 (54.000)\tPrec@5 94.000 (96.220)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 10.1850 (9.8267)\tPrec@1 52.000 (54.235)\tPrec@5 95.000 (96.412)\n",
            "Test: [60/100]\tTime 0.011 (0.031)\tLoss 9.6071 (9.8720)\tPrec@1 53.000 (54.098)\tPrec@5 94.000 (96.443)\n",
            "Test: [70/100]\tTime 0.026 (0.030)\tLoss 8.6683 (9.8639)\tPrec@1 62.000 (54.225)\tPrec@5 98.000 (96.296)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 9.0383 (9.8200)\tPrec@1 56.000 (54.444)\tPrec@5 94.000 (96.358)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 8.9795 (9.8576)\tPrec@1 58.000 (54.319)\tPrec@5 97.000 (96.242)\n",
            "val Results: Prec@1 54.320 Prec@5 96.280 Loss 9.87021\n",
            "val Class Accuracy: [0.818,0.947,0.895,0.815,0.509,0.104,0.518,0.484,0.211,0.131]\n",
            "Best Prec@1: 58.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [22][0/110], lr: 0.01000\tTime 0.437 (0.437)\tData 0.337 (0.337)\tLoss 2.4418 (2.4418)\tPrec@1 87.500 (87.500)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [22][10/110], lr: 0.01000\tTime 0.048 (0.103)\tData 0.010 (0.035)\tLoss 2.7217 (2.7552)\tPrec@1 85.156 (85.582)\tPrec@5 96.094 (98.864)\n",
            "Epoch: [22][20/110], lr: 0.01000\tTime 0.073 (0.083)\tData 0.000 (0.020)\tLoss 2.4334 (2.6977)\tPrec@1 86.719 (85.640)\tPrec@5 100.000 (99.182)\n",
            "Epoch: [22][30/110], lr: 0.01000\tTime 0.040 (0.076)\tData 0.000 (0.015)\tLoss 2.7235 (2.7608)\tPrec@1 85.156 (85.207)\tPrec@5 98.438 (99.042)\n",
            "Epoch: [22][40/110], lr: 0.01000\tTime 0.062 (0.071)\tData 0.006 (0.013)\tLoss 3.3029 (2.7904)\tPrec@1 80.469 (85.175)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [22][50/110], lr: 0.01000\tTime 0.054 (0.069)\tData 0.006 (0.011)\tLoss 2.4178 (2.8018)\tPrec@1 88.281 (85.049)\tPrec@5 98.438 (99.035)\n",
            "Epoch: [22][60/110], lr: 0.01000\tTime 0.062 (0.067)\tData 0.010 (0.010)\tLoss 2.7190 (2.7717)\tPrec@1 84.375 (85.156)\tPrec@5 99.219 (99.065)\n",
            "Epoch: [22][70/110], lr: 0.01000\tTime 0.057 (0.067)\tData 0.000 (0.009)\tLoss 3.0079 (2.7676)\tPrec@1 83.594 (85.068)\tPrec@5 99.219 (99.043)\n",
            "Epoch: [22][80/110], lr: 0.01000\tTime 0.053 (0.066)\tData 0.000 (0.009)\tLoss 2.5601 (2.7907)\tPrec@1 84.375 (84.915)\tPrec@5 99.219 (99.035)\n",
            "Epoch: [22][90/110], lr: 0.01000\tTime 0.042 (0.065)\tData 0.000 (0.009)\tLoss 2.1790 (2.7696)\tPrec@1 89.062 (85.062)\tPrec@5 99.219 (99.038)\n",
            "Epoch: [22][100/110], lr: 0.01000\tTime 0.063 (0.065)\tData 0.006 (0.008)\tLoss 3.2006 (2.7810)\tPrec@1 82.812 (84.955)\tPrec@5 99.219 (99.010)\n",
            "Test: [0/100]\tTime 0.251 (0.251)\tLoss 11.2107 (11.2107)\tPrec@1 48.000 (48.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.025 (0.055)\tLoss 7.5494 (10.4747)\tPrec@1 68.000 (53.364)\tPrec@5 94.000 (91.545)\n",
            "Test: [20/100]\tTime 0.011 (0.040)\tLoss 9.5244 (10.3735)\tPrec@1 55.000 (53.429)\tPrec@5 97.000 (91.619)\n",
            "Test: [30/100]\tTime 0.028 (0.036)\tLoss 9.9227 (10.4298)\tPrec@1 53.000 (53.129)\tPrec@5 93.000 (92.032)\n",
            "Test: [40/100]\tTime 0.027 (0.033)\tLoss 11.3732 (10.5214)\tPrec@1 46.000 (52.293)\tPrec@5 89.000 (91.805)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 8.9633 (10.3376)\tPrec@1 61.000 (53.176)\tPrec@5 92.000 (91.784)\n",
            "Test: [60/100]\tTime 0.042 (0.031)\tLoss 9.1733 (10.3261)\tPrec@1 61.000 (53.180)\tPrec@5 92.000 (91.672)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 9.6532 (10.2864)\tPrec@1 56.000 (53.380)\tPrec@5 95.000 (91.620)\n",
            "Test: [80/100]\tTime 0.041 (0.030)\tLoss 9.8684 (10.2555)\tPrec@1 54.000 (53.481)\tPrec@5 88.000 (91.580)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 10.0705 (10.3120)\tPrec@1 55.000 (53.264)\tPrec@5 92.000 (91.462)\n",
            "val Results: Prec@1 53.070 Prec@5 91.460 Loss 10.35949\n",
            "val Class Accuracy: [0.926,0.981,0.554,0.795,0.830,0.395,0.496,0.138,0.108,0.084]\n",
            "Best Prec@1: 58.080\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [23][0/110], lr: 0.01000\tTime 0.452 (0.452)\tData 0.346 (0.346)\tLoss 2.5575 (2.5575)\tPrec@1 87.500 (87.500)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [23][10/110], lr: 0.01000\tTime 0.062 (0.102)\tData 0.013 (0.038)\tLoss 2.6240 (2.5398)\tPrec@1 82.812 (86.364)\tPrec@5 99.219 (98.864)\n",
            "Epoch: [23][20/110], lr: 0.01000\tTime 0.045 (0.080)\tData 0.000 (0.022)\tLoss 1.6454 (2.4777)\tPrec@1 92.188 (86.793)\tPrec@5 99.219 (99.033)\n",
            "Epoch: [23][30/110], lr: 0.01000\tTime 0.062 (0.074)\tData 0.000 (0.016)\tLoss 1.9401 (2.6257)\tPrec@1 89.844 (85.963)\tPrec@5 100.000 (98.866)\n",
            "Epoch: [23][40/110], lr: 0.01000\tTime 0.059 (0.072)\tData 0.000 (0.013)\tLoss 1.7109 (2.5769)\tPrec@1 91.406 (86.319)\tPrec@5 100.000 (98.971)\n",
            "Epoch: [23][50/110], lr: 0.01000\tTime 0.055 (0.069)\tData 0.007 (0.011)\tLoss 2.7040 (2.6056)\tPrec@1 86.719 (86.167)\tPrec@5 99.219 (98.866)\n",
            "Epoch: [23][60/110], lr: 0.01000\tTime 0.071 (0.068)\tData 0.000 (0.010)\tLoss 2.6074 (2.6122)\tPrec@1 87.500 (86.206)\tPrec@5 99.219 (98.809)\n",
            "Epoch: [23][70/110], lr: 0.01000\tTime 0.045 (0.068)\tData 0.000 (0.009)\tLoss 3.1722 (2.6271)\tPrec@1 82.031 (86.081)\tPrec@5 99.219 (98.856)\n",
            "Epoch: [23][80/110], lr: 0.01000\tTime 0.041 (0.066)\tData 0.000 (0.009)\tLoss 2.4621 (2.6358)\tPrec@1 88.281 (85.995)\tPrec@5 100.000 (98.881)\n",
            "Epoch: [23][90/110], lr: 0.01000\tTime 0.073 (0.066)\tData 0.010 (0.008)\tLoss 1.9026 (2.6384)\tPrec@1 92.188 (86.015)\tPrec@5 100.000 (98.875)\n",
            "Epoch: [23][100/110], lr: 0.01000\tTime 0.067 (0.067)\tData 0.007 (0.008)\tLoss 2.5270 (2.6370)\tPrec@1 87.500 (86.023)\tPrec@5 100.000 (98.925)\n",
            "Test: [0/100]\tTime 0.454 (0.454)\tLoss 8.9208 (8.9208)\tPrec@1 60.000 (60.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.046 (0.076)\tLoss 6.7749 (8.0097)\tPrec@1 70.000 (63.545)\tPrec@5 94.000 (96.909)\n",
            "Test: [20/100]\tTime 0.055 (0.061)\tLoss 7.2248 (7.8012)\tPrec@1 65.000 (64.905)\tPrec@5 99.000 (96.524)\n",
            "Test: [30/100]\tTime 0.039 (0.054)\tLoss 7.2771 (7.8262)\tPrec@1 68.000 (64.742)\tPrec@5 96.000 (96.290)\n",
            "Test: [40/100]\tTime 0.039 (0.050)\tLoss 7.8550 (7.8413)\tPrec@1 68.000 (64.732)\tPrec@5 97.000 (96.195)\n",
            "Test: [50/100]\tTime 0.051 (0.049)\tLoss 6.6553 (7.7406)\tPrec@1 70.000 (65.020)\tPrec@5 97.000 (96.294)\n",
            "Test: [60/100]\tTime 0.031 (0.047)\tLoss 6.9853 (7.7752)\tPrec@1 66.000 (64.803)\tPrec@5 97.000 (96.410)\n",
            "Test: [70/100]\tTime 0.019 (0.044)\tLoss 7.3876 (7.7709)\tPrec@1 63.000 (64.690)\tPrec@5 98.000 (96.479)\n",
            "Test: [80/100]\tTime 0.018 (0.042)\tLoss 6.8432 (7.7231)\tPrec@1 74.000 (64.988)\tPrec@5 97.000 (96.556)\n",
            "Test: [90/100]\tTime 0.026 (0.040)\tLoss 7.4170 (7.7821)\tPrec@1 60.000 (64.714)\tPrec@5 99.000 (96.516)\n",
            "val Results: Prec@1 64.850 Prec@5 96.480 Loss 7.78447\n",
            "val Class Accuracy: [0.838,0.969,0.755,0.643,0.843,0.566,0.364,0.356,0.785,0.366]\n",
            "Best Prec@1: 64.850\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [24][0/110], lr: 0.01000\tTime 0.484 (0.484)\tData 0.376 (0.376)\tLoss 2.4682 (2.4682)\tPrec@1 86.719 (86.719)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [24][10/110], lr: 0.01000\tTime 0.045 (0.099)\tData 0.000 (0.039)\tLoss 2.5814 (2.6998)\tPrec@1 84.375 (86.009)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [24][20/110], lr: 0.01000\tTime 0.047 (0.082)\tData 0.000 (0.023)\tLoss 2.2371 (2.5868)\tPrec@1 89.062 (86.644)\tPrec@5 98.438 (99.330)\n",
            "Epoch: [24][30/110], lr: 0.01000\tTime 0.045 (0.074)\tData 0.000 (0.016)\tLoss 2.2812 (2.5437)\tPrec@1 89.062 (86.971)\tPrec@5 100.000 (99.294)\n",
            "Epoch: [24][40/110], lr: 0.01000\tTime 0.060 (0.071)\tData 0.006 (0.014)\tLoss 2.4360 (2.5186)\tPrec@1 87.500 (87.024)\tPrec@5 99.219 (99.123)\n",
            "Epoch: [24][50/110], lr: 0.01000\tTime 0.048 (0.069)\tData 0.010 (0.012)\tLoss 2.4142 (2.5717)\tPrec@1 84.375 (86.734)\tPrec@5 99.219 (99.050)\n",
            "Epoch: [24][60/110], lr: 0.01000\tTime 0.063 (0.068)\tData 0.000 (0.011)\tLoss 2.7019 (2.5755)\tPrec@1 87.500 (86.680)\tPrec@5 98.438 (99.014)\n",
            "Epoch: [24][70/110], lr: 0.01000\tTime 0.076 (0.066)\tData 0.006 (0.010)\tLoss 2.2238 (2.5976)\tPrec@1 85.938 (86.356)\tPrec@5 99.219 (98.977)\n",
            "Epoch: [24][80/110], lr: 0.01000\tTime 0.070 (0.066)\tData 0.009 (0.010)\tLoss 2.3868 (2.6049)\tPrec@1 86.719 (86.439)\tPrec@5 99.219 (98.987)\n",
            "Epoch: [24][90/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.006 (0.009)\tLoss 2.3684 (2.6249)\tPrec@1 85.938 (86.272)\tPrec@5 98.438 (99.004)\n",
            "Epoch: [24][100/110], lr: 0.01000\tTime 0.073 (0.065)\tData 0.008 (0.009)\tLoss 2.9050 (2.6451)\tPrec@1 84.375 (86.084)\tPrec@5 99.219 (99.002)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 10.5456 (10.5456)\tPrec@1 53.000 (53.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.025 (0.049)\tLoss 7.6898 (9.4917)\tPrec@1 65.000 (57.727)\tPrec@5 95.000 (93.545)\n",
            "Test: [20/100]\tTime 0.036 (0.041)\tLoss 9.5893 (9.5092)\tPrec@1 53.000 (57.286)\tPrec@5 94.000 (93.810)\n",
            "Test: [30/100]\tTime 0.015 (0.035)\tLoss 8.6554 (9.4723)\tPrec@1 55.000 (57.129)\tPrec@5 97.000 (93.484)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 10.1917 (9.5227)\tPrec@1 54.000 (56.878)\tPrec@5 94.000 (93.537)\n",
            "Test: [50/100]\tTime 0.012 (0.031)\tLoss 9.5925 (9.4567)\tPrec@1 53.000 (57.137)\tPrec@5 93.000 (93.765)\n",
            "Test: [60/100]\tTime 0.035 (0.030)\tLoss 8.4984 (9.4466)\tPrec@1 61.000 (56.869)\tPrec@5 96.000 (94.000)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 8.6268 (9.4823)\tPrec@1 61.000 (56.634)\tPrec@5 97.000 (93.873)\n",
            "Test: [80/100]\tTime 0.021 (0.030)\tLoss 8.3711 (9.4458)\tPrec@1 62.000 (56.617)\tPrec@5 93.000 (93.951)\n",
            "Test: [90/100]\tTime 0.021 (0.028)\tLoss 8.8865 (9.5186)\tPrec@1 62.000 (56.374)\tPrec@5 91.000 (93.736)\n",
            "val Results: Prec@1 56.160 Prec@5 93.760 Loss 9.56239\n",
            "val Class Accuracy: [0.914,0.936,0.858,0.592,0.730,0.234,0.603,0.443,0.260,0.046]\n",
            "Best Prec@1: 64.850\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [25][0/110], lr: 0.01000\tTime 0.492 (0.492)\tData 0.387 (0.387)\tLoss 2.6187 (2.6187)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [25][10/110], lr: 0.01000\tTime 0.052 (0.102)\tData 0.000 (0.038)\tLoss 2.9460 (2.7892)\tPrec@1 85.156 (85.440)\tPrec@5 99.219 (99.006)\n",
            "Epoch: [25][20/110], lr: 0.01000\tTime 0.053 (0.081)\tData 0.006 (0.023)\tLoss 2.4038 (2.6946)\tPrec@1 89.844 (86.086)\tPrec@5 99.219 (99.107)\n",
            "Epoch: [25][30/110], lr: 0.01000\tTime 0.068 (0.074)\tData 0.007 (0.017)\tLoss 2.5354 (2.5538)\tPrec@1 85.156 (86.643)\tPrec@5 100.000 (99.244)\n",
            "Epoch: [25][40/110], lr: 0.01000\tTime 0.044 (0.070)\tData 0.000 (0.013)\tLoss 3.6657 (2.5173)\tPrec@1 79.688 (86.890)\tPrec@5 100.000 (99.238)\n",
            "Epoch: [25][50/110], lr: 0.01000\tTime 0.038 (0.068)\tData 0.002 (0.012)\tLoss 2.5400 (2.5504)\tPrec@1 85.938 (86.657)\tPrec@5 97.656 (99.173)\n",
            "Epoch: [25][60/110], lr: 0.01000\tTime 0.068 (0.067)\tData 0.005 (0.011)\tLoss 2.8297 (2.5526)\tPrec@1 85.156 (86.616)\tPrec@5 100.000 (99.027)\n",
            "Epoch: [25][70/110], lr: 0.01000\tTime 0.064 (0.066)\tData 0.012 (0.010)\tLoss 2.1850 (2.5514)\tPrec@1 88.281 (86.620)\tPrec@5 97.656 (99.010)\n",
            "Epoch: [25][80/110], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.009)\tLoss 3.2159 (2.5700)\tPrec@1 82.812 (86.429)\tPrec@5 99.219 (99.055)\n",
            "Epoch: [25][90/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.007 (0.009)\tLoss 2.4582 (2.5710)\tPrec@1 88.281 (86.418)\tPrec@5 99.219 (99.073)\n",
            "Epoch: [25][100/110], lr: 0.01000\tTime 0.059 (0.064)\tData 0.007 (0.009)\tLoss 2.5782 (2.5887)\tPrec@1 82.031 (86.216)\tPrec@5 100.000 (99.002)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 8.5865 (8.5865)\tPrec@1 61.000 (61.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.023 (0.054)\tLoss 6.9766 (8.3003)\tPrec@1 67.000 (61.455)\tPrec@5 95.000 (95.182)\n",
            "Test: [20/100]\tTime 0.044 (0.042)\tLoss 6.3313 (8.2183)\tPrec@1 71.000 (61.619)\tPrec@5 97.000 (94.762)\n",
            "Test: [30/100]\tTime 0.016 (0.035)\tLoss 7.5196 (8.2904)\tPrec@1 63.000 (61.323)\tPrec@5 92.000 (95.032)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 8.8102 (8.3516)\tPrec@1 54.000 (60.756)\tPrec@5 95.000 (95.220)\n",
            "Test: [50/100]\tTime 0.014 (0.032)\tLoss 7.3970 (8.1866)\tPrec@1 64.000 (61.706)\tPrec@5 97.000 (95.373)\n",
            "Test: [60/100]\tTime 0.028 (0.031)\tLoss 7.2064 (8.1106)\tPrec@1 66.000 (62.197)\tPrec@5 93.000 (95.344)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 7.6091 (8.1050)\tPrec@1 70.000 (62.423)\tPrec@5 96.000 (95.085)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 6.7197 (8.0462)\tPrec@1 68.000 (62.704)\tPrec@5 96.000 (95.235)\n",
            "Test: [90/100]\tTime 0.011 (0.029)\tLoss 7.8579 (8.0911)\tPrec@1 63.000 (62.648)\tPrec@5 95.000 (95.154)\n",
            "val Results: Prec@1 62.650 Prec@5 95.150 Loss 8.12225\n",
            "val Class Accuracy: [0.913,0.985,0.675,0.568,0.707,0.638,0.695,0.684,0.110,0.290]\n",
            "Best Prec@1: 64.850\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [26][0/110], lr: 0.01000\tTime 0.484 (0.484)\tData 0.402 (0.402)\tLoss 2.0111 (2.0111)\tPrec@1 89.844 (89.844)\tPrec@5 97.656 (97.656)\n",
            "Epoch: [26][10/110], lr: 0.01000\tTime 0.049 (0.100)\tData 0.000 (0.041)\tLoss 1.9601 (2.4364)\tPrec@1 89.062 (86.435)\tPrec@5 99.219 (99.006)\n",
            "Epoch: [26][20/110], lr: 0.01000\tTime 0.073 (0.082)\tData 0.006 (0.024)\tLoss 2.1904 (2.3415)\tPrec@1 88.281 (87.054)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [26][30/110], lr: 0.01000\tTime 0.066 (0.074)\tData 0.005 (0.017)\tLoss 3.0374 (2.3866)\tPrec@1 84.375 (87.021)\tPrec@5 96.875 (98.992)\n",
            "Epoch: [26][40/110], lr: 0.01000\tTime 0.043 (0.071)\tData 0.000 (0.014)\tLoss 3.0756 (2.4068)\tPrec@1 85.156 (86.928)\tPrec@5 98.438 (99.028)\n",
            "Epoch: [26][50/110], lr: 0.01000\tTime 0.066 (0.069)\tData 0.005 (0.013)\tLoss 1.7908 (2.4181)\tPrec@1 90.625 (87.132)\tPrec@5 99.219 (99.035)\n",
            "Epoch: [26][60/110], lr: 0.01000\tTime 0.063 (0.067)\tData 0.007 (0.012)\tLoss 2.0892 (2.4347)\tPrec@1 87.500 (86.936)\tPrec@5 97.656 (99.014)\n",
            "Epoch: [26][70/110], lr: 0.01000\tTime 0.056 (0.066)\tData 0.007 (0.011)\tLoss 2.4125 (2.4437)\tPrec@1 87.500 (86.906)\tPrec@5 100.000 (99.010)\n",
            "Epoch: [26][80/110], lr: 0.01000\tTime 0.053 (0.065)\tData 0.002 (0.010)\tLoss 2.3458 (2.4322)\tPrec@1 87.500 (86.960)\tPrec@5 100.000 (99.016)\n",
            "Epoch: [26][90/110], lr: 0.01000\tTime 0.078 (0.065)\tData 0.007 (0.009)\tLoss 2.3197 (2.4585)\tPrec@1 89.062 (86.830)\tPrec@5 99.219 (99.004)\n",
            "Epoch: [26][100/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.003 (0.009)\tLoss 2.2819 (2.4349)\tPrec@1 89.062 (86.966)\tPrec@5 100.000 (99.025)\n",
            "Test: [0/100]\tTime 0.265 (0.265)\tLoss 8.6161 (8.6161)\tPrec@1 59.000 (59.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.034 (0.053)\tLoss 7.2096 (7.5371)\tPrec@1 66.000 (65.273)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.042 (0.039)\tLoss 5.6632 (7.4283)\tPrec@1 75.000 (66.476)\tPrec@5 98.000 (96.190)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 7.5208 (7.5206)\tPrec@1 67.000 (66.355)\tPrec@5 97.000 (96.032)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 6.7984 (7.5530)\tPrec@1 72.000 (66.293)\tPrec@5 93.000 (95.927)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 6.4059 (7.4677)\tPrec@1 70.000 (66.412)\tPrec@5 97.000 (96.176)\n",
            "Test: [60/100]\tTime 0.017 (0.030)\tLoss 6.8330 (7.4651)\tPrec@1 69.000 (66.525)\tPrec@5 98.000 (96.311)\n",
            "Test: [70/100]\tTime 0.036 (0.030)\tLoss 7.4447 (7.4751)\tPrec@1 65.000 (66.366)\tPrec@5 99.000 (96.338)\n",
            "Test: [80/100]\tTime 0.033 (0.030)\tLoss 6.5255 (7.4002)\tPrec@1 73.000 (66.704)\tPrec@5 94.000 (96.370)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 6.7094 (7.4637)\tPrec@1 70.000 (66.341)\tPrec@5 96.000 (96.319)\n",
            "val Results: Prec@1 66.440 Prec@5 96.320 Loss 7.46907\n",
            "val Class Accuracy: [0.915,0.979,0.673,0.408,0.632,0.771,0.508,0.688,0.590,0.480]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [27][0/110], lr: 0.01000\tTime 0.371 (0.371)\tData 0.273 (0.273)\tLoss 2.7872 (2.7872)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [27][10/110], lr: 0.01000\tTime 0.060 (0.102)\tData 0.007 (0.035)\tLoss 2.9458 (2.7841)\tPrec@1 84.375 (85.511)\tPrec@5 97.656 (98.509)\n",
            "Epoch: [27][20/110], lr: 0.01000\tTime 0.059 (0.081)\tData 0.007 (0.020)\tLoss 1.6981 (2.7164)\tPrec@1 91.406 (85.789)\tPrec@5 100.000 (98.810)\n",
            "Epoch: [27][30/110], lr: 0.01000\tTime 0.043 (0.074)\tData 0.000 (0.016)\tLoss 2.5409 (2.6524)\tPrec@1 87.500 (86.164)\tPrec@5 99.219 (98.866)\n",
            "Epoch: [27][40/110], lr: 0.01000\tTime 0.047 (0.070)\tData 0.000 (0.013)\tLoss 2.8632 (2.6141)\tPrec@1 83.594 (86.185)\tPrec@5 97.656 (98.914)\n",
            "Epoch: [27][50/110], lr: 0.01000\tTime 0.054 (0.069)\tData 0.000 (0.011)\tLoss 3.8851 (2.6736)\tPrec@1 81.250 (85.754)\tPrec@5 96.094 (98.744)\n",
            "Epoch: [27][60/110], lr: 0.01000\tTime 0.062 (0.067)\tData 0.000 (0.010)\tLoss 2.8216 (2.6459)\tPrec@1 82.812 (85.886)\tPrec@5 98.438 (98.732)\n",
            "Epoch: [27][70/110], lr: 0.01000\tTime 0.063 (0.067)\tData 0.003 (0.009)\tLoss 2.0032 (2.6096)\tPrec@1 89.062 (86.081)\tPrec@5 98.438 (98.801)\n",
            "Epoch: [27][80/110], lr: 0.01000\tTime 0.072 (0.065)\tData 0.010 (0.008)\tLoss 1.7216 (2.5944)\tPrec@1 90.625 (86.140)\tPrec@5 100.000 (98.852)\n",
            "Epoch: [27][90/110], lr: 0.01000\tTime 0.049 (0.065)\tData 0.008 (0.008)\tLoss 1.6860 (2.5682)\tPrec@1 92.188 (86.332)\tPrec@5 100.000 (98.824)\n",
            "Epoch: [27][100/110], lr: 0.01000\tTime 0.058 (0.065)\tData 0.007 (0.008)\tLoss 1.9052 (2.5617)\tPrec@1 90.625 (86.293)\tPrec@5 100.000 (98.847)\n",
            "Test: [0/100]\tTime 0.242 (0.242)\tLoss 11.7678 (11.7678)\tPrec@1 44.000 (44.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/100]\tTime 0.044 (0.053)\tLoss 8.7593 (11.0868)\tPrec@1 60.000 (49.182)\tPrec@5 89.000 (92.909)\n",
            "Test: [20/100]\tTime 0.021 (0.039)\tLoss 10.2554 (11.1371)\tPrec@1 48.000 (48.667)\tPrec@5 94.000 (93.000)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 10.1266 (11.1540)\tPrec@1 51.000 (48.548)\tPrec@5 93.000 (92.484)\n",
            "Test: [40/100]\tTime 0.016 (0.032)\tLoss 11.6654 (11.1909)\tPrec@1 45.000 (48.390)\tPrec@5 94.000 (92.537)\n",
            "Test: [50/100]\tTime 0.032 (0.031)\tLoss 10.6682 (11.1187)\tPrec@1 51.000 (48.725)\tPrec@5 96.000 (92.686)\n",
            "Test: [60/100]\tTime 0.027 (0.030)\tLoss 10.0954 (11.1328)\tPrec@1 53.000 (48.770)\tPrec@5 92.000 (92.623)\n",
            "Test: [70/100]\tTime 0.034 (0.030)\tLoss 10.9371 (11.1856)\tPrec@1 52.000 (48.577)\tPrec@5 96.000 (92.662)\n",
            "Test: [80/100]\tTime 0.018 (0.029)\tLoss 9.2362 (11.1582)\tPrec@1 58.000 (48.617)\tPrec@5 92.000 (92.790)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 11.2913 (11.2411)\tPrec@1 51.000 (48.396)\tPrec@5 93.000 (92.846)\n",
            "val Results: Prec@1 48.380 Prec@5 92.790 Loss 11.26825\n",
            "val Class Accuracy: [0.943,0.916,0.854,0.371,0.682,0.142,0.568,0.196,0.096,0.070]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [28][0/110], lr: 0.01000\tTime 0.409 (0.409)\tData 0.311 (0.311)\tLoss 2.8429 (2.8429)\tPrec@1 85.156 (85.156)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [28][10/110], lr: 0.01000\tTime 0.114 (0.106)\tData 0.008 (0.034)\tLoss 2.7477 (2.6276)\tPrec@1 83.594 (86.080)\tPrec@5 97.656 (99.290)\n",
            "Epoch: [28][20/110], lr: 0.01000\tTime 0.083 (0.092)\tData 0.000 (0.021)\tLoss 3.1878 (2.5334)\tPrec@1 83.594 (86.682)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [28][30/110], lr: 0.01000\tTime 0.071 (0.091)\tData 0.006 (0.018)\tLoss 2.7910 (2.4447)\tPrec@1 85.156 (87.399)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [28][40/110], lr: 0.01000\tTime 0.085 (0.091)\tData 0.000 (0.015)\tLoss 2.2331 (2.4538)\tPrec@1 88.281 (87.329)\tPrec@5 98.438 (99.162)\n",
            "Epoch: [28][50/110], lr: 0.01000\tTime 0.079 (0.090)\tData 0.003 (0.013)\tLoss 1.9061 (2.3975)\tPrec@1 89.062 (87.561)\tPrec@5 100.000 (99.188)\n",
            "Epoch: [28][60/110], lr: 0.01000\tTime 0.086 (0.091)\tData 0.003 (0.013)\tLoss 2.5145 (2.4113)\tPrec@1 85.938 (87.346)\tPrec@5 100.000 (99.155)\n",
            "Epoch: [28][70/110], lr: 0.01000\tTime 0.058 (0.087)\tData 0.007 (0.012)\tLoss 1.6553 (2.4039)\tPrec@1 92.188 (87.423)\tPrec@5 99.219 (99.142)\n",
            "Epoch: [28][80/110], lr: 0.01000\tTime 0.059 (0.084)\tData 0.006 (0.011)\tLoss 1.8469 (2.4316)\tPrec@1 91.406 (87.240)\tPrec@5 99.219 (99.064)\n",
            "Epoch: [28][90/110], lr: 0.01000\tTime 0.068 (0.081)\tData 0.000 (0.011)\tLoss 2.6667 (2.4379)\tPrec@1 85.938 (87.174)\tPrec@5 98.438 (99.047)\n",
            "Epoch: [28][100/110], lr: 0.01000\tTime 0.053 (0.079)\tData 0.007 (0.010)\tLoss 2.4851 (2.4500)\tPrec@1 86.719 (87.113)\tPrec@5 99.219 (99.025)\n",
            "Test: [0/100]\tTime 0.335 (0.335)\tLoss 12.4722 (12.4722)\tPrec@1 47.000 (47.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/100]\tTime 0.023 (0.052)\tLoss 7.3705 (10.3226)\tPrec@1 65.000 (56.091)\tPrec@5 96.000 (94.545)\n",
            "Test: [20/100]\tTime 0.027 (0.040)\tLoss 8.1236 (10.2266)\tPrec@1 67.000 (56.048)\tPrec@5 97.000 (94.143)\n",
            "Test: [30/100]\tTime 0.022 (0.037)\tLoss 10.3036 (10.3194)\tPrec@1 51.000 (55.194)\tPrec@5 93.000 (93.839)\n",
            "Test: [40/100]\tTime 0.022 (0.034)\tLoss 11.3649 (10.4407)\tPrec@1 53.000 (54.976)\tPrec@5 88.000 (93.317)\n",
            "Test: [50/100]\tTime 0.028 (0.032)\tLoss 10.0888 (10.3362)\tPrec@1 58.000 (55.353)\tPrec@5 93.000 (93.510)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 8.6253 (10.3197)\tPrec@1 65.000 (55.295)\tPrec@5 92.000 (93.525)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 10.8066 (10.3278)\tPrec@1 51.000 (55.282)\tPrec@5 97.000 (93.718)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 9.3647 (10.2793)\tPrec@1 62.000 (55.481)\tPrec@5 91.000 (93.753)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 10.1851 (10.3359)\tPrec@1 60.000 (55.429)\tPrec@5 93.000 (93.582)\n",
            "val Results: Prec@1 55.220 Prec@5 93.590 Loss 10.38174\n",
            "val Class Accuracy: [0.933,0.975,0.885,0.504,0.627,0.524,0.504,0.226,0.282,0.062]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [29][0/110], lr: 0.01000\tTime 0.432 (0.432)\tData 0.351 (0.351)\tLoss 2.1005 (2.1005)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [29][10/110], lr: 0.01000\tTime 0.061 (0.105)\tData 0.007 (0.036)\tLoss 2.7137 (2.4088)\tPrec@1 84.375 (87.784)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [29][20/110], lr: 0.01000\tTime 0.061 (0.082)\tData 0.000 (0.022)\tLoss 1.8877 (2.4296)\tPrec@1 91.406 (87.463)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [29][30/110], lr: 0.01000\tTime 0.066 (0.076)\tData 0.010 (0.016)\tLoss 2.5820 (2.5225)\tPrec@1 86.719 (86.845)\tPrec@5 99.219 (99.168)\n",
            "Epoch: [29][40/110], lr: 0.01000\tTime 0.085 (0.071)\tData 0.006 (0.014)\tLoss 2.6377 (2.4808)\tPrec@1 85.938 (87.062)\tPrec@5 97.656 (99.104)\n",
            "Epoch: [29][50/110], lr: 0.01000\tTime 0.062 (0.069)\tData 0.007 (0.011)\tLoss 2.7366 (2.4567)\tPrec@1 87.500 (87.056)\tPrec@5 98.438 (99.096)\n",
            "Epoch: [29][60/110], lr: 0.01000\tTime 0.073 (0.067)\tData 0.006 (0.010)\tLoss 2.5323 (2.4691)\tPrec@1 85.938 (86.949)\tPrec@5 97.656 (99.091)\n",
            "Epoch: [29][70/110], lr: 0.01000\tTime 0.054 (0.066)\tData 0.012 (0.010)\tLoss 2.1722 (2.4492)\tPrec@1 89.844 (86.972)\tPrec@5 100.000 (99.175)\n",
            "Epoch: [29][80/110], lr: 0.01000\tTime 0.059 (0.064)\tData 0.000 (0.009)\tLoss 3.4525 (2.4122)\tPrec@1 79.688 (87.124)\tPrec@5 97.656 (99.209)\n",
            "Epoch: [29][90/110], lr: 0.01000\tTime 0.057 (0.064)\tData 0.006 (0.008)\tLoss 2.3298 (2.4008)\tPrec@1 89.844 (87.217)\tPrec@5 98.438 (99.193)\n",
            "Epoch: [29][100/110], lr: 0.01000\tTime 0.063 (0.063)\tData 0.002 (0.008)\tLoss 1.7263 (2.3846)\tPrec@1 89.062 (87.276)\tPrec@5 98.438 (99.211)\n",
            "Test: [0/100]\tTime 0.250 (0.250)\tLoss 9.0575 (9.0575)\tPrec@1 60.000 (60.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.047 (0.052)\tLoss 6.5596 (8.7876)\tPrec@1 70.000 (60.818)\tPrec@5 96.000 (97.091)\n",
            "Test: [20/100]\tTime 0.018 (0.040)\tLoss 7.8565 (8.8399)\tPrec@1 65.000 (60.381)\tPrec@5 98.000 (96.619)\n",
            "Test: [30/100]\tTime 0.018 (0.037)\tLoss 8.9030 (8.9060)\tPrec@1 55.000 (60.032)\tPrec@5 98.000 (96.452)\n",
            "Test: [40/100]\tTime 0.035 (0.034)\tLoss 9.8631 (8.9374)\tPrec@1 54.000 (59.902)\tPrec@5 90.000 (96.171)\n",
            "Test: [50/100]\tTime 0.018 (0.033)\tLoss 7.9484 (8.7889)\tPrec@1 64.000 (60.588)\tPrec@5 98.000 (96.373)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 7.7301 (8.7333)\tPrec@1 66.000 (60.820)\tPrec@5 94.000 (96.230)\n",
            "Test: [70/100]\tTime 0.035 (0.030)\tLoss 8.8466 (8.7538)\tPrec@1 63.000 (60.775)\tPrec@5 98.000 (96.254)\n",
            "Test: [80/100]\tTime 0.014 (0.029)\tLoss 8.0741 (8.7311)\tPrec@1 64.000 (60.802)\tPrec@5 94.000 (96.247)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 8.0993 (8.8105)\tPrec@1 65.000 (60.484)\tPrec@5 97.000 (96.154)\n",
            "val Results: Prec@1 60.420 Prec@5 96.170 Loss 8.81590\n",
            "val Class Accuracy: [0.968,0.954,0.765,0.656,0.660,0.554,0.702,0.521,0.092,0.170]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [30][0/110], lr: 0.01000\tTime 0.426 (0.426)\tData 0.331 (0.331)\tLoss 2.4333 (2.4333)\tPrec@1 85.938 (85.938)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [30][10/110], lr: 0.01000\tTime 0.070 (0.100)\tData 0.014 (0.034)\tLoss 3.4134 (2.5540)\tPrec@1 80.469 (86.293)\tPrec@5 98.438 (99.077)\n",
            "Epoch: [30][20/110], lr: 0.01000\tTime 0.058 (0.080)\tData 0.000 (0.020)\tLoss 2.3248 (2.3766)\tPrec@1 89.062 (87.351)\tPrec@5 98.438 (99.182)\n",
            "Epoch: [30][30/110], lr: 0.01000\tTime 0.062 (0.073)\tData 0.007 (0.015)\tLoss 1.5017 (2.4095)\tPrec@1 92.969 (87.273)\tPrec@5 98.438 (99.093)\n",
            "Epoch: [30][40/110], lr: 0.01000\tTime 0.072 (0.070)\tData 0.005 (0.013)\tLoss 2.0854 (2.3572)\tPrec@1 91.406 (87.691)\tPrec@5 98.438 (99.123)\n",
            "Epoch: [30][50/110], lr: 0.01000\tTime 0.052 (0.068)\tData 0.006 (0.012)\tLoss 1.8302 (2.3301)\tPrec@1 90.625 (87.760)\tPrec@5 100.000 (99.142)\n",
            "Epoch: [30][60/110], lr: 0.01000\tTime 0.059 (0.066)\tData 0.006 (0.011)\tLoss 1.7735 (2.3100)\tPrec@1 90.625 (87.871)\tPrec@5 99.219 (99.180)\n",
            "Epoch: [30][70/110], lr: 0.01000\tTime 0.044 (0.065)\tData 0.004 (0.010)\tLoss 1.9061 (2.2937)\tPrec@1 90.625 (87.962)\tPrec@5 99.219 (99.186)\n",
            "Epoch: [30][80/110], lr: 0.01000\tTime 0.060 (0.064)\tData 0.000 (0.009)\tLoss 1.6374 (2.2964)\tPrec@1 91.406 (87.953)\tPrec@5 100.000 (99.161)\n",
            "Epoch: [30][90/110], lr: 0.01000\tTime 0.042 (0.063)\tData 0.000 (0.008)\tLoss 2.3715 (2.3043)\tPrec@1 87.500 (87.921)\tPrec@5 100.000 (99.184)\n",
            "Epoch: [30][100/110], lr: 0.01000\tTime 0.061 (0.063)\tData 0.000 (0.008)\tLoss 1.8626 (2.3226)\tPrec@1 88.281 (87.802)\tPrec@5 100.000 (99.157)\n",
            "Test: [0/100]\tTime 0.266 (0.266)\tLoss 8.9833 (8.9833)\tPrec@1 59.000 (59.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.054)\tLoss 7.1649 (8.8271)\tPrec@1 65.000 (60.455)\tPrec@5 97.000 (95.364)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 7.8114 (8.8736)\tPrec@1 62.000 (59.857)\tPrec@5 96.000 (94.810)\n",
            "Test: [30/100]\tTime 0.010 (0.035)\tLoss 8.9762 (8.8708)\tPrec@1 54.000 (59.774)\tPrec@5 94.000 (94.581)\n",
            "Test: [40/100]\tTime 0.032 (0.032)\tLoss 9.3099 (8.8642)\tPrec@1 59.000 (59.927)\tPrec@5 96.000 (94.585)\n",
            "Test: [50/100]\tTime 0.020 (0.031)\tLoss 7.9699 (8.7122)\tPrec@1 65.000 (60.725)\tPrec@5 96.000 (94.725)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 7.1441 (8.7043)\tPrec@1 67.000 (60.639)\tPrec@5 96.000 (94.689)\n",
            "Test: [70/100]\tTime 0.020 (0.029)\tLoss 8.5992 (8.7060)\tPrec@1 63.000 (60.662)\tPrec@5 98.000 (94.817)\n",
            "Test: [80/100]\tTime 0.030 (0.028)\tLoss 8.2861 (8.6618)\tPrec@1 64.000 (60.728)\tPrec@5 96.000 (94.975)\n",
            "Test: [90/100]\tTime 0.035 (0.028)\tLoss 8.2840 (8.6993)\tPrec@1 69.000 (60.780)\tPrec@5 94.000 (94.956)\n",
            "val Results: Prec@1 60.670 Prec@5 94.910 Loss 8.72705\n",
            "val Class Accuracy: [0.980,0.967,0.746,0.661,0.661,0.523,0.513,0.405,0.393,0.218]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [31][0/110], lr: 0.01000\tTime 0.391 (0.391)\tData 0.320 (0.320)\tLoss 1.8676 (1.8676)\tPrec@1 90.625 (90.625)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [31][10/110], lr: 0.01000\tTime 0.060 (0.098)\tData 0.000 (0.035)\tLoss 2.4937 (2.4731)\tPrec@1 87.500 (87.074)\tPrec@5 98.438 (98.864)\n",
            "Epoch: [31][20/110], lr: 0.01000\tTime 0.047 (0.081)\tData 0.000 (0.020)\tLoss 2.0078 (2.4246)\tPrec@1 89.844 (87.277)\tPrec@5 100.000 (99.107)\n",
            "Epoch: [31][30/110], lr: 0.01000\tTime 0.067 (0.074)\tData 0.006 (0.015)\tLoss 2.0877 (2.3896)\tPrec@1 87.500 (87.223)\tPrec@5 100.000 (99.194)\n",
            "Epoch: [31][40/110], lr: 0.01000\tTime 0.057 (0.071)\tData 0.000 (0.012)\tLoss 2.2853 (2.3836)\tPrec@1 85.938 (87.271)\tPrec@5 100.000 (99.181)\n",
            "Epoch: [31][50/110], lr: 0.01000\tTime 0.056 (0.068)\tData 0.006 (0.011)\tLoss 2.8454 (2.3236)\tPrec@1 85.156 (87.561)\tPrec@5 96.875 (99.219)\n",
            "Epoch: [31][60/110], lr: 0.01000\tTime 0.043 (0.067)\tData 0.003 (0.010)\tLoss 2.9959 (2.3432)\tPrec@1 84.375 (87.462)\tPrec@5 97.656 (99.155)\n",
            "Epoch: [31][70/110], lr: 0.01000\tTime 0.070 (0.065)\tData 0.006 (0.010)\tLoss 3.4373 (2.3468)\tPrec@1 82.812 (87.467)\tPrec@5 98.438 (99.153)\n",
            "Epoch: [31][80/110], lr: 0.01000\tTime 0.060 (0.064)\tData 0.005 (0.009)\tLoss 2.5274 (2.3410)\tPrec@1 86.719 (87.548)\tPrec@5 99.219 (99.199)\n",
            "Epoch: [31][90/110], lr: 0.01000\tTime 0.056 (0.064)\tData 0.007 (0.009)\tLoss 2.3027 (2.3412)\tPrec@1 87.500 (87.552)\tPrec@5 100.000 (99.167)\n",
            "Epoch: [31][100/110], lr: 0.01000\tTime 0.075 (0.063)\tData 0.013 (0.009)\tLoss 2.1254 (2.3217)\tPrec@1 89.062 (87.624)\tPrec@5 98.438 (99.141)\n",
            "Test: [0/100]\tTime 0.274 (0.274)\tLoss 8.3038 (8.3038)\tPrec@1 64.000 (64.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.011 (0.054)\tLoss 5.9133 (7.9811)\tPrec@1 75.000 (64.909)\tPrec@5 96.000 (95.636)\n",
            "Test: [20/100]\tTime 0.046 (0.040)\tLoss 7.2558 (8.0618)\tPrec@1 66.000 (63.714)\tPrec@5 99.000 (95.571)\n",
            "Test: [30/100]\tTime 0.042 (0.035)\tLoss 8.2332 (8.2017)\tPrec@1 59.000 (62.935)\tPrec@5 97.000 (95.419)\n",
            "Test: [40/100]\tTime 0.037 (0.032)\tLoss 8.8279 (8.2169)\tPrec@1 60.000 (62.878)\tPrec@5 95.000 (95.220)\n",
            "Test: [50/100]\tTime 0.046 (0.032)\tLoss 7.8350 (8.1149)\tPrec@1 66.000 (63.412)\tPrec@5 97.000 (95.392)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 6.8368 (8.1092)\tPrec@1 69.000 (63.180)\tPrec@5 94.000 (95.197)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 7.5667 (8.1282)\tPrec@1 68.000 (63.211)\tPrec@5 95.000 (95.141)\n",
            "Test: [80/100]\tTime 0.030 (0.030)\tLoss 7.7073 (8.0793)\tPrec@1 68.000 (63.346)\tPrec@5 94.000 (95.123)\n",
            "Test: [90/100]\tTime 0.020 (0.029)\tLoss 8.0503 (8.1463)\tPrec@1 67.000 (63.154)\tPrec@5 95.000 (95.110)\n",
            "val Results: Prec@1 63.070 Prec@5 95.100 Loss 8.17236\n",
            "val Class Accuracy: [0.962,0.938,0.779,0.751,0.642,0.417,0.698,0.408,0.351,0.361]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [32][0/110], lr: 0.01000\tTime 0.429 (0.429)\tData 0.330 (0.330)\tLoss 1.7049 (1.7049)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [32][10/110], lr: 0.01000\tTime 0.063 (0.102)\tData 0.005 (0.033)\tLoss 2.9366 (2.1908)\tPrec@1 82.812 (87.713)\tPrec@5 98.438 (99.006)\n",
            "Epoch: [32][20/110], lr: 0.01000\tTime 0.069 (0.080)\tData 0.005 (0.019)\tLoss 1.9959 (2.1396)\tPrec@1 89.062 (88.318)\tPrec@5 100.000 (99.182)\n",
            "Epoch: [32][30/110], lr: 0.01000\tTime 0.053 (0.073)\tData 0.005 (0.014)\tLoss 2.0560 (2.1521)\tPrec@1 87.500 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [32][40/110], lr: 0.01000\tTime 0.064 (0.070)\tData 0.006 (0.012)\tLoss 2.0270 (2.1564)\tPrec@1 88.281 (88.262)\tPrec@5 99.219 (99.295)\n",
            "Epoch: [32][50/110], lr: 0.01000\tTime 0.056 (0.067)\tData 0.000 (0.010)\tLoss 1.8970 (2.1475)\tPrec@1 89.844 (88.343)\tPrec@5 99.219 (99.234)\n",
            "Epoch: [32][60/110], lr: 0.01000\tTime 0.047 (0.065)\tData 0.000 (0.009)\tLoss 2.6040 (2.1778)\tPrec@1 84.375 (88.217)\tPrec@5 98.438 (99.193)\n",
            "Epoch: [32][70/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.006 (0.008)\tLoss 1.7555 (2.1961)\tPrec@1 90.625 (88.160)\tPrec@5 100.000 (99.208)\n",
            "Epoch: [32][80/110], lr: 0.01000\tTime 0.065 (0.064)\tData 0.006 (0.008)\tLoss 2.5305 (2.2516)\tPrec@1 85.938 (87.973)\tPrec@5 98.438 (99.180)\n",
            "Epoch: [32][90/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.000 (0.008)\tLoss 2.9510 (2.2590)\tPrec@1 85.156 (87.912)\tPrec@5 100.000 (99.184)\n",
            "Epoch: [32][100/110], lr: 0.01000\tTime 0.071 (0.064)\tData 0.001 (0.007)\tLoss 1.5567 (2.2656)\tPrec@1 92.969 (87.887)\tPrec@5 99.219 (99.149)\n",
            "Test: [0/100]\tTime 0.357 (0.357)\tLoss 6.9413 (6.9413)\tPrec@1 72.000 (72.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.045 (0.073)\tLoss 5.5964 (7.5667)\tPrec@1 74.000 (66.545)\tPrec@5 95.000 (96.364)\n",
            "Test: [20/100]\tTime 0.036 (0.055)\tLoss 6.7582 (7.5404)\tPrec@1 67.000 (66.048)\tPrec@5 100.000 (96.333)\n",
            "Test: [30/100]\tTime 0.037 (0.052)\tLoss 7.4630 (7.6449)\tPrec@1 65.000 (65.419)\tPrec@5 97.000 (96.000)\n",
            "Test: [40/100]\tTime 0.050 (0.050)\tLoss 7.8853 (7.6814)\tPrec@1 64.000 (65.463)\tPrec@5 91.000 (95.585)\n",
            "Test: [50/100]\tTime 0.030 (0.047)\tLoss 7.6960 (7.6017)\tPrec@1 66.000 (65.882)\tPrec@5 97.000 (95.863)\n",
            "Test: [60/100]\tTime 0.046 (0.047)\tLoss 7.2500 (7.6405)\tPrec@1 64.000 (65.443)\tPrec@5 97.000 (95.820)\n",
            "Test: [70/100]\tTime 0.048 (0.046)\tLoss 7.8348 (7.6551)\tPrec@1 63.000 (65.394)\tPrec@5 95.000 (95.803)\n",
            "Test: [80/100]\tTime 0.047 (0.046)\tLoss 7.2891 (7.6637)\tPrec@1 69.000 (65.272)\tPrec@5 93.000 (95.827)\n",
            "Test: [90/100]\tTime 0.038 (0.045)\tLoss 7.0079 (7.7150)\tPrec@1 69.000 (65.055)\tPrec@5 97.000 (95.703)\n",
            "val Results: Prec@1 64.900 Prec@5 95.710 Loss 7.75057\n",
            "val Class Accuracy: [0.902,0.959,0.831,0.428,0.720,0.507,0.843,0.388,0.551,0.361]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [33][0/110], lr: 0.01000\tTime 0.447 (0.447)\tData 0.340 (0.340)\tLoss 2.0389 (2.0389)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [33][10/110], lr: 0.01000\tTime 0.059 (0.106)\tData 0.003 (0.036)\tLoss 1.6689 (2.3056)\tPrec@1 92.188 (87.926)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [33][20/110], lr: 0.01000\tTime 0.060 (0.084)\tData 0.007 (0.022)\tLoss 1.7275 (2.2423)\tPrec@1 90.625 (87.984)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [33][30/110], lr: 0.01000\tTime 0.044 (0.075)\tData 0.000 (0.017)\tLoss 2.6420 (2.3115)\tPrec@1 83.594 (87.500)\tPrec@5 100.000 (99.395)\n",
            "Epoch: [33][40/110], lr: 0.01000\tTime 0.060 (0.072)\tData 0.010 (0.014)\tLoss 1.8546 (2.2793)\tPrec@1 91.406 (87.748)\tPrec@5 100.000 (99.352)\n",
            "Epoch: [33][50/110], lr: 0.01000\tTime 0.065 (0.069)\tData 0.000 (0.012)\tLoss 2.6963 (2.2190)\tPrec@1 85.938 (88.143)\tPrec@5 99.219 (99.295)\n",
            "Epoch: [33][60/110], lr: 0.01000\tTime 0.063 (0.067)\tData 0.013 (0.011)\tLoss 2.1898 (2.2690)\tPrec@1 87.500 (87.884)\tPrec@5 99.219 (99.244)\n",
            "Epoch: [33][70/110], lr: 0.01000\tTime 0.072 (0.067)\tData 0.007 (0.011)\tLoss 2.1494 (2.2339)\tPrec@1 89.844 (88.193)\tPrec@5 99.219 (99.252)\n",
            "Epoch: [33][80/110], lr: 0.01000\tTime 0.073 (0.066)\tData 0.006 (0.010)\tLoss 1.9838 (2.2533)\tPrec@1 91.406 (88.050)\tPrec@5 98.438 (99.248)\n",
            "Epoch: [33][90/110], lr: 0.01000\tTime 0.044 (0.065)\tData 0.000 (0.009)\tLoss 2.1652 (2.2797)\tPrec@1 91.406 (87.886)\tPrec@5 99.219 (99.270)\n",
            "Epoch: [33][100/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.007 (0.009)\tLoss 1.8837 (2.2493)\tPrec@1 88.281 (88.041)\tPrec@5 100.000 (99.288)\n",
            "Test: [0/100]\tTime 0.270 (0.270)\tLoss 11.3837 (11.3837)\tPrec@1 49.000 (49.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.019 (0.052)\tLoss 8.5322 (10.6783)\tPrec@1 64.000 (52.455)\tPrec@5 95.000 (94.091)\n",
            "Test: [20/100]\tTime 0.033 (0.042)\tLoss 9.5279 (10.4159)\tPrec@1 54.000 (53.143)\tPrec@5 94.000 (94.381)\n",
            "Test: [30/100]\tTime 0.035 (0.034)\tLoss 10.3938 (10.5063)\tPrec@1 52.000 (52.968)\tPrec@5 94.000 (93.871)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 10.7397 (10.5385)\tPrec@1 54.000 (53.220)\tPrec@5 95.000 (93.829)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 10.8563 (10.4416)\tPrec@1 48.000 (53.471)\tPrec@5 94.000 (94.078)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 8.9519 (10.4205)\tPrec@1 59.000 (53.393)\tPrec@5 95.000 (94.213)\n",
            "Test: [70/100]\tTime 0.038 (0.030)\tLoss 9.5268 (10.4944)\tPrec@1 59.000 (53.239)\tPrec@5 96.000 (93.972)\n",
            "Test: [80/100]\tTime 0.020 (0.030)\tLoss 10.3993 (10.5002)\tPrec@1 54.000 (53.123)\tPrec@5 90.000 (93.877)\n",
            "Test: [90/100]\tTime 0.012 (0.029)\tLoss 11.1539 (10.5685)\tPrec@1 50.000 (52.791)\tPrec@5 95.000 (93.769)\n",
            "val Results: Prec@1 52.730 Prec@5 93.710 Loss 10.58716\n",
            "val Class Accuracy: [0.836,0.808,0.651,0.926,0.731,0.140,0.460,0.369,0.241,0.111]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [34][0/110], lr: 0.01000\tTime 0.458 (0.458)\tData 0.359 (0.359)\tLoss 2.0538 (2.0538)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [34][10/110], lr: 0.01000\tTime 0.058 (0.105)\tData 0.006 (0.036)\tLoss 2.8961 (2.0764)\tPrec@1 83.594 (88.991)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [34][20/110], lr: 0.01000\tTime 0.055 (0.083)\tData 0.007 (0.022)\tLoss 2.1679 (1.9847)\tPrec@1 89.844 (89.621)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [34][30/110], lr: 0.01000\tTime 0.077 (0.075)\tData 0.007 (0.016)\tLoss 2.3680 (2.0792)\tPrec@1 87.500 (88.987)\tPrec@5 100.000 (99.345)\n",
            "Epoch: [34][40/110], lr: 0.01000\tTime 0.071 (0.071)\tData 0.014 (0.013)\tLoss 2.1704 (2.1425)\tPrec@1 91.406 (88.720)\tPrec@5 99.219 (99.123)\n",
            "Epoch: [34][50/110], lr: 0.01000\tTime 0.078 (0.068)\tData 0.002 (0.012)\tLoss 2.5789 (2.1608)\tPrec@1 85.938 (88.634)\tPrec@5 100.000 (99.173)\n",
            "Epoch: [34][60/110], lr: 0.01000\tTime 0.047 (0.066)\tData 0.000 (0.011)\tLoss 2.6467 (2.2077)\tPrec@1 85.938 (88.281)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [34][70/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.006 (0.010)\tLoss 1.8420 (2.2373)\tPrec@1 90.625 (88.039)\tPrec@5 100.000 (99.263)\n",
            "Epoch: [34][80/110], lr: 0.01000\tTime 0.073 (0.064)\tData 0.007 (0.009)\tLoss 2.5704 (2.2289)\tPrec@1 89.062 (88.137)\tPrec@5 99.219 (99.286)\n",
            "Epoch: [34][90/110], lr: 0.01000\tTime 0.035 (0.063)\tData 0.000 (0.009)\tLoss 2.3728 (2.2110)\tPrec@1 89.062 (88.290)\tPrec@5 99.219 (99.296)\n",
            "Epoch: [34][100/110], lr: 0.01000\tTime 0.057 (0.063)\tData 0.007 (0.009)\tLoss 1.8021 (2.2173)\tPrec@1 91.406 (88.243)\tPrec@5 99.219 (99.319)\n",
            "Test: [0/100]\tTime 0.278 (0.278)\tLoss 10.7029 (10.7029)\tPrec@1 49.000 (49.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.018 (0.053)\tLoss 8.2277 (9.2038)\tPrec@1 63.000 (58.636)\tPrec@5 90.000 (92.909)\n",
            "Test: [20/100]\tTime 0.038 (0.041)\tLoss 7.0117 (9.1032)\tPrec@1 69.000 (59.286)\tPrec@5 95.000 (92.857)\n",
            "Test: [30/100]\tTime 0.015 (0.035)\tLoss 8.9503 (9.1723)\tPrec@1 60.000 (59.129)\tPrec@5 92.000 (92.387)\n",
            "Test: [40/100]\tTime 0.041 (0.033)\tLoss 8.8506 (9.1356)\tPrec@1 59.000 (59.268)\tPrec@5 94.000 (92.659)\n",
            "Test: [50/100]\tTime 0.016 (0.032)\tLoss 8.9367 (8.9868)\tPrec@1 58.000 (59.941)\tPrec@5 89.000 (92.745)\n",
            "Test: [60/100]\tTime 0.033 (0.030)\tLoss 7.4789 (9.0004)\tPrec@1 67.000 (59.803)\tPrec@5 91.000 (92.607)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 8.1831 (9.0125)\tPrec@1 66.000 (59.901)\tPrec@5 94.000 (92.437)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 8.0603 (8.9392)\tPrec@1 65.000 (60.321)\tPrec@5 95.000 (92.630)\n",
            "Test: [90/100]\tTime 0.034 (0.029)\tLoss 8.2283 (9.0524)\tPrec@1 64.000 (59.758)\tPrec@5 93.000 (92.440)\n",
            "val Results: Prec@1 59.560 Prec@5 92.440 Loss 9.08507\n",
            "val Class Accuracy: [0.918,0.986,0.821,0.680,0.636,0.690,0.215,0.581,0.156,0.273]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [35][0/110], lr: 0.01000\tTime 0.475 (0.475)\tData 0.385 (0.385)\tLoss 2.0789 (2.0789)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [35][10/110], lr: 0.01000\tTime 0.041 (0.099)\tData 0.000 (0.040)\tLoss 1.6100 (2.3377)\tPrec@1 92.969 (87.926)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [35][20/110], lr: 0.01000\tTime 0.052 (0.081)\tData 0.010 (0.024)\tLoss 2.1528 (2.1685)\tPrec@1 89.062 (88.653)\tPrec@5 100.000 (99.330)\n",
            "Epoch: [35][30/110], lr: 0.01000\tTime 0.051 (0.074)\tData 0.007 (0.018)\tLoss 2.3420 (2.1631)\tPrec@1 88.281 (88.710)\tPrec@5 99.219 (99.370)\n",
            "Epoch: [35][40/110], lr: 0.01000\tTime 0.054 (0.070)\tData 0.007 (0.015)\tLoss 2.3569 (2.1881)\tPrec@1 88.281 (88.453)\tPrec@5 99.219 (99.295)\n",
            "Epoch: [35][50/110], lr: 0.01000\tTime 0.088 (0.068)\tData 0.007 (0.013)\tLoss 2.2286 (2.1876)\tPrec@1 87.500 (88.603)\tPrec@5 99.219 (99.341)\n",
            "Epoch: [35][60/110], lr: 0.01000\tTime 0.039 (0.066)\tData 0.000 (0.012)\tLoss 2.5343 (2.1946)\tPrec@1 85.156 (88.461)\tPrec@5 99.219 (99.360)\n",
            "Epoch: [35][70/110], lr: 0.01000\tTime 0.046 (0.065)\tData 0.000 (0.011)\tLoss 2.5866 (2.2122)\tPrec@1 86.719 (88.413)\tPrec@5 99.219 (99.307)\n",
            "Epoch: [35][80/110], lr: 0.01000\tTime 0.065 (0.064)\tData 0.005 (0.010)\tLoss 2.2047 (2.2246)\tPrec@1 87.500 (88.329)\tPrec@5 100.000 (99.286)\n",
            "Epoch: [35][90/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.004 (0.010)\tLoss 1.7805 (2.2061)\tPrec@1 92.188 (88.341)\tPrec@5 98.438 (99.296)\n",
            "Epoch: [35][100/110], lr: 0.01000\tTime 0.044 (0.063)\tData 0.000 (0.009)\tLoss 2.2352 (2.2052)\tPrec@1 89.062 (88.359)\tPrec@5 99.219 (99.273)\n",
            "Test: [0/100]\tTime 0.304 (0.304)\tLoss 7.6475 (7.6475)\tPrec@1 68.000 (68.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.031 (0.051)\tLoss 5.6155 (8.0029)\tPrec@1 75.000 (64.182)\tPrec@5 97.000 (95.273)\n",
            "Test: [20/100]\tTime 0.027 (0.041)\tLoss 7.5582 (7.8518)\tPrec@1 65.000 (65.286)\tPrec@5 98.000 (94.905)\n",
            "Test: [30/100]\tTime 0.043 (0.036)\tLoss 7.6437 (7.8918)\tPrec@1 66.000 (65.258)\tPrec@5 95.000 (94.613)\n",
            "Test: [40/100]\tTime 0.028 (0.032)\tLoss 7.6917 (7.8451)\tPrec@1 67.000 (65.634)\tPrec@5 97.000 (94.683)\n",
            "Test: [50/100]\tTime 0.017 (0.031)\tLoss 8.8501 (7.8179)\tPrec@1 60.000 (65.353)\tPrec@5 93.000 (94.843)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 7.2703 (7.8746)\tPrec@1 65.000 (64.869)\tPrec@5 97.000 (94.836)\n",
            "Test: [70/100]\tTime 0.039 (0.030)\tLoss 6.3550 (7.8816)\tPrec@1 69.000 (64.648)\tPrec@5 98.000 (95.042)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 7.8333 (7.8812)\tPrec@1 65.000 (64.556)\tPrec@5 94.000 (95.086)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 7.5956 (7.9245)\tPrec@1 65.000 (64.429)\tPrec@5 98.000 (95.022)\n",
            "val Results: Prec@1 64.480 Prec@5 94.980 Loss 7.91932\n",
            "val Class Accuracy: [0.915,0.911,0.820,0.817,0.554,0.366,0.640,0.598,0.599,0.228]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [36][0/110], lr: 0.01000\tTime 0.453 (0.453)\tData 0.363 (0.363)\tLoss 1.6643 (1.6643)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [36][10/110], lr: 0.01000\tTime 0.046 (0.099)\tData 0.000 (0.038)\tLoss 1.7117 (1.9628)\tPrec@1 92.188 (89.347)\tPrec@5 99.219 (99.787)\n",
            "Epoch: [36][20/110], lr: 0.01000\tTime 0.042 (0.079)\tData 0.000 (0.022)\tLoss 2.0825 (2.0307)\tPrec@1 89.844 (89.286)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [36][30/110], lr: 0.01000\tTime 0.054 (0.072)\tData 0.000 (0.017)\tLoss 2.2718 (2.0681)\tPrec@1 88.281 (89.062)\tPrec@5 98.438 (99.496)\n",
            "Epoch: [36][40/110], lr: 0.01000\tTime 0.056 (0.069)\tData 0.013 (0.014)\tLoss 1.9376 (2.0917)\tPrec@1 89.844 (88.891)\tPrec@5 99.219 (99.409)\n",
            "Epoch: [36][50/110], lr: 0.01000\tTime 0.058 (0.067)\tData 0.002 (0.012)\tLoss 2.6056 (2.1720)\tPrec@1 86.719 (88.496)\tPrec@5 100.000 (99.418)\n",
            "Epoch: [36][60/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.007 (0.011)\tLoss 2.0532 (2.1901)\tPrec@1 89.844 (88.332)\tPrec@5 99.219 (99.424)\n",
            "Epoch: [36][70/110], lr: 0.01000\tTime 0.043 (0.064)\tData 0.000 (0.010)\tLoss 1.5378 (2.1735)\tPrec@1 92.188 (88.446)\tPrec@5 100.000 (99.417)\n",
            "Epoch: [36][80/110], lr: 0.01000\tTime 0.043 (0.064)\tData 0.003 (0.010)\tLoss 1.8781 (2.1919)\tPrec@1 90.625 (88.378)\tPrec@5 100.000 (99.392)\n",
            "Epoch: [36][90/110], lr: 0.01000\tTime 0.054 (0.063)\tData 0.004 (0.009)\tLoss 2.2300 (2.1891)\tPrec@1 89.062 (88.376)\tPrec@5 97.656 (99.356)\n",
            "Epoch: [36][100/110], lr: 0.01000\tTime 0.075 (0.063)\tData 0.000 (0.009)\tLoss 2.7667 (2.1942)\tPrec@1 83.594 (88.374)\tPrec@5 99.219 (99.319)\n",
            "Test: [0/100]\tTime 0.275 (0.275)\tLoss 9.2468 (9.2468)\tPrec@1 58.000 (58.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.036 (0.054)\tLoss 6.2538 (8.2334)\tPrec@1 71.000 (63.636)\tPrec@5 96.000 (95.545)\n",
            "Test: [20/100]\tTime 0.030 (0.041)\tLoss 6.9164 (8.2711)\tPrec@1 68.000 (62.857)\tPrec@5 96.000 (95.571)\n",
            "Test: [30/100]\tTime 0.014 (0.036)\tLoss 6.9896 (8.3089)\tPrec@1 69.000 (62.710)\tPrec@5 95.000 (95.290)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 7.7416 (8.3177)\tPrec@1 66.000 (62.829)\tPrec@5 92.000 (95.098)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 7.9521 (8.2225)\tPrec@1 64.000 (63.373)\tPrec@5 97.000 (95.235)\n",
            "Test: [60/100]\tTime 0.034 (0.031)\tLoss 6.3252 (8.2139)\tPrec@1 70.000 (63.000)\tPrec@5 97.000 (95.246)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 8.3273 (8.2639)\tPrec@1 62.000 (62.775)\tPrec@5 96.000 (95.169)\n",
            "Test: [80/100]\tTime 0.016 (0.030)\tLoss 7.0689 (8.2118)\tPrec@1 66.000 (63.037)\tPrec@5 97.000 (95.185)\n",
            "Test: [90/100]\tTime 0.027 (0.029)\tLoss 8.2549 (8.3065)\tPrec@1 64.000 (62.549)\tPrec@5 98.000 (95.264)\n",
            "val Results: Prec@1 62.460 Prec@5 95.240 Loss 8.32614\n",
            "val Class Accuracy: [0.968,0.936,0.786,0.655,0.747,0.453,0.674,0.552,0.305,0.170]\n",
            "Best Prec@1: 66.440\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [37][0/110], lr: 0.01000\tTime 0.509 (0.509)\tData 0.444 (0.444)\tLoss 2.2764 (2.2764)\tPrec@1 86.719 (86.719)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [37][10/110], lr: 0.01000\tTime 0.057 (0.101)\tData 0.000 (0.048)\tLoss 0.9907 (1.9944)\tPrec@1 96.094 (89.347)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [37][20/110], lr: 0.01000\tTime 0.057 (0.081)\tData 0.007 (0.028)\tLoss 2.1414 (1.9899)\tPrec@1 89.062 (89.397)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [37][30/110], lr: 0.01000\tTime 0.042 (0.074)\tData 0.000 (0.021)\tLoss 1.5151 (1.9846)\tPrec@1 92.188 (89.415)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [37][40/110], lr: 0.01000\tTime 0.062 (0.071)\tData 0.007 (0.017)\tLoss 1.6471 (2.0000)\tPrec@1 91.406 (89.253)\tPrec@5 100.000 (99.486)\n",
            "Epoch: [37][50/110], lr: 0.01000\tTime 0.068 (0.068)\tData 0.007 (0.015)\tLoss 1.5688 (2.0231)\tPrec@1 92.969 (89.093)\tPrec@5 100.000 (99.464)\n",
            "Epoch: [37][60/110], lr: 0.01000\tTime 0.089 (0.071)\tData 0.010 (0.013)\tLoss 2.4568 (2.0760)\tPrec@1 85.938 (88.832)\tPrec@5 99.219 (99.398)\n",
            "Epoch: [37][70/110], lr: 0.01000\tTime 0.113 (0.074)\tData 0.000 (0.012)\tLoss 2.7000 (2.1171)\tPrec@1 85.156 (88.545)\tPrec@5 99.219 (99.373)\n",
            "Epoch: [37][80/110], lr: 0.01000\tTime 0.089 (0.076)\tData 0.007 (0.012)\tLoss 2.3356 (2.1372)\tPrec@1 88.281 (88.503)\tPrec@5 99.219 (99.354)\n",
            "Epoch: [37][90/110], lr: 0.01000\tTime 0.090 (0.078)\tData 0.007 (0.011)\tLoss 2.1599 (2.1495)\tPrec@1 91.406 (88.453)\tPrec@5 100.000 (99.348)\n",
            "Epoch: [37][100/110], lr: 0.01000\tTime 0.050 (0.078)\tData 0.000 (0.011)\tLoss 1.7427 (2.1613)\tPrec@1 90.625 (88.413)\tPrec@5 100.000 (99.343)\n",
            "Test: [0/100]\tTime 0.322 (0.322)\tLoss 6.5731 (6.5731)\tPrec@1 70.000 (70.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.031 (0.055)\tLoss 5.1587 (6.8974)\tPrec@1 76.000 (69.000)\tPrec@5 95.000 (96.909)\n",
            "Test: [20/100]\tTime 0.024 (0.041)\tLoss 6.2379 (6.8398)\tPrec@1 70.000 (69.286)\tPrec@5 98.000 (96.667)\n",
            "Test: [30/100]\tTime 0.043 (0.036)\tLoss 6.6607 (6.8657)\tPrec@1 68.000 (69.065)\tPrec@5 97.000 (96.742)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 7.2742 (6.8102)\tPrec@1 66.000 (69.366)\tPrec@5 96.000 (96.610)\n",
            "Test: [50/100]\tTime 0.039 (0.031)\tLoss 6.3695 (6.7149)\tPrec@1 72.000 (69.706)\tPrec@5 96.000 (96.902)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 6.4691 (6.7969)\tPrec@1 73.000 (69.311)\tPrec@5 95.000 (97.000)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 6.4077 (6.8035)\tPrec@1 70.000 (69.211)\tPrec@5 99.000 (96.958)\n",
            "Test: [80/100]\tTime 0.039 (0.030)\tLoss 6.0159 (6.7371)\tPrec@1 76.000 (69.481)\tPrec@5 96.000 (97.062)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 6.7735 (6.8161)\tPrec@1 70.000 (68.989)\tPrec@5 97.000 (97.033)\n",
            "val Results: Prec@1 69.060 Prec@5 97.070 Loss 6.82347\n",
            "val Class Accuracy: [0.903,0.960,0.774,0.783,0.759,0.559,0.514,0.560,0.446,0.648]\n",
            "Best Prec@1: 69.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [38][0/110], lr: 0.01000\tTime 0.348 (0.348)\tData 0.280 (0.280)\tLoss 1.9417 (1.9417)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [38][10/110], lr: 0.01000\tTime 0.050 (0.103)\tData 0.000 (0.037)\tLoss 1.7035 (2.0186)\tPrec@1 90.625 (89.418)\tPrec@5 98.438 (99.432)\n",
            "Epoch: [38][20/110], lr: 0.01000\tTime 0.052 (0.082)\tData 0.000 (0.023)\tLoss 1.7921 (1.9630)\tPrec@1 91.406 (89.881)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [38][30/110], lr: 0.01000\tTime 0.048 (0.074)\tData 0.002 (0.017)\tLoss 2.7037 (1.9718)\tPrec@1 85.938 (89.793)\tPrec@5 96.875 (99.446)\n",
            "Epoch: [38][40/110], lr: 0.01000\tTime 0.042 (0.071)\tData 0.000 (0.014)\tLoss 1.4731 (2.0165)\tPrec@1 93.750 (89.158)\tPrec@5 99.219 (99.390)\n",
            "Epoch: [38][50/110], lr: 0.01000\tTime 0.063 (0.070)\tData 0.012 (0.013)\tLoss 1.5772 (2.0468)\tPrec@1 92.969 (88.971)\tPrec@5 100.000 (99.357)\n",
            "Epoch: [38][60/110], lr: 0.01000\tTime 0.065 (0.068)\tData 0.001 (0.012)\tLoss 2.0715 (2.0968)\tPrec@1 88.281 (88.665)\tPrec@5 99.219 (99.244)\n",
            "Epoch: [38][70/110], lr: 0.01000\tTime 0.060 (0.067)\tData 0.006 (0.011)\tLoss 1.7587 (2.0851)\tPrec@1 93.750 (88.787)\tPrec@5 100.000 (99.274)\n",
            "Epoch: [38][80/110], lr: 0.01000\tTime 0.058 (0.066)\tData 0.006 (0.010)\tLoss 2.3551 (2.1026)\tPrec@1 85.938 (88.715)\tPrec@5 98.438 (99.248)\n",
            "Epoch: [38][90/110], lr: 0.01000\tTime 0.039 (0.065)\tData 0.000 (0.010)\tLoss 2.2589 (2.1019)\tPrec@1 88.281 (88.719)\tPrec@5 100.000 (99.287)\n",
            "Epoch: [38][100/110], lr: 0.01000\tTime 0.058 (0.064)\tData 0.005 (0.009)\tLoss 2.5156 (2.1173)\tPrec@1 88.281 (88.653)\tPrec@5 97.656 (99.296)\n",
            "Test: [0/100]\tTime 0.289 (0.289)\tLoss 8.5728 (8.5728)\tPrec@1 59.000 (59.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.020 (0.053)\tLoss 6.1101 (8.3689)\tPrec@1 71.000 (61.636)\tPrec@5 96.000 (95.091)\n",
            "Test: [20/100]\tTime 0.026 (0.043)\tLoss 7.6314 (8.5658)\tPrec@1 61.000 (60.238)\tPrec@5 97.000 (94.286)\n",
            "Test: [30/100]\tTime 0.020 (0.036)\tLoss 8.9489 (8.7040)\tPrec@1 58.000 (59.484)\tPrec@5 92.000 (94.129)\n",
            "Test: [40/100]\tTime 0.013 (0.034)\tLoss 8.5737 (8.7298)\tPrec@1 59.000 (59.439)\tPrec@5 92.000 (93.756)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 8.8500 (8.6234)\tPrec@1 60.000 (59.843)\tPrec@5 91.000 (93.725)\n",
            "Test: [60/100]\tTime 0.034 (0.032)\tLoss 8.4710 (8.6595)\tPrec@1 61.000 (59.623)\tPrec@5 96.000 (93.639)\n",
            "Test: [70/100]\tTime 0.030 (0.032)\tLoss 8.4623 (8.6844)\tPrec@1 64.000 (59.606)\tPrec@5 95.000 (93.676)\n",
            "Test: [80/100]\tTime 0.023 (0.030)\tLoss 8.1729 (8.6642)\tPrec@1 61.000 (59.716)\tPrec@5 91.000 (93.556)\n",
            "Test: [90/100]\tTime 0.024 (0.030)\tLoss 8.5793 (8.7348)\tPrec@1 58.000 (59.242)\tPrec@5 92.000 (93.615)\n",
            "val Results: Prec@1 59.390 Prec@5 93.670 Loss 8.73869\n",
            "val Class Accuracy: [0.988,0.937,0.603,0.569,0.478,0.312,0.835,0.350,0.280,0.587]\n",
            "Best Prec@1: 69.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [39][0/110], lr: 0.01000\tTime 0.420 (0.420)\tData 0.348 (0.348)\tLoss 2.1351 (2.1351)\tPrec@1 87.500 (87.500)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [39][10/110], lr: 0.01000\tTime 0.036 (0.103)\tData 0.000 (0.038)\tLoss 1.5612 (2.1430)\tPrec@1 90.625 (88.281)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [39][20/110], lr: 0.01000\tTime 0.069 (0.083)\tData 0.007 (0.022)\tLoss 2.3698 (2.0843)\tPrec@1 88.281 (88.876)\tPrec@5 98.438 (99.368)\n",
            "Epoch: [39][30/110], lr: 0.01000\tTime 0.073 (0.074)\tData 0.006 (0.018)\tLoss 2.9333 (2.0622)\tPrec@1 83.594 (89.189)\tPrec@5 98.438 (99.395)\n",
            "Epoch: [39][40/110], lr: 0.01000\tTime 0.063 (0.070)\tData 0.006 (0.014)\tLoss 2.4330 (2.1371)\tPrec@1 87.500 (88.872)\tPrec@5 98.438 (99.409)\n",
            "Epoch: [39][50/110], lr: 0.01000\tTime 0.038 (0.067)\tData 0.000 (0.013)\tLoss 2.2629 (2.1781)\tPrec@1 89.062 (88.756)\tPrec@5 100.000 (99.372)\n",
            "Epoch: [39][60/110], lr: 0.01000\tTime 0.060 (0.066)\tData 0.007 (0.011)\tLoss 2.6765 (2.1208)\tPrec@1 84.375 (88.973)\tPrec@5 98.438 (99.321)\n",
            "Epoch: [39][70/110], lr: 0.01000\tTime 0.062 (0.065)\tData 0.000 (0.010)\tLoss 1.9877 (2.1302)\tPrec@1 89.062 (88.919)\tPrec@5 98.438 (99.329)\n",
            "Epoch: [39][80/110], lr: 0.01000\tTime 0.068 (0.064)\tData 0.007 (0.009)\tLoss 1.7300 (2.1278)\tPrec@1 91.406 (88.908)\tPrec@5 100.000 (99.373)\n",
            "Epoch: [39][90/110], lr: 0.01000\tTime 0.042 (0.063)\tData 0.000 (0.009)\tLoss 1.7618 (2.1348)\tPrec@1 89.062 (88.839)\tPrec@5 100.000 (99.365)\n",
            "Epoch: [39][100/110], lr: 0.01000\tTime 0.073 (0.063)\tData 0.000 (0.008)\tLoss 1.4828 (2.1115)\tPrec@1 92.188 (88.931)\tPrec@5 100.000 (99.404)\n",
            "Test: [0/100]\tTime 0.298 (0.298)\tLoss 6.3997 (6.3997)\tPrec@1 73.000 (73.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.035 (0.052)\tLoss 5.2166 (7.1621)\tPrec@1 77.000 (67.818)\tPrec@5 99.000 (98.000)\n",
            "Test: [20/100]\tTime 0.024 (0.039)\tLoss 5.3673 (7.0179)\tPrec@1 74.000 (67.857)\tPrec@5 99.000 (97.333)\n",
            "Test: [30/100]\tTime 0.034 (0.036)\tLoss 7.0852 (7.0724)\tPrec@1 66.000 (67.710)\tPrec@5 98.000 (97.226)\n",
            "Test: [40/100]\tTime 0.017 (0.032)\tLoss 7.7357 (7.1366)\tPrec@1 65.000 (67.634)\tPrec@5 96.000 (97.098)\n",
            "Test: [50/100]\tTime 0.021 (0.031)\tLoss 6.8494 (7.0261)\tPrec@1 71.000 (68.216)\tPrec@5 94.000 (97.176)\n",
            "Test: [60/100]\tTime 0.050 (0.031)\tLoss 6.4036 (7.0909)\tPrec@1 72.000 (68.016)\tPrec@5 98.000 (97.164)\n",
            "Test: [70/100]\tTime 0.033 (0.030)\tLoss 7.2059 (7.0872)\tPrec@1 67.000 (68.127)\tPrec@5 97.000 (97.282)\n",
            "Test: [80/100]\tTime 0.020 (0.030)\tLoss 6.9562 (7.0589)\tPrec@1 67.000 (68.160)\tPrec@5 98.000 (97.346)\n",
            "Test: [90/100]\tTime 0.036 (0.029)\tLoss 6.7671 (7.0925)\tPrec@1 66.000 (67.890)\tPrec@5 100.000 (97.385)\n",
            "val Results: Prec@1 67.880 Prec@5 97.400 Loss 7.10725\n",
            "val Class Accuracy: [0.934,0.985,0.651,0.720,0.622,0.635,0.730,0.499,0.677,0.335]\n",
            "Best Prec@1: 69.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [40][0/110], lr: 0.01000\tTime 0.368 (0.368)\tData 0.296 (0.296)\tLoss 2.2384 (2.2384)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [40][10/110], lr: 0.01000\tTime 0.066 (0.099)\tData 0.002 (0.037)\tLoss 2.0377 (2.0758)\tPrec@1 89.844 (89.347)\tPrec@5 100.000 (99.290)\n",
            "Epoch: [40][20/110], lr: 0.01000\tTime 0.072 (0.080)\tData 0.000 (0.021)\tLoss 2.3147 (2.0017)\tPrec@1 88.281 (89.844)\tPrec@5 100.000 (99.293)\n",
            "Epoch: [40][30/110], lr: 0.01000\tTime 0.067 (0.074)\tData 0.000 (0.015)\tLoss 1.8838 (1.8842)\tPrec@1 90.625 (90.323)\tPrec@5 97.656 (99.168)\n",
            "Epoch: [40][40/110], lr: 0.01000\tTime 0.068 (0.070)\tData 0.019 (0.013)\tLoss 1.6356 (1.9010)\tPrec@1 91.406 (90.034)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [40][50/110], lr: 0.01000\tTime 0.041 (0.068)\tData 0.000 (0.011)\tLoss 1.4465 (1.9410)\tPrec@1 92.188 (89.844)\tPrec@5 100.000 (99.265)\n",
            "Epoch: [40][60/110], lr: 0.01000\tTime 0.065 (0.067)\tData 0.002 (0.010)\tLoss 2.1317 (1.9525)\tPrec@1 85.938 (89.690)\tPrec@5 99.219 (99.308)\n",
            "Epoch: [40][70/110], lr: 0.01000\tTime 0.057 (0.065)\tData 0.007 (0.009)\tLoss 1.5321 (1.9776)\tPrec@1 92.969 (89.558)\tPrec@5 100.000 (99.351)\n",
            "Epoch: [40][80/110], lr: 0.01000\tTime 0.060 (0.064)\tData 0.007 (0.009)\tLoss 1.4170 (1.9802)\tPrec@1 92.969 (89.574)\tPrec@5 100.000 (99.354)\n",
            "Epoch: [40][90/110], lr: 0.01000\tTime 0.058 (0.064)\tData 0.007 (0.009)\tLoss 1.5203 (2.0040)\tPrec@1 92.969 (89.414)\tPrec@5 99.219 (99.313)\n",
            "Epoch: [40][100/110], lr: 0.01000\tTime 0.065 (0.063)\tData 0.000 (0.008)\tLoss 1.5340 (2.0260)\tPrec@1 92.969 (89.349)\tPrec@5 100.000 (99.327)\n",
            "Test: [0/100]\tTime 0.294 (0.294)\tLoss 8.3833 (8.3833)\tPrec@1 59.000 (59.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.044 (0.055)\tLoss 6.6439 (7.6540)\tPrec@1 71.000 (65.000)\tPrec@5 91.000 (95.818)\n",
            "Test: [20/100]\tTime 0.026 (0.039)\tLoss 6.5642 (7.6085)\tPrec@1 71.000 (65.095)\tPrec@5 99.000 (96.238)\n",
            "Test: [30/100]\tTime 0.036 (0.035)\tLoss 7.5151 (7.6825)\tPrec@1 66.000 (65.290)\tPrec@5 95.000 (96.032)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 7.3149 (7.6234)\tPrec@1 70.000 (65.732)\tPrec@5 96.000 (96.024)\n",
            "Test: [50/100]\tTime 0.036 (0.031)\tLoss 6.3736 (7.5245)\tPrec@1 73.000 (65.941)\tPrec@5 94.000 (96.137)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 6.6440 (7.5380)\tPrec@1 69.000 (65.852)\tPrec@5 96.000 (96.066)\n",
            "Test: [70/100]\tTime 0.012 (0.029)\tLoss 7.8372 (7.5845)\tPrec@1 66.000 (65.535)\tPrec@5 96.000 (96.113)\n",
            "Test: [80/100]\tTime 0.031 (0.028)\tLoss 7.1671 (7.5295)\tPrec@1 68.000 (65.778)\tPrec@5 95.000 (96.198)\n",
            "Test: [90/100]\tTime 0.033 (0.028)\tLoss 6.9196 (7.5944)\tPrec@1 70.000 (65.440)\tPrec@5 100.000 (96.275)\n",
            "val Results: Prec@1 65.500 Prec@5 96.350 Loss 7.59911\n",
            "val Class Accuracy: [0.976,0.949,0.793,0.555,0.761,0.643,0.534,0.382,0.479,0.478]\n",
            "Best Prec@1: 69.060\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [41][0/110], lr: 0.01000\tTime 0.375 (0.375)\tData 0.280 (0.280)\tLoss 1.2858 (1.2858)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [41][10/110], lr: 0.01000\tTime 0.079 (0.102)\tData 0.000 (0.033)\tLoss 1.9706 (1.8204)\tPrec@1 89.062 (91.122)\tPrec@5 99.219 (99.077)\n",
            "Epoch: [41][20/110], lr: 0.01000\tTime 0.055 (0.080)\tData 0.008 (0.019)\tLoss 2.8939 (1.9315)\tPrec@1 87.500 (90.030)\tPrec@5 98.438 (99.293)\n",
            "Epoch: [41][30/110], lr: 0.01000\tTime 0.041 (0.073)\tData 0.000 (0.015)\tLoss 2.4609 (1.9194)\tPrec@1 87.500 (90.096)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [41][40/110], lr: 0.01000\tTime 0.073 (0.070)\tData 0.001 (0.013)\tLoss 2.6370 (1.9130)\tPrec@1 85.156 (90.053)\tPrec@5 98.438 (99.390)\n",
            "Epoch: [41][50/110], lr: 0.01000\tTime 0.069 (0.067)\tData 0.001 (0.011)\tLoss 1.9862 (1.9637)\tPrec@1 87.500 (89.675)\tPrec@5 100.000 (99.372)\n",
            "Epoch: [41][60/110], lr: 0.01000\tTime 0.055 (0.066)\tData 0.002 (0.010)\tLoss 1.8311 (1.9611)\tPrec@1 89.844 (89.626)\tPrec@5 99.219 (99.424)\n",
            "Epoch: [41][70/110], lr: 0.01000\tTime 0.059 (0.065)\tData 0.000 (0.009)\tLoss 1.3720 (1.9711)\tPrec@1 92.188 (89.525)\tPrec@5 100.000 (99.428)\n",
            "Epoch: [41][80/110], lr: 0.01000\tTime 0.051 (0.064)\tData 0.000 (0.009)\tLoss 2.2922 (2.0140)\tPrec@1 85.938 (89.236)\tPrec@5 98.438 (99.363)\n",
            "Epoch: [41][90/110], lr: 0.01000\tTime 0.059 (0.063)\tData 0.004 (0.008)\tLoss 1.4076 (1.9996)\tPrec@1 92.969 (89.329)\tPrec@5 100.000 (99.365)\n",
            "Epoch: [41][100/110], lr: 0.01000\tTime 0.071 (0.063)\tData 0.000 (0.008)\tLoss 2.2065 (2.0140)\tPrec@1 88.281 (89.179)\tPrec@5 98.438 (99.366)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 6.7043 (6.7043)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.008 (0.052)\tLoss 5.9137 (6.8346)\tPrec@1 71.000 (69.545)\tPrec@5 92.000 (96.727)\n",
            "Test: [20/100]\tTime 0.022 (0.038)\tLoss 6.0596 (6.6964)\tPrec@1 72.000 (70.095)\tPrec@5 98.000 (96.619)\n",
            "Test: [30/100]\tTime 0.020 (0.035)\tLoss 6.6002 (6.7121)\tPrec@1 66.000 (70.194)\tPrec@5 97.000 (96.484)\n",
            "Test: [40/100]\tTime 0.039 (0.032)\tLoss 6.9551 (6.7231)\tPrec@1 68.000 (70.244)\tPrec@5 96.000 (96.561)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 6.7306 (6.6436)\tPrec@1 71.000 (70.529)\tPrec@5 98.000 (96.706)\n",
            "Test: [60/100]\tTime 0.037 (0.030)\tLoss 6.2876 (6.6924)\tPrec@1 70.000 (70.197)\tPrec@5 98.000 (96.721)\n",
            "Test: [70/100]\tTime 0.030 (0.030)\tLoss 6.0231 (6.6965)\tPrec@1 74.000 (70.183)\tPrec@5 98.000 (96.746)\n",
            "Test: [80/100]\tTime 0.026 (0.031)\tLoss 6.2042 (6.6501)\tPrec@1 71.000 (70.358)\tPrec@5 96.000 (96.815)\n",
            "Test: [90/100]\tTime 0.039 (0.032)\tLoss 6.2965 (6.7214)\tPrec@1 73.000 (70.055)\tPrec@5 96.000 (96.725)\n",
            "val Results: Prec@1 69.900 Prec@5 96.790 Loss 6.75297\n",
            "val Class Accuracy: [0.928,0.962,0.773,0.615,0.730,0.755,0.555,0.611,0.505,0.556]\n",
            "Best Prec@1: 69.900\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [42][0/110], lr: 0.01000\tTime 0.572 (0.572)\tData 0.430 (0.430)\tLoss 1.5407 (1.5407)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [42][10/110], lr: 0.01000\tTime 0.059 (0.150)\tData 0.007 (0.045)\tLoss 1.7739 (1.9608)\tPrec@1 92.188 (89.844)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [42][20/110], lr: 0.01000\tTime 0.083 (0.121)\tData 0.010 (0.027)\tLoss 2.2877 (2.0641)\tPrec@1 89.844 (89.211)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [42][30/110], lr: 0.01000\tTime 0.047 (0.105)\tData 0.000 (0.020)\tLoss 1.8368 (2.0562)\tPrec@1 89.844 (89.264)\tPrec@5 100.000 (99.446)\n",
            "Epoch: [42][40/110], lr: 0.01000\tTime 0.067 (0.094)\tData 0.008 (0.016)\tLoss 1.1376 (2.0517)\tPrec@1 94.531 (89.120)\tPrec@5 99.219 (99.447)\n",
            "Epoch: [42][50/110], lr: 0.01000\tTime 0.066 (0.088)\tData 0.000 (0.014)\tLoss 2.6385 (2.0767)\tPrec@1 85.156 (88.955)\tPrec@5 99.219 (99.494)\n",
            "Epoch: [42][60/110], lr: 0.01000\tTime 0.072 (0.083)\tData 0.007 (0.012)\tLoss 2.4157 (2.1027)\tPrec@1 86.719 (88.806)\tPrec@5 97.656 (99.488)\n",
            "Epoch: [42][70/110], lr: 0.01000\tTime 0.056 (0.079)\tData 0.000 (0.011)\tLoss 2.1929 (2.1058)\tPrec@1 89.062 (88.710)\tPrec@5 99.219 (99.461)\n",
            "Epoch: [42][80/110], lr: 0.01000\tTime 0.047 (0.077)\tData 0.000 (0.010)\tLoss 1.3413 (2.1325)\tPrec@1 92.188 (88.561)\tPrec@5 100.000 (99.421)\n",
            "Epoch: [42][90/110], lr: 0.01000\tTime 0.089 (0.075)\tData 0.006 (0.010)\tLoss 2.0434 (2.1084)\tPrec@1 89.844 (88.745)\tPrec@5 100.000 (99.399)\n",
            "Epoch: [42][100/110], lr: 0.01000\tTime 0.066 (0.073)\tData 0.002 (0.009)\tLoss 1.5234 (2.0822)\tPrec@1 93.750 (88.900)\tPrec@5 100.000 (99.397)\n",
            "Test: [0/100]\tTime 0.332 (0.332)\tLoss 8.2391 (8.2391)\tPrec@1 64.000 (64.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 6.8958 (8.6266)\tPrec@1 67.000 (61.455)\tPrec@5 98.000 (96.455)\n",
            "Test: [20/100]\tTime 0.028 (0.041)\tLoss 7.7736 (8.5024)\tPrec@1 63.000 (61.905)\tPrec@5 99.000 (96.238)\n",
            "Test: [30/100]\tTime 0.013 (0.036)\tLoss 8.6809 (8.6331)\tPrec@1 61.000 (61.484)\tPrec@5 98.000 (95.935)\n",
            "Test: [40/100]\tTime 0.034 (0.034)\tLoss 8.2812 (8.6627)\tPrec@1 63.000 (61.439)\tPrec@5 95.000 (95.634)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 9.2083 (8.6134)\tPrec@1 60.000 (61.608)\tPrec@5 96.000 (95.706)\n",
            "Test: [60/100]\tTime 0.029 (0.032)\tLoss 7.3489 (8.6781)\tPrec@1 65.000 (61.279)\tPrec@5 98.000 (95.721)\n",
            "Test: [70/100]\tTime 0.039 (0.031)\tLoss 7.2090 (8.6558)\tPrec@1 69.000 (61.268)\tPrec@5 98.000 (95.718)\n",
            "Test: [80/100]\tTime 0.011 (0.030)\tLoss 9.4968 (8.6311)\tPrec@1 58.000 (61.370)\tPrec@5 93.000 (95.728)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 8.3157 (8.6667)\tPrec@1 63.000 (61.297)\tPrec@5 99.000 (95.758)\n",
            "val Results: Prec@1 61.630 Prec@5 95.810 Loss 8.62471\n",
            "val Class Accuracy: [0.885,0.958,0.788,0.891,0.438,0.269,0.490,0.518,0.649,0.277]\n",
            "Best Prec@1: 69.900\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [43][0/110], lr: 0.01000\tTime 0.339 (0.339)\tData 0.260 (0.260)\tLoss 1.5964 (1.5964)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [43][10/110], lr: 0.01000\tTime 0.058 (0.099)\tData 0.007 (0.037)\tLoss 1.7467 (1.8566)\tPrec@1 90.625 (90.128)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [43][20/110], lr: 0.01000\tTime 0.041 (0.078)\tData 0.000 (0.021)\tLoss 1.4279 (1.9297)\tPrec@1 92.969 (89.695)\tPrec@5 99.219 (99.144)\n",
            "Epoch: [43][30/110], lr: 0.01000\tTime 0.065 (0.072)\tData 0.000 (0.016)\tLoss 2.0428 (1.8898)\tPrec@1 89.844 (89.894)\tPrec@5 100.000 (99.320)\n",
            "Epoch: [43][40/110], lr: 0.01000\tTime 0.063 (0.069)\tData 0.005 (0.012)\tLoss 2.2434 (1.8670)\tPrec@1 89.062 (90.053)\tPrec@5 99.219 (99.314)\n",
            "Epoch: [43][50/110], lr: 0.01000\tTime 0.054 (0.066)\tData 0.000 (0.011)\tLoss 2.9305 (1.9712)\tPrec@1 86.719 (89.445)\tPrec@5 99.219 (99.295)\n",
            "Epoch: [43][60/110], lr: 0.01000\tTime 0.051 (0.065)\tData 0.000 (0.009)\tLoss 3.2629 (2.0156)\tPrec@1 82.812 (89.280)\tPrec@5 99.219 (99.334)\n",
            "Epoch: [43][70/110], lr: 0.01000\tTime 0.039 (0.064)\tData 0.000 (0.009)\tLoss 2.0555 (2.0294)\tPrec@1 89.062 (89.195)\tPrec@5 100.000 (99.351)\n",
            "Epoch: [43][80/110], lr: 0.01000\tTime 0.058 (0.063)\tData 0.006 (0.008)\tLoss 1.8987 (2.0345)\tPrec@1 89.844 (89.140)\tPrec@5 98.438 (99.267)\n",
            "Epoch: [43][90/110], lr: 0.01000\tTime 0.063 (0.063)\tData 0.002 (0.008)\tLoss 1.2436 (2.0203)\tPrec@1 92.969 (89.208)\tPrec@5 99.219 (99.270)\n",
            "Epoch: [43][100/110], lr: 0.01000\tTime 0.047 (0.062)\tData 0.001 (0.007)\tLoss 2.0660 (2.0162)\tPrec@1 88.281 (89.248)\tPrec@5 99.219 (99.296)\n",
            "Test: [0/100]\tTime 0.305 (0.305)\tLoss 7.1584 (7.1584)\tPrec@1 70.000 (70.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.031 (0.051)\tLoss 7.1280 (7.8203)\tPrec@1 66.000 (64.909)\tPrec@5 95.000 (96.273)\n",
            "Test: [20/100]\tTime 0.024 (0.039)\tLoss 7.1373 (7.5713)\tPrec@1 69.000 (66.190)\tPrec@5 97.000 (96.476)\n",
            "Test: [30/100]\tTime 0.031 (0.035)\tLoss 7.0578 (7.6313)\tPrec@1 67.000 (65.806)\tPrec@5 96.000 (96.645)\n",
            "Test: [40/100]\tTime 0.040 (0.033)\tLoss 6.5252 (7.5843)\tPrec@1 69.000 (66.122)\tPrec@5 97.000 (96.439)\n",
            "Test: [50/100]\tTime 0.010 (0.031)\tLoss 7.7931 (7.5819)\tPrec@1 65.000 (66.020)\tPrec@5 94.000 (96.549)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 7.2511 (7.5597)\tPrec@1 68.000 (66.098)\tPrec@5 95.000 (96.410)\n",
            "Test: [70/100]\tTime 0.053 (0.029)\tLoss 7.8040 (7.5668)\tPrec@1 62.000 (66.042)\tPrec@5 98.000 (96.338)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 6.8524 (7.5151)\tPrec@1 68.000 (66.383)\tPrec@5 97.000 (96.383)\n",
            "Test: [90/100]\tTime 0.033 (0.029)\tLoss 7.9669 (7.5810)\tPrec@1 64.000 (66.055)\tPrec@5 98.000 (96.396)\n",
            "val Results: Prec@1 66.050 Prec@5 96.430 Loss 7.59586\n",
            "val Class Accuracy: [0.814,0.987,0.703,0.352,0.937,0.721,0.602,0.392,0.661,0.436]\n",
            "Best Prec@1: 69.900\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [44][0/110], lr: 0.01000\tTime 0.475 (0.475)\tData 0.387 (0.387)\tLoss 2.8322 (2.8322)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [44][10/110], lr: 0.01000\tTime 0.068 (0.100)\tData 0.006 (0.041)\tLoss 1.6757 (1.9666)\tPrec@1 91.406 (89.276)\tPrec@5 99.219 (99.290)\n",
            "Epoch: [44][20/110], lr: 0.01000\tTime 0.062 (0.080)\tData 0.008 (0.023)\tLoss 2.3562 (1.9412)\tPrec@1 85.156 (89.397)\tPrec@5 100.000 (99.368)\n",
            "Epoch: [44][30/110], lr: 0.01000\tTime 0.034 (0.072)\tData 0.000 (0.018)\tLoss 1.9469 (1.9098)\tPrec@1 89.062 (89.541)\tPrec@5 99.219 (99.446)\n",
            "Epoch: [44][40/110], lr: 0.01000\tTime 0.045 (0.069)\tData 0.005 (0.015)\tLoss 2.3439 (1.9177)\tPrec@1 86.719 (89.520)\tPrec@5 100.000 (99.447)\n",
            "Epoch: [44][50/110], lr: 0.01000\tTime 0.050 (0.067)\tData 0.012 (0.013)\tLoss 1.8341 (1.9343)\tPrec@1 91.406 (89.430)\tPrec@5 100.000 (99.494)\n",
            "Epoch: [44][60/110], lr: 0.01000\tTime 0.069 (0.066)\tData 0.000 (0.012)\tLoss 2.3227 (1.9354)\tPrec@1 89.844 (89.536)\tPrec@5 99.219 (99.501)\n",
            "Epoch: [44][70/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.000 (0.011)\tLoss 2.0524 (1.9527)\tPrec@1 89.062 (89.547)\tPrec@5 99.219 (99.406)\n",
            "Epoch: [44][80/110], lr: 0.01000\tTime 0.054 (0.064)\tData 0.000 (0.010)\tLoss 1.7103 (1.9456)\tPrec@1 92.188 (89.612)\tPrec@5 99.219 (99.431)\n",
            "Epoch: [44][90/110], lr: 0.01000\tTime 0.064 (0.063)\tData 0.002 (0.009)\tLoss 2.5968 (1.9613)\tPrec@1 85.938 (89.526)\tPrec@5 98.438 (99.425)\n",
            "Epoch: [44][100/110], lr: 0.01000\tTime 0.062 (0.062)\tData 0.004 (0.009)\tLoss 1.9459 (1.9490)\tPrec@1 89.062 (89.627)\tPrec@5 99.219 (99.435)\n",
            "Test: [0/100]\tTime 0.296 (0.296)\tLoss 8.6959 (8.6959)\tPrec@1 58.000 (58.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.045 (0.056)\tLoss 7.2031 (8.6451)\tPrec@1 68.000 (60.909)\tPrec@5 98.000 (94.818)\n",
            "Test: [20/100]\tTime 0.024 (0.039)\tLoss 6.6482 (8.5491)\tPrec@1 68.000 (61.476)\tPrec@5 98.000 (94.619)\n",
            "Test: [30/100]\tTime 0.024 (0.034)\tLoss 8.2883 (8.6382)\tPrec@1 61.000 (61.226)\tPrec@5 96.000 (94.387)\n",
            "Test: [40/100]\tTime 0.023 (0.032)\tLoss 7.3810 (8.6578)\tPrec@1 70.000 (61.610)\tPrec@5 97.000 (94.146)\n",
            "Test: [50/100]\tTime 0.024 (0.031)\tLoss 9.7531 (8.6014)\tPrec@1 56.000 (61.980)\tPrec@5 93.000 (94.176)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 6.3775 (8.5950)\tPrec@1 74.000 (61.869)\tPrec@5 97.000 (94.361)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 7.9271 (8.6180)\tPrec@1 65.000 (61.563)\tPrec@5 97.000 (94.254)\n",
            "Test: [80/100]\tTime 0.017 (0.029)\tLoss 8.3530 (8.5649)\tPrec@1 65.000 (61.840)\tPrec@5 93.000 (94.370)\n",
            "Test: [90/100]\tTime 0.012 (0.028)\tLoss 7.2817 (8.6072)\tPrec@1 69.000 (61.637)\tPrec@5 96.000 (94.319)\n",
            "val Results: Prec@1 61.830 Prec@5 94.290 Loss 8.59829\n",
            "val Class Accuracy: [0.934,0.955,0.823,0.778,0.531,0.430,0.474,0.743,0.459,0.056]\n",
            "Best Prec@1: 69.900\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [45][0/110], lr: 0.01000\tTime 0.339 (0.339)\tData 0.270 (0.270)\tLoss 1.6550 (1.6550)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [45][10/110], lr: 0.01000\tTime 0.045 (0.106)\tData 0.000 (0.035)\tLoss 1.4439 (1.7824)\tPrec@1 92.188 (90.412)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [45][20/110], lr: 0.01000\tTime 0.068 (0.084)\tData 0.014 (0.021)\tLoss 2.1838 (1.9314)\tPrec@1 89.844 (89.881)\tPrec@5 99.219 (99.330)\n",
            "Epoch: [45][30/110], lr: 0.01000\tTime 0.061 (0.075)\tData 0.013 (0.017)\tLoss 1.9684 (1.8867)\tPrec@1 88.281 (89.995)\tPrec@5 99.219 (99.370)\n",
            "Epoch: [45][40/110], lr: 0.01000\tTime 0.079 (0.071)\tData 0.007 (0.013)\tLoss 2.8708 (1.9514)\tPrec@1 83.594 (89.577)\tPrec@5 99.219 (99.371)\n",
            "Epoch: [45][50/110], lr: 0.01000\tTime 0.043 (0.068)\tData 0.003 (0.011)\tLoss 1.5712 (1.9308)\tPrec@1 91.406 (89.721)\tPrec@5 99.219 (99.464)\n",
            "Epoch: [45][60/110], lr: 0.01000\tTime 0.056 (0.067)\tData 0.004 (0.011)\tLoss 1.4560 (1.9535)\tPrec@1 94.531 (89.716)\tPrec@5 100.000 (99.488)\n",
            "Epoch: [45][70/110], lr: 0.01000\tTime 0.060 (0.065)\tData 0.007 (0.010)\tLoss 2.8838 (1.9762)\tPrec@1 83.594 (89.591)\tPrec@5 99.219 (99.450)\n",
            "Epoch: [45][80/110], lr: 0.01000\tTime 0.058 (0.065)\tData 0.010 (0.010)\tLoss 1.7568 (1.9712)\tPrec@1 90.625 (89.651)\tPrec@5 100.000 (99.441)\n",
            "Epoch: [45][90/110], lr: 0.01000\tTime 0.048 (0.064)\tData 0.000 (0.009)\tLoss 1.9899 (1.9661)\tPrec@1 89.844 (89.663)\tPrec@5 97.656 (99.433)\n",
            "Epoch: [45][100/110], lr: 0.01000\tTime 0.067 (0.064)\tData 0.013 (0.009)\tLoss 2.2198 (1.9749)\tPrec@1 88.281 (89.550)\tPrec@5 99.219 (99.435)\n",
            "Test: [0/100]\tTime 0.252 (0.252)\tLoss 5.7284 (5.7284)\tPrec@1 72.000 (72.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.039 (0.053)\tLoss 4.9413 (6.5054)\tPrec@1 77.000 (71.273)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 6.1797 (6.4281)\tPrec@1 74.000 (71.429)\tPrec@5 99.000 (97.381)\n",
            "Test: [30/100]\tTime 0.011 (0.037)\tLoss 5.7589 (6.5354)\tPrec@1 71.000 (70.839)\tPrec@5 96.000 (97.194)\n",
            "Test: [40/100]\tTime 0.013 (0.032)\tLoss 6.1494 (6.5680)\tPrec@1 73.000 (70.634)\tPrec@5 95.000 (96.976)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 6.1721 (6.5608)\tPrec@1 72.000 (70.529)\tPrec@5 97.000 (97.020)\n",
            "Test: [60/100]\tTime 0.033 (0.032)\tLoss 5.2885 (6.5317)\tPrec@1 77.000 (70.738)\tPrec@5 97.000 (96.836)\n",
            "Test: [70/100]\tTime 0.054 (0.032)\tLoss 6.5934 (6.5295)\tPrec@1 68.000 (70.831)\tPrec@5 99.000 (96.915)\n",
            "Test: [80/100]\tTime 0.022 (0.031)\tLoss 5.9216 (6.4644)\tPrec@1 75.000 (71.235)\tPrec@5 97.000 (96.963)\n",
            "Test: [90/100]\tTime 0.025 (0.030)\tLoss 6.1147 (6.5153)\tPrec@1 72.000 (71.011)\tPrec@5 97.000 (96.934)\n",
            "val Results: Prec@1 71.030 Prec@5 96.970 Loss 6.52154\n",
            "val Class Accuracy: [0.921,0.977,0.745,0.567,0.742,0.718,0.868,0.522,0.530,0.513]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [46][0/110], lr: 0.01000\tTime 0.463 (0.463)\tData 0.373 (0.373)\tLoss 1.7822 (1.7822)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [46][10/110], lr: 0.01000\tTime 0.063 (0.099)\tData 0.000 (0.038)\tLoss 2.2063 (2.0942)\tPrec@1 86.719 (88.778)\tPrec@5 97.656 (99.574)\n",
            "Epoch: [46][20/110], lr: 0.01000\tTime 0.061 (0.080)\tData 0.005 (0.022)\tLoss 2.2460 (1.8542)\tPrec@1 86.719 (90.179)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [46][30/110], lr: 0.01000\tTime 0.066 (0.072)\tData 0.000 (0.016)\tLoss 2.3777 (1.8746)\tPrec@1 86.719 (89.970)\tPrec@5 99.219 (99.521)\n",
            "Epoch: [46][40/110], lr: 0.01000\tTime 0.049 (0.070)\tData 0.000 (0.013)\tLoss 2.2209 (1.8815)\tPrec@1 88.281 (89.958)\tPrec@5 100.000 (99.505)\n",
            "Epoch: [46][50/110], lr: 0.01000\tTime 0.073 (0.068)\tData 0.000 (0.011)\tLoss 1.4228 (1.8825)\tPrec@1 92.969 (89.982)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [46][60/110], lr: 0.01000\tTime 0.076 (0.066)\tData 0.000 (0.010)\tLoss 1.2655 (1.8889)\tPrec@1 94.531 (90.100)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [46][70/110], lr: 0.01000\tTime 0.036 (0.065)\tData 0.000 (0.009)\tLoss 2.2048 (1.9030)\tPrec@1 88.281 (90.031)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [46][80/110], lr: 0.01000\tTime 0.065 (0.067)\tData 0.000 (0.009)\tLoss 2.5580 (1.9259)\tPrec@1 87.500 (89.902)\tPrec@5 99.219 (99.566)\n",
            "Epoch: [46][90/110], lr: 0.01000\tTime 0.093 (0.069)\tData 0.016 (0.009)\tLoss 2.2740 (1.9511)\tPrec@1 87.500 (89.698)\tPrec@5 99.219 (99.502)\n",
            "Epoch: [46][100/110], lr: 0.01000\tTime 0.112 (0.071)\tData 0.012 (0.009)\tLoss 1.7291 (1.9457)\tPrec@1 91.406 (89.705)\tPrec@5 100.000 (99.489)\n",
            "Test: [0/100]\tTime 0.423 (0.423)\tLoss 6.0126 (6.0126)\tPrec@1 71.000 (71.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.032 (0.078)\tLoss 4.9823 (6.5487)\tPrec@1 78.000 (70.091)\tPrec@5 98.000 (97.455)\n",
            "Test: [20/100]\tTime 0.031 (0.057)\tLoss 6.1581 (6.4555)\tPrec@1 69.000 (70.952)\tPrec@5 98.000 (97.286)\n",
            "Test: [30/100]\tTime 0.039 (0.047)\tLoss 6.8489 (6.5966)\tPrec@1 68.000 (70.226)\tPrec@5 97.000 (97.065)\n",
            "Test: [40/100]\tTime 0.022 (0.041)\tLoss 6.7142 (6.6608)\tPrec@1 68.000 (69.878)\tPrec@5 97.000 (96.927)\n",
            "Test: [50/100]\tTime 0.027 (0.038)\tLoss 5.8083 (6.5564)\tPrec@1 75.000 (70.392)\tPrec@5 97.000 (97.157)\n",
            "Test: [60/100]\tTime 0.035 (0.036)\tLoss 4.8258 (6.5476)\tPrec@1 79.000 (70.426)\tPrec@5 97.000 (97.131)\n",
            "Test: [70/100]\tTime 0.024 (0.035)\tLoss 5.5577 (6.5455)\tPrec@1 78.000 (70.521)\tPrec@5 97.000 (97.113)\n",
            "Test: [80/100]\tTime 0.019 (0.034)\tLoss 6.2890 (6.4967)\tPrec@1 70.000 (70.691)\tPrec@5 98.000 (97.247)\n",
            "Test: [90/100]\tTime 0.017 (0.033)\tLoss 6.4164 (6.5337)\tPrec@1 71.000 (70.593)\tPrec@5 100.000 (97.297)\n",
            "val Results: Prec@1 70.620 Prec@5 97.210 Loss 6.53630\n",
            "val Class Accuracy: [0.908,0.954,0.771,0.798,0.735,0.501,0.701,0.671,0.657,0.366]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [47][0/110], lr: 0.01000\tTime 0.483 (0.483)\tData 0.400 (0.400)\tLoss 1.5700 (1.5700)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [47][10/110], lr: 0.01000\tTime 0.049 (0.105)\tData 0.000 (0.040)\tLoss 1.6456 (1.9648)\tPrec@1 91.406 (90.199)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [47][20/110], lr: 0.01000\tTime 0.063 (0.084)\tData 0.010 (0.024)\tLoss 2.7496 (2.0183)\tPrec@1 84.375 (89.360)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [47][30/110], lr: 0.01000\tTime 0.061 (0.076)\tData 0.005 (0.018)\tLoss 2.2370 (1.9737)\tPrec@1 88.281 (89.693)\tPrec@5 96.875 (99.420)\n",
            "Epoch: [47][40/110], lr: 0.01000\tTime 0.066 (0.072)\tData 0.008 (0.014)\tLoss 1.6972 (1.9736)\tPrec@1 92.188 (89.710)\tPrec@5 100.000 (99.486)\n",
            "Epoch: [47][50/110], lr: 0.01000\tTime 0.059 (0.070)\tData 0.006 (0.013)\tLoss 1.5588 (1.9028)\tPrec@1 92.188 (90.058)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [47][60/110], lr: 0.01000\tTime 0.066 (0.068)\tData 0.006 (0.012)\tLoss 2.0518 (1.9141)\tPrec@1 90.625 (90.010)\tPrec@5 100.000 (99.436)\n",
            "Epoch: [47][70/110], lr: 0.01000\tTime 0.066 (0.067)\tData 0.006 (0.011)\tLoss 1.2464 (1.8881)\tPrec@1 94.531 (90.108)\tPrec@5 100.000 (99.384)\n",
            "Epoch: [47][80/110], lr: 0.01000\tTime 0.052 (0.065)\tData 0.015 (0.010)\tLoss 2.4101 (1.8976)\tPrec@1 85.938 (90.056)\tPrec@5 100.000 (99.363)\n",
            "Epoch: [47][90/110], lr: 0.01000\tTime 0.040 (0.064)\tData 0.000 (0.009)\tLoss 1.7310 (1.9054)\tPrec@1 91.406 (90.050)\tPrec@5 99.219 (99.339)\n",
            "Epoch: [47][100/110], lr: 0.01000\tTime 0.075 (0.064)\tData 0.000 (0.009)\tLoss 1.4219 (1.9170)\tPrec@1 91.406 (89.960)\tPrec@5 100.000 (99.312)\n",
            "Test: [0/100]\tTime 0.334 (0.334)\tLoss 8.1716 (8.1716)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.034 (0.054)\tLoss 6.9194 (8.8324)\tPrec@1 72.000 (61.000)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 7.9640 (8.7928)\tPrec@1 63.000 (61.000)\tPrec@5 98.000 (96.952)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 8.2697 (8.8890)\tPrec@1 59.000 (60.516)\tPrec@5 95.000 (96.710)\n",
            "Test: [40/100]\tTime 0.021 (0.033)\tLoss 9.3527 (8.9521)\tPrec@1 61.000 (60.244)\tPrec@5 95.000 (96.488)\n",
            "Test: [50/100]\tTime 0.011 (0.031)\tLoss 8.9582 (8.8897)\tPrec@1 60.000 (60.373)\tPrec@5 97.000 (96.608)\n",
            "Test: [60/100]\tTime 0.036 (0.030)\tLoss 7.4193 (8.9070)\tPrec@1 66.000 (60.131)\tPrec@5 95.000 (96.426)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 8.9405 (8.9178)\tPrec@1 60.000 (59.915)\tPrec@5 97.000 (96.493)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 8.1778 (8.8840)\tPrec@1 63.000 (60.111)\tPrec@5 98.000 (96.531)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 9.2365 (8.9603)\tPrec@1 60.000 (59.714)\tPrec@5 96.000 (96.560)\n",
            "val Results: Prec@1 59.730 Prec@5 96.640 Loss 8.98495\n",
            "val Class Accuracy: [0.959,0.992,0.789,0.705,0.653,0.170,0.627,0.486,0.420,0.172]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [48][0/110], lr: 0.01000\tTime 0.450 (0.450)\tData 0.352 (0.352)\tLoss 2.0597 (2.0597)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [48][10/110], lr: 0.01000\tTime 0.073 (0.100)\tData 0.012 (0.035)\tLoss 1.7105 (2.0672)\tPrec@1 92.969 (89.134)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [48][20/110], lr: 0.01000\tTime 0.068 (0.079)\tData 0.007 (0.020)\tLoss 2.2084 (1.8532)\tPrec@1 87.500 (90.141)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [48][30/110], lr: 0.01000\tTime 0.057 (0.073)\tData 0.007 (0.015)\tLoss 2.6835 (1.8562)\tPrec@1 84.375 (89.995)\tPrec@5 98.438 (99.471)\n",
            "Epoch: [48][40/110], lr: 0.01000\tTime 0.065 (0.070)\tData 0.000 (0.012)\tLoss 1.8929 (1.8656)\tPrec@1 89.844 (90.034)\tPrec@5 98.438 (99.505)\n",
            "Epoch: [48][50/110], lr: 0.01000\tTime 0.058 (0.067)\tData 0.006 (0.011)\tLoss 2.0040 (1.8602)\tPrec@1 88.281 (90.043)\tPrec@5 98.438 (99.540)\n",
            "Epoch: [48][60/110], lr: 0.01000\tTime 0.067 (0.066)\tData 0.006 (0.010)\tLoss 1.5329 (1.9132)\tPrec@1 90.625 (89.728)\tPrec@5 100.000 (99.513)\n",
            "Epoch: [48][70/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.001 (0.009)\tLoss 2.3321 (1.9227)\tPrec@1 86.719 (89.690)\tPrec@5 99.219 (99.461)\n",
            "Epoch: [48][80/110], lr: 0.01000\tTime 0.065 (0.064)\tData 0.000 (0.008)\tLoss 1.4821 (1.9417)\tPrec@1 90.625 (89.564)\tPrec@5 99.219 (99.421)\n",
            "Epoch: [48][90/110], lr: 0.01000\tTime 0.059 (0.063)\tData 0.000 (0.008)\tLoss 2.0148 (1.9513)\tPrec@1 87.500 (89.578)\tPrec@5 98.438 (99.373)\n",
            "Epoch: [48][100/110], lr: 0.01000\tTime 0.091 (0.063)\tData 0.010 (0.008)\tLoss 1.1962 (1.9512)\tPrec@1 95.312 (89.635)\tPrec@5 98.438 (99.335)\n",
            "Test: [0/100]\tTime 0.281 (0.281)\tLoss 10.8412 (10.8412)\tPrec@1 54.000 (54.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.025 (0.051)\tLoss 7.9093 (9.8678)\tPrec@1 66.000 (57.636)\tPrec@5 97.000 (95.727)\n",
            "Test: [20/100]\tTime 0.027 (0.039)\tLoss 8.3825 (9.8137)\tPrec@1 63.000 (57.667)\tPrec@5 97.000 (95.381)\n",
            "Test: [30/100]\tTime 0.011 (0.034)\tLoss 8.8807 (9.8756)\tPrec@1 57.000 (57.452)\tPrec@5 93.000 (94.871)\n",
            "Test: [40/100]\tTime 0.012 (0.031)\tLoss 10.3184 (9.9425)\tPrec@1 54.000 (57.415)\tPrec@5 95.000 (94.780)\n",
            "Test: [50/100]\tTime 0.033 (0.031)\tLoss 9.4232 (9.8599)\tPrec@1 60.000 (57.824)\tPrec@5 97.000 (94.863)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 8.4285 (9.8585)\tPrec@1 60.000 (57.525)\tPrec@5 96.000 (94.672)\n",
            "Test: [70/100]\tTime 0.021 (0.029)\tLoss 10.1156 (9.8482)\tPrec@1 55.000 (57.535)\tPrec@5 94.000 (94.662)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 8.6278 (9.7993)\tPrec@1 63.000 (57.630)\tPrec@5 94.000 (94.815)\n",
            "Test: [90/100]\tTime 0.028 (0.029)\tLoss 9.7576 (9.8578)\tPrec@1 59.000 (57.418)\tPrec@5 98.000 (94.868)\n",
            "val Results: Prec@1 57.350 Prec@5 94.840 Loss 9.89234\n",
            "val Class Accuracy: [0.952,0.993,0.845,0.441,0.621,0.501,0.717,0.404,0.192,0.069]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [49][0/110], lr: 0.01000\tTime 0.391 (0.391)\tData 0.272 (0.272)\tLoss 2.2592 (2.2592)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [49][10/110], lr: 0.01000\tTime 0.054 (0.099)\tData 0.000 (0.034)\tLoss 1.4509 (1.7564)\tPrec@1 92.188 (90.909)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [49][20/110], lr: 0.01000\tTime 0.054 (0.080)\tData 0.000 (0.019)\tLoss 1.4664 (1.7514)\tPrec@1 92.969 (90.774)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [49][30/110], lr: 0.01000\tTime 0.061 (0.073)\tData 0.006 (0.014)\tLoss 2.0814 (1.8390)\tPrec@1 87.500 (90.348)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [49][40/110], lr: 0.01000\tTime 0.071 (0.070)\tData 0.003 (0.012)\tLoss 1.5192 (1.8588)\tPrec@1 90.625 (90.244)\tPrec@5 100.000 (99.619)\n",
            "Epoch: [49][50/110], lr: 0.01000\tTime 0.059 (0.067)\tData 0.000 (0.011)\tLoss 1.9740 (1.8444)\tPrec@1 89.062 (90.319)\tPrec@5 99.219 (99.602)\n",
            "Epoch: [49][60/110], lr: 0.01000\tTime 0.056 (0.066)\tData 0.006 (0.010)\tLoss 1.7019 (1.8555)\tPrec@1 90.625 (90.279)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [49][70/110], lr: 0.01000\tTime 0.064 (0.065)\tData 0.004 (0.010)\tLoss 1.8311 (1.8541)\tPrec@1 91.406 (90.273)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [49][80/110], lr: 0.01000\tTime 0.057 (0.064)\tData 0.006 (0.009)\tLoss 1.5753 (1.8870)\tPrec@1 90.625 (90.143)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [49][90/110], lr: 0.01000\tTime 0.050 (0.063)\tData 0.004 (0.009)\tLoss 2.0735 (1.8980)\tPrec@1 89.062 (90.058)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [49][100/110], lr: 0.01000\tTime 0.050 (0.063)\tData 0.007 (0.008)\tLoss 1.8900 (1.8794)\tPrec@1 89.844 (90.084)\tPrec@5 99.219 (99.451)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 7.4829 (7.4829)\tPrec@1 68.000 (68.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.039 (0.055)\tLoss 7.2559 (7.9609)\tPrec@1 70.000 (65.182)\tPrec@5 93.000 (95.364)\n",
            "Test: [20/100]\tTime 0.017 (0.040)\tLoss 7.0124 (8.0648)\tPrec@1 66.000 (64.000)\tPrec@5 99.000 (95.619)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 8.2360 (8.1039)\tPrec@1 62.000 (64.129)\tPrec@5 96.000 (95.323)\n",
            "Test: [40/100]\tTime 0.054 (0.034)\tLoss 8.5154 (8.0650)\tPrec@1 65.000 (64.439)\tPrec@5 93.000 (95.146)\n",
            "Test: [50/100]\tTime 0.033 (0.032)\tLoss 7.4742 (7.9949)\tPrec@1 72.000 (64.765)\tPrec@5 98.000 (95.196)\n",
            "Test: [60/100]\tTime 0.030 (0.031)\tLoss 6.8032 (7.9948)\tPrec@1 69.000 (64.656)\tPrec@5 95.000 (95.311)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 7.1297 (7.9916)\tPrec@1 67.000 (64.606)\tPrec@5 98.000 (95.211)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 7.3207 (7.9113)\tPrec@1 68.000 (64.827)\tPrec@5 96.000 (95.309)\n",
            "Test: [90/100]\tTime 0.020 (0.028)\tLoss 8.1603 (8.0125)\tPrec@1 66.000 (64.451)\tPrec@5 94.000 (95.231)\n",
            "val Results: Prec@1 64.520 Prec@5 95.230 Loss 8.01166\n",
            "val Class Accuracy: [0.953,0.954,0.804,0.743,0.557,0.539,0.550,0.678,0.168,0.506]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [50][0/110], lr: 0.01000\tTime 0.352 (0.352)\tData 0.277 (0.277)\tLoss 1.5696 (1.5696)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [50][10/110], lr: 0.01000\tTime 0.038 (0.099)\tData 0.000 (0.034)\tLoss 1.9356 (1.7397)\tPrec@1 88.281 (90.838)\tPrec@5 99.219 (99.503)\n",
            "Epoch: [50][20/110], lr: 0.01000\tTime 0.065 (0.080)\tData 0.005 (0.020)\tLoss 2.3944 (1.8292)\tPrec@1 88.281 (90.476)\tPrec@5 99.219 (99.479)\n",
            "Epoch: [50][30/110], lr: 0.01000\tTime 0.073 (0.074)\tData 0.010 (0.015)\tLoss 2.1949 (1.9367)\tPrec@1 89.062 (89.869)\tPrec@5 98.438 (99.521)\n",
            "Epoch: [50][40/110], lr: 0.01000\tTime 0.059 (0.070)\tData 0.007 (0.013)\tLoss 2.0969 (1.9287)\tPrec@1 90.625 (89.882)\tPrec@5 99.219 (99.524)\n",
            "Epoch: [50][50/110], lr: 0.01000\tTime 0.049 (0.066)\tData 0.000 (0.011)\tLoss 2.0491 (1.8969)\tPrec@1 88.281 (89.982)\tPrec@5 100.000 (99.525)\n",
            "Epoch: [50][60/110], lr: 0.01000\tTime 0.043 (0.065)\tData 0.000 (0.010)\tLoss 1.4310 (1.8922)\tPrec@1 90.625 (89.985)\tPrec@5 100.000 (99.552)\n",
            "Epoch: [50][70/110], lr: 0.01000\tTime 0.076 (0.065)\tData 0.003 (0.009)\tLoss 1.6268 (1.8987)\tPrec@1 92.188 (89.910)\tPrec@5 100.000 (99.560)\n",
            "Epoch: [50][80/110], lr: 0.01000\tTime 0.064 (0.064)\tData 0.001 (0.009)\tLoss 1.5959 (1.8865)\tPrec@1 92.969 (89.988)\tPrec@5 99.219 (99.556)\n",
            "Epoch: [50][90/110], lr: 0.01000\tTime 0.063 (0.063)\tData 0.007 (0.008)\tLoss 1.5257 (1.8605)\tPrec@1 91.406 (90.153)\tPrec@5 100.000 (99.562)\n",
            "Epoch: [50][100/110], lr: 0.01000\tTime 0.051 (0.062)\tData 0.000 (0.008)\tLoss 1.7526 (1.8447)\tPrec@1 89.062 (90.215)\tPrec@5 99.219 (99.575)\n",
            "Test: [0/100]\tTime 0.340 (0.340)\tLoss 9.9404 (9.9404)\tPrec@1 56.000 (56.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/100]\tTime 0.020 (0.055)\tLoss 7.1571 (9.0425)\tPrec@1 69.000 (60.455)\tPrec@5 95.000 (94.909)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 7.8796 (9.0822)\tPrec@1 64.000 (59.952)\tPrec@5 98.000 (94.952)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 7.7190 (9.0319)\tPrec@1 70.000 (60.226)\tPrec@5 94.000 (95.065)\n",
            "Test: [40/100]\tTime 0.017 (0.034)\tLoss 8.7816 (8.9803)\tPrec@1 60.000 (60.268)\tPrec@5 96.000 (95.293)\n",
            "Test: [50/100]\tTime 0.010 (0.032)\tLoss 8.0502 (8.9078)\tPrec@1 61.000 (60.431)\tPrec@5 97.000 (95.216)\n",
            "Test: [60/100]\tTime 0.033 (0.031)\tLoss 7.4412 (8.8782)\tPrec@1 67.000 (60.508)\tPrec@5 97.000 (95.262)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 8.6847 (8.8909)\tPrec@1 58.000 (60.408)\tPrec@5 97.000 (95.268)\n",
            "Test: [80/100]\tTime 0.010 (0.030)\tLoss 8.3070 (8.8463)\tPrec@1 65.000 (60.741)\tPrec@5 94.000 (95.296)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 8.5927 (8.9090)\tPrec@1 63.000 (60.527)\tPrec@5 94.000 (95.264)\n",
            "val Results: Prec@1 60.660 Prec@5 95.240 Loss 8.92041\n",
            "val Class Accuracy: [0.961,0.981,0.784,0.708,0.666,0.443,0.496,0.556,0.140,0.331]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [51][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.386 (0.386)\tLoss 1.2924 (1.2924)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [51][10/110], lr: 0.01000\tTime 0.049 (0.099)\tData 0.000 (0.038)\tLoss 1.8550 (1.4503)\tPrec@1 89.062 (92.188)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [51][20/110], lr: 0.01000\tTime 0.067 (0.081)\tData 0.007 (0.023)\tLoss 1.8556 (1.6579)\tPrec@1 90.625 (91.146)\tPrec@5 99.219 (99.628)\n",
            "Epoch: [51][30/110], lr: 0.01000\tTime 0.088 (0.079)\tData 0.010 (0.017)\tLoss 1.6998 (1.7090)\tPrec@1 91.406 (91.003)\tPrec@5 100.000 (99.672)\n",
            "Epoch: [51][40/110], lr: 0.01000\tTime 0.080 (0.081)\tData 0.000 (0.015)\tLoss 1.5406 (1.7805)\tPrec@1 93.750 (90.587)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [51][50/110], lr: 0.01000\tTime 0.110 (0.083)\tData 0.013 (0.013)\tLoss 1.4257 (1.7889)\tPrec@1 91.406 (90.564)\tPrec@5 100.000 (99.586)\n",
            "Epoch: [51][60/110], lr: 0.01000\tTime 0.069 (0.085)\tData 0.006 (0.012)\tLoss 1.8125 (1.7658)\tPrec@1 89.844 (90.612)\tPrec@5 100.000 (99.526)\n",
            "Epoch: [51][70/110], lr: 0.01000\tTime 0.128 (0.086)\tData 0.011 (0.012)\tLoss 1.7049 (1.7894)\tPrec@1 89.844 (90.416)\tPrec@5 99.219 (99.472)\n",
            "Epoch: [51][80/110], lr: 0.01000\tTime 0.045 (0.083)\tData 0.000 (0.011)\tLoss 1.5354 (1.8416)\tPrec@1 92.969 (90.181)\tPrec@5 99.219 (99.479)\n",
            "Epoch: [51][90/110], lr: 0.01000\tTime 0.054 (0.081)\tData 0.007 (0.010)\tLoss 2.3795 (1.8531)\tPrec@1 85.938 (90.093)\tPrec@5 99.219 (99.476)\n",
            "Epoch: [51][100/110], lr: 0.01000\tTime 0.048 (0.079)\tData 0.000 (0.010)\tLoss 1.7473 (1.8584)\tPrec@1 90.625 (90.076)\tPrec@5 100.000 (99.489)\n",
            "Test: [0/100]\tTime 0.330 (0.330)\tLoss 9.4865 (9.4865)\tPrec@1 57.000 (57.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.020 (0.056)\tLoss 7.2824 (8.9101)\tPrec@1 68.000 (60.364)\tPrec@5 95.000 (95.636)\n",
            "Test: [20/100]\tTime 0.037 (0.042)\tLoss 7.8518 (8.9962)\tPrec@1 66.000 (60.143)\tPrec@5 99.000 (96.238)\n",
            "Test: [30/100]\tTime 0.026 (0.034)\tLoss 8.5252 (9.0107)\tPrec@1 61.000 (60.000)\tPrec@5 93.000 (95.742)\n",
            "Test: [40/100]\tTime 0.023 (0.034)\tLoss 10.5400 (9.0157)\tPrec@1 54.000 (59.951)\tPrec@5 93.000 (95.659)\n",
            "Test: [50/100]\tTime 0.018 (0.033)\tLoss 9.2887 (8.9878)\tPrec@1 60.000 (60.000)\tPrec@5 95.000 (95.745)\n",
            "Test: [60/100]\tTime 0.041 (0.031)\tLoss 7.4197 (9.0280)\tPrec@1 67.000 (59.787)\tPrec@5 97.000 (95.672)\n",
            "Test: [70/100]\tTime 0.011 (0.030)\tLoss 8.9349 (9.0358)\tPrec@1 61.000 (59.803)\tPrec@5 97.000 (95.817)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 8.6015 (9.0023)\tPrec@1 60.000 (59.914)\tPrec@5 96.000 (95.877)\n",
            "Test: [90/100]\tTime 0.021 (0.029)\tLoss 8.6994 (9.0533)\tPrec@1 63.000 (59.659)\tPrec@5 99.000 (95.934)\n",
            "val Results: Prec@1 59.540 Prec@5 95.840 Loss 9.10117\n",
            "val Class Accuracy: [0.953,0.967,0.902,0.550,0.658,0.271,0.635,0.375,0.403,0.240]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [52][0/110], lr: 0.01000\tTime 0.450 (0.450)\tData 0.356 (0.356)\tLoss 1.4252 (1.4252)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [52][10/110], lr: 0.01000\tTime 0.066 (0.098)\tData 0.007 (0.035)\tLoss 1.6918 (1.9687)\tPrec@1 91.406 (89.631)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [52][20/110], lr: 0.01000\tTime 0.064 (0.081)\tData 0.005 (0.021)\tLoss 2.2940 (1.9223)\tPrec@1 86.719 (89.993)\tPrec@5 96.875 (99.368)\n",
            "Epoch: [52][30/110], lr: 0.01000\tTime 0.052 (0.073)\tData 0.000 (0.016)\tLoss 1.2364 (1.9276)\tPrec@1 94.531 (89.844)\tPrec@5 100.000 (99.345)\n",
            "Epoch: [52][40/110], lr: 0.01000\tTime 0.042 (0.070)\tData 0.000 (0.014)\tLoss 1.3678 (1.9221)\tPrec@1 92.969 (89.825)\tPrec@5 99.219 (99.390)\n",
            "Epoch: [52][50/110], lr: 0.01000\tTime 0.055 (0.067)\tData 0.000 (0.012)\tLoss 2.8333 (1.8819)\tPrec@1 84.375 (90.181)\tPrec@5 99.219 (99.433)\n",
            "Epoch: [52][60/110], lr: 0.01000\tTime 0.074 (0.066)\tData 0.007 (0.011)\tLoss 1.5064 (1.8513)\tPrec@1 92.188 (90.343)\tPrec@5 100.000 (99.424)\n",
            "Epoch: [52][70/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.005 (0.010)\tLoss 1.8453 (1.8436)\tPrec@1 91.406 (90.416)\tPrec@5 99.219 (99.450)\n",
            "Epoch: [52][80/110], lr: 0.01000\tTime 0.053 (0.064)\tData 0.010 (0.009)\tLoss 2.2694 (1.8249)\tPrec@1 89.062 (90.509)\tPrec@5 100.000 (99.460)\n",
            "Epoch: [52][90/110], lr: 0.01000\tTime 0.069 (0.064)\tData 0.007 (0.009)\tLoss 1.9183 (1.8077)\tPrec@1 88.281 (90.548)\tPrec@5 100.000 (99.502)\n",
            "Epoch: [52][100/110], lr: 0.01000\tTime 0.057 (0.063)\tData 0.000 (0.009)\tLoss 1.3825 (1.8065)\tPrec@1 91.406 (90.540)\tPrec@5 100.000 (99.528)\n",
            "Test: [0/100]\tTime 0.302 (0.302)\tLoss 8.5203 (8.5203)\tPrec@1 63.000 (63.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.020 (0.049)\tLoss 6.4693 (8.3541)\tPrec@1 73.000 (64.364)\tPrec@5 95.000 (97.273)\n",
            "Test: [20/100]\tTime 0.015 (0.039)\tLoss 6.2154 (8.1633)\tPrec@1 72.000 (65.143)\tPrec@5 98.000 (97.286)\n",
            "Test: [30/100]\tTime 0.035 (0.033)\tLoss 7.5808 (8.2603)\tPrec@1 66.000 (64.452)\tPrec@5 97.000 (96.806)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 8.1811 (8.2817)\tPrec@1 67.000 (64.585)\tPrec@5 95.000 (96.659)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 8.5353 (8.2155)\tPrec@1 66.000 (64.882)\tPrec@5 97.000 (96.882)\n",
            "Test: [60/100]\tTime 0.021 (0.030)\tLoss 6.5764 (8.2135)\tPrec@1 70.000 (64.639)\tPrec@5 98.000 (97.016)\n",
            "Test: [70/100]\tTime 0.044 (0.029)\tLoss 8.6608 (8.2016)\tPrec@1 64.000 (64.746)\tPrec@5 97.000 (97.070)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 8.2620 (8.1624)\tPrec@1 64.000 (64.988)\tPrec@5 96.000 (97.160)\n",
            "Test: [90/100]\tTime 0.041 (0.028)\tLoss 8.0813 (8.2234)\tPrec@1 69.000 (64.714)\tPrec@5 99.000 (97.198)\n",
            "val Results: Prec@1 64.730 Prec@5 97.160 Loss 8.24262\n",
            "val Class Accuracy: [0.907,0.981,0.821,0.746,0.574,0.605,0.724,0.590,0.433,0.092]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [53][0/110], lr: 0.01000\tTime 0.447 (0.447)\tData 0.356 (0.356)\tLoss 2.2848 (2.2848)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [53][10/110], lr: 0.01000\tTime 0.058 (0.099)\tData 0.007 (0.037)\tLoss 1.6916 (1.7261)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [53][20/110], lr: 0.01000\tTime 0.050 (0.079)\tData 0.000 (0.022)\tLoss 1.7320 (1.6640)\tPrec@1 92.188 (91.592)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [53][30/110], lr: 0.01000\tTime 0.058 (0.072)\tData 0.004 (0.016)\tLoss 2.4276 (1.7531)\tPrec@1 88.281 (91.154)\tPrec@5 100.000 (99.546)\n",
            "Epoch: [53][40/110], lr: 0.01000\tTime 0.043 (0.068)\tData 0.000 (0.013)\tLoss 2.3088 (1.7885)\tPrec@1 86.719 (90.835)\tPrec@5 99.219 (99.524)\n",
            "Epoch: [53][50/110], lr: 0.01000\tTime 0.066 (0.066)\tData 0.005 (0.012)\tLoss 1.7527 (1.7709)\tPrec@1 89.844 (90.931)\tPrec@5 99.219 (99.525)\n",
            "Epoch: [53][60/110], lr: 0.01000\tTime 0.072 (0.066)\tData 0.000 (0.011)\tLoss 1.6846 (1.7438)\tPrec@1 89.062 (90.932)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [53][70/110], lr: 0.01000\tTime 0.056 (0.065)\tData 0.007 (0.010)\tLoss 1.3145 (1.7328)\tPrec@1 92.188 (90.999)\tPrec@5 100.000 (99.527)\n",
            "Epoch: [53][80/110], lr: 0.01000\tTime 0.064 (0.064)\tData 0.007 (0.010)\tLoss 1.9138 (1.7662)\tPrec@1 90.625 (90.876)\tPrec@5 99.219 (99.527)\n",
            "Epoch: [53][90/110], lr: 0.01000\tTime 0.053 (0.063)\tData 0.000 (0.009)\tLoss 1.0234 (1.7394)\tPrec@1 95.312 (91.020)\tPrec@5 99.219 (99.528)\n",
            "Epoch: [53][100/110], lr: 0.01000\tTime 0.059 (0.063)\tData 0.001 (0.009)\tLoss 1.9566 (1.7693)\tPrec@1 89.062 (90.880)\tPrec@5 99.219 (99.505)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 8.3856 (8.3856)\tPrec@1 62.000 (62.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.039 (0.054)\tLoss 7.4228 (8.5038)\tPrec@1 66.000 (62.182)\tPrec@5 92.000 (95.909)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 7.8140 (8.2737)\tPrec@1 64.000 (62.857)\tPrec@5 98.000 (95.952)\n",
            "Test: [30/100]\tTime 0.016 (0.034)\tLoss 6.9933 (8.2838)\tPrec@1 68.000 (62.935)\tPrec@5 97.000 (96.290)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 8.3523 (8.2968)\tPrec@1 61.000 (63.195)\tPrec@5 95.000 (96.122)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 7.6912 (8.2204)\tPrec@1 67.000 (63.647)\tPrec@5 97.000 (96.216)\n",
            "Test: [60/100]\tTime 0.023 (0.030)\tLoss 7.1708 (8.2596)\tPrec@1 66.000 (63.279)\tPrec@5 99.000 (96.164)\n",
            "Test: [70/100]\tTime 0.037 (0.029)\tLoss 6.9577 (8.2577)\tPrec@1 73.000 (63.268)\tPrec@5 98.000 (96.155)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 8.0179 (8.1951)\tPrec@1 64.000 (63.519)\tPrec@5 95.000 (96.235)\n",
            "Test: [90/100]\tTime 0.038 (0.028)\tLoss 8.0548 (8.2224)\tPrec@1 66.000 (63.451)\tPrec@5 97.000 (96.209)\n",
            "val Results: Prec@1 63.380 Prec@5 96.160 Loss 8.24697\n",
            "val Class Accuracy: [0.881,0.989,0.916,0.473,0.675,0.491,0.539,0.448,0.647,0.279]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [54][0/110], lr: 0.01000\tTime 0.493 (0.493)\tData 0.380 (0.380)\tLoss 2.3239 (2.3239)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [54][10/110], lr: 0.01000\tTime 0.054 (0.103)\tData 0.007 (0.040)\tLoss 1.6512 (1.8880)\tPrec@1 91.406 (90.270)\tPrec@5 99.219 (99.503)\n",
            "Epoch: [54][20/110], lr: 0.01000\tTime 0.056 (0.081)\tData 0.000 (0.023)\tLoss 1.5954 (1.7715)\tPrec@1 92.188 (90.699)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [54][30/110], lr: 0.01000\tTime 0.041 (0.073)\tData 0.000 (0.017)\tLoss 2.1888 (1.8227)\tPrec@1 89.062 (90.323)\tPrec@5 98.438 (99.446)\n",
            "Epoch: [54][40/110], lr: 0.01000\tTime 0.061 (0.070)\tData 0.007 (0.013)\tLoss 1.0284 (1.7115)\tPrec@1 95.312 (90.968)\tPrec@5 98.438 (99.505)\n",
            "Epoch: [54][50/110], lr: 0.01000\tTime 0.066 (0.068)\tData 0.003 (0.012)\tLoss 1.9653 (1.7214)\tPrec@1 92.188 (90.947)\tPrec@5 98.438 (99.418)\n",
            "Epoch: [54][60/110], lr: 0.01000\tTime 0.047 (0.066)\tData 0.000 (0.011)\tLoss 2.2018 (1.7307)\tPrec@1 87.500 (90.958)\tPrec@5 100.000 (99.475)\n",
            "Epoch: [54][70/110], lr: 0.01000\tTime 0.036 (0.064)\tData 0.000 (0.011)\tLoss 2.1567 (1.7245)\tPrec@1 87.500 (90.988)\tPrec@5 100.000 (99.450)\n",
            "Epoch: [54][80/110], lr: 0.01000\tTime 0.069 (0.064)\tData 0.007 (0.010)\tLoss 2.0358 (1.7192)\tPrec@1 88.281 (90.963)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [54][90/110], lr: 0.01000\tTime 0.054 (0.063)\tData 0.015 (0.009)\tLoss 2.1360 (1.7483)\tPrec@1 88.281 (90.771)\tPrec@5 100.000 (99.511)\n",
            "Epoch: [54][100/110], lr: 0.01000\tTime 0.043 (0.063)\tData 0.000 (0.009)\tLoss 2.1311 (1.7807)\tPrec@1 91.406 (90.571)\tPrec@5 100.000 (99.489)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 8.0146 (8.0146)\tPrec@1 67.000 (67.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.021 (0.052)\tLoss 6.8644 (8.3126)\tPrec@1 72.000 (63.000)\tPrec@5 91.000 (95.364)\n",
            "Test: [20/100]\tTime 0.030 (0.038)\tLoss 7.4829 (8.4478)\tPrec@1 62.000 (61.048)\tPrec@5 96.000 (95.381)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 8.1633 (8.4022)\tPrec@1 58.000 (60.839)\tPrec@5 96.000 (95.226)\n",
            "Test: [40/100]\tTime 0.024 (0.032)\tLoss 7.7240 (8.3038)\tPrec@1 64.000 (61.415)\tPrec@5 96.000 (95.317)\n",
            "Test: [50/100]\tTime 0.017 (0.030)\tLoss 7.8017 (8.1996)\tPrec@1 62.000 (62.020)\tPrec@5 94.000 (95.549)\n",
            "Test: [60/100]\tTime 0.011 (0.029)\tLoss 7.5258 (8.3023)\tPrec@1 63.000 (61.393)\tPrec@5 97.000 (95.525)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 8.4142 (8.3384)\tPrec@1 58.000 (61.197)\tPrec@5 98.000 (95.549)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 7.3294 (8.2947)\tPrec@1 66.000 (61.494)\tPrec@5 95.000 (95.617)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 7.9305 (8.3917)\tPrec@1 63.000 (60.989)\tPrec@5 98.000 (95.571)\n",
            "val Results: Prec@1 60.930 Prec@5 95.500 Loss 8.40222\n",
            "val Class Accuracy: [0.979,0.919,0.816,0.395,0.683,0.497,0.331,0.485,0.422,0.566]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [55][0/110], lr: 0.01000\tTime 0.451 (0.451)\tData 0.375 (0.375)\tLoss 2.5367 (2.5367)\tPrec@1 85.938 (85.938)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [55][10/110], lr: 0.01000\tTime 0.048 (0.098)\tData 0.000 (0.038)\tLoss 2.9613 (2.1136)\tPrec@1 82.812 (88.991)\tPrec@5 97.656 (99.077)\n",
            "Epoch: [55][20/110], lr: 0.01000\tTime 0.053 (0.079)\tData 0.011 (0.024)\tLoss 1.2773 (2.0407)\tPrec@1 93.750 (89.137)\tPrec@5 100.000 (99.219)\n",
            "Epoch: [55][30/110], lr: 0.01000\tTime 0.050 (0.073)\tData 0.000 (0.018)\tLoss 1.4832 (1.9136)\tPrec@1 92.188 (89.844)\tPrec@5 98.438 (99.320)\n",
            "Epoch: [55][40/110], lr: 0.01000\tTime 0.078 (0.070)\tData 0.000 (0.014)\tLoss 1.6032 (1.8971)\tPrec@1 92.188 (90.072)\tPrec@5 99.219 (99.276)\n",
            "Epoch: [55][50/110], lr: 0.01000\tTime 0.087 (0.068)\tData 0.007 (0.012)\tLoss 2.1649 (1.8526)\tPrec@1 88.281 (90.242)\tPrec@5 99.219 (99.372)\n",
            "Epoch: [55][60/110], lr: 0.01000\tTime 0.066 (0.066)\tData 0.010 (0.011)\tLoss 1.2878 (1.8562)\tPrec@1 91.406 (90.164)\tPrec@5 100.000 (99.372)\n",
            "Epoch: [55][70/110], lr: 0.01000\tTime 0.048 (0.065)\tData 0.012 (0.011)\tLoss 2.2051 (1.8562)\tPrec@1 87.500 (90.163)\tPrec@5 98.438 (99.362)\n",
            "Epoch: [55][80/110], lr: 0.01000\tTime 0.062 (0.064)\tData 0.000 (0.010)\tLoss 2.0497 (1.8567)\tPrec@1 87.500 (90.085)\tPrec@5 99.219 (99.373)\n",
            "Epoch: [55][90/110], lr: 0.01000\tTime 0.053 (0.063)\tData 0.000 (0.009)\tLoss 1.4816 (1.8563)\tPrec@1 92.969 (90.093)\tPrec@5 100.000 (99.416)\n",
            "Epoch: [55][100/110], lr: 0.01000\tTime 0.043 (0.063)\tData 0.007 (0.009)\tLoss 1.4814 (1.8531)\tPrec@1 92.188 (90.122)\tPrec@5 100.000 (99.428)\n",
            "Test: [0/100]\tTime 0.437 (0.437)\tLoss 8.6158 (8.6158)\tPrec@1 61.000 (61.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.034 (0.081)\tLoss 6.3528 (7.4095)\tPrec@1 71.000 (67.091)\tPrec@5 94.000 (95.818)\n",
            "Test: [20/100]\tTime 0.042 (0.062)\tLoss 7.2972 (7.6012)\tPrec@1 65.000 (65.857)\tPrec@5 96.000 (95.571)\n",
            "Test: [30/100]\tTime 0.033 (0.055)\tLoss 6.9610 (7.5793)\tPrec@1 69.000 (65.710)\tPrec@5 93.000 (95.387)\n",
            "Test: [40/100]\tTime 0.036 (0.052)\tLoss 7.0296 (7.4402)\tPrec@1 72.000 (66.756)\tPrec@5 93.000 (95.341)\n",
            "Test: [50/100]\tTime 0.035 (0.049)\tLoss 6.1829 (7.3079)\tPrec@1 75.000 (67.392)\tPrec@5 97.000 (95.412)\n",
            "Test: [60/100]\tTime 0.039 (0.048)\tLoss 6.7290 (7.2628)\tPrec@1 68.000 (67.541)\tPrec@5 93.000 (95.361)\n",
            "Test: [70/100]\tTime 0.036 (0.046)\tLoss 7.2925 (7.3432)\tPrec@1 68.000 (67.183)\tPrec@5 95.000 (95.437)\n",
            "Test: [80/100]\tTime 0.037 (0.045)\tLoss 4.9967 (7.2786)\tPrec@1 76.000 (67.284)\tPrec@5 96.000 (95.506)\n",
            "Test: [90/100]\tTime 0.048 (0.045)\tLoss 6.9550 (7.3786)\tPrec@1 71.000 (66.813)\tPrec@5 96.000 (95.407)\n",
            "val Results: Prec@1 66.740 Prec@5 95.430 Loss 7.39664\n",
            "val Class Accuracy: [0.962,0.872,0.714,0.389,0.778,0.749,0.540,0.844,0.093,0.733]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [56][0/110], lr: 0.01000\tTime 0.391 (0.391)\tData 0.304 (0.304)\tLoss 1.2734 (1.2734)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [56][10/110], lr: 0.01000\tTime 0.046 (0.103)\tData 0.000 (0.036)\tLoss 1.6833 (1.6712)\tPrec@1 91.406 (90.909)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [56][20/110], lr: 0.01000\tTime 0.053 (0.083)\tData 0.000 (0.021)\tLoss 2.2742 (1.6504)\tPrec@1 86.719 (91.295)\tPrec@5 100.000 (99.516)\n",
            "Epoch: [56][30/110], lr: 0.01000\tTime 0.062 (0.076)\tData 0.005 (0.016)\tLoss 1.8731 (1.7317)\tPrec@1 89.844 (91.028)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [56][40/110], lr: 0.01000\tTime 0.043 (0.071)\tData 0.000 (0.013)\tLoss 1.6652 (1.7070)\tPrec@1 89.844 (91.139)\tPrec@5 100.000 (99.409)\n",
            "Epoch: [56][50/110], lr: 0.01000\tTime 0.065 (0.070)\tData 0.005 (0.012)\tLoss 2.2329 (1.7343)\tPrec@1 89.062 (90.977)\tPrec@5 98.438 (99.403)\n",
            "Epoch: [56][60/110], lr: 0.01000\tTime 0.077 (0.068)\tData 0.004 (0.010)\tLoss 2.3869 (1.7269)\tPrec@1 87.500 (91.009)\tPrec@5 100.000 (99.449)\n",
            "Epoch: [56][70/110], lr: 0.01000\tTime 0.067 (0.067)\tData 0.007 (0.009)\tLoss 2.0592 (1.7425)\tPrec@1 89.062 (90.889)\tPrec@5 100.000 (99.450)\n",
            "Epoch: [56][80/110], lr: 0.01000\tTime 0.061 (0.066)\tData 0.011 (0.009)\tLoss 1.9887 (1.7434)\tPrec@1 88.281 (90.856)\tPrec@5 99.219 (99.470)\n",
            "Epoch: [56][90/110], lr: 0.01000\tTime 0.056 (0.065)\tData 0.008 (0.009)\tLoss 1.7132 (1.7560)\tPrec@1 91.406 (90.745)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [56][100/110], lr: 0.01000\tTime 0.064 (0.065)\tData 0.007 (0.008)\tLoss 0.9145 (1.7518)\tPrec@1 94.531 (90.764)\tPrec@5 100.000 (99.451)\n",
            "Test: [0/100]\tTime 0.260 (0.260)\tLoss 5.5756 (5.5756)\tPrec@1 77.000 (77.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.047 (0.056)\tLoss 5.3465 (6.2998)\tPrec@1 77.000 (71.818)\tPrec@5 94.000 (97.273)\n",
            "Test: [20/100]\tTime 0.056 (0.040)\tLoss 5.7529 (6.4350)\tPrec@1 75.000 (71.238)\tPrec@5 99.000 (97.333)\n",
            "Test: [30/100]\tTime 0.043 (0.036)\tLoss 6.1838 (6.5075)\tPrec@1 70.000 (70.871)\tPrec@5 95.000 (97.065)\n",
            "Test: [40/100]\tTime 0.031 (0.033)\tLoss 6.1167 (6.5425)\tPrec@1 74.000 (70.585)\tPrec@5 96.000 (96.878)\n",
            "Test: [50/100]\tTime 0.023 (0.032)\tLoss 6.0633 (6.4793)\tPrec@1 72.000 (71.000)\tPrec@5 98.000 (97.157)\n",
            "Test: [60/100]\tTime 0.024 (0.031)\tLoss 5.5874 (6.4893)\tPrec@1 73.000 (70.836)\tPrec@5 100.000 (97.164)\n",
            "Test: [70/100]\tTime 0.019 (0.030)\tLoss 6.5768 (6.5082)\tPrec@1 66.000 (70.634)\tPrec@5 99.000 (97.197)\n",
            "Test: [80/100]\tTime 0.026 (0.029)\tLoss 6.0306 (6.4869)\tPrec@1 74.000 (70.728)\tPrec@5 97.000 (97.272)\n",
            "Test: [90/100]\tTime 0.019 (0.029)\tLoss 7.4199 (6.5675)\tPrec@1 69.000 (70.418)\tPrec@5 99.000 (97.319)\n",
            "val Results: Prec@1 70.500 Prec@5 97.310 Loss 6.57001\n",
            "val Class Accuracy: [0.984,0.944,0.685,0.716,0.803,0.594,0.638,0.629,0.585,0.472]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [57][0/110], lr: 0.01000\tTime 0.397 (0.397)\tData 0.301 (0.301)\tLoss 1.5486 (1.5486)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [57][10/110], lr: 0.01000\tTime 0.044 (0.101)\tData 0.008 (0.032)\tLoss 1.5784 (1.5833)\tPrec@1 89.844 (91.761)\tPrec@5 100.000 (99.432)\n",
            "Epoch: [57][20/110], lr: 0.01000\tTime 0.067 (0.083)\tData 0.007 (0.019)\tLoss 1.9295 (1.6465)\tPrec@1 91.406 (91.332)\tPrec@5 99.219 (99.516)\n",
            "Epoch: [57][30/110], lr: 0.01000\tTime 0.062 (0.076)\tData 0.002 (0.014)\tLoss 1.5690 (1.7331)\tPrec@1 92.969 (91.079)\tPrec@5 99.219 (99.546)\n",
            "Epoch: [57][40/110], lr: 0.01000\tTime 0.054 (0.073)\tData 0.011 (0.012)\tLoss 2.2604 (1.7473)\tPrec@1 89.062 (90.816)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [57][50/110], lr: 0.01000\tTime 0.050 (0.071)\tData 0.000 (0.010)\tLoss 1.3456 (1.7342)\tPrec@1 92.969 (90.824)\tPrec@5 100.000 (99.602)\n",
            "Epoch: [57][60/110], lr: 0.01000\tTime 0.041 (0.069)\tData 0.000 (0.009)\tLoss 1.3714 (1.7066)\tPrec@1 92.188 (90.932)\tPrec@5 100.000 (99.616)\n",
            "Epoch: [57][70/110], lr: 0.01000\tTime 0.070 (0.068)\tData 0.000 (0.008)\tLoss 1.8566 (1.7120)\tPrec@1 93.750 (90.922)\tPrec@5 98.438 (99.571)\n",
            "Epoch: [57][80/110], lr: 0.01000\tTime 0.044 (0.067)\tData 0.000 (0.008)\tLoss 0.8981 (1.6982)\tPrec@1 94.531 (91.040)\tPrec@5 100.000 (99.585)\n",
            "Epoch: [57][90/110], lr: 0.01000\tTime 0.066 (0.066)\tData 0.008 (0.008)\tLoss 2.7418 (1.7223)\tPrec@1 84.375 (90.857)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [57][100/110], lr: 0.01000\tTime 0.061 (0.066)\tData 0.000 (0.007)\tLoss 0.9646 (1.7010)\tPrec@1 94.531 (90.989)\tPrec@5 100.000 (99.544)\n",
            "Test: [0/100]\tTime 0.306 (0.306)\tLoss 6.1856 (6.1856)\tPrec@1 69.000 (69.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.022 (0.053)\tLoss 5.8678 (6.3682)\tPrec@1 75.000 (72.273)\tPrec@5 95.000 (96.727)\n",
            "Test: [20/100]\tTime 0.019 (0.040)\tLoss 5.8171 (6.2687)\tPrec@1 73.000 (72.762)\tPrec@5 100.000 (97.048)\n",
            "Test: [30/100]\tTime 0.023 (0.036)\tLoss 6.3916 (6.3137)\tPrec@1 72.000 (72.097)\tPrec@5 96.000 (97.161)\n",
            "Test: [40/100]\tTime 0.025 (0.033)\tLoss 7.0144 (6.3674)\tPrec@1 67.000 (71.683)\tPrec@5 97.000 (97.220)\n",
            "Test: [50/100]\tTime 0.013 (0.031)\tLoss 5.8827 (6.3114)\tPrec@1 73.000 (71.745)\tPrec@5 97.000 (97.353)\n",
            "Test: [60/100]\tTime 0.021 (0.030)\tLoss 6.6072 (6.4003)\tPrec@1 67.000 (71.082)\tPrec@5 99.000 (97.230)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 6.7616 (6.4465)\tPrec@1 69.000 (70.958)\tPrec@5 96.000 (97.183)\n",
            "Test: [80/100]\tTime 0.013 (0.029)\tLoss 5.4163 (6.4015)\tPrec@1 76.000 (71.173)\tPrec@5 95.000 (97.235)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 6.2821 (6.4916)\tPrec@1 74.000 (70.824)\tPrec@5 97.000 (97.176)\n",
            "val Results: Prec@1 70.790 Prec@5 97.080 Loss 6.49770\n",
            "val Class Accuracy: [0.916,0.944,0.804,0.678,0.785,0.549,0.669,0.554,0.381,0.799]\n",
            "Best Prec@1: 71.030\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [58][0/110], lr: 0.01000\tTime 0.415 (0.415)\tData 0.335 (0.335)\tLoss 1.8415 (1.8415)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [58][10/110], lr: 0.01000\tTime 0.073 (0.100)\tData 0.000 (0.035)\tLoss 1.7251 (1.7611)\tPrec@1 91.406 (90.412)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [58][20/110], lr: 0.01000\tTime 0.061 (0.078)\tData 0.005 (0.020)\tLoss 2.1247 (1.8100)\tPrec@1 88.281 (90.216)\tPrec@5 97.656 (99.554)\n",
            "Epoch: [58][30/110], lr: 0.01000\tTime 0.064 (0.074)\tData 0.007 (0.015)\tLoss 1.5726 (1.7861)\tPrec@1 90.625 (90.474)\tPrec@5 100.000 (99.622)\n",
            "Epoch: [58][40/110], lr: 0.01000\tTime 0.057 (0.070)\tData 0.007 (0.013)\tLoss 2.5735 (1.7862)\tPrec@1 85.938 (90.377)\tPrec@5 98.438 (99.562)\n",
            "Epoch: [58][50/110], lr: 0.01000\tTime 0.060 (0.068)\tData 0.000 (0.012)\tLoss 2.1950 (1.8109)\tPrec@1 88.281 (90.395)\tPrec@5 98.438 (99.510)\n",
            "Epoch: [58][60/110], lr: 0.01000\tTime 0.059 (0.066)\tData 0.007 (0.010)\tLoss 1.6102 (1.8085)\tPrec@1 92.188 (90.407)\tPrec@5 98.438 (99.526)\n",
            "Epoch: [58][70/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.000 (0.009)\tLoss 3.6425 (1.8151)\tPrec@1 80.469 (90.449)\tPrec@5 100.000 (99.505)\n",
            "Epoch: [58][80/110], lr: 0.01000\tTime 0.060 (0.065)\tData 0.007 (0.009)\tLoss 1.4543 (1.7991)\tPrec@1 92.188 (90.500)\tPrec@5 99.219 (99.470)\n",
            "Epoch: [58][90/110], lr: 0.01000\tTime 0.062 (0.064)\tData 0.012 (0.009)\tLoss 1.9376 (1.7842)\tPrec@1 91.406 (90.599)\tPrec@5 100.000 (99.476)\n",
            "Epoch: [58][100/110], lr: 0.01000\tTime 0.074 (0.064)\tData 0.010 (0.008)\tLoss 1.5009 (1.7790)\tPrec@1 93.750 (90.702)\tPrec@5 99.219 (99.489)\n",
            "Test: [0/100]\tTime 0.251 (0.251)\tLoss 4.7253 (4.7253)\tPrec@1 78.000 (78.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.025 (0.053)\tLoss 4.7912 (5.9683)\tPrec@1 80.000 (72.909)\tPrec@5 96.000 (97.182)\n",
            "Test: [20/100]\tTime 0.029 (0.041)\tLoss 5.2063 (5.8101)\tPrec@1 75.000 (73.667)\tPrec@5 99.000 (96.857)\n",
            "Test: [30/100]\tTime 0.010 (0.034)\tLoss 6.6319 (5.9645)\tPrec@1 70.000 (73.161)\tPrec@5 96.000 (96.839)\n",
            "Test: [40/100]\tTime 0.017 (0.033)\tLoss 6.6843 (6.0221)\tPrec@1 69.000 (72.805)\tPrec@5 96.000 (96.561)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 6.4055 (5.9360)\tPrec@1 72.000 (73.137)\tPrec@5 97.000 (96.765)\n",
            "Test: [60/100]\tTime 0.032 (0.031)\tLoss 6.0912 (6.0083)\tPrec@1 71.000 (72.787)\tPrec@5 95.000 (96.607)\n",
            "Test: [70/100]\tTime 0.028 (0.029)\tLoss 5.9688 (6.0353)\tPrec@1 71.000 (72.620)\tPrec@5 99.000 (96.648)\n",
            "Test: [80/100]\tTime 0.042 (0.029)\tLoss 6.1082 (6.0160)\tPrec@1 72.000 (72.704)\tPrec@5 95.000 (96.704)\n",
            "Test: [90/100]\tTime 0.040 (0.029)\tLoss 5.9808 (6.0891)\tPrec@1 75.000 (72.451)\tPrec@5 97.000 (96.725)\n",
            "val Results: Prec@1 72.280 Prec@5 96.780 Loss 6.10562\n",
            "val Class Accuracy: [0.953,0.923,0.810,0.530,0.621,0.639,0.837,0.560,0.666,0.689]\n",
            "Best Prec@1: 72.280\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [59][0/110], lr: 0.01000\tTime 0.357 (0.357)\tData 0.282 (0.282)\tLoss 1.4344 (1.4344)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [59][10/110], lr: 0.01000\tTime 0.046 (0.101)\tData 0.000 (0.038)\tLoss 1.6718 (1.5972)\tPrec@1 90.625 (90.909)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [59][20/110], lr: 0.01000\tTime 0.045 (0.079)\tData 0.000 (0.022)\tLoss 1.1049 (1.5728)\tPrec@1 92.969 (91.481)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [59][30/110], lr: 0.01000\tTime 0.043 (0.073)\tData 0.000 (0.017)\tLoss 1.2839 (1.6068)\tPrec@1 95.312 (91.532)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [59][40/110], lr: 0.01000\tTime 0.048 (0.071)\tData 0.007 (0.014)\tLoss 1.8118 (1.6186)\tPrec@1 90.625 (91.654)\tPrec@5 100.000 (99.524)\n",
            "Epoch: [59][50/110], lr: 0.01000\tTime 0.052 (0.068)\tData 0.006 (0.013)\tLoss 0.9895 (1.5892)\tPrec@1 94.531 (91.820)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [59][60/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.000 (0.012)\tLoss 1.5571 (1.6159)\tPrec@1 91.406 (91.662)\tPrec@5 99.219 (99.526)\n",
            "Epoch: [59][70/110], lr: 0.01000\tTime 0.056 (0.065)\tData 0.016 (0.011)\tLoss 1.8097 (1.6146)\tPrec@1 89.062 (91.626)\tPrec@5 99.219 (99.516)\n",
            "Epoch: [59][80/110], lr: 0.01000\tTime 0.051 (0.064)\tData 0.000 (0.010)\tLoss 1.2043 (1.6150)\tPrec@1 94.531 (91.657)\tPrec@5 100.000 (99.518)\n",
            "Epoch: [59][90/110], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.009)\tLoss 1.8177 (1.6357)\tPrec@1 91.406 (91.587)\tPrec@5 98.438 (99.511)\n",
            "Epoch: [59][100/110], lr: 0.01000\tTime 0.058 (0.064)\tData 0.009 (0.009)\tLoss 1.1918 (1.6403)\tPrec@1 94.531 (91.515)\tPrec@5 100.000 (99.536)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 6.9885 (6.9885)\tPrec@1 69.000 (69.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.017 (0.055)\tLoss 6.0328 (6.8909)\tPrec@1 72.000 (69.818)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/100]\tTime 0.017 (0.041)\tLoss 5.6329 (6.9580)\tPrec@1 71.000 (68.571)\tPrec@5 100.000 (97.381)\n",
            "Test: [30/100]\tTime 0.011 (0.036)\tLoss 6.7217 (7.0005)\tPrec@1 68.000 (68.226)\tPrec@5 96.000 (97.452)\n",
            "Test: [40/100]\tTime 0.013 (0.033)\tLoss 6.5379 (6.9935)\tPrec@1 70.000 (68.268)\tPrec@5 96.000 (97.415)\n",
            "Test: [50/100]\tTime 0.025 (0.032)\tLoss 6.2461 (6.9370)\tPrec@1 72.000 (68.588)\tPrec@5 97.000 (97.529)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 6.4957 (6.9685)\tPrec@1 67.000 (68.279)\tPrec@5 99.000 (97.525)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 6.7819 (6.9788)\tPrec@1 66.000 (68.268)\tPrec@5 98.000 (97.549)\n",
            "Test: [80/100]\tTime 0.019 (0.030)\tLoss 7.4366 (6.9275)\tPrec@1 64.000 (68.407)\tPrec@5 98.000 (97.593)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 6.8691 (7.0019)\tPrec@1 69.000 (68.143)\tPrec@5 100.000 (97.604)\n",
            "val Results: Prec@1 68.060 Prec@5 97.540 Loss 7.04048\n",
            "val Class Accuracy: [0.987,0.897,0.711,0.549,0.807,0.542,0.723,0.704,0.411,0.475]\n",
            "Best Prec@1: 72.280\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [60][0/110], lr: 0.01000\tTime 0.360 (0.360)\tData 0.286 (0.286)\tLoss 2.1384 (2.1384)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [60][10/110], lr: 0.01000\tTime 0.088 (0.099)\tData 0.000 (0.034)\tLoss 2.6055 (1.6327)\tPrec@1 84.375 (91.264)\tPrec@5 99.219 (99.503)\n",
            "Epoch: [60][20/110], lr: 0.01000\tTime 0.057 (0.081)\tData 0.006 (0.021)\tLoss 1.8355 (1.7379)\tPrec@1 89.844 (90.699)\tPrec@5 98.438 (99.442)\n",
            "Epoch: [60][30/110], lr: 0.01000\tTime 0.066 (0.074)\tData 0.011 (0.015)\tLoss 1.4876 (1.7415)\tPrec@1 92.969 (90.701)\tPrec@5 100.000 (99.420)\n",
            "Epoch: [60][40/110], lr: 0.01000\tTime 0.065 (0.071)\tData 0.000 (0.013)\tLoss 0.9595 (1.7000)\tPrec@1 96.875 (91.025)\tPrec@5 99.219 (99.486)\n",
            "Epoch: [60][50/110], lr: 0.01000\tTime 0.097 (0.074)\tData 0.000 (0.011)\tLoss 2.9511 (1.7068)\tPrec@1 83.594 (91.008)\tPrec@5 98.438 (99.525)\n",
            "Epoch: [60][60/110], lr: 0.01000\tTime 0.090 (0.077)\tData 0.006 (0.011)\tLoss 2.1225 (1.7079)\tPrec@1 89.062 (90.958)\tPrec@5 99.219 (99.552)\n",
            "Epoch: [60][70/110], lr: 0.01000\tTime 0.088 (0.078)\tData 0.008 (0.010)\tLoss 2.3751 (1.7130)\tPrec@1 88.281 (90.933)\tPrec@5 100.000 (99.538)\n",
            "Epoch: [60][80/110], lr: 0.01000\tTime 0.123 (0.080)\tData 0.012 (0.010)\tLoss 1.4757 (1.6850)\tPrec@1 93.750 (91.194)\tPrec@5 98.438 (99.527)\n",
            "Epoch: [60][90/110], lr: 0.01000\tTime 0.057 (0.080)\tData 0.007 (0.009)\tLoss 2.0009 (1.7079)\tPrec@1 89.062 (91.029)\tPrec@5 100.000 (99.562)\n",
            "Epoch: [60][100/110], lr: 0.01000\tTime 0.063 (0.078)\tData 0.011 (0.009)\tLoss 0.7073 (1.7332)\tPrec@1 96.875 (90.873)\tPrec@5 99.219 (99.551)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 5.7047 (5.7047)\tPrec@1 74.000 (74.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.010 (0.051)\tLoss 5.4121 (6.1052)\tPrec@1 76.000 (72.000)\tPrec@5 96.000 (97.818)\n",
            "Test: [20/100]\tTime 0.028 (0.040)\tLoss 5.2294 (5.9607)\tPrec@1 76.000 (72.571)\tPrec@5 99.000 (97.619)\n",
            "Test: [30/100]\tTime 0.023 (0.034)\tLoss 5.9300 (6.0772)\tPrec@1 75.000 (72.613)\tPrec@5 97.000 (97.290)\n",
            "Test: [40/100]\tTime 0.030 (0.032)\tLoss 6.0073 (6.0825)\tPrec@1 76.000 (72.732)\tPrec@5 96.000 (96.976)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 6.1873 (6.0647)\tPrec@1 73.000 (72.863)\tPrec@5 98.000 (97.098)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 5.6108 (6.1018)\tPrec@1 78.000 (72.754)\tPrec@5 98.000 (97.180)\n",
            "Test: [70/100]\tTime 0.050 (0.029)\tLoss 6.0953 (6.1237)\tPrec@1 74.000 (72.493)\tPrec@5 97.000 (97.268)\n",
            "Test: [80/100]\tTime 0.024 (0.029)\tLoss 5.7467 (6.1017)\tPrec@1 78.000 (72.580)\tPrec@5 99.000 (97.383)\n",
            "Test: [90/100]\tTime 0.027 (0.028)\tLoss 5.5427 (6.1249)\tPrec@1 77.000 (72.549)\tPrec@5 98.000 (97.352)\n",
            "val Results: Prec@1 72.550 Prec@5 97.370 Loss 6.13220\n",
            "val Class Accuracy: [0.933,0.977,0.837,0.652,0.723,0.586,0.636,0.659,0.693,0.559]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [61][0/110], lr: 0.01000\tTime 0.440 (0.440)\tData 0.358 (0.358)\tLoss 1.6269 (1.6269)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [61][10/110], lr: 0.01000\tTime 0.062 (0.102)\tData 0.015 (0.039)\tLoss 1.7629 (1.4990)\tPrec@1 90.625 (92.330)\tPrec@5 98.438 (99.290)\n",
            "Epoch: [61][20/110], lr: 0.01000\tTime 0.048 (0.080)\tData 0.000 (0.023)\tLoss 2.1620 (1.7439)\tPrec@1 89.062 (91.034)\tPrec@5 100.000 (99.405)\n",
            "Epoch: [61][30/110], lr: 0.01000\tTime 0.067 (0.075)\tData 0.007 (0.017)\tLoss 1.4154 (1.7426)\tPrec@1 91.406 (90.978)\tPrec@5 100.000 (99.471)\n",
            "Epoch: [61][40/110], lr: 0.01000\tTime 0.055 (0.071)\tData 0.000 (0.013)\tLoss 1.2531 (1.7211)\tPrec@1 92.969 (90.968)\tPrec@5 100.000 (99.486)\n",
            "Epoch: [61][50/110], lr: 0.01000\tTime 0.069 (0.069)\tData 0.001 (0.012)\tLoss 1.2581 (1.6608)\tPrec@1 92.188 (91.192)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [61][60/110], lr: 0.01000\tTime 0.051 (0.067)\tData 0.006 (0.010)\tLoss 2.0538 (1.6603)\tPrec@1 87.500 (91.214)\tPrec@5 100.000 (99.603)\n",
            "Epoch: [61][70/110], lr: 0.01000\tTime 0.043 (0.066)\tData 0.000 (0.010)\tLoss 2.1791 (1.6403)\tPrec@1 88.281 (91.318)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [61][80/110], lr: 0.01000\tTime 0.063 (0.065)\tData 0.007 (0.009)\tLoss 1.7023 (1.6575)\tPrec@1 90.625 (91.184)\tPrec@5 100.000 (99.605)\n",
            "Epoch: [61][90/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.006 (0.009)\tLoss 2.8153 (1.6994)\tPrec@1 85.938 (90.943)\tPrec@5 97.656 (99.554)\n",
            "Epoch: [61][100/110], lr: 0.01000\tTime 0.061 (0.064)\tData 0.007 (0.009)\tLoss 1.6669 (1.6759)\tPrec@1 91.406 (91.066)\tPrec@5 100.000 (99.575)\n",
            "Test: [0/100]\tTime 0.327 (0.327)\tLoss 5.7674 (5.7674)\tPrec@1 75.000 (75.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.037 (0.055)\tLoss 6.1868 (6.7558)\tPrec@1 70.000 (70.091)\tPrec@5 94.000 (97.273)\n",
            "Test: [20/100]\tTime 0.012 (0.041)\tLoss 6.1341 (6.7091)\tPrec@1 70.000 (69.857)\tPrec@5 99.000 (97.000)\n",
            "Test: [30/100]\tTime 0.035 (0.034)\tLoss 6.3981 (6.7888)\tPrec@1 71.000 (69.484)\tPrec@5 93.000 (96.871)\n",
            "Test: [40/100]\tTime 0.026 (0.033)\tLoss 7.0130 (6.7969)\tPrec@1 69.000 (69.463)\tPrec@5 97.000 (96.976)\n",
            "Test: [50/100]\tTime 0.038 (0.032)\tLoss 5.6840 (6.7134)\tPrec@1 79.000 (69.804)\tPrec@5 97.000 (97.059)\n",
            "Test: [60/100]\tTime 0.027 (0.031)\tLoss 6.4511 (6.7190)\tPrec@1 70.000 (69.852)\tPrec@5 97.000 (97.049)\n",
            "Test: [70/100]\tTime 0.028 (0.030)\tLoss 6.5123 (6.7307)\tPrec@1 73.000 (69.859)\tPrec@5 98.000 (97.056)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 6.2347 (6.6904)\tPrec@1 73.000 (70.148)\tPrec@5 98.000 (97.025)\n",
            "Test: [90/100]\tTime 0.033 (0.029)\tLoss 7.4359 (6.7667)\tPrec@1 67.000 (69.813)\tPrec@5 98.000 (97.055)\n",
            "val Results: Prec@1 69.850 Prec@5 97.020 Loss 6.78216\n",
            "val Class Accuracy: [0.952,0.994,0.677,0.652,0.776,0.564,0.656,0.674,0.535,0.505]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [62][0/110], lr: 0.01000\tTime 0.410 (0.410)\tData 0.287 (0.287)\tLoss 1.3128 (1.3128)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [62][10/110], lr: 0.01000\tTime 0.066 (0.101)\tData 0.003 (0.032)\tLoss 1.6189 (1.7028)\tPrec@1 90.625 (91.051)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [62][20/110], lr: 0.01000\tTime 0.065 (0.082)\tData 0.001 (0.019)\tLoss 1.9066 (1.7343)\tPrec@1 90.625 (90.960)\tPrec@5 100.000 (99.628)\n",
            "Epoch: [62][30/110], lr: 0.01000\tTime 0.050 (0.073)\tData 0.007 (0.015)\tLoss 0.9464 (1.6007)\tPrec@1 93.750 (91.759)\tPrec@5 100.000 (99.647)\n",
            "Epoch: [62][40/110], lr: 0.01000\tTime 0.045 (0.069)\tData 0.006 (0.013)\tLoss 1.8240 (1.6298)\tPrec@1 89.062 (91.482)\tPrec@5 99.219 (99.600)\n",
            "Epoch: [62][50/110], lr: 0.01000\tTime 0.063 (0.067)\tData 0.000 (0.011)\tLoss 1.8703 (1.6864)\tPrec@1 87.500 (91.115)\tPrec@5 99.219 (99.586)\n",
            "Epoch: [62][60/110], lr: 0.01000\tTime 0.058 (0.066)\tData 0.000 (0.010)\tLoss 1.9174 (1.6712)\tPrec@1 89.844 (91.227)\tPrec@5 100.000 (99.590)\n",
            "Epoch: [62][70/110], lr: 0.01000\tTime 0.070 (0.065)\tData 0.005 (0.009)\tLoss 0.9242 (1.6698)\tPrec@1 95.312 (91.197)\tPrec@5 99.219 (99.582)\n",
            "Epoch: [62][80/110], lr: 0.01000\tTime 0.052 (0.064)\tData 0.006 (0.009)\tLoss 1.5030 (1.7030)\tPrec@1 93.750 (91.020)\tPrec@5 98.438 (99.576)\n",
            "Epoch: [62][90/110], lr: 0.01000\tTime 0.058 (0.063)\tData 0.005 (0.009)\tLoss 1.5411 (1.7286)\tPrec@1 90.625 (90.848)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [62][100/110], lr: 0.01000\tTime 0.051 (0.063)\tData 0.012 (0.008)\tLoss 1.9564 (1.7427)\tPrec@1 90.625 (90.780)\tPrec@5 100.000 (99.551)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 6.4762 (6.4762)\tPrec@1 71.000 (71.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.026 (0.051)\tLoss 5.8514 (6.5746)\tPrec@1 75.000 (71.818)\tPrec@5 95.000 (96.909)\n",
            "Test: [20/100]\tTime 0.010 (0.036)\tLoss 6.1190 (6.5959)\tPrec@1 73.000 (70.810)\tPrec@5 98.000 (96.571)\n",
            "Test: [30/100]\tTime 0.041 (0.033)\tLoss 6.1693 (6.6915)\tPrec@1 74.000 (70.742)\tPrec@5 95.000 (96.516)\n",
            "Test: [40/100]\tTime 0.020 (0.031)\tLoss 6.9597 (6.6871)\tPrec@1 67.000 (70.659)\tPrec@5 95.000 (96.098)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 6.7360 (6.6463)\tPrec@1 69.000 (70.667)\tPrec@5 95.000 (96.235)\n",
            "Test: [60/100]\tTime 0.009 (0.030)\tLoss 6.0233 (6.7324)\tPrec@1 75.000 (70.148)\tPrec@5 94.000 (96.197)\n",
            "Test: [70/100]\tTime 0.016 (0.029)\tLoss 6.4251 (6.7910)\tPrec@1 69.000 (69.887)\tPrec@5 97.000 (96.056)\n",
            "Test: [80/100]\tTime 0.035 (0.029)\tLoss 6.0478 (6.7481)\tPrec@1 75.000 (69.938)\tPrec@5 99.000 (96.259)\n",
            "Test: [90/100]\tTime 0.034 (0.028)\tLoss 7.5486 (6.8587)\tPrec@1 63.000 (69.473)\tPrec@5 97.000 (96.242)\n",
            "val Results: Prec@1 69.250 Prec@5 96.180 Loss 6.90236\n",
            "val Class Accuracy: [0.912,0.952,0.691,0.793,0.902,0.468,0.479,0.532,0.469,0.727]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [63][0/110], lr: 0.01000\tTime 0.506 (0.506)\tData 0.427 (0.427)\tLoss 0.7502 (0.7502)\tPrec@1 97.656 (97.656)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [63][10/110], lr: 0.01000\tTime 0.065 (0.105)\tData 0.016 (0.043)\tLoss 1.6311 (1.5822)\tPrec@1 91.406 (91.974)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [63][20/110], lr: 0.01000\tTime 0.071 (0.084)\tData 0.000 (0.024)\tLoss 1.3160 (1.5906)\tPrec@1 92.188 (91.927)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [63][30/110], lr: 0.01000\tTime 0.069 (0.077)\tData 0.015 (0.019)\tLoss 1.6768 (1.6341)\tPrec@1 92.188 (91.809)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [63][40/110], lr: 0.01000\tTime 0.044 (0.071)\tData 0.000 (0.015)\tLoss 1.7623 (1.6692)\tPrec@1 91.406 (91.597)\tPrec@5 98.438 (99.657)\n",
            "Epoch: [63][50/110], lr: 0.01000\tTime 0.047 (0.069)\tData 0.004 (0.013)\tLoss 2.0424 (1.6876)\tPrec@1 88.281 (91.422)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [63][60/110], lr: 0.01000\tTime 0.041 (0.067)\tData 0.000 (0.012)\tLoss 1.1478 (1.6938)\tPrec@1 92.969 (91.304)\tPrec@5 98.438 (99.629)\n",
            "Epoch: [63][70/110], lr: 0.01000\tTime 0.054 (0.067)\tData 0.000 (0.011)\tLoss 0.8667 (1.7078)\tPrec@1 96.875 (91.318)\tPrec@5 100.000 (99.571)\n",
            "Epoch: [63][80/110], lr: 0.01000\tTime 0.061 (0.066)\tData 0.007 (0.010)\tLoss 1.1692 (1.7159)\tPrec@1 92.969 (91.242)\tPrec@5 100.000 (99.566)\n",
            "Epoch: [63][90/110], lr: 0.01000\tTime 0.053 (0.066)\tData 0.007 (0.010)\tLoss 1.5574 (1.7030)\tPrec@1 90.625 (91.269)\tPrec@5 99.219 (99.588)\n",
            "Epoch: [63][100/110], lr: 0.01000\tTime 0.068 (0.065)\tData 0.000 (0.009)\tLoss 1.2329 (1.7097)\tPrec@1 94.531 (91.213)\tPrec@5 98.438 (99.559)\n",
            "Test: [0/100]\tTime 0.307 (0.307)\tLoss 6.5381 (6.5381)\tPrec@1 69.000 (69.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.043 (0.059)\tLoss 6.0562 (7.5116)\tPrec@1 72.000 (66.364)\tPrec@5 94.000 (96.273)\n",
            "Test: [20/100]\tTime 0.020 (0.042)\tLoss 6.1507 (7.3954)\tPrec@1 74.000 (67.238)\tPrec@5 100.000 (96.286)\n",
            "Test: [30/100]\tTime 0.017 (0.036)\tLoss 7.5845 (7.4848)\tPrec@1 65.000 (67.000)\tPrec@5 95.000 (96.000)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 7.5959 (7.5579)\tPrec@1 70.000 (66.829)\tPrec@5 97.000 (95.951)\n",
            "Test: [50/100]\tTime 0.019 (0.033)\tLoss 7.3131 (7.4946)\tPrec@1 70.000 (67.137)\tPrec@5 99.000 (96.157)\n",
            "Test: [60/100]\tTime 0.023 (0.031)\tLoss 6.4866 (7.5173)\tPrec@1 72.000 (66.934)\tPrec@5 96.000 (96.098)\n",
            "Test: [70/100]\tTime 0.038 (0.031)\tLoss 7.2028 (7.4861)\tPrec@1 67.000 (67.127)\tPrec@5 97.000 (96.099)\n",
            "Test: [80/100]\tTime 0.030 (0.030)\tLoss 7.7143 (7.4831)\tPrec@1 68.000 (67.235)\tPrec@5 94.000 (96.160)\n",
            "Test: [90/100]\tTime 0.041 (0.030)\tLoss 8.9884 (7.5586)\tPrec@1 58.000 (66.791)\tPrec@5 97.000 (96.143)\n",
            "val Results: Prec@1 67.010 Prec@5 96.140 Loss 7.54493\n",
            "val Class Accuracy: [0.897,0.973,0.758,0.806,0.581,0.653,0.606,0.483,0.669,0.275]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [64][0/110], lr: 0.01000\tTime 0.512 (0.512)\tData 0.451 (0.451)\tLoss 1.5556 (1.5556)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [64][10/110], lr: 0.01000\tTime 0.063 (0.102)\tData 0.000 (0.045)\tLoss 1.2959 (1.7413)\tPrec@1 92.969 (90.909)\tPrec@5 99.219 (99.361)\n",
            "Epoch: [64][20/110], lr: 0.01000\tTime 0.058 (0.083)\tData 0.000 (0.025)\tLoss 1.8943 (1.7076)\tPrec@1 89.844 (91.183)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [64][30/110], lr: 0.01000\tTime 0.071 (0.076)\tData 0.008 (0.018)\tLoss 1.1876 (1.6555)\tPrec@1 93.750 (91.431)\tPrec@5 99.219 (99.521)\n",
            "Epoch: [64][40/110], lr: 0.01000\tTime 0.075 (0.071)\tData 0.010 (0.015)\tLoss 1.7397 (1.7079)\tPrec@1 89.844 (91.082)\tPrec@5 99.219 (99.562)\n",
            "Epoch: [64][50/110], lr: 0.01000\tTime 0.065 (0.069)\tData 0.000 (0.013)\tLoss 1.4511 (1.7623)\tPrec@1 92.188 (90.809)\tPrec@5 99.219 (99.617)\n",
            "Epoch: [64][60/110], lr: 0.01000\tTime 0.045 (0.068)\tData 0.000 (0.012)\tLoss 1.6818 (1.7450)\tPrec@1 91.406 (90.958)\tPrec@5 100.000 (99.629)\n",
            "Epoch: [64][70/110], lr: 0.01000\tTime 0.087 (0.067)\tData 0.000 (0.010)\tLoss 2.4304 (1.7371)\tPrec@1 83.594 (90.900)\tPrec@5 100.000 (99.637)\n",
            "Epoch: [64][80/110], lr: 0.01000\tTime 0.074 (0.066)\tData 0.005 (0.009)\tLoss 1.7964 (1.7268)\tPrec@1 89.062 (90.953)\tPrec@5 99.219 (99.643)\n",
            "Epoch: [64][90/110], lr: 0.01000\tTime 0.062 (0.065)\tData 0.005 (0.009)\tLoss 1.3247 (1.7126)\tPrec@1 94.531 (91.020)\tPrec@5 98.438 (99.631)\n",
            "Epoch: [64][100/110], lr: 0.01000\tTime 0.082 (0.065)\tData 0.007 (0.008)\tLoss 1.6516 (1.7260)\tPrec@1 88.281 (90.919)\tPrec@5 100.000 (99.613)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 8.6153 (8.6153)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.017 (0.054)\tLoss 6.8491 (8.6251)\tPrec@1 69.000 (62.182)\tPrec@5 95.000 (96.727)\n",
            "Test: [20/100]\tTime 0.033 (0.040)\tLoss 7.9336 (8.4666)\tPrec@1 64.000 (63.143)\tPrec@5 98.000 (96.524)\n",
            "Test: [30/100]\tTime 0.026 (0.036)\tLoss 8.1818 (8.6539)\tPrec@1 61.000 (62.452)\tPrec@5 95.000 (96.645)\n",
            "Test: [40/100]\tTime 0.034 (0.034)\tLoss 9.0674 (8.7249)\tPrec@1 60.000 (62.220)\tPrec@5 94.000 (96.512)\n",
            "Test: [50/100]\tTime 0.044 (0.032)\tLoss 8.7770 (8.6831)\tPrec@1 64.000 (62.431)\tPrec@5 99.000 (96.765)\n",
            "Test: [60/100]\tTime 0.029 (0.031)\tLoss 7.2607 (8.6622)\tPrec@1 70.000 (62.525)\tPrec@5 96.000 (96.738)\n",
            "Test: [70/100]\tTime 0.022 (0.030)\tLoss 8.1831 (8.6428)\tPrec@1 64.000 (62.577)\tPrec@5 98.000 (96.676)\n",
            "Test: [80/100]\tTime 0.025 (0.030)\tLoss 8.1343 (8.6041)\tPrec@1 64.000 (62.778)\tPrec@5 96.000 (96.728)\n",
            "Test: [90/100]\tTime 0.035 (0.031)\tLoss 9.9114 (8.6720)\tPrec@1 57.000 (62.473)\tPrec@5 96.000 (96.637)\n",
            "val Results: Prec@1 62.490 Prec@5 96.610 Loss 8.68597\n",
            "val Class Accuracy: [0.886,0.990,0.736,0.882,0.734,0.340,0.664,0.444,0.320,0.253]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [65][0/110], lr: 0.01000\tTime 0.592 (0.592)\tData 0.500 (0.500)\tLoss 1.7068 (1.7068)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [65][10/110], lr: 0.01000\tTime 0.097 (0.153)\tData 0.007 (0.055)\tLoss 2.0765 (1.7186)\tPrec@1 88.281 (91.051)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [65][20/110], lr: 0.01000\tTime 0.104 (0.126)\tData 0.003 (0.032)\tLoss 2.1164 (1.6780)\tPrec@1 88.281 (91.183)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [65][30/110], lr: 0.01000\tTime 0.042 (0.114)\tData 0.000 (0.024)\tLoss 1.2335 (1.5949)\tPrec@1 93.750 (91.633)\tPrec@5 99.219 (99.723)\n",
            "Epoch: [65][40/110], lr: 0.01000\tTime 0.041 (0.101)\tData 0.000 (0.019)\tLoss 1.1976 (1.5456)\tPrec@1 95.312 (91.864)\tPrec@5 100.000 (99.752)\n",
            "Epoch: [65][50/110], lr: 0.01000\tTime 0.050 (0.093)\tData 0.007 (0.016)\tLoss 1.3836 (1.5489)\tPrec@1 92.188 (91.881)\tPrec@5 99.219 (99.663)\n",
            "Epoch: [65][60/110], lr: 0.01000\tTime 0.063 (0.087)\tData 0.007 (0.015)\tLoss 1.4473 (1.5328)\tPrec@1 92.969 (91.944)\tPrec@5 100.000 (99.641)\n",
            "Epoch: [65][70/110], lr: 0.01000\tTime 0.043 (0.083)\tData 0.000 (0.013)\tLoss 1.6557 (1.5564)\tPrec@1 90.625 (91.791)\tPrec@5 99.219 (99.615)\n",
            "Epoch: [65][80/110], lr: 0.01000\tTime 0.070 (0.080)\tData 0.000 (0.013)\tLoss 1.6477 (1.5837)\tPrec@1 93.750 (91.667)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [65][90/110], lr: 0.01000\tTime 0.079 (0.078)\tData 0.004 (0.012)\tLoss 1.6201 (1.6198)\tPrec@1 92.188 (91.526)\tPrec@5 99.219 (99.588)\n",
            "Epoch: [65][100/110], lr: 0.01000\tTime 0.053 (0.076)\tData 0.005 (0.011)\tLoss 1.4888 (1.6448)\tPrec@1 91.406 (91.391)\tPrec@5 99.219 (99.575)\n",
            "Test: [0/100]\tTime 0.254 (0.254)\tLoss 5.9704 (5.9704)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.021 (0.056)\tLoss 5.2914 (6.7588)\tPrec@1 77.000 (68.909)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/100]\tTime 0.025 (0.041)\tLoss 6.8722 (6.8667)\tPrec@1 68.000 (68.190)\tPrec@5 96.000 (97.143)\n",
            "Test: [30/100]\tTime 0.037 (0.037)\tLoss 7.0721 (7.0274)\tPrec@1 65.000 (67.548)\tPrec@5 96.000 (96.742)\n",
            "Test: [40/100]\tTime 0.019 (0.034)\tLoss 7.2417 (7.0318)\tPrec@1 67.000 (67.732)\tPrec@5 97.000 (96.683)\n",
            "Test: [50/100]\tTime 0.019 (0.032)\tLoss 5.8318 (6.9077)\tPrec@1 72.000 (68.451)\tPrec@5 98.000 (96.902)\n",
            "Test: [60/100]\tTime 0.013 (0.031)\tLoss 7.5337 (6.9648)\tPrec@1 67.000 (68.180)\tPrec@5 96.000 (96.820)\n",
            "Test: [70/100]\tTime 0.027 (0.031)\tLoss 7.0010 (6.9608)\tPrec@1 67.000 (68.366)\tPrec@5 97.000 (96.775)\n",
            "Test: [80/100]\tTime 0.032 (0.030)\tLoss 6.9810 (6.9206)\tPrec@1 69.000 (68.481)\tPrec@5 98.000 (96.790)\n",
            "Test: [90/100]\tTime 0.028 (0.030)\tLoss 8.2882 (6.9961)\tPrec@1 60.000 (68.011)\tPrec@5 95.000 (96.692)\n",
            "val Results: Prec@1 67.970 Prec@5 96.730 Loss 7.00678\n",
            "val Class Accuracy: [0.979,0.949,0.572,0.662,0.562,0.546,0.764,0.543,0.564,0.656]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [66][0/110], lr: 0.01000\tTime 0.505 (0.505)\tData 0.386 (0.386)\tLoss 2.0496 (2.0496)\tPrec@1 90.625 (90.625)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [66][10/110], lr: 0.01000\tTime 0.074 (0.103)\tData 0.009 (0.038)\tLoss 1.5327 (1.6932)\tPrec@1 90.625 (91.051)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [66][20/110], lr: 0.01000\tTime 0.044 (0.081)\tData 0.000 (0.022)\tLoss 1.2973 (1.7156)\tPrec@1 92.969 (90.885)\tPrec@5 99.219 (99.293)\n",
            "Epoch: [66][30/110], lr: 0.01000\tTime 0.041 (0.074)\tData 0.000 (0.016)\tLoss 1.7110 (1.7006)\tPrec@1 90.625 (90.953)\tPrec@5 99.219 (99.370)\n",
            "Epoch: [66][40/110], lr: 0.01000\tTime 0.050 (0.070)\tData 0.000 (0.014)\tLoss 0.8021 (1.7281)\tPrec@1 97.656 (90.968)\tPrec@5 100.000 (99.390)\n",
            "Epoch: [66][50/110], lr: 0.01000\tTime 0.043 (0.068)\tData 0.000 (0.012)\tLoss 2.1484 (1.6787)\tPrec@1 87.500 (91.176)\tPrec@5 100.000 (99.464)\n",
            "Epoch: [66][60/110], lr: 0.01000\tTime 0.063 (0.066)\tData 0.005 (0.011)\tLoss 1.5541 (1.6548)\tPrec@1 92.188 (91.265)\tPrec@5 100.000 (99.488)\n",
            "Epoch: [66][70/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.000 (0.010)\tLoss 0.9443 (1.6180)\tPrec@1 95.312 (91.406)\tPrec@5 100.000 (99.538)\n",
            "Epoch: [66][80/110], lr: 0.01000\tTime 0.085 (0.064)\tData 0.014 (0.010)\tLoss 1.7316 (1.6511)\tPrec@1 91.406 (91.223)\tPrec@5 100.000 (99.556)\n",
            "Epoch: [66][90/110], lr: 0.01000\tTime 0.046 (0.064)\tData 0.007 (0.009)\tLoss 1.8393 (1.6849)\tPrec@1 89.844 (90.986)\tPrec@5 99.219 (99.545)\n",
            "Epoch: [66][100/110], lr: 0.01000\tTime 0.053 (0.063)\tData 0.000 (0.009)\tLoss 1.9780 (1.6970)\tPrec@1 88.281 (90.958)\tPrec@5 99.219 (99.536)\n",
            "Test: [0/100]\tTime 0.267 (0.267)\tLoss 5.1248 (5.1248)\tPrec@1 79.000 (79.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.029 (0.053)\tLoss 4.9755 (6.1666)\tPrec@1 78.000 (72.545)\tPrec@5 96.000 (97.818)\n",
            "Test: [20/100]\tTime 0.049 (0.040)\tLoss 5.6520 (6.1297)\tPrec@1 75.000 (72.714)\tPrec@5 99.000 (97.810)\n",
            "Test: [30/100]\tTime 0.009 (0.034)\tLoss 5.9417 (6.3325)\tPrec@1 74.000 (71.839)\tPrec@5 95.000 (97.484)\n",
            "Test: [40/100]\tTime 0.039 (0.031)\tLoss 6.0707 (6.3204)\tPrec@1 73.000 (71.976)\tPrec@5 97.000 (97.293)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 6.5239 (6.2642)\tPrec@1 72.000 (72.176)\tPrec@5 96.000 (97.471)\n",
            "Test: [60/100]\tTime 0.048 (0.031)\tLoss 7.0363 (6.3197)\tPrec@1 68.000 (71.852)\tPrec@5 99.000 (97.459)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 5.1657 (6.2928)\tPrec@1 76.000 (71.901)\tPrec@5 98.000 (97.423)\n",
            "Test: [80/100]\tTime 0.025 (0.029)\tLoss 5.3911 (6.2386)\tPrec@1 74.000 (72.074)\tPrec@5 98.000 (97.457)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 6.0418 (6.3002)\tPrec@1 72.000 (71.791)\tPrec@5 99.000 (97.527)\n",
            "val Results: Prec@1 71.800 Prec@5 97.500 Loss 6.31455\n",
            "val Class Accuracy: [0.913,0.973,0.844,0.534,0.761,0.469,0.883,0.675,0.698,0.430]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [67][0/110], lr: 0.01000\tTime 0.361 (0.361)\tData 0.279 (0.279)\tLoss 1.0308 (1.0308)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [67][10/110], lr: 0.01000\tTime 0.035 (0.100)\tData 0.000 (0.037)\tLoss 1.8128 (1.5809)\tPrec@1 91.406 (91.761)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [67][20/110], lr: 0.01000\tTime 0.055 (0.080)\tData 0.007 (0.021)\tLoss 1.1709 (1.5239)\tPrec@1 94.531 (92.076)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [67][30/110], lr: 0.01000\tTime 0.039 (0.072)\tData 0.000 (0.015)\tLoss 1.0423 (1.5535)\tPrec@1 94.531 (92.061)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [67][40/110], lr: 0.01000\tTime 0.036 (0.068)\tData 0.000 (0.013)\tLoss 1.6697 (1.5483)\tPrec@1 91.406 (92.130)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [67][50/110], lr: 0.01000\tTime 0.062 (0.067)\tData 0.010 (0.011)\tLoss 1.4105 (1.5778)\tPrec@1 92.969 (91.973)\tPrec@5 99.219 (99.678)\n",
            "Epoch: [67][60/110], lr: 0.01000\tTime 0.057 (0.065)\tData 0.000 (0.010)\tLoss 1.1349 (1.5796)\tPrec@1 93.750 (92.021)\tPrec@5 100.000 (99.641)\n",
            "Epoch: [67][70/110], lr: 0.01000\tTime 0.058 (0.064)\tData 0.006 (0.010)\tLoss 1.8080 (1.5731)\tPrec@1 91.406 (92.088)\tPrec@5 99.219 (99.637)\n",
            "Epoch: [67][80/110], lr: 0.01000\tTime 0.074 (0.064)\tData 0.007 (0.009)\tLoss 0.7561 (1.5793)\tPrec@1 95.312 (91.995)\tPrec@5 100.000 (99.576)\n",
            "Epoch: [67][90/110], lr: 0.01000\tTime 0.045 (0.063)\tData 0.002 (0.009)\tLoss 1.2618 (1.5840)\tPrec@1 92.969 (91.921)\tPrec@5 100.000 (99.588)\n",
            "Epoch: [67][100/110], lr: 0.01000\tTime 0.071 (0.063)\tData 0.002 (0.008)\tLoss 2.2682 (1.6262)\tPrec@1 87.500 (91.708)\tPrec@5 99.219 (99.567)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 7.9453 (7.9453)\tPrec@1 63.000 (63.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.030 (0.051)\tLoss 6.5426 (7.7784)\tPrec@1 70.000 (64.545)\tPrec@5 97.000 (96.636)\n",
            "Test: [20/100]\tTime 0.033 (0.040)\tLoss 6.0634 (7.8331)\tPrec@1 73.000 (64.524)\tPrec@5 97.000 (96.143)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 7.7635 (7.8967)\tPrec@1 64.000 (64.194)\tPrec@5 95.000 (95.871)\n",
            "Test: [40/100]\tTime 0.011 (0.032)\tLoss 7.5429 (7.8812)\tPrec@1 66.000 (64.122)\tPrec@5 94.000 (95.780)\n",
            "Test: [50/100]\tTime 0.031 (0.031)\tLoss 8.5686 (7.8987)\tPrec@1 62.000 (64.039)\tPrec@5 97.000 (96.000)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 7.0896 (7.9260)\tPrec@1 62.000 (63.525)\tPrec@5 96.000 (95.803)\n",
            "Test: [70/100]\tTime 0.023 (0.030)\tLoss 7.6405 (7.9488)\tPrec@1 66.000 (63.592)\tPrec@5 95.000 (95.803)\n",
            "Test: [80/100]\tTime 0.022 (0.029)\tLoss 7.0584 (7.8665)\tPrec@1 68.000 (63.901)\tPrec@5 96.000 (95.901)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 7.2670 (7.9143)\tPrec@1 68.000 (63.659)\tPrec@5 97.000 (95.879)\n",
            "val Results: Prec@1 63.480 Prec@5 95.870 Loss 7.94955\n",
            "val Class Accuracy: [0.984,0.959,0.810,0.415,0.724,0.426,0.626,0.585,0.406,0.413]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [68][0/110], lr: 0.01000\tTime 0.427 (0.427)\tData 0.336 (0.336)\tLoss 1.3088 (1.3088)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [68][10/110], lr: 0.01000\tTime 0.056 (0.098)\tData 0.011 (0.035)\tLoss 1.9322 (1.7446)\tPrec@1 89.062 (90.483)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [68][20/110], lr: 0.01000\tTime 0.057 (0.078)\tData 0.005 (0.021)\tLoss 2.2499 (1.7380)\tPrec@1 89.062 (90.699)\tPrec@5 99.219 (99.591)\n",
            "Epoch: [68][30/110], lr: 0.01000\tTime 0.037 (0.071)\tData 0.000 (0.016)\tLoss 1.1605 (1.7201)\tPrec@1 94.531 (91.028)\tPrec@5 100.000 (99.647)\n",
            "Epoch: [68][40/110], lr: 0.01000\tTime 0.058 (0.068)\tData 0.005 (0.013)\tLoss 1.3654 (1.7801)\tPrec@1 91.406 (90.777)\tPrec@5 100.000 (99.562)\n",
            "Epoch: [68][50/110], lr: 0.01000\tTime 0.075 (0.067)\tData 0.006 (0.011)\tLoss 1.0472 (1.7366)\tPrec@1 94.531 (91.039)\tPrec@5 98.438 (99.571)\n",
            "Epoch: [68][60/110], lr: 0.01000\tTime 0.084 (0.066)\tData 0.011 (0.010)\tLoss 2.6955 (1.7176)\tPrec@1 87.500 (91.112)\tPrec@5 99.219 (99.603)\n",
            "Epoch: [68][70/110], lr: 0.01000\tTime 0.078 (0.065)\tData 0.000 (0.009)\tLoss 1.5962 (1.7173)\tPrec@1 91.406 (91.032)\tPrec@5 100.000 (99.615)\n",
            "Epoch: [68][80/110], lr: 0.01000\tTime 0.074 (0.064)\tData 0.000 (0.008)\tLoss 1.5036 (1.6972)\tPrec@1 92.969 (91.088)\tPrec@5 100.000 (99.643)\n",
            "Epoch: [68][90/110], lr: 0.01000\tTime 0.080 (0.063)\tData 0.007 (0.008)\tLoss 1.9922 (1.7001)\tPrec@1 89.062 (91.046)\tPrec@5 100.000 (99.614)\n",
            "Epoch: [68][100/110], lr: 0.01000\tTime 0.055 (0.063)\tData 0.005 (0.008)\tLoss 1.1879 (1.6757)\tPrec@1 94.531 (91.221)\tPrec@5 99.219 (99.613)\n",
            "Test: [0/100]\tTime 0.249 (0.249)\tLoss 7.2046 (7.2046)\tPrec@1 65.000 (65.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.021 (0.054)\tLoss 6.2705 (7.4090)\tPrec@1 70.000 (66.000)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.038 (0.040)\tLoss 6.5711 (7.3981)\tPrec@1 69.000 (65.857)\tPrec@5 100.000 (96.905)\n",
            "Test: [30/100]\tTime 0.030 (0.035)\tLoss 7.4282 (7.4664)\tPrec@1 64.000 (65.871)\tPrec@5 97.000 (97.065)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 7.9943 (7.4672)\tPrec@1 64.000 (66.122)\tPrec@5 94.000 (96.707)\n",
            "Test: [50/100]\tTime 0.025 (0.031)\tLoss 7.2930 (7.4076)\tPrec@1 66.000 (66.392)\tPrec@5 98.000 (96.922)\n",
            "Test: [60/100]\tTime 0.031 (0.030)\tLoss 7.3759 (7.4354)\tPrec@1 65.000 (66.033)\tPrec@5 95.000 (96.885)\n",
            "Test: [70/100]\tTime 0.039 (0.030)\tLoss 8.1971 (7.4552)\tPrec@1 59.000 (65.901)\tPrec@5 97.000 (96.944)\n",
            "Test: [80/100]\tTime 0.011 (0.029)\tLoss 7.9934 (7.4271)\tPrec@1 65.000 (66.123)\tPrec@5 99.000 (97.037)\n",
            "Test: [90/100]\tTime 0.029 (0.028)\tLoss 6.7189 (7.4841)\tPrec@1 69.000 (65.846)\tPrec@5 99.000 (97.066)\n",
            "val Results: Prec@1 65.850 Prec@5 97.070 Loss 7.50890\n",
            "val Class Accuracy: [0.976,0.978,0.854,0.359,0.734,0.490,0.630,0.534,0.526,0.504]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [69][0/110], lr: 0.01000\tTime 0.461 (0.461)\tData 0.362 (0.362)\tLoss 1.8811 (1.8811)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [69][10/110], lr: 0.01000\tTime 0.065 (0.100)\tData 0.005 (0.036)\tLoss 2.4159 (1.6114)\tPrec@1 87.500 (91.548)\tPrec@5 100.000 (99.503)\n",
            "Epoch: [69][20/110], lr: 0.01000\tTime 0.053 (0.082)\tData 0.000 (0.021)\tLoss 1.0845 (1.6014)\tPrec@1 93.750 (91.518)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [69][30/110], lr: 0.01000\tTime 0.080 (0.075)\tData 0.007 (0.016)\tLoss 2.0211 (1.5756)\tPrec@1 89.844 (91.759)\tPrec@5 99.219 (99.698)\n",
            "Epoch: [69][40/110], lr: 0.01000\tTime 0.049 (0.071)\tData 0.006 (0.013)\tLoss 1.3515 (1.5802)\tPrec@1 94.531 (91.711)\tPrec@5 98.438 (99.543)\n",
            "Epoch: [69][50/110], lr: 0.01000\tTime 0.089 (0.070)\tData 0.007 (0.011)\tLoss 1.1418 (1.6330)\tPrec@1 92.969 (91.314)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [69][60/110], lr: 0.01000\tTime 0.060 (0.068)\tData 0.000 (0.010)\tLoss 1.6986 (1.6195)\tPrec@1 91.406 (91.355)\tPrec@5 99.219 (99.539)\n",
            "Epoch: [69][70/110], lr: 0.01000\tTime 0.059 (0.068)\tData 0.007 (0.009)\tLoss 1.4674 (1.6310)\tPrec@1 91.406 (91.340)\tPrec@5 100.000 (99.505)\n",
            "Epoch: [69][80/110], lr: 0.01000\tTime 0.071 (0.067)\tData 0.000 (0.009)\tLoss 2.5033 (1.6471)\tPrec@1 86.719 (91.262)\tPrec@5 98.438 (99.508)\n",
            "Epoch: [69][90/110], lr: 0.01000\tTime 0.093 (0.068)\tData 0.013 (0.008)\tLoss 1.7573 (1.6729)\tPrec@1 89.844 (91.046)\tPrec@5 100.000 (99.528)\n",
            "Epoch: [69][100/110], lr: 0.01000\tTime 0.057 (0.070)\tData 0.008 (0.008)\tLoss 1.1584 (1.6645)\tPrec@1 94.531 (91.074)\tPrec@5 100.000 (99.559)\n",
            "Test: [0/100]\tTime 0.449 (0.449)\tLoss 6.8496 (6.8496)\tPrec@1 70.000 (70.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.018 (0.076)\tLoss 6.4855 (7.1473)\tPrec@1 68.000 (68.545)\tPrec@5 95.000 (96.273)\n",
            "Test: [20/100]\tTime 0.023 (0.056)\tLoss 6.9040 (7.2895)\tPrec@1 67.000 (67.714)\tPrec@5 97.000 (95.952)\n",
            "Test: [30/100]\tTime 0.041 (0.052)\tLoss 7.8338 (7.3554)\tPrec@1 63.000 (67.065)\tPrec@5 96.000 (95.968)\n",
            "Test: [40/100]\tTime 0.039 (0.050)\tLoss 7.6374 (7.3527)\tPrec@1 66.000 (67.366)\tPrec@5 94.000 (95.902)\n",
            "Test: [50/100]\tTime 0.032 (0.048)\tLoss 7.7875 (7.3707)\tPrec@1 65.000 (67.137)\tPrec@5 99.000 (96.137)\n",
            "Test: [60/100]\tTime 0.027 (0.044)\tLoss 7.5648 (7.4221)\tPrec@1 62.000 (66.820)\tPrec@5 95.000 (96.098)\n",
            "Test: [70/100]\tTime 0.021 (0.041)\tLoss 6.5877 (7.4095)\tPrec@1 72.000 (66.789)\tPrec@5 93.000 (95.958)\n",
            "Test: [80/100]\tTime 0.017 (0.040)\tLoss 6.8799 (7.3635)\tPrec@1 69.000 (67.025)\tPrec@5 96.000 (95.951)\n",
            "Test: [90/100]\tTime 0.014 (0.038)\tLoss 7.5143 (7.4057)\tPrec@1 66.000 (66.890)\tPrec@5 95.000 (95.967)\n",
            "val Results: Prec@1 66.850 Prec@5 95.930 Loss 7.41668\n",
            "val Class Accuracy: [0.906,0.986,0.862,0.679,0.668,0.455,0.564,0.578,0.534,0.453]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [70][0/110], lr: 0.01000\tTime 0.486 (0.486)\tData 0.412 (0.412)\tLoss 2.2055 (2.2055)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [70][10/110], lr: 0.01000\tTime 0.059 (0.103)\tData 0.009 (0.041)\tLoss 1.2732 (1.5080)\tPrec@1 93.750 (92.116)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [70][20/110], lr: 0.01000\tTime 0.060 (0.082)\tData 0.000 (0.023)\tLoss 1.4167 (1.4996)\tPrec@1 93.750 (92.188)\tPrec@5 99.219 (99.479)\n",
            "Epoch: [70][30/110], lr: 0.01000\tTime 0.063 (0.076)\tData 0.001 (0.017)\tLoss 1.1429 (1.4868)\tPrec@1 94.531 (92.288)\tPrec@5 99.219 (99.572)\n",
            "Epoch: [70][40/110], lr: 0.01000\tTime 0.068 (0.071)\tData 0.000 (0.014)\tLoss 1.4318 (1.4986)\tPrec@1 92.188 (92.226)\tPrec@5 99.219 (99.543)\n",
            "Epoch: [70][50/110], lr: 0.01000\tTime 0.071 (0.070)\tData 0.007 (0.011)\tLoss 2.5544 (1.5417)\tPrec@1 85.938 (91.973)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [70][60/110], lr: 0.01000\tTime 0.048 (0.068)\tData 0.000 (0.010)\tLoss 2.1052 (1.6040)\tPrec@1 88.281 (91.611)\tPrec@5 100.000 (99.501)\n",
            "Epoch: [70][70/110], lr: 0.01000\tTime 0.062 (0.067)\tData 0.008 (0.009)\tLoss 1.6758 (1.5960)\tPrec@1 92.188 (91.648)\tPrec@5 99.219 (99.516)\n",
            "Epoch: [70][80/110], lr: 0.01000\tTime 0.070 (0.066)\tData 0.007 (0.009)\tLoss 1.9591 (1.6016)\tPrec@1 88.281 (91.609)\tPrec@5 99.219 (99.518)\n",
            "Epoch: [70][90/110], lr: 0.01000\tTime 0.052 (0.065)\tData 0.008 (0.009)\tLoss 1.9309 (1.5958)\tPrec@1 89.062 (91.604)\tPrec@5 99.219 (99.528)\n",
            "Epoch: [70][100/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.006 (0.008)\tLoss 2.2709 (1.5959)\tPrec@1 89.062 (91.576)\tPrec@5 99.219 (99.544)\n",
            "Test: [0/100]\tTime 0.339 (0.339)\tLoss 8.6817 (8.6817)\tPrec@1 61.000 (61.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.010 (0.049)\tLoss 7.4373 (8.4492)\tPrec@1 67.000 (63.000)\tPrec@5 94.000 (96.273)\n",
            "Test: [20/100]\tTime 0.033 (0.039)\tLoss 6.8211 (8.3712)\tPrec@1 67.000 (62.762)\tPrec@5 99.000 (96.524)\n",
            "Test: [30/100]\tTime 0.022 (0.033)\tLoss 8.2390 (8.3991)\tPrec@1 58.000 (62.774)\tPrec@5 97.000 (96.677)\n",
            "Test: [40/100]\tTime 0.029 (0.032)\tLoss 9.3028 (8.3500)\tPrec@1 58.000 (63.244)\tPrec@5 96.000 (96.610)\n",
            "Test: [50/100]\tTime 0.029 (0.031)\tLoss 7.6476 (8.3009)\tPrec@1 66.000 (63.373)\tPrec@5 97.000 (96.686)\n",
            "Test: [60/100]\tTime 0.036 (0.031)\tLoss 7.2439 (8.2997)\tPrec@1 64.000 (63.180)\tPrec@5 97.000 (96.787)\n",
            "Test: [70/100]\tTime 0.032 (0.030)\tLoss 9.2871 (8.3052)\tPrec@1 58.000 (63.169)\tPrec@5 97.000 (96.718)\n",
            "Test: [80/100]\tTime 0.016 (0.029)\tLoss 6.7141 (8.2469)\tPrec@1 70.000 (63.407)\tPrec@5 98.000 (96.753)\n",
            "Test: [90/100]\tTime 0.032 (0.029)\tLoss 7.9886 (8.3166)\tPrec@1 65.000 (63.088)\tPrec@5 97.000 (96.769)\n",
            "val Results: Prec@1 63.210 Prec@5 96.720 Loss 8.31258\n",
            "val Class Accuracy: [0.964,0.954,0.861,0.508,0.723,0.660,0.459,0.427,0.272,0.493]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [71][0/110], lr: 0.01000\tTime 0.402 (0.402)\tData 0.311 (0.311)\tLoss 0.8913 (0.8913)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [71][10/110], lr: 0.01000\tTime 0.040 (0.103)\tData 0.000 (0.034)\tLoss 1.3991 (1.7998)\tPrec@1 92.969 (90.696)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [71][20/110], lr: 0.01000\tTime 0.043 (0.084)\tData 0.000 (0.019)\tLoss 1.6847 (1.8533)\tPrec@1 89.844 (90.439)\tPrec@5 100.000 (99.442)\n",
            "Epoch: [71][30/110], lr: 0.01000\tTime 0.066 (0.075)\tData 0.008 (0.014)\tLoss 1.8292 (1.8144)\tPrec@1 89.844 (90.575)\tPrec@5 100.000 (99.420)\n",
            "Epoch: [71][40/110], lr: 0.01000\tTime 0.062 (0.072)\tData 0.013 (0.012)\tLoss 1.4037 (1.7041)\tPrec@1 92.188 (91.082)\tPrec@5 98.438 (99.505)\n",
            "Epoch: [71][50/110], lr: 0.01000\tTime 0.074 (0.070)\tData 0.004 (0.011)\tLoss 1.5540 (1.6685)\tPrec@1 92.969 (91.299)\tPrec@5 100.000 (99.556)\n",
            "Epoch: [71][60/110], lr: 0.01000\tTime 0.043 (0.068)\tData 0.000 (0.009)\tLoss 1.2657 (1.6181)\tPrec@1 92.969 (91.598)\tPrec@5 100.000 (99.577)\n",
            "Epoch: [71][70/110], lr: 0.01000\tTime 0.055 (0.067)\tData 0.010 (0.009)\tLoss 1.8488 (1.6399)\tPrec@1 89.062 (91.395)\tPrec@5 100.000 (99.582)\n",
            "Epoch: [71][80/110], lr: 0.01000\tTime 0.043 (0.066)\tData 0.002 (0.009)\tLoss 1.4145 (1.6099)\tPrec@1 92.969 (91.551)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [71][90/110], lr: 0.01000\tTime 0.052 (0.065)\tData 0.000 (0.008)\tLoss 1.5423 (1.6008)\tPrec@1 93.750 (91.638)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [71][100/110], lr: 0.01000\tTime 0.066 (0.064)\tData 0.000 (0.008)\tLoss 1.8989 (1.6163)\tPrec@1 89.062 (91.491)\tPrec@5 99.219 (99.636)\n",
            "Test: [0/100]\tTime 0.246 (0.246)\tLoss 7.3835 (7.3835)\tPrec@1 64.000 (64.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.026 (0.052)\tLoss 6.4573 (7.6150)\tPrec@1 72.000 (65.545)\tPrec@5 96.000 (96.273)\n",
            "Test: [20/100]\tTime 0.016 (0.040)\tLoss 6.6689 (7.5677)\tPrec@1 68.000 (65.905)\tPrec@5 99.000 (96.619)\n",
            "Test: [30/100]\tTime 0.041 (0.036)\tLoss 6.9001 (7.6561)\tPrec@1 68.000 (65.806)\tPrec@5 97.000 (96.419)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 8.5557 (7.7432)\tPrec@1 62.000 (65.415)\tPrec@5 92.000 (96.171)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 8.2852 (7.7510)\tPrec@1 61.000 (65.275)\tPrec@5 98.000 (96.294)\n",
            "Test: [60/100]\tTime 0.025 (0.030)\tLoss 6.4802 (7.7164)\tPrec@1 69.000 (65.344)\tPrec@5 99.000 (96.377)\n",
            "Test: [70/100]\tTime 0.040 (0.030)\tLoss 7.8442 (7.7476)\tPrec@1 69.000 (65.225)\tPrec@5 97.000 (96.451)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 6.8338 (7.7488)\tPrec@1 70.000 (65.235)\tPrec@5 97.000 (96.457)\n",
            "Test: [90/100]\tTime 0.026 (0.029)\tLoss 8.5947 (7.8125)\tPrec@1 63.000 (64.857)\tPrec@5 99.000 (96.451)\n",
            "val Results: Prec@1 64.890 Prec@5 96.420 Loss 7.82295\n",
            "val Class Accuracy: [0.942,0.957,0.815,0.676,0.829,0.311,0.739,0.414,0.553,0.253]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [72][0/110], lr: 0.01000\tTime 0.397 (0.397)\tData 0.294 (0.294)\tLoss 2.0337 (2.0337)\tPrec@1 88.281 (88.281)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [72][10/110], lr: 0.01000\tTime 0.044 (0.100)\tData 0.000 (0.032)\tLoss 1.0279 (1.4650)\tPrec@1 96.875 (92.330)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [72][20/110], lr: 0.01000\tTime 0.049 (0.080)\tData 0.000 (0.020)\tLoss 1.9881 (1.5241)\tPrec@1 89.844 (91.890)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [72][30/110], lr: 0.01000\tTime 0.051 (0.074)\tData 0.000 (0.015)\tLoss 1.3326 (1.5772)\tPrec@1 92.969 (91.633)\tPrec@5 99.219 (99.597)\n",
            "Epoch: [72][40/110], lr: 0.01000\tTime 0.061 (0.070)\tData 0.001 (0.013)\tLoss 1.6230 (1.5690)\tPrec@1 91.406 (91.616)\tPrec@5 100.000 (99.600)\n",
            "Epoch: [72][50/110], lr: 0.01000\tTime 0.059 (0.068)\tData 0.006 (0.011)\tLoss 1.5968 (1.5492)\tPrec@1 92.969 (91.743)\tPrec@5 100.000 (99.632)\n",
            "Epoch: [72][60/110], lr: 0.01000\tTime 0.041 (0.067)\tData 0.006 (0.010)\tLoss 1.6630 (1.5458)\tPrec@1 92.188 (91.790)\tPrec@5 100.000 (99.654)\n",
            "Epoch: [72][70/110], lr: 0.01000\tTime 0.083 (0.066)\tData 0.007 (0.010)\tLoss 1.5149 (1.5473)\tPrec@1 92.969 (91.791)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [72][80/110], lr: 0.01000\tTime 0.046 (0.066)\tData 0.011 (0.009)\tLoss 1.6105 (1.5472)\tPrec@1 92.188 (91.840)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [72][90/110], lr: 0.01000\tTime 0.066 (0.065)\tData 0.000 (0.009)\tLoss 1.5888 (1.5611)\tPrec@1 90.625 (91.724)\tPrec@5 99.219 (99.631)\n",
            "Epoch: [72][100/110], lr: 0.01000\tTime 0.068 (0.065)\tData 0.007 (0.008)\tLoss 2.0422 (1.5686)\tPrec@1 89.062 (91.669)\tPrec@5 100.000 (99.629)\n",
            "Test: [0/100]\tTime 0.322 (0.322)\tLoss 9.0722 (9.0722)\tPrec@1 63.000 (63.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.039 (0.058)\tLoss 7.1052 (7.8829)\tPrec@1 67.000 (65.818)\tPrec@5 93.000 (96.364)\n",
            "Test: [20/100]\tTime 0.020 (0.038)\tLoss 6.7339 (7.9031)\tPrec@1 70.000 (65.619)\tPrec@5 100.000 (96.000)\n",
            "Test: [30/100]\tTime 0.031 (0.037)\tLoss 7.7920 (7.9473)\tPrec@1 64.000 (65.419)\tPrec@5 97.000 (96.032)\n",
            "Test: [40/100]\tTime 0.027 (0.034)\tLoss 7.8658 (7.9889)\tPrec@1 65.000 (65.268)\tPrec@5 95.000 (95.756)\n",
            "Test: [50/100]\tTime 0.021 (0.033)\tLoss 8.6967 (7.9195)\tPrec@1 60.000 (65.392)\tPrec@5 95.000 (95.882)\n",
            "Test: [60/100]\tTime 0.025 (0.031)\tLoss 6.6847 (7.9593)\tPrec@1 70.000 (65.000)\tPrec@5 96.000 (95.820)\n",
            "Test: [70/100]\tTime 0.033 (0.031)\tLoss 7.7230 (7.9528)\tPrec@1 61.000 (64.972)\tPrec@5 95.000 (95.732)\n",
            "Test: [80/100]\tTime 0.020 (0.030)\tLoss 6.6753 (7.9198)\tPrec@1 72.000 (65.210)\tPrec@5 94.000 (95.790)\n",
            "Test: [90/100]\tTime 0.013 (0.029)\tLoss 8.1038 (7.9980)\tPrec@1 63.000 (64.890)\tPrec@5 98.000 (95.703)\n",
            "val Results: Prec@1 64.970 Prec@5 95.660 Loss 7.99308\n",
            "val Class Accuracy: [0.966,0.974,0.785,0.794,0.716,0.478,0.325,0.540,0.385,0.534]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [73][0/110], lr: 0.01000\tTime 0.458 (0.458)\tData 0.337 (0.337)\tLoss 1.6290 (1.6290)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [73][10/110], lr: 0.01000\tTime 0.057 (0.102)\tData 0.000 (0.033)\tLoss 1.9159 (1.5893)\tPrec@1 89.844 (91.477)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [73][20/110], lr: 0.01000\tTime 0.040 (0.080)\tData 0.000 (0.020)\tLoss 1.7225 (1.8063)\tPrec@1 89.844 (90.253)\tPrec@5 99.219 (99.628)\n",
            "Epoch: [73][30/110], lr: 0.01000\tTime 0.060 (0.074)\tData 0.001 (0.015)\tLoss 1.9286 (1.8489)\tPrec@1 90.625 (89.995)\tPrec@5 99.219 (99.597)\n",
            "Epoch: [73][40/110], lr: 0.01000\tTime 0.040 (0.070)\tData 0.000 (0.012)\tLoss 1.0074 (1.7997)\tPrec@1 94.531 (90.358)\tPrec@5 100.000 (99.600)\n",
            "Epoch: [73][50/110], lr: 0.01000\tTime 0.057 (0.068)\tData 0.007 (0.011)\tLoss 2.3095 (1.7615)\tPrec@1 87.500 (90.610)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [73][60/110], lr: 0.01000\tTime 0.060 (0.067)\tData 0.008 (0.010)\tLoss 1.4865 (1.7165)\tPrec@1 92.188 (90.958)\tPrec@5 97.656 (99.577)\n",
            "Epoch: [73][70/110], lr: 0.01000\tTime 0.074 (0.066)\tData 0.001 (0.009)\tLoss 1.5614 (1.6786)\tPrec@1 91.406 (91.219)\tPrec@5 100.000 (99.593)\n",
            "Epoch: [73][80/110], lr: 0.01000\tTime 0.054 (0.065)\tData 0.000 (0.009)\tLoss 1.0897 (1.6434)\tPrec@1 93.750 (91.397)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [73][90/110], lr: 0.01000\tTime 0.062 (0.065)\tData 0.007 (0.009)\tLoss 1.8456 (1.6487)\tPrec@1 90.625 (91.320)\tPrec@5 100.000 (99.622)\n",
            "Epoch: [73][100/110], lr: 0.01000\tTime 0.048 (0.064)\tData 0.007 (0.008)\tLoss 1.4507 (1.6487)\tPrec@1 92.969 (91.290)\tPrec@5 99.219 (99.598)\n",
            "Test: [0/100]\tTime 0.321 (0.321)\tLoss 6.4573 (6.4573)\tPrec@1 69.000 (69.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.010 (0.053)\tLoss 6.8075 (7.1095)\tPrec@1 68.000 (68.273)\tPrec@5 96.000 (96.455)\n",
            "Test: [20/100]\tTime 0.010 (0.039)\tLoss 5.8732 (6.9112)\tPrec@1 71.000 (68.762)\tPrec@5 99.000 (96.524)\n",
            "Test: [30/100]\tTime 0.037 (0.035)\tLoss 6.7180 (6.8830)\tPrec@1 70.000 (69.032)\tPrec@5 95.000 (96.226)\n",
            "Test: [40/100]\tTime 0.029 (0.034)\tLoss 7.1166 (6.8502)\tPrec@1 70.000 (69.268)\tPrec@5 94.000 (96.268)\n",
            "Test: [50/100]\tTime 0.026 (0.032)\tLoss 6.6193 (6.8443)\tPrec@1 70.000 (69.235)\tPrec@5 96.000 (96.431)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 5.5308 (6.8925)\tPrec@1 75.000 (69.000)\tPrec@5 97.000 (96.459)\n",
            "Test: [70/100]\tTime 0.022 (0.029)\tLoss 6.4204 (6.9036)\tPrec@1 74.000 (69.183)\tPrec@5 95.000 (96.394)\n",
            "Test: [80/100]\tTime 0.010 (0.029)\tLoss 6.2401 (6.8748)\tPrec@1 73.000 (69.173)\tPrec@5 96.000 (96.481)\n",
            "Test: [90/100]\tTime 0.033 (0.029)\tLoss 6.7539 (6.9528)\tPrec@1 72.000 (68.813)\tPrec@5 97.000 (96.418)\n",
            "val Results: Prec@1 68.830 Prec@5 96.380 Loss 6.96765\n",
            "val Class Accuracy: [0.933,0.917,0.880,0.382,0.739,0.672,0.653,0.681,0.559,0.467]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [74][0/110], lr: 0.01000\tTime 0.366 (0.366)\tData 0.278 (0.278)\tLoss 1.8539 (1.8539)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [74][10/110], lr: 0.01000\tTime 0.061 (0.100)\tData 0.005 (0.034)\tLoss 1.7856 (1.4591)\tPrec@1 90.625 (91.974)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [74][20/110], lr: 0.01000\tTime 0.043 (0.081)\tData 0.000 (0.020)\tLoss 1.2380 (1.3718)\tPrec@1 93.750 (92.671)\tPrec@5 99.219 (99.702)\n",
            "Epoch: [74][30/110], lr: 0.01000\tTime 0.052 (0.075)\tData 0.007 (0.016)\tLoss 1.2058 (1.3831)\tPrec@1 93.750 (92.717)\tPrec@5 100.000 (99.698)\n",
            "Epoch: [74][40/110], lr: 0.01000\tTime 0.072 (0.072)\tData 0.000 (0.014)\tLoss 1.3859 (1.3990)\tPrec@1 92.188 (92.702)\tPrec@5 99.219 (99.638)\n",
            "Epoch: [74][50/110], lr: 0.01000\tTime 0.085 (0.072)\tData 0.000 (0.011)\tLoss 0.7785 (1.4227)\tPrec@1 96.875 (92.632)\tPrec@5 99.219 (99.648)\n",
            "Epoch: [74][60/110], lr: 0.01000\tTime 0.098 (0.075)\tData 0.008 (0.010)\tLoss 1.0714 (1.4500)\tPrec@1 95.312 (92.469)\tPrec@5 100.000 (99.616)\n",
            "Epoch: [74][70/110], lr: 0.01000\tTime 0.070 (0.076)\tData 0.000 (0.009)\tLoss 1.2175 (1.4810)\tPrec@1 93.750 (92.287)\tPrec@5 99.219 (99.615)\n",
            "Epoch: [74][80/110], lr: 0.01000\tTime 0.105 (0.078)\tData 0.006 (0.009)\tLoss 1.6207 (1.4810)\tPrec@1 92.969 (92.303)\tPrec@5 100.000 (99.624)\n",
            "Epoch: [74][90/110], lr: 0.01000\tTime 0.061 (0.079)\tData 0.000 (0.009)\tLoss 2.2944 (1.5039)\tPrec@1 86.719 (92.196)\tPrec@5 99.219 (99.596)\n",
            "Epoch: [74][100/110], lr: 0.01000\tTime 0.046 (0.079)\tData 0.008 (0.008)\tLoss 2.5399 (1.5379)\tPrec@1 85.156 (91.979)\tPrec@5 100.000 (99.590)\n",
            "Test: [0/100]\tTime 0.279 (0.279)\tLoss 5.8944 (5.8944)\tPrec@1 76.000 (76.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.021 (0.050)\tLoss 5.8987 (6.6574)\tPrec@1 74.000 (70.000)\tPrec@5 97.000 (98.636)\n",
            "Test: [20/100]\tTime 0.031 (0.042)\tLoss 6.8423 (6.6537)\tPrec@1 69.000 (69.905)\tPrec@5 100.000 (98.143)\n",
            "Test: [30/100]\tTime 0.023 (0.034)\tLoss 7.1563 (6.8127)\tPrec@1 68.000 (69.065)\tPrec@5 97.000 (97.839)\n",
            "Test: [40/100]\tTime 0.022 (0.033)\tLoss 7.5995 (6.8783)\tPrec@1 64.000 (68.927)\tPrec@5 95.000 (97.512)\n",
            "Test: [50/100]\tTime 0.035 (0.032)\tLoss 7.2239 (6.8291)\tPrec@1 66.000 (69.137)\tPrec@5 97.000 (97.627)\n",
            "Test: [60/100]\tTime 0.020 (0.032)\tLoss 7.5464 (6.9063)\tPrec@1 64.000 (68.754)\tPrec@5 100.000 (97.672)\n",
            "Test: [70/100]\tTime 0.035 (0.030)\tLoss 4.6958 (6.8948)\tPrec@1 81.000 (68.958)\tPrec@5 98.000 (97.662)\n",
            "Test: [80/100]\tTime 0.013 (0.031)\tLoss 6.3367 (6.8696)\tPrec@1 74.000 (69.049)\tPrec@5 98.000 (97.704)\n",
            "Test: [90/100]\tTime 0.027 (0.030)\tLoss 6.9756 (6.8647)\tPrec@1 71.000 (69.231)\tPrec@5 99.000 (97.714)\n",
            "val Results: Prec@1 69.330 Prec@5 97.700 Loss 6.85677\n",
            "val Class Accuracy: [0.889,0.972,0.763,0.882,0.718,0.131,0.627,0.752,0.640,0.559]\n",
            "Best Prec@1: 72.550\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [75][0/110], lr: 0.01000\tTime 0.382 (0.382)\tData 0.289 (0.289)\tLoss 1.6179 (1.6179)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][10/110], lr: 0.01000\tTime 0.056 (0.108)\tData 0.000 (0.036)\tLoss 1.3250 (1.5933)\tPrec@1 92.969 (91.690)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [75][20/110], lr: 0.01000\tTime 0.094 (0.088)\tData 0.011 (0.021)\tLoss 1.4445 (1.5645)\tPrec@1 92.969 (91.815)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [75][30/110], lr: 0.01000\tTime 0.044 (0.079)\tData 0.000 (0.016)\tLoss 1.1800 (1.6125)\tPrec@1 92.969 (91.482)\tPrec@5 99.219 (99.597)\n",
            "Epoch: [75][40/110], lr: 0.01000\tTime 0.058 (0.075)\tData 0.007 (0.013)\tLoss 1.9613 (1.6224)\tPrec@1 90.625 (91.502)\tPrec@5 100.000 (99.600)\n",
            "Epoch: [75][50/110], lr: 0.01000\tTime 0.071 (0.073)\tData 0.001 (0.012)\tLoss 1.4621 (1.5910)\tPrec@1 94.531 (91.682)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [75][60/110], lr: 0.01000\tTime 0.065 (0.070)\tData 0.005 (0.010)\tLoss 0.9221 (1.5766)\tPrec@1 94.531 (91.739)\tPrec@5 100.000 (99.603)\n",
            "Epoch: [75][70/110], lr: 0.01000\tTime 0.076 (0.069)\tData 0.012 (0.010)\tLoss 2.7009 (1.5775)\tPrec@1 85.938 (91.769)\tPrec@5 100.000 (99.637)\n",
            "Epoch: [75][80/110], lr: 0.01000\tTime 0.054 (0.067)\tData 0.011 (0.009)\tLoss 1.2099 (1.5465)\tPrec@1 92.188 (91.889)\tPrec@5 99.219 (99.653)\n",
            "Epoch: [75][90/110], lr: 0.01000\tTime 0.041 (0.067)\tData 0.000 (0.009)\tLoss 0.9909 (1.5515)\tPrec@1 94.531 (91.827)\tPrec@5 100.000 (99.648)\n",
            "Epoch: [75][100/110], lr: 0.01000\tTime 0.072 (0.066)\tData 0.000 (0.009)\tLoss 2.6386 (1.5442)\tPrec@1 86.719 (91.870)\tPrec@5 99.219 (99.621)\n",
            "Test: [0/100]\tTime 0.251 (0.251)\tLoss 5.1125 (5.1125)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.022 (0.050)\tLoss 5.1228 (5.7440)\tPrec@1 76.000 (73.091)\tPrec@5 97.000 (98.364)\n",
            "Test: [20/100]\tTime 0.035 (0.037)\tLoss 4.9113 (5.6957)\tPrec@1 77.000 (74.143)\tPrec@5 100.000 (97.905)\n",
            "Test: [30/100]\tTime 0.023 (0.035)\tLoss 5.7128 (5.7541)\tPrec@1 74.000 (73.935)\tPrec@5 96.000 (97.742)\n",
            "Test: [40/100]\tTime 0.028 (0.033)\tLoss 6.7860 (5.7732)\tPrec@1 71.000 (73.854)\tPrec@5 96.000 (97.780)\n",
            "Test: [50/100]\tTime 0.022 (0.031)\tLoss 5.2190 (5.6788)\tPrec@1 78.000 (74.451)\tPrec@5 97.000 (97.882)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 5.8406 (5.7593)\tPrec@1 76.000 (74.049)\tPrec@5 98.000 (97.820)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 5.6743 (5.7622)\tPrec@1 74.000 (74.085)\tPrec@5 99.000 (97.859)\n",
            "Test: [80/100]\tTime 0.031 (0.029)\tLoss 5.1534 (5.7262)\tPrec@1 80.000 (74.235)\tPrec@5 98.000 (97.926)\n",
            "Test: [90/100]\tTime 0.015 (0.029)\tLoss 5.2872 (5.7689)\tPrec@1 76.000 (73.956)\tPrec@5 97.000 (97.934)\n",
            "val Results: Prec@1 73.880 Prec@5 97.960 Loss 5.77924\n",
            "val Class Accuracy: [0.954,0.957,0.776,0.678,0.763,0.570,0.643,0.707,0.671,0.669]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [76][0/110], lr: 0.01000\tTime 0.481 (0.481)\tData 0.408 (0.408)\tLoss 1.4732 (1.4732)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [76][10/110], lr: 0.01000\tTime 0.060 (0.104)\tData 0.010 (0.042)\tLoss 1.2435 (1.3917)\tPrec@1 95.312 (92.898)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [76][20/110], lr: 0.01000\tTime 0.051 (0.082)\tData 0.000 (0.025)\tLoss 1.9492 (1.3850)\tPrec@1 90.625 (92.894)\tPrec@5 99.219 (99.554)\n",
            "Epoch: [76][30/110], lr: 0.01000\tTime 0.060 (0.075)\tData 0.007 (0.018)\tLoss 1.0201 (1.3991)\tPrec@1 96.094 (92.717)\tPrec@5 100.000 (99.546)\n",
            "Epoch: [76][40/110], lr: 0.01000\tTime 0.073 (0.072)\tData 0.006 (0.015)\tLoss 1.2246 (1.4033)\tPrec@1 92.969 (92.702)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [76][50/110], lr: 0.01000\tTime 0.047 (0.069)\tData 0.000 (0.013)\tLoss 2.2992 (1.4268)\tPrec@1 88.281 (92.555)\tPrec@5 100.000 (99.602)\n",
            "Epoch: [76][60/110], lr: 0.01000\tTime 0.054 (0.067)\tData 0.006 (0.012)\tLoss 1.0687 (1.4391)\tPrec@1 94.531 (92.520)\tPrec@5 100.000 (99.577)\n",
            "Epoch: [76][70/110], lr: 0.01000\tTime 0.060 (0.066)\tData 0.007 (0.011)\tLoss 1.9691 (1.4776)\tPrec@1 89.844 (92.243)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [76][80/110], lr: 0.01000\tTime 0.051 (0.065)\tData 0.001 (0.010)\tLoss 1.3119 (1.5074)\tPrec@1 93.750 (92.168)\tPrec@5 99.219 (99.547)\n",
            "Epoch: [76][90/110], lr: 0.01000\tTime 0.049 (0.064)\tData 0.000 (0.010)\tLoss 1.6131 (1.5201)\tPrec@1 90.625 (92.110)\tPrec@5 99.219 (99.536)\n",
            "Epoch: [76][100/110], lr: 0.01000\tTime 0.097 (0.063)\tData 0.007 (0.010)\tLoss 1.0187 (1.5410)\tPrec@1 94.531 (91.986)\tPrec@5 100.000 (99.544)\n",
            "Test: [0/100]\tTime 0.243 (0.243)\tLoss 5.9222 (5.9222)\tPrec@1 77.000 (77.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.037 (0.052)\tLoss 5.4976 (6.9662)\tPrec@1 77.000 (69.182)\tPrec@5 96.000 (96.182)\n",
            "Test: [20/100]\tTime 0.025 (0.037)\tLoss 5.9568 (6.9465)\tPrec@1 74.000 (68.905)\tPrec@5 96.000 (95.857)\n",
            "Test: [30/100]\tTime 0.024 (0.033)\tLoss 7.2616 (7.0964)\tPrec@1 66.000 (68.452)\tPrec@5 97.000 (95.645)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 7.0701 (7.1396)\tPrec@1 69.000 (68.341)\tPrec@5 96.000 (95.610)\n",
            "Test: [50/100]\tTime 0.022 (0.032)\tLoss 7.1828 (7.0862)\tPrec@1 65.000 (68.608)\tPrec@5 96.000 (95.627)\n",
            "Test: [60/100]\tTime 0.038 (0.031)\tLoss 6.6985 (7.1048)\tPrec@1 66.000 (68.475)\tPrec@5 95.000 (95.623)\n",
            "Test: [70/100]\tTime 0.039 (0.030)\tLoss 6.4282 (7.0568)\tPrec@1 72.000 (68.803)\tPrec@5 97.000 (95.592)\n",
            "Test: [80/100]\tTime 0.021 (0.030)\tLoss 7.2691 (7.0181)\tPrec@1 68.000 (69.049)\tPrec@5 93.000 (95.580)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 6.8112 (7.0844)\tPrec@1 71.000 (68.648)\tPrec@5 97.000 (95.549)\n",
            "val Results: Prec@1 68.650 Prec@5 95.580 Loss 7.07570\n",
            "val Class Accuracy: [0.960,0.947,0.753,0.435,0.596,0.835,0.847,0.489,0.595,0.408]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [77][0/110], lr: 0.01000\tTime 0.386 (0.386)\tData 0.275 (0.275)\tLoss 0.7862 (0.7862)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][10/110], lr: 0.01000\tTime 0.042 (0.100)\tData 0.000 (0.033)\tLoss 2.1333 (1.5031)\tPrec@1 89.062 (92.401)\tPrec@5 99.219 (99.574)\n",
            "Epoch: [77][20/110], lr: 0.01000\tTime 0.063 (0.080)\tData 0.000 (0.019)\tLoss 1.6993 (1.5418)\tPrec@1 91.406 (92.039)\tPrec@5 98.438 (99.554)\n",
            "Epoch: [77][30/110], lr: 0.01000\tTime 0.042 (0.074)\tData 0.000 (0.014)\tLoss 2.1423 (1.6052)\tPrec@1 89.062 (91.683)\tPrec@5 100.000 (99.521)\n",
            "Epoch: [77][40/110], lr: 0.01000\tTime 0.050 (0.070)\tData 0.000 (0.012)\tLoss 1.2085 (1.5601)\tPrec@1 93.750 (91.864)\tPrec@5 100.000 (99.581)\n",
            "Epoch: [77][50/110], lr: 0.01000\tTime 0.075 (0.068)\tData 0.009 (0.010)\tLoss 1.3889 (1.5461)\tPrec@1 91.406 (91.958)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [77][60/110], lr: 0.01000\tTime 0.041 (0.066)\tData 0.000 (0.009)\tLoss 1.6051 (1.5825)\tPrec@1 90.625 (91.726)\tPrec@5 100.000 (99.552)\n",
            "Epoch: [77][70/110], lr: 0.01000\tTime 0.070 (0.065)\tData 0.006 (0.009)\tLoss 2.0013 (1.5954)\tPrec@1 89.844 (91.582)\tPrec@5 100.000 (99.527)\n",
            "Epoch: [77][80/110], lr: 0.01000\tTime 0.054 (0.064)\tData 0.006 (0.008)\tLoss 1.3542 (1.5984)\tPrec@1 92.969 (91.522)\tPrec@5 100.000 (99.508)\n",
            "Epoch: [77][90/110], lr: 0.01000\tTime 0.042 (0.064)\tData 0.006 (0.008)\tLoss 1.6015 (1.5941)\tPrec@1 92.969 (91.612)\tPrec@5 100.000 (99.511)\n",
            "Epoch: [77][100/110], lr: 0.01000\tTime 0.046 (0.063)\tData 0.000 (0.008)\tLoss 1.4605 (1.5989)\tPrec@1 92.969 (91.623)\tPrec@5 100.000 (99.536)\n",
            "Test: [0/100]\tTime 0.324 (0.324)\tLoss 6.0017 (6.0017)\tPrec@1 70.000 (70.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.023 (0.055)\tLoss 5.0830 (6.2152)\tPrec@1 77.000 (71.091)\tPrec@5 96.000 (97.727)\n",
            "Test: [20/100]\tTime 0.023 (0.041)\tLoss 5.6092 (6.1722)\tPrec@1 73.000 (71.286)\tPrec@5 99.000 (97.333)\n",
            "Test: [30/100]\tTime 0.013 (0.034)\tLoss 7.1476 (6.0476)\tPrec@1 68.000 (72.000)\tPrec@5 95.000 (97.290)\n",
            "Test: [40/100]\tTime 0.043 (0.033)\tLoss 5.2157 (6.0590)\tPrec@1 75.000 (72.049)\tPrec@5 97.000 (97.146)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 6.2478 (6.0030)\tPrec@1 71.000 (72.275)\tPrec@5 96.000 (97.314)\n",
            "Test: [60/100]\tTime 0.017 (0.031)\tLoss 5.8795 (6.0730)\tPrec@1 74.000 (72.131)\tPrec@5 99.000 (97.246)\n",
            "Test: [70/100]\tTime 0.031 (0.030)\tLoss 5.9745 (6.0960)\tPrec@1 74.000 (72.085)\tPrec@5 96.000 (97.197)\n",
            "Test: [80/100]\tTime 0.036 (0.029)\tLoss 7.6304 (6.0449)\tPrec@1 64.000 (72.358)\tPrec@5 98.000 (97.296)\n",
            "Test: [90/100]\tTime 0.022 (0.029)\tLoss 5.8009 (6.1090)\tPrec@1 75.000 (71.978)\tPrec@5 100.000 (97.308)\n",
            "val Results: Prec@1 71.910 Prec@5 97.330 Loss 6.11341\n",
            "val Class Accuracy: [0.946,0.715,0.506,0.710,0.561,0.691,0.894,0.704,0.568,0.896]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [78][0/110], lr: 0.01000\tTime 0.393 (0.393)\tData 0.302 (0.302)\tLoss 1.4006 (1.4006)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][10/110], lr: 0.01000\tTime 0.052 (0.100)\tData 0.000 (0.031)\tLoss 1.5810 (1.5593)\tPrec@1 91.406 (92.259)\tPrec@5 99.219 (99.574)\n",
            "Epoch: [78][20/110], lr: 0.01000\tTime 0.064 (0.082)\tData 0.000 (0.019)\tLoss 1.8265 (1.5904)\tPrec@1 89.062 (92.262)\tPrec@5 99.219 (99.554)\n",
            "Epoch: [78][30/110], lr: 0.01000\tTime 0.050 (0.074)\tData 0.000 (0.014)\tLoss 2.0444 (1.5729)\tPrec@1 89.844 (92.263)\tPrec@5 100.000 (99.597)\n",
            "Epoch: [78][40/110], lr: 0.01000\tTime 0.053 (0.070)\tData 0.000 (0.011)\tLoss 1.2148 (1.5436)\tPrec@1 93.750 (92.264)\tPrec@5 99.219 (99.619)\n",
            "Epoch: [78][50/110], lr: 0.01000\tTime 0.043 (0.068)\tData 0.000 (0.010)\tLoss 0.8881 (1.5282)\tPrec@1 94.531 (92.341)\tPrec@5 100.000 (99.617)\n",
            "Epoch: [78][60/110], lr: 0.01000\tTime 0.060 (0.067)\tData 0.007 (0.009)\tLoss 1.6054 (1.5295)\tPrec@1 92.188 (92.213)\tPrec@5 98.438 (99.641)\n",
            "Epoch: [78][70/110], lr: 0.01000\tTime 0.044 (0.065)\tData 0.000 (0.008)\tLoss 1.5547 (1.5100)\tPrec@1 92.188 (92.243)\tPrec@5 100.000 (99.692)\n",
            "Epoch: [78][80/110], lr: 0.01000\tTime 0.040 (0.065)\tData 0.000 (0.008)\tLoss 1.7987 (1.5483)\tPrec@1 89.062 (91.985)\tPrec@5 100.000 (99.682)\n",
            "Epoch: [78][90/110], lr: 0.01000\tTime 0.065 (0.064)\tData 0.002 (0.007)\tLoss 1.2418 (1.5522)\tPrec@1 95.312 (91.956)\tPrec@5 100.000 (99.691)\n",
            "Epoch: [78][100/110], lr: 0.01000\tTime 0.075 (0.064)\tData 0.003 (0.007)\tLoss 0.9176 (1.5377)\tPrec@1 96.094 (91.971)\tPrec@5 99.219 (99.675)\n",
            "Test: [0/100]\tTime 0.309 (0.309)\tLoss 5.7986 (5.7986)\tPrec@1 76.000 (76.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.024 (0.050)\tLoss 4.5012 (6.4750)\tPrec@1 81.000 (71.000)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/100]\tTime 0.015 (0.040)\tLoss 6.2038 (6.4755)\tPrec@1 73.000 (71.000)\tPrec@5 100.000 (97.476)\n",
            "Test: [30/100]\tTime 0.035 (0.036)\tLoss 6.4436 (6.5280)\tPrec@1 68.000 (70.774)\tPrec@5 97.000 (97.226)\n",
            "Test: [40/100]\tTime 0.023 (0.033)\tLoss 6.1837 (6.4803)\tPrec@1 74.000 (71.146)\tPrec@5 97.000 (97.122)\n",
            "Test: [50/100]\tTime 0.037 (0.032)\tLoss 6.7696 (6.4393)\tPrec@1 69.000 (71.275)\tPrec@5 95.000 (97.098)\n",
            "Test: [60/100]\tTime 0.045 (0.034)\tLoss 5.2327 (6.4511)\tPrec@1 76.000 (71.098)\tPrec@5 98.000 (97.082)\n",
            "Test: [70/100]\tTime 0.037 (0.035)\tLoss 6.8082 (6.4665)\tPrec@1 66.000 (71.085)\tPrec@5 99.000 (97.056)\n",
            "Test: [80/100]\tTime 0.047 (0.036)\tLoss 6.7098 (6.4425)\tPrec@1 70.000 (71.049)\tPrec@5 96.000 (97.086)\n",
            "Test: [90/100]\tTime 0.034 (0.037)\tLoss 7.0112 (6.5421)\tPrec@1 67.000 (70.604)\tPrec@5 98.000 (97.132)\n",
            "val Results: Prec@1 70.560 Prec@5 97.170 Loss 6.55229\n",
            "val Class Accuracy: [0.957,0.961,0.689,0.823,0.670,0.631,0.658,0.595,0.449,0.623]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [79][0/110], lr: 0.01000\tTime 0.702 (0.702)\tData 0.638 (0.638)\tLoss 1.4368 (1.4368)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][10/110], lr: 0.01000\tTime 0.091 (0.151)\tData 0.010 (0.066)\tLoss 1.2477 (1.4999)\tPrec@1 94.531 (92.472)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [79][20/110], lr: 0.01000\tTime 0.058 (0.118)\tData 0.007 (0.038)\tLoss 1.6092 (1.4326)\tPrec@1 91.406 (92.857)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [79][30/110], lr: 0.01000\tTime 0.060 (0.097)\tData 0.003 (0.026)\tLoss 1.1747 (1.4059)\tPrec@1 94.531 (92.692)\tPrec@5 100.000 (99.672)\n",
            "Epoch: [79][40/110], lr: 0.01000\tTime 0.063 (0.088)\tData 0.000 (0.021)\tLoss 1.4450 (1.3931)\tPrec@1 92.188 (92.835)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [79][50/110], lr: 0.01000\tTime 0.055 (0.082)\tData 0.000 (0.018)\tLoss 1.6465 (1.3778)\tPrec@1 89.062 (92.923)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [79][60/110], lr: 0.01000\tTime 0.072 (0.078)\tData 0.005 (0.016)\tLoss 1.8538 (1.4349)\tPrec@1 90.625 (92.649)\tPrec@5 98.438 (99.667)\n",
            "Epoch: [79][70/110], lr: 0.01000\tTime 0.046 (0.076)\tData 0.005 (0.014)\tLoss 1.4560 (1.4442)\tPrec@1 92.188 (92.650)\tPrec@5 98.438 (99.648)\n",
            "Epoch: [79][80/110], lr: 0.01000\tTime 0.059 (0.074)\tData 0.000 (0.013)\tLoss 1.6803 (1.4259)\tPrec@1 89.844 (92.718)\tPrec@5 99.219 (99.662)\n",
            "Epoch: [79][90/110], lr: 0.01000\tTime 0.059 (0.072)\tData 0.007 (0.012)\tLoss 1.8158 (1.4359)\tPrec@1 89.062 (92.600)\tPrec@5 99.219 (99.674)\n",
            "Epoch: [79][100/110], lr: 0.01000\tTime 0.067 (0.071)\tData 0.006 (0.011)\tLoss 2.0226 (1.4370)\tPrec@1 88.281 (92.559)\tPrec@5 100.000 (99.667)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 6.4137 (6.4137)\tPrec@1 70.000 (70.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.035 (0.053)\tLoss 5.2166 (6.9548)\tPrec@1 79.000 (69.455)\tPrec@5 94.000 (95.273)\n",
            "Test: [20/100]\tTime 0.020 (0.040)\tLoss 6.3223 (6.8364)\tPrec@1 70.000 (69.952)\tPrec@5 99.000 (95.048)\n",
            "Test: [30/100]\tTime 0.015 (0.036)\tLoss 6.9091 (6.8891)\tPrec@1 67.000 (69.806)\tPrec@5 93.000 (94.935)\n",
            "Test: [40/100]\tTime 0.018 (0.034)\tLoss 6.6673 (6.8688)\tPrec@1 71.000 (69.976)\tPrec@5 97.000 (94.927)\n",
            "Test: [50/100]\tTime 0.037 (0.032)\tLoss 6.6167 (6.8029)\tPrec@1 70.000 (70.588)\tPrec@5 95.000 (94.961)\n",
            "Test: [60/100]\tTime 0.021 (0.031)\tLoss 5.8440 (6.8066)\tPrec@1 73.000 (70.426)\tPrec@5 95.000 (94.918)\n",
            "Test: [70/100]\tTime 0.034 (0.031)\tLoss 5.8802 (6.8036)\tPrec@1 75.000 (70.493)\tPrec@5 96.000 (94.761)\n",
            "Test: [80/100]\tTime 0.022 (0.030)\tLoss 6.0050 (6.7641)\tPrec@1 77.000 (70.630)\tPrec@5 95.000 (94.889)\n",
            "Test: [90/100]\tTime 0.038 (0.030)\tLoss 6.6388 (6.8002)\tPrec@1 71.000 (70.538)\tPrec@5 96.000 (94.934)\n",
            "val Results: Prec@1 70.500 Prec@5 94.900 Loss 6.83061\n",
            "val Class Accuracy: [0.803,0.974,0.799,0.762,0.819,0.609,0.794,0.658,0.438,0.394]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [80][0/110], lr: 0.01000\tTime 0.454 (0.454)\tData 0.354 (0.354)\tLoss 0.7252 (0.7252)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][10/110], lr: 0.01000\tTime 0.064 (0.105)\tData 0.000 (0.037)\tLoss 1.9135 (1.5796)\tPrec@1 89.844 (91.974)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [80][20/110], lr: 0.01000\tTime 0.071 (0.085)\tData 0.009 (0.021)\tLoss 1.5595 (1.5240)\tPrec@1 92.188 (92.001)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [80][30/110], lr: 0.01000\tTime 0.056 (0.077)\tData 0.007 (0.016)\tLoss 1.4760 (1.4475)\tPrec@1 91.406 (92.465)\tPrec@5 100.000 (99.546)\n",
            "Epoch: [80][40/110], lr: 0.01000\tTime 0.054 (0.072)\tData 0.001 (0.013)\tLoss 1.0948 (1.5028)\tPrec@1 94.531 (92.016)\tPrec@5 100.000 (99.524)\n",
            "Epoch: [80][50/110], lr: 0.01000\tTime 0.069 (0.070)\tData 0.005 (0.011)\tLoss 2.1058 (1.5287)\tPrec@1 88.281 (91.912)\tPrec@5 100.000 (99.556)\n",
            "Epoch: [80][60/110], lr: 0.01000\tTime 0.053 (0.069)\tData 0.007 (0.011)\tLoss 1.4741 (1.5457)\tPrec@1 91.406 (91.880)\tPrec@5 100.000 (99.552)\n",
            "Epoch: [80][70/110], lr: 0.01000\tTime 0.055 (0.067)\tData 0.006 (0.010)\tLoss 1.8493 (1.5471)\tPrec@1 89.844 (91.967)\tPrec@5 100.000 (99.549)\n",
            "Epoch: [80][80/110], lr: 0.01000\tTime 0.058 (0.066)\tData 0.007 (0.009)\tLoss 2.0589 (1.5385)\tPrec@1 88.281 (92.062)\tPrec@5 98.438 (99.537)\n",
            "Epoch: [80][90/110], lr: 0.01000\tTime 0.060 (0.065)\tData 0.007 (0.009)\tLoss 1.8904 (1.5520)\tPrec@1 89.844 (91.981)\tPrec@5 100.000 (99.545)\n",
            "Epoch: [80][100/110], lr: 0.01000\tTime 0.061 (0.065)\tData 0.000 (0.008)\tLoss 1.5979 (1.5382)\tPrec@1 92.188 (92.033)\tPrec@5 99.219 (99.559)\n",
            "Test: [0/100]\tTime 0.323 (0.323)\tLoss 6.5033 (6.5033)\tPrec@1 72.000 (72.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.018 (0.054)\tLoss 5.2800 (6.9630)\tPrec@1 75.000 (69.455)\tPrec@5 96.000 (95.727)\n",
            "Test: [20/100]\tTime 0.022 (0.041)\tLoss 6.2360 (6.8563)\tPrec@1 74.000 (69.857)\tPrec@5 95.000 (95.762)\n",
            "Test: [30/100]\tTime 0.046 (0.036)\tLoss 6.4938 (6.8634)\tPrec@1 73.000 (70.000)\tPrec@5 96.000 (95.742)\n",
            "Test: [40/100]\tTime 0.024 (0.033)\tLoss 6.5268 (6.8701)\tPrec@1 72.000 (69.683)\tPrec@5 97.000 (95.683)\n",
            "Test: [50/100]\tTime 0.027 (0.031)\tLoss 6.8539 (6.8313)\tPrec@1 72.000 (69.765)\tPrec@5 93.000 (95.784)\n",
            "Test: [60/100]\tTime 0.036 (0.032)\tLoss 5.4940 (6.8130)\tPrec@1 77.000 (69.803)\tPrec@5 96.000 (95.820)\n",
            "Test: [70/100]\tTime 0.024 (0.031)\tLoss 6.5811 (6.8502)\tPrec@1 75.000 (69.606)\tPrec@5 97.000 (95.732)\n",
            "Test: [80/100]\tTime 0.029 (0.030)\tLoss 6.3563 (6.7856)\tPrec@1 71.000 (69.889)\tPrec@5 94.000 (95.802)\n",
            "Test: [90/100]\tTime 0.024 (0.030)\tLoss 6.0793 (6.8740)\tPrec@1 74.000 (69.330)\tPrec@5 96.000 (95.846)\n",
            "val Results: Prec@1 69.320 Prec@5 95.870 Loss 6.88082\n",
            "val Class Accuracy: [0.916,0.941,0.838,0.713,0.746,0.538,0.714,0.756,0.262,0.508]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [81][0/110], lr: 0.01000\tTime 0.504 (0.504)\tData 0.436 (0.436)\tLoss 1.6783 (1.6783)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [81][10/110], lr: 0.01000\tTime 0.063 (0.109)\tData 0.006 (0.044)\tLoss 2.4549 (1.5407)\tPrec@1 85.156 (91.832)\tPrec@5 99.219 (99.574)\n",
            "Epoch: [81][20/110], lr: 0.01000\tTime 0.047 (0.087)\tData 0.006 (0.026)\tLoss 1.4164 (1.4884)\tPrec@1 91.406 (91.927)\tPrec@5 99.219 (99.628)\n",
            "Epoch: [81][30/110], lr: 0.01000\tTime 0.040 (0.078)\tData 0.000 (0.019)\tLoss 1.3937 (1.3514)\tPrec@1 95.312 (92.893)\tPrec@5 98.438 (99.597)\n",
            "Epoch: [81][40/110], lr: 0.01000\tTime 0.061 (0.073)\tData 0.007 (0.016)\tLoss 1.8130 (1.3197)\tPrec@1 89.844 (92.931)\tPrec@5 100.000 (99.638)\n",
            "Epoch: [81][50/110], lr: 0.01000\tTime 0.073 (0.070)\tData 0.004 (0.014)\tLoss 2.0918 (1.3890)\tPrec@1 88.281 (92.540)\tPrec@5 100.000 (99.617)\n",
            "Epoch: [81][60/110], lr: 0.01000\tTime 0.048 (0.068)\tData 0.000 (0.013)\tLoss 1.8183 (1.4313)\tPrec@1 92.188 (92.405)\tPrec@5 100.000 (99.590)\n",
            "Epoch: [81][70/110], lr: 0.01000\tTime 0.049 (0.066)\tData 0.007 (0.012)\tLoss 2.4257 (1.4363)\tPrec@1 88.281 (92.353)\tPrec@5 100.000 (99.626)\n",
            "Epoch: [81][80/110], lr: 0.01000\tTime 0.040 (0.065)\tData 0.000 (0.011)\tLoss 1.5476 (1.4240)\tPrec@1 92.969 (92.515)\tPrec@5 97.656 (99.605)\n",
            "Epoch: [81][90/110], lr: 0.01000\tTime 0.052 (0.064)\tData 0.007 (0.011)\tLoss 1.3648 (1.4408)\tPrec@1 92.969 (92.394)\tPrec@5 100.000 (99.605)\n",
            "Epoch: [81][100/110], lr: 0.01000\tTime 0.071 (0.064)\tData 0.016 (0.010)\tLoss 2.0298 (1.4469)\tPrec@1 88.281 (92.373)\tPrec@5 99.219 (99.606)\n",
            "Test: [0/100]\tTime 0.283 (0.283)\tLoss 6.4085 (6.4085)\tPrec@1 72.000 (72.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.010 (0.054)\tLoss 4.4767 (6.1534)\tPrec@1 81.000 (72.636)\tPrec@5 99.000 (97.364)\n",
            "Test: [20/100]\tTime 0.036 (0.039)\tLoss 6.0569 (6.3654)\tPrec@1 74.000 (71.476)\tPrec@5 97.000 (96.810)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 5.7087 (6.5247)\tPrec@1 73.000 (70.839)\tPrec@5 95.000 (96.742)\n",
            "Test: [40/100]\tTime 0.016 (0.033)\tLoss 7.1093 (6.4962)\tPrec@1 70.000 (71.244)\tPrec@5 94.000 (96.537)\n",
            "Test: [50/100]\tTime 0.024 (0.032)\tLoss 6.5101 (6.4870)\tPrec@1 70.000 (71.255)\tPrec@5 96.000 (96.588)\n",
            "Test: [60/100]\tTime 0.022 (0.031)\tLoss 6.7436 (6.5215)\tPrec@1 70.000 (71.082)\tPrec@5 96.000 (96.623)\n",
            "Test: [70/100]\tTime 0.039 (0.030)\tLoss 6.2043 (6.4776)\tPrec@1 72.000 (71.352)\tPrec@5 96.000 (96.620)\n",
            "Test: [80/100]\tTime 0.021 (0.030)\tLoss 4.9354 (6.4316)\tPrec@1 80.000 (71.506)\tPrec@5 98.000 (96.765)\n",
            "Test: [90/100]\tTime 0.025 (0.030)\tLoss 6.2393 (6.4662)\tPrec@1 72.000 (71.385)\tPrec@5 98.000 (96.813)\n",
            "val Results: Prec@1 71.460 Prec@5 96.810 Loss 6.46073\n",
            "val Class Accuracy: [0.930,0.972,0.814,0.651,0.814,0.580,0.730,0.532,0.544,0.579]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [82][0/110], lr: 0.01000\tTime 0.492 (0.492)\tData 0.387 (0.387)\tLoss 1.3987 (1.3987)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [82][10/110], lr: 0.01000\tTime 0.059 (0.102)\tData 0.000 (0.040)\tLoss 1.3888 (1.6332)\tPrec@1 92.969 (91.548)\tPrec@5 99.219 (99.432)\n",
            "Epoch: [82][20/110], lr: 0.01000\tTime 0.054 (0.081)\tData 0.000 (0.024)\tLoss 1.0224 (1.5716)\tPrec@1 92.969 (91.555)\tPrec@5 100.000 (99.479)\n",
            "Epoch: [82][30/110], lr: 0.01000\tTime 0.044 (0.073)\tData 0.000 (0.018)\tLoss 1.1426 (1.5567)\tPrec@1 92.969 (91.860)\tPrec@5 100.000 (99.521)\n",
            "Epoch: [82][40/110], lr: 0.01000\tTime 0.050 (0.070)\tData 0.000 (0.015)\tLoss 1.9323 (1.5398)\tPrec@1 87.500 (91.787)\tPrec@5 99.219 (99.524)\n",
            "Epoch: [82][50/110], lr: 0.01000\tTime 0.056 (0.068)\tData 0.007 (0.013)\tLoss 0.7782 (1.5230)\tPrec@1 97.656 (91.866)\tPrec@5 100.000 (99.540)\n",
            "Epoch: [82][60/110], lr: 0.01000\tTime 0.058 (0.066)\tData 0.007 (0.012)\tLoss 2.4910 (1.5338)\tPrec@1 84.375 (91.739)\tPrec@5 100.000 (99.539)\n",
            "Epoch: [82][70/110], lr: 0.01000\tTime 0.065 (0.065)\tData 0.001 (0.011)\tLoss 1.3313 (1.5315)\tPrec@1 92.969 (91.813)\tPrec@5 99.219 (99.549)\n",
            "Epoch: [82][80/110], lr: 0.01000\tTime 0.058 (0.065)\tData 0.007 (0.010)\tLoss 1.1928 (1.5388)\tPrec@1 93.750 (91.821)\tPrec@5 99.219 (99.556)\n",
            "Epoch: [82][90/110], lr: 0.01000\tTime 0.063 (0.064)\tData 0.007 (0.010)\tLoss 1.1394 (1.5580)\tPrec@1 93.750 (91.775)\tPrec@5 100.000 (99.545)\n",
            "Epoch: [82][100/110], lr: 0.01000\tTime 0.054 (0.063)\tData 0.000 (0.009)\tLoss 2.0699 (1.5762)\tPrec@1 89.844 (91.669)\tPrec@5 98.438 (99.528)\n",
            "Test: [0/100]\tTime 0.329 (0.329)\tLoss 8.8317 (8.8317)\tPrec@1 61.000 (61.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.036 (0.055)\tLoss 7.2706 (8.5298)\tPrec@1 73.000 (64.273)\tPrec@5 97.000 (96.909)\n",
            "Test: [20/100]\tTime 0.024 (0.038)\tLoss 7.6408 (8.4291)\tPrec@1 66.000 (64.381)\tPrec@5 99.000 (96.571)\n",
            "Test: [30/100]\tTime 0.024 (0.034)\tLoss 7.0608 (8.4644)\tPrec@1 70.000 (64.323)\tPrec@5 96.000 (96.484)\n",
            "Test: [40/100]\tTime 0.019 (0.032)\tLoss 8.6522 (8.5382)\tPrec@1 61.000 (64.220)\tPrec@5 98.000 (96.390)\n",
            "Test: [50/100]\tTime 0.044 (0.031)\tLoss 8.2213 (8.5297)\tPrec@1 65.000 (64.451)\tPrec@5 96.000 (96.588)\n",
            "Test: [60/100]\tTime 0.042 (0.030)\tLoss 6.7490 (8.5187)\tPrec@1 68.000 (64.311)\tPrec@5 97.000 (96.525)\n",
            "Test: [70/100]\tTime 0.038 (0.030)\tLoss 7.5035 (8.4846)\tPrec@1 69.000 (64.451)\tPrec@5 99.000 (96.648)\n",
            "Test: [80/100]\tTime 0.029 (0.029)\tLoss 8.5394 (8.4546)\tPrec@1 65.000 (64.519)\tPrec@5 97.000 (96.679)\n",
            "Test: [90/100]\tTime 0.037 (0.028)\tLoss 8.8919 (8.5205)\tPrec@1 62.000 (64.297)\tPrec@5 99.000 (96.637)\n",
            "val Results: Prec@1 64.250 Prec@5 96.700 Loss 8.53562\n",
            "val Class Accuracy: [0.963,0.987,0.736,0.758,0.709,0.533,0.544,0.645,0.495,0.055]\n",
            "Best Prec@1: 73.880\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [83][0/110], lr: 0.01000\tTime 0.500 (0.500)\tData 0.402 (0.402)\tLoss 1.7204 (1.7204)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][10/110], lr: 0.01000\tTime 0.053 (0.101)\tData 0.007 (0.041)\tLoss 1.5260 (1.6781)\tPrec@1 91.406 (91.548)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [83][20/110], lr: 0.01000\tTime 0.063 (0.082)\tData 0.012 (0.024)\tLoss 1.4508 (1.6036)\tPrec@1 92.969 (92.076)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [83][30/110], lr: 0.01000\tTime 0.062 (0.074)\tData 0.006 (0.018)\tLoss 2.2846 (1.6040)\tPrec@1 87.500 (92.011)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [83][40/110], lr: 0.01000\tTime 0.055 (0.070)\tData 0.013 (0.016)\tLoss 1.5980 (1.5680)\tPrec@1 92.188 (92.092)\tPrec@5 100.000 (99.733)\n",
            "Epoch: [83][50/110], lr: 0.01000\tTime 0.088 (0.068)\tData 0.011 (0.014)\tLoss 1.5406 (1.5606)\tPrec@1 91.406 (92.050)\tPrec@5 99.219 (99.694)\n",
            "Epoch: [83][60/110], lr: 0.01000\tTime 0.055 (0.067)\tData 0.011 (0.013)\tLoss 0.9726 (1.5161)\tPrec@1 96.875 (92.380)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [83][70/110], lr: 0.01000\tTime 0.042 (0.068)\tData 0.000 (0.012)\tLoss 0.8384 (1.5108)\tPrec@1 95.312 (92.342)\tPrec@5 100.000 (99.692)\n",
            "Epoch: [83][80/110], lr: 0.01000\tTime 0.076 (0.071)\tData 0.000 (0.011)\tLoss 1.3145 (1.5038)\tPrec@1 92.188 (92.323)\tPrec@5 100.000 (99.691)\n",
            "Epoch: [83][90/110], lr: 0.01000\tTime 0.069 (0.072)\tData 0.006 (0.010)\tLoss 0.6714 (1.4784)\tPrec@1 96.875 (92.454)\tPrec@5 100.000 (99.700)\n",
            "Epoch: [83][100/110], lr: 0.01000\tTime 0.125 (0.074)\tData 0.000 (0.010)\tLoss 2.1181 (1.5091)\tPrec@1 89.062 (92.211)\tPrec@5 100.000 (99.683)\n",
            "Test: [0/100]\tTime 0.252 (0.252)\tLoss 5.6624 (5.6624)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.029 (0.053)\tLoss 5.2041 (5.8340)\tPrec@1 77.000 (74.091)\tPrec@5 94.000 (97.182)\n",
            "Test: [20/100]\tTime 0.023 (0.040)\tLoss 5.3406 (5.7291)\tPrec@1 75.000 (74.333)\tPrec@5 99.000 (97.095)\n",
            "Test: [30/100]\tTime 0.034 (0.035)\tLoss 5.0319 (5.7869)\tPrec@1 74.000 (74.161)\tPrec@5 97.000 (96.839)\n",
            "Test: [40/100]\tTime 0.014 (0.033)\tLoss 5.2841 (5.8073)\tPrec@1 78.000 (74.146)\tPrec@5 95.000 (96.756)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 7.0143 (5.7840)\tPrec@1 70.000 (74.235)\tPrec@5 98.000 (97.059)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 4.9048 (5.8050)\tPrec@1 76.000 (74.115)\tPrec@5 99.000 (97.033)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 5.5263 (5.7734)\tPrec@1 72.000 (74.310)\tPrec@5 98.000 (97.099)\n",
            "Test: [80/100]\tTime 0.012 (0.029)\tLoss 4.9584 (5.7724)\tPrec@1 77.000 (74.222)\tPrec@5 98.000 (97.222)\n",
            "Test: [90/100]\tTime 0.026 (0.028)\tLoss 5.0309 (5.8164)\tPrec@1 79.000 (74.022)\tPrec@5 100.000 (97.275)\n",
            "val Results: Prec@1 73.980 Prec@5 97.260 Loss 5.81705\n",
            "val Class Accuracy: [0.935,0.965,0.812,0.494,0.765,0.759,0.729,0.666,0.718,0.555]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [84][0/110], lr: 0.01000\tTime 0.398 (0.398)\tData 0.303 (0.303)\tLoss 1.2452 (1.2452)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [84][10/110], lr: 0.01000\tTime 0.057 (0.101)\tData 0.007 (0.035)\tLoss 2.1971 (1.4383)\tPrec@1 85.938 (92.543)\tPrec@5 99.219 (99.858)\n",
            "Epoch: [84][20/110], lr: 0.01000\tTime 0.060 (0.081)\tData 0.007 (0.022)\tLoss 2.8699 (1.5219)\tPrec@1 82.031 (91.964)\tPrec@5 99.219 (99.777)\n",
            "Epoch: [84][30/110], lr: 0.01000\tTime 0.046 (0.073)\tData 0.000 (0.016)\tLoss 2.5778 (1.5622)\tPrec@1 85.938 (91.683)\tPrec@5 99.219 (99.698)\n",
            "Epoch: [84][40/110], lr: 0.01000\tTime 0.077 (0.070)\tData 0.012 (0.013)\tLoss 2.7012 (1.5581)\tPrec@1 84.375 (91.635)\tPrec@5 99.219 (99.714)\n",
            "Epoch: [84][50/110], lr: 0.01000\tTime 0.057 (0.068)\tData 0.000 (0.012)\tLoss 2.1289 (1.6080)\tPrec@1 89.062 (91.422)\tPrec@5 97.656 (99.632)\n",
            "Epoch: [84][60/110], lr: 0.01000\tTime 0.056 (0.067)\tData 0.000 (0.010)\tLoss 0.9935 (1.6041)\tPrec@1 95.312 (91.419)\tPrec@5 99.219 (99.577)\n",
            "Epoch: [84][70/110], lr: 0.01000\tTime 0.074 (0.065)\tData 0.007 (0.009)\tLoss 0.8674 (1.5471)\tPrec@1 96.094 (91.747)\tPrec@5 100.000 (99.637)\n",
            "Epoch: [84][80/110], lr: 0.01000\tTime 0.043 (0.064)\tData 0.000 (0.009)\tLoss 1.3672 (1.5530)\tPrec@1 92.969 (91.705)\tPrec@5 99.219 (99.624)\n",
            "Epoch: [84][90/110], lr: 0.01000\tTime 0.067 (0.064)\tData 0.007 (0.008)\tLoss 0.7098 (1.5053)\tPrec@1 96.094 (91.973)\tPrec@5 100.000 (99.631)\n",
            "Epoch: [84][100/110], lr: 0.01000\tTime 0.043 (0.063)\tData 0.001 (0.008)\tLoss 1.0943 (1.4931)\tPrec@1 95.312 (92.041)\tPrec@5 100.000 (99.636)\n",
            "Test: [0/100]\tTime 0.320 (0.320)\tLoss 5.4371 (5.4371)\tPrec@1 75.000 (75.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.024 (0.051)\tLoss 4.8831 (6.3207)\tPrec@1 79.000 (73.000)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/100]\tTime 0.020 (0.037)\tLoss 5.5210 (6.2724)\tPrec@1 74.000 (72.810)\tPrec@5 98.000 (96.619)\n",
            "Test: [30/100]\tTime 0.024 (0.035)\tLoss 6.5378 (6.3877)\tPrec@1 66.000 (72.129)\tPrec@5 95.000 (96.452)\n",
            "Test: [40/100]\tTime 0.010 (0.032)\tLoss 6.4450 (6.4198)\tPrec@1 73.000 (71.976)\tPrec@5 97.000 (96.439)\n",
            "Test: [50/100]\tTime 0.018 (0.031)\tLoss 5.8041 (6.3538)\tPrec@1 75.000 (72.333)\tPrec@5 95.000 (96.431)\n",
            "Test: [60/100]\tTime 0.010 (0.030)\tLoss 6.7999 (6.3537)\tPrec@1 68.000 (72.426)\tPrec@5 94.000 (96.508)\n",
            "Test: [70/100]\tTime 0.017 (0.029)\tLoss 5.6167 (6.3511)\tPrec@1 74.000 (72.310)\tPrec@5 98.000 (96.577)\n",
            "Test: [80/100]\tTime 0.010 (0.028)\tLoss 4.6559 (6.3306)\tPrec@1 83.000 (72.383)\tPrec@5 97.000 (96.617)\n",
            "Test: [90/100]\tTime 0.016 (0.028)\tLoss 5.9833 (6.3951)\tPrec@1 74.000 (72.066)\tPrec@5 98.000 (96.637)\n",
            "val Results: Prec@1 72.080 Prec@5 96.690 Loss 6.41407\n",
            "val Class Accuracy: [0.911,0.968,0.812,0.455,0.688,0.867,0.757,0.683,0.409,0.658]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [85][0/110], lr: 0.01000\tTime 0.474 (0.474)\tData 0.378 (0.378)\tLoss 1.3955 (1.3955)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][10/110], lr: 0.01000\tTime 0.039 (0.099)\tData 0.000 (0.039)\tLoss 0.7866 (1.1165)\tPrec@1 96.875 (94.176)\tPrec@5 100.000 (99.503)\n",
            "Epoch: [85][20/110], lr: 0.01000\tTime 0.054 (0.081)\tData 0.006 (0.024)\tLoss 1.0563 (1.1344)\tPrec@1 95.312 (94.010)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [85][30/110], lr: 0.01000\tTime 0.052 (0.073)\tData 0.006 (0.018)\tLoss 1.1826 (1.2251)\tPrec@1 92.969 (93.422)\tPrec@5 100.000 (99.622)\n",
            "Epoch: [85][40/110], lr: 0.01000\tTime 0.047 (0.069)\tData 0.010 (0.015)\tLoss 1.1253 (1.2584)\tPrec@1 94.531 (93.350)\tPrec@5 99.219 (99.676)\n",
            "Epoch: [85][50/110], lr: 0.01000\tTime 0.059 (0.067)\tData 0.007 (0.013)\tLoss 0.5690 (1.2647)\tPrec@1 96.094 (93.183)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [85][60/110], lr: 0.01000\tTime 0.056 (0.065)\tData 0.005 (0.012)\tLoss 1.2810 (1.2731)\tPrec@1 92.188 (93.122)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [85][70/110], lr: 0.01000\tTime 0.043 (0.064)\tData 0.003 (0.011)\tLoss 1.8860 (1.3355)\tPrec@1 89.844 (92.870)\tPrec@5 99.219 (99.725)\n",
            "Epoch: [85][80/110], lr: 0.01000\tTime 0.048 (0.064)\tData 0.000 (0.010)\tLoss 1.4757 (1.3551)\tPrec@1 92.188 (92.737)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [85][90/110], lr: 0.01000\tTime 0.042 (0.063)\tData 0.000 (0.009)\tLoss 1.3511 (1.4103)\tPrec@1 91.406 (92.488)\tPrec@5 98.438 (99.674)\n",
            "Epoch: [85][100/110], lr: 0.01000\tTime 0.071 (0.062)\tData 0.000 (0.009)\tLoss 1.8064 (1.4440)\tPrec@1 92.188 (92.350)\tPrec@5 100.000 (99.683)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 6.3273 (6.3273)\tPrec@1 70.000 (70.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.041 (0.052)\tLoss 5.9070 (7.3305)\tPrec@1 76.000 (67.545)\tPrec@5 94.000 (96.364)\n",
            "Test: [20/100]\tTime 0.013 (0.039)\tLoss 5.6948 (7.4158)\tPrec@1 75.000 (67.429)\tPrec@5 99.000 (96.048)\n",
            "Test: [30/100]\tTime 0.017 (0.035)\tLoss 6.8791 (7.5499)\tPrec@1 69.000 (67.097)\tPrec@5 95.000 (95.742)\n",
            "Test: [40/100]\tTime 0.046 (0.032)\tLoss 7.6952 (7.5518)\tPrec@1 67.000 (67.073)\tPrec@5 96.000 (95.902)\n",
            "Test: [50/100]\tTime 0.040 (0.031)\tLoss 8.1894 (7.4931)\tPrec@1 62.000 (67.353)\tPrec@5 97.000 (96.059)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 6.4851 (7.5008)\tPrec@1 71.000 (67.262)\tPrec@5 99.000 (96.180)\n",
            "Test: [70/100]\tTime 0.014 (0.029)\tLoss 7.8936 (7.5036)\tPrec@1 64.000 (67.183)\tPrec@5 98.000 (96.169)\n",
            "Test: [80/100]\tTime 0.017 (0.028)\tLoss 6.1232 (7.4586)\tPrec@1 73.000 (67.321)\tPrec@5 97.000 (96.185)\n",
            "Test: [90/100]\tTime 0.030 (0.028)\tLoss 7.5114 (7.5370)\tPrec@1 67.000 (66.945)\tPrec@5 99.000 (96.264)\n",
            "val Results: Prec@1 66.960 Prec@5 96.330 Loss 7.52841\n",
            "val Class Accuracy: [0.975,0.942,0.778,0.628,0.571,0.521,0.666,0.736,0.526,0.353]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [86][0/110], lr: 0.01000\tTime 0.380 (0.380)\tData 0.295 (0.295)\tLoss 0.9696 (0.9696)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][10/110], lr: 0.01000\tTime 0.036 (0.100)\tData 0.000 (0.034)\tLoss 1.4782 (1.4548)\tPrec@1 92.188 (92.259)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [86][20/110], lr: 0.01000\tTime 0.074 (0.081)\tData 0.005 (0.021)\tLoss 1.2238 (1.4678)\tPrec@1 95.312 (92.150)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [86][30/110], lr: 0.01000\tTime 0.060 (0.074)\tData 0.000 (0.015)\tLoss 0.7467 (1.3796)\tPrec@1 96.875 (92.692)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [86][40/110], lr: 0.01000\tTime 0.074 (0.070)\tData 0.007 (0.013)\tLoss 1.2600 (1.3991)\tPrec@1 93.750 (92.626)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [86][50/110], lr: 0.01000\tTime 0.064 (0.067)\tData 0.000 (0.011)\tLoss 1.6325 (1.3756)\tPrec@1 91.406 (92.632)\tPrec@5 100.000 (99.694)\n",
            "Epoch: [86][60/110], lr: 0.01000\tTime 0.041 (0.066)\tData 0.000 (0.010)\tLoss 2.6636 (1.4052)\tPrec@1 86.719 (92.482)\tPrec@5 99.219 (99.693)\n",
            "Epoch: [86][70/110], lr: 0.01000\tTime 0.044 (0.064)\tData 0.000 (0.009)\tLoss 2.3114 (1.4270)\tPrec@1 86.719 (92.419)\tPrec@5 98.438 (99.681)\n",
            "Epoch: [86][80/110], lr: 0.01000\tTime 0.053 (0.064)\tData 0.012 (0.009)\tLoss 1.3001 (1.4360)\tPrec@1 92.188 (92.351)\tPrec@5 100.000 (99.691)\n",
            "Epoch: [86][90/110], lr: 0.01000\tTime 0.048 (0.063)\tData 0.000 (0.008)\tLoss 1.4885 (1.4589)\tPrec@1 90.625 (92.213)\tPrec@5 100.000 (99.682)\n",
            "Epoch: [86][100/110], lr: 0.01000\tTime 0.043 (0.062)\tData 0.000 (0.008)\tLoss 1.1955 (1.4895)\tPrec@1 95.312 (92.095)\tPrec@5 100.000 (99.652)\n",
            "Test: [0/100]\tTime 0.295 (0.295)\tLoss 5.4448 (5.4448)\tPrec@1 76.000 (76.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.035 (0.055)\tLoss 5.2842 (5.7077)\tPrec@1 77.000 (75.364)\tPrec@5 95.000 (98.091)\n",
            "Test: [20/100]\tTime 0.044 (0.042)\tLoss 5.7000 (5.7113)\tPrec@1 72.000 (74.857)\tPrec@5 99.000 (98.000)\n",
            "Test: [30/100]\tTime 0.029 (0.034)\tLoss 6.0526 (5.8802)\tPrec@1 72.000 (73.871)\tPrec@5 96.000 (97.774)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 5.5722 (5.8704)\tPrec@1 73.000 (73.756)\tPrec@5 96.000 (97.659)\n",
            "Test: [50/100]\tTime 0.037 (0.031)\tLoss 5.8814 (5.8381)\tPrec@1 75.000 (73.941)\tPrec@5 98.000 (97.706)\n",
            "Test: [60/100]\tTime 0.042 (0.031)\tLoss 6.0649 (5.9410)\tPrec@1 72.000 (73.377)\tPrec@5 95.000 (97.721)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 6.0865 (6.0101)\tPrec@1 71.000 (72.972)\tPrec@5 97.000 (97.676)\n",
            "Test: [80/100]\tTime 0.010 (0.030)\tLoss 3.7893 (5.9330)\tPrec@1 83.000 (73.358)\tPrec@5 99.000 (97.667)\n",
            "Test: [90/100]\tTime 0.038 (0.030)\tLoss 5.6990 (6.0036)\tPrec@1 74.000 (73.110)\tPrec@5 100.000 (97.626)\n",
            "val Results: Prec@1 73.120 Prec@5 97.690 Loss 6.00840\n",
            "val Class Accuracy: [0.935,0.969,0.758,0.623,0.873,0.626,0.720,0.568,0.519,0.721]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [87][0/110], lr: 0.01000\tTime 0.368 (0.368)\tData 0.257 (0.257)\tLoss 1.6570 (1.6570)\tPrec@1 92.188 (92.188)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [87][10/110], lr: 0.01000\tTime 0.051 (0.106)\tData 0.005 (0.034)\tLoss 1.5730 (1.4114)\tPrec@1 89.062 (92.045)\tPrec@5 100.000 (99.574)\n",
            "Epoch: [87][20/110], lr: 0.01000\tTime 0.047 (0.084)\tData 0.002 (0.019)\tLoss 1.6560 (1.5786)\tPrec@1 92.188 (91.481)\tPrec@5 99.219 (99.702)\n",
            "Epoch: [87][30/110], lr: 0.01000\tTime 0.064 (0.078)\tData 0.000 (0.014)\tLoss 2.7215 (1.6215)\tPrec@1 86.719 (91.356)\tPrec@5 98.438 (99.672)\n",
            "Epoch: [87][40/110], lr: 0.01000\tTime 0.075 (0.073)\tData 0.006 (0.012)\tLoss 2.3080 (1.6414)\tPrec@1 89.062 (91.273)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [87][50/110], lr: 0.01000\tTime 0.052 (0.071)\tData 0.007 (0.010)\tLoss 1.5209 (1.5979)\tPrec@1 92.188 (91.513)\tPrec@5 100.000 (99.724)\n",
            "Epoch: [87][60/110], lr: 0.01000\tTime 0.055 (0.068)\tData 0.013 (0.010)\tLoss 1.3146 (1.5726)\tPrec@1 91.406 (91.522)\tPrec@5 100.000 (99.731)\n",
            "Epoch: [87][70/110], lr: 0.01000\tTime 0.051 (0.067)\tData 0.000 (0.010)\tLoss 1.8063 (1.5650)\tPrec@1 89.844 (91.648)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [87][80/110], lr: 0.01000\tTime 0.050 (0.065)\tData 0.007 (0.009)\tLoss 1.2994 (1.5548)\tPrec@1 95.312 (91.792)\tPrec@5 99.219 (99.662)\n",
            "Epoch: [87][90/110], lr: 0.01000\tTime 0.050 (0.065)\tData 0.006 (0.009)\tLoss 1.7752 (1.5477)\tPrec@1 87.500 (91.810)\tPrec@5 99.219 (99.674)\n",
            "Epoch: [87][100/110], lr: 0.01000\tTime 0.066 (0.064)\tData 0.001 (0.009)\tLoss 1.3415 (1.5221)\tPrec@1 92.188 (91.955)\tPrec@5 99.219 (99.667)\n",
            "Test: [0/100]\tTime 0.287 (0.287)\tLoss 7.2191 (7.2191)\tPrec@1 65.000 (65.000)\tPrec@5 100.000 (100.000)\n",
            "Test: [10/100]\tTime 0.032 (0.056)\tLoss 6.6053 (6.9912)\tPrec@1 70.000 (68.818)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/100]\tTime 0.032 (0.041)\tLoss 6.8217 (6.8181)\tPrec@1 63.000 (69.333)\tPrec@5 100.000 (97.286)\n",
            "Test: [30/100]\tTime 0.024 (0.036)\tLoss 7.6622 (6.8833)\tPrec@1 66.000 (69.484)\tPrec@5 96.000 (97.194)\n",
            "Test: [40/100]\tTime 0.018 (0.033)\tLoss 6.9443 (6.8561)\tPrec@1 72.000 (69.707)\tPrec@5 94.000 (97.220)\n",
            "Test: [50/100]\tTime 0.040 (0.032)\tLoss 6.9138 (6.8285)\tPrec@1 71.000 (69.824)\tPrec@5 95.000 (97.275)\n",
            "Test: [60/100]\tTime 0.022 (0.030)\tLoss 6.4490 (6.8886)\tPrec@1 69.000 (69.475)\tPrec@5 100.000 (97.344)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 6.7314 (6.8697)\tPrec@1 73.000 (69.577)\tPrec@5 98.000 (97.423)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 5.9871 (6.8672)\tPrec@1 75.000 (69.580)\tPrec@5 96.000 (97.395)\n",
            "Test: [90/100]\tTime 0.032 (0.029)\tLoss 5.9749 (6.8765)\tPrec@1 73.000 (69.549)\tPrec@5 99.000 (97.396)\n",
            "val Results: Prec@1 69.610 Prec@5 97.370 Loss 6.87755\n",
            "val Class Accuracy: [0.941,0.925,0.580,0.380,0.767,0.927,0.603,0.484,0.604,0.750]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [88][0/110], lr: 0.01000\tTime 0.463 (0.463)\tData 0.393 (0.393)\tLoss 0.8991 (0.8991)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][10/110], lr: 0.01000\tTime 0.084 (0.101)\tData 0.000 (0.040)\tLoss 1.5573 (1.4037)\tPrec@1 90.625 (92.259)\tPrec@5 100.000 (99.645)\n",
            "Epoch: [88][20/110], lr: 0.01000\tTime 0.088 (0.099)\tData 0.013 (0.024)\tLoss 1.9201 (1.5099)\tPrec@1 90.625 (92.262)\tPrec@5 99.219 (99.516)\n",
            "Epoch: [88][30/110], lr: 0.01000\tTime 0.067 (0.095)\tData 0.000 (0.019)\tLoss 1.4399 (1.5364)\tPrec@1 91.406 (92.162)\tPrec@5 100.000 (99.496)\n",
            "Epoch: [88][40/110], lr: 0.01000\tTime 0.081 (0.093)\tData 0.000 (0.017)\tLoss 1.1931 (1.5052)\tPrec@1 93.750 (92.226)\tPrec@5 100.000 (99.562)\n",
            "Epoch: [88][50/110], lr: 0.01000\tTime 0.090 (0.094)\tData 0.000 (0.014)\tLoss 1.3477 (1.5222)\tPrec@1 94.531 (92.172)\tPrec@5 98.438 (99.556)\n",
            "Epoch: [88][60/110], lr: 0.01000\tTime 0.045 (0.090)\tData 0.000 (0.012)\tLoss 1.0549 (1.4927)\tPrec@1 95.312 (92.328)\tPrec@5 100.000 (99.552)\n",
            "Epoch: [88][70/110], lr: 0.01000\tTime 0.046 (0.085)\tData 0.002 (0.012)\tLoss 1.4002 (1.4873)\tPrec@1 92.188 (92.265)\tPrec@5 99.219 (99.549)\n",
            "Epoch: [88][80/110], lr: 0.01000\tTime 0.044 (0.082)\tData 0.000 (0.011)\tLoss 1.3710 (1.5022)\tPrec@1 93.750 (92.188)\tPrec@5 100.000 (99.547)\n",
            "Epoch: [88][90/110], lr: 0.01000\tTime 0.048 (0.079)\tData 0.000 (0.010)\tLoss 1.8413 (1.5175)\tPrec@1 90.625 (92.127)\tPrec@5 99.219 (99.571)\n",
            "Epoch: [88][100/110], lr: 0.01000\tTime 0.044 (0.077)\tData 0.000 (0.010)\tLoss 1.5704 (1.5256)\tPrec@1 89.844 (92.048)\tPrec@5 98.438 (99.567)\n",
            "Test: [0/100]\tTime 0.268 (0.268)\tLoss 8.3943 (8.3943)\tPrec@1 66.000 (66.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.015 (0.052)\tLoss 5.8674 (8.1762)\tPrec@1 79.000 (65.000)\tPrec@5 96.000 (97.364)\n",
            "Test: [20/100]\tTime 0.035 (0.040)\tLoss 8.3464 (8.1619)\tPrec@1 63.000 (65.095)\tPrec@5 97.000 (96.952)\n",
            "Test: [30/100]\tTime 0.038 (0.036)\tLoss 7.5092 (8.2394)\tPrec@1 67.000 (64.742)\tPrec@5 97.000 (96.548)\n",
            "Test: [40/100]\tTime 0.037 (0.033)\tLoss 9.3594 (8.2393)\tPrec@1 59.000 (64.561)\tPrec@5 96.000 (96.463)\n",
            "Test: [50/100]\tTime 0.015 (0.031)\tLoss 8.0786 (8.2107)\tPrec@1 63.000 (64.549)\tPrec@5 98.000 (96.529)\n",
            "Test: [60/100]\tTime 0.031 (0.031)\tLoss 7.3064 (8.2351)\tPrec@1 70.000 (64.410)\tPrec@5 97.000 (96.344)\n",
            "Test: [70/100]\tTime 0.023 (0.029)\tLoss 8.0715 (8.2698)\tPrec@1 69.000 (64.380)\tPrec@5 97.000 (96.268)\n",
            "Test: [80/100]\tTime 0.027 (0.029)\tLoss 7.1665 (8.2038)\tPrec@1 71.000 (64.605)\tPrec@5 98.000 (96.370)\n",
            "Test: [90/100]\tTime 0.011 (0.028)\tLoss 7.9950 (8.2759)\tPrec@1 67.000 (64.363)\tPrec@5 96.000 (96.374)\n",
            "val Results: Prec@1 64.300 Prec@5 96.380 Loss 8.29946\n",
            "val Class Accuracy: [0.956,0.988,0.845,0.671,0.724,0.320,0.814,0.567,0.135,0.410]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [89][0/110], lr: 0.01000\tTime 0.408 (0.408)\tData 0.299 (0.299)\tLoss 1.2023 (1.2023)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][10/110], lr: 0.01000\tTime 0.069 (0.102)\tData 0.008 (0.031)\tLoss 0.9601 (1.3342)\tPrec@1 94.531 (93.395)\tPrec@5 98.438 (99.645)\n",
            "Epoch: [89][20/110], lr: 0.01000\tTime 0.057 (0.082)\tData 0.007 (0.019)\tLoss 1.5699 (1.3361)\tPrec@1 90.625 (93.378)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [89][30/110], lr: 0.01000\tTime 0.059 (0.074)\tData 0.008 (0.015)\tLoss 1.3814 (1.4142)\tPrec@1 92.969 (92.767)\tPrec@5 99.219 (99.672)\n",
            "Epoch: [89][40/110], lr: 0.01000\tTime 0.043 (0.069)\tData 0.000 (0.013)\tLoss 2.1415 (1.4551)\tPrec@1 89.062 (92.397)\tPrec@5 100.000 (99.676)\n",
            "Epoch: [89][50/110], lr: 0.01000\tTime 0.055 (0.068)\tData 0.007 (0.011)\tLoss 1.2577 (1.4666)\tPrec@1 93.750 (92.264)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [89][60/110], lr: 0.01000\tTime 0.064 (0.066)\tData 0.000 (0.010)\tLoss 1.7452 (1.4657)\tPrec@1 91.406 (92.328)\tPrec@5 99.219 (99.629)\n",
            "Epoch: [89][70/110], lr: 0.01000\tTime 0.048 (0.065)\tData 0.000 (0.009)\tLoss 1.8506 (1.4857)\tPrec@1 92.188 (92.254)\tPrec@5 100.000 (99.604)\n",
            "Epoch: [89][80/110], lr: 0.01000\tTime 0.044 (0.065)\tData 0.006 (0.008)\tLoss 1.6539 (1.5100)\tPrec@1 90.625 (92.120)\tPrec@5 97.656 (99.556)\n",
            "Epoch: [89][90/110], lr: 0.01000\tTime 0.040 (0.064)\tData 0.000 (0.008)\tLoss 1.7780 (1.5105)\tPrec@1 89.062 (92.093)\tPrec@5 100.000 (99.554)\n",
            "Epoch: [89][100/110], lr: 0.01000\tTime 0.044 (0.063)\tData 0.000 (0.008)\tLoss 1.0954 (1.5326)\tPrec@1 95.312 (91.925)\tPrec@5 100.000 (99.528)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 6.9982 (6.9982)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.024 (0.053)\tLoss 5.5162 (7.0193)\tPrec@1 75.000 (69.091)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/100]\tTime 0.033 (0.038)\tLoss 7.1346 (6.8846)\tPrec@1 69.000 (69.762)\tPrec@5 98.000 (96.857)\n",
            "Test: [30/100]\tTime 0.042 (0.035)\tLoss 6.4701 (6.9188)\tPrec@1 70.000 (69.871)\tPrec@5 96.000 (96.645)\n",
            "Test: [40/100]\tTime 0.034 (0.033)\tLoss 7.1300 (6.9118)\tPrec@1 68.000 (69.951)\tPrec@5 96.000 (96.463)\n",
            "Test: [50/100]\tTime 0.017 (0.030)\tLoss 5.8578 (6.8197)\tPrec@1 75.000 (70.392)\tPrec@5 96.000 (96.510)\n",
            "Test: [60/100]\tTime 0.029 (0.029)\tLoss 6.3077 (6.8377)\tPrec@1 72.000 (70.377)\tPrec@5 95.000 (96.328)\n",
            "Test: [70/100]\tTime 0.020 (0.028)\tLoss 7.4882 (6.8538)\tPrec@1 67.000 (70.127)\tPrec@5 96.000 (96.366)\n",
            "Test: [80/100]\tTime 0.021 (0.028)\tLoss 6.1779 (6.8050)\tPrec@1 74.000 (70.259)\tPrec@5 95.000 (96.358)\n",
            "Test: [90/100]\tTime 0.022 (0.027)\tLoss 6.7137 (6.8872)\tPrec@1 76.000 (69.868)\tPrec@5 96.000 (96.319)\n",
            "val Results: Prec@1 69.740 Prec@5 96.360 Loss 6.91051\n",
            "val Class Accuracy: [0.944,0.978,0.768,0.697,0.839,0.578,0.839,0.499,0.310,0.522]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [90][0/110], lr: 0.01000\tTime 0.444 (0.444)\tData 0.354 (0.354)\tLoss 0.9394 (0.9394)\tPrec@1 96.875 (96.875)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [90][10/110], lr: 0.01000\tTime 0.056 (0.100)\tData 0.010 (0.039)\tLoss 1.1629 (1.3493)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [90][20/110], lr: 0.01000\tTime 0.040 (0.080)\tData 0.000 (0.023)\tLoss 1.3647 (1.3875)\tPrec@1 92.969 (92.560)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [90][30/110], lr: 0.01000\tTime 0.051 (0.072)\tData 0.004 (0.017)\tLoss 1.6651 (1.4359)\tPrec@1 92.188 (92.490)\tPrec@5 98.438 (99.597)\n",
            "Epoch: [90][40/110], lr: 0.01000\tTime 0.047 (0.069)\tData 0.000 (0.014)\tLoss 1.0041 (1.3993)\tPrec@1 94.531 (92.588)\tPrec@5 99.219 (99.486)\n",
            "Epoch: [90][50/110], lr: 0.01000\tTime 0.055 (0.066)\tData 0.010 (0.012)\tLoss 2.5044 (1.4345)\tPrec@1 86.719 (92.279)\tPrec@5 99.219 (99.510)\n",
            "Epoch: [90][60/110], lr: 0.01000\tTime 0.064 (0.065)\tData 0.006 (0.011)\tLoss 1.3748 (1.4153)\tPrec@1 92.969 (92.495)\tPrec@5 99.219 (99.513)\n",
            "Epoch: [90][70/110], lr: 0.01000\tTime 0.041 (0.063)\tData 0.000 (0.010)\tLoss 0.7261 (1.4164)\tPrec@1 97.656 (92.507)\tPrec@5 100.000 (99.560)\n",
            "Epoch: [90][80/110], lr: 0.01000\tTime 0.045 (0.063)\tData 0.000 (0.009)\tLoss 1.2642 (1.4419)\tPrec@1 95.312 (92.323)\tPrec@5 100.000 (99.585)\n",
            "Epoch: [90][90/110], lr: 0.01000\tTime 0.062 (0.063)\tData 0.000 (0.009)\tLoss 1.6036 (1.4343)\tPrec@1 91.406 (92.445)\tPrec@5 100.000 (99.596)\n",
            "Epoch: [90][100/110], lr: 0.01000\tTime 0.092 (0.063)\tData 0.000 (0.008)\tLoss 1.5787 (1.4297)\tPrec@1 91.406 (92.481)\tPrec@5 100.000 (99.606)\n",
            "Test: [0/100]\tTime 0.240 (0.240)\tLoss 8.9433 (8.9433)\tPrec@1 55.000 (55.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.025 (0.051)\tLoss 6.1598 (7.9138)\tPrec@1 72.000 (64.545)\tPrec@5 96.000 (97.636)\n",
            "Test: [20/100]\tTime 0.010 (0.038)\tLoss 7.5991 (7.8762)\tPrec@1 66.000 (65.238)\tPrec@5 98.000 (97.048)\n",
            "Test: [30/100]\tTime 0.046 (0.034)\tLoss 6.9136 (7.8177)\tPrec@1 69.000 (66.032)\tPrec@5 96.000 (97.032)\n",
            "Test: [40/100]\tTime 0.039 (0.032)\tLoss 8.2844 (7.8741)\tPrec@1 64.000 (66.024)\tPrec@5 95.000 (96.854)\n",
            "Test: [50/100]\tTime 0.031 (0.030)\tLoss 7.0409 (7.8413)\tPrec@1 71.000 (66.235)\tPrec@5 97.000 (96.804)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 7.3957 (7.8615)\tPrec@1 68.000 (66.033)\tPrec@5 96.000 (96.738)\n",
            "Test: [70/100]\tTime 0.024 (0.029)\tLoss 7.4752 (7.8907)\tPrec@1 68.000 (65.986)\tPrec@5 98.000 (96.634)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 6.5021 (7.8770)\tPrec@1 71.000 (65.951)\tPrec@5 99.000 (96.642)\n",
            "Test: [90/100]\tTime 0.035 (0.028)\tLoss 7.7946 (7.9227)\tPrec@1 69.000 (65.681)\tPrec@5 100.000 (96.648)\n",
            "val Results: Prec@1 65.750 Prec@5 96.680 Loss 7.93774\n",
            "val Class Accuracy: [0.942,0.984,0.902,0.609,0.630,0.595,0.633,0.467,0.509,0.304]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [91][0/110], lr: 0.01000\tTime 0.365 (0.365)\tData 0.283 (0.283)\tLoss 1.7915 (1.7915)\tPrec@1 90.625 (90.625)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [91][10/110], lr: 0.01000\tTime 0.051 (0.100)\tData 0.014 (0.038)\tLoss 0.6967 (1.3439)\tPrec@1 96.094 (92.330)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [91][20/110], lr: 0.01000\tTime 0.068 (0.080)\tData 0.001 (0.022)\tLoss 1.4766 (1.4253)\tPrec@1 93.750 (92.188)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [91][30/110], lr: 0.01000\tTime 0.080 (0.073)\tData 0.010 (0.016)\tLoss 1.3331 (1.3810)\tPrec@1 92.188 (92.490)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [91][40/110], lr: 0.01000\tTime 0.059 (0.069)\tData 0.000 (0.013)\tLoss 1.9082 (1.4191)\tPrec@1 90.625 (92.454)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [91][50/110], lr: 0.01000\tTime 0.064 (0.067)\tData 0.005 (0.012)\tLoss 1.4187 (1.4796)\tPrec@1 92.969 (92.218)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [91][60/110], lr: 0.01000\tTime 0.070 (0.066)\tData 0.012 (0.011)\tLoss 1.2374 (1.4909)\tPrec@1 92.969 (92.187)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [91][70/110], lr: 0.01000\tTime 0.061 (0.064)\tData 0.000 (0.010)\tLoss 1.9197 (1.4844)\tPrec@1 88.281 (92.331)\tPrec@5 98.438 (99.681)\n",
            "Epoch: [91][80/110], lr: 0.01000\tTime 0.056 (0.064)\tData 0.000 (0.009)\tLoss 1.3521 (1.5058)\tPrec@1 89.844 (92.130)\tPrec@5 100.000 (99.643)\n",
            "Epoch: [91][90/110], lr: 0.01000\tTime 0.046 (0.063)\tData 0.002 (0.008)\tLoss 1.7218 (1.5044)\tPrec@1 92.969 (92.170)\tPrec@5 100.000 (99.657)\n",
            "Epoch: [91][100/110], lr: 0.01000\tTime 0.053 (0.062)\tData 0.006 (0.008)\tLoss 1.4045 (1.4895)\tPrec@1 92.969 (92.288)\tPrec@5 100.000 (99.675)\n",
            "Test: [0/100]\tTime 0.308 (0.308)\tLoss 6.3251 (6.3251)\tPrec@1 71.000 (71.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.013 (0.050)\tLoss 5.4320 (6.3144)\tPrec@1 75.000 (72.182)\tPrec@5 94.000 (97.364)\n",
            "Test: [20/100]\tTime 0.030 (0.039)\tLoss 5.6334 (6.2515)\tPrec@1 73.000 (72.143)\tPrec@5 99.000 (97.190)\n",
            "Test: [30/100]\tTime 0.016 (0.034)\tLoss 6.5161 (6.3312)\tPrec@1 71.000 (71.903)\tPrec@5 95.000 (96.903)\n",
            "Test: [40/100]\tTime 0.028 (0.032)\tLoss 7.0616 (6.3788)\tPrec@1 65.000 (71.610)\tPrec@5 97.000 (96.878)\n",
            "Test: [50/100]\tTime 0.020 (0.030)\tLoss 6.8938 (6.3395)\tPrec@1 71.000 (72.098)\tPrec@5 98.000 (96.980)\n",
            "Test: [60/100]\tTime 0.010 (0.029)\tLoss 6.4156 (6.3761)\tPrec@1 72.000 (71.852)\tPrec@5 97.000 (96.885)\n",
            "Test: [70/100]\tTime 0.019 (0.029)\tLoss 6.4561 (6.4298)\tPrec@1 70.000 (71.521)\tPrec@5 97.000 (96.789)\n",
            "Test: [80/100]\tTime 0.024 (0.028)\tLoss 5.2517 (6.3509)\tPrec@1 78.000 (71.938)\tPrec@5 98.000 (96.901)\n",
            "Test: [90/100]\tTime 0.025 (0.028)\tLoss 6.3283 (6.4264)\tPrec@1 74.000 (71.495)\tPrec@5 97.000 (96.956)\n",
            "val Results: Prec@1 71.410 Prec@5 97.000 Loss 6.44964\n",
            "val Class Accuracy: [0.920,0.967,0.863,0.618,0.722,0.547,0.769,0.632,0.486,0.617]\n",
            "Best Prec@1: 73.980\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [92][0/110], lr: 0.01000\tTime 0.365 (0.365)\tData 0.284 (0.284)\tLoss 0.8209 (0.8209)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [92][10/110], lr: 0.01000\tTime 0.060 (0.100)\tData 0.007 (0.032)\tLoss 1.8336 (1.2027)\tPrec@1 92.188 (93.821)\tPrec@5 99.219 (99.929)\n",
            "Epoch: [92][20/110], lr: 0.01000\tTime 0.049 (0.079)\tData 0.006 (0.020)\tLoss 1.3637 (1.2634)\tPrec@1 92.188 (93.378)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [92][30/110], lr: 0.01000\tTime 0.049 (0.073)\tData 0.009 (0.015)\tLoss 1.1111 (1.2727)\tPrec@1 92.969 (93.296)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [92][40/110], lr: 0.01000\tTime 0.066 (0.069)\tData 0.006 (0.013)\tLoss 1.8086 (1.2995)\tPrec@1 89.844 (93.102)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [92][50/110], lr: 0.01000\tTime 0.045 (0.066)\tData 0.000 (0.011)\tLoss 1.2509 (1.3458)\tPrec@1 94.531 (92.923)\tPrec@5 100.000 (99.755)\n",
            "Epoch: [92][60/110], lr: 0.01000\tTime 0.059 (0.065)\tData 0.000 (0.010)\tLoss 1.1820 (1.3650)\tPrec@1 91.406 (92.764)\tPrec@5 99.219 (99.718)\n",
            "Epoch: [92][70/110], lr: 0.01000\tTime 0.054 (0.064)\tData 0.007 (0.010)\tLoss 1.3727 (1.3911)\tPrec@1 92.969 (92.562)\tPrec@5 99.219 (99.670)\n",
            "Epoch: [92][80/110], lr: 0.01000\tTime 0.059 (0.063)\tData 0.013 (0.009)\tLoss 1.7603 (1.4164)\tPrec@1 92.188 (92.438)\tPrec@5 100.000 (99.653)\n",
            "Epoch: [92][90/110], lr: 0.01000\tTime 0.039 (0.062)\tData 0.001 (0.009)\tLoss 2.0775 (1.4394)\tPrec@1 89.844 (92.213)\tPrec@5 98.438 (99.665)\n",
            "Epoch: [92][100/110], lr: 0.01000\tTime 0.064 (0.062)\tData 0.006 (0.009)\tLoss 1.1174 (1.4460)\tPrec@1 95.312 (92.180)\tPrec@5 100.000 (99.675)\n",
            "Test: [0/100]\tTime 0.325 (0.325)\tLoss 4.3003 (4.3003)\tPrec@1 81.000 (81.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.021 (0.048)\tLoss 4.0513 (5.0847)\tPrec@1 82.000 (77.545)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.035 (0.047)\tLoss 5.0633 (5.0545)\tPrec@1 73.000 (76.905)\tPrec@5 99.000 (97.857)\n",
            "Test: [30/100]\tTime 0.042 (0.044)\tLoss 5.8693 (5.1682)\tPrec@1 70.000 (76.452)\tPrec@5 99.000 (98.000)\n",
            "Test: [40/100]\tTime 0.038 (0.042)\tLoss 5.0324 (5.1888)\tPrec@1 78.000 (76.415)\tPrec@5 97.000 (97.780)\n",
            "Test: [50/100]\tTime 0.045 (0.041)\tLoss 5.2925 (5.1726)\tPrec@1 78.000 (76.529)\tPrec@5 98.000 (97.765)\n",
            "Test: [60/100]\tTime 0.039 (0.041)\tLoss 5.7547 (5.2441)\tPrec@1 74.000 (76.148)\tPrec@5 99.000 (97.721)\n",
            "Test: [70/100]\tTime 0.030 (0.040)\tLoss 4.4000 (5.2490)\tPrec@1 79.000 (76.056)\tPrec@5 99.000 (97.746)\n",
            "Test: [80/100]\tTime 0.046 (0.041)\tLoss 5.1352 (5.2438)\tPrec@1 79.000 (76.136)\tPrec@5 98.000 (97.802)\n",
            "Test: [90/100]\tTime 0.026 (0.040)\tLoss 5.3221 (5.2997)\tPrec@1 77.000 (75.846)\tPrec@5 100.000 (97.725)\n",
            "val Results: Prec@1 75.870 Prec@5 97.780 Loss 5.28630\n",
            "val Class Accuracy: [0.938,0.981,0.804,0.663,0.711,0.713,0.827,0.622,0.637,0.691]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [93][0/110], lr: 0.01000\tTime 0.658 (0.658)\tData 0.521 (0.521)\tLoss 1.3035 (1.3035)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][10/110], lr: 0.01000\tTime 0.038 (0.123)\tData 0.000 (0.051)\tLoss 0.9511 (1.1389)\tPrec@1 95.312 (94.247)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [93][20/110], lr: 0.01000\tTime 0.045 (0.095)\tData 0.000 (0.029)\tLoss 1.9080 (1.2101)\tPrec@1 90.625 (93.452)\tPrec@5 98.438 (99.740)\n",
            "Epoch: [93][30/110], lr: 0.01000\tTime 0.053 (0.083)\tData 0.010 (0.022)\tLoss 1.6317 (1.2287)\tPrec@1 91.406 (93.498)\tPrec@5 99.219 (99.672)\n",
            "Epoch: [93][40/110], lr: 0.01000\tTime 0.076 (0.077)\tData 0.001 (0.018)\tLoss 1.6604 (1.3093)\tPrec@1 89.844 (93.083)\tPrec@5 100.000 (99.676)\n",
            "Epoch: [93][50/110], lr: 0.01000\tTime 0.044 (0.073)\tData 0.010 (0.015)\tLoss 1.0659 (1.3557)\tPrec@1 94.531 (92.816)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [93][60/110], lr: 0.01000\tTime 0.041 (0.071)\tData 0.000 (0.013)\tLoss 1.2307 (1.3643)\tPrec@1 95.312 (92.751)\tPrec@5 98.438 (99.667)\n",
            "Epoch: [93][70/110], lr: 0.01000\tTime 0.049 (0.069)\tData 0.000 (0.012)\tLoss 1.2101 (1.3692)\tPrec@1 95.312 (92.804)\tPrec@5 100.000 (99.714)\n",
            "Epoch: [93][80/110], lr: 0.01000\tTime 0.052 (0.068)\tData 0.000 (0.011)\tLoss 1.0088 (1.3860)\tPrec@1 94.531 (92.776)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [93][90/110], lr: 0.01000\tTime 0.054 (0.067)\tData 0.005 (0.010)\tLoss 1.1360 (1.3740)\tPrec@1 93.750 (92.849)\tPrec@5 99.219 (99.725)\n",
            "Epoch: [93][100/110], lr: 0.01000\tTime 0.064 (0.067)\tData 0.006 (0.010)\tLoss 0.9004 (1.3832)\tPrec@1 95.312 (92.845)\tPrec@5 100.000 (99.729)\n",
            "Test: [0/100]\tTime 0.280 (0.280)\tLoss 5.1311 (5.1311)\tPrec@1 76.000 (76.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.017 (0.050)\tLoss 4.1338 (5.6273)\tPrec@1 79.000 (74.545)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/100]\tTime 0.030 (0.040)\tLoss 5.9398 (5.5352)\tPrec@1 72.000 (74.762)\tPrec@5 94.000 (95.857)\n",
            "Test: [30/100]\tTime 0.027 (0.035)\tLoss 6.0607 (5.7230)\tPrec@1 74.000 (73.903)\tPrec@5 95.000 (95.710)\n",
            "Test: [40/100]\tTime 0.039 (0.033)\tLoss 6.7819 (5.7667)\tPrec@1 70.000 (73.951)\tPrec@5 89.000 (95.415)\n",
            "Test: [50/100]\tTime 0.030 (0.032)\tLoss 5.4049 (5.6735)\tPrec@1 78.000 (74.373)\tPrec@5 94.000 (95.510)\n",
            "Test: [60/100]\tTime 0.042 (0.030)\tLoss 5.9216 (5.7140)\tPrec@1 76.000 (74.311)\tPrec@5 96.000 (95.541)\n",
            "Test: [70/100]\tTime 0.024 (0.030)\tLoss 5.6902 (5.7156)\tPrec@1 75.000 (74.296)\tPrec@5 97.000 (95.676)\n",
            "Test: [80/100]\tTime 0.023 (0.029)\tLoss 4.7735 (5.7148)\tPrec@1 79.000 (74.284)\tPrec@5 97.000 (95.716)\n",
            "Test: [90/100]\tTime 0.022 (0.028)\tLoss 5.5828 (5.7253)\tPrec@1 75.000 (74.275)\tPrec@5 99.000 (95.736)\n",
            "val Results: Prec@1 74.370 Prec@5 95.740 Loss 5.72763\n",
            "val Class Accuracy: [0.866,0.975,0.803,0.604,0.827,0.573,0.889,0.331,0.817,0.752]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [94][0/110], lr: 0.01000\tTime 0.457 (0.457)\tData 0.364 (0.364)\tLoss 1.1979 (1.1979)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][10/110], lr: 0.01000\tTime 0.066 (0.100)\tData 0.010 (0.038)\tLoss 0.9580 (1.1610)\tPrec@1 96.094 (94.176)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [94][20/110], lr: 0.01000\tTime 0.054 (0.079)\tData 0.000 (0.022)\tLoss 1.6578 (1.2333)\tPrec@1 92.188 (93.750)\tPrec@5 99.219 (99.777)\n",
            "Epoch: [94][30/110], lr: 0.01000\tTime 0.053 (0.073)\tData 0.011 (0.017)\tLoss 0.8259 (1.1925)\tPrec@1 96.094 (94.153)\tPrec@5 100.000 (99.773)\n",
            "Epoch: [94][40/110], lr: 0.01000\tTime 0.066 (0.068)\tData 0.007 (0.014)\tLoss 1.2127 (1.2171)\tPrec@1 92.969 (93.941)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [94][50/110], lr: 0.01000\tTime 0.050 (0.067)\tData 0.007 (0.012)\tLoss 1.2483 (1.2123)\tPrec@1 93.750 (93.949)\tPrec@5 99.219 (99.724)\n",
            "Epoch: [94][60/110], lr: 0.01000\tTime 0.060 (0.065)\tData 0.005 (0.011)\tLoss 1.3481 (1.2334)\tPrec@1 92.969 (93.814)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [94][70/110], lr: 0.01000\tTime 0.041 (0.064)\tData 0.000 (0.010)\tLoss 2.0500 (1.2901)\tPrec@1 88.281 (93.420)\tPrec@5 100.000 (99.736)\n",
            "Epoch: [94][80/110], lr: 0.01000\tTime 0.043 (0.063)\tData 0.000 (0.010)\tLoss 0.8461 (1.2995)\tPrec@1 96.094 (93.335)\tPrec@5 100.000 (99.711)\n",
            "Epoch: [94][90/110], lr: 0.01000\tTime 0.042 (0.062)\tData 0.000 (0.009)\tLoss 1.1277 (1.3006)\tPrec@1 94.531 (93.372)\tPrec@5 99.219 (99.717)\n",
            "Epoch: [94][100/110], lr: 0.01000\tTime 0.044 (0.062)\tData 0.000 (0.008)\tLoss 1.8970 (1.3294)\tPrec@1 91.406 (93.232)\tPrec@5 100.000 (99.698)\n",
            "Test: [0/100]\tTime 0.294 (0.294)\tLoss 5.5276 (5.5276)\tPrec@1 78.000 (78.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.034 (0.055)\tLoss 5.0228 (5.4285)\tPrec@1 79.000 (76.000)\tPrec@5 96.000 (97.636)\n",
            "Test: [20/100]\tTime 0.027 (0.040)\tLoss 5.3316 (5.4367)\tPrec@1 75.000 (75.857)\tPrec@5 100.000 (97.762)\n",
            "Test: [30/100]\tTime 0.010 (0.036)\tLoss 5.8959 (5.6447)\tPrec@1 74.000 (75.226)\tPrec@5 99.000 (97.419)\n",
            "Test: [40/100]\tTime 0.012 (0.034)\tLoss 5.5595 (5.7178)\tPrec@1 73.000 (74.780)\tPrec@5 98.000 (97.244)\n",
            "Test: [50/100]\tTime 0.018 (0.032)\tLoss 5.8244 (5.5729)\tPrec@1 76.000 (75.529)\tPrec@5 96.000 (97.314)\n",
            "Test: [60/100]\tTime 0.019 (0.031)\tLoss 4.4613 (5.5663)\tPrec@1 81.000 (75.574)\tPrec@5 96.000 (97.344)\n",
            "Test: [70/100]\tTime 0.034 (0.031)\tLoss 5.2075 (5.5746)\tPrec@1 75.000 (75.324)\tPrec@5 98.000 (97.423)\n",
            "Test: [80/100]\tTime 0.035 (0.030)\tLoss 5.2533 (5.5363)\tPrec@1 77.000 (75.481)\tPrec@5 97.000 (97.469)\n",
            "Test: [90/100]\tTime 0.024 (0.029)\tLoss 4.8127 (5.5844)\tPrec@1 80.000 (75.297)\tPrec@5 97.000 (97.505)\n",
            "val Results: Prec@1 75.260 Prec@5 97.490 Loss 5.58580\n",
            "val Class Accuracy: [0.909,0.928,0.785,0.669,0.735,0.787,0.763,0.636,0.567,0.747]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [95][0/110], lr: 0.01000\tTime 0.396 (0.396)\tData 0.286 (0.286)\tLoss 1.3686 (1.3686)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][10/110], lr: 0.01000\tTime 0.073 (0.098)\tData 0.012 (0.032)\tLoss 0.9545 (1.2684)\tPrec@1 94.531 (93.395)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [95][20/110], lr: 0.01000\tTime 0.052 (0.079)\tData 0.007 (0.020)\tLoss 1.1785 (1.3755)\tPrec@1 92.969 (92.671)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [95][30/110], lr: 0.01000\tTime 0.061 (0.072)\tData 0.011 (0.015)\tLoss 1.4800 (1.3948)\tPrec@1 91.406 (92.767)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [95][40/110], lr: 0.01000\tTime 0.066 (0.068)\tData 0.012 (0.012)\tLoss 2.0504 (1.3676)\tPrec@1 90.625 (92.912)\tPrec@5 99.219 (99.733)\n",
            "Epoch: [95][50/110], lr: 0.01000\tTime 0.049 (0.066)\tData 0.007 (0.011)\tLoss 0.9977 (1.3682)\tPrec@1 96.094 (92.938)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [95][60/110], lr: 0.01000\tTime 0.045 (0.064)\tData 0.000 (0.010)\tLoss 1.7043 (1.4016)\tPrec@1 89.844 (92.713)\tPrec@5 100.000 (99.744)\n",
            "Epoch: [95][70/110], lr: 0.01000\tTime 0.040 (0.064)\tData 0.000 (0.009)\tLoss 1.3360 (1.4070)\tPrec@1 94.531 (92.661)\tPrec@5 99.219 (99.714)\n",
            "Epoch: [95][80/110], lr: 0.01000\tTime 0.061 (0.063)\tData 0.005 (0.008)\tLoss 1.3478 (1.4211)\tPrec@1 92.969 (92.583)\tPrec@5 100.000 (99.730)\n",
            "Epoch: [95][90/110], lr: 0.01000\tTime 0.083 (0.063)\tData 0.014 (0.008)\tLoss 1.0483 (1.4100)\tPrec@1 95.312 (92.591)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [95][100/110], lr: 0.01000\tTime 0.070 (0.063)\tData 0.005 (0.007)\tLoss 1.3083 (1.3852)\tPrec@1 92.969 (92.768)\tPrec@5 100.000 (99.752)\n",
            "Test: [0/100]\tTime 0.248 (0.248)\tLoss 7.3944 (7.3944)\tPrec@1 69.000 (69.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/100]\tTime 0.023 (0.052)\tLoss 6.4184 (6.9227)\tPrec@1 70.000 (70.273)\tPrec@5 98.000 (97.727)\n",
            "Test: [20/100]\tTime 0.020 (0.038)\tLoss 6.6886 (6.9582)\tPrec@1 73.000 (70.095)\tPrec@5 100.000 (97.476)\n",
            "Test: [30/100]\tTime 0.037 (0.034)\tLoss 6.9479 (7.1465)\tPrec@1 69.000 (69.355)\tPrec@5 97.000 (97.484)\n",
            "Test: [40/100]\tTime 0.035 (0.031)\tLoss 7.1426 (7.1659)\tPrec@1 69.000 (69.341)\tPrec@5 96.000 (97.244)\n",
            "Test: [50/100]\tTime 0.045 (0.031)\tLoss 6.3069 (7.1093)\tPrec@1 72.000 (69.490)\tPrec@5 98.000 (97.314)\n",
            "Test: [60/100]\tTime 0.018 (0.030)\tLoss 6.7922 (7.1243)\tPrec@1 69.000 (69.426)\tPrec@5 98.000 (97.246)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 6.1384 (7.1069)\tPrec@1 72.000 (69.437)\tPrec@5 98.000 (97.225)\n",
            "Test: [80/100]\tTime 0.041 (0.028)\tLoss 7.1537 (7.0732)\tPrec@1 72.000 (69.630)\tPrec@5 96.000 (97.284)\n",
            "Test: [90/100]\tTime 0.013 (0.027)\tLoss 7.0904 (7.1469)\tPrec@1 70.000 (69.253)\tPrec@5 97.000 (97.297)\n",
            "val Results: Prec@1 69.290 Prec@5 97.260 Loss 7.16087\n",
            "val Class Accuracy: [0.917,0.991,0.783,0.768,0.852,0.577,0.594,0.478,0.507,0.462]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [96][0/110], lr: 0.01000\tTime 0.489 (0.489)\tData 0.394 (0.394)\tLoss 1.0250 (1.0250)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][10/110], lr: 0.01000\tTime 0.061 (0.102)\tData 0.007 (0.041)\tLoss 1.8496 (1.2549)\tPrec@1 92.188 (93.608)\tPrec@5 99.219 (99.716)\n",
            "Epoch: [96][20/110], lr: 0.01000\tTime 0.065 (0.081)\tData 0.016 (0.025)\tLoss 1.7764 (1.3234)\tPrec@1 87.500 (93.043)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [96][30/110], lr: 0.01000\tTime 0.047 (0.073)\tData 0.000 (0.018)\tLoss 0.8334 (1.3168)\tPrec@1 95.312 (93.145)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [96][40/110], lr: 0.01000\tTime 0.077 (0.070)\tData 0.004 (0.015)\tLoss 0.9984 (1.2793)\tPrec@1 93.750 (93.407)\tPrec@5 99.219 (99.676)\n",
            "Epoch: [96][50/110], lr: 0.01000\tTime 0.069 (0.067)\tData 0.005 (0.013)\tLoss 1.7243 (1.3724)\tPrec@1 92.188 (92.816)\tPrec@5 100.000 (99.663)\n",
            "Epoch: [96][60/110], lr: 0.01000\tTime 0.042 (0.065)\tData 0.000 (0.011)\tLoss 1.7313 (1.3790)\tPrec@1 92.188 (92.892)\tPrec@5 100.000 (99.705)\n",
            "Epoch: [96][70/110], lr: 0.01000\tTime 0.053 (0.065)\tData 0.009 (0.010)\tLoss 1.0421 (1.3707)\tPrec@1 94.531 (92.925)\tPrec@5 100.000 (99.681)\n",
            "Epoch: [96][80/110], lr: 0.01000\tTime 0.059 (0.064)\tData 0.007 (0.010)\tLoss 0.8643 (1.3557)\tPrec@1 95.312 (92.988)\tPrec@5 100.000 (99.653)\n",
            "Epoch: [96][90/110], lr: 0.01000\tTime 0.069 (0.063)\tData 0.007 (0.009)\tLoss 1.1268 (1.3450)\tPrec@1 93.750 (93.020)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [96][100/110], lr: 0.01000\tTime 0.075 (0.063)\tData 0.000 (0.008)\tLoss 1.5527 (1.3635)\tPrec@1 94.531 (92.976)\tPrec@5 100.000 (99.683)\n",
            "Test: [0/100]\tTime 0.301 (0.301)\tLoss 9.2368 (9.2368)\tPrec@1 60.000 (60.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/100]\tTime 0.029 (0.053)\tLoss 6.7236 (8.1663)\tPrec@1 71.000 (64.818)\tPrec@5 96.000 (94.727)\n",
            "Test: [20/100]\tTime 0.044 (0.041)\tLoss 6.3717 (8.2409)\tPrec@1 74.000 (64.571)\tPrec@5 97.000 (94.333)\n",
            "Test: [30/100]\tTime 0.047 (0.035)\tLoss 8.8998 (8.3883)\tPrec@1 62.000 (64.161)\tPrec@5 88.000 (93.548)\n",
            "Test: [40/100]\tTime 0.020 (0.032)\tLoss 8.1177 (8.3839)\tPrec@1 65.000 (64.195)\tPrec@5 93.000 (93.439)\n",
            "Test: [50/100]\tTime 0.023 (0.031)\tLoss 7.9974 (8.3011)\tPrec@1 68.000 (64.608)\tPrec@5 91.000 (93.549)\n",
            "Test: [60/100]\tTime 0.026 (0.030)\tLoss 6.9528 (8.2847)\tPrec@1 68.000 (64.607)\tPrec@5 96.000 (93.525)\n",
            "Test: [70/100]\tTime 0.018 (0.030)\tLoss 8.0147 (8.2764)\tPrec@1 66.000 (64.789)\tPrec@5 93.000 (93.549)\n",
            "Test: [80/100]\tTime 0.034 (0.029)\tLoss 7.8626 (8.2449)\tPrec@1 68.000 (64.852)\tPrec@5 94.000 (93.556)\n",
            "Test: [90/100]\tTime 0.023 (0.029)\tLoss 8.6556 (8.3472)\tPrec@1 65.000 (64.462)\tPrec@5 90.000 (93.407)\n",
            "val Results: Prec@1 64.460 Prec@5 93.380 Loss 8.35925\n",
            "val Class Accuracy: [0.979,0.962,0.738,0.498,0.800,0.783,0.755,0.298,0.309,0.324]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [97][0/110], lr: 0.01000\tTime 0.394 (0.394)\tData 0.297 (0.297)\tLoss 1.4599 (1.4599)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [97][10/110], lr: 0.01000\tTime 0.040 (0.097)\tData 0.000 (0.035)\tLoss 1.5752 (1.4984)\tPrec@1 92.188 (92.259)\tPrec@5 97.656 (99.432)\n",
            "Epoch: [97][20/110], lr: 0.01000\tTime 0.048 (0.080)\tData 0.002 (0.020)\tLoss 1.3062 (1.5220)\tPrec@1 92.188 (91.853)\tPrec@5 100.000 (99.591)\n",
            "Epoch: [97][30/110], lr: 0.01000\tTime 0.057 (0.075)\tData 0.004 (0.016)\tLoss 1.3552 (1.4562)\tPrec@1 90.625 (92.339)\tPrec@5 100.000 (99.647)\n",
            "Epoch: [97][40/110], lr: 0.01000\tTime 0.076 (0.072)\tData 0.006 (0.013)\tLoss 1.1814 (1.4381)\tPrec@1 93.750 (92.416)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [97][50/110], lr: 0.01000\tTime 0.036 (0.069)\tData 0.000 (0.011)\tLoss 1.0793 (1.4141)\tPrec@1 93.750 (92.540)\tPrec@5 100.000 (99.678)\n",
            "Epoch: [97][60/110], lr: 0.01000\tTime 0.093 (0.069)\tData 0.000 (0.010)\tLoss 1.4663 (1.3933)\tPrec@1 92.969 (92.713)\tPrec@5 99.219 (99.680)\n",
            "Epoch: [97][70/110], lr: 0.01000\tTime 0.084 (0.071)\tData 0.011 (0.009)\tLoss 1.5272 (1.3915)\tPrec@1 92.969 (92.749)\tPrec@5 100.000 (99.670)\n",
            "Epoch: [97][80/110], lr: 0.01000\tTime 0.084 (0.073)\tData 0.000 (0.009)\tLoss 0.9073 (1.4013)\tPrec@1 94.531 (92.679)\tPrec@5 100.000 (99.672)\n",
            "Epoch: [97][90/110], lr: 0.01000\tTime 0.115 (0.075)\tData 0.010 (0.009)\tLoss 1.1624 (1.4025)\tPrec@1 93.750 (92.660)\tPrec@5 99.219 (99.648)\n",
            "Epoch: [97][100/110], lr: 0.01000\tTime 0.105 (0.077)\tData 0.014 (0.009)\tLoss 1.1518 (1.3639)\tPrec@1 94.531 (92.891)\tPrec@5 100.000 (99.660)\n",
            "Test: [0/100]\tTime 0.256 (0.256)\tLoss 6.1775 (6.1775)\tPrec@1 73.000 (73.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.018 (0.056)\tLoss 6.0681 (6.7739)\tPrec@1 72.000 (69.727)\tPrec@5 97.000 (97.636)\n",
            "Test: [20/100]\tTime 0.038 (0.040)\tLoss 5.6997 (6.7067)\tPrec@1 75.000 (70.000)\tPrec@5 98.000 (97.333)\n",
            "Test: [30/100]\tTime 0.012 (0.035)\tLoss 6.7131 (6.8411)\tPrec@1 69.000 (69.839)\tPrec@5 96.000 (97.032)\n",
            "Test: [40/100]\tTime 0.036 (0.034)\tLoss 6.7323 (6.8406)\tPrec@1 70.000 (69.780)\tPrec@5 97.000 (96.707)\n",
            "Test: [50/100]\tTime 0.027 (0.032)\tLoss 6.2923 (6.7554)\tPrec@1 74.000 (70.314)\tPrec@5 96.000 (96.804)\n",
            "Test: [60/100]\tTime 0.029 (0.031)\tLoss 7.1349 (6.8390)\tPrec@1 68.000 (69.869)\tPrec@5 100.000 (96.787)\n",
            "Test: [70/100]\tTime 0.013 (0.030)\tLoss 6.1131 (6.8519)\tPrec@1 70.000 (69.859)\tPrec@5 99.000 (96.859)\n",
            "Test: [80/100]\tTime 0.019 (0.029)\tLoss 7.2265 (6.8210)\tPrec@1 71.000 (69.975)\tPrec@5 95.000 (96.815)\n",
            "Test: [90/100]\tTime 0.025 (0.029)\tLoss 7.1643 (6.9009)\tPrec@1 68.000 (69.648)\tPrec@5 98.000 (96.824)\n",
            "val Results: Prec@1 69.650 Prec@5 96.870 Loss 6.91486\n",
            "val Class Accuracy: [0.978,0.971,0.732,0.690,0.690,0.613,0.589,0.603,0.645,0.454]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/110], lr: 0.01000\tTime 0.399 (0.399)\tData 0.285 (0.285)\tLoss 1.0450 (1.0450)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][10/110], lr: 0.01000\tTime 0.075 (0.101)\tData 0.000 (0.035)\tLoss 0.8445 (1.2428)\tPrec@1 96.094 (93.466)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [98][20/110], lr: 0.01000\tTime 0.072 (0.082)\tData 0.013 (0.020)\tLoss 1.2852 (1.4271)\tPrec@1 92.188 (92.597)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [98][30/110], lr: 0.01000\tTime 0.063 (0.074)\tData 0.003 (0.015)\tLoss 1.4334 (1.4293)\tPrec@1 92.969 (92.591)\tPrec@5 100.000 (99.672)\n",
            "Epoch: [98][40/110], lr: 0.01000\tTime 0.037 (0.070)\tData 0.000 (0.013)\tLoss 1.0626 (1.3966)\tPrec@1 94.531 (92.778)\tPrec@5 99.219 (99.676)\n",
            "Epoch: [98][50/110], lr: 0.01000\tTime 0.042 (0.067)\tData 0.000 (0.011)\tLoss 1.4903 (1.4164)\tPrec@1 92.969 (92.724)\tPrec@5 99.219 (99.663)\n",
            "Epoch: [98][60/110], lr: 0.01000\tTime 0.065 (0.066)\tData 0.012 (0.010)\tLoss 1.4700 (1.4181)\tPrec@1 92.969 (92.636)\tPrec@5 99.219 (99.667)\n",
            "Epoch: [98][70/110], lr: 0.01000\tTime 0.064 (0.065)\tData 0.006 (0.010)\tLoss 1.8361 (1.4458)\tPrec@1 90.625 (92.496)\tPrec@5 100.000 (99.659)\n",
            "Epoch: [98][80/110], lr: 0.01000\tTime 0.069 (0.064)\tData 0.012 (0.009)\tLoss 1.0683 (1.4388)\tPrec@1 94.531 (92.525)\tPrec@5 100.000 (99.682)\n",
            "Epoch: [98][90/110], lr: 0.01000\tTime 0.060 (0.064)\tData 0.000 (0.008)\tLoss 1.2040 (1.4319)\tPrec@1 92.969 (92.565)\tPrec@5 100.000 (99.674)\n",
            "Epoch: [98][100/110], lr: 0.01000\tTime 0.068 (0.063)\tData 0.000 (0.008)\tLoss 2.2512 (1.4462)\tPrec@1 90.625 (92.474)\tPrec@5 99.219 (99.644)\n",
            "Test: [0/100]\tTime 0.235 (0.235)\tLoss 8.3292 (8.3292)\tPrec@1 66.000 (66.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/100]\tTime 0.021 (0.050)\tLoss 5.8084 (7.4439)\tPrec@1 74.000 (67.364)\tPrec@5 97.000 (97.273)\n",
            "Test: [20/100]\tTime 0.051 (0.040)\tLoss 5.8867 (7.4296)\tPrec@1 74.000 (67.762)\tPrec@5 99.000 (96.714)\n",
            "Test: [30/100]\tTime 0.026 (0.035)\tLoss 7.4284 (7.5696)\tPrec@1 66.000 (67.161)\tPrec@5 93.000 (96.613)\n",
            "Test: [40/100]\tTime 0.028 (0.033)\tLoss 8.1337 (7.5779)\tPrec@1 67.000 (67.220)\tPrec@5 95.000 (96.439)\n",
            "Test: [50/100]\tTime 0.011 (0.030)\tLoss 7.5923 (7.4409)\tPrec@1 67.000 (67.804)\tPrec@5 96.000 (96.627)\n",
            "Test: [60/100]\tTime 0.032 (0.030)\tLoss 6.4003 (7.4119)\tPrec@1 71.000 (67.852)\tPrec@5 94.000 (96.475)\n",
            "Test: [70/100]\tTime 0.010 (0.029)\tLoss 7.6264 (7.4231)\tPrec@1 64.000 (67.746)\tPrec@5 97.000 (96.465)\n",
            "Test: [80/100]\tTime 0.038 (0.029)\tLoss 7.0132 (7.3648)\tPrec@1 71.000 (68.012)\tPrec@5 94.000 (96.481)\n",
            "Test: [90/100]\tTime 0.042 (0.029)\tLoss 8.9027 (7.4618)\tPrec@1 61.000 (67.659)\tPrec@5 97.000 (96.516)\n",
            "val Results: Prec@1 67.740 Prec@5 96.590 Loss 7.45588\n",
            "val Class Accuracy: [0.963,0.977,0.758,0.791,0.690,0.622,0.662,0.565,0.283,0.463]\n",
            "Best Prec@1: 75.870\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/110], lr: 0.01000\tTime 0.482 (0.482)\tData 0.375 (0.375)\tLoss 0.9161 (0.9161)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][10/110], lr: 0.01000\tTime 0.065 (0.107)\tData 0.000 (0.038)\tLoss 1.3308 (1.2658)\tPrec@1 94.531 (93.537)\tPrec@5 99.219 (99.858)\n",
            "Epoch: [99][20/110], lr: 0.01000\tTime 0.075 (0.083)\tData 0.007 (0.021)\tLoss 0.7272 (1.3378)\tPrec@1 96.875 (93.006)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [99][30/110], lr: 0.01000\tTime 0.099 (0.077)\tData 0.000 (0.016)\tLoss 1.2839 (1.3190)\tPrec@1 92.969 (93.019)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [99][40/110], lr: 0.01000\tTime 0.048 (0.072)\tData 0.007 (0.013)\tLoss 1.7777 (1.3305)\tPrec@1 88.281 (92.835)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [99][50/110], lr: 0.01000\tTime 0.070 (0.070)\tData 0.007 (0.011)\tLoss 1.7103 (1.3278)\tPrec@1 92.188 (92.999)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [99][60/110], lr: 0.01000\tTime 0.087 (0.068)\tData 0.010 (0.010)\tLoss 0.5444 (1.3104)\tPrec@1 98.438 (93.135)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [99][70/110], lr: 0.01000\tTime 0.057 (0.067)\tData 0.000 (0.010)\tLoss 1.3354 (1.3347)\tPrec@1 93.750 (92.969)\tPrec@5 100.000 (99.769)\n",
            "Epoch: [99][80/110], lr: 0.01000\tTime 0.067 (0.066)\tData 0.008 (0.009)\tLoss 1.0847 (1.3291)\tPrec@1 96.094 (92.959)\tPrec@5 100.000 (99.778)\n",
            "Epoch: [99][90/110], lr: 0.01000\tTime 0.056 (0.065)\tData 0.007 (0.009)\tLoss 1.1227 (1.3224)\tPrec@1 93.750 (93.089)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [99][100/110], lr: 0.01000\tTime 0.052 (0.064)\tData 0.010 (0.008)\tLoss 1.1749 (1.3394)\tPrec@1 94.531 (93.007)\tPrec@5 99.219 (99.737)\n",
            "Test: [0/100]\tTime 0.273 (0.273)\tLoss 6.4245 (6.4245)\tPrec@1 69.000 (69.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/100]\tTime 0.013 (0.050)\tLoss 5.3284 (6.3554)\tPrec@1 76.000 (71.455)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/100]\tTime 0.045 (0.040)\tLoss 5.9136 (6.4546)\tPrec@1 74.000 (71.143)\tPrec@5 99.000 (96.762)\n",
            "Test: [30/100]\tTime 0.022 (0.035)\tLoss 6.5240 (6.6455)\tPrec@1 69.000 (70.161)\tPrec@5 94.000 (96.548)\n",
            "Test: [40/100]\tTime 0.029 (0.033)\tLoss 7.5744 (6.6660)\tPrec@1 64.000 (70.220)\tPrec@5 92.000 (96.195)\n",
            "Test: [50/100]\tTime 0.030 (0.031)\tLoss 6.6612 (6.6605)\tPrec@1 71.000 (70.314)\tPrec@5 94.000 (96.235)\n",
            "Test: [60/100]\tTime 0.024 (0.030)\tLoss 6.0539 (6.6682)\tPrec@1 73.000 (70.197)\tPrec@5 96.000 (96.049)\n",
            "Test: [70/100]\tTime 0.027 (0.030)\tLoss 6.9818 (6.6775)\tPrec@1 66.000 (70.056)\tPrec@5 96.000 (96.085)\n",
            "Test: [80/100]\tTime 0.040 (0.029)\tLoss 6.5022 (6.6592)\tPrec@1 70.000 (70.148)\tPrec@5 98.000 (96.099)\n",
            "Test: [90/100]\tTime 0.047 (0.028)\tLoss 6.2502 (6.7120)\tPrec@1 73.000 (70.066)\tPrec@5 99.000 (96.110)\n",
            "val Results: Prec@1 70.030 Prec@5 96.120 Loss 6.71603\n",
            "val Class Accuracy: [0.973,0.972,0.810,0.715,0.701,0.437,0.798,0.445,0.490,0.662]\n",
            "Best Prec@1: 75.870\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test a pretrained checkpoint (on CIFAR-10)"
      ],
      "metadata": {
        "id": "STTzcmwlPu62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --loss_type LDAM --imb_factor 0.02 --epochs=100 --resume '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_LDAM_None_exp_0.02_ss_pretrained/ckpt.best.pth.tar' -e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RI6g3plBHAX",
        "outputId": "ec6b7895-c25a-4079-a68f-dfde9804a510"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/cifar10_resnet32_LDAM_None_exp_0.02_ss_pretrained/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/100]\tTime 2.699 (2.699)\tLoss 1.8359 (1.8359)\tPrec@1 81.000 (81.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/100]\tTime 0.031 (0.265)\tLoss 1.8558 (1.8620)\tPrec@1 82.000 (77.545)\tPrec@5 99.000 (98.545)\n",
            "Test: [20/100]\tTime 0.015 (0.148)\tLoss 1.8667 (1.8602)\tPrec@1 73.000 (76.905)\tPrec@5 99.000 (97.857)\n",
            "Test: [30/100]\tTime 0.036 (0.109)\tLoss 1.8848 (1.8648)\tPrec@1 70.000 (76.452)\tPrec@5 99.000 (98.000)\n",
            "Test: [40/100]\tTime 0.024 (0.090)\tLoss 1.8560 (1.8644)\tPrec@1 78.000 (76.415)\tPrec@5 97.000 (97.780)\n",
            "Test: [50/100]\tTime 0.010 (0.076)\tLoss 1.8663 (1.8637)\tPrec@1 78.000 (76.529)\tPrec@5 98.000 (97.765)\n",
            "Test: [60/100]\tTime 0.034 (0.067)\tLoss 1.9035 (1.8666)\tPrec@1 74.000 (76.148)\tPrec@5 99.000 (97.721)\n",
            "Test: [70/100]\tTime 0.030 (0.062)\tLoss 1.8417 (1.8676)\tPrec@1 79.000 (76.056)\tPrec@5 99.000 (97.746)\n",
            "Test: [80/100]\tTime 0.037 (0.057)\tLoss 1.8555 (1.8671)\tPrec@1 79.000 (76.136)\tPrec@5 98.000 (97.802)\n",
            "Test: [90/100]\tTime 0.036 (0.054)\tLoss 1.8785 (1.8683)\tPrec@1 77.000 (75.846)\tPrec@5 100.000 (97.725)\n",
            "val Results: Prec@1 75.870 Prec@5 97.780 Loss 1.86775\n",
            "val Class Accuracy: [0.938,0.981,0.804,0.663,0.711,0.713,0.827,0.622,0.637,0.691]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYh09WyJN_Mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}