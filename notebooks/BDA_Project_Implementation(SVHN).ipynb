{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMnf3Xqn6EgA",
        "outputId": "78bea433-93bb-48ec-8d8d-ff5cec2e78a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorBoardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1TX5LK2HYgx",
        "outputId": "519b8c79-f35c-498e-9000-90ac28ebc18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TensorBoardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->TensorBoardX) (1.15.0)\n",
            "Installing collected packages: TensorBoardX\n",
            "Successfully installed TensorBoardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wlAfnk6HszO",
        "outputId": "7dd562e7-e702-4ae7-ea05-1c7ccca40e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import yaml\n",
        "import sklearn\n",
        "import tensorboardX"
      ],
      "metadata": {
        "id": "0ycPQC9iHxzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/BDA_Pre-Files/imbalanced-semi-self-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtceccWX_ool",
        "outputId": "ec4917b4-3938-4aed-d8c6-3f2504f8be76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BDA_Pre-Files/imbalanced-semi-self-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gen_pseudolabels.py --resume \"./checkpoint\" --data_dir \"./data\" --output_dir \"./output\" --output_filename \"./gen_pseudolabels_ouptut\""
      ],
      "metadata": {
        "id": "iHxhl8An7QUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-Supervised Imbalance Learning"
      ],
      "metadata": {
        "id": "34MRc1R2m7-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train with unlabeled data"
      ],
      "metadata": {
        "id": "FvqYE5wzm_4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset svhn --imb_factor 0.02 --imb_factor_unlabel 0.02"
      ],
      "metadata": {
        "id": "DUhB43gJArTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f558364b-7147-46fa-9677-e547201f67c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [75][0/66], lr: 0.01000\tTime 0.586 (0.586)\tData 0.507 (0.507)\tLoss 0.1016 (0.1016)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][10/66], lr: 0.01000\tTime 0.098 (0.141)\tData 0.004 (0.051)\tLoss 0.0636 (0.0645)\tPrec@1 96.875 (97.514)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [75][20/66], lr: 0.01000\tTime 0.100 (0.120)\tData 0.005 (0.028)\tLoss 0.0310 (0.0624)\tPrec@1 99.219 (97.731)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [75][30/66], lr: 0.01000\tTime 0.098 (0.111)\tData 0.007 (0.021)\tLoss 0.0766 (0.0607)\tPrec@1 97.656 (97.921)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [75][40/66], lr: 0.01000\tTime 0.057 (0.106)\tData 0.006 (0.016)\tLoss 0.0783 (0.0614)\tPrec@1 97.656 (97.875)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [75][50/66], lr: 0.01000\tTime 0.085 (0.105)\tData 0.000 (0.015)\tLoss 0.0327 (0.0590)\tPrec@1 99.219 (97.978)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [75][60/66], lr: 0.01000\tTime 0.080 (0.102)\tData 0.000 (0.013)\tLoss 0.0796 (0.0602)\tPrec@1 97.266 (97.925)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.248 (0.248)\tLoss 1.0390 (1.0390)\tPrec@1 79.000 (79.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.027 (0.053)\tLoss 1.4180 (0.9961)\tPrec@1 79.000 (79.182)\tPrec@5 99.000 (97.727)\n",
            "Test: [20/261]\tTime 0.017 (0.038)\tLoss 1.2230 (0.9588)\tPrec@1 78.000 (80.048)\tPrec@5 96.000 (97.524)\n",
            "Test: [30/261]\tTime 0.029 (0.034)\tLoss 0.6710 (0.9109)\tPrec@1 79.000 (80.516)\tPrec@5 98.000 (97.774)\n",
            "Test: [40/261]\tTime 0.030 (0.031)\tLoss 0.8353 (0.8748)\tPrec@1 85.000 (81.171)\tPrec@5 97.000 (98.049)\n",
            "Test: [50/261]\tTime 0.029 (0.030)\tLoss 0.5620 (0.8500)\tPrec@1 83.000 (81.314)\tPrec@5 99.000 (98.216)\n",
            "Test: [60/261]\tTime 0.032 (0.029)\tLoss 0.6975 (0.8514)\tPrec@1 84.000 (81.525)\tPrec@5 99.000 (98.164)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 0.8470 (0.8561)\tPrec@1 79.000 (81.620)\tPrec@5 98.000 (98.042)\n",
            "Test: [80/261]\tTime 0.023 (0.028)\tLoss 0.8168 (0.8599)\tPrec@1 82.000 (81.444)\tPrec@5 98.000 (98.099)\n",
            "Test: [90/261]\tTime 0.022 (0.027)\tLoss 0.8363 (0.8898)\tPrec@1 81.000 (81.198)\tPrec@5 98.000 (97.978)\n",
            "Test: [100/261]\tTime 0.039 (0.027)\tLoss 1.0588 (0.8790)\tPrec@1 79.000 (81.426)\tPrec@5 96.000 (98.020)\n",
            "Test: [110/261]\tTime 0.015 (0.027)\tLoss 0.7986 (0.8661)\tPrec@1 83.000 (81.604)\tPrec@5 98.000 (98.018)\n",
            "Test: [120/261]\tTime 0.032 (0.026)\tLoss 0.7477 (0.8628)\tPrec@1 87.000 (81.645)\tPrec@5 97.000 (97.967)\n",
            "Test: [130/261]\tTime 0.021 (0.026)\tLoss 0.9437 (0.8617)\tPrec@1 77.000 (81.603)\tPrec@5 97.000 (97.977)\n",
            "Test: [140/261]\tTime 0.038 (0.026)\tLoss 1.1151 (0.8591)\tPrec@1 77.000 (81.482)\tPrec@5 98.000 (98.007)\n",
            "Test: [150/261]\tTime 0.041 (0.026)\tLoss 0.6044 (0.8588)\tPrec@1 86.000 (81.470)\tPrec@5 98.000 (97.974)\n",
            "Test: [160/261]\tTime 0.025 (0.026)\tLoss 0.4171 (0.8588)\tPrec@1 89.000 (81.460)\tPrec@5 99.000 (97.950)\n",
            "Test: [170/261]\tTime 0.021 (0.026)\tLoss 0.8041 (0.8563)\tPrec@1 80.000 (81.480)\tPrec@5 95.000 (97.918)\n",
            "Test: [180/261]\tTime 0.020 (0.025)\tLoss 0.9694 (0.8571)\tPrec@1 82.000 (81.409)\tPrec@5 95.000 (97.912)\n",
            "Test: [190/261]\tTime 0.023 (0.025)\tLoss 0.8471 (0.8518)\tPrec@1 80.000 (81.508)\tPrec@5 100.000 (97.942)\n",
            "Test: [200/261]\tTime 0.019 (0.025)\tLoss 1.0599 (0.8532)\tPrec@1 81.000 (81.478)\tPrec@5 98.000 (97.900)\n",
            "Test: [210/261]\tTime 0.016 (0.025)\tLoss 0.6778 (0.8512)\tPrec@1 82.000 (81.498)\tPrec@5 99.000 (97.919)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 1.0639 (0.8512)\tPrec@1 80.000 (81.448)\tPrec@5 98.000 (97.955)\n",
            "Test: [230/261]\tTime 0.023 (0.025)\tLoss 0.8572 (0.8536)\tPrec@1 76.000 (81.411)\tPrec@5 97.000 (97.944)\n",
            "Test: [240/261]\tTime 0.012 (0.025)\tLoss 0.6315 (0.8559)\tPrec@1 82.000 (81.423)\tPrec@5 98.000 (97.925)\n",
            "Test: [250/261]\tTime 0.025 (0.025)\tLoss 0.7041 (0.8509)\tPrec@1 79.000 (81.498)\tPrec@5 100.000 (97.940)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3931 (0.8529)\tPrec@1 93.750 (81.492)\tPrec@5 96.875 (97.926)\n",
            "val Results: Prec@1 81.492 Prec@5 97.926 Loss 0.85285\n",
            "val Class Accuracy: [0.644,0.958,0.933,0.876,0.828,0.812,0.691,0.704,0.614,0.612]\n",
            "Best Prec@1: 85.245\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [76][0/66], lr: 0.01000\tTime 0.429 (0.429)\tData 0.353 (0.353)\tLoss 0.0547 (0.0547)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [76][10/66], lr: 0.01000\tTime 0.105 (0.136)\tData 0.000 (0.045)\tLoss 0.0272 (0.0530)\tPrec@1 99.609 (98.153)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [76][20/66], lr: 0.01000\tTime 0.083 (0.117)\tData 0.001 (0.025)\tLoss 0.0997 (0.0618)\tPrec@1 95.312 (97.842)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [76][30/66], lr: 0.01000\tTime 0.105 (0.109)\tData 0.000 (0.018)\tLoss 0.1051 (0.0690)\tPrec@1 96.094 (97.732)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [76][40/66], lr: 0.01000\tTime 0.092 (0.106)\tData 0.007 (0.015)\tLoss 0.0270 (0.0678)\tPrec@1 99.609 (97.647)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [76][50/66], lr: 0.01000\tTime 0.083 (0.103)\tData 0.005 (0.013)\tLoss 0.1122 (0.0699)\tPrec@1 95.703 (97.572)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [76][60/66], lr: 0.01000\tTime 0.077 (0.101)\tData 0.000 (0.012)\tLoss 0.0606 (0.0684)\tPrec@1 97.656 (97.586)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.302 (0.302)\tLoss 1.4570 (1.4570)\tPrec@1 74.000 (74.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.017 (0.049)\tLoss 1.9770 (1.4026)\tPrec@1 72.000 (74.000)\tPrec@5 92.000 (96.182)\n",
            "Test: [20/261]\tTime 0.010 (0.038)\tLoss 1.5523 (1.3578)\tPrec@1 75.000 (74.381)\tPrec@5 96.000 (96.714)\n",
            "Test: [30/261]\tTime 0.031 (0.032)\tLoss 0.9563 (1.2736)\tPrec@1 79.000 (75.387)\tPrec@5 98.000 (97.097)\n",
            "Test: [40/261]\tTime 0.016 (0.031)\tLoss 1.0455 (1.2291)\tPrec@1 78.000 (76.195)\tPrec@5 96.000 (97.268)\n",
            "Test: [50/261]\tTime 0.034 (0.030)\tLoss 1.4637 (1.2177)\tPrec@1 72.000 (76.294)\tPrec@5 97.000 (97.196)\n",
            "Test: [60/261]\tTime 0.028 (0.029)\tLoss 1.0938 (1.2196)\tPrec@1 78.000 (76.426)\tPrec@5 98.000 (97.098)\n",
            "Test: [70/261]\tTime 0.024 (0.028)\tLoss 1.1497 (1.2326)\tPrec@1 75.000 (76.437)\tPrec@5 99.000 (97.099)\n",
            "Test: [80/261]\tTime 0.025 (0.028)\tLoss 1.1014 (1.2554)\tPrec@1 73.000 (76.185)\tPrec@5 97.000 (97.099)\n",
            "Test: [90/261]\tTime 0.023 (0.028)\tLoss 1.1801 (1.2697)\tPrec@1 77.000 (76.198)\tPrec@5 96.000 (96.967)\n",
            "Test: [100/261]\tTime 0.034 (0.028)\tLoss 1.4007 (1.2671)\tPrec@1 70.000 (76.158)\tPrec@5 95.000 (96.931)\n",
            "Test: [110/261]\tTime 0.030 (0.027)\tLoss 1.4584 (1.2606)\tPrec@1 76.000 (76.261)\tPrec@5 98.000 (96.946)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 1.3555 (1.2607)\tPrec@1 78.000 (76.397)\tPrec@5 97.000 (96.893)\n",
            "Test: [130/261]\tTime 0.030 (0.027)\tLoss 1.3029 (1.2701)\tPrec@1 75.000 (76.351)\tPrec@5 97.000 (96.847)\n",
            "Test: [140/261]\tTime 0.024 (0.027)\tLoss 1.4730 (1.2630)\tPrec@1 71.000 (76.404)\tPrec@5 92.000 (96.823)\n",
            "Test: [150/261]\tTime 0.017 (0.027)\tLoss 0.9473 (1.2610)\tPrec@1 79.000 (76.397)\tPrec@5 98.000 (96.868)\n",
            "Test: [160/261]\tTime 0.010 (0.026)\tLoss 1.1884 (1.2649)\tPrec@1 80.000 (76.429)\tPrec@5 98.000 (96.870)\n",
            "Test: [170/261]\tTime 0.010 (0.026)\tLoss 1.1022 (1.2574)\tPrec@1 83.000 (76.567)\tPrec@5 96.000 (96.906)\n",
            "Test: [180/261]\tTime 0.027 (0.026)\tLoss 1.1409 (1.2595)\tPrec@1 81.000 (76.503)\tPrec@5 95.000 (96.890)\n",
            "Test: [190/261]\tTime 0.010 (0.026)\tLoss 1.2503 (1.2566)\tPrec@1 75.000 (76.461)\tPrec@5 95.000 (96.921)\n",
            "Test: [200/261]\tTime 0.022 (0.026)\tLoss 1.3886 (1.2557)\tPrec@1 78.000 (76.443)\tPrec@5 96.000 (96.915)\n",
            "Test: [210/261]\tTime 0.041 (0.026)\tLoss 0.9671 (1.2528)\tPrec@1 79.000 (76.493)\tPrec@5 98.000 (96.934)\n",
            "Test: [220/261]\tTime 0.029 (0.026)\tLoss 1.4141 (1.2517)\tPrec@1 81.000 (76.520)\tPrec@5 96.000 (96.973)\n",
            "Test: [230/261]\tTime 0.028 (0.026)\tLoss 1.3020 (1.2561)\tPrec@1 76.000 (76.455)\tPrec@5 95.000 (96.931)\n",
            "Test: [240/261]\tTime 0.012 (0.026)\tLoss 1.0088 (1.2580)\tPrec@1 78.000 (76.502)\tPrec@5 95.000 (96.913)\n",
            "Test: [250/261]\tTime 0.022 (0.026)\tLoss 1.3207 (1.2536)\tPrec@1 75.000 (76.554)\tPrec@5 98.000 (96.940)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.8744 (1.2555)\tPrec@1 78.125 (76.525)\tPrec@5 96.875 (96.923)\n",
            "val Results: Prec@1 76.525 Prec@5 96.923 Loss 1.25552\n",
            "val Class Accuracy: [0.510,0.983,0.834,0.751,0.847,0.779,0.664,0.567,0.548,0.649]\n",
            "Best Prec@1: 85.245\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [77][0/66], lr: 0.01000\tTime 0.473 (0.473)\tData 0.392 (0.392)\tLoss 0.0540 (0.0540)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][10/66], lr: 0.01000\tTime 0.076 (0.139)\tData 0.000 (0.045)\tLoss 0.0296 (0.0622)\tPrec@1 99.219 (97.443)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][20/66], lr: 0.01000\tTime 0.094 (0.118)\tData 0.000 (0.028)\tLoss 0.0347 (0.0617)\tPrec@1 99.219 (97.693)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][30/66], lr: 0.01000\tTime 0.094 (0.110)\tData 0.004 (0.022)\tLoss 0.0507 (0.0593)\tPrec@1 98.047 (97.858)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][40/66], lr: 0.01000\tTime 0.079 (0.105)\tData 0.000 (0.019)\tLoss 0.0653 (0.0591)\tPrec@1 97.656 (97.952)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [77][50/66], lr: 0.01000\tTime 0.096 (0.102)\tData 0.004 (0.017)\tLoss 0.0377 (0.0604)\tPrec@1 98.828 (97.909)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [77][60/66], lr: 0.01000\tTime 0.076 (0.100)\tData 0.000 (0.015)\tLoss 0.0278 (0.0605)\tPrec@1 99.609 (97.912)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.260 (0.260)\tLoss 0.7942 (0.7942)\tPrec@1 83.000 (83.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.050 (0.054)\tLoss 1.0362 (0.8188)\tPrec@1 77.000 (80.727)\tPrec@5 99.000 (97.818)\n",
            "Test: [20/261]\tTime 0.015 (0.036)\tLoss 1.1050 (0.8100)\tPrec@1 75.000 (81.048)\tPrec@5 97.000 (97.714)\n",
            "Test: [30/261]\tTime 0.015 (0.033)\tLoss 0.6308 (0.7652)\tPrec@1 85.000 (82.323)\tPrec@5 99.000 (97.968)\n",
            "Test: [40/261]\tTime 0.038 (0.031)\tLoss 0.7696 (0.7574)\tPrec@1 83.000 (82.829)\tPrec@5 99.000 (98.220)\n",
            "Test: [50/261]\tTime 0.016 (0.030)\tLoss 0.5901 (0.7355)\tPrec@1 85.000 (83.137)\tPrec@5 98.000 (98.255)\n",
            "Test: [60/261]\tTime 0.034 (0.029)\tLoss 0.6808 (0.7338)\tPrec@1 85.000 (83.213)\tPrec@5 99.000 (98.246)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 0.8108 (0.7448)\tPrec@1 80.000 (83.169)\tPrec@5 99.000 (98.211)\n",
            "Test: [80/261]\tTime 0.026 (0.028)\tLoss 0.7205 (0.7429)\tPrec@1 81.000 (83.086)\tPrec@5 97.000 (98.235)\n",
            "Test: [90/261]\tTime 0.011 (0.027)\tLoss 0.8045 (0.7620)\tPrec@1 86.000 (82.989)\tPrec@5 96.000 (98.121)\n",
            "Test: [100/261]\tTime 0.016 (0.026)\tLoss 1.0392 (0.7602)\tPrec@1 77.000 (82.980)\tPrec@5 98.000 (98.129)\n",
            "Test: [110/261]\tTime 0.022 (0.027)\tLoss 0.9300 (0.7566)\tPrec@1 84.000 (83.009)\tPrec@5 98.000 (98.090)\n",
            "Test: [120/261]\tTime 0.021 (0.027)\tLoss 0.6064 (0.7542)\tPrec@1 89.000 (83.025)\tPrec@5 98.000 (98.083)\n",
            "Test: [130/261]\tTime 0.018 (0.026)\tLoss 0.6175 (0.7559)\tPrec@1 84.000 (83.023)\tPrec@5 97.000 (98.061)\n",
            "Test: [140/261]\tTime 0.033 (0.026)\tLoss 0.8637 (0.7515)\tPrec@1 80.000 (83.000)\tPrec@5 96.000 (98.057)\n",
            "Test: [150/261]\tTime 0.010 (0.026)\tLoss 0.4496 (0.7482)\tPrec@1 83.000 (82.987)\tPrec@5 98.000 (98.066)\n",
            "Test: [160/261]\tTime 0.027 (0.025)\tLoss 0.3260 (0.7493)\tPrec@1 89.000 (82.994)\tPrec@5 100.000 (98.075)\n",
            "Test: [170/261]\tTime 0.017 (0.026)\tLoss 0.7256 (0.7461)\tPrec@1 85.000 (83.088)\tPrec@5 98.000 (98.076)\n",
            "Test: [180/261]\tTime 0.026 (0.025)\tLoss 0.6927 (0.7472)\tPrec@1 84.000 (83.077)\tPrec@5 96.000 (98.061)\n",
            "Test: [190/261]\tTime 0.028 (0.025)\tLoss 0.4139 (0.7433)\tPrec@1 86.000 (83.126)\tPrec@5 99.000 (98.126)\n",
            "Test: [200/261]\tTime 0.019 (0.025)\tLoss 0.7026 (0.7435)\tPrec@1 81.000 (83.080)\tPrec@5 97.000 (98.109)\n",
            "Test: [210/261]\tTime 0.027 (0.025)\tLoss 0.5673 (0.7422)\tPrec@1 87.000 (83.104)\tPrec@5 98.000 (98.114)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.7638 (0.7407)\tPrec@1 82.000 (83.086)\tPrec@5 98.000 (98.136)\n",
            "Test: [230/261]\tTime 0.024 (0.025)\tLoss 0.8057 (0.7423)\tPrec@1 80.000 (83.065)\tPrec@5 96.000 (98.121)\n",
            "Test: [240/261]\tTime 0.026 (0.025)\tLoss 0.6866 (0.7435)\tPrec@1 85.000 (83.050)\tPrec@5 99.000 (98.091)\n",
            "Test: [250/261]\tTime 0.014 (0.025)\tLoss 0.7862 (0.7399)\tPrec@1 79.000 (83.068)\tPrec@5 99.000 (98.096)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.6370 (0.7399)\tPrec@1 87.500 (83.125)\tPrec@5 96.875 (98.072)\n",
            "val Results: Prec@1 83.125 Prec@5 98.072 Loss 0.73992\n",
            "val Class Accuracy: [0.623,0.971,0.963,0.769,0.893,0.843,0.745,0.705,0.666,0.707]\n",
            "Best Prec@1: 85.245\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [78][0/66], lr: 0.01000\tTime 0.620 (0.620)\tData 0.559 (0.559)\tLoss 0.0639 (0.0639)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][10/66], lr: 0.01000\tTime 0.085 (0.138)\tData 0.000 (0.055)\tLoss 0.0998 (0.0672)\tPrec@1 96.484 (97.727)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][20/66], lr: 0.01000\tTime 0.108 (0.119)\tData 0.000 (0.036)\tLoss 0.0454 (0.0628)\tPrec@1 98.438 (97.879)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [78][30/66], lr: 0.01000\tTime 0.137 (0.112)\tData 0.000 (0.026)\tLoss 0.0486 (0.0613)\tPrec@1 99.219 (97.921)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [78][40/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.005 (0.021)\tLoss 0.0486 (0.0579)\tPrec@1 98.438 (98.075)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [78][50/66], lr: 0.01000\tTime 0.074 (0.103)\tData 0.000 (0.018)\tLoss 0.0331 (0.0582)\tPrec@1 99.219 (98.070)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [78][60/66], lr: 0.01000\tTime 0.070 (0.101)\tData 0.000 (0.016)\tLoss 0.0631 (0.0586)\tPrec@1 97.266 (98.021)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.266 (0.266)\tLoss 0.6553 (0.6553)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.010 (0.047)\tLoss 0.9614 (0.7552)\tPrec@1 79.000 (81.182)\tPrec@5 99.000 (97.091)\n",
            "Test: [20/261]\tTime 0.020 (0.035)\tLoss 1.1276 (0.7812)\tPrec@1 75.000 (81.143)\tPrec@5 96.000 (97.429)\n",
            "Test: [30/261]\tTime 0.028 (0.033)\tLoss 0.5903 (0.7279)\tPrec@1 80.000 (82.000)\tPrec@5 98.000 (97.839)\n",
            "Test: [40/261]\tTime 0.026 (0.031)\tLoss 0.8467 (0.7306)\tPrec@1 81.000 (82.000)\tPrec@5 98.000 (97.854)\n",
            "Test: [50/261]\tTime 0.023 (0.030)\tLoss 0.5064 (0.7151)\tPrec@1 82.000 (82.412)\tPrec@5 99.000 (97.863)\n",
            "Test: [60/261]\tTime 0.009 (0.029)\tLoss 0.5721 (0.7103)\tPrec@1 83.000 (82.475)\tPrec@5 98.000 (97.820)\n",
            "Test: [70/261]\tTime 0.016 (0.027)\tLoss 0.6369 (0.7158)\tPrec@1 83.000 (82.521)\tPrec@5 98.000 (97.704)\n",
            "Test: [80/261]\tTime 0.029 (0.027)\tLoss 0.4679 (0.7129)\tPrec@1 86.000 (82.469)\tPrec@5 100.000 (97.716)\n",
            "Test: [90/261]\tTime 0.022 (0.027)\tLoss 0.4960 (0.7326)\tPrec@1 87.000 (82.275)\tPrec@5 97.000 (97.670)\n",
            "Test: [100/261]\tTime 0.028 (0.026)\tLoss 0.8594 (0.7293)\tPrec@1 80.000 (82.228)\tPrec@5 96.000 (97.673)\n",
            "Test: [110/261]\tTime 0.025 (0.026)\tLoss 0.7568 (0.7225)\tPrec@1 82.000 (82.378)\tPrec@5 97.000 (97.676)\n",
            "Test: [120/261]\tTime 0.026 (0.026)\tLoss 0.6483 (0.7208)\tPrec@1 85.000 (82.364)\tPrec@5 96.000 (97.686)\n",
            "Test: [130/261]\tTime 0.049 (0.027)\tLoss 1.0347 (0.7240)\tPrec@1 75.000 (82.275)\tPrec@5 97.000 (97.641)\n",
            "Test: [140/261]\tTime 0.038 (0.028)\tLoss 0.8948 (0.7208)\tPrec@1 77.000 (82.340)\tPrec@5 97.000 (97.624)\n",
            "Test: [150/261]\tTime 0.017 (0.028)\tLoss 0.7334 (0.7198)\tPrec@1 81.000 (82.371)\tPrec@5 98.000 (97.649)\n",
            "Test: [160/261]\tTime 0.036 (0.029)\tLoss 0.4387 (0.7173)\tPrec@1 84.000 (82.404)\tPrec@5 99.000 (97.634)\n",
            "Test: [170/261]\tTime 0.043 (0.029)\tLoss 0.8074 (0.7147)\tPrec@1 83.000 (82.515)\tPrec@5 95.000 (97.608)\n",
            "Test: [180/261]\tTime 0.040 (0.030)\tLoss 0.6735 (0.7143)\tPrec@1 81.000 (82.547)\tPrec@5 95.000 (97.580)\n",
            "Test: [190/261]\tTime 0.053 (0.030)\tLoss 0.4283 (0.7138)\tPrec@1 87.000 (82.586)\tPrec@5 100.000 (97.634)\n",
            "Test: [200/261]\tTime 0.034 (0.031)\tLoss 0.5322 (0.7108)\tPrec@1 87.000 (82.657)\tPrec@5 98.000 (97.632)\n",
            "Test: [210/261]\tTime 0.033 (0.031)\tLoss 0.6452 (0.7107)\tPrec@1 84.000 (82.697)\tPrec@5 96.000 (97.640)\n",
            "Test: [220/261]\tTime 0.015 (0.031)\tLoss 0.7042 (0.7094)\tPrec@1 81.000 (82.643)\tPrec@5 97.000 (97.674)\n",
            "Test: [230/261]\tTime 0.029 (0.031)\tLoss 0.5512 (0.7099)\tPrec@1 83.000 (82.623)\tPrec@5 98.000 (97.667)\n",
            "Test: [240/261]\tTime 0.017 (0.031)\tLoss 0.5865 (0.7119)\tPrec@1 84.000 (82.564)\tPrec@5 98.000 (97.656)\n",
            "Test: [250/261]\tTime 0.010 (0.030)\tLoss 0.8777 (0.7091)\tPrec@1 82.000 (82.625)\tPrec@5 98.000 (97.653)\n",
            "Test: [260/261]\tTime 0.005 (0.030)\tLoss 0.6879 (0.7095)\tPrec@1 84.375 (82.652)\tPrec@5 96.875 (97.641)\n",
            "val Results: Prec@1 82.652 Prec@5 97.641 Loss 0.70948\n",
            "val Class Accuracy: [0.718,0.946,0.894,0.667,0.920,0.900,0.676,0.836,0.708,0.716]\n",
            "Best Prec@1: 85.245\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [79][0/66], lr: 0.01000\tTime 0.569 (0.569)\tData 0.477 (0.477)\tLoss 0.0460 (0.0460)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][10/66], lr: 0.01000\tTime 0.069 (0.139)\tData 0.001 (0.048)\tLoss 0.0431 (0.0705)\tPrec@1 99.219 (97.443)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][20/66], lr: 0.01000\tTime 0.103 (0.119)\tData 0.003 (0.028)\tLoss 0.0395 (0.0673)\tPrec@1 98.047 (97.545)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][30/66], lr: 0.01000\tTime 0.099 (0.111)\tData 0.000 (0.021)\tLoss 0.0982 (0.0638)\tPrec@1 96.094 (97.644)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][40/66], lr: 0.01000\tTime 0.093 (0.106)\tData 0.005 (0.017)\tLoss 0.0398 (0.0619)\tPrec@1 98.828 (97.742)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][50/66], lr: 0.01000\tTime 0.094 (0.103)\tData 0.000 (0.015)\tLoss 0.0619 (0.0616)\tPrec@1 97.266 (97.786)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.014)\tLoss 0.0780 (0.0598)\tPrec@1 98.438 (97.880)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.227 (0.227)\tLoss 0.5974 (0.5974)\tPrec@1 85.000 (85.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.023 (0.050)\tLoss 0.9014 (0.6884)\tPrec@1 83.000 (83.545)\tPrec@5 99.000 (98.091)\n",
            "Test: [20/261]\tTime 0.032 (0.037)\tLoss 0.9176 (0.6839)\tPrec@1 80.000 (84.190)\tPrec@5 99.000 (98.143)\n",
            "Test: [30/261]\tTime 0.034 (0.033)\tLoss 0.4971 (0.6456)\tPrec@1 86.000 (85.258)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/261]\tTime 0.019 (0.030)\tLoss 0.7313 (0.6532)\tPrec@1 84.000 (85.195)\tPrec@5 100.000 (98.512)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.6395 (0.6514)\tPrec@1 82.000 (85.137)\tPrec@5 100.000 (98.529)\n",
            "Test: [60/261]\tTime 0.033 (0.028)\tLoss 0.5440 (0.6454)\tPrec@1 87.000 (85.230)\tPrec@5 99.000 (98.459)\n",
            "Test: [70/261]\tTime 0.012 (0.028)\tLoss 0.6636 (0.6537)\tPrec@1 87.000 (85.254)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.024 (0.027)\tLoss 0.6107 (0.6526)\tPrec@1 85.000 (85.173)\tPrec@5 99.000 (98.432)\n",
            "Test: [90/261]\tTime 0.023 (0.027)\tLoss 0.4858 (0.6701)\tPrec@1 90.000 (85.022)\tPrec@5 98.000 (98.352)\n",
            "Test: [100/261]\tTime 0.021 (0.026)\tLoss 0.9941 (0.6674)\tPrec@1 80.000 (84.960)\tPrec@5 96.000 (98.347)\n",
            "Test: [110/261]\tTime 0.053 (0.027)\tLoss 0.5023 (0.6591)\tPrec@1 88.000 (85.090)\tPrec@5 99.000 (98.360)\n",
            "Test: [120/261]\tTime 0.014 (0.026)\tLoss 0.5188 (0.6623)\tPrec@1 88.000 (85.107)\tPrec@5 96.000 (98.322)\n",
            "Test: [130/261]\tTime 0.015 (0.026)\tLoss 0.7708 (0.6650)\tPrec@1 84.000 (85.107)\tPrec@5 98.000 (98.305)\n",
            "Test: [140/261]\tTime 0.049 (0.026)\tLoss 0.8030 (0.6621)\tPrec@1 81.000 (85.106)\tPrec@5 99.000 (98.312)\n",
            "Test: [150/261]\tTime 0.018 (0.026)\tLoss 0.4911 (0.6598)\tPrec@1 84.000 (85.159)\tPrec@5 98.000 (98.325)\n",
            "Test: [160/261]\tTime 0.025 (0.026)\tLoss 0.3266 (0.6582)\tPrec@1 91.000 (85.199)\tPrec@5 100.000 (98.366)\n",
            "Test: [170/261]\tTime 0.024 (0.025)\tLoss 0.6583 (0.6525)\tPrec@1 86.000 (85.287)\tPrec@5 98.000 (98.386)\n",
            "Test: [180/261]\tTime 0.025 (0.025)\tLoss 0.4875 (0.6524)\tPrec@1 88.000 (85.315)\tPrec@5 98.000 (98.392)\n",
            "Test: [190/261]\tTime 0.022 (0.025)\tLoss 0.3005 (0.6532)\tPrec@1 90.000 (85.351)\tPrec@5 100.000 (98.393)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.5229 (0.6543)\tPrec@1 87.000 (85.299)\tPrec@5 96.000 (98.353)\n",
            "Test: [210/261]\tTime 0.022 (0.025)\tLoss 0.7318 (0.6564)\tPrec@1 82.000 (85.227)\tPrec@5 99.000 (98.370)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.5370 (0.6535)\tPrec@1 86.000 (85.226)\tPrec@5 99.000 (98.394)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.6029 (0.6557)\tPrec@1 87.000 (85.164)\tPrec@5 97.000 (98.390)\n",
            "Test: [240/261]\tTime 0.020 (0.025)\tLoss 0.6899 (0.6573)\tPrec@1 88.000 (85.154)\tPrec@5 98.000 (98.382)\n",
            "Test: [250/261]\tTime 0.055 (0.025)\tLoss 0.6224 (0.6524)\tPrec@1 87.000 (85.259)\tPrec@5 100.000 (98.390)\n",
            "Test: [260/261]\tTime 0.006 (0.024)\tLoss 0.2881 (0.6526)\tPrec@1 90.625 (85.249)\tPrec@5 100.000 (98.375)\n",
            "val Results: Prec@1 85.249 Prec@5 98.375 Loss 0.65260\n",
            "val Class Accuracy: [0.717,0.930,0.944,0.748,0.917,0.911,0.717,0.809,0.842,0.747]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [80][0/66], lr: 0.01000\tTime 0.472 (0.472)\tData 0.412 (0.412)\tLoss 0.0853 (0.0853)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][10/66], lr: 0.01000\tTime 0.129 (0.135)\tData 0.015 (0.049)\tLoss 0.0715 (0.0637)\tPrec@1 97.266 (97.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][20/66], lr: 0.01000\tTime 0.108 (0.115)\tData 0.000 (0.028)\tLoss 0.0167 (0.0561)\tPrec@1 99.609 (98.158)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][30/66], lr: 0.01000\tTime 0.096 (0.107)\tData 0.000 (0.020)\tLoss 0.0460 (0.0530)\tPrec@1 98.438 (98.198)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][40/66], lr: 0.01000\tTime 0.078 (0.103)\tData 0.000 (0.016)\tLoss 0.0784 (0.0544)\tPrec@1 98.438 (98.209)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][50/66], lr: 0.01000\tTime 0.092 (0.101)\tData 0.000 (0.015)\tLoss 0.0811 (0.0551)\tPrec@1 97.656 (98.169)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][60/66], lr: 0.01000\tTime 0.074 (0.098)\tData 0.000 (0.013)\tLoss 0.0737 (0.0554)\tPrec@1 96.094 (98.143)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.296 (0.296)\tLoss 0.8917 (0.8917)\tPrec@1 83.000 (83.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.027 (0.051)\tLoss 0.9156 (0.8411)\tPrec@1 82.000 (80.818)\tPrec@5 98.000 (96.273)\n",
            "Test: [20/261]\tTime 0.025 (0.036)\tLoss 1.0314 (0.8320)\tPrec@1 76.000 (80.762)\tPrec@5 96.000 (96.571)\n",
            "Test: [30/261]\tTime 0.039 (0.033)\tLoss 0.4923 (0.7743)\tPrec@1 92.000 (82.032)\tPrec@5 97.000 (96.871)\n",
            "Test: [40/261]\tTime 0.036 (0.029)\tLoss 0.6824 (0.7638)\tPrec@1 83.000 (82.293)\tPrec@5 98.000 (97.000)\n",
            "Test: [50/261]\tTime 0.022 (0.028)\tLoss 0.6527 (0.7527)\tPrec@1 82.000 (82.529)\tPrec@5 97.000 (96.980)\n",
            "Test: [60/261]\tTime 0.018 (0.029)\tLoss 0.6848 (0.7593)\tPrec@1 83.000 (82.410)\tPrec@5 98.000 (96.967)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 0.8182 (0.7701)\tPrec@1 76.000 (82.197)\tPrec@5 95.000 (96.901)\n",
            "Test: [80/261]\tTime 0.028 (0.028)\tLoss 0.8224 (0.7729)\tPrec@1 80.000 (82.012)\tPrec@5 97.000 (96.901)\n",
            "Test: [90/261]\tTime 0.030 (0.028)\tLoss 0.7166 (0.7935)\tPrec@1 85.000 (81.769)\tPrec@5 97.000 (96.835)\n",
            "Test: [100/261]\tTime 0.021 (0.027)\tLoss 1.0840 (0.7894)\tPrec@1 76.000 (81.842)\tPrec@5 95.000 (96.822)\n",
            "Test: [110/261]\tTime 0.009 (0.027)\tLoss 0.7690 (0.7881)\tPrec@1 81.000 (81.838)\tPrec@5 97.000 (96.847)\n",
            "Test: [120/261]\tTime 0.025 (0.027)\tLoss 0.7005 (0.7876)\tPrec@1 84.000 (81.702)\tPrec@5 97.000 (96.843)\n",
            "Test: [130/261]\tTime 0.016 (0.027)\tLoss 0.8564 (0.7862)\tPrec@1 79.000 (81.779)\tPrec@5 96.000 (96.847)\n",
            "Test: [140/261]\tTime 0.024 (0.026)\tLoss 0.8276 (0.7814)\tPrec@1 79.000 (81.787)\tPrec@5 97.000 (96.901)\n",
            "Test: [150/261]\tTime 0.023 (0.026)\tLoss 0.6510 (0.7784)\tPrec@1 81.000 (81.768)\tPrec@5 97.000 (96.907)\n",
            "Test: [160/261]\tTime 0.024 (0.026)\tLoss 0.3651 (0.7765)\tPrec@1 89.000 (81.832)\tPrec@5 99.000 (96.888)\n",
            "Test: [170/261]\tTime 0.023 (0.026)\tLoss 0.6900 (0.7699)\tPrec@1 86.000 (81.918)\tPrec@5 97.000 (96.883)\n",
            "Test: [180/261]\tTime 0.010 (0.026)\tLoss 0.9061 (0.7735)\tPrec@1 81.000 (81.851)\tPrec@5 95.000 (96.895)\n",
            "Test: [190/261]\tTime 0.035 (0.026)\tLoss 0.6962 (0.7725)\tPrec@1 81.000 (81.838)\tPrec@5 99.000 (96.969)\n",
            "Test: [200/261]\tTime 0.026 (0.025)\tLoss 0.7101 (0.7726)\tPrec@1 84.000 (81.861)\tPrec@5 97.000 (96.960)\n",
            "Test: [210/261]\tTime 0.017 (0.026)\tLoss 0.8268 (0.7711)\tPrec@1 77.000 (81.900)\tPrec@5 98.000 (96.972)\n",
            "Test: [220/261]\tTime 0.018 (0.025)\tLoss 0.7083 (0.7691)\tPrec@1 84.000 (81.910)\tPrec@5 98.000 (96.986)\n",
            "Test: [230/261]\tTime 0.023 (0.025)\tLoss 1.0051 (0.7737)\tPrec@1 78.000 (81.853)\tPrec@5 90.000 (96.939)\n",
            "Test: [240/261]\tTime 0.021 (0.025)\tLoss 0.8317 (0.7771)\tPrec@1 84.000 (81.797)\tPrec@5 97.000 (96.938)\n",
            "Test: [250/261]\tTime 0.033 (0.025)\tLoss 0.8340 (0.7715)\tPrec@1 83.000 (81.892)\tPrec@5 99.000 (96.960)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.4979 (0.7710)\tPrec@1 90.625 (81.888)\tPrec@5 96.875 (96.965)\n",
            "val Results: Prec@1 81.888 Prec@5 96.965 Loss 0.77103\n",
            "val Class Accuracy: [0.617,0.954,0.910,0.723,0.881,0.923,0.683,0.854,0.596,0.645]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [81][0/66], lr: 0.01000\tTime 0.433 (0.433)\tData 0.365 (0.365)\tLoss 0.0573 (0.0573)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][10/66], lr: 0.01000\tTime 0.072 (0.127)\tData 0.016 (0.055)\tLoss 0.0631 (0.0736)\tPrec@1 97.656 (97.834)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [81][20/66], lr: 0.01000\tTime 0.088 (0.111)\tData 0.000 (0.033)\tLoss 0.0752 (0.0709)\tPrec@1 97.266 (97.935)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [81][30/66], lr: 0.01000\tTime 0.090 (0.105)\tData 0.000 (0.026)\tLoss 0.0552 (0.0674)\tPrec@1 98.047 (97.883)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [81][40/66], lr: 0.01000\tTime 0.081 (0.103)\tData 0.000 (0.023)\tLoss 0.0928 (0.0636)\tPrec@1 96.875 (97.942)\tPrec@5 99.609 (99.981)\n",
            "Epoch: [81][50/66], lr: 0.01000\tTime 0.101 (0.101)\tData 0.000 (0.019)\tLoss 0.0612 (0.0634)\tPrec@1 97.656 (97.917)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [81][60/66], lr: 0.01000\tTime 0.077 (0.099)\tData 0.000 (0.017)\tLoss 0.0572 (0.0617)\tPrec@1 97.656 (97.957)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.286 (0.286)\tLoss 0.8698 (0.8698)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.022 (0.048)\tLoss 0.9619 (0.8877)\tPrec@1 81.000 (80.364)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/261]\tTime 0.026 (0.036)\tLoss 1.3313 (0.8659)\tPrec@1 75.000 (81.048)\tPrec@5 96.000 (97.476)\n",
            "Test: [30/261]\tTime 0.034 (0.032)\tLoss 0.5440 (0.8110)\tPrec@1 85.000 (82.419)\tPrec@5 98.000 (97.677)\n",
            "Test: [40/261]\tTime 0.024 (0.030)\tLoss 0.7695 (0.7849)\tPrec@1 87.000 (82.829)\tPrec@5 98.000 (98.000)\n",
            "Test: [50/261]\tTime 0.036 (0.029)\tLoss 0.5743 (0.7689)\tPrec@1 84.000 (82.882)\tPrec@5 98.000 (98.000)\n",
            "Test: [60/261]\tTime 0.019 (0.028)\tLoss 0.8226 (0.7713)\tPrec@1 82.000 (82.836)\tPrec@5 98.000 (97.934)\n",
            "Test: [70/261]\tTime 0.023 (0.028)\tLoss 0.8066 (0.7747)\tPrec@1 78.000 (82.958)\tPrec@5 98.000 (97.845)\n",
            "Test: [80/261]\tTime 0.010 (0.027)\tLoss 0.6699 (0.7797)\tPrec@1 79.000 (82.716)\tPrec@5 100.000 (97.901)\n",
            "Test: [90/261]\tTime 0.025 (0.027)\tLoss 0.9282 (0.8066)\tPrec@1 78.000 (82.527)\tPrec@5 98.000 (97.802)\n",
            "Test: [100/261]\tTime 0.013 (0.026)\tLoss 1.0815 (0.7957)\tPrec@1 78.000 (82.752)\tPrec@5 97.000 (97.822)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.6697 (0.7852)\tPrec@1 86.000 (82.937)\tPrec@5 97.000 (97.811)\n",
            "Test: [120/261]\tTime 0.024 (0.026)\tLoss 0.7376 (0.7892)\tPrec@1 83.000 (82.901)\tPrec@5 97.000 (97.769)\n",
            "Test: [130/261]\tTime 0.019 (0.026)\tLoss 0.8345 (0.7906)\tPrec@1 84.000 (82.893)\tPrec@5 96.000 (97.786)\n",
            "Test: [140/261]\tTime 0.023 (0.026)\tLoss 0.9011 (0.7921)\tPrec@1 79.000 (82.851)\tPrec@5 96.000 (97.787)\n",
            "Test: [150/261]\tTime 0.017 (0.025)\tLoss 0.5535 (0.7910)\tPrec@1 86.000 (82.881)\tPrec@5 98.000 (97.768)\n",
            "Test: [160/261]\tTime 0.023 (0.025)\tLoss 0.3096 (0.7904)\tPrec@1 90.000 (82.863)\tPrec@5 100.000 (97.783)\n",
            "Test: [170/261]\tTime 0.016 (0.025)\tLoss 0.7537 (0.7878)\tPrec@1 86.000 (82.901)\tPrec@5 96.000 (97.749)\n",
            "Test: [180/261]\tTime 0.025 (0.025)\tLoss 0.9052 (0.7890)\tPrec@1 85.000 (82.901)\tPrec@5 96.000 (97.757)\n",
            "Test: [190/261]\tTime 0.026 (0.025)\tLoss 0.6645 (0.7864)\tPrec@1 82.000 (82.916)\tPrec@5 99.000 (97.827)\n",
            "Test: [200/261]\tTime 0.025 (0.025)\tLoss 0.6585 (0.7848)\tPrec@1 84.000 (82.831)\tPrec@5 98.000 (97.846)\n",
            "Test: [210/261]\tTime 0.032 (0.025)\tLoss 0.6405 (0.7829)\tPrec@1 84.000 (82.863)\tPrec@5 96.000 (97.834)\n",
            "Test: [220/261]\tTime 0.026 (0.025)\tLoss 1.0167 (0.7809)\tPrec@1 79.000 (82.846)\tPrec@5 95.000 (97.855)\n",
            "Test: [230/261]\tTime 0.021 (0.025)\tLoss 0.8503 (0.7813)\tPrec@1 82.000 (82.831)\tPrec@5 95.000 (97.861)\n",
            "Test: [240/261]\tTime 0.031 (0.025)\tLoss 0.7989 (0.7846)\tPrec@1 85.000 (82.763)\tPrec@5 97.000 (97.851)\n",
            "Test: [250/261]\tTime 0.044 (0.025)\tLoss 0.8753 (0.7817)\tPrec@1 81.000 (82.825)\tPrec@5 100.000 (97.865)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4135 (0.7805)\tPrec@1 90.625 (82.852)\tPrec@5 96.875 (97.853)\n",
            "val Results: Prec@1 82.852 Prec@5 97.853 Loss 0.78048\n",
            "val Class Accuracy: [0.651,0.958,0.953,0.827,0.870,0.923,0.703,0.676,0.637,0.634]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [82][0/66], lr: 0.01000\tTime 0.544 (0.544)\tData 0.455 (0.455)\tLoss 0.0362 (0.0362)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][10/66], lr: 0.01000\tTime 0.084 (0.134)\tData 0.000 (0.045)\tLoss 0.0929 (0.0504)\tPrec@1 96.484 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][20/66], lr: 0.01000\tTime 0.083 (0.115)\tData 0.003 (0.027)\tLoss 0.0277 (0.0533)\tPrec@1 99.219 (98.065)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [82][30/66], lr: 0.01000\tTime 0.106 (0.107)\tData 0.015 (0.021)\tLoss 0.0691 (0.0520)\tPrec@1 98.047 (98.160)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [82][40/66], lr: 0.01000\tTime 0.097 (0.104)\tData 0.005 (0.017)\tLoss 0.0762 (0.0539)\tPrec@1 96.094 (98.075)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [82][50/66], lr: 0.01000\tTime 0.112 (0.102)\tData 0.000 (0.015)\tLoss 0.0537 (0.0567)\tPrec@1 98.438 (98.016)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [82][60/66], lr: 0.01000\tTime 0.081 (0.099)\tData 0.000 (0.013)\tLoss 0.0490 (0.0563)\tPrec@1 98.047 (98.028)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.293 (0.293)\tLoss 0.9475 (0.9475)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.049 (0.053)\tLoss 1.3811 (1.0662)\tPrec@1 74.000 (78.091)\tPrec@5 98.000 (96.455)\n",
            "Test: [20/261]\tTime 0.029 (0.036)\tLoss 1.1688 (1.0130)\tPrec@1 74.000 (78.667)\tPrec@5 95.000 (96.524)\n",
            "Test: [30/261]\tTime 0.021 (0.034)\tLoss 0.7059 (0.9568)\tPrec@1 85.000 (79.710)\tPrec@5 98.000 (96.935)\n",
            "Test: [40/261]\tTime 0.022 (0.030)\tLoss 0.8790 (0.9432)\tPrec@1 87.000 (80.098)\tPrec@5 97.000 (97.122)\n",
            "Test: [50/261]\tTime 0.028 (0.029)\tLoss 0.8102 (0.9332)\tPrec@1 82.000 (80.412)\tPrec@5 98.000 (97.275)\n",
            "Test: [60/261]\tTime 0.049 (0.029)\tLoss 0.9311 (0.9331)\tPrec@1 77.000 (80.443)\tPrec@5 95.000 (97.246)\n",
            "Test: [70/261]\tTime 0.020 (0.028)\tLoss 1.0714 (0.9344)\tPrec@1 77.000 (80.479)\tPrec@5 95.000 (97.197)\n",
            "Test: [80/261]\tTime 0.025 (0.028)\tLoss 1.0369 (0.9404)\tPrec@1 75.000 (80.284)\tPrec@5 99.000 (97.160)\n",
            "Test: [90/261]\tTime 0.013 (0.027)\tLoss 1.0305 (0.9673)\tPrec@1 75.000 (79.978)\tPrec@5 96.000 (97.055)\n",
            "Test: [100/261]\tTime 0.026 (0.027)\tLoss 1.1598 (0.9578)\tPrec@1 78.000 (80.109)\tPrec@5 95.000 (97.059)\n",
            "Test: [110/261]\tTime 0.030 (0.027)\tLoss 1.0751 (0.9491)\tPrec@1 81.000 (80.189)\tPrec@5 99.000 (97.072)\n",
            "Test: [120/261]\tTime 0.036 (0.026)\tLoss 0.8073 (0.9425)\tPrec@1 81.000 (80.248)\tPrec@5 98.000 (97.083)\n",
            "Test: [130/261]\tTime 0.015 (0.026)\tLoss 1.1733 (0.9402)\tPrec@1 77.000 (80.282)\tPrec@5 94.000 (97.092)\n",
            "Test: [140/261]\tTime 0.009 (0.026)\tLoss 0.9200 (0.9358)\tPrec@1 80.000 (80.383)\tPrec@5 98.000 (97.113)\n",
            "Test: [150/261]\tTime 0.023 (0.026)\tLoss 0.6598 (0.9377)\tPrec@1 82.000 (80.377)\tPrec@5 98.000 (97.086)\n",
            "Test: [160/261]\tTime 0.013 (0.026)\tLoss 0.4484 (0.9358)\tPrec@1 87.000 (80.391)\tPrec@5 100.000 (97.093)\n",
            "Test: [170/261]\tTime 0.028 (0.026)\tLoss 0.7424 (0.9308)\tPrec@1 87.000 (80.509)\tPrec@5 97.000 (97.070)\n",
            "Test: [180/261]\tTime 0.033 (0.026)\tLoss 0.7865 (0.9285)\tPrec@1 85.000 (80.586)\tPrec@5 95.000 (97.061)\n",
            "Test: [190/261]\tTime 0.035 (0.026)\tLoss 0.8430 (0.9227)\tPrec@1 79.000 (80.634)\tPrec@5 99.000 (97.099)\n",
            "Test: [200/261]\tTime 0.015 (0.025)\tLoss 0.8833 (0.9233)\tPrec@1 81.000 (80.597)\tPrec@5 98.000 (97.085)\n",
            "Test: [210/261]\tTime 0.041 (0.025)\tLoss 0.7704 (0.9194)\tPrec@1 78.000 (80.687)\tPrec@5 97.000 (97.095)\n",
            "Test: [220/261]\tTime 0.040 (0.025)\tLoss 1.0285 (0.9182)\tPrec@1 76.000 (80.701)\tPrec@5 96.000 (97.086)\n",
            "Test: [230/261]\tTime 0.027 (0.025)\tLoss 0.9003 (0.9206)\tPrec@1 79.000 (80.636)\tPrec@5 95.000 (97.065)\n",
            "Test: [240/261]\tTime 0.019 (0.025)\tLoss 0.7951 (0.9212)\tPrec@1 82.000 (80.680)\tPrec@5 99.000 (97.071)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.7285 (0.9177)\tPrec@1 81.000 (80.721)\tPrec@5 99.000 (97.108)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3186 (0.9204)\tPrec@1 93.750 (80.635)\tPrec@5 96.875 (97.084)\n",
            "val Results: Prec@1 80.635 Prec@5 97.084 Loss 0.92041\n",
            "val Class Accuracy: [0.458,0.943,0.922,0.910,0.844,0.820,0.775,0.630,0.774,0.477]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [83][0/66], lr: 0.01000\tTime 0.537 (0.537)\tData 0.464 (0.464)\tLoss 0.0326 (0.0326)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][10/66], lr: 0.01000\tTime 0.110 (0.135)\tData 0.005 (0.047)\tLoss 0.0226 (0.0618)\tPrec@1 99.219 (97.692)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][20/66], lr: 0.01000\tTime 0.102 (0.114)\tData 0.005 (0.027)\tLoss 0.0292 (0.0600)\tPrec@1 99.219 (97.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][30/66], lr: 0.01000\tTime 0.094 (0.107)\tData 0.004 (0.020)\tLoss 0.0410 (0.0603)\tPrec@1 98.828 (97.896)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][40/66], lr: 0.01000\tTime 0.082 (0.104)\tData 0.000 (0.017)\tLoss 0.0459 (0.0582)\tPrec@1 98.828 (97.942)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][50/66], lr: 0.01000\tTime 0.105 (0.103)\tData 0.004 (0.015)\tLoss 0.0404 (0.0567)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [83][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.013)\tLoss 0.0573 (0.0566)\tPrec@1 97.656 (98.111)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.284 (0.284)\tLoss 1.1023 (1.1023)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.013 (0.047)\tLoss 1.3434 (0.9769)\tPrec@1 75.000 (79.091)\tPrec@5 98.000 (97.182)\n",
            "Test: [20/261]\tTime 0.026 (0.036)\tLoss 1.2882 (0.9438)\tPrec@1 76.000 (80.000)\tPrec@5 98.000 (97.619)\n",
            "Test: [30/261]\tTime 0.023 (0.032)\tLoss 0.8139 (0.8938)\tPrec@1 82.000 (80.806)\tPrec@5 100.000 (97.935)\n",
            "Test: [40/261]\tTime 0.033 (0.030)\tLoss 0.7277 (0.8743)\tPrec@1 84.000 (81.000)\tPrec@5 97.000 (98.049)\n",
            "Test: [50/261]\tTime 0.019 (0.029)\tLoss 0.6449 (0.8739)\tPrec@1 81.000 (80.961)\tPrec@5 98.000 (98.118)\n",
            "Test: [60/261]\tTime 0.019 (0.027)\tLoss 0.9992 (0.8747)\tPrec@1 79.000 (81.230)\tPrec@5 98.000 (98.049)\n",
            "Test: [70/261]\tTime 0.026 (0.027)\tLoss 0.8625 (0.8685)\tPrec@1 77.000 (81.366)\tPrec@5 98.000 (98.000)\n",
            "Test: [80/261]\tTime 0.046 (0.027)\tLoss 0.9270 (0.8699)\tPrec@1 82.000 (81.247)\tPrec@5 98.000 (98.062)\n",
            "Test: [90/261]\tTime 0.033 (0.026)\tLoss 1.0695 (0.8974)\tPrec@1 78.000 (81.110)\tPrec@5 96.000 (97.934)\n",
            "Test: [100/261]\tTime 0.022 (0.026)\tLoss 0.9327 (0.8975)\tPrec@1 78.000 (81.069)\tPrec@5 98.000 (97.931)\n",
            "Test: [110/261]\tTime 0.033 (0.026)\tLoss 1.1215 (0.8877)\tPrec@1 81.000 (81.207)\tPrec@5 99.000 (97.964)\n",
            "Test: [120/261]\tTime 0.016 (0.026)\tLoss 0.5624 (0.8833)\tPrec@1 89.000 (81.455)\tPrec@5 99.000 (97.926)\n",
            "Test: [130/261]\tTime 0.010 (0.025)\tLoss 1.0242 (0.8879)\tPrec@1 76.000 (81.328)\tPrec@5 97.000 (97.878)\n",
            "Test: [140/261]\tTime 0.036 (0.025)\tLoss 1.0123 (0.8833)\tPrec@1 84.000 (81.426)\tPrec@5 96.000 (97.858)\n",
            "Test: [150/261]\tTime 0.025 (0.025)\tLoss 0.6146 (0.8828)\tPrec@1 90.000 (81.457)\tPrec@5 97.000 (97.815)\n",
            "Test: [160/261]\tTime 0.026 (0.025)\tLoss 0.3159 (0.8824)\tPrec@1 90.000 (81.491)\tPrec@5 100.000 (97.845)\n",
            "Test: [170/261]\tTime 0.022 (0.025)\tLoss 0.9059 (0.8768)\tPrec@1 83.000 (81.614)\tPrec@5 97.000 (97.854)\n",
            "Test: [180/261]\tTime 0.025 (0.025)\tLoss 0.8628 (0.8785)\tPrec@1 87.000 (81.691)\tPrec@5 94.000 (97.829)\n",
            "Test: [190/261]\tTime 0.010 (0.025)\tLoss 0.7682 (0.8723)\tPrec@1 83.000 (81.759)\tPrec@5 99.000 (97.864)\n",
            "Test: [200/261]\tTime 0.036 (0.025)\tLoss 0.8075 (0.8702)\tPrec@1 80.000 (81.726)\tPrec@5 99.000 (97.861)\n",
            "Test: [210/261]\tTime 0.024 (0.025)\tLoss 0.7385 (0.8696)\tPrec@1 81.000 (81.730)\tPrec@5 99.000 (97.877)\n",
            "Test: [220/261]\tTime 0.018 (0.025)\tLoss 1.1863 (0.8711)\tPrec@1 75.000 (81.661)\tPrec@5 97.000 (97.891)\n",
            "Test: [230/261]\tTime 0.031 (0.025)\tLoss 0.8634 (0.8703)\tPrec@1 81.000 (81.645)\tPrec@5 96.000 (97.887)\n",
            "Test: [240/261]\tTime 0.009 (0.025)\tLoss 0.7188 (0.8730)\tPrec@1 83.000 (81.598)\tPrec@5 98.000 (97.892)\n",
            "Test: [250/261]\tTime 0.029 (0.024)\tLoss 0.8489 (0.8697)\tPrec@1 81.000 (81.590)\tPrec@5 99.000 (97.912)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3928 (0.8727)\tPrec@1 93.750 (81.623)\tPrec@5 96.875 (97.872)\n",
            "val Results: Prec@1 81.623 Prec@5 97.872 Loss 0.87268\n",
            "val Class Accuracy: [0.647,0.948,0.924,0.912,0.821,0.812,0.617,0.641,0.783,0.627]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [84][0/66], lr: 0.01000\tTime 0.641 (0.641)\tData 0.563 (0.563)\tLoss 0.0486 (0.0486)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][10/66], lr: 0.01000\tTime 0.104 (0.147)\tData 0.002 (0.058)\tLoss 0.0436 (0.0507)\tPrec@1 98.828 (98.224)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][20/66], lr: 0.01000\tTime 0.078 (0.121)\tData 0.015 (0.033)\tLoss 0.0229 (0.0577)\tPrec@1 99.609 (97.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][30/66], lr: 0.01000\tTime 0.089 (0.111)\tData 0.005 (0.025)\tLoss 0.0471 (0.0590)\tPrec@1 98.828 (97.959)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][40/66], lr: 0.01000\tTime 0.108 (0.107)\tData 0.005 (0.020)\tLoss 0.0933 (0.0596)\tPrec@1 97.656 (98.018)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][50/66], lr: 0.01000\tTime 0.095 (0.103)\tData 0.007 (0.018)\tLoss 0.0658 (0.0610)\tPrec@1 97.656 (97.932)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][60/66], lr: 0.01000\tTime 0.063 (0.101)\tData 0.000 (0.016)\tLoss 0.0653 (0.0615)\tPrec@1 97.656 (97.874)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.217 (0.217)\tLoss 0.9503 (0.9503)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.029 (0.046)\tLoss 1.2551 (0.9353)\tPrec@1 76.000 (79.091)\tPrec@5 98.000 (97.182)\n",
            "Test: [20/261]\tTime 0.020 (0.035)\tLoss 1.0861 (0.9023)\tPrec@1 76.000 (79.714)\tPrec@5 95.000 (96.905)\n",
            "Test: [30/261]\tTime 0.026 (0.033)\tLoss 0.8552 (0.8547)\tPrec@1 81.000 (80.839)\tPrec@5 98.000 (97.258)\n",
            "Test: [40/261]\tTime 0.020 (0.030)\tLoss 0.7220 (0.8272)\tPrec@1 85.000 (81.293)\tPrec@5 97.000 (97.488)\n",
            "Test: [50/261]\tTime 0.016 (0.028)\tLoss 0.9693 (0.8311)\tPrec@1 80.000 (81.412)\tPrec@5 98.000 (97.490)\n",
            "Test: [60/261]\tTime 0.011 (0.027)\tLoss 0.6032 (0.8293)\tPrec@1 85.000 (81.590)\tPrec@5 99.000 (97.393)\n",
            "Test: [70/261]\tTime 0.029 (0.027)\tLoss 0.8492 (0.8303)\tPrec@1 81.000 (81.521)\tPrec@5 98.000 (97.437)\n",
            "Test: [80/261]\tTime 0.025 (0.027)\tLoss 0.6632 (0.8289)\tPrec@1 82.000 (81.568)\tPrec@5 99.000 (97.432)\n",
            "Test: [90/261]\tTime 0.020 (0.025)\tLoss 0.8754 (0.8562)\tPrec@1 85.000 (81.396)\tPrec@5 96.000 (97.363)\n",
            "Test: [100/261]\tTime 0.021 (0.025)\tLoss 0.8449 (0.8512)\tPrec@1 81.000 (81.436)\tPrec@5 96.000 (97.436)\n",
            "Test: [110/261]\tTime 0.024 (0.026)\tLoss 0.7477 (0.8454)\tPrec@1 83.000 (81.459)\tPrec@5 98.000 (97.495)\n",
            "Test: [120/261]\tTime 0.030 (0.025)\tLoss 0.7555 (0.8431)\tPrec@1 85.000 (81.463)\tPrec@5 96.000 (97.405)\n",
            "Test: [130/261]\tTime 0.014 (0.025)\tLoss 0.7790 (0.8427)\tPrec@1 81.000 (81.481)\tPrec@5 96.000 (97.389)\n",
            "Test: [140/261]\tTime 0.032 (0.025)\tLoss 0.9700 (0.8396)\tPrec@1 79.000 (81.489)\tPrec@5 95.000 (97.404)\n",
            "Test: [150/261]\tTime 0.031 (0.025)\tLoss 0.6986 (0.8419)\tPrec@1 83.000 (81.536)\tPrec@5 98.000 (97.397)\n",
            "Test: [160/261]\tTime 0.032 (0.025)\tLoss 0.4641 (0.8393)\tPrec@1 87.000 (81.578)\tPrec@5 100.000 (97.453)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.7604 (0.8380)\tPrec@1 81.000 (81.573)\tPrec@5 97.000 (97.468)\n",
            "Test: [180/261]\tTime 0.022 (0.025)\tLoss 0.7068 (0.8413)\tPrec@1 84.000 (81.530)\tPrec@5 93.000 (97.431)\n",
            "Test: [190/261]\tTime 0.013 (0.024)\tLoss 0.7689 (0.8391)\tPrec@1 82.000 (81.571)\tPrec@5 98.000 (97.445)\n",
            "Test: [200/261]\tTime 0.031 (0.024)\tLoss 0.6831 (0.8381)\tPrec@1 87.000 (81.542)\tPrec@5 98.000 (97.418)\n",
            "Test: [210/261]\tTime 0.026 (0.025)\tLoss 0.6512 (0.8381)\tPrec@1 84.000 (81.564)\tPrec@5 98.000 (97.403)\n",
            "Test: [220/261]\tTime 0.016 (0.024)\tLoss 0.9564 (0.8346)\tPrec@1 77.000 (81.552)\tPrec@5 97.000 (97.430)\n",
            "Test: [230/261]\tTime 0.025 (0.024)\tLoss 0.9736 (0.8377)\tPrec@1 81.000 (81.571)\tPrec@5 96.000 (97.398)\n",
            "Test: [240/261]\tTime 0.024 (0.024)\tLoss 0.9073 (0.8406)\tPrec@1 79.000 (81.531)\tPrec@5 98.000 (97.386)\n",
            "Test: [250/261]\tTime 0.019 (0.024)\tLoss 0.9418 (0.8391)\tPrec@1 79.000 (81.526)\tPrec@5 99.000 (97.398)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4600 (0.8411)\tPrec@1 87.500 (81.538)\tPrec@5 100.000 (97.357)\n",
            "val Results: Prec@1 81.538 Prec@5 97.357 Loss 0.84114\n",
            "val Class Accuracy: [0.650,0.932,0.888,0.833,0.932,0.852,0.789,0.820,0.411,0.612]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [85][0/66], lr: 0.01000\tTime 0.492 (0.492)\tData 0.413 (0.413)\tLoss 0.0504 (0.0504)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][10/66], lr: 0.01000\tTime 0.091 (0.133)\tData 0.000 (0.042)\tLoss 0.0526 (0.0576)\tPrec@1 98.438 (97.976)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][20/66], lr: 0.01000\tTime 0.109 (0.115)\tData 0.000 (0.024)\tLoss 0.0347 (0.0611)\tPrec@1 98.828 (98.028)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][30/66], lr: 0.01000\tTime 0.111 (0.109)\tData 0.000 (0.018)\tLoss 0.0954 (0.0617)\tPrec@1 96.484 (98.059)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][40/66], lr: 0.01000\tTime 0.107 (0.106)\tData 0.000 (0.015)\tLoss 0.0813 (0.0591)\tPrec@1 97.266 (98.123)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][50/66], lr: 0.01000\tTime 0.103 (0.103)\tData 0.005 (0.013)\tLoss 0.0892 (0.0593)\tPrec@1 97.266 (98.116)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][60/66], lr: 0.01000\tTime 0.071 (0.100)\tData 0.000 (0.011)\tLoss 0.0629 (0.0609)\tPrec@1 96.875 (98.008)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.216 (0.216)\tLoss 1.0931 (1.0931)\tPrec@1 83.000 (83.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.017 (0.049)\tLoss 1.4906 (0.9552)\tPrec@1 75.000 (80.636)\tPrec@5 96.000 (97.364)\n",
            "Test: [20/261]\tTime 0.018 (0.034)\tLoss 1.2656 (0.9080)\tPrec@1 80.000 (81.381)\tPrec@5 94.000 (97.238)\n",
            "Test: [30/261]\tTime 0.016 (0.031)\tLoss 0.8696 (0.8396)\tPrec@1 81.000 (82.129)\tPrec@5 98.000 (97.516)\n",
            "Test: [40/261]\tTime 0.035 (0.029)\tLoss 0.5758 (0.8024)\tPrec@1 87.000 (82.634)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/261]\tTime 0.017 (0.028)\tLoss 0.6770 (0.7909)\tPrec@1 85.000 (82.824)\tPrec@5 98.000 (97.784)\n",
            "Test: [60/261]\tTime 0.027 (0.027)\tLoss 0.7878 (0.7980)\tPrec@1 86.000 (82.836)\tPrec@5 97.000 (97.639)\n",
            "Test: [70/261]\tTime 0.027 (0.027)\tLoss 0.7720 (0.8026)\tPrec@1 80.000 (82.704)\tPrec@5 99.000 (97.648)\n",
            "Test: [80/261]\tTime 0.009 (0.027)\tLoss 0.6762 (0.8017)\tPrec@1 82.000 (82.642)\tPrec@5 98.000 (97.691)\n",
            "Test: [90/261]\tTime 0.009 (0.026)\tLoss 0.9273 (0.8274)\tPrec@1 81.000 (82.440)\tPrec@5 96.000 (97.593)\n",
            "Test: [100/261]\tTime 0.027 (0.026)\tLoss 0.9019 (0.8239)\tPrec@1 81.000 (82.545)\tPrec@5 97.000 (97.545)\n",
            "Test: [110/261]\tTime 0.022 (0.026)\tLoss 1.0505 (0.8202)\tPrec@1 82.000 (82.559)\tPrec@5 98.000 (97.559)\n",
            "Test: [120/261]\tTime 0.020 (0.025)\tLoss 0.7231 (0.8211)\tPrec@1 85.000 (82.587)\tPrec@5 97.000 (97.488)\n",
            "Test: [130/261]\tTime 0.016 (0.025)\tLoss 0.9241 (0.8217)\tPrec@1 79.000 (82.618)\tPrec@5 97.000 (97.481)\n",
            "Test: [140/261]\tTime 0.019 (0.025)\tLoss 0.9054 (0.8182)\tPrec@1 78.000 (82.596)\tPrec@5 98.000 (97.532)\n",
            "Test: [150/261]\tTime 0.023 (0.025)\tLoss 0.7487 (0.8184)\tPrec@1 83.000 (82.543)\tPrec@5 96.000 (97.503)\n",
            "Test: [160/261]\tTime 0.031 (0.025)\tLoss 0.4678 (0.8172)\tPrec@1 88.000 (82.559)\tPrec@5 99.000 (97.553)\n",
            "Test: [170/261]\tTime 0.014 (0.025)\tLoss 0.5742 (0.8115)\tPrec@1 90.000 (82.579)\tPrec@5 98.000 (97.567)\n",
            "Test: [180/261]\tTime 0.019 (0.025)\tLoss 0.7083 (0.8125)\tPrec@1 85.000 (82.597)\tPrec@5 95.000 (97.564)\n",
            "Test: [190/261]\tTime 0.020 (0.025)\tLoss 0.8614 (0.8107)\tPrec@1 78.000 (82.571)\tPrec@5 98.000 (97.597)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.9052 (0.8118)\tPrec@1 84.000 (82.537)\tPrec@5 98.000 (97.602)\n",
            "Test: [210/261]\tTime 0.009 (0.025)\tLoss 0.6796 (0.8140)\tPrec@1 83.000 (82.540)\tPrec@5 99.000 (97.578)\n",
            "Test: [220/261]\tTime 0.034 (0.025)\tLoss 0.9912 (0.8117)\tPrec@1 81.000 (82.520)\tPrec@5 97.000 (97.597)\n",
            "Test: [230/261]\tTime 0.019 (0.025)\tLoss 1.0107 (0.8151)\tPrec@1 77.000 (82.455)\tPrec@5 95.000 (97.563)\n",
            "Test: [240/261]\tTime 0.021 (0.024)\tLoss 0.5748 (0.8196)\tPrec@1 84.000 (82.423)\tPrec@5 98.000 (97.519)\n",
            "Test: [250/261]\tTime 0.021 (0.024)\tLoss 0.5280 (0.8141)\tPrec@1 83.000 (82.486)\tPrec@5 100.000 (97.522)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.5641 (0.8123)\tPrec@1 87.500 (82.548)\tPrec@5 100.000 (97.511)\n",
            "val Results: Prec@1 82.548 Prec@5 97.511 Loss 0.81234\n",
            "val Class Accuracy: [0.595,0.974,0.903,0.873,0.832,0.786,0.742,0.847,0.610,0.665]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [86][0/66], lr: 0.01000\tTime 0.476 (0.476)\tData 0.397 (0.397)\tLoss 0.0426 (0.0426)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][10/66], lr: 0.01000\tTime 0.085 (0.135)\tData 0.004 (0.042)\tLoss 0.0757 (0.0406)\tPrec@1 97.266 (98.544)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][20/66], lr: 0.01000\tTime 0.116 (0.114)\tData 0.005 (0.024)\tLoss 0.0785 (0.0501)\tPrec@1 98.438 (98.233)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][30/66], lr: 0.01000\tTime 0.096 (0.108)\tData 0.000 (0.018)\tLoss 0.0585 (0.0521)\tPrec@1 98.047 (98.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][40/66], lr: 0.01000\tTime 0.088 (0.104)\tData 0.003 (0.015)\tLoss 0.0584 (0.0505)\tPrec@1 98.047 (98.276)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][50/66], lr: 0.01000\tTime 0.098 (0.101)\tData 0.000 (0.013)\tLoss 0.1060 (0.0511)\tPrec@1 96.094 (98.284)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][60/66], lr: 0.01000\tTime 0.066 (0.099)\tData 0.000 (0.011)\tLoss 0.0913 (0.0530)\tPrec@1 95.703 (98.175)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.220 (0.220)\tLoss 1.0042 (1.0042)\tPrec@1 83.000 (83.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.034 (0.050)\tLoss 1.2792 (0.9020)\tPrec@1 78.000 (80.909)\tPrec@5 97.000 (96.909)\n",
            "Test: [20/261]\tTime 0.010 (0.036)\tLoss 1.3699 (0.8526)\tPrec@1 74.000 (81.810)\tPrec@5 93.000 (97.048)\n",
            "Test: [30/261]\tTime 0.036 (0.032)\tLoss 0.6231 (0.8070)\tPrec@1 84.000 (82.484)\tPrec@5 98.000 (97.581)\n",
            "Test: [40/261]\tTime 0.034 (0.031)\tLoss 0.6674 (0.7743)\tPrec@1 86.000 (83.098)\tPrec@5 98.000 (97.805)\n",
            "Test: [50/261]\tTime 0.031 (0.029)\tLoss 0.6562 (0.7576)\tPrec@1 82.000 (83.353)\tPrec@5 99.000 (97.922)\n",
            "Test: [60/261]\tTime 0.016 (0.028)\tLoss 0.6010 (0.7611)\tPrec@1 87.000 (83.492)\tPrec@5 99.000 (97.803)\n",
            "Test: [70/261]\tTime 0.019 (0.027)\tLoss 0.6289 (0.7610)\tPrec@1 82.000 (83.563)\tPrec@5 98.000 (97.803)\n",
            "Test: [80/261]\tTime 0.049 (0.028)\tLoss 0.6032 (0.7643)\tPrec@1 85.000 (83.543)\tPrec@5 98.000 (97.790)\n",
            "Test: [90/261]\tTime 0.019 (0.027)\tLoss 0.8840 (0.7876)\tPrec@1 82.000 (83.275)\tPrec@5 96.000 (97.692)\n",
            "Test: [100/261]\tTime 0.044 (0.027)\tLoss 0.8666 (0.7792)\tPrec@1 83.000 (83.376)\tPrec@5 95.000 (97.713)\n",
            "Test: [110/261]\tTime 0.049 (0.027)\tLoss 0.8185 (0.7727)\tPrec@1 85.000 (83.360)\tPrec@5 98.000 (97.766)\n",
            "Test: [120/261]\tTime 0.025 (0.026)\tLoss 0.8766 (0.7708)\tPrec@1 86.000 (83.421)\tPrec@5 96.000 (97.760)\n",
            "Test: [130/261]\tTime 0.032 (0.026)\tLoss 0.7004 (0.7726)\tPrec@1 81.000 (83.481)\tPrec@5 99.000 (97.756)\n",
            "Test: [140/261]\tTime 0.035 (0.026)\tLoss 0.9189 (0.7721)\tPrec@1 75.000 (83.362)\tPrec@5 96.000 (97.787)\n",
            "Test: [150/261]\tTime 0.012 (0.026)\tLoss 0.5675 (0.7694)\tPrec@1 83.000 (83.437)\tPrec@5 98.000 (97.775)\n",
            "Test: [160/261]\tTime 0.009 (0.025)\tLoss 0.4063 (0.7678)\tPrec@1 88.000 (83.453)\tPrec@5 99.000 (97.770)\n",
            "Test: [170/261]\tTime 0.022 (0.025)\tLoss 0.7292 (0.7624)\tPrec@1 82.000 (83.538)\tPrec@5 96.000 (97.743)\n",
            "Test: [180/261]\tTime 0.010 (0.025)\tLoss 0.7569 (0.7639)\tPrec@1 87.000 (83.420)\tPrec@5 95.000 (97.707)\n",
            "Test: [190/261]\tTime 0.031 (0.025)\tLoss 0.5574 (0.7593)\tPrec@1 85.000 (83.476)\tPrec@5 99.000 (97.770)\n",
            "Test: [200/261]\tTime 0.024 (0.025)\tLoss 0.6424 (0.7572)\tPrec@1 86.000 (83.507)\tPrec@5 98.000 (97.781)\n",
            "Test: [210/261]\tTime 0.030 (0.025)\tLoss 0.5681 (0.7567)\tPrec@1 89.000 (83.526)\tPrec@5 96.000 (97.768)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 1.0622 (0.7547)\tPrec@1 76.000 (83.511)\tPrec@5 98.000 (97.783)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 0.7543 (0.7555)\tPrec@1 85.000 (83.455)\tPrec@5 97.000 (97.779)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.6347 (0.7599)\tPrec@1 86.000 (83.419)\tPrec@5 97.000 (97.759)\n",
            "Test: [250/261]\tTime 0.017 (0.025)\tLoss 0.7931 (0.7582)\tPrec@1 86.000 (83.454)\tPrec@5 99.000 (97.749)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3469 (0.7586)\tPrec@1 87.500 (83.424)\tPrec@5 100.000 (97.749)\n",
            "val Results: Prec@1 83.424 Prec@5 97.749 Loss 0.75856\n",
            "val Class Accuracy: [0.802,0.949,0.875,0.828,0.887,0.880,0.679,0.788,0.562,0.791]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [87][0/66], lr: 0.01000\tTime 0.402 (0.402)\tData 0.337 (0.337)\tLoss 0.0519 (0.0519)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][10/66], lr: 0.01000\tTime 0.112 (0.138)\tData 0.000 (0.051)\tLoss 0.0317 (0.0661)\tPrec@1 98.047 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][20/66], lr: 0.01000\tTime 0.072 (0.116)\tData 0.003 (0.029)\tLoss 0.0263 (0.0671)\tPrec@1 99.609 (97.638)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [87][30/66], lr: 0.01000\tTime 0.091 (0.108)\tData 0.004 (0.022)\tLoss 0.0716 (0.0655)\tPrec@1 98.828 (97.719)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [87][40/66], lr: 0.01000\tTime 0.093 (0.105)\tData 0.007 (0.018)\tLoss 0.0638 (0.0660)\tPrec@1 97.266 (97.685)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [87][50/66], lr: 0.01000\tTime 0.097 (0.102)\tData 0.000 (0.016)\tLoss 0.0541 (0.0666)\tPrec@1 98.047 (97.687)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [87][60/66], lr: 0.01000\tTime 0.077 (0.099)\tData 0.000 (0.014)\tLoss 0.0702 (0.0655)\tPrec@1 97.266 (97.720)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.223 (0.223)\tLoss 1.0889 (1.0889)\tPrec@1 80.000 (80.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.022 (0.049)\tLoss 1.2129 (0.9297)\tPrec@1 79.000 (80.364)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/261]\tTime 0.020 (0.036)\tLoss 1.0306 (0.8595)\tPrec@1 78.000 (81.095)\tPrec@5 96.000 (97.143)\n",
            "Test: [30/261]\tTime 0.029 (0.034)\tLoss 0.7071 (0.8069)\tPrec@1 86.000 (82.097)\tPrec@5 98.000 (97.484)\n",
            "Test: [40/261]\tTime 0.031 (0.032)\tLoss 0.6583 (0.7813)\tPrec@1 83.000 (82.390)\tPrec@5 98.000 (97.732)\n",
            "Test: [50/261]\tTime 0.020 (0.030)\tLoss 0.5199 (0.7692)\tPrec@1 88.000 (82.804)\tPrec@5 99.000 (97.784)\n",
            "Test: [60/261]\tTime 0.021 (0.030)\tLoss 0.7807 (0.7842)\tPrec@1 80.000 (82.574)\tPrec@5 99.000 (97.705)\n",
            "Test: [70/261]\tTime 0.031 (0.029)\tLoss 0.8463 (0.7858)\tPrec@1 80.000 (82.732)\tPrec@5 98.000 (97.704)\n",
            "Test: [80/261]\tTime 0.021 (0.028)\tLoss 0.8289 (0.7909)\tPrec@1 81.000 (82.630)\tPrec@5 95.000 (97.630)\n",
            "Test: [90/261]\tTime 0.019 (0.028)\tLoss 0.9218 (0.8185)\tPrec@1 82.000 (82.385)\tPrec@5 97.000 (97.462)\n",
            "Test: [100/261]\tTime 0.012 (0.027)\tLoss 0.7391 (0.8165)\tPrec@1 84.000 (82.416)\tPrec@5 96.000 (97.406)\n",
            "Test: [110/261]\tTime 0.016 (0.027)\tLoss 1.0486 (0.8101)\tPrec@1 79.000 (82.468)\tPrec@5 98.000 (97.396)\n",
            "Test: [120/261]\tTime 0.021 (0.027)\tLoss 0.7741 (0.8076)\tPrec@1 84.000 (82.554)\tPrec@5 96.000 (97.339)\n",
            "Test: [130/261]\tTime 0.015 (0.026)\tLoss 0.7345 (0.8085)\tPrec@1 83.000 (82.443)\tPrec@5 97.000 (97.389)\n",
            "Test: [140/261]\tTime 0.040 (0.027)\tLoss 0.8824 (0.8052)\tPrec@1 79.000 (82.475)\tPrec@5 97.000 (97.468)\n",
            "Test: [150/261]\tTime 0.018 (0.026)\tLoss 0.5240 (0.8071)\tPrec@1 89.000 (82.510)\tPrec@5 98.000 (97.450)\n",
            "Test: [160/261]\tTime 0.035 (0.026)\tLoss 0.5109 (0.8080)\tPrec@1 88.000 (82.596)\tPrec@5 99.000 (97.422)\n",
            "Test: [170/261]\tTime 0.024 (0.026)\tLoss 0.5927 (0.7989)\tPrec@1 87.000 (82.713)\tPrec@5 99.000 (97.491)\n",
            "Test: [180/261]\tTime 0.022 (0.026)\tLoss 0.8117 (0.7995)\tPrec@1 82.000 (82.702)\tPrec@5 93.000 (97.508)\n",
            "Test: [190/261]\tTime 0.017 (0.026)\tLoss 0.4776 (0.7960)\tPrec@1 89.000 (82.754)\tPrec@5 99.000 (97.560)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.6084 (0.7931)\tPrec@1 85.000 (82.781)\tPrec@5 98.000 (97.567)\n",
            "Test: [210/261]\tTime 0.024 (0.026)\tLoss 0.7259 (0.7949)\tPrec@1 82.000 (82.787)\tPrec@5 99.000 (97.578)\n",
            "Test: [220/261]\tTime 0.023 (0.026)\tLoss 0.9440 (0.7919)\tPrec@1 81.000 (82.792)\tPrec@5 95.000 (97.597)\n",
            "Test: [230/261]\tTime 0.026 (0.026)\tLoss 0.7227 (0.7912)\tPrec@1 83.000 (82.784)\tPrec@5 96.000 (97.571)\n",
            "Test: [240/261]\tTime 0.019 (0.025)\tLoss 0.8132 (0.7938)\tPrec@1 81.000 (82.747)\tPrec@5 96.000 (97.568)\n",
            "Test: [250/261]\tTime 0.021 (0.025)\tLoss 0.4481 (0.7878)\tPrec@1 88.000 (82.845)\tPrec@5 99.000 (97.590)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3197 (0.7880)\tPrec@1 93.750 (82.844)\tPrec@5 100.000 (97.576)\n",
            "val Results: Prec@1 82.844 Prec@5 97.576 Loss 0.78799\n",
            "val Class Accuracy: [0.581,0.941,0.909,0.923,0.850,0.800,0.734,0.797,0.648,0.712]\n",
            "Best Prec@1: 85.249\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [88][0/66], lr: 0.01000\tTime 0.607 (0.607)\tData 0.542 (0.542)\tLoss 0.0678 (0.0678)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][10/66], lr: 0.01000\tTime 0.088 (0.135)\tData 0.000 (0.053)\tLoss 0.0479 (0.0597)\tPrec@1 98.047 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][20/66], lr: 0.01000\tTime 0.108 (0.117)\tData 0.005 (0.031)\tLoss 0.0621 (0.0550)\tPrec@1 97.266 (98.196)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][30/66], lr: 0.01000\tTime 0.088 (0.109)\tData 0.000 (0.022)\tLoss 0.0400 (0.0554)\tPrec@1 98.438 (98.198)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][40/66], lr: 0.01000\tTime 0.066 (0.106)\tData 0.000 (0.018)\tLoss 0.0577 (0.0567)\tPrec@1 97.266 (98.114)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][50/66], lr: 0.01000\tTime 0.081 (0.102)\tData 0.000 (0.016)\tLoss 0.0697 (0.0563)\tPrec@1 97.656 (98.116)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][60/66], lr: 0.01000\tTime 0.067 (0.100)\tData 0.000 (0.015)\tLoss 0.0563 (0.0563)\tPrec@1 98.828 (98.098)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.217 (0.217)\tLoss 0.5718 (0.5718)\tPrec@1 86.000 (86.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.018 (0.048)\tLoss 1.3419 (0.7401)\tPrec@1 80.000 (83.091)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/261]\tTime 0.046 (0.036)\tLoss 1.0086 (0.7353)\tPrec@1 80.000 (83.429)\tPrec@5 95.000 (98.238)\n",
            "Test: [30/261]\tTime 0.046 (0.034)\tLoss 0.6161 (0.6768)\tPrec@1 87.000 (85.000)\tPrec@5 97.000 (98.387)\n",
            "Test: [40/261]\tTime 0.024 (0.031)\tLoss 0.6312 (0.6462)\tPrec@1 86.000 (85.561)\tPrec@5 98.000 (98.488)\n",
            "Test: [50/261]\tTime 0.031 (0.030)\tLoss 0.5848 (0.6474)\tPrec@1 84.000 (85.588)\tPrec@5 99.000 (98.412)\n",
            "Test: [60/261]\tTime 0.014 (0.027)\tLoss 0.6394 (0.6457)\tPrec@1 83.000 (85.574)\tPrec@5 99.000 (98.426)\n",
            "Test: [70/261]\tTime 0.025 (0.027)\tLoss 0.6096 (0.6504)\tPrec@1 82.000 (85.592)\tPrec@5 99.000 (98.479)\n",
            "Test: [80/261]\tTime 0.011 (0.027)\tLoss 0.7374 (0.6615)\tPrec@1 86.000 (85.543)\tPrec@5 98.000 (98.457)\n",
            "Test: [90/261]\tTime 0.009 (0.027)\tLoss 0.6624 (0.6845)\tPrec@1 87.000 (85.319)\tPrec@5 97.000 (98.330)\n",
            "Test: [100/261]\tTime 0.023 (0.026)\tLoss 0.9048 (0.6801)\tPrec@1 82.000 (85.386)\tPrec@5 97.000 (98.277)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.6976 (0.6778)\tPrec@1 86.000 (85.441)\tPrec@5 99.000 (98.333)\n",
            "Test: [120/261]\tTime 0.010 (0.026)\tLoss 0.8146 (0.6762)\tPrec@1 87.000 (85.512)\tPrec@5 96.000 (98.314)\n",
            "Test: [130/261]\tTime 0.010 (0.026)\tLoss 0.8997 (0.6798)\tPrec@1 81.000 (85.511)\tPrec@5 100.000 (98.275)\n",
            "Test: [140/261]\tTime 0.024 (0.026)\tLoss 0.8038 (0.6732)\tPrec@1 82.000 (85.546)\tPrec@5 100.000 (98.284)\n",
            "Test: [150/261]\tTime 0.031 (0.026)\tLoss 0.5141 (0.6727)\tPrec@1 87.000 (85.636)\tPrec@5 98.000 (98.238)\n",
            "Test: [160/261]\tTime 0.022 (0.026)\tLoss 0.4467 (0.6722)\tPrec@1 90.000 (85.590)\tPrec@5 99.000 (98.267)\n",
            "Test: [170/261]\tTime 0.012 (0.025)\tLoss 0.6671 (0.6690)\tPrec@1 90.000 (85.725)\tPrec@5 98.000 (98.269)\n",
            "Test: [180/261]\tTime 0.018 (0.025)\tLoss 0.6211 (0.6731)\tPrec@1 85.000 (85.597)\tPrec@5 96.000 (98.260)\n",
            "Test: [190/261]\tTime 0.017 (0.025)\tLoss 0.5517 (0.6694)\tPrec@1 86.000 (85.639)\tPrec@5 100.000 (98.298)\n",
            "Test: [200/261]\tTime 0.012 (0.025)\tLoss 0.7405 (0.6694)\tPrec@1 83.000 (85.577)\tPrec@5 98.000 (98.289)\n",
            "Test: [210/261]\tTime 0.019 (0.025)\tLoss 0.5141 (0.6695)\tPrec@1 90.000 (85.592)\tPrec@5 99.000 (98.275)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.9142 (0.6678)\tPrec@1 83.000 (85.570)\tPrec@5 98.000 (98.299)\n",
            "Test: [230/261]\tTime 0.029 (0.025)\tLoss 0.7129 (0.6688)\tPrec@1 82.000 (85.498)\tPrec@5 98.000 (98.294)\n",
            "Test: [240/261]\tTime 0.012 (0.025)\tLoss 0.5895 (0.6720)\tPrec@1 88.000 (85.477)\tPrec@5 98.000 (98.261)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.5140 (0.6673)\tPrec@1 88.000 (85.546)\tPrec@5 100.000 (98.259)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3208 (0.6676)\tPrec@1 93.750 (85.552)\tPrec@5 100.000 (98.248)\n",
            "val Results: Prec@1 85.552 Prec@5 98.248 Loss 0.66756\n",
            "val Class Accuracy: [0.774,0.974,0.923,0.821,0.914,0.819,0.830,0.751,0.683,0.761]\n",
            "Best Prec@1: 85.552\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [89][0/66], lr: 0.01000\tTime 0.559 (0.559)\tData 0.458 (0.458)\tLoss 0.0325 (0.0325)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][10/66], lr: 0.01000\tTime 0.093 (0.137)\tData 0.000 (0.049)\tLoss 0.0494 (0.0498)\tPrec@1 97.266 (98.224)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][20/66], lr: 0.01000\tTime 0.077 (0.117)\tData 0.001 (0.032)\tLoss 0.0546 (0.0520)\tPrec@1 97.656 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][30/66], lr: 0.01000\tTime 0.079 (0.108)\tData 0.000 (0.024)\tLoss 0.1285 (0.0604)\tPrec@1 96.875 (98.072)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [89][40/66], lr: 0.01000\tTime 0.091 (0.105)\tData 0.003 (0.020)\tLoss 0.0563 (0.0598)\tPrec@1 98.438 (98.095)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [89][50/66], lr: 0.01000\tTime 0.089 (0.102)\tData 0.007 (0.017)\tLoss 0.0946 (0.0609)\tPrec@1 95.703 (98.001)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [89][60/66], lr: 0.01000\tTime 0.078 (0.099)\tData 0.000 (0.015)\tLoss 0.0472 (0.0633)\tPrec@1 98.828 (97.906)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.284 (0.284)\tLoss 1.0687 (1.0687)\tPrec@1 80.000 (80.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.026 (0.047)\tLoss 1.3920 (1.1526)\tPrec@1 78.000 (76.182)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/261]\tTime 0.030 (0.038)\tLoss 1.4903 (1.1404)\tPrec@1 74.000 (76.857)\tPrec@5 96.000 (96.810)\n",
            "Test: [30/261]\tTime 0.009 (0.033)\tLoss 0.8147 (1.0640)\tPrec@1 82.000 (77.935)\tPrec@5 97.000 (97.323)\n",
            "Test: [40/261]\tTime 0.046 (0.031)\tLoss 1.2097 (1.0571)\tPrec@1 77.000 (77.927)\tPrec@5 96.000 (97.341)\n",
            "Test: [50/261]\tTime 0.022 (0.030)\tLoss 1.0455 (1.0668)\tPrec@1 75.000 (77.745)\tPrec@5 99.000 (97.412)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 1.4272 (1.0766)\tPrec@1 71.000 (77.721)\tPrec@5 97.000 (97.311)\n",
            "Test: [70/261]\tTime 0.044 (0.028)\tLoss 0.9960 (1.0813)\tPrec@1 73.000 (77.775)\tPrec@5 98.000 (97.338)\n",
            "Test: [80/261]\tTime 0.017 (0.027)\tLoss 1.2776 (1.0877)\tPrec@1 73.000 (77.630)\tPrec@5 97.000 (97.333)\n",
            "Test: [90/261]\tTime 0.015 (0.027)\tLoss 0.9795 (1.1181)\tPrec@1 79.000 (77.363)\tPrec@5 94.000 (97.209)\n",
            "Test: [100/261]\tTime 0.022 (0.027)\tLoss 1.4586 (1.1121)\tPrec@1 70.000 (77.366)\tPrec@5 98.000 (97.208)\n",
            "Test: [110/261]\tTime 0.026 (0.027)\tLoss 1.0903 (1.1002)\tPrec@1 78.000 (77.414)\tPrec@5 98.000 (97.261)\n",
            "Test: [120/261]\tTime 0.027 (0.026)\tLoss 1.0179 (1.0997)\tPrec@1 83.000 (77.488)\tPrec@5 97.000 (97.223)\n",
            "Test: [130/261]\tTime 0.020 (0.026)\tLoss 1.2383 (1.1012)\tPrec@1 72.000 (77.511)\tPrec@5 99.000 (97.206)\n",
            "Test: [140/261]\tTime 0.021 (0.026)\tLoss 1.2639 (1.0941)\tPrec@1 71.000 (77.582)\tPrec@5 99.000 (97.241)\n",
            "Test: [150/261]\tTime 0.029 (0.026)\tLoss 0.7480 (1.0980)\tPrec@1 83.000 (77.510)\tPrec@5 98.000 (97.205)\n",
            "Test: [160/261]\tTime 0.034 (0.026)\tLoss 0.8935 (1.0966)\tPrec@1 81.000 (77.540)\tPrec@5 98.000 (97.211)\n",
            "Test: [170/261]\tTime 0.016 (0.026)\tLoss 0.8033 (1.0887)\tPrec@1 81.000 (77.649)\tPrec@5 98.000 (97.228)\n",
            "Test: [180/261]\tTime 0.026 (0.025)\tLoss 1.0564 (1.0913)\tPrec@1 79.000 (77.619)\tPrec@5 94.000 (97.204)\n",
            "Test: [190/261]\tTime 0.019 (0.025)\tLoss 0.9393 (1.0903)\tPrec@1 80.000 (77.649)\tPrec@5 97.000 (97.215)\n",
            "Test: [200/261]\tTime 0.031 (0.025)\tLoss 1.1764 (1.0907)\tPrec@1 80.000 (77.627)\tPrec@5 98.000 (97.204)\n",
            "Test: [210/261]\tTime 0.038 (0.025)\tLoss 1.3713 (1.0899)\tPrec@1 74.000 (77.640)\tPrec@5 96.000 (97.213)\n",
            "Test: [220/261]\tTime 0.035 (0.025)\tLoss 1.1622 (1.0879)\tPrec@1 82.000 (77.688)\tPrec@5 97.000 (97.244)\n",
            "Test: [230/261]\tTime 0.023 (0.025)\tLoss 0.9978 (1.0893)\tPrec@1 77.000 (77.649)\tPrec@5 97.000 (97.212)\n",
            "Test: [240/261]\tTime 0.014 (0.025)\tLoss 0.9121 (1.0890)\tPrec@1 79.000 (77.676)\tPrec@5 96.000 (97.199)\n",
            "Test: [250/261]\tTime 0.022 (0.025)\tLoss 1.0053 (1.0845)\tPrec@1 73.000 (77.713)\tPrec@5 100.000 (97.247)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.6791 (1.0852)\tPrec@1 84.375 (77.693)\tPrec@5 96.875 (97.230)\n",
            "val Results: Prec@1 77.693 Prec@5 97.230 Loss 1.08525\n",
            "val Class Accuracy: [0.304,0.982,0.944,0.672,0.808,0.831,0.688,0.561,0.861,0.559]\n",
            "Best Prec@1: 85.552\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [90][0/66], lr: 0.01000\tTime 0.556 (0.556)\tData 0.469 (0.469)\tLoss 0.0439 (0.0439)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][10/66], lr: 0.01000\tTime 0.089 (0.138)\tData 0.000 (0.047)\tLoss 0.0662 (0.0512)\tPrec@1 98.438 (98.153)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][20/66], lr: 0.01000\tTime 0.095 (0.114)\tData 0.004 (0.027)\tLoss 0.0556 (0.0536)\tPrec@1 98.438 (98.065)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][30/66], lr: 0.01000\tTime 0.091 (0.108)\tData 0.010 (0.020)\tLoss 0.0612 (0.0543)\tPrec@1 97.266 (98.072)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][40/66], lr: 0.01000\tTime 0.090 (0.103)\tData 0.006 (0.017)\tLoss 0.0787 (0.0534)\tPrec@1 96.875 (98.104)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][50/66], lr: 0.01000\tTime 0.104 (0.101)\tData 0.003 (0.015)\tLoss 0.0384 (0.0518)\tPrec@1 98.828 (98.162)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][60/66], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.013)\tLoss 0.0865 (0.0512)\tPrec@1 95.312 (98.149)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.224 (0.224)\tLoss 0.7367 (0.7367)\tPrec@1 86.000 (86.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.030 (0.050)\tLoss 1.1740 (0.8550)\tPrec@1 77.000 (81.545)\tPrec@5 97.000 (97.364)\n",
            "Test: [20/261]\tTime 0.021 (0.037)\tLoss 1.0729 (0.8463)\tPrec@1 76.000 (81.190)\tPrec@5 100.000 (97.619)\n",
            "Test: [30/261]\tTime 0.026 (0.033)\tLoss 0.5614 (0.7923)\tPrec@1 86.000 (81.935)\tPrec@5 98.000 (97.903)\n",
            "Test: [40/261]\tTime 0.023 (0.030)\tLoss 0.7503 (0.7721)\tPrec@1 86.000 (82.146)\tPrec@5 98.000 (98.049)\n",
            "Test: [50/261]\tTime 0.025 (0.030)\tLoss 0.6894 (0.7633)\tPrec@1 83.000 (82.510)\tPrec@5 99.000 (98.137)\n",
            "Test: [60/261]\tTime 0.025 (0.028)\tLoss 0.6096 (0.7642)\tPrec@1 84.000 (82.787)\tPrec@5 99.000 (98.066)\n",
            "Test: [70/261]\tTime 0.015 (0.028)\tLoss 0.9255 (0.7683)\tPrec@1 71.000 (82.521)\tPrec@5 98.000 (98.028)\n",
            "Test: [80/261]\tTime 0.033 (0.027)\tLoss 0.8373 (0.7755)\tPrec@1 82.000 (82.531)\tPrec@5 97.000 (97.975)\n",
            "Test: [90/261]\tTime 0.031 (0.027)\tLoss 0.8990 (0.7978)\tPrec@1 81.000 (82.330)\tPrec@5 96.000 (97.846)\n",
            "Test: [100/261]\tTime 0.009 (0.026)\tLoss 1.0561 (0.7978)\tPrec@1 81.000 (82.396)\tPrec@5 96.000 (97.832)\n",
            "Test: [110/261]\tTime 0.032 (0.026)\tLoss 0.8342 (0.7883)\tPrec@1 83.000 (82.441)\tPrec@5 97.000 (97.865)\n",
            "Test: [120/261]\tTime 0.030 (0.026)\tLoss 0.8996 (0.7889)\tPrec@1 84.000 (82.446)\tPrec@5 95.000 (97.810)\n",
            "Test: [130/261]\tTime 0.020 (0.026)\tLoss 0.8187 (0.7928)\tPrec@1 83.000 (82.466)\tPrec@5 95.000 (97.771)\n",
            "Test: [140/261]\tTime 0.012 (0.026)\tLoss 0.8580 (0.7849)\tPrec@1 83.000 (82.574)\tPrec@5 95.000 (97.816)\n",
            "Test: [150/261]\tTime 0.021 (0.025)\tLoss 0.4898 (0.7826)\tPrec@1 86.000 (82.616)\tPrec@5 98.000 (97.781)\n",
            "Test: [160/261]\tTime 0.018 (0.025)\tLoss 0.5691 (0.7796)\tPrec@1 85.000 (82.658)\tPrec@5 99.000 (97.832)\n",
            "Test: [170/261]\tTime 0.035 (0.025)\tLoss 0.7223 (0.7767)\tPrec@1 87.000 (82.684)\tPrec@5 97.000 (97.795)\n",
            "Test: [180/261]\tTime 0.066 (0.025)\tLoss 0.7342 (0.7782)\tPrec@1 83.000 (82.696)\tPrec@5 94.000 (97.779)\n",
            "Test: [190/261]\tTime 0.009 (0.025)\tLoss 0.6709 (0.7777)\tPrec@1 80.000 (82.675)\tPrec@5 100.000 (97.801)\n",
            "Test: [200/261]\tTime 0.027 (0.025)\tLoss 0.7017 (0.7761)\tPrec@1 86.000 (82.667)\tPrec@5 97.000 (97.801)\n",
            "Test: [210/261]\tTime 0.009 (0.025)\tLoss 0.6003 (0.7778)\tPrec@1 87.000 (82.692)\tPrec@5 99.000 (97.754)\n",
            "Test: [220/261]\tTime 0.063 (0.025)\tLoss 0.7775 (0.7746)\tPrec@1 77.000 (82.665)\tPrec@5 99.000 (97.783)\n",
            "Test: [230/261]\tTime 0.045 (0.026)\tLoss 0.9337 (0.7776)\tPrec@1 75.000 (82.580)\tPrec@5 97.000 (97.758)\n",
            "Test: [240/261]\tTime 0.043 (0.026)\tLoss 0.7859 (0.7802)\tPrec@1 82.000 (82.568)\tPrec@5 97.000 (97.747)\n",
            "Test: [250/261]\tTime 0.044 (0.026)\tLoss 0.6589 (0.7748)\tPrec@1 84.000 (82.622)\tPrec@5 98.000 (97.757)\n",
            "Test: [260/261]\tTime 0.007 (0.026)\tLoss 0.4875 (0.7768)\tPrec@1 87.500 (82.610)\tPrec@5 96.875 (97.734)\n",
            "val Results: Prec@1 82.610 Prec@5 97.734 Loss 0.77677\n",
            "val Class Accuracy: [0.651,0.981,0.917,0.824,0.844,0.826,0.805,0.798,0.609,0.547]\n",
            "Best Prec@1: 85.552\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [91][0/66], lr: 0.01000\tTime 0.835 (0.835)\tData 0.736 (0.736)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][10/66], lr: 0.01000\tTime 0.084 (0.195)\tData 0.011 (0.102)\tLoss 0.0576 (0.0419)\tPrec@1 98.047 (98.757)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][20/66], lr: 0.01000\tTime 0.095 (0.149)\tData 0.024 (0.062)\tLoss 0.0289 (0.0406)\tPrec@1 99.609 (98.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][30/66], lr: 0.01000\tTime 0.081 (0.130)\tData 0.000 (0.044)\tLoss 0.0412 (0.0484)\tPrec@1 98.438 (98.387)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][40/66], lr: 0.01000\tTime 0.122 (0.122)\tData 0.006 (0.035)\tLoss 0.0736 (0.0483)\tPrec@1 96.875 (98.342)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][50/66], lr: 0.01000\tTime 0.084 (0.116)\tData 0.001 (0.029)\tLoss 0.0556 (0.0503)\tPrec@1 98.047 (98.277)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [91][60/66], lr: 0.01000\tTime 0.075 (0.111)\tData 0.000 (0.025)\tLoss 0.0690 (0.0501)\tPrec@1 97.656 (98.297)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.283 (0.283)\tLoss 0.7635 (0.7635)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.021 (0.046)\tLoss 1.1745 (0.8469)\tPrec@1 82.000 (81.182)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/261]\tTime 0.035 (0.036)\tLoss 1.1652 (0.8429)\tPrec@1 76.000 (81.810)\tPrec@5 97.000 (97.476)\n",
            "Test: [30/261]\tTime 0.029 (0.032)\tLoss 0.6683 (0.7513)\tPrec@1 84.000 (83.194)\tPrec@5 98.000 (97.903)\n",
            "Test: [40/261]\tTime 0.014 (0.030)\tLoss 0.6657 (0.7409)\tPrec@1 88.000 (83.512)\tPrec@5 99.000 (98.000)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.6100 (0.7397)\tPrec@1 86.000 (83.627)\tPrec@5 100.000 (98.137)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.6502 (0.7368)\tPrec@1 86.000 (83.508)\tPrec@5 99.000 (98.164)\n",
            "Test: [70/261]\tTime 0.019 (0.027)\tLoss 0.7004 (0.7347)\tPrec@1 83.000 (83.690)\tPrec@5 99.000 (98.155)\n",
            "Test: [80/261]\tTime 0.038 (0.027)\tLoss 0.7125 (0.7340)\tPrec@1 82.000 (83.630)\tPrec@5 99.000 (98.222)\n",
            "Test: [90/261]\tTime 0.046 (0.026)\tLoss 0.7225 (0.7544)\tPrec@1 87.000 (83.637)\tPrec@5 97.000 (98.088)\n",
            "Test: [100/261]\tTime 0.016 (0.026)\tLoss 0.9636 (0.7535)\tPrec@1 82.000 (83.832)\tPrec@5 97.000 (98.020)\n",
            "Test: [110/261]\tTime 0.009 (0.026)\tLoss 0.7355 (0.7476)\tPrec@1 86.000 (83.928)\tPrec@5 98.000 (98.009)\n",
            "Test: [120/261]\tTime 0.028 (0.026)\tLoss 0.6536 (0.7477)\tPrec@1 84.000 (83.843)\tPrec@5 98.000 (98.017)\n",
            "Test: [130/261]\tTime 0.021 (0.025)\tLoss 0.7868 (0.7493)\tPrec@1 83.000 (83.870)\tPrec@5 98.000 (98.031)\n",
            "Test: [140/261]\tTime 0.032 (0.025)\tLoss 0.7405 (0.7460)\tPrec@1 83.000 (83.894)\tPrec@5 98.000 (98.028)\n",
            "Test: [150/261]\tTime 0.019 (0.025)\tLoss 0.6191 (0.7465)\tPrec@1 88.000 (83.980)\tPrec@5 100.000 (98.020)\n",
            "Test: [160/261]\tTime 0.009 (0.025)\tLoss 0.3819 (0.7436)\tPrec@1 91.000 (83.988)\tPrec@5 100.000 (98.019)\n",
            "Test: [170/261]\tTime 0.027 (0.025)\tLoss 0.6569 (0.7391)\tPrec@1 86.000 (84.041)\tPrec@5 97.000 (98.035)\n",
            "Test: [180/261]\tTime 0.021 (0.025)\tLoss 0.6177 (0.7386)\tPrec@1 84.000 (84.033)\tPrec@5 97.000 (98.055)\n",
            "Test: [190/261]\tTime 0.015 (0.025)\tLoss 0.5175 (0.7370)\tPrec@1 87.000 (83.995)\tPrec@5 100.000 (98.099)\n",
            "Test: [200/261]\tTime 0.026 (0.025)\tLoss 0.7960 (0.7382)\tPrec@1 83.000 (83.891)\tPrec@5 96.000 (98.095)\n",
            "Test: [210/261]\tTime 0.018 (0.025)\tLoss 0.8378 (0.7390)\tPrec@1 82.000 (83.877)\tPrec@5 98.000 (98.133)\n",
            "Test: [220/261]\tTime 0.028 (0.025)\tLoss 0.7280 (0.7358)\tPrec@1 83.000 (83.887)\tPrec@5 97.000 (98.176)\n",
            "Test: [230/261]\tTime 0.009 (0.025)\tLoss 0.6338 (0.7391)\tPrec@1 85.000 (83.857)\tPrec@5 97.000 (98.160)\n",
            "Test: [240/261]\tTime 0.030 (0.025)\tLoss 0.8282 (0.7400)\tPrec@1 86.000 (83.884)\tPrec@5 97.000 (98.154)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.5682 (0.7346)\tPrec@1 86.000 (83.952)\tPrec@5 100.000 (98.183)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3081 (0.7357)\tPrec@1 90.625 (83.943)\tPrec@5 96.875 (98.164)\n",
            "val Results: Prec@1 83.943 Prec@5 98.164 Loss 0.73568\n",
            "val Class Accuracy: [0.696,0.958,0.948,0.698,0.913,0.753,0.806,0.779,0.773,0.789]\n",
            "Best Prec@1: 85.552\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [92][0/66], lr: 0.01000\tTime 0.568 (0.568)\tData 0.488 (0.488)\tLoss 0.0387 (0.0387)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [92][10/66], lr: 0.01000\tTime 0.117 (0.144)\tData 0.000 (0.048)\tLoss 0.1103 (0.0631)\tPrec@1 97.266 (97.692)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [92][20/66], lr: 0.01000\tTime 0.105 (0.120)\tData 0.000 (0.027)\tLoss 0.0567 (0.0657)\tPrec@1 98.438 (97.656)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [92][30/66], lr: 0.01000\tTime 0.085 (0.112)\tData 0.000 (0.019)\tLoss 0.0596 (0.0686)\tPrec@1 98.047 (97.555)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [92][40/66], lr: 0.01000\tTime 0.078 (0.107)\tData 0.001 (0.016)\tLoss 0.0672 (0.0687)\tPrec@1 98.047 (97.694)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [92][50/66], lr: 0.01000\tTime 0.074 (0.104)\tData 0.000 (0.014)\tLoss 0.0250 (0.0651)\tPrec@1 99.219 (97.794)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [92][60/66], lr: 0.01000\tTime 0.069 (0.101)\tData 0.000 (0.012)\tLoss 0.0470 (0.0633)\tPrec@1 98.828 (97.842)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.234 (0.234)\tLoss 0.6444 (0.6444)\tPrec@1 86.000 (86.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.027 (0.045)\tLoss 1.1772 (0.7341)\tPrec@1 78.000 (83.636)\tPrec@5 97.000 (98.091)\n",
            "Test: [20/261]\tTime 0.047 (0.036)\tLoss 0.8831 (0.6830)\tPrec@1 80.000 (84.476)\tPrec@5 98.000 (98.190)\n",
            "Test: [30/261]\tTime 0.027 (0.032)\tLoss 0.6275 (0.6169)\tPrec@1 82.000 (85.387)\tPrec@5 99.000 (98.516)\n",
            "Test: [40/261]\tTime 0.015 (0.030)\tLoss 0.6412 (0.6048)\tPrec@1 87.000 (85.561)\tPrec@5 98.000 (98.585)\n",
            "Test: [50/261]\tTime 0.030 (0.029)\tLoss 0.5334 (0.6044)\tPrec@1 86.000 (85.510)\tPrec@5 99.000 (98.627)\n",
            "Test: [60/261]\tTime 0.019 (0.028)\tLoss 0.5000 (0.5979)\tPrec@1 90.000 (85.672)\tPrec@5 98.000 (98.607)\n",
            "Test: [70/261]\tTime 0.023 (0.028)\tLoss 0.6047 (0.5951)\tPrec@1 86.000 (85.930)\tPrec@5 100.000 (98.634)\n",
            "Test: [80/261]\tTime 0.017 (0.027)\tLoss 0.5515 (0.5946)\tPrec@1 88.000 (85.914)\tPrec@5 99.000 (98.654)\n",
            "Test: [90/261]\tTime 0.036 (0.027)\tLoss 0.6640 (0.6149)\tPrec@1 85.000 (85.725)\tPrec@5 96.000 (98.549)\n",
            "Test: [100/261]\tTime 0.024 (0.026)\tLoss 0.7874 (0.6111)\tPrec@1 85.000 (85.703)\tPrec@5 98.000 (98.515)\n",
            "Test: [110/261]\tTime 0.026 (0.026)\tLoss 0.5557 (0.6060)\tPrec@1 87.000 (85.757)\tPrec@5 99.000 (98.577)\n",
            "Test: [120/261]\tTime 0.020 (0.026)\tLoss 0.6139 (0.6068)\tPrec@1 89.000 (85.802)\tPrec@5 97.000 (98.562)\n",
            "Test: [130/261]\tTime 0.026 (0.026)\tLoss 0.6717 (0.6110)\tPrec@1 81.000 (85.702)\tPrec@5 100.000 (98.565)\n",
            "Test: [140/261]\tTime 0.017 (0.025)\tLoss 0.5375 (0.6068)\tPrec@1 85.000 (85.667)\tPrec@5 99.000 (98.553)\n",
            "Test: [150/261]\tTime 0.021 (0.025)\tLoss 0.4554 (0.6082)\tPrec@1 88.000 (85.669)\tPrec@5 98.000 (98.543)\n",
            "Test: [160/261]\tTime 0.011 (0.025)\tLoss 0.2576 (0.6083)\tPrec@1 92.000 (85.702)\tPrec@5 100.000 (98.540)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.5486 (0.6050)\tPrec@1 89.000 (85.760)\tPrec@5 99.000 (98.561)\n",
            "Test: [180/261]\tTime 0.010 (0.025)\tLoss 0.5827 (0.6069)\tPrec@1 85.000 (85.718)\tPrec@5 95.000 (98.541)\n",
            "Test: [190/261]\tTime 0.012 (0.025)\tLoss 0.4987 (0.6071)\tPrec@1 88.000 (85.723)\tPrec@5 99.000 (98.560)\n",
            "Test: [200/261]\tTime 0.036 (0.025)\tLoss 0.6548 (0.6056)\tPrec@1 87.000 (85.741)\tPrec@5 98.000 (98.567)\n",
            "Test: [210/261]\tTime 0.032 (0.025)\tLoss 0.7583 (0.6091)\tPrec@1 84.000 (85.739)\tPrec@5 97.000 (98.536)\n",
            "Test: [220/261]\tTime 0.019 (0.025)\tLoss 0.6716 (0.6045)\tPrec@1 84.000 (85.747)\tPrec@5 100.000 (98.566)\n",
            "Test: [230/261]\tTime 0.022 (0.025)\tLoss 0.7857 (0.6055)\tPrec@1 82.000 (85.719)\tPrec@5 96.000 (98.532)\n",
            "Test: [240/261]\tTime 0.051 (0.025)\tLoss 0.5819 (0.6089)\tPrec@1 88.000 (85.689)\tPrec@5 98.000 (98.510)\n",
            "Test: [250/261]\tTime 0.013 (0.025)\tLoss 0.3496 (0.6042)\tPrec@1 87.000 (85.789)\tPrec@5 100.000 (98.518)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.1743 (0.6046)\tPrec@1 93.750 (85.787)\tPrec@5 100.000 (98.502)\n",
            "val Results: Prec@1 85.787 Prec@5 98.502 Loss 0.60461\n",
            "val Class Accuracy: [0.762,0.985,0.938,0.837,0.834,0.811,0.794,0.835,0.739,0.726]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [93][0/66], lr: 0.01000\tTime 0.601 (0.601)\tData 0.504 (0.504)\tLoss 0.0544 (0.0544)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][10/66], lr: 0.01000\tTime 0.072 (0.138)\tData 0.000 (0.050)\tLoss 0.0668 (0.0554)\tPrec@1 98.438 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][20/66], lr: 0.01000\tTime 0.096 (0.117)\tData 0.000 (0.028)\tLoss 0.0523 (0.0614)\tPrec@1 98.438 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][30/66], lr: 0.01000\tTime 0.102 (0.110)\tData 0.000 (0.021)\tLoss 0.0788 (0.0583)\tPrec@1 97.656 (98.248)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [93][40/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.000 (0.017)\tLoss 0.0334 (0.0578)\tPrec@1 98.828 (98.237)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [93][50/66], lr: 0.01000\tTime 0.102 (0.103)\tData 0.006 (0.015)\tLoss 0.0660 (0.0584)\tPrec@1 97.266 (98.208)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [93][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.013)\tLoss 0.0672 (0.0570)\tPrec@1 96.875 (98.201)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.231 (0.231)\tLoss 0.8166 (0.8166)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.025 (0.044)\tLoss 1.1800 (0.8585)\tPrec@1 82.000 (81.000)\tPrec@5 97.000 (97.182)\n",
            "Test: [20/261]\tTime 0.019 (0.035)\tLoss 0.9744 (0.8160)\tPrec@1 80.000 (81.857)\tPrec@5 97.000 (97.429)\n",
            "Test: [30/261]\tTime 0.033 (0.032)\tLoss 0.6924 (0.7896)\tPrec@1 83.000 (82.484)\tPrec@5 99.000 (97.774)\n",
            "Test: [40/261]\tTime 0.041 (0.030)\tLoss 0.7067 (0.7714)\tPrec@1 82.000 (82.902)\tPrec@5 99.000 (98.000)\n",
            "Test: [50/261]\tTime 0.037 (0.029)\tLoss 0.6682 (0.7765)\tPrec@1 83.000 (82.745)\tPrec@5 98.000 (98.000)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 0.8160 (0.7793)\tPrec@1 80.000 (82.656)\tPrec@5 99.000 (97.918)\n",
            "Test: [70/261]\tTime 0.034 (0.028)\tLoss 0.8333 (0.7837)\tPrec@1 76.000 (82.563)\tPrec@5 96.000 (97.873)\n",
            "Test: [80/261]\tTime 0.022 (0.027)\tLoss 0.7514 (0.7881)\tPrec@1 81.000 (82.407)\tPrec@5 99.000 (97.926)\n",
            "Test: [90/261]\tTime 0.012 (0.027)\tLoss 0.7322 (0.8129)\tPrec@1 79.000 (82.187)\tPrec@5 96.000 (97.802)\n",
            "Test: [100/261]\tTime 0.022 (0.027)\tLoss 0.9101 (0.8068)\tPrec@1 82.000 (82.317)\tPrec@5 98.000 (97.762)\n",
            "Test: [110/261]\tTime 0.016 (0.026)\tLoss 0.8548 (0.7961)\tPrec@1 82.000 (82.396)\tPrec@5 96.000 (97.766)\n",
            "Test: [120/261]\tTime 0.019 (0.026)\tLoss 0.7998 (0.8012)\tPrec@1 84.000 (82.248)\tPrec@5 96.000 (97.760)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.9963 (0.8072)\tPrec@1 78.000 (82.176)\tPrec@5 97.000 (97.733)\n",
            "Test: [140/261]\tTime 0.024 (0.026)\tLoss 0.9133 (0.8022)\tPrec@1 80.000 (82.234)\tPrec@5 97.000 (97.752)\n",
            "Test: [150/261]\tTime 0.045 (0.026)\tLoss 0.7032 (0.8055)\tPrec@1 80.000 (82.166)\tPrec@5 97.000 (97.689)\n",
            "Test: [160/261]\tTime 0.038 (0.026)\tLoss 0.5483 (0.8051)\tPrec@1 87.000 (82.199)\tPrec@5 100.000 (97.727)\n",
            "Test: [170/261]\tTime 0.020 (0.025)\tLoss 0.5842 (0.7967)\tPrec@1 86.000 (82.351)\tPrec@5 97.000 (97.760)\n",
            "Test: [180/261]\tTime 0.017 (0.025)\tLoss 0.6088 (0.7964)\tPrec@1 85.000 (82.354)\tPrec@5 97.000 (97.746)\n",
            "Test: [190/261]\tTime 0.023 (0.025)\tLoss 0.5514 (0.7928)\tPrec@1 84.000 (82.398)\tPrec@5 98.000 (97.754)\n",
            "Test: [200/261]\tTime 0.012 (0.025)\tLoss 0.7107 (0.7911)\tPrec@1 82.000 (82.323)\tPrec@5 97.000 (97.771)\n",
            "Test: [210/261]\tTime 0.014 (0.025)\tLoss 0.8369 (0.7936)\tPrec@1 79.000 (82.256)\tPrec@5 98.000 (97.777)\n",
            "Test: [220/261]\tTime 0.024 (0.025)\tLoss 0.8863 (0.7918)\tPrec@1 81.000 (82.244)\tPrec@5 97.000 (97.796)\n",
            "Test: [230/261]\tTime 0.025 (0.025)\tLoss 0.8331 (0.7940)\tPrec@1 81.000 (82.173)\tPrec@5 96.000 (97.788)\n",
            "Test: [240/261]\tTime 0.021 (0.025)\tLoss 0.8897 (0.7974)\tPrec@1 82.000 (82.154)\tPrec@5 97.000 (97.763)\n",
            "Test: [250/261]\tTime 0.025 (0.025)\tLoss 0.5789 (0.7935)\tPrec@1 85.000 (82.215)\tPrec@5 100.000 (97.769)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3612 (0.7964)\tPrec@1 93.750 (82.199)\tPrec@5 96.875 (97.745)\n",
            "val Results: Prec@1 82.199 Prec@5 97.745 Loss 0.79637\n",
            "val Class Accuracy: [0.479,0.961,0.879,0.800,0.867,0.813,0.816,0.758,0.756,0.743]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [94][0/66], lr: 0.01000\tTime 0.591 (0.591)\tData 0.500 (0.500)\tLoss 0.0391 (0.0391)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][10/66], lr: 0.01000\tTime 0.098 (0.136)\tData 0.004 (0.055)\tLoss 0.0918 (0.0651)\tPrec@1 96.875 (97.763)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [94][20/66], lr: 0.01000\tTime 0.074 (0.116)\tData 0.000 (0.032)\tLoss 0.0500 (0.0638)\tPrec@1 98.828 (97.879)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [94][30/66], lr: 0.01000\tTime 0.090 (0.109)\tData 0.006 (0.025)\tLoss 0.0936 (0.0616)\tPrec@1 96.875 (97.959)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [94][40/66], lr: 0.01000\tTime 0.086 (0.105)\tData 0.004 (0.020)\tLoss 0.0384 (0.0619)\tPrec@1 99.219 (97.980)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [94][50/66], lr: 0.01000\tTime 0.088 (0.102)\tData 0.005 (0.018)\tLoss 0.0282 (0.0600)\tPrec@1 99.219 (98.062)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [94][60/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.016)\tLoss 0.0441 (0.0606)\tPrec@1 98.438 (98.034)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.258 (0.258)\tLoss 0.7894 (0.7894)\tPrec@1 80.000 (80.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.036 (0.049)\tLoss 1.0543 (0.8490)\tPrec@1 77.000 (81.364)\tPrec@5 97.000 (98.091)\n",
            "Test: [20/261]\tTime 0.015 (0.036)\tLoss 0.9966 (0.8308)\tPrec@1 79.000 (81.095)\tPrec@5 97.000 (98.095)\n",
            "Test: [30/261]\tTime 0.026 (0.032)\tLoss 0.6572 (0.8003)\tPrec@1 87.000 (81.935)\tPrec@5 98.000 (98.226)\n",
            "Test: [40/261]\tTime 0.022 (0.031)\tLoss 0.6334 (0.7772)\tPrec@1 82.000 (82.317)\tPrec@5 98.000 (98.293)\n",
            "Test: [50/261]\tTime 0.009 (0.029)\tLoss 0.8470 (0.7865)\tPrec@1 78.000 (82.235)\tPrec@5 98.000 (98.255)\n",
            "Test: [60/261]\tTime 0.024 (0.028)\tLoss 0.5355 (0.7808)\tPrec@1 89.000 (82.410)\tPrec@5 98.000 (98.213)\n",
            "Test: [70/261]\tTime 0.030 (0.028)\tLoss 0.6641 (0.7716)\tPrec@1 83.000 (82.592)\tPrec@5 99.000 (98.268)\n",
            "Test: [80/261]\tTime 0.017 (0.027)\tLoss 0.6608 (0.7723)\tPrec@1 86.000 (82.506)\tPrec@5 96.000 (98.222)\n",
            "Test: [90/261]\tTime 0.028 (0.027)\tLoss 0.7224 (0.7925)\tPrec@1 85.000 (82.429)\tPrec@5 96.000 (98.088)\n",
            "Test: [100/261]\tTime 0.032 (0.027)\tLoss 1.0119 (0.7881)\tPrec@1 82.000 (82.495)\tPrec@5 96.000 (98.079)\n",
            "Test: [110/261]\tTime 0.015 (0.026)\tLoss 0.6347 (0.7841)\tPrec@1 85.000 (82.486)\tPrec@5 99.000 (98.117)\n",
            "Test: [120/261]\tTime 0.047 (0.026)\tLoss 0.6129 (0.7780)\tPrec@1 89.000 (82.587)\tPrec@5 99.000 (98.107)\n",
            "Test: [130/261]\tTime 0.018 (0.026)\tLoss 0.7201 (0.7780)\tPrec@1 80.000 (82.527)\tPrec@5 96.000 (98.053)\n",
            "Test: [140/261]\tTime 0.015 (0.026)\tLoss 1.0374 (0.7740)\tPrec@1 80.000 (82.596)\tPrec@5 97.000 (98.035)\n",
            "Test: [150/261]\tTime 0.018 (0.025)\tLoss 0.7162 (0.7765)\tPrec@1 85.000 (82.570)\tPrec@5 98.000 (98.040)\n",
            "Test: [160/261]\tTime 0.022 (0.025)\tLoss 0.4546 (0.7758)\tPrec@1 89.000 (82.615)\tPrec@5 100.000 (98.062)\n",
            "Test: [170/261]\tTime 0.020 (0.026)\tLoss 0.6469 (0.7726)\tPrec@1 84.000 (82.643)\tPrec@5 99.000 (98.058)\n",
            "Test: [180/261]\tTime 0.017 (0.025)\tLoss 0.8970 (0.7754)\tPrec@1 82.000 (82.619)\tPrec@5 95.000 (98.044)\n",
            "Test: [190/261]\tTime 0.015 (0.025)\tLoss 0.6522 (0.7736)\tPrec@1 87.000 (82.654)\tPrec@5 98.000 (98.058)\n",
            "Test: [200/261]\tTime 0.035 (0.025)\tLoss 0.7639 (0.7688)\tPrec@1 83.000 (82.657)\tPrec@5 97.000 (98.050)\n",
            "Test: [210/261]\tTime 0.015 (0.025)\tLoss 0.5260 (0.7673)\tPrec@1 79.000 (82.682)\tPrec@5 99.000 (98.038)\n",
            "Test: [220/261]\tTime 0.020 (0.025)\tLoss 0.6804 (0.7642)\tPrec@1 80.000 (82.665)\tPrec@5 98.000 (98.086)\n",
            "Test: [230/261]\tTime 0.028 (0.025)\tLoss 0.6230 (0.7660)\tPrec@1 83.000 (82.649)\tPrec@5 97.000 (98.065)\n",
            "Test: [240/261]\tTime 0.026 (0.025)\tLoss 0.6461 (0.7687)\tPrec@1 85.000 (82.656)\tPrec@5 98.000 (98.033)\n",
            "Test: [250/261]\tTime 0.017 (0.025)\tLoss 0.7115 (0.7649)\tPrec@1 84.000 (82.725)\tPrec@5 99.000 (98.060)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3278 (0.7660)\tPrec@1 93.750 (82.729)\tPrec@5 96.875 (98.029)\n",
            "val Results: Prec@1 82.729 Prec@5 98.029 Loss 0.76605\n",
            "val Class Accuracy: [0.624,0.950,0.852,0.859,0.899,0.869,0.679,0.804,0.760,0.643]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [95][0/66], lr: 0.01000\tTime 0.547 (0.547)\tData 0.470 (0.470)\tLoss 0.0337 (0.0337)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][10/66], lr: 0.01000\tTime 0.082 (0.139)\tData 0.000 (0.050)\tLoss 0.0267 (0.0442)\tPrec@1 99.609 (98.509)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][20/66], lr: 0.01000\tTime 0.093 (0.118)\tData 0.000 (0.029)\tLoss 0.0471 (0.0497)\tPrec@1 98.047 (98.214)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][30/66], lr: 0.01000\tTime 0.081 (0.110)\tData 0.005 (0.022)\tLoss 0.0235 (0.0505)\tPrec@1 99.219 (98.211)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][40/66], lr: 0.01000\tTime 0.094 (0.106)\tData 0.002 (0.019)\tLoss 0.0659 (0.0526)\tPrec@1 98.047 (98.114)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][50/66], lr: 0.01000\tTime 0.081 (0.102)\tData 0.006 (0.016)\tLoss 0.0551 (0.0530)\tPrec@1 98.047 (98.055)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [95][60/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.014)\tLoss 0.0831 (0.0542)\tPrec@1 97.266 (98.015)\tPrec@5 99.609 (99.987)\n",
            "Test: [0/261]\tTime 0.278 (0.278)\tLoss 0.7175 (0.7175)\tPrec@1 86.000 (86.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.025 (0.054)\tLoss 0.9226 (0.7337)\tPrec@1 84.000 (83.909)\tPrec@5 99.000 (97.455)\n",
            "Test: [20/261]\tTime 0.014 (0.038)\tLoss 1.0544 (0.7406)\tPrec@1 81.000 (84.190)\tPrec@5 96.000 (97.524)\n",
            "Test: [30/261]\tTime 0.022 (0.035)\tLoss 0.6591 (0.7148)\tPrec@1 86.000 (84.968)\tPrec@5 99.000 (97.903)\n",
            "Test: [40/261]\tTime 0.022 (0.032)\tLoss 0.5499 (0.7065)\tPrec@1 85.000 (85.098)\tPrec@5 98.000 (98.024)\n",
            "Test: [50/261]\tTime 0.012 (0.031)\tLoss 0.5301 (0.6988)\tPrec@1 88.000 (85.294)\tPrec@5 100.000 (98.059)\n",
            "Test: [60/261]\tTime 0.028 (0.029)\tLoss 0.6397 (0.7024)\tPrec@1 88.000 (85.164)\tPrec@5 98.000 (97.951)\n",
            "Test: [70/261]\tTime 0.023 (0.029)\tLoss 0.6081 (0.7002)\tPrec@1 84.000 (85.113)\tPrec@5 98.000 (97.986)\n",
            "Test: [80/261]\tTime 0.009 (0.027)\tLoss 0.5957 (0.7020)\tPrec@1 85.000 (85.037)\tPrec@5 99.000 (98.062)\n",
            "Test: [90/261]\tTime 0.025 (0.027)\tLoss 0.6284 (0.7246)\tPrec@1 88.000 (84.835)\tPrec@5 98.000 (98.000)\n",
            "Test: [100/261]\tTime 0.035 (0.028)\tLoss 0.9997 (0.7207)\tPrec@1 79.000 (84.881)\tPrec@5 97.000 (97.990)\n",
            "Test: [110/261]\tTime 0.022 (0.027)\tLoss 0.5677 (0.7132)\tPrec@1 89.000 (84.901)\tPrec@5 98.000 (98.036)\n",
            "Test: [120/261]\tTime 0.010 (0.027)\tLoss 0.6948 (0.7122)\tPrec@1 87.000 (84.926)\tPrec@5 97.000 (98.008)\n",
            "Test: [130/261]\tTime 0.026 (0.027)\tLoss 0.7242 (0.7136)\tPrec@1 85.000 (84.939)\tPrec@5 98.000 (97.985)\n",
            "Test: [140/261]\tTime 0.015 (0.027)\tLoss 0.7388 (0.7128)\tPrec@1 83.000 (84.915)\tPrec@5 99.000 (97.972)\n",
            "Test: [150/261]\tTime 0.027 (0.026)\tLoss 0.5132 (0.7149)\tPrec@1 88.000 (84.914)\tPrec@5 98.000 (97.974)\n",
            "Test: [160/261]\tTime 0.017 (0.026)\tLoss 0.4783 (0.7191)\tPrec@1 84.000 (84.826)\tPrec@5 100.000 (97.950)\n",
            "Test: [170/261]\tTime 0.021 (0.026)\tLoss 0.6101 (0.7145)\tPrec@1 89.000 (84.906)\tPrec@5 97.000 (97.953)\n",
            "Test: [180/261]\tTime 0.018 (0.026)\tLoss 0.5629 (0.7136)\tPrec@1 87.000 (84.912)\tPrec@5 95.000 (97.961)\n",
            "Test: [190/261]\tTime 0.041 (0.026)\tLoss 0.3619 (0.7129)\tPrec@1 88.000 (84.921)\tPrec@5 100.000 (97.995)\n",
            "Test: [200/261]\tTime 0.016 (0.026)\tLoss 0.6526 (0.7124)\tPrec@1 88.000 (84.915)\tPrec@5 97.000 (97.980)\n",
            "Test: [210/261]\tTime 0.023 (0.026)\tLoss 0.7259 (0.7094)\tPrec@1 85.000 (85.043)\tPrec@5 98.000 (97.981)\n",
            "Test: [220/261]\tTime 0.017 (0.025)\tLoss 0.7639 (0.7050)\tPrec@1 84.000 (85.050)\tPrec@5 97.000 (98.005)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.7597 (0.7066)\tPrec@1 83.000 (85.017)\tPrec@5 97.000 (98.013)\n",
            "Test: [240/261]\tTime 0.032 (0.025)\tLoss 0.7997 (0.7090)\tPrec@1 81.000 (85.008)\tPrec@5 99.000 (98.017)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.4449 (0.7058)\tPrec@1 87.000 (85.032)\tPrec@5 100.000 (98.020)\n",
            "Test: [260/261]\tTime 0.006 (0.025)\tLoss 0.4224 (0.7054)\tPrec@1 90.625 (85.049)\tPrec@5 96.875 (97.995)\n",
            "val Results: Prec@1 85.049 Prec@5 97.995 Loss 0.70536\n",
            "val Class Accuracy: [0.532,0.948,0.911,0.811,0.919,0.859,0.796,0.814,0.803,0.845]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [96][0/66], lr: 0.01000\tTime 0.586 (0.586)\tData 0.486 (0.486)\tLoss 0.0415 (0.0415)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][10/66], lr: 0.01000\tTime 0.079 (0.138)\tData 0.004 (0.050)\tLoss 0.0335 (0.0560)\tPrec@1 99.219 (97.976)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][20/66], lr: 0.01000\tTime 0.077 (0.115)\tData 0.000 (0.028)\tLoss 0.1249 (0.0622)\tPrec@1 96.484 (97.861)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][30/66], lr: 0.01000\tTime 0.084 (0.107)\tData 0.008 (0.021)\tLoss 0.0304 (0.0591)\tPrec@1 99.219 (97.971)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][40/66], lr: 0.01000\tTime 0.082 (0.104)\tData 0.000 (0.018)\tLoss 0.0449 (0.0595)\tPrec@1 98.047 (97.933)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][50/66], lr: 0.01000\tTime 0.094 (0.101)\tData 0.000 (0.015)\tLoss 0.0529 (0.0607)\tPrec@1 98.438 (97.917)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [96][60/66], lr: 0.01000\tTime 0.068 (0.098)\tData 0.000 (0.013)\tLoss 0.0601 (0.0606)\tPrec@1 97.656 (97.944)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.239 (0.239)\tLoss 0.6733 (0.6733)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.036 (0.051)\tLoss 1.1200 (0.9164)\tPrec@1 79.000 (79.182)\tPrec@5 98.000 (97.909)\n",
            "Test: [20/261]\tTime 0.035 (0.037)\tLoss 1.0620 (0.9059)\tPrec@1 82.000 (80.524)\tPrec@5 98.000 (97.762)\n",
            "Test: [30/261]\tTime 0.017 (0.033)\tLoss 0.8729 (0.8634)\tPrec@1 83.000 (81.484)\tPrec@5 97.000 (98.000)\n",
            "Test: [40/261]\tTime 0.024 (0.031)\tLoss 0.6710 (0.8383)\tPrec@1 85.000 (81.829)\tPrec@5 98.000 (98.000)\n",
            "Test: [50/261]\tTime 0.021 (0.030)\tLoss 0.8295 (0.8313)\tPrec@1 80.000 (81.863)\tPrec@5 98.000 (98.059)\n",
            "Test: [60/261]\tTime 0.016 (0.029)\tLoss 0.8281 (0.8316)\tPrec@1 81.000 (81.951)\tPrec@5 99.000 (98.033)\n",
            "Test: [70/261]\tTime 0.010 (0.028)\tLoss 0.9058 (0.8288)\tPrec@1 81.000 (82.183)\tPrec@5 96.000 (97.972)\n",
            "Test: [80/261]\tTime 0.012 (0.027)\tLoss 0.9247 (0.8352)\tPrec@1 83.000 (82.160)\tPrec@5 98.000 (98.012)\n",
            "Test: [90/261]\tTime 0.017 (0.027)\tLoss 0.7067 (0.8510)\tPrec@1 84.000 (82.132)\tPrec@5 96.000 (97.912)\n",
            "Test: [100/261]\tTime 0.039 (0.027)\tLoss 0.9188 (0.8502)\tPrec@1 81.000 (82.208)\tPrec@5 96.000 (97.861)\n",
            "Test: [110/261]\tTime 0.020 (0.026)\tLoss 0.9514 (0.8443)\tPrec@1 79.000 (82.135)\tPrec@5 98.000 (97.883)\n",
            "Test: [120/261]\tTime 0.025 (0.027)\tLoss 0.7897 (0.8462)\tPrec@1 86.000 (82.174)\tPrec@5 97.000 (97.851)\n",
            "Test: [130/261]\tTime 0.035 (0.027)\tLoss 0.8711 (0.8480)\tPrec@1 83.000 (82.191)\tPrec@5 96.000 (97.756)\n",
            "Test: [140/261]\tTime 0.035 (0.027)\tLoss 1.0290 (0.8419)\tPrec@1 79.000 (82.227)\tPrec@5 97.000 (97.787)\n",
            "Test: [150/261]\tTime 0.017 (0.026)\tLoss 0.4982 (0.8432)\tPrec@1 92.000 (82.272)\tPrec@5 97.000 (97.795)\n",
            "Test: [160/261]\tTime 0.015 (0.026)\tLoss 0.4950 (0.8436)\tPrec@1 87.000 (82.286)\tPrec@5 99.000 (97.801)\n",
            "Test: [170/261]\tTime 0.015 (0.026)\tLoss 0.7983 (0.8373)\tPrec@1 88.000 (82.433)\tPrec@5 97.000 (97.795)\n",
            "Test: [180/261]\tTime 0.026 (0.026)\tLoss 0.7204 (0.8368)\tPrec@1 85.000 (82.420)\tPrec@5 94.000 (97.768)\n",
            "Test: [190/261]\tTime 0.027 (0.026)\tLoss 0.7417 (0.8360)\tPrec@1 84.000 (82.482)\tPrec@5 99.000 (97.764)\n",
            "Test: [200/261]\tTime 0.029 (0.026)\tLoss 0.7599 (0.8349)\tPrec@1 85.000 (82.458)\tPrec@5 97.000 (97.746)\n",
            "Test: [210/261]\tTime 0.015 (0.026)\tLoss 0.5937 (0.8340)\tPrec@1 86.000 (82.502)\tPrec@5 98.000 (97.739)\n",
            "Test: [220/261]\tTime 0.010 (0.025)\tLoss 0.8159 (0.8304)\tPrec@1 82.000 (82.516)\tPrec@5 97.000 (97.760)\n",
            "Test: [230/261]\tTime 0.024 (0.026)\tLoss 1.0795 (0.8341)\tPrec@1 75.000 (82.437)\tPrec@5 96.000 (97.732)\n",
            "Test: [240/261]\tTime 0.036 (0.026)\tLoss 0.6614 (0.8351)\tPrec@1 85.000 (82.402)\tPrec@5 99.000 (97.730)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.5755 (0.8299)\tPrec@1 83.000 (82.482)\tPrec@5 100.000 (97.765)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.8204 (0.8342)\tPrec@1 84.375 (82.468)\tPrec@5 96.875 (97.726)\n",
            "val Results: Prec@1 82.468 Prec@5 97.726 Loss 0.83418\n",
            "val Class Accuracy: [0.570,0.935,0.914,0.832,0.946,0.792,0.768,0.776,0.741,0.579]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [97][0/66], lr: 0.01000\tTime 0.557 (0.557)\tData 0.475 (0.475)\tLoss 0.0341 (0.0341)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][10/66], lr: 0.01000\tTime 0.068 (0.143)\tData 0.000 (0.048)\tLoss 0.0756 (0.0550)\tPrec@1 97.266 (98.118)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][20/66], lr: 0.01000\tTime 0.105 (0.120)\tData 0.000 (0.028)\tLoss 0.0718 (0.0547)\tPrec@1 97.656 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][30/66], lr: 0.01000\tTime 0.075 (0.110)\tData 0.000 (0.021)\tLoss 0.0154 (0.0540)\tPrec@1 100.000 (98.160)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][40/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.009 (0.019)\tLoss 0.0738 (0.0543)\tPrec@1 97.266 (98.161)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][50/66], lr: 0.01000\tTime 0.080 (0.103)\tData 0.000 (0.016)\tLoss 0.0545 (0.0535)\tPrec@1 98.438 (98.192)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][60/66], lr: 0.01000\tTime 0.080 (0.101)\tData 0.000 (0.014)\tLoss 0.0464 (0.0540)\tPrec@1 98.047 (98.137)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.294 (0.294)\tLoss 0.9205 (0.9205)\tPrec@1 81.000 (81.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.031 (0.046)\tLoss 1.0946 (0.8793)\tPrec@1 78.000 (81.091)\tPrec@5 99.000 (97.909)\n",
            "Test: [20/261]\tTime 0.026 (0.036)\tLoss 1.2270 (0.8504)\tPrec@1 79.000 (81.381)\tPrec@5 96.000 (97.857)\n",
            "Test: [30/261]\tTime 0.019 (0.032)\tLoss 0.6205 (0.8072)\tPrec@1 85.000 (82.097)\tPrec@5 99.000 (98.097)\n",
            "Test: [40/261]\tTime 0.026 (0.029)\tLoss 0.6244 (0.7803)\tPrec@1 88.000 (82.659)\tPrec@5 98.000 (98.195)\n",
            "Test: [50/261]\tTime 0.017 (0.029)\tLoss 0.6328 (0.7720)\tPrec@1 84.000 (82.725)\tPrec@5 98.000 (98.196)\n",
            "Test: [60/261]\tTime 0.028 (0.028)\tLoss 0.5914 (0.7776)\tPrec@1 82.000 (82.689)\tPrec@5 99.000 (98.148)\n",
            "Test: [70/261]\tTime 0.037 (0.027)\tLoss 0.7481 (0.7817)\tPrec@1 84.000 (82.803)\tPrec@5 98.000 (98.197)\n",
            "Test: [80/261]\tTime 0.030 (0.027)\tLoss 0.7461 (0.7869)\tPrec@1 79.000 (82.753)\tPrec@5 98.000 (98.185)\n",
            "Test: [90/261]\tTime 0.026 (0.027)\tLoss 0.9141 (0.8138)\tPrec@1 85.000 (82.527)\tPrec@5 96.000 (98.055)\n",
            "Test: [100/261]\tTime 0.027 (0.026)\tLoss 0.8611 (0.8093)\tPrec@1 79.000 (82.634)\tPrec@5 96.000 (98.099)\n",
            "Test: [110/261]\tTime 0.029 (0.026)\tLoss 0.9196 (0.8051)\tPrec@1 82.000 (82.667)\tPrec@5 98.000 (98.153)\n",
            "Test: [120/261]\tTime 0.027 (0.026)\tLoss 0.7207 (0.8099)\tPrec@1 87.000 (82.603)\tPrec@5 98.000 (98.124)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8478 (0.8093)\tPrec@1 81.000 (82.634)\tPrec@5 97.000 (98.076)\n",
            "Test: [140/261]\tTime 0.031 (0.026)\tLoss 1.0634 (0.8110)\tPrec@1 72.000 (82.525)\tPrec@5 99.000 (98.106)\n",
            "Test: [150/261]\tTime 0.026 (0.025)\tLoss 0.6524 (0.8146)\tPrec@1 81.000 (82.523)\tPrec@5 97.000 (98.066)\n",
            "Test: [160/261]\tTime 0.020 (0.025)\tLoss 0.6043 (0.8118)\tPrec@1 85.000 (82.571)\tPrec@5 99.000 (98.075)\n",
            "Test: [170/261]\tTime 0.037 (0.025)\tLoss 0.6336 (0.8076)\tPrec@1 87.000 (82.614)\tPrec@5 98.000 (98.099)\n",
            "Test: [180/261]\tTime 0.021 (0.025)\tLoss 0.7206 (0.8088)\tPrec@1 85.000 (82.597)\tPrec@5 98.000 (98.099)\n",
            "Test: [190/261]\tTime 0.020 (0.025)\tLoss 0.6323 (0.8034)\tPrec@1 85.000 (82.681)\tPrec@5 100.000 (98.152)\n",
            "Test: [200/261]\tTime 0.019 (0.025)\tLoss 0.6784 (0.8024)\tPrec@1 83.000 (82.627)\tPrec@5 98.000 (98.119)\n",
            "Test: [210/261]\tTime 0.023 (0.025)\tLoss 0.5372 (0.8014)\tPrec@1 85.000 (82.664)\tPrec@5 99.000 (98.123)\n",
            "Test: [220/261]\tTime 0.016 (0.025)\tLoss 0.8476 (0.7999)\tPrec@1 77.000 (82.575)\tPrec@5 99.000 (98.149)\n",
            "Test: [230/261]\tTime 0.023 (0.025)\tLoss 1.0778 (0.8021)\tPrec@1 80.000 (82.545)\tPrec@5 95.000 (98.143)\n",
            "Test: [240/261]\tTime 0.025 (0.025)\tLoss 0.9202 (0.8063)\tPrec@1 82.000 (82.548)\tPrec@5 98.000 (98.116)\n",
            "Test: [250/261]\tTime 0.027 (0.025)\tLoss 0.7596 (0.8030)\tPrec@1 83.000 (82.562)\tPrec@5 100.000 (98.139)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.5996 (0.8054)\tPrec@1 87.500 (82.568)\tPrec@5 96.875 (98.110)\n",
            "val Results: Prec@1 82.568 Prec@5 98.110 Loss 0.80539\n",
            "val Class Accuracy: [0.622,0.982,0.910,0.877,0.843,0.809,0.732,0.704,0.631,0.707]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/66], lr: 0.01000\tTime 0.582 (0.582)\tData 0.495 (0.495)\tLoss 0.0592 (0.0592)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][10/66], lr: 0.01000\tTime 0.082 (0.138)\tData 0.009 (0.050)\tLoss 0.0511 (0.0440)\tPrec@1 98.438 (98.473)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][20/66], lr: 0.01000\tTime 0.100 (0.117)\tData 0.009 (0.033)\tLoss 0.0626 (0.0496)\tPrec@1 98.047 (98.419)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][30/66], lr: 0.01000\tTime 0.091 (0.108)\tData 0.014 (0.025)\tLoss 0.0531 (0.0505)\tPrec@1 98.047 (98.387)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][40/66], lr: 0.01000\tTime 0.095 (0.104)\tData 0.000 (0.020)\tLoss 0.0494 (0.0541)\tPrec@1 98.438 (98.228)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [98][50/66], lr: 0.01000\tTime 0.085 (0.102)\tData 0.003 (0.017)\tLoss 0.0671 (0.0549)\tPrec@1 98.047 (98.200)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [98][60/66], lr: 0.01000\tTime 0.070 (0.099)\tData 0.000 (0.015)\tLoss 0.0527 (0.0557)\tPrec@1 98.047 (98.213)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.223 (0.223)\tLoss 0.7211 (0.7211)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.021 (0.049)\tLoss 1.0343 (0.7774)\tPrec@1 81.000 (81.909)\tPrec@5 100.000 (98.091)\n",
            "Test: [20/261]\tTime 0.022 (0.036)\tLoss 0.7676 (0.7668)\tPrec@1 81.000 (82.571)\tPrec@5 98.000 (98.000)\n",
            "Test: [30/261]\tTime 0.016 (0.032)\tLoss 0.6392 (0.7390)\tPrec@1 82.000 (83.452)\tPrec@5 99.000 (98.290)\n",
            "Test: [40/261]\tTime 0.021 (0.030)\tLoss 0.6821 (0.7250)\tPrec@1 88.000 (83.634)\tPrec@5 98.000 (98.390)\n",
            "Test: [50/261]\tTime 0.025 (0.028)\tLoss 0.6086 (0.7071)\tPrec@1 85.000 (83.941)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.017 (0.027)\tLoss 0.7060 (0.7069)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.492)\n",
            "Test: [70/261]\tTime 0.036 (0.027)\tLoss 0.6281 (0.6991)\tPrec@1 82.000 (84.042)\tPrec@5 99.000 (98.507)\n",
            "Test: [80/261]\tTime 0.020 (0.027)\tLoss 0.6592 (0.6971)\tPrec@1 87.000 (84.148)\tPrec@5 99.000 (98.494)\n",
            "Test: [90/261]\tTime 0.039 (0.027)\tLoss 0.8272 (0.7201)\tPrec@1 84.000 (83.923)\tPrec@5 96.000 (98.330)\n",
            "Test: [100/261]\tTime 0.030 (0.026)\tLoss 0.9002 (0.7125)\tPrec@1 82.000 (84.010)\tPrec@5 96.000 (98.307)\n",
            "Test: [110/261]\tTime 0.023 (0.026)\tLoss 0.8774 (0.7070)\tPrec@1 83.000 (84.072)\tPrec@5 97.000 (98.333)\n",
            "Test: [120/261]\tTime 0.023 (0.026)\tLoss 0.6958 (0.7065)\tPrec@1 87.000 (84.132)\tPrec@5 96.000 (98.322)\n",
            "Test: [130/261]\tTime 0.011 (0.026)\tLoss 0.6374 (0.7051)\tPrec@1 82.000 (84.092)\tPrec@5 98.000 (98.282)\n",
            "Test: [140/261]\tTime 0.017 (0.025)\tLoss 0.5974 (0.6992)\tPrec@1 83.000 (84.142)\tPrec@5 100.000 (98.277)\n",
            "Test: [150/261]\tTime 0.026 (0.025)\tLoss 0.4222 (0.6996)\tPrec@1 90.000 (84.126)\tPrec@5 98.000 (98.258)\n",
            "Test: [160/261]\tTime 0.022 (0.025)\tLoss 0.3463 (0.6945)\tPrec@1 89.000 (84.205)\tPrec@5 100.000 (98.273)\n",
            "Test: [170/261]\tTime 0.028 (0.025)\tLoss 0.6053 (0.6929)\tPrec@1 88.000 (84.222)\tPrec@5 98.000 (98.298)\n",
            "Test: [180/261]\tTime 0.022 (0.025)\tLoss 0.5942 (0.6958)\tPrec@1 88.000 (84.177)\tPrec@5 97.000 (98.276)\n",
            "Test: [190/261]\tTime 0.031 (0.025)\tLoss 0.6701 (0.6941)\tPrec@1 84.000 (84.157)\tPrec@5 96.000 (98.283)\n",
            "Test: [200/261]\tTime 0.034 (0.025)\tLoss 0.8102 (0.6926)\tPrec@1 87.000 (84.169)\tPrec@5 96.000 (98.269)\n",
            "Test: [210/261]\tTime 0.022 (0.025)\tLoss 0.6681 (0.6952)\tPrec@1 87.000 (84.137)\tPrec@5 99.000 (98.256)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 0.5619 (0.6918)\tPrec@1 82.000 (84.068)\tPrec@5 98.000 (98.294)\n",
            "Test: [230/261]\tTime 0.025 (0.025)\tLoss 0.7897 (0.6936)\tPrec@1 81.000 (84.017)\tPrec@5 97.000 (98.264)\n",
            "Test: [240/261]\tTime 0.029 (0.025)\tLoss 0.5508 (0.6958)\tPrec@1 84.000 (84.004)\tPrec@5 98.000 (98.241)\n",
            "Test: [250/261]\tTime 0.042 (0.025)\tLoss 0.4314 (0.6929)\tPrec@1 85.000 (84.056)\tPrec@5 100.000 (98.247)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.1810 (0.6953)\tPrec@1 96.875 (83.997)\tPrec@5 100.000 (98.241)\n",
            "val Results: Prec@1 83.997 Prec@5 98.241 Loss 0.69534\n",
            "val Class Accuracy: [0.747,0.965,0.933,0.871,0.876,0.703,0.804,0.773,0.728,0.638]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/66], lr: 0.01000\tTime 0.618 (0.618)\tData 0.492 (0.492)\tLoss 0.0846 (0.0846)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][10/66], lr: 0.01000\tTime 0.111 (0.148)\tData 0.004 (0.053)\tLoss 0.0748 (0.0587)\tPrec@1 98.047 (97.976)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [99][20/66], lr: 0.01000\tTime 0.089 (0.123)\tData 0.005 (0.032)\tLoss 0.0536 (0.0538)\tPrec@1 98.438 (98.158)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [99][30/66], lr: 0.01000\tTime 0.101 (0.113)\tData 0.007 (0.024)\tLoss 0.0884 (0.0577)\tPrec@1 98.047 (98.034)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [99][40/66], lr: 0.01000\tTime 0.076 (0.107)\tData 0.000 (0.019)\tLoss 0.0549 (0.0560)\tPrec@1 97.656 (98.066)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [99][50/66], lr: 0.01000\tTime 0.105 (0.104)\tData 0.001 (0.017)\tLoss 0.0458 (0.0586)\tPrec@1 98.438 (98.016)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [99][60/66], lr: 0.01000\tTime 0.077 (0.101)\tData 0.000 (0.015)\tLoss 0.0501 (0.0576)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.284 (0.284)\tLoss 1.2003 (1.2003)\tPrec@1 79.000 (79.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.027 (0.049)\tLoss 1.6443 (1.0795)\tPrec@1 77.000 (78.909)\tPrec@5 98.000 (97.182)\n",
            "Test: [20/261]\tTime 0.031 (0.037)\tLoss 1.1935 (1.0233)\tPrec@1 79.000 (79.238)\tPrec@5 95.000 (97.238)\n",
            "Test: [30/261]\tTime 0.010 (0.030)\tLoss 0.7995 (0.9421)\tPrec@1 81.000 (80.032)\tPrec@5 98.000 (97.613)\n",
            "Test: [40/261]\tTime 0.026 (0.029)\tLoss 0.8164 (0.9256)\tPrec@1 83.000 (79.927)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/261]\tTime 0.021 (0.029)\tLoss 1.0885 (0.9284)\tPrec@1 77.000 (79.961)\tPrec@5 96.000 (97.706)\n",
            "Test: [60/261]\tTime 0.034 (0.028)\tLoss 0.7976 (0.9312)\tPrec@1 84.000 (80.016)\tPrec@5 99.000 (97.705)\n",
            "Test: [70/261]\tTime 0.028 (0.028)\tLoss 1.0538 (0.9385)\tPrec@1 76.000 (79.972)\tPrec@5 96.000 (97.732)\n",
            "Test: [80/261]\tTime 0.031 (0.027)\tLoss 1.3604 (0.9518)\tPrec@1 76.000 (79.951)\tPrec@5 97.000 (97.716)\n",
            "Test: [90/261]\tTime 0.015 (0.027)\tLoss 1.3174 (0.9773)\tPrec@1 76.000 (79.736)\tPrec@5 95.000 (97.615)\n",
            "Test: [100/261]\tTime 0.024 (0.026)\tLoss 1.0279 (0.9669)\tPrec@1 82.000 (79.990)\tPrec@5 96.000 (97.564)\n",
            "Test: [110/261]\tTime 0.025 (0.026)\tLoss 0.8933 (0.9617)\tPrec@1 80.000 (79.991)\tPrec@5 98.000 (97.586)\n",
            "Test: [120/261]\tTime 0.020 (0.026)\tLoss 1.1689 (0.9605)\tPrec@1 80.000 (80.083)\tPrec@5 96.000 (97.562)\n",
            "Test: [130/261]\tTime 0.019 (0.026)\tLoss 0.8770 (0.9658)\tPrec@1 79.000 (80.153)\tPrec@5 98.000 (97.519)\n",
            "Test: [140/261]\tTime 0.012 (0.026)\tLoss 1.2976 (0.9655)\tPrec@1 72.000 (80.170)\tPrec@5 96.000 (97.525)\n",
            "Test: [150/261]\tTime 0.035 (0.026)\tLoss 0.7414 (0.9652)\tPrec@1 85.000 (80.132)\tPrec@5 97.000 (97.490)\n",
            "Test: [160/261]\tTime 0.027 (0.025)\tLoss 0.7142 (0.9647)\tPrec@1 83.000 (80.161)\tPrec@5 98.000 (97.491)\n",
            "Test: [170/261]\tTime 0.024 (0.025)\tLoss 0.7444 (0.9611)\tPrec@1 84.000 (80.164)\tPrec@5 97.000 (97.462)\n",
            "Test: [180/261]\tTime 0.038 (0.025)\tLoss 1.2364 (0.9657)\tPrec@1 79.000 (80.083)\tPrec@5 96.000 (97.453)\n",
            "Test: [190/261]\tTime 0.033 (0.025)\tLoss 1.0830 (0.9642)\tPrec@1 80.000 (80.079)\tPrec@5 97.000 (97.497)\n",
            "Test: [200/261]\tTime 0.022 (0.025)\tLoss 1.1761 (0.9657)\tPrec@1 79.000 (80.104)\tPrec@5 97.000 (97.522)\n",
            "Test: [210/261]\tTime 0.035 (0.025)\tLoss 0.7088 (0.9624)\tPrec@1 90.000 (80.218)\tPrec@5 96.000 (97.498)\n",
            "Test: [220/261]\tTime 0.014 (0.025)\tLoss 0.9242 (0.9597)\tPrec@1 80.000 (80.222)\tPrec@5 98.000 (97.516)\n",
            "Test: [230/261]\tTime 0.026 (0.025)\tLoss 0.9748 (0.9609)\tPrec@1 78.000 (80.186)\tPrec@5 98.000 (97.498)\n",
            "Test: [240/261]\tTime 0.026 (0.025)\tLoss 0.7930 (0.9664)\tPrec@1 79.000 (80.095)\tPrec@5 98.000 (97.477)\n",
            "Test: [250/261]\tTime 0.024 (0.025)\tLoss 0.7551 (0.9596)\tPrec@1 81.000 (80.203)\tPrec@5 100.000 (97.490)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.1768 (0.9577)\tPrec@1 90.625 (80.220)\tPrec@5 100.000 (97.476)\n",
            "val Results: Prec@1 80.220 Prec@5 97.476 Loss 0.95768\n",
            "val Class Accuracy: [0.798,0.980,0.889,0.890,0.718,0.660,0.758,0.778,0.540,0.560]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [100][0/66], lr: 0.01000\tTime 0.471 (0.471)\tData 0.389 (0.389)\tLoss 0.0665 (0.0665)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][10/66], lr: 0.01000\tTime 0.092 (0.130)\tData 0.000 (0.042)\tLoss 0.0657 (0.0686)\tPrec@1 97.266 (97.372)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [100][20/66], lr: 0.01000\tTime 0.114 (0.113)\tData 0.045 (0.026)\tLoss 0.0613 (0.0670)\tPrec@1 98.438 (97.489)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [100][30/66], lr: 0.01000\tTime 0.109 (0.108)\tData 0.004 (0.021)\tLoss 0.0882 (0.0622)\tPrec@1 96.094 (97.618)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [100][40/66], lr: 0.01000\tTime 0.076 (0.105)\tData 0.005 (0.017)\tLoss 0.0943 (0.0614)\tPrec@1 97.656 (97.723)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [100][50/66], lr: 0.01000\tTime 0.089 (0.102)\tData 0.005 (0.015)\tLoss 0.0738 (0.0626)\tPrec@1 98.047 (97.664)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [100][60/66], lr: 0.01000\tTime 0.071 (0.100)\tData 0.000 (0.013)\tLoss 0.0605 (0.0635)\tPrec@1 98.047 (97.643)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/261]\tTime 0.243 (0.243)\tLoss 0.7600 (0.7600)\tPrec@1 85.000 (85.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.041 (0.049)\tLoss 0.9283 (0.7950)\tPrec@1 83.000 (82.273)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/261]\tTime 0.018 (0.036)\tLoss 1.1127 (0.8211)\tPrec@1 75.000 (81.476)\tPrec@5 97.000 (97.667)\n",
            "Test: [30/261]\tTime 0.023 (0.033)\tLoss 0.6805 (0.7767)\tPrec@1 84.000 (82.516)\tPrec@5 98.000 (98.032)\n",
            "Test: [40/261]\tTime 0.017 (0.031)\tLoss 0.7181 (0.7539)\tPrec@1 89.000 (83.073)\tPrec@5 97.000 (98.171)\n",
            "Test: [50/261]\tTime 0.018 (0.029)\tLoss 0.5577 (0.7373)\tPrec@1 86.000 (83.333)\tPrec@5 97.000 (98.235)\n",
            "Test: [60/261]\tTime 0.020 (0.028)\tLoss 0.5064 (0.7251)\tPrec@1 87.000 (83.557)\tPrec@5 99.000 (98.230)\n",
            "Test: [70/261]\tTime 0.019 (0.028)\tLoss 0.8209 (0.7309)\tPrec@1 77.000 (83.507)\tPrec@5 99.000 (98.310)\n",
            "Test: [80/261]\tTime 0.018 (0.027)\tLoss 0.6359 (0.7331)\tPrec@1 85.000 (83.617)\tPrec@5 99.000 (98.309)\n",
            "Test: [90/261]\tTime 0.033 (0.027)\tLoss 0.7767 (0.7608)\tPrec@1 85.000 (83.341)\tPrec@5 96.000 (98.209)\n",
            "Test: [100/261]\tTime 0.032 (0.027)\tLoss 1.1415 (0.7553)\tPrec@1 77.000 (83.475)\tPrec@5 96.000 (98.168)\n",
            "Test: [110/261]\tTime 0.018 (0.026)\tLoss 0.7941 (0.7552)\tPrec@1 84.000 (83.423)\tPrec@5 97.000 (98.180)\n",
            "Test: [120/261]\tTime 0.033 (0.026)\tLoss 0.8683 (0.7549)\tPrec@1 88.000 (83.512)\tPrec@5 95.000 (98.198)\n",
            "Test: [130/261]\tTime 0.015 (0.026)\tLoss 0.8700 (0.7570)\tPrec@1 80.000 (83.481)\tPrec@5 97.000 (98.153)\n",
            "Test: [140/261]\tTime 0.026 (0.026)\tLoss 0.8042 (0.7554)\tPrec@1 81.000 (83.489)\tPrec@5 98.000 (98.149)\n",
            "Test: [150/261]\tTime 0.015 (0.026)\tLoss 0.5595 (0.7549)\tPrec@1 83.000 (83.450)\tPrec@5 98.000 (98.139)\n",
            "Test: [160/261]\tTime 0.017 (0.025)\tLoss 0.3932 (0.7538)\tPrec@1 87.000 (83.391)\tPrec@5 100.000 (98.143)\n",
            "Test: [170/261]\tTime 0.033 (0.025)\tLoss 0.5796 (0.7532)\tPrec@1 85.000 (83.398)\tPrec@5 98.000 (98.164)\n",
            "Test: [180/261]\tTime 0.022 (0.025)\tLoss 0.5806 (0.7579)\tPrec@1 87.000 (83.331)\tPrec@5 95.000 (98.160)\n",
            "Test: [190/261]\tTime 0.022 (0.025)\tLoss 0.7670 (0.7541)\tPrec@1 85.000 (83.424)\tPrec@5 99.000 (98.183)\n",
            "Test: [200/261]\tTime 0.023 (0.025)\tLoss 0.7291 (0.7546)\tPrec@1 89.000 (83.393)\tPrec@5 98.000 (98.139)\n",
            "Test: [210/261]\tTime 0.023 (0.025)\tLoss 0.8000 (0.7561)\tPrec@1 80.000 (83.360)\tPrec@5 97.000 (98.133)\n",
            "Test: [220/261]\tTime 0.039 (0.025)\tLoss 0.7354 (0.7567)\tPrec@1 82.000 (83.276)\tPrec@5 100.000 (98.154)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 0.7464 (0.7591)\tPrec@1 83.000 (83.260)\tPrec@5 95.000 (98.126)\n",
            "Test: [240/261]\tTime 0.021 (0.025)\tLoss 0.7392 (0.7621)\tPrec@1 86.000 (83.266)\tPrec@5 99.000 (98.116)\n",
            "Test: [250/261]\tTime 0.014 (0.025)\tLoss 0.6730 (0.7564)\tPrec@1 81.000 (83.371)\tPrec@5 100.000 (98.127)\n",
            "Test: [260/261]\tTime 0.006 (0.025)\tLoss 0.6073 (0.7582)\tPrec@1 90.625 (83.382)\tPrec@5 100.000 (98.114)\n",
            "val Results: Prec@1 83.382 Prec@5 98.114 Loss 0.75820\n",
            "val Class Accuracy: [0.747,0.976,0.916,0.813,0.822,0.826,0.779,0.806,0.691,0.582]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [101][0/66], lr: 0.01000\tTime 0.425 (0.425)\tData 0.329 (0.329)\tLoss 0.0811 (0.0811)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][10/66], lr: 0.01000\tTime 0.084 (0.139)\tData 0.000 (0.045)\tLoss 0.0714 (0.0588)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][20/66], lr: 0.01000\tTime 0.098 (0.119)\tData 0.007 (0.027)\tLoss 0.0341 (0.0512)\tPrec@1 99.219 (98.363)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][30/66], lr: 0.01000\tTime 0.091 (0.110)\tData 0.000 (0.020)\tLoss 0.0595 (0.0517)\tPrec@1 97.656 (98.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][40/66], lr: 0.01000\tTime 0.098 (0.105)\tData 0.005 (0.016)\tLoss 0.0679 (0.0527)\tPrec@1 97.266 (98.199)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][50/66], lr: 0.01000\tTime 0.087 (0.102)\tData 0.004 (0.014)\tLoss 0.0190 (0.0515)\tPrec@1 99.609 (98.284)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [101][60/66], lr: 0.01000\tTime 0.062 (0.099)\tData 0.000 (0.012)\tLoss 0.0327 (0.0512)\tPrec@1 98.828 (98.258)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.222 (0.222)\tLoss 0.6698 (0.6698)\tPrec@1 85.000 (85.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.056 (0.053)\tLoss 1.0391 (0.7816)\tPrec@1 80.000 (81.818)\tPrec@5 98.000 (98.000)\n",
            "Test: [20/261]\tTime 0.010 (0.038)\tLoss 1.0668 (0.7550)\tPrec@1 78.000 (82.238)\tPrec@5 95.000 (97.619)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.4521 (0.7123)\tPrec@1 90.000 (83.290)\tPrec@5 99.000 (97.968)\n",
            "Test: [40/261]\tTime 0.025 (0.031)\tLoss 0.5006 (0.6916)\tPrec@1 89.000 (83.829)\tPrec@5 98.000 (98.122)\n",
            "Test: [50/261]\tTime 0.020 (0.029)\tLoss 0.4717 (0.6901)\tPrec@1 86.000 (83.824)\tPrec@5 99.000 (98.157)\n",
            "Test: [60/261]\tTime 0.018 (0.029)\tLoss 0.6495 (0.7002)\tPrec@1 85.000 (83.885)\tPrec@5 99.000 (98.115)\n",
            "Test: [70/261]\tTime 0.029 (0.028)\tLoss 0.5437 (0.6973)\tPrec@1 88.000 (84.085)\tPrec@5 99.000 (98.141)\n",
            "Test: [80/261]\tTime 0.028 (0.028)\tLoss 0.8610 (0.7019)\tPrec@1 80.000 (84.000)\tPrec@5 97.000 (98.136)\n",
            "Test: [90/261]\tTime 0.015 (0.028)\tLoss 0.6880 (0.7275)\tPrec@1 87.000 (83.846)\tPrec@5 97.000 (97.989)\n",
            "Test: [100/261]\tTime 0.029 (0.027)\tLoss 0.8488 (0.7218)\tPrec@1 82.000 (83.911)\tPrec@5 98.000 (98.030)\n",
            "Test: [110/261]\tTime 0.023 (0.027)\tLoss 0.7398 (0.7144)\tPrec@1 84.000 (84.009)\tPrec@5 98.000 (98.063)\n",
            "Test: [120/261]\tTime 0.044 (0.027)\tLoss 0.6418 (0.7115)\tPrec@1 86.000 (84.025)\tPrec@5 96.000 (98.074)\n",
            "Test: [130/261]\tTime 0.036 (0.026)\tLoss 0.6549 (0.7138)\tPrec@1 82.000 (84.015)\tPrec@5 98.000 (98.076)\n",
            "Test: [140/261]\tTime 0.024 (0.026)\tLoss 0.9379 (0.7161)\tPrec@1 79.000 (83.993)\tPrec@5 97.000 (98.071)\n",
            "Test: [150/261]\tTime 0.019 (0.026)\tLoss 0.4629 (0.7182)\tPrec@1 87.000 (83.960)\tPrec@5 97.000 (98.079)\n",
            "Test: [160/261]\tTime 0.018 (0.026)\tLoss 0.3782 (0.7209)\tPrec@1 91.000 (83.913)\tPrec@5 99.000 (98.099)\n",
            "Test: [170/261]\tTime 0.009 (0.026)\tLoss 0.6330 (0.7172)\tPrec@1 88.000 (83.994)\tPrec@5 98.000 (98.082)\n",
            "Test: [180/261]\tTime 0.020 (0.026)\tLoss 0.5800 (0.7186)\tPrec@1 87.000 (83.994)\tPrec@5 96.000 (98.072)\n",
            "Test: [190/261]\tTime 0.014 (0.026)\tLoss 0.5264 (0.7153)\tPrec@1 89.000 (84.099)\tPrec@5 100.000 (98.105)\n",
            "Test: [200/261]\tTime 0.017 (0.026)\tLoss 0.6772 (0.7153)\tPrec@1 85.000 (84.070)\tPrec@5 98.000 (98.090)\n",
            "Test: [210/261]\tTime 0.019 (0.026)\tLoss 0.5131 (0.7125)\tPrec@1 84.000 (84.123)\tPrec@5 99.000 (98.128)\n",
            "Test: [220/261]\tTime 0.030 (0.026)\tLoss 0.6630 (0.7071)\tPrec@1 83.000 (84.199)\tPrec@5 97.000 (98.140)\n",
            "Test: [230/261]\tTime 0.017 (0.026)\tLoss 0.9226 (0.7098)\tPrec@1 81.000 (84.139)\tPrec@5 96.000 (98.130)\n",
            "Test: [240/261]\tTime 0.027 (0.025)\tLoss 0.7756 (0.7124)\tPrec@1 82.000 (84.124)\tPrec@5 99.000 (98.124)\n",
            "Test: [250/261]\tTime 0.009 (0.025)\tLoss 0.5767 (0.7094)\tPrec@1 87.000 (84.183)\tPrec@5 99.000 (98.120)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2638 (0.7092)\tPrec@1 93.750 (84.193)\tPrec@5 96.875 (98.106)\n",
            "val Results: Prec@1 84.193 Prec@5 98.106 Loss 0.70915\n",
            "val Class Accuracy: [0.600,0.933,0.921,0.853,0.932,0.875,0.789,0.735,0.670,0.779]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [102][0/66], lr: 0.01000\tTime 0.523 (0.523)\tData 0.433 (0.433)\tLoss 0.0469 (0.0469)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][10/66], lr: 0.01000\tTime 0.097 (0.137)\tData 0.000 (0.043)\tLoss 0.0480 (0.0522)\tPrec@1 97.656 (98.011)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][20/66], lr: 0.01000\tTime 0.083 (0.118)\tData 0.002 (0.025)\tLoss 0.0316 (0.0521)\tPrec@1 99.219 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][30/66], lr: 0.01000\tTime 0.095 (0.109)\tData 0.005 (0.019)\tLoss 0.0724 (0.0515)\tPrec@1 96.875 (98.198)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][40/66], lr: 0.01000\tTime 0.084 (0.105)\tData 0.001 (0.016)\tLoss 0.0934 (0.0516)\tPrec@1 96.875 (98.209)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][50/66], lr: 0.01000\tTime 0.100 (0.103)\tData 0.000 (0.013)\tLoss 0.0813 (0.0523)\tPrec@1 97.656 (98.185)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [102][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.012)\tLoss 0.0700 (0.0535)\tPrec@1 97.266 (98.130)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.213 (0.213)\tLoss 0.6572 (0.6572)\tPrec@1 86.000 (86.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.026 (0.049)\tLoss 1.0405 (0.7992)\tPrec@1 80.000 (82.909)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/261]\tTime 0.034 (0.037)\tLoss 0.9896 (0.8112)\tPrec@1 80.000 (82.571)\tPrec@5 95.000 (97.762)\n",
            "Test: [30/261]\tTime 0.030 (0.033)\tLoss 0.6218 (0.7585)\tPrec@1 86.000 (83.194)\tPrec@5 98.000 (98.032)\n",
            "Test: [40/261]\tTime 0.021 (0.030)\tLoss 0.6174 (0.7378)\tPrec@1 87.000 (83.756)\tPrec@5 97.000 (98.146)\n",
            "Test: [50/261]\tTime 0.030 (0.029)\tLoss 0.8118 (0.7309)\tPrec@1 80.000 (84.059)\tPrec@5 97.000 (98.235)\n",
            "Test: [60/261]\tTime 0.016 (0.028)\tLoss 0.5375 (0.7343)\tPrec@1 87.000 (83.951)\tPrec@5 99.000 (98.311)\n",
            "Test: [70/261]\tTime 0.022 (0.027)\tLoss 0.8067 (0.7406)\tPrec@1 82.000 (83.873)\tPrec@5 98.000 (98.239)\n",
            "Test: [80/261]\tTime 0.029 (0.027)\tLoss 0.7109 (0.7475)\tPrec@1 85.000 (83.864)\tPrec@5 98.000 (98.160)\n",
            "Test: [90/261]\tTime 0.018 (0.027)\tLoss 0.9256 (0.7722)\tPrec@1 82.000 (83.637)\tPrec@5 96.000 (98.066)\n",
            "Test: [100/261]\tTime 0.020 (0.026)\tLoss 0.9574 (0.7697)\tPrec@1 83.000 (83.772)\tPrec@5 94.000 (98.000)\n",
            "Test: [110/261]\tTime 0.043 (0.026)\tLoss 0.9795 (0.7682)\tPrec@1 82.000 (83.793)\tPrec@5 99.000 (98.054)\n",
            "Test: [120/261]\tTime 0.024 (0.026)\tLoss 0.5980 (0.7672)\tPrec@1 88.000 (83.843)\tPrec@5 98.000 (98.033)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8223 (0.7705)\tPrec@1 84.000 (83.855)\tPrec@5 98.000 (97.992)\n",
            "Test: [140/261]\tTime 0.032 (0.026)\tLoss 0.9807 (0.7645)\tPrec@1 82.000 (84.014)\tPrec@5 99.000 (97.986)\n",
            "Test: [150/261]\tTime 0.010 (0.026)\tLoss 0.6194 (0.7642)\tPrec@1 86.000 (84.033)\tPrec@5 98.000 (97.993)\n",
            "Test: [160/261]\tTime 0.039 (0.026)\tLoss 0.4911 (0.7638)\tPrec@1 87.000 (83.981)\tPrec@5 99.000 (98.012)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.7301 (0.7619)\tPrec@1 88.000 (84.029)\tPrec@5 97.000 (97.982)\n",
            "Test: [180/261]\tTime 0.024 (0.025)\tLoss 0.6109 (0.7639)\tPrec@1 87.000 (83.989)\tPrec@5 96.000 (97.983)\n",
            "Test: [190/261]\tTime 0.016 (0.025)\tLoss 0.6814 (0.7635)\tPrec@1 81.000 (83.963)\tPrec@5 99.000 (97.995)\n",
            "Test: [200/261]\tTime 0.029 (0.025)\tLoss 0.7760 (0.7632)\tPrec@1 85.000 (83.940)\tPrec@5 97.000 (97.975)\n",
            "Test: [210/261]\tTime 0.025 (0.025)\tLoss 0.5967 (0.7625)\tPrec@1 87.000 (83.972)\tPrec@5 99.000 (97.972)\n",
            "Test: [220/261]\tTime 0.022 (0.025)\tLoss 0.5876 (0.7617)\tPrec@1 83.000 (83.928)\tPrec@5 98.000 (97.982)\n",
            "Test: [230/261]\tTime 0.030 (0.025)\tLoss 0.7717 (0.7652)\tPrec@1 83.000 (83.818)\tPrec@5 98.000 (97.961)\n",
            "Test: [240/261]\tTime 0.049 (0.025)\tLoss 0.5352 (0.7658)\tPrec@1 88.000 (83.842)\tPrec@5 99.000 (97.942)\n",
            "Test: [250/261]\tTime 0.054 (0.026)\tLoss 0.5674 (0.7618)\tPrec@1 85.000 (83.900)\tPrec@5 100.000 (97.948)\n",
            "Test: [260/261]\tTime 0.007 (0.025)\tLoss 0.3568 (0.7632)\tPrec@1 87.500 (83.901)\tPrec@5 96.875 (97.922)\n",
            "val Results: Prec@1 83.901 Prec@5 97.922 Loss 0.76322\n",
            "val Class Accuracy: [0.752,0.966,0.893,0.831,0.929,0.761,0.793,0.824,0.654,0.645]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [103][0/66], lr: 0.01000\tTime 0.804 (0.804)\tData 0.662 (0.662)\tLoss 0.0432 (0.0432)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][10/66], lr: 0.01000\tTime 0.095 (0.191)\tData 0.005 (0.090)\tLoss 0.0550 (0.0623)\tPrec@1 98.438 (97.869)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][20/66], lr: 0.01000\tTime 0.109 (0.159)\tData 0.008 (0.066)\tLoss 0.0571 (0.0615)\tPrec@1 98.438 (97.972)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][30/66], lr: 0.01000\tTime 0.102 (0.139)\tData 0.003 (0.050)\tLoss 0.0678 (0.0612)\tPrec@1 98.438 (98.059)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][40/66], lr: 0.01000\tTime 0.101 (0.128)\tData 0.000 (0.039)\tLoss 0.0518 (0.0567)\tPrec@1 97.656 (98.190)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [103][50/66], lr: 0.01000\tTime 0.104 (0.120)\tData 0.004 (0.033)\tLoss 0.0315 (0.0571)\tPrec@1 99.219 (98.123)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [103][60/66], lr: 0.01000\tTime 0.074 (0.115)\tData 0.000 (0.029)\tLoss 0.0417 (0.0549)\tPrec@1 98.828 (98.220)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.291 (0.291)\tLoss 0.9279 (0.9279)\tPrec@1 77.000 (77.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.051)\tLoss 1.3124 (0.9327)\tPrec@1 77.000 (79.273)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/261]\tTime 0.021 (0.036)\tLoss 1.2610 (0.9396)\tPrec@1 74.000 (79.333)\tPrec@5 96.000 (97.571)\n",
            "Test: [30/261]\tTime 0.038 (0.033)\tLoss 0.7011 (0.8638)\tPrec@1 84.000 (81.032)\tPrec@5 99.000 (97.903)\n",
            "Test: [40/261]\tTime 0.019 (0.030)\tLoss 0.9371 (0.8499)\tPrec@1 80.000 (81.293)\tPrec@5 100.000 (98.244)\n",
            "Test: [50/261]\tTime 0.024 (0.029)\tLoss 0.6924 (0.8381)\tPrec@1 86.000 (81.608)\tPrec@5 99.000 (98.333)\n",
            "Test: [60/261]\tTime 0.025 (0.028)\tLoss 0.8358 (0.8316)\tPrec@1 79.000 (81.738)\tPrec@5 98.000 (98.230)\n",
            "Test: [70/261]\tTime 0.035 (0.028)\tLoss 1.0152 (0.8317)\tPrec@1 79.000 (81.704)\tPrec@5 98.000 (98.169)\n",
            "Test: [80/261]\tTime 0.018 (0.027)\tLoss 0.9018 (0.8326)\tPrec@1 79.000 (81.778)\tPrec@5 97.000 (98.136)\n",
            "Test: [90/261]\tTime 0.021 (0.027)\tLoss 0.8240 (0.8566)\tPrec@1 83.000 (81.549)\tPrec@5 97.000 (98.088)\n",
            "Test: [100/261]\tTime 0.009 (0.026)\tLoss 0.9241 (0.8478)\tPrec@1 79.000 (81.634)\tPrec@5 98.000 (98.059)\n",
            "Test: [110/261]\tTime 0.048 (0.026)\tLoss 0.9818 (0.8445)\tPrec@1 84.000 (81.685)\tPrec@5 97.000 (98.063)\n",
            "Test: [120/261]\tTime 0.023 (0.026)\tLoss 0.7045 (0.8440)\tPrec@1 88.000 (81.835)\tPrec@5 98.000 (98.000)\n",
            "Test: [130/261]\tTime 0.011 (0.026)\tLoss 0.9385 (0.8464)\tPrec@1 79.000 (81.779)\tPrec@5 98.000 (97.985)\n",
            "Test: [140/261]\tTime 0.017 (0.026)\tLoss 0.7731 (0.8450)\tPrec@1 80.000 (81.794)\tPrec@5 99.000 (97.993)\n",
            "Test: [150/261]\tTime 0.022 (0.025)\tLoss 0.5860 (0.8428)\tPrec@1 84.000 (81.815)\tPrec@5 97.000 (97.960)\n",
            "Test: [160/261]\tTime 0.032 (0.026)\tLoss 0.4780 (0.8399)\tPrec@1 86.000 (81.764)\tPrec@5 99.000 (97.963)\n",
            "Test: [170/261]\tTime 0.025 (0.025)\tLoss 0.6917 (0.8358)\tPrec@1 84.000 (81.819)\tPrec@5 95.000 (97.942)\n",
            "Test: [180/261]\tTime 0.026 (0.025)\tLoss 0.8556 (0.8345)\tPrec@1 86.000 (81.906)\tPrec@5 95.000 (97.939)\n",
            "Test: [190/261]\tTime 0.025 (0.025)\tLoss 0.7500 (0.8343)\tPrec@1 82.000 (81.911)\tPrec@5 99.000 (97.990)\n",
            "Test: [200/261]\tTime 0.023 (0.025)\tLoss 0.7839 (0.8342)\tPrec@1 83.000 (81.905)\tPrec@5 98.000 (97.975)\n",
            "Test: [210/261]\tTime 0.030 (0.025)\tLoss 1.0116 (0.8346)\tPrec@1 77.000 (81.891)\tPrec@5 97.000 (97.938)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.7268 (0.8278)\tPrec@1 81.000 (81.932)\tPrec@5 98.000 (97.977)\n",
            "Test: [230/261]\tTime 0.021 (0.025)\tLoss 0.8341 (0.8286)\tPrec@1 77.000 (81.853)\tPrec@5 97.000 (97.957)\n",
            "Test: [240/261]\tTime 0.010 (0.025)\tLoss 0.8689 (0.8295)\tPrec@1 79.000 (81.876)\tPrec@5 98.000 (97.959)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.8466 (0.8252)\tPrec@1 78.000 (81.869)\tPrec@5 100.000 (97.976)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3880 (0.8264)\tPrec@1 93.750 (81.865)\tPrec@5 96.875 (97.941)\n",
            "val Results: Prec@1 81.865 Prec@5 97.941 Loss 0.82638\n",
            "val Class Accuracy: [0.371,0.969,0.931,0.800,0.863,0.781,0.837,0.769,0.728,0.688]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [104][0/66], lr: 0.01000\tTime 0.532 (0.532)\tData 0.442 (0.442)\tLoss 0.0696 (0.0696)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [104][10/66], lr: 0.01000\tTime 0.073 (0.134)\tData 0.000 (0.046)\tLoss 0.0112 (0.0489)\tPrec@1 100.000 (98.473)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [104][20/66], lr: 0.01000\tTime 0.096 (0.117)\tData 0.000 (0.028)\tLoss 0.0734 (0.0475)\tPrec@1 97.656 (98.400)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [104][30/66], lr: 0.01000\tTime 0.084 (0.110)\tData 0.000 (0.021)\tLoss 0.0769 (0.0435)\tPrec@1 97.266 (98.475)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [104][40/66], lr: 0.01000\tTime 0.102 (0.106)\tData 0.000 (0.017)\tLoss 0.0698 (0.0473)\tPrec@1 98.438 (98.371)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [104][50/66], lr: 0.01000\tTime 0.086 (0.104)\tData 0.000 (0.015)\tLoss 0.0445 (0.0500)\tPrec@1 98.828 (98.307)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [104][60/66], lr: 0.01000\tTime 0.068 (0.101)\tData 0.000 (0.013)\tLoss 0.0609 (0.0514)\tPrec@1 97.266 (98.258)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.283 (0.283)\tLoss 0.5510 (0.5510)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.009 (0.047)\tLoss 1.1958 (0.7987)\tPrec@1 82.000 (81.364)\tPrec@5 99.000 (98.818)\n",
            "Test: [20/261]\tTime 0.019 (0.035)\tLoss 0.9762 (0.8047)\tPrec@1 77.000 (81.476)\tPrec@5 98.000 (98.381)\n",
            "Test: [30/261]\tTime 0.024 (0.031)\tLoss 0.6757 (0.7550)\tPrec@1 87.000 (82.581)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.032 (0.030)\tLoss 0.8224 (0.7385)\tPrec@1 83.000 (83.146)\tPrec@5 99.000 (98.561)\n",
            "Test: [50/261]\tTime 0.013 (0.029)\tLoss 0.6184 (0.7559)\tPrec@1 83.000 (83.059)\tPrec@5 99.000 (98.608)\n",
            "Test: [60/261]\tTime 0.011 (0.028)\tLoss 0.6837 (0.7545)\tPrec@1 86.000 (83.230)\tPrec@5 98.000 (98.492)\n",
            "Test: [70/261]\tTime 0.019 (0.027)\tLoss 0.6927 (0.7525)\tPrec@1 86.000 (83.352)\tPrec@5 98.000 (98.507)\n",
            "Test: [80/261]\tTime 0.039 (0.027)\tLoss 0.7891 (0.7490)\tPrec@1 80.000 (83.259)\tPrec@5 98.000 (98.519)\n",
            "Test: [90/261]\tTime 0.022 (0.026)\tLoss 0.4725 (0.7659)\tPrec@1 86.000 (83.165)\tPrec@5 97.000 (98.319)\n",
            "Test: [100/261]\tTime 0.042 (0.026)\tLoss 1.0834 (0.7686)\tPrec@1 83.000 (83.248)\tPrec@5 99.000 (98.317)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.7157 (0.7627)\tPrec@1 86.000 (83.270)\tPrec@5 99.000 (98.324)\n",
            "Test: [120/261]\tTime 0.024 (0.026)\tLoss 0.8670 (0.7647)\tPrec@1 85.000 (83.215)\tPrec@5 96.000 (98.289)\n",
            "Test: [130/261]\tTime 0.023 (0.025)\tLoss 1.0570 (0.7707)\tPrec@1 81.000 (83.221)\tPrec@5 98.000 (98.282)\n",
            "Test: [140/261]\tTime 0.032 (0.026)\tLoss 0.9097 (0.7655)\tPrec@1 81.000 (83.262)\tPrec@5 98.000 (98.262)\n",
            "Test: [150/261]\tTime 0.031 (0.025)\tLoss 0.6121 (0.7638)\tPrec@1 85.000 (83.384)\tPrec@5 98.000 (98.238)\n",
            "Test: [160/261]\tTime 0.028 (0.025)\tLoss 0.4311 (0.7646)\tPrec@1 88.000 (83.429)\tPrec@5 100.000 (98.242)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.7639 (0.7594)\tPrec@1 83.000 (83.538)\tPrec@5 94.000 (98.216)\n",
            "Test: [180/261]\tTime 0.028 (0.025)\tLoss 0.7592 (0.7600)\tPrec@1 84.000 (83.608)\tPrec@5 95.000 (98.215)\n",
            "Test: [190/261]\tTime 0.023 (0.025)\tLoss 0.4872 (0.7558)\tPrec@1 89.000 (83.702)\tPrec@5 100.000 (98.246)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.7929 (0.7572)\tPrec@1 86.000 (83.692)\tPrec@5 98.000 (98.229)\n",
            "Test: [210/261]\tTime 0.040 (0.025)\tLoss 0.7278 (0.7556)\tPrec@1 84.000 (83.758)\tPrec@5 98.000 (98.251)\n",
            "Test: [220/261]\tTime 0.012 (0.025)\tLoss 0.8330 (0.7512)\tPrec@1 82.000 (83.778)\tPrec@5 98.000 (98.271)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.7258 (0.7504)\tPrec@1 81.000 (83.771)\tPrec@5 98.000 (98.251)\n",
            "Test: [240/261]\tTime 0.044 (0.025)\tLoss 0.7774 (0.7511)\tPrec@1 84.000 (83.784)\tPrec@5 97.000 (98.224)\n",
            "Test: [250/261]\tTime 0.016 (0.025)\tLoss 0.4082 (0.7466)\tPrec@1 85.000 (83.821)\tPrec@5 100.000 (98.223)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.2573 (0.7462)\tPrec@1 93.750 (83.847)\tPrec@5 100.000 (98.221)\n",
            "val Results: Prec@1 83.847 Prec@5 98.221 Loss 0.74622\n",
            "val Class Accuracy: [0.708,0.920,0.951,0.833,0.841,0.786,0.798,0.758,0.799,0.708]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [105][0/66], lr: 0.01000\tTime 0.598 (0.598)\tData 0.523 (0.523)\tLoss 0.1067 (0.1067)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][10/66], lr: 0.01000\tTime 0.085 (0.135)\tData 0.000 (0.057)\tLoss 0.0776 (0.0722)\tPrec@1 96.094 (97.408)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [105][20/66], lr: 0.01000\tTime 0.081 (0.116)\tData 0.000 (0.036)\tLoss 0.0614 (0.0768)\tPrec@1 97.266 (97.303)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [105][30/66], lr: 0.01000\tTime 0.088 (0.108)\tData 0.007 (0.027)\tLoss 0.0382 (0.0680)\tPrec@1 98.828 (97.581)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [105][40/66], lr: 0.01000\tTime 0.092 (0.104)\tData 0.005 (0.022)\tLoss 0.0520 (0.0667)\tPrec@1 99.219 (97.647)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [105][50/66], lr: 0.01000\tTime 0.094 (0.102)\tData 0.006 (0.019)\tLoss 0.1084 (0.0652)\tPrec@1 96.094 (97.710)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [105][60/66], lr: 0.01000\tTime 0.073 (0.099)\tData 0.000 (0.017)\tLoss 0.0485 (0.0628)\tPrec@1 98.047 (97.804)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.274 (0.274)\tLoss 1.0630 (1.0630)\tPrec@1 80.000 (80.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.024 (0.050)\tLoss 1.3043 (0.9750)\tPrec@1 78.000 (79.273)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/261]\tTime 0.020 (0.035)\tLoss 1.2004 (0.9616)\tPrec@1 76.000 (79.714)\tPrec@5 97.000 (97.524)\n",
            "Test: [30/261]\tTime 0.030 (0.032)\tLoss 0.5891 (0.8975)\tPrec@1 88.000 (80.968)\tPrec@5 99.000 (97.839)\n",
            "Test: [40/261]\tTime 0.016 (0.030)\tLoss 0.9386 (0.8783)\tPrec@1 85.000 (81.268)\tPrec@5 99.000 (97.927)\n",
            "Test: [50/261]\tTime 0.021 (0.029)\tLoss 0.8103 (0.8628)\tPrec@1 83.000 (81.431)\tPrec@5 99.000 (98.059)\n",
            "Test: [60/261]\tTime 0.033 (0.028)\tLoss 0.6823 (0.8597)\tPrec@1 82.000 (81.508)\tPrec@5 99.000 (97.984)\n",
            "Test: [70/261]\tTime 0.030 (0.027)\tLoss 1.0068 (0.8627)\tPrec@1 80.000 (81.451)\tPrec@5 98.000 (98.028)\n",
            "Test: [80/261]\tTime 0.023 (0.026)\tLoss 0.8277 (0.8620)\tPrec@1 81.000 (81.395)\tPrec@5 97.000 (98.012)\n",
            "Test: [90/261]\tTime 0.026 (0.026)\tLoss 1.0325 (0.8906)\tPrec@1 83.000 (81.088)\tPrec@5 96.000 (97.934)\n",
            "Test: [100/261]\tTime 0.026 (0.026)\tLoss 0.8695 (0.8812)\tPrec@1 77.000 (81.248)\tPrec@5 97.000 (97.950)\n",
            "Test: [110/261]\tTime 0.027 (0.025)\tLoss 0.7526 (0.8809)\tPrec@1 85.000 (81.252)\tPrec@5 98.000 (97.955)\n",
            "Test: [120/261]\tTime 0.030 (0.026)\tLoss 0.5786 (0.8819)\tPrec@1 86.000 (81.273)\tPrec@5 98.000 (97.893)\n",
            "Test: [130/261]\tTime 0.017 (0.025)\tLoss 1.0028 (0.8895)\tPrec@1 82.000 (81.206)\tPrec@5 93.000 (97.840)\n",
            "Test: [140/261]\tTime 0.022 (0.025)\tLoss 0.9841 (0.8869)\tPrec@1 80.000 (81.156)\tPrec@5 98.000 (97.837)\n",
            "Test: [150/261]\tTime 0.020 (0.025)\tLoss 0.6062 (0.8828)\tPrec@1 85.000 (81.166)\tPrec@5 98.000 (97.868)\n",
            "Test: [160/261]\tTime 0.025 (0.025)\tLoss 0.4999 (0.8833)\tPrec@1 89.000 (81.248)\tPrec@5 99.000 (97.857)\n",
            "Test: [170/261]\tTime 0.037 (0.025)\tLoss 0.7366 (0.8824)\tPrec@1 84.000 (81.211)\tPrec@5 99.000 (97.860)\n",
            "Test: [180/261]\tTime 0.022 (0.025)\tLoss 0.8697 (0.8822)\tPrec@1 83.000 (81.221)\tPrec@5 97.000 (97.862)\n",
            "Test: [190/261]\tTime 0.010 (0.025)\tLoss 0.9034 (0.8813)\tPrec@1 81.000 (81.262)\tPrec@5 99.000 (97.911)\n",
            "Test: [200/261]\tTime 0.031 (0.025)\tLoss 0.7404 (0.8785)\tPrec@1 85.000 (81.264)\tPrec@5 98.000 (97.881)\n",
            "Test: [210/261]\tTime 0.015 (0.025)\tLoss 0.7126 (0.8819)\tPrec@1 86.000 (81.251)\tPrec@5 99.000 (97.872)\n",
            "Test: [220/261]\tTime 0.032 (0.025)\tLoss 0.7932 (0.8792)\tPrec@1 81.000 (81.235)\tPrec@5 96.000 (97.873)\n",
            "Test: [230/261]\tTime 0.017 (0.025)\tLoss 1.0813 (0.8792)\tPrec@1 78.000 (81.208)\tPrec@5 95.000 (97.853)\n",
            "Test: [240/261]\tTime 0.026 (0.025)\tLoss 0.9070 (0.8849)\tPrec@1 81.000 (81.129)\tPrec@5 98.000 (97.830)\n",
            "Test: [250/261]\tTime 0.014 (0.025)\tLoss 1.0481 (0.8825)\tPrec@1 79.000 (81.179)\tPrec@5 99.000 (97.837)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.5789 (0.8838)\tPrec@1 87.500 (81.173)\tPrec@5 96.875 (97.818)\n",
            "val Results: Prec@1 81.173 Prec@5 97.818 Loss 0.88376\n",
            "val Class Accuracy: [0.666,0.960,0.959,0.820,0.889,0.862,0.602,0.741,0.551,0.524]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [106][0/66], lr: 0.01000\tTime 0.568 (0.568)\tData 0.498 (0.498)\tLoss 0.0536 (0.0536)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][10/66], lr: 0.01000\tTime 0.078 (0.139)\tData 0.000 (0.059)\tLoss 0.0910 (0.0543)\tPrec@1 96.094 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][20/66], lr: 0.01000\tTime 0.096 (0.119)\tData 0.005 (0.037)\tLoss 0.0458 (0.0521)\tPrec@1 98.438 (98.214)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][30/66], lr: 0.01000\tTime 0.099 (0.110)\tData 0.008 (0.027)\tLoss 0.0604 (0.0539)\tPrec@1 98.047 (98.110)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][40/66], lr: 0.01000\tTime 0.082 (0.106)\tData 0.001 (0.021)\tLoss 0.0205 (0.0508)\tPrec@1 99.609 (98.237)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][50/66], lr: 0.01000\tTime 0.083 (0.103)\tData 0.007 (0.018)\tLoss 0.0261 (0.0498)\tPrec@1 98.828 (98.292)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [106][60/66], lr: 0.01000\tTime 0.076 (0.100)\tData 0.000 (0.016)\tLoss 0.0622 (0.0495)\tPrec@1 98.828 (98.290)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.272 (0.272)\tLoss 0.7755 (0.7755)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.021 (0.052)\tLoss 1.3119 (0.8737)\tPrec@1 84.000 (83.455)\tPrec@5 100.000 (97.364)\n",
            "Test: [20/261]\tTime 0.045 (0.039)\tLoss 0.9995 (0.8505)\tPrec@1 84.000 (83.143)\tPrec@5 96.000 (97.571)\n",
            "Test: [30/261]\tTime 0.026 (0.034)\tLoss 0.7783 (0.8099)\tPrec@1 86.000 (83.839)\tPrec@5 100.000 (97.935)\n",
            "Test: [40/261]\tTime 0.021 (0.032)\tLoss 0.5553 (0.7672)\tPrec@1 88.000 (84.683)\tPrec@5 98.000 (98.122)\n",
            "Test: [50/261]\tTime 0.046 (0.030)\tLoss 0.6732 (0.7567)\tPrec@1 83.000 (84.627)\tPrec@5 97.000 (98.137)\n",
            "Test: [60/261]\tTime 0.009 (0.028)\tLoss 0.6135 (0.7501)\tPrec@1 84.000 (84.721)\tPrec@5 99.000 (98.049)\n",
            "Test: [70/261]\tTime 0.028 (0.028)\tLoss 0.6656 (0.7498)\tPrec@1 85.000 (84.634)\tPrec@5 100.000 (98.085)\n",
            "Test: [80/261]\tTime 0.019 (0.028)\tLoss 0.7465 (0.7459)\tPrec@1 82.000 (84.704)\tPrec@5 99.000 (98.086)\n",
            "Test: [90/261]\tTime 0.010 (0.027)\tLoss 0.7222 (0.7775)\tPrec@1 85.000 (84.407)\tPrec@5 97.000 (97.956)\n",
            "Test: [100/261]\tTime 0.022 (0.027)\tLoss 0.9991 (0.7773)\tPrec@1 82.000 (84.337)\tPrec@5 96.000 (97.941)\n",
            "Test: [110/261]\tTime 0.011 (0.027)\tLoss 1.0498 (0.7769)\tPrec@1 80.000 (84.270)\tPrec@5 97.000 (97.982)\n",
            "Test: [120/261]\tTime 0.022 (0.027)\tLoss 0.6734 (0.7724)\tPrec@1 87.000 (84.306)\tPrec@5 97.000 (97.983)\n",
            "Test: [130/261]\tTime 0.025 (0.026)\tLoss 0.7644 (0.7755)\tPrec@1 87.000 (84.282)\tPrec@5 97.000 (97.931)\n",
            "Test: [140/261]\tTime 0.026 (0.026)\tLoss 0.7302 (0.7706)\tPrec@1 81.000 (84.277)\tPrec@5 97.000 (97.950)\n",
            "Test: [150/261]\tTime 0.025 (0.026)\tLoss 0.5374 (0.7718)\tPrec@1 88.000 (84.291)\tPrec@5 98.000 (97.940)\n",
            "Test: [160/261]\tTime 0.023 (0.026)\tLoss 0.4317 (0.7716)\tPrec@1 92.000 (84.335)\tPrec@5 100.000 (97.975)\n",
            "Test: [170/261]\tTime 0.020 (0.026)\tLoss 0.6344 (0.7659)\tPrec@1 90.000 (84.415)\tPrec@5 98.000 (98.000)\n",
            "Test: [180/261]\tTime 0.010 (0.026)\tLoss 0.6859 (0.7700)\tPrec@1 88.000 (84.392)\tPrec@5 96.000 (97.972)\n",
            "Test: [190/261]\tTime 0.018 (0.026)\tLoss 0.7416 (0.7684)\tPrec@1 86.000 (84.377)\tPrec@5 98.000 (98.005)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 0.6163 (0.7676)\tPrec@1 87.000 (84.368)\tPrec@5 97.000 (98.000)\n",
            "Test: [210/261]\tTime 0.027 (0.026)\tLoss 0.8218 (0.7690)\tPrec@1 82.000 (84.355)\tPrec@5 99.000 (97.995)\n",
            "Test: [220/261]\tTime 0.017 (0.026)\tLoss 0.7477 (0.7654)\tPrec@1 81.000 (84.348)\tPrec@5 100.000 (98.045)\n",
            "Test: [230/261]\tTime 0.033 (0.026)\tLoss 0.8309 (0.7682)\tPrec@1 82.000 (84.251)\tPrec@5 96.000 (98.035)\n",
            "Test: [240/261]\tTime 0.020 (0.026)\tLoss 0.6449 (0.7695)\tPrec@1 88.000 (84.295)\tPrec@5 99.000 (98.029)\n",
            "Test: [250/261]\tTime 0.027 (0.026)\tLoss 0.4850 (0.7654)\tPrec@1 84.000 (84.311)\tPrec@5 100.000 (98.048)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.7515 (0.7700)\tPrec@1 87.500 (84.281)\tPrec@5 96.875 (97.999)\n",
            "val Results: Prec@1 84.281 Prec@5 97.999 Loss 0.77000\n",
            "val Class Accuracy: [0.554,0.965,0.877,0.904,0.864,0.825,0.845,0.813,0.731,0.717]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [107][0/66], lr: 0.01000\tTime 0.454 (0.454)\tData 0.371 (0.371)\tLoss 0.1064 (0.1064)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][10/66], lr: 0.01000\tTime 0.083 (0.129)\tData 0.006 (0.047)\tLoss 0.0295 (0.0436)\tPrec@1 99.219 (98.615)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][20/66], lr: 0.01000\tTime 0.085 (0.112)\tData 0.005 (0.031)\tLoss 0.0265 (0.0434)\tPrec@1 98.828 (98.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][30/66], lr: 0.01000\tTime 0.159 (0.108)\tData 0.088 (0.027)\tLoss 0.0426 (0.0446)\tPrec@1 98.047 (98.488)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][40/66], lr: 0.01000\tTime 0.083 (0.105)\tData 0.000 (0.022)\tLoss 0.0606 (0.0461)\tPrec@1 98.828 (98.495)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][50/66], lr: 0.01000\tTime 0.114 (0.103)\tData 0.004 (0.019)\tLoss 0.0373 (0.0465)\tPrec@1 98.438 (98.483)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [107][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.016)\tLoss 0.0566 (0.0467)\tPrec@1 97.656 (98.405)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.264 (0.264)\tLoss 0.8428 (0.8428)\tPrec@1 82.000 (82.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.035 (0.049)\tLoss 1.3628 (0.8818)\tPrec@1 76.000 (80.273)\tPrec@5 96.000 (97.000)\n",
            "Test: [20/261]\tTime 0.017 (0.035)\tLoss 1.1601 (0.9020)\tPrec@1 79.000 (80.619)\tPrec@5 97.000 (96.857)\n",
            "Test: [30/261]\tTime 0.026 (0.031)\tLoss 0.5859 (0.8469)\tPrec@1 88.000 (82.065)\tPrec@5 96.000 (97.065)\n",
            "Test: [40/261]\tTime 0.016 (0.030)\tLoss 0.5779 (0.8153)\tPrec@1 87.000 (82.756)\tPrec@5 99.000 (97.220)\n",
            "Test: [50/261]\tTime 0.027 (0.029)\tLoss 0.5628 (0.7944)\tPrec@1 85.000 (82.922)\tPrec@5 99.000 (97.333)\n",
            "Test: [60/261]\tTime 0.018 (0.028)\tLoss 0.9186 (0.7953)\tPrec@1 76.000 (82.770)\tPrec@5 96.000 (97.311)\n",
            "Test: [70/261]\tTime 0.010 (0.027)\tLoss 0.8608 (0.8027)\tPrec@1 81.000 (82.718)\tPrec@5 98.000 (97.282)\n",
            "Test: [80/261]\tTime 0.043 (0.028)\tLoss 1.0202 (0.8103)\tPrec@1 78.000 (82.469)\tPrec@5 97.000 (97.395)\n",
            "Test: [90/261]\tTime 0.026 (0.027)\tLoss 0.8541 (0.8336)\tPrec@1 84.000 (82.209)\tPrec@5 96.000 (97.319)\n",
            "Test: [100/261]\tTime 0.015 (0.027)\tLoss 0.8965 (0.8311)\tPrec@1 80.000 (82.297)\tPrec@5 98.000 (97.337)\n",
            "Test: [110/261]\tTime 0.026 (0.026)\tLoss 0.9836 (0.8235)\tPrec@1 81.000 (82.378)\tPrec@5 98.000 (97.360)\n",
            "Test: [120/261]\tTime 0.017 (0.026)\tLoss 0.8508 (0.8265)\tPrec@1 85.000 (82.364)\tPrec@5 97.000 (97.314)\n",
            "Test: [130/261]\tTime 0.029 (0.026)\tLoss 0.8335 (0.8285)\tPrec@1 79.000 (82.237)\tPrec@5 98.000 (97.260)\n",
            "Test: [140/261]\tTime 0.042 (0.026)\tLoss 0.8866 (0.8215)\tPrec@1 80.000 (82.305)\tPrec@5 98.000 (97.333)\n",
            "Test: [150/261]\tTime 0.009 (0.026)\tLoss 0.8000 (0.8214)\tPrec@1 82.000 (82.338)\tPrec@5 98.000 (97.344)\n",
            "Test: [160/261]\tTime 0.028 (0.025)\tLoss 0.4981 (0.8233)\tPrec@1 88.000 (82.255)\tPrec@5 100.000 (97.311)\n",
            "Test: [170/261]\tTime 0.026 (0.026)\tLoss 0.7569 (0.8154)\tPrec@1 87.000 (82.392)\tPrec@5 96.000 (97.327)\n",
            "Test: [180/261]\tTime 0.009 (0.025)\tLoss 0.7748 (0.8157)\tPrec@1 85.000 (82.398)\tPrec@5 95.000 (97.326)\n",
            "Test: [190/261]\tTime 0.019 (0.025)\tLoss 0.6869 (0.8147)\tPrec@1 85.000 (82.487)\tPrec@5 99.000 (97.335)\n",
            "Test: [200/261]\tTime 0.018 (0.025)\tLoss 0.6852 (0.8148)\tPrec@1 86.000 (82.433)\tPrec@5 98.000 (97.318)\n",
            "Test: [210/261]\tTime 0.025 (0.025)\tLoss 0.7746 (0.8146)\tPrec@1 79.000 (82.431)\tPrec@5 98.000 (97.299)\n",
            "Test: [220/261]\tTime 0.011 (0.025)\tLoss 0.6897 (0.8103)\tPrec@1 87.000 (82.484)\tPrec@5 98.000 (97.294)\n",
            "Test: [230/261]\tTime 0.013 (0.025)\tLoss 0.8821 (0.8119)\tPrec@1 78.000 (82.420)\tPrec@5 95.000 (97.273)\n",
            "Test: [240/261]\tTime 0.021 (0.025)\tLoss 0.8991 (0.8146)\tPrec@1 80.000 (82.365)\tPrec@5 100.000 (97.261)\n",
            "Test: [250/261]\tTime 0.028 (0.025)\tLoss 0.6208 (0.8096)\tPrec@1 83.000 (82.410)\tPrec@5 100.000 (97.299)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.4940 (0.8111)\tPrec@1 84.375 (82.425)\tPrec@5 96.875 (97.284)\n",
            "val Results: Prec@1 82.425 Prec@5 97.284 Loss 0.81110\n",
            "val Class Accuracy: [0.354,0.972,0.922,0.812,0.929,0.828,0.658,0.793,0.766,0.768]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [108][0/66], lr: 0.01000\tTime 0.586 (0.586)\tData 0.518 (0.518)\tLoss 0.0288 (0.0288)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][10/66], lr: 0.01000\tTime 0.105 (0.141)\tData 0.009 (0.060)\tLoss 0.0774 (0.0427)\tPrec@1 98.438 (98.509)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][20/66], lr: 0.01000\tTime 0.092 (0.119)\tData 0.005 (0.035)\tLoss 0.0344 (0.0391)\tPrec@1 99.219 (98.679)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][30/66], lr: 0.01000\tTime 0.079 (0.111)\tData 0.002 (0.025)\tLoss 0.0143 (0.0410)\tPrec@1 100.000 (98.690)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][40/66], lr: 0.01000\tTime 0.101 (0.106)\tData 0.000 (0.020)\tLoss 0.0585 (0.0448)\tPrec@1 96.875 (98.514)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][50/66], lr: 0.01000\tTime 0.089 (0.104)\tData 0.000 (0.017)\tLoss 0.0289 (0.0447)\tPrec@1 99.219 (98.560)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [108][60/66], lr: 0.01000\tTime 0.077 (0.101)\tData 0.000 (0.015)\tLoss 0.0212 (0.0445)\tPrec@1 99.219 (98.546)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.295 (0.295)\tLoss 0.6044 (0.6044)\tPrec@1 85.000 (85.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.040 (0.049)\tLoss 1.1573 (0.8167)\tPrec@1 82.000 (81.364)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/261]\tTime 0.021 (0.038)\tLoss 1.1198 (0.8322)\tPrec@1 78.000 (81.571)\tPrec@5 96.000 (97.762)\n",
            "Test: [30/261]\tTime 0.016 (0.033)\tLoss 0.5453 (0.7855)\tPrec@1 87.000 (82.613)\tPrec@5 99.000 (98.032)\n",
            "Test: [40/261]\tTime 0.020 (0.031)\tLoss 0.8680 (0.7646)\tPrec@1 82.000 (82.878)\tPrec@5 98.000 (98.220)\n",
            "Test: [50/261]\tTime 0.032 (0.029)\tLoss 0.6457 (0.7504)\tPrec@1 82.000 (82.804)\tPrec@5 99.000 (98.255)\n",
            "Test: [60/261]\tTime 0.033 (0.029)\tLoss 0.9322 (0.7556)\tPrec@1 81.000 (82.787)\tPrec@5 97.000 (98.197)\n",
            "Test: [70/261]\tTime 0.044 (0.028)\tLoss 0.6547 (0.7545)\tPrec@1 79.000 (82.845)\tPrec@5 98.000 (98.113)\n",
            "Test: [80/261]\tTime 0.016 (0.027)\tLoss 0.8012 (0.7548)\tPrec@1 80.000 (82.765)\tPrec@5 98.000 (98.123)\n",
            "Test: [90/261]\tTime 0.034 (0.027)\tLoss 0.7546 (0.7770)\tPrec@1 84.000 (82.714)\tPrec@5 97.000 (97.978)\n",
            "Test: [100/261]\tTime 0.017 (0.027)\tLoss 0.8234 (0.7735)\tPrec@1 79.000 (82.663)\tPrec@5 98.000 (97.941)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.7769 (0.7706)\tPrec@1 85.000 (82.667)\tPrec@5 98.000 (97.955)\n",
            "Test: [120/261]\tTime 0.028 (0.026)\tLoss 0.6416 (0.7713)\tPrec@1 86.000 (82.645)\tPrec@5 97.000 (97.983)\n",
            "Test: [130/261]\tTime 0.045 (0.026)\tLoss 0.8705 (0.7770)\tPrec@1 83.000 (82.634)\tPrec@5 97.000 (97.924)\n",
            "Test: [140/261]\tTime 0.013 (0.026)\tLoss 0.6518 (0.7693)\tPrec@1 80.000 (82.780)\tPrec@5 99.000 (97.979)\n",
            "Test: [150/261]\tTime 0.024 (0.026)\tLoss 0.6213 (0.7724)\tPrec@1 84.000 (82.775)\tPrec@5 98.000 (97.987)\n",
            "Test: [160/261]\tTime 0.017 (0.025)\tLoss 0.4481 (0.7713)\tPrec@1 88.000 (82.832)\tPrec@5 100.000 (98.006)\n",
            "Test: [170/261]\tTime 0.021 (0.025)\tLoss 0.5950 (0.7670)\tPrec@1 86.000 (82.918)\tPrec@5 96.000 (98.006)\n",
            "Test: [180/261]\tTime 0.026 (0.025)\tLoss 0.6815 (0.7692)\tPrec@1 87.000 (82.961)\tPrec@5 94.000 (97.950)\n",
            "Test: [190/261]\tTime 0.026 (0.025)\tLoss 0.5754 (0.7686)\tPrec@1 85.000 (82.979)\tPrec@5 100.000 (97.995)\n",
            "Test: [200/261]\tTime 0.018 (0.025)\tLoss 0.6827 (0.7691)\tPrec@1 87.000 (82.965)\tPrec@5 97.000 (97.955)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.7254 (0.7692)\tPrec@1 84.000 (82.976)\tPrec@5 97.000 (97.976)\n",
            "Test: [220/261]\tTime 0.030 (0.025)\tLoss 0.8964 (0.7700)\tPrec@1 81.000 (82.896)\tPrec@5 98.000 (97.995)\n",
            "Test: [230/261]\tTime 0.026 (0.025)\tLoss 0.8507 (0.7745)\tPrec@1 85.000 (82.848)\tPrec@5 96.000 (97.952)\n",
            "Test: [240/261]\tTime 0.012 (0.025)\tLoss 0.6724 (0.7750)\tPrec@1 83.000 (82.855)\tPrec@5 99.000 (97.929)\n",
            "Test: [250/261]\tTime 0.020 (0.025)\tLoss 0.5671 (0.7706)\tPrec@1 84.000 (82.912)\tPrec@5 99.000 (97.940)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4446 (0.7725)\tPrec@1 90.625 (82.913)\tPrec@5 96.875 (97.941)\n",
            "val Results: Prec@1 82.913 Prec@5 97.941 Loss 0.77249\n",
            "val Class Accuracy: [0.728,0.962,0.929,0.700,0.901,0.803,0.890,0.738,0.621,0.671]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [109][0/66], lr: 0.01000\tTime 0.591 (0.591)\tData 0.494 (0.494)\tLoss 0.0487 (0.0487)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][10/66], lr: 0.01000\tTime 0.094 (0.138)\tData 0.004 (0.051)\tLoss 0.0395 (0.0535)\tPrec@1 98.438 (98.011)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][20/66], lr: 0.01000\tTime 0.092 (0.117)\tData 0.001 (0.030)\tLoss 0.0191 (0.0492)\tPrec@1 100.000 (98.270)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][30/66], lr: 0.01000\tTime 0.099 (0.109)\tData 0.000 (0.022)\tLoss 0.0388 (0.0494)\tPrec@1 98.438 (98.311)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][40/66], lr: 0.01000\tTime 0.101 (0.106)\tData 0.005 (0.018)\tLoss 0.0414 (0.0537)\tPrec@1 97.266 (98.075)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [109][50/66], lr: 0.01000\tTime 0.108 (0.103)\tData 0.001 (0.015)\tLoss 0.0746 (0.0543)\tPrec@1 97.656 (98.070)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [109][60/66], lr: 0.01000\tTime 0.074 (0.100)\tData 0.000 (0.014)\tLoss 0.0639 (0.0551)\tPrec@1 98.047 (98.040)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.262 (0.262)\tLoss 0.7989 (0.7989)\tPrec@1 86.000 (86.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.036 (0.051)\tLoss 1.4197 (0.9827)\tPrec@1 80.000 (79.909)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/261]\tTime 0.035 (0.038)\tLoss 1.1511 (0.9763)\tPrec@1 82.000 (80.333)\tPrec@5 97.000 (97.190)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.7805 (0.9130)\tPrec@1 81.000 (81.387)\tPrec@5 99.000 (97.613)\n",
            "Test: [40/261]\tTime 0.015 (0.031)\tLoss 0.6483 (0.8874)\tPrec@1 88.000 (81.805)\tPrec@5 98.000 (97.902)\n",
            "Test: [50/261]\tTime 0.009 (0.028)\tLoss 0.9736 (0.8893)\tPrec@1 80.000 (81.725)\tPrec@5 96.000 (97.941)\n",
            "Test: [60/261]\tTime 0.026 (0.028)\tLoss 0.8721 (0.8864)\tPrec@1 81.000 (81.721)\tPrec@5 98.000 (97.869)\n",
            "Test: [70/261]\tTime 0.036 (0.028)\tLoss 0.9933 (0.8861)\tPrec@1 74.000 (81.789)\tPrec@5 99.000 (97.944)\n",
            "Test: [80/261]\tTime 0.024 (0.027)\tLoss 1.1950 (0.8946)\tPrec@1 77.000 (81.815)\tPrec@5 97.000 (97.938)\n",
            "Test: [90/261]\tTime 0.022 (0.027)\tLoss 1.0547 (0.9284)\tPrec@1 77.000 (81.473)\tPrec@5 98.000 (97.802)\n",
            "Test: [100/261]\tTime 0.029 (0.027)\tLoss 1.2499 (0.9291)\tPrec@1 78.000 (81.396)\tPrec@5 96.000 (97.723)\n",
            "Test: [110/261]\tTime 0.009 (0.026)\tLoss 0.9884 (0.9276)\tPrec@1 82.000 (81.333)\tPrec@5 99.000 (97.784)\n",
            "Test: [120/261]\tTime 0.043 (0.026)\tLoss 0.9451 (0.9223)\tPrec@1 82.000 (81.388)\tPrec@5 97.000 (97.777)\n",
            "Test: [130/261]\tTime 0.009 (0.026)\tLoss 0.9943 (0.9250)\tPrec@1 75.000 (81.275)\tPrec@5 96.000 (97.786)\n",
            "Test: [140/261]\tTime 0.021 (0.025)\tLoss 1.0427 (0.9211)\tPrec@1 77.000 (81.305)\tPrec@5 96.000 (97.773)\n",
            "Test: [150/261]\tTime 0.033 (0.026)\tLoss 0.8304 (0.9223)\tPrec@1 79.000 (81.285)\tPrec@5 98.000 (97.742)\n",
            "Test: [160/261]\tTime 0.022 (0.025)\tLoss 0.4658 (0.9194)\tPrec@1 87.000 (81.304)\tPrec@5 100.000 (97.727)\n",
            "Test: [170/261]\tTime 0.019 (0.025)\tLoss 0.7565 (0.9096)\tPrec@1 84.000 (81.474)\tPrec@5 97.000 (97.696)\n",
            "Test: [180/261]\tTime 0.018 (0.025)\tLoss 0.7707 (0.9126)\tPrec@1 87.000 (81.425)\tPrec@5 95.000 (97.657)\n",
            "Test: [190/261]\tTime 0.027 (0.025)\tLoss 0.8629 (0.9086)\tPrec@1 81.000 (81.487)\tPrec@5 99.000 (97.691)\n",
            "Test: [200/261]\tTime 0.029 (0.025)\tLoss 1.1125 (0.9120)\tPrec@1 83.000 (81.478)\tPrec@5 97.000 (97.677)\n",
            "Test: [210/261]\tTime 0.027 (0.025)\tLoss 0.8109 (0.9105)\tPrec@1 82.000 (81.479)\tPrec@5 97.000 (97.659)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 0.9528 (0.9105)\tPrec@1 80.000 (81.425)\tPrec@5 99.000 (97.688)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 0.9345 (0.9108)\tPrec@1 79.000 (81.403)\tPrec@5 98.000 (97.697)\n",
            "Test: [240/261]\tTime 0.031 (0.025)\tLoss 0.5621 (0.9123)\tPrec@1 89.000 (81.440)\tPrec@5 98.000 (97.705)\n",
            "Test: [250/261]\tTime 0.015 (0.025)\tLoss 0.7381 (0.9097)\tPrec@1 82.000 (81.430)\tPrec@5 99.000 (97.713)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.7182 (0.9139)\tPrec@1 90.625 (81.407)\tPrec@5 96.875 (97.714)\n",
            "val Results: Prec@1 81.407 Prec@5 97.714 Loss 0.91387\n",
            "val Class Accuracy: [0.712,0.976,0.865,0.888,0.797,0.820,0.833,0.508,0.742,0.598]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [110][0/66], lr: 0.01000\tTime 0.566 (0.566)\tData 0.480 (0.480)\tLoss 0.0542 (0.0542)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][10/66], lr: 0.01000\tTime 0.094 (0.135)\tData 0.000 (0.050)\tLoss 0.0366 (0.0453)\tPrec@1 98.828 (98.651)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][20/66], lr: 0.01000\tTime 0.072 (0.115)\tData 0.005 (0.034)\tLoss 0.0295 (0.0437)\tPrec@1 99.219 (98.642)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][30/66], lr: 0.01000\tTime 0.105 (0.108)\tData 0.000 (0.025)\tLoss 0.0298 (0.0469)\tPrec@1 98.828 (98.614)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][40/66], lr: 0.01000\tTime 0.092 (0.103)\tData 0.005 (0.020)\tLoss 0.0321 (0.0464)\tPrec@1 98.828 (98.571)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][50/66], lr: 0.01000\tTime 0.111 (0.102)\tData 0.003 (0.017)\tLoss 0.0627 (0.0480)\tPrec@1 98.047 (98.483)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [110][60/66], lr: 0.01000\tTime 0.073 (0.100)\tData 0.000 (0.016)\tLoss 0.0830 (0.0522)\tPrec@1 97.266 (98.316)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.317 (0.317)\tLoss 0.6091 (0.6091)\tPrec@1 87.000 (87.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.020 (0.052)\tLoss 1.1336 (0.8330)\tPrec@1 79.000 (81.273)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/261]\tTime 0.017 (0.038)\tLoss 1.0418 (0.8261)\tPrec@1 74.000 (81.333)\tPrec@5 97.000 (97.667)\n",
            "Test: [30/261]\tTime 0.023 (0.033)\tLoss 0.5877 (0.7852)\tPrec@1 90.000 (82.710)\tPrec@5 98.000 (97.903)\n",
            "Test: [40/261]\tTime 0.032 (0.031)\tLoss 0.6810 (0.7632)\tPrec@1 83.000 (83.171)\tPrec@5 98.000 (98.122)\n",
            "Test: [50/261]\tTime 0.032 (0.029)\tLoss 0.6031 (0.7531)\tPrec@1 87.000 (83.549)\tPrec@5 98.000 (98.137)\n",
            "Test: [60/261]\tTime 0.026 (0.028)\tLoss 0.8162 (0.7493)\tPrec@1 82.000 (83.770)\tPrec@5 98.000 (98.131)\n",
            "Test: [70/261]\tTime 0.024 (0.027)\tLoss 0.7407 (0.7542)\tPrec@1 83.000 (83.761)\tPrec@5 98.000 (98.169)\n",
            "Test: [80/261]\tTime 0.019 (0.027)\tLoss 0.6365 (0.7511)\tPrec@1 84.000 (83.667)\tPrec@5 98.000 (98.099)\n",
            "Test: [90/261]\tTime 0.018 (0.027)\tLoss 1.0070 (0.7803)\tPrec@1 85.000 (83.308)\tPrec@5 95.000 (97.989)\n",
            "Test: [100/261]\tTime 0.041 (0.027)\tLoss 1.0544 (0.7764)\tPrec@1 79.000 (83.386)\tPrec@5 95.000 (97.990)\n",
            "Test: [110/261]\tTime 0.030 (0.026)\tLoss 0.6093 (0.7719)\tPrec@1 86.000 (83.405)\tPrec@5 99.000 (98.000)\n",
            "Test: [120/261]\tTime 0.033 (0.026)\tLoss 0.7397 (0.7718)\tPrec@1 88.000 (83.471)\tPrec@5 96.000 (97.992)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.6347 (0.7725)\tPrec@1 84.000 (83.527)\tPrec@5 99.000 (97.992)\n",
            "Test: [140/261]\tTime 0.034 (0.026)\tLoss 0.7401 (0.7714)\tPrec@1 81.000 (83.518)\tPrec@5 98.000 (98.014)\n",
            "Test: [150/261]\tTime 0.029 (0.025)\tLoss 0.5628 (0.7721)\tPrec@1 84.000 (83.523)\tPrec@5 98.000 (98.013)\n",
            "Test: [160/261]\tTime 0.010 (0.025)\tLoss 0.3877 (0.7710)\tPrec@1 86.000 (83.497)\tPrec@5 99.000 (98.012)\n",
            "Test: [170/261]\tTime 0.027 (0.025)\tLoss 0.6984 (0.7676)\tPrec@1 86.000 (83.602)\tPrec@5 95.000 (97.982)\n",
            "Test: [180/261]\tTime 0.028 (0.025)\tLoss 0.7635 (0.7723)\tPrec@1 87.000 (83.508)\tPrec@5 97.000 (97.972)\n",
            "Test: [190/261]\tTime 0.021 (0.025)\tLoss 0.6422 (0.7725)\tPrec@1 87.000 (83.461)\tPrec@5 100.000 (98.000)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 0.5097 (0.7716)\tPrec@1 87.000 (83.423)\tPrec@5 97.000 (98.000)\n",
            "Test: [210/261]\tTime 0.029 (0.025)\tLoss 0.6264 (0.7697)\tPrec@1 87.000 (83.521)\tPrec@5 100.000 (98.005)\n",
            "Test: [220/261]\tTime 0.014 (0.025)\tLoss 0.5219 (0.7652)\tPrec@1 85.000 (83.529)\tPrec@5 100.000 (98.023)\n",
            "Test: [230/261]\tTime 0.010 (0.025)\tLoss 0.9049 (0.7680)\tPrec@1 84.000 (83.472)\tPrec@5 98.000 (98.022)\n",
            "Test: [240/261]\tTime 0.020 (0.025)\tLoss 0.7483 (0.7702)\tPrec@1 85.000 (83.498)\tPrec@5 97.000 (98.000)\n",
            "Test: [250/261]\tTime 0.021 (0.025)\tLoss 0.7208 (0.7679)\tPrec@1 82.000 (83.558)\tPrec@5 100.000 (98.000)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4045 (0.7682)\tPrec@1 90.625 (83.532)\tPrec@5 100.000 (97.995)\n",
            "val Results: Prec@1 83.532 Prec@5 97.995 Loss 0.76818\n",
            "val Class Accuracy: [0.593,0.947,0.907,0.769,0.938,0.904,0.831,0.854,0.539,0.699]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [111][0/66], lr: 0.01000\tTime 0.581 (0.581)\tData 0.491 (0.491)\tLoss 0.0592 (0.0592)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][10/66], lr: 0.01000\tTime 0.076 (0.139)\tData 0.005 (0.050)\tLoss 0.0704 (0.0719)\tPrec@1 97.656 (97.976)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][20/66], lr: 0.01000\tTime 0.103 (0.117)\tData 0.000 (0.028)\tLoss 0.0438 (0.0664)\tPrec@1 99.219 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][30/66], lr: 0.01000\tTime 0.091 (0.107)\tData 0.007 (0.021)\tLoss 0.0744 (0.0638)\tPrec@1 97.656 (98.034)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][40/66], lr: 0.01000\tTime 0.075 (0.104)\tData 0.000 (0.017)\tLoss 0.0474 (0.0636)\tPrec@1 98.438 (97.971)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][50/66], lr: 0.01000\tTime 0.081 (0.103)\tData 0.004 (0.015)\tLoss 0.0478 (0.0602)\tPrec@1 98.047 (98.070)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [111][60/66], lr: 0.01000\tTime 0.076 (0.100)\tData 0.000 (0.013)\tLoss 0.0348 (0.0569)\tPrec@1 99.219 (98.162)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.266 (0.266)\tLoss 1.0473 (1.0473)\tPrec@1 78.000 (78.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.042 (0.047)\tLoss 1.3469 (1.0869)\tPrec@1 73.000 (77.909)\tPrec@5 97.000 (96.727)\n",
            "Test: [20/261]\tTime 0.018 (0.037)\tLoss 1.1981 (1.0667)\tPrec@1 80.000 (78.952)\tPrec@5 97.000 (96.810)\n",
            "Test: [30/261]\tTime 0.026 (0.033)\tLoss 0.5755 (1.0272)\tPrec@1 86.000 (79.581)\tPrec@5 97.000 (97.097)\n",
            "Test: [40/261]\tTime 0.033 (0.030)\tLoss 0.7180 (0.9754)\tPrec@1 85.000 (80.268)\tPrec@5 98.000 (97.439)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.9512 (0.9660)\tPrec@1 79.000 (80.412)\tPrec@5 97.000 (97.471)\n",
            "Test: [60/261]\tTime 0.012 (0.028)\tLoss 1.0794 (0.9671)\tPrec@1 76.000 (80.377)\tPrec@5 96.000 (97.459)\n",
            "Test: [70/261]\tTime 0.023 (0.028)\tLoss 0.9927 (0.9748)\tPrec@1 81.000 (80.408)\tPrec@5 99.000 (97.493)\n",
            "Test: [80/261]\tTime 0.015 (0.027)\tLoss 1.1346 (0.9829)\tPrec@1 80.000 (80.370)\tPrec@5 95.000 (97.457)\n",
            "Test: [90/261]\tTime 0.024 (0.026)\tLoss 1.0644 (1.0040)\tPrec@1 80.000 (80.275)\tPrec@5 97.000 (97.330)\n",
            "Test: [100/261]\tTime 0.024 (0.027)\tLoss 0.8791 (0.9924)\tPrec@1 82.000 (80.495)\tPrec@5 97.000 (97.406)\n",
            "Test: [110/261]\tTime 0.022 (0.026)\tLoss 1.0397 (0.9897)\tPrec@1 81.000 (80.477)\tPrec@5 98.000 (97.423)\n",
            "Test: [120/261]\tTime 0.024 (0.026)\tLoss 0.9353 (0.9869)\tPrec@1 83.000 (80.496)\tPrec@5 97.000 (97.405)\n",
            "Test: [130/261]\tTime 0.031 (0.026)\tLoss 0.9762 (0.9902)\tPrec@1 82.000 (80.466)\tPrec@5 95.000 (97.351)\n",
            "Test: [140/261]\tTime 0.022 (0.026)\tLoss 1.1183 (0.9891)\tPrec@1 80.000 (80.468)\tPrec@5 96.000 (97.376)\n",
            "Test: [150/261]\tTime 0.032 (0.026)\tLoss 0.5958 (0.9888)\tPrec@1 84.000 (80.470)\tPrec@5 98.000 (97.358)\n",
            "Test: [160/261]\tTime 0.030 (0.025)\tLoss 0.6264 (0.9872)\tPrec@1 84.000 (80.553)\tPrec@5 100.000 (97.385)\n",
            "Test: [170/261]\tTime 0.027 (0.025)\tLoss 0.9228 (0.9793)\tPrec@1 82.000 (80.632)\tPrec@5 97.000 (97.386)\n",
            "Test: [180/261]\tTime 0.029 (0.025)\tLoss 0.7312 (0.9794)\tPrec@1 84.000 (80.602)\tPrec@5 96.000 (97.387)\n",
            "Test: [190/261]\tTime 0.013 (0.025)\tLoss 0.7579 (0.9775)\tPrec@1 84.000 (80.639)\tPrec@5 99.000 (97.435)\n",
            "Test: [200/261]\tTime 0.010 (0.025)\tLoss 0.8051 (0.9749)\tPrec@1 82.000 (80.632)\tPrec@5 98.000 (97.423)\n",
            "Test: [210/261]\tTime 0.039 (0.025)\tLoss 0.7612 (0.9757)\tPrec@1 80.000 (80.645)\tPrec@5 98.000 (97.422)\n",
            "Test: [220/261]\tTime 0.018 (0.025)\tLoss 1.1454 (0.9746)\tPrec@1 78.000 (80.647)\tPrec@5 94.000 (97.421)\n",
            "Test: [230/261]\tTime 0.037 (0.025)\tLoss 1.2740 (0.9765)\tPrec@1 76.000 (80.610)\tPrec@5 95.000 (97.385)\n",
            "Test: [240/261]\tTime 0.018 (0.025)\tLoss 0.9584 (0.9813)\tPrec@1 84.000 (80.539)\tPrec@5 97.000 (97.390)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 1.0132 (0.9770)\tPrec@1 77.000 (80.586)\tPrec@5 97.000 (97.398)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4275 (0.9796)\tPrec@1 90.625 (80.570)\tPrec@5 96.875 (97.372)\n",
            "val Results: Prec@1 80.570 Prec@5 97.372 Loss 0.97956\n",
            "val Class Accuracy: [0.546,0.974,0.917,0.844,0.860,0.916,0.595,0.690,0.659,0.502]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [112][0/66], lr: 0.01000\tTime 0.604 (0.604)\tData 0.542 (0.542)\tLoss 0.0333 (0.0333)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][10/66], lr: 0.01000\tTime 0.095 (0.142)\tData 0.000 (0.054)\tLoss 0.0987 (0.0582)\tPrec@1 97.656 (97.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][20/66], lr: 0.01000\tTime 0.081 (0.117)\tData 0.000 (0.031)\tLoss 0.0294 (0.0556)\tPrec@1 99.219 (98.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][30/66], lr: 0.01000\tTime 0.101 (0.110)\tData 0.006 (0.023)\tLoss 0.0303 (0.0537)\tPrec@1 99.219 (98.223)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [112][40/66], lr: 0.01000\tTime 0.096 (0.105)\tData 0.009 (0.019)\tLoss 0.1318 (0.0559)\tPrec@1 96.484 (98.180)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [112][50/66], lr: 0.01000\tTime 0.086 (0.103)\tData 0.005 (0.017)\tLoss 0.0298 (0.0570)\tPrec@1 99.219 (98.093)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [112][60/66], lr: 0.01000\tTime 0.079 (0.100)\tData 0.000 (0.015)\tLoss 0.0330 (0.0555)\tPrec@1 99.219 (98.137)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.232 (0.232)\tLoss 0.8696 (0.8696)\tPrec@1 85.000 (85.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.021 (0.046)\tLoss 1.2188 (0.8032)\tPrec@1 82.000 (83.364)\tPrec@5 96.000 (97.909)\n",
            "Test: [20/261]\tTime 0.018 (0.036)\tLoss 1.2038 (0.8145)\tPrec@1 79.000 (83.190)\tPrec@5 97.000 (97.857)\n",
            "Test: [30/261]\tTime 0.016 (0.031)\tLoss 0.7180 (0.7460)\tPrec@1 84.000 (84.194)\tPrec@5 96.000 (98.194)\n",
            "Test: [40/261]\tTime 0.034 (0.029)\tLoss 0.6422 (0.7449)\tPrec@1 91.000 (84.439)\tPrec@5 97.000 (98.122)\n",
            "Test: [50/261]\tTime 0.033 (0.029)\tLoss 0.5818 (0.7347)\tPrec@1 82.000 (84.549)\tPrec@5 99.000 (98.118)\n",
            "Test: [60/261]\tTime 0.021 (0.028)\tLoss 0.8789 (0.7451)\tPrec@1 82.000 (84.426)\tPrec@5 99.000 (98.082)\n",
            "Test: [70/261]\tTime 0.019 (0.027)\tLoss 0.7096 (0.7562)\tPrec@1 82.000 (84.254)\tPrec@5 98.000 (98.099)\n",
            "Test: [80/261]\tTime 0.025 (0.027)\tLoss 0.6860 (0.7592)\tPrec@1 82.000 (84.074)\tPrec@5 98.000 (98.037)\n",
            "Test: [90/261]\tTime 0.028 (0.027)\tLoss 0.7460 (0.7832)\tPrec@1 86.000 (83.890)\tPrec@5 97.000 (97.945)\n",
            "Test: [100/261]\tTime 0.029 (0.026)\tLoss 1.1095 (0.7808)\tPrec@1 80.000 (83.901)\tPrec@5 95.000 (97.871)\n",
            "Test: [110/261]\tTime 0.023 (0.026)\tLoss 0.7497 (0.7800)\tPrec@1 85.000 (83.847)\tPrec@5 99.000 (97.910)\n",
            "Test: [120/261]\tTime 0.026 (0.026)\tLoss 0.8305 (0.7769)\tPrec@1 89.000 (83.926)\tPrec@5 95.000 (97.884)\n",
            "Test: [130/261]\tTime 0.037 (0.026)\tLoss 0.8980 (0.7844)\tPrec@1 80.000 (83.748)\tPrec@5 97.000 (97.809)\n",
            "Test: [140/261]\tTime 0.026 (0.026)\tLoss 0.9634 (0.7772)\tPrec@1 74.000 (83.766)\tPrec@5 99.000 (97.823)\n",
            "Test: [150/261]\tTime 0.013 (0.026)\tLoss 0.7437 (0.7769)\tPrec@1 81.000 (83.801)\tPrec@5 97.000 (97.841)\n",
            "Test: [160/261]\tTime 0.013 (0.026)\tLoss 0.4825 (0.7755)\tPrec@1 88.000 (83.851)\tPrec@5 99.000 (97.863)\n",
            "Test: [170/261]\tTime 0.016 (0.026)\tLoss 0.6079 (0.7728)\tPrec@1 90.000 (83.942)\tPrec@5 97.000 (97.871)\n",
            "Test: [180/261]\tTime 0.016 (0.026)\tLoss 0.9395 (0.7763)\tPrec@1 84.000 (83.906)\tPrec@5 94.000 (97.840)\n",
            "Test: [190/261]\tTime 0.031 (0.026)\tLoss 0.6592 (0.7714)\tPrec@1 82.000 (83.942)\tPrec@5 99.000 (97.874)\n",
            "Test: [200/261]\tTime 0.030 (0.025)\tLoss 0.7239 (0.7742)\tPrec@1 83.000 (83.856)\tPrec@5 96.000 (97.856)\n",
            "Test: [210/261]\tTime 0.023 (0.025)\tLoss 0.8514 (0.7744)\tPrec@1 84.000 (83.877)\tPrec@5 96.000 (97.844)\n",
            "Test: [220/261]\tTime 0.035 (0.025)\tLoss 0.8153 (0.7742)\tPrec@1 86.000 (83.851)\tPrec@5 98.000 (97.878)\n",
            "Test: [230/261]\tTime 0.035 (0.025)\tLoss 1.1007 (0.7774)\tPrec@1 78.000 (83.766)\tPrec@5 95.000 (97.874)\n",
            "Test: [240/261]\tTime 0.028 (0.025)\tLoss 0.5575 (0.7770)\tPrec@1 90.000 (83.822)\tPrec@5 99.000 (97.851)\n",
            "Test: [250/261]\tTime 0.025 (0.025)\tLoss 0.5927 (0.7739)\tPrec@1 88.000 (83.876)\tPrec@5 100.000 (97.873)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.5572 (0.7735)\tPrec@1 90.625 (83.866)\tPrec@5 100.000 (97.883)\n",
            "val Results: Prec@1 83.866 Prec@5 97.883 Loss 0.77351\n",
            "val Class Accuracy: [0.809,0.976,0.887,0.715,0.889,0.797,0.814,0.746,0.655,0.851]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [113][0/66], lr: 0.01000\tTime 0.653 (0.653)\tData 0.559 (0.559)\tLoss 0.0171 (0.0171)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][10/66], lr: 0.01000\tTime 0.104 (0.147)\tData 0.013 (0.056)\tLoss 0.0373 (0.0466)\tPrec@1 98.828 (98.544)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][20/66], lr: 0.01000\tTime 0.099 (0.121)\tData 0.000 (0.032)\tLoss 0.0319 (0.0441)\tPrec@1 99.219 (98.568)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][30/66], lr: 0.01000\tTime 0.096 (0.113)\tData 0.007 (0.023)\tLoss 0.0916 (0.0480)\tPrec@1 96.875 (98.425)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][40/66], lr: 0.01000\tTime 0.092 (0.107)\tData 0.006 (0.019)\tLoss 0.0340 (0.0488)\tPrec@1 99.219 (98.380)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [113][50/66], lr: 0.01000\tTime 0.077 (0.104)\tData 0.006 (0.017)\tLoss 0.0418 (0.0492)\tPrec@1 98.047 (98.392)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [113][60/66], lr: 0.01000\tTime 0.079 (0.101)\tData 0.000 (0.015)\tLoss 0.0965 (0.0508)\tPrec@1 96.094 (98.341)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.283 (0.283)\tLoss 0.7022 (0.7022)\tPrec@1 86.000 (86.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.022 (0.047)\tLoss 1.1505 (0.7648)\tPrec@1 81.000 (83.000)\tPrec@5 100.000 (98.000)\n",
            "Test: [20/261]\tTime 0.035 (0.036)\tLoss 0.9237 (0.7638)\tPrec@1 80.000 (83.286)\tPrec@5 95.000 (97.571)\n",
            "Test: [30/261]\tTime 0.023 (0.032)\tLoss 0.5285 (0.7119)\tPrec@1 87.000 (84.452)\tPrec@5 99.000 (97.968)\n",
            "Test: [40/261]\tTime 0.013 (0.030)\tLoss 0.6024 (0.6825)\tPrec@1 87.000 (85.024)\tPrec@5 98.000 (98.098)\n",
            "Test: [50/261]\tTime 0.024 (0.029)\tLoss 0.6071 (0.6716)\tPrec@1 87.000 (85.176)\tPrec@5 97.000 (98.176)\n",
            "Test: [60/261]\tTime 0.029 (0.028)\tLoss 0.5251 (0.6651)\tPrec@1 88.000 (85.443)\tPrec@5 98.000 (98.180)\n",
            "Test: [70/261]\tTime 0.027 (0.027)\tLoss 0.5721 (0.6641)\tPrec@1 86.000 (85.592)\tPrec@5 100.000 (98.254)\n",
            "Test: [80/261]\tTime 0.013 (0.027)\tLoss 0.5231 (0.6577)\tPrec@1 87.000 (85.704)\tPrec@5 99.000 (98.259)\n",
            "Test: [90/261]\tTime 0.019 (0.027)\tLoss 0.7196 (0.6804)\tPrec@1 83.000 (85.374)\tPrec@5 98.000 (98.121)\n",
            "Test: [100/261]\tTime 0.013 (0.026)\tLoss 0.8193 (0.6697)\tPrec@1 85.000 (85.495)\tPrec@5 96.000 (98.149)\n",
            "Test: [110/261]\tTime 0.010 (0.026)\tLoss 0.6573 (0.6654)\tPrec@1 88.000 (85.631)\tPrec@5 97.000 (98.144)\n",
            "Test: [120/261]\tTime 0.030 (0.026)\tLoss 0.7047 (0.6666)\tPrec@1 87.000 (85.628)\tPrec@5 97.000 (98.132)\n",
            "Test: [130/261]\tTime 0.012 (0.026)\tLoss 0.6428 (0.6687)\tPrec@1 89.000 (85.672)\tPrec@5 98.000 (98.084)\n",
            "Test: [140/261]\tTime 0.043 (0.026)\tLoss 0.7404 (0.6652)\tPrec@1 82.000 (85.652)\tPrec@5 99.000 (98.142)\n",
            "Test: [150/261]\tTime 0.038 (0.025)\tLoss 0.4402 (0.6686)\tPrec@1 88.000 (85.589)\tPrec@5 100.000 (98.132)\n",
            "Test: [160/261]\tTime 0.036 (0.025)\tLoss 0.3823 (0.6654)\tPrec@1 89.000 (85.658)\tPrec@5 100.000 (98.180)\n",
            "Test: [170/261]\tTime 0.039 (0.025)\tLoss 0.6555 (0.6643)\tPrec@1 90.000 (85.696)\tPrec@5 97.000 (98.175)\n",
            "Test: [180/261]\tTime 0.027 (0.025)\tLoss 0.6447 (0.6638)\tPrec@1 84.000 (85.663)\tPrec@5 95.000 (98.193)\n",
            "Test: [190/261]\tTime 0.025 (0.025)\tLoss 0.5951 (0.6615)\tPrec@1 88.000 (85.728)\tPrec@5 98.000 (98.209)\n",
            "Test: [200/261]\tTime 0.040 (0.025)\tLoss 0.4728 (0.6591)\tPrec@1 89.000 (85.692)\tPrec@5 97.000 (98.199)\n",
            "Test: [210/261]\tTime 0.022 (0.025)\tLoss 0.4181 (0.6579)\tPrec@1 88.000 (85.720)\tPrec@5 99.000 (98.204)\n",
            "Test: [220/261]\tTime 0.039 (0.025)\tLoss 0.7145 (0.6579)\tPrec@1 85.000 (85.710)\tPrec@5 100.000 (98.226)\n",
            "Test: [230/261]\tTime 0.029 (0.025)\tLoss 0.9008 (0.6607)\tPrec@1 79.000 (85.654)\tPrec@5 97.000 (98.208)\n",
            "Test: [240/261]\tTime 0.020 (0.025)\tLoss 0.6289 (0.6638)\tPrec@1 88.000 (85.627)\tPrec@5 98.000 (98.183)\n",
            "Test: [250/261]\tTime 0.022 (0.025)\tLoss 0.3561 (0.6591)\tPrec@1 89.000 (85.685)\tPrec@5 100.000 (98.199)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3526 (0.6603)\tPrec@1 96.875 (85.695)\tPrec@5 96.875 (98.187)\n",
            "val Results: Prec@1 85.695 Prec@5 98.187 Loss 0.66028\n",
            "val Class Accuracy: [0.709,0.954,0.920,0.868,0.933,0.812,0.830,0.856,0.683,0.687]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [114][0/66], lr: 0.01000\tTime 0.448 (0.448)\tData 0.362 (0.362)\tLoss 0.0414 (0.0414)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][10/66], lr: 0.01000\tTime 0.087 (0.134)\tData 0.006 (0.051)\tLoss 0.0488 (0.0448)\tPrec@1 98.047 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][20/66], lr: 0.01000\tTime 0.094 (0.116)\tData 0.006 (0.030)\tLoss 0.0692 (0.0538)\tPrec@1 97.656 (98.065)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][30/66], lr: 0.01000\tTime 0.093 (0.107)\tData 0.005 (0.022)\tLoss 0.0146 (0.0536)\tPrec@1 99.609 (98.097)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][40/66], lr: 0.01000\tTime 0.113 (0.103)\tData 0.000 (0.017)\tLoss 0.0551 (0.0522)\tPrec@1 98.047 (98.161)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [114][50/66], lr: 0.01000\tTime 0.085 (0.100)\tData 0.007 (0.015)\tLoss 0.0359 (0.0530)\tPrec@1 99.219 (98.185)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [114][60/66], lr: 0.01000\tTime 0.077 (0.098)\tData 0.000 (0.014)\tLoss 0.0439 (0.0531)\tPrec@1 98.438 (98.194)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.213 (0.213)\tLoss 0.9079 (0.9079)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.031 (0.052)\tLoss 1.2880 (0.8918)\tPrec@1 81.000 (81.727)\tPrec@5 96.000 (97.182)\n",
            "Test: [20/261]\tTime 0.035 (0.037)\tLoss 1.2668 (0.9031)\tPrec@1 74.000 (81.667)\tPrec@5 94.000 (97.286)\n",
            "Test: [30/261]\tTime 0.019 (0.032)\tLoss 0.6532 (0.8491)\tPrec@1 85.000 (82.484)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/261]\tTime 0.032 (0.030)\tLoss 0.6907 (0.8024)\tPrec@1 87.000 (82.976)\tPrec@5 99.000 (98.073)\n",
            "Test: [50/261]\tTime 0.026 (0.029)\tLoss 0.5740 (0.7814)\tPrec@1 87.000 (83.294)\tPrec@5 98.000 (98.137)\n",
            "Test: [60/261]\tTime 0.018 (0.028)\tLoss 0.6255 (0.7817)\tPrec@1 84.000 (83.295)\tPrec@5 98.000 (98.098)\n",
            "Test: [70/261]\tTime 0.020 (0.028)\tLoss 0.8998 (0.7874)\tPrec@1 78.000 (83.296)\tPrec@5 98.000 (98.113)\n",
            "Test: [80/261]\tTime 0.025 (0.026)\tLoss 0.7822 (0.7865)\tPrec@1 80.000 (83.346)\tPrec@5 99.000 (98.099)\n",
            "Test: [90/261]\tTime 0.013 (0.027)\tLoss 0.8311 (0.8102)\tPrec@1 84.000 (83.143)\tPrec@5 97.000 (97.978)\n",
            "Test: [100/261]\tTime 0.021 (0.026)\tLoss 1.0205 (0.7986)\tPrec@1 79.000 (83.248)\tPrec@5 96.000 (97.980)\n",
            "Test: [110/261]\tTime 0.030 (0.026)\tLoss 0.8490 (0.7916)\tPrec@1 82.000 (83.333)\tPrec@5 98.000 (97.973)\n",
            "Test: [120/261]\tTime 0.026 (0.026)\tLoss 0.6122 (0.7846)\tPrec@1 88.000 (83.430)\tPrec@5 98.000 (97.967)\n",
            "Test: [130/261]\tTime 0.012 (0.026)\tLoss 0.9157 (0.7845)\tPrec@1 83.000 (83.382)\tPrec@5 98.000 (97.992)\n",
            "Test: [140/261]\tTime 0.014 (0.026)\tLoss 0.8380 (0.7828)\tPrec@1 79.000 (83.433)\tPrec@5 99.000 (98.028)\n",
            "Test: [150/261]\tTime 0.016 (0.025)\tLoss 0.6062 (0.7815)\tPrec@1 84.000 (83.464)\tPrec@5 98.000 (98.000)\n",
            "Test: [160/261]\tTime 0.022 (0.025)\tLoss 0.3050 (0.7809)\tPrec@1 91.000 (83.478)\tPrec@5 100.000 (98.000)\n",
            "Test: [170/261]\tTime 0.045 (0.026)\tLoss 0.7618 (0.7759)\tPrec@1 84.000 (83.532)\tPrec@5 98.000 (98.006)\n",
            "Test: [180/261]\tTime 0.018 (0.025)\tLoss 0.7373 (0.7804)\tPrec@1 88.000 (83.470)\tPrec@5 96.000 (98.006)\n",
            "Test: [190/261]\tTime 0.046 (0.025)\tLoss 0.6597 (0.7748)\tPrec@1 85.000 (83.524)\tPrec@5 99.000 (98.026)\n",
            "Test: [200/261]\tTime 0.037 (0.025)\tLoss 0.7780 (0.7756)\tPrec@1 86.000 (83.428)\tPrec@5 98.000 (98.015)\n",
            "Test: [210/261]\tTime 0.042 (0.025)\tLoss 0.6017 (0.7736)\tPrec@1 83.000 (83.479)\tPrec@5 99.000 (98.047)\n",
            "Test: [220/261]\tTime 0.024 (0.025)\tLoss 0.7929 (0.7717)\tPrec@1 81.000 (83.484)\tPrec@5 97.000 (98.068)\n",
            "Test: [230/261]\tTime 0.022 (0.025)\tLoss 0.9207 (0.7740)\tPrec@1 77.000 (83.442)\tPrec@5 96.000 (98.026)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.6165 (0.7759)\tPrec@1 89.000 (83.469)\tPrec@5 98.000 (98.000)\n",
            "Test: [250/261]\tTime 0.021 (0.025)\tLoss 0.5631 (0.7694)\tPrec@1 84.000 (83.530)\tPrec@5 100.000 (98.004)\n",
            "Test: [260/261]\tTime 0.008 (0.025)\tLoss 0.3745 (0.7695)\tPrec@1 90.625 (83.536)\tPrec@5 100.000 (97.979)\n",
            "val Results: Prec@1 83.536 Prec@5 97.979 Loss 0.76952\n",
            "val Class Accuracy: [0.708,0.950,0.942,0.888,0.906,0.812,0.687,0.772,0.590,0.676]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [115][0/66], lr: 0.01000\tTime 0.870 (0.870)\tData 0.697 (0.697)\tLoss 0.0512 (0.0512)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][10/66], lr: 0.01000\tTime 0.072 (0.190)\tData 0.000 (0.093)\tLoss 0.0379 (0.0572)\tPrec@1 98.438 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][20/66], lr: 0.01000\tTime 0.092 (0.163)\tData 0.007 (0.070)\tLoss 0.1285 (0.0559)\tPrec@1 96.875 (98.121)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][30/66], lr: 0.01000\tTime 0.092 (0.142)\tData 0.000 (0.050)\tLoss 0.0174 (0.0501)\tPrec@1 99.609 (98.349)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][40/66], lr: 0.01000\tTime 0.082 (0.130)\tData 0.001 (0.039)\tLoss 0.0369 (0.0476)\tPrec@1 98.828 (98.409)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [115][50/66], lr: 0.01000\tTime 0.081 (0.123)\tData 0.000 (0.032)\tLoss 0.0378 (0.0480)\tPrec@1 98.438 (98.415)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [115][60/66], lr: 0.01000\tTime 0.068 (0.118)\tData 0.000 (0.028)\tLoss 0.0461 (0.0472)\tPrec@1 98.438 (98.444)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.281 (0.281)\tLoss 0.6465 (0.6465)\tPrec@1 85.000 (85.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.020 (0.051)\tLoss 1.2710 (0.9110)\tPrec@1 78.000 (80.273)\tPrec@5 98.000 (96.636)\n",
            "Test: [20/261]\tTime 0.009 (0.036)\tLoss 1.0870 (0.8938)\tPrec@1 81.000 (80.952)\tPrec@5 95.000 (96.810)\n",
            "Test: [30/261]\tTime 0.024 (0.033)\tLoss 0.6422 (0.8453)\tPrec@1 86.000 (82.032)\tPrec@5 99.000 (97.194)\n",
            "Test: [40/261]\tTime 0.028 (0.030)\tLoss 0.6666 (0.8303)\tPrec@1 87.000 (82.317)\tPrec@5 98.000 (97.439)\n",
            "Test: [50/261]\tTime 0.023 (0.030)\tLoss 0.7474 (0.8278)\tPrec@1 79.000 (82.000)\tPrec@5 98.000 (97.510)\n",
            "Test: [60/261]\tTime 0.018 (0.029)\tLoss 0.8766 (0.8188)\tPrec@1 81.000 (82.115)\tPrec@5 96.000 (97.574)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 0.6149 (0.8224)\tPrec@1 83.000 (82.254)\tPrec@5 98.000 (97.662)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 0.7553 (0.8293)\tPrec@1 78.000 (81.827)\tPrec@5 99.000 (97.691)\n",
            "Test: [90/261]\tTime 0.022 (0.027)\tLoss 0.5998 (0.8469)\tPrec@1 87.000 (81.846)\tPrec@5 96.000 (97.571)\n",
            "Test: [100/261]\tTime 0.033 (0.027)\tLoss 0.9789 (0.8476)\tPrec@1 82.000 (81.842)\tPrec@5 97.000 (97.545)\n",
            "Test: [110/261]\tTime 0.036 (0.027)\tLoss 0.8573 (0.8383)\tPrec@1 81.000 (81.892)\tPrec@5 97.000 (97.577)\n",
            "Test: [120/261]\tTime 0.017 (0.026)\tLoss 0.7154 (0.8390)\tPrec@1 85.000 (81.826)\tPrec@5 96.000 (97.512)\n",
            "Test: [130/261]\tTime 0.011 (0.026)\tLoss 1.0038 (0.8426)\tPrec@1 76.000 (81.832)\tPrec@5 96.000 (97.443)\n",
            "Test: [140/261]\tTime 0.027 (0.026)\tLoss 1.0593 (0.8347)\tPrec@1 77.000 (81.872)\tPrec@5 96.000 (97.461)\n",
            "Test: [150/261]\tTime 0.033 (0.026)\tLoss 0.8046 (0.8392)\tPrec@1 82.000 (81.934)\tPrec@5 98.000 (97.450)\n",
            "Test: [160/261]\tTime 0.017 (0.026)\tLoss 0.5697 (0.8388)\tPrec@1 85.000 (81.882)\tPrec@5 100.000 (97.460)\n",
            "Test: [170/261]\tTime 0.027 (0.025)\tLoss 0.8077 (0.8323)\tPrec@1 85.000 (81.965)\tPrec@5 97.000 (97.462)\n",
            "Test: [180/261]\tTime 0.013 (0.025)\tLoss 0.8217 (0.8361)\tPrec@1 85.000 (81.917)\tPrec@5 97.000 (97.459)\n",
            "Test: [190/261]\tTime 0.017 (0.025)\tLoss 0.6137 (0.8341)\tPrec@1 84.000 (81.937)\tPrec@5 98.000 (97.503)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.8106 (0.8335)\tPrec@1 84.000 (81.965)\tPrec@5 98.000 (97.468)\n",
            "Test: [210/261]\tTime 0.020 (0.025)\tLoss 0.6816 (0.8315)\tPrec@1 81.000 (82.005)\tPrec@5 97.000 (97.450)\n",
            "Test: [220/261]\tTime 0.030 (0.025)\tLoss 0.7349 (0.8288)\tPrec@1 84.000 (82.036)\tPrec@5 97.000 (97.480)\n",
            "Test: [230/261]\tTime 0.017 (0.025)\tLoss 0.8431 (0.8304)\tPrec@1 81.000 (82.035)\tPrec@5 98.000 (97.485)\n",
            "Test: [240/261]\tTime 0.027 (0.025)\tLoss 0.7264 (0.8318)\tPrec@1 85.000 (82.058)\tPrec@5 99.000 (97.473)\n",
            "Test: [250/261]\tTime 0.017 (0.025)\tLoss 0.8105 (0.8269)\tPrec@1 82.000 (82.124)\tPrec@5 100.000 (97.514)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4192 (0.8284)\tPrec@1 90.625 (82.110)\tPrec@5 96.875 (97.495)\n",
            "val Results: Prec@1 82.110 Prec@5 97.495 Loss 0.82842\n",
            "val Class Accuracy: [0.651,0.943,0.892,0.762,0.930,0.863,0.692,0.696,0.840,0.604]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [116][0/66], lr: 0.01000\tTime 0.503 (0.503)\tData 0.391 (0.391)\tLoss 0.0451 (0.0451)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [116][10/66], lr: 0.01000\tTime 0.098 (0.136)\tData 0.000 (0.045)\tLoss 0.0415 (0.0542)\tPrec@1 98.438 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [116][20/66], lr: 0.01000\tTime 0.103 (0.117)\tData 0.005 (0.027)\tLoss 0.0775 (0.0614)\tPrec@1 97.266 (97.972)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [116][30/66], lr: 0.01000\tTime 0.092 (0.109)\tData 0.000 (0.020)\tLoss 0.0345 (0.0592)\tPrec@1 98.828 (98.034)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [116][40/66], lr: 0.01000\tTime 0.107 (0.105)\tData 0.005 (0.017)\tLoss 0.1266 (0.0617)\tPrec@1 96.484 (97.933)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [116][50/66], lr: 0.01000\tTime 0.075 (0.102)\tData 0.000 (0.014)\tLoss 0.0723 (0.0661)\tPrec@1 97.656 (97.802)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [116][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.013)\tLoss 0.0710 (0.0652)\tPrec@1 98.047 (97.842)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.292 (0.292)\tLoss 0.6785 (0.6785)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.017 (0.050)\tLoss 1.4159 (0.9713)\tPrec@1 78.000 (79.182)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/261]\tTime 0.025 (0.038)\tLoss 1.0879 (0.9410)\tPrec@1 78.000 (80.048)\tPrec@5 97.000 (96.857)\n",
            "Test: [30/261]\tTime 0.018 (0.033)\tLoss 0.7314 (0.8877)\tPrec@1 85.000 (80.935)\tPrec@5 97.000 (97.161)\n",
            "Test: [40/261]\tTime 0.016 (0.029)\tLoss 0.7886 (0.8842)\tPrec@1 83.000 (80.780)\tPrec@5 97.000 (97.293)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.9085 (0.8769)\tPrec@1 76.000 (81.000)\tPrec@5 98.000 (97.353)\n",
            "Test: [60/261]\tTime 0.024 (0.028)\tLoss 0.9326 (0.8784)\tPrec@1 80.000 (80.967)\tPrec@5 96.000 (97.344)\n",
            "Test: [70/261]\tTime 0.033 (0.028)\tLoss 1.0118 (0.8776)\tPrec@1 81.000 (81.225)\tPrec@5 99.000 (97.408)\n",
            "Test: [80/261]\tTime 0.009 (0.027)\tLoss 0.9977 (0.8830)\tPrec@1 80.000 (81.099)\tPrec@5 97.000 (97.506)\n",
            "Test: [90/261]\tTime 0.038 (0.026)\tLoss 1.0181 (0.9052)\tPrec@1 82.000 (80.978)\tPrec@5 95.000 (97.352)\n",
            "Test: [100/261]\tTime 0.035 (0.026)\tLoss 0.9362 (0.8986)\tPrec@1 83.000 (81.218)\tPrec@5 96.000 (97.307)\n",
            "Test: [110/261]\tTime 0.024 (0.026)\tLoss 1.0761 (0.8956)\tPrec@1 81.000 (81.342)\tPrec@5 98.000 (97.369)\n",
            "Test: [120/261]\tTime 0.025 (0.026)\tLoss 0.7983 (0.8896)\tPrec@1 83.000 (81.413)\tPrec@5 97.000 (97.347)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.9789 (0.8908)\tPrec@1 79.000 (81.450)\tPrec@5 97.000 (97.321)\n",
            "Test: [140/261]\tTime 0.033 (0.025)\tLoss 0.8914 (0.8856)\tPrec@1 81.000 (81.440)\tPrec@5 95.000 (97.340)\n",
            "Test: [150/261]\tTime 0.021 (0.025)\tLoss 0.5795 (0.8860)\tPrec@1 86.000 (81.404)\tPrec@5 98.000 (97.325)\n",
            "Test: [160/261]\tTime 0.016 (0.025)\tLoss 0.5623 (0.8842)\tPrec@1 81.000 (81.379)\tPrec@5 100.000 (97.335)\n",
            "Test: [170/261]\tTime 0.018 (0.025)\tLoss 0.8514 (0.8791)\tPrec@1 84.000 (81.491)\tPrec@5 96.000 (97.339)\n",
            "Test: [180/261]\tTime 0.009 (0.024)\tLoss 0.8711 (0.8802)\tPrec@1 85.000 (81.464)\tPrec@5 94.000 (97.320)\n",
            "Test: [190/261]\tTime 0.030 (0.025)\tLoss 0.6274 (0.8791)\tPrec@1 87.000 (81.455)\tPrec@5 97.000 (97.361)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 0.8045 (0.8784)\tPrec@1 84.000 (81.418)\tPrec@5 97.000 (97.353)\n",
            "Test: [210/261]\tTime 0.019 (0.025)\tLoss 0.7837 (0.8771)\tPrec@1 78.000 (81.431)\tPrec@5 99.000 (97.346)\n",
            "Test: [220/261]\tTime 0.027 (0.025)\tLoss 0.7010 (0.8751)\tPrec@1 85.000 (81.443)\tPrec@5 99.000 (97.357)\n",
            "Test: [230/261]\tTime 0.011 (0.025)\tLoss 1.0424 (0.8769)\tPrec@1 78.000 (81.381)\tPrec@5 95.000 (97.346)\n",
            "Test: [240/261]\tTime 0.016 (0.024)\tLoss 1.0115 (0.8800)\tPrec@1 75.000 (81.349)\tPrec@5 98.000 (97.332)\n",
            "Test: [250/261]\tTime 0.022 (0.025)\tLoss 0.7218 (0.8763)\tPrec@1 80.000 (81.402)\tPrec@5 98.000 (97.363)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4963 (0.8785)\tPrec@1 87.500 (81.373)\tPrec@5 96.875 (97.346)\n",
            "val Results: Prec@1 81.373 Prec@5 97.346 Loss 0.87855\n",
            "val Class Accuracy: [0.673,0.944,0.936,0.836,0.937,0.673,0.769,0.689,0.719,0.520]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [117][0/66], lr: 0.01000\tTime 0.576 (0.576)\tData 0.486 (0.486)\tLoss 0.0747 (0.0747)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][10/66], lr: 0.01000\tTime 0.087 (0.137)\tData 0.000 (0.049)\tLoss 0.0164 (0.0469)\tPrec@1 99.219 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][20/66], lr: 0.01000\tTime 0.096 (0.116)\tData 0.000 (0.029)\tLoss 0.0864 (0.0452)\tPrec@1 99.219 (98.549)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][30/66], lr: 0.01000\tTime 0.094 (0.108)\tData 0.000 (0.020)\tLoss 0.0497 (0.0463)\tPrec@1 98.438 (98.501)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][40/66], lr: 0.01000\tTime 0.095 (0.105)\tData 0.000 (0.017)\tLoss 0.0362 (0.0442)\tPrec@1 98.828 (98.533)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][50/66], lr: 0.01000\tTime 0.083 (0.103)\tData 0.001 (0.015)\tLoss 0.0557 (0.0446)\tPrec@1 98.047 (98.522)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [117][60/66], lr: 0.01000\tTime 0.077 (0.101)\tData 0.000 (0.014)\tLoss 0.0795 (0.0467)\tPrec@1 96.875 (98.457)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.227 (0.227)\tLoss 0.8778 (0.8778)\tPrec@1 84.000 (84.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.015 (0.048)\tLoss 1.4413 (0.9351)\tPrec@1 79.000 (81.182)\tPrec@5 97.000 (96.909)\n",
            "Test: [20/261]\tTime 0.019 (0.036)\tLoss 1.2408 (0.9059)\tPrec@1 78.000 (81.571)\tPrec@5 96.000 (97.190)\n",
            "Test: [30/261]\tTime 0.022 (0.032)\tLoss 0.6733 (0.8323)\tPrec@1 85.000 (82.710)\tPrec@5 98.000 (97.387)\n",
            "Test: [40/261]\tTime 0.010 (0.029)\tLoss 0.7703 (0.8338)\tPrec@1 81.000 (82.585)\tPrec@5 98.000 (97.610)\n",
            "Test: [50/261]\tTime 0.024 (0.029)\tLoss 0.6761 (0.8319)\tPrec@1 84.000 (82.569)\tPrec@5 99.000 (97.784)\n",
            "Test: [60/261]\tTime 0.009 (0.028)\tLoss 0.9144 (0.8337)\tPrec@1 83.000 (82.443)\tPrec@5 97.000 (97.902)\n",
            "Test: [70/261]\tTime 0.018 (0.027)\tLoss 0.6896 (0.8386)\tPrec@1 78.000 (82.366)\tPrec@5 99.000 (97.915)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 1.0527 (0.8482)\tPrec@1 79.000 (82.370)\tPrec@5 97.000 (97.926)\n",
            "Test: [90/261]\tTime 0.009 (0.026)\tLoss 0.9339 (0.8796)\tPrec@1 78.000 (82.110)\tPrec@5 99.000 (97.725)\n",
            "Test: [100/261]\tTime 0.013 (0.026)\tLoss 0.9421 (0.8770)\tPrec@1 79.000 (82.099)\tPrec@5 98.000 (97.703)\n",
            "Test: [110/261]\tTime 0.040 (0.026)\tLoss 1.0297 (0.8748)\tPrec@1 77.000 (82.027)\tPrec@5 98.000 (97.694)\n",
            "Test: [120/261]\tTime 0.021 (0.026)\tLoss 1.0452 (0.8747)\tPrec@1 84.000 (81.983)\tPrec@5 95.000 (97.669)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 1.0760 (0.8761)\tPrec@1 78.000 (82.053)\tPrec@5 97.000 (97.618)\n",
            "Test: [140/261]\tTime 0.015 (0.025)\tLoss 0.8684 (0.8661)\tPrec@1 77.000 (82.135)\tPrec@5 96.000 (97.645)\n",
            "Test: [150/261]\tTime 0.025 (0.025)\tLoss 0.5749 (0.8697)\tPrec@1 85.000 (82.159)\tPrec@5 98.000 (97.636)\n",
            "Test: [160/261]\tTime 0.035 (0.025)\tLoss 0.5569 (0.8711)\tPrec@1 87.000 (82.168)\tPrec@5 100.000 (97.671)\n",
            "Test: [170/261]\tTime 0.015 (0.025)\tLoss 0.7867 (0.8623)\tPrec@1 85.000 (82.287)\tPrec@5 96.000 (97.713)\n",
            "Test: [180/261]\tTime 0.030 (0.025)\tLoss 0.7068 (0.8648)\tPrec@1 82.000 (82.254)\tPrec@5 97.000 (97.702)\n",
            "Test: [190/261]\tTime 0.026 (0.025)\tLoss 0.4654 (0.8607)\tPrec@1 83.000 (82.277)\tPrec@5 100.000 (97.770)\n",
            "Test: [200/261]\tTime 0.027 (0.025)\tLoss 1.3194 (0.8650)\tPrec@1 79.000 (82.189)\tPrec@5 97.000 (97.751)\n",
            "Test: [210/261]\tTime 0.022 (0.025)\tLoss 0.8422 (0.8651)\tPrec@1 82.000 (82.213)\tPrec@5 98.000 (97.758)\n",
            "Test: [220/261]\tTime 0.042 (0.025)\tLoss 1.0945 (0.8662)\tPrec@1 82.000 (82.149)\tPrec@5 98.000 (97.769)\n",
            "Test: [230/261]\tTime 0.009 (0.025)\tLoss 0.9512 (0.8676)\tPrec@1 81.000 (82.121)\tPrec@5 96.000 (97.745)\n",
            "Test: [240/261]\tTime 0.032 (0.025)\tLoss 0.7633 (0.8685)\tPrec@1 87.000 (82.154)\tPrec@5 98.000 (97.730)\n",
            "Test: [250/261]\tTime 0.029 (0.025)\tLoss 0.8423 (0.8666)\tPrec@1 80.000 (82.155)\tPrec@5 100.000 (97.733)\n",
            "Test: [260/261]\tTime 0.006 (0.024)\tLoss 0.8981 (0.8681)\tPrec@1 84.375 (82.164)\tPrec@5 96.875 (97.714)\n",
            "val Results: Prec@1 82.164 Prec@5 97.714 Loss 0.86806\n",
            "val Class Accuracy: [0.590,0.975,0.895,0.840,0.887,0.797,0.783,0.460,0.845,0.776]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [118][0/66], lr: 0.01000\tTime 0.491 (0.491)\tData 0.389 (0.389)\tLoss 0.0266 (0.0266)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [118][10/66], lr: 0.01000\tTime 0.083 (0.131)\tData 0.000 (0.040)\tLoss 0.0476 (0.0500)\tPrec@1 98.047 (98.402)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [118][20/66], lr: 0.01000\tTime 0.126 (0.115)\tData 0.005 (0.023)\tLoss 0.0458 (0.0489)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [118][30/66], lr: 0.01000\tTime 0.113 (0.108)\tData 0.003 (0.017)\tLoss 0.0298 (0.0500)\tPrec@1 98.828 (98.349)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [118][40/66], lr: 0.01000\tTime 0.119 (0.105)\tData 0.007 (0.014)\tLoss 0.0420 (0.0496)\tPrec@1 98.828 (98.409)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [118][50/66], lr: 0.01000\tTime 0.099 (0.104)\tData 0.000 (0.012)\tLoss 0.0250 (0.0472)\tPrec@1 99.609 (98.491)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [118][60/66], lr: 0.01000\tTime 0.079 (0.101)\tData 0.000 (0.011)\tLoss 0.0760 (0.0477)\tPrec@1 97.656 (98.470)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.246 (0.246)\tLoss 1.0053 (1.0053)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.027 (0.047)\tLoss 1.5557 (0.9259)\tPrec@1 79.000 (82.455)\tPrec@5 97.000 (97.909)\n",
            "Test: [20/261]\tTime 0.016 (0.035)\tLoss 1.2326 (0.8878)\tPrec@1 80.000 (82.286)\tPrec@5 97.000 (97.810)\n",
            "Test: [30/261]\tTime 0.012 (0.032)\tLoss 0.7074 (0.8119)\tPrec@1 85.000 (83.452)\tPrec@5 98.000 (98.161)\n",
            "Test: [40/261]\tTime 0.025 (0.030)\tLoss 0.9330 (0.7926)\tPrec@1 79.000 (83.805)\tPrec@5 99.000 (98.293)\n",
            "Test: [50/261]\tTime 0.024 (0.029)\tLoss 0.7718 (0.7813)\tPrec@1 84.000 (83.725)\tPrec@5 100.000 (98.294)\n",
            "Test: [60/261]\tTime 0.030 (0.028)\tLoss 0.5729 (0.7785)\tPrec@1 87.000 (83.885)\tPrec@5 99.000 (98.279)\n",
            "Test: [70/261]\tTime 0.030 (0.027)\tLoss 0.8308 (0.7851)\tPrec@1 83.000 (83.831)\tPrec@5 98.000 (98.282)\n",
            "Test: [80/261]\tTime 0.030 (0.027)\tLoss 0.9317 (0.7901)\tPrec@1 83.000 (83.901)\tPrec@5 98.000 (98.309)\n",
            "Test: [90/261]\tTime 0.032 (0.026)\tLoss 1.0658 (0.8213)\tPrec@1 78.000 (83.571)\tPrec@5 96.000 (98.187)\n",
            "Test: [100/261]\tTime 0.016 (0.026)\tLoss 1.0004 (0.8103)\tPrec@1 85.000 (83.752)\tPrec@5 97.000 (98.198)\n",
            "Test: [110/261]\tTime 0.012 (0.026)\tLoss 1.0306 (0.8079)\tPrec@1 79.000 (83.676)\tPrec@5 99.000 (98.270)\n",
            "Test: [120/261]\tTime 0.012 (0.026)\tLoss 1.0484 (0.8068)\tPrec@1 85.000 (83.678)\tPrec@5 98.000 (98.248)\n",
            "Test: [130/261]\tTime 0.028 (0.025)\tLoss 0.9417 (0.8126)\tPrec@1 83.000 (83.672)\tPrec@5 98.000 (98.214)\n",
            "Test: [140/261]\tTime 0.028 (0.025)\tLoss 1.0464 (0.8152)\tPrec@1 79.000 (83.596)\tPrec@5 97.000 (98.206)\n",
            "Test: [150/261]\tTime 0.017 (0.025)\tLoss 0.6550 (0.8132)\tPrec@1 83.000 (83.583)\tPrec@5 98.000 (98.199)\n",
            "Test: [160/261]\tTime 0.016 (0.025)\tLoss 0.5540 (0.8124)\tPrec@1 85.000 (83.609)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.018 (0.025)\tLoss 0.7160 (0.8085)\tPrec@1 88.000 (83.637)\tPrec@5 97.000 (98.222)\n",
            "Test: [180/261]\tTime 0.022 (0.025)\tLoss 0.9862 (0.8082)\tPrec@1 82.000 (83.646)\tPrec@5 94.000 (98.188)\n",
            "Test: [190/261]\tTime 0.014 (0.025)\tLoss 0.8866 (0.8062)\tPrec@1 83.000 (83.623)\tPrec@5 99.000 (98.225)\n",
            "Test: [200/261]\tTime 0.013 (0.025)\tLoss 0.7164 (0.8067)\tPrec@1 84.000 (83.607)\tPrec@5 99.000 (98.219)\n",
            "Test: [210/261]\tTime 0.025 (0.025)\tLoss 0.7416 (0.8096)\tPrec@1 83.000 (83.555)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.047 (0.025)\tLoss 0.8105 (0.8074)\tPrec@1 84.000 (83.516)\tPrec@5 99.000 (98.231)\n",
            "Test: [230/261]\tTime 0.010 (0.025)\tLoss 0.7964 (0.8086)\tPrec@1 82.000 (83.472)\tPrec@5 98.000 (98.229)\n",
            "Test: [240/261]\tTime 0.035 (0.025)\tLoss 0.6976 (0.8115)\tPrec@1 81.000 (83.469)\tPrec@5 97.000 (98.191)\n",
            "Test: [250/261]\tTime 0.037 (0.025)\tLoss 0.6244 (0.8066)\tPrec@1 86.000 (83.558)\tPrec@5 99.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.5750 (0.8055)\tPrec@1 90.625 (83.559)\tPrec@5 100.000 (98.202)\n",
            "val Results: Prec@1 83.559 Prec@5 98.202 Loss 0.80548\n",
            "val Class Accuracy: [0.847,0.971,0.901,0.884,0.752,0.782,0.686,0.857,0.642,0.703]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [119][0/66], lr: 0.01000\tTime 0.464 (0.464)\tData 0.385 (0.385)\tLoss 0.0562 (0.0562)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][10/66], lr: 0.01000\tTime 0.091 (0.125)\tData 0.005 (0.045)\tLoss 0.0226 (0.0543)\tPrec@1 99.609 (98.224)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][20/66], lr: 0.01000\tTime 0.093 (0.112)\tData 0.004 (0.028)\tLoss 0.0678 (0.0529)\tPrec@1 98.047 (98.289)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][30/66], lr: 0.01000\tTime 0.089 (0.107)\tData 0.005 (0.020)\tLoss 0.0568 (0.0518)\tPrec@1 97.266 (98.185)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][40/66], lr: 0.01000\tTime 0.086 (0.104)\tData 0.005 (0.017)\tLoss 0.0554 (0.0521)\tPrec@1 98.047 (98.247)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [119][50/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.015)\tLoss 0.0160 (0.0531)\tPrec@1 100.000 (98.200)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [119][60/66], lr: 0.01000\tTime 0.064 (0.098)\tData 0.000 (0.013)\tLoss 0.0647 (0.0537)\tPrec@1 97.656 (98.143)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.228 (0.228)\tLoss 0.7006 (0.7006)\tPrec@1 78.000 (78.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.029 (0.049)\tLoss 1.4105 (0.8076)\tPrec@1 76.000 (81.182)\tPrec@5 96.000 (97.364)\n",
            "Test: [20/261]\tTime 0.033 (0.038)\tLoss 1.0804 (0.8021)\tPrec@1 77.000 (81.714)\tPrec@5 95.000 (97.333)\n",
            "Test: [30/261]\tTime 0.050 (0.034)\tLoss 0.5163 (0.7590)\tPrec@1 84.000 (82.613)\tPrec@5 99.000 (97.677)\n",
            "Test: [40/261]\tTime 0.019 (0.032)\tLoss 0.6872 (0.7493)\tPrec@1 85.000 (82.951)\tPrec@5 99.000 (97.756)\n",
            "Test: [50/261]\tTime 0.026 (0.030)\tLoss 0.7650 (0.7500)\tPrec@1 79.000 (82.765)\tPrec@5 97.000 (97.843)\n",
            "Test: [60/261]\tTime 0.022 (0.029)\tLoss 0.7836 (0.7485)\tPrec@1 81.000 (82.836)\tPrec@5 97.000 (97.721)\n",
            "Test: [70/261]\tTime 0.024 (0.028)\tLoss 0.7386 (0.7551)\tPrec@1 78.000 (82.690)\tPrec@5 99.000 (97.746)\n",
            "Test: [80/261]\tTime 0.038 (0.028)\tLoss 0.8443 (0.7664)\tPrec@1 81.000 (82.556)\tPrec@5 99.000 (97.753)\n",
            "Test: [90/261]\tTime 0.023 (0.027)\tLoss 0.8070 (0.7922)\tPrec@1 83.000 (82.516)\tPrec@5 95.000 (97.626)\n",
            "Test: [100/261]\tTime 0.027 (0.027)\tLoss 0.9642 (0.7861)\tPrec@1 82.000 (82.644)\tPrec@5 97.000 (97.604)\n",
            "Test: [110/261]\tTime 0.016 (0.027)\tLoss 0.9179 (0.7808)\tPrec@1 77.000 (82.631)\tPrec@5 100.000 (97.703)\n",
            "Test: [120/261]\tTime 0.036 (0.026)\tLoss 0.7483 (0.7758)\tPrec@1 85.000 (82.744)\tPrec@5 97.000 (97.711)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.8335 (0.7816)\tPrec@1 82.000 (82.672)\tPrec@5 97.000 (97.679)\n",
            "Test: [140/261]\tTime 0.022 (0.026)\tLoss 1.0033 (0.7782)\tPrec@1 80.000 (82.766)\tPrec@5 96.000 (97.709)\n",
            "Test: [150/261]\tTime 0.018 (0.026)\tLoss 0.5229 (0.7769)\tPrec@1 87.000 (82.755)\tPrec@5 98.000 (97.715)\n",
            "Test: [160/261]\tTime 0.016 (0.026)\tLoss 0.5089 (0.7752)\tPrec@1 85.000 (82.807)\tPrec@5 100.000 (97.696)\n",
            "Test: [170/261]\tTime 0.024 (0.026)\tLoss 0.7771 (0.7720)\tPrec@1 82.000 (82.830)\tPrec@5 96.000 (97.690)\n",
            "Test: [180/261]\tTime 0.028 (0.026)\tLoss 0.6433 (0.7734)\tPrec@1 86.000 (82.818)\tPrec@5 96.000 (97.680)\n",
            "Test: [190/261]\tTime 0.035 (0.025)\tLoss 0.6234 (0.7691)\tPrec@1 83.000 (82.880)\tPrec@5 99.000 (97.707)\n",
            "Test: [200/261]\tTime 0.018 (0.025)\tLoss 0.9676 (0.7709)\tPrec@1 84.000 (82.781)\tPrec@5 97.000 (97.672)\n",
            "Test: [210/261]\tTime 0.045 (0.025)\tLoss 0.6405 (0.7689)\tPrec@1 84.000 (82.825)\tPrec@5 99.000 (97.673)\n",
            "Test: [220/261]\tTime 0.015 (0.025)\tLoss 0.8779 (0.7699)\tPrec@1 82.000 (82.751)\tPrec@5 99.000 (97.710)\n",
            "Test: [230/261]\tTime 0.022 (0.025)\tLoss 0.8439 (0.7720)\tPrec@1 79.000 (82.710)\tPrec@5 96.000 (97.684)\n",
            "Test: [240/261]\tTime 0.014 (0.025)\tLoss 0.6936 (0.7738)\tPrec@1 82.000 (82.685)\tPrec@5 97.000 (97.660)\n",
            "Test: [250/261]\tTime 0.024 (0.025)\tLoss 0.6390 (0.7684)\tPrec@1 83.000 (82.769)\tPrec@5 98.000 (97.673)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.6098 (0.7720)\tPrec@1 87.500 (82.748)\tPrec@5 96.875 (97.664)\n",
            "val Results: Prec@1 82.748 Prec@5 97.664 Loss 0.77201\n",
            "val Class Accuracy: [0.676,0.978,0.888,0.877,0.883,0.792,0.753,0.727,0.701,0.581]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [120][0/66], lr: 0.01000\tTime 0.531 (0.531)\tData 0.451 (0.451)\tLoss 0.0222 (0.0222)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][10/66], lr: 0.01000\tTime 0.086 (0.135)\tData 0.006 (0.052)\tLoss 0.0596 (0.0450)\tPrec@1 97.266 (98.544)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][20/66], lr: 0.01000\tTime 0.105 (0.117)\tData 0.000 (0.031)\tLoss 0.0313 (0.0462)\tPrec@1 98.438 (98.456)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][30/66], lr: 0.01000\tTime 0.087 (0.109)\tData 0.000 (0.022)\tLoss 0.0771 (0.0477)\tPrec@1 96.094 (98.274)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][40/66], lr: 0.01000\tTime 0.087 (0.105)\tData 0.000 (0.018)\tLoss 0.0230 (0.0468)\tPrec@1 98.828 (98.380)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][50/66], lr: 0.01000\tTime 0.082 (0.102)\tData 0.009 (0.016)\tLoss 0.0440 (0.0470)\tPrec@1 98.047 (98.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [120][60/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.014)\tLoss 0.0324 (0.0466)\tPrec@1 98.828 (98.386)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.259 (0.259)\tLoss 0.7089 (0.7089)\tPrec@1 88.000 (88.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.029 (0.049)\tLoss 1.5881 (0.9690)\tPrec@1 76.000 (80.818)\tPrec@5 98.000 (97.727)\n",
            "Test: [20/261]\tTime 0.028 (0.039)\tLoss 1.2878 (0.9411)\tPrec@1 79.000 (81.286)\tPrec@5 95.000 (97.762)\n",
            "Test: [30/261]\tTime 0.013 (0.032)\tLoss 0.5832 (0.8718)\tPrec@1 87.000 (82.419)\tPrec@5 99.000 (98.032)\n",
            "Test: [40/261]\tTime 0.025 (0.031)\tLoss 0.7955 (0.8675)\tPrec@1 85.000 (82.512)\tPrec@5 98.000 (98.195)\n",
            "Test: [50/261]\tTime 0.018 (0.029)\tLoss 0.9784 (0.8640)\tPrec@1 79.000 (82.706)\tPrec@5 97.000 (98.157)\n",
            "Test: [60/261]\tTime 0.021 (0.029)\tLoss 0.8954 (0.8660)\tPrec@1 81.000 (82.639)\tPrec@5 97.000 (98.131)\n",
            "Test: [70/261]\tTime 0.039 (0.028)\tLoss 0.9613 (0.8644)\tPrec@1 76.000 (82.437)\tPrec@5 99.000 (98.141)\n",
            "Test: [80/261]\tTime 0.017 (0.027)\tLoss 1.0563 (0.8777)\tPrec@1 79.000 (82.198)\tPrec@5 97.000 (98.111)\n",
            "Test: [90/261]\tTime 0.013 (0.027)\tLoss 0.9558 (0.8969)\tPrec@1 80.000 (82.088)\tPrec@5 96.000 (98.033)\n",
            "Test: [100/261]\tTime 0.042 (0.027)\tLoss 0.9753 (0.8888)\tPrec@1 82.000 (82.396)\tPrec@5 96.000 (97.980)\n",
            "Test: [110/261]\tTime 0.025 (0.026)\tLoss 1.0117 (0.8832)\tPrec@1 81.000 (82.423)\tPrec@5 98.000 (97.982)\n",
            "Test: [120/261]\tTime 0.010 (0.026)\tLoss 0.8514 (0.8797)\tPrec@1 84.000 (82.455)\tPrec@5 96.000 (98.025)\n",
            "Test: [130/261]\tTime 0.031 (0.026)\tLoss 0.8960 (0.8830)\tPrec@1 82.000 (82.550)\tPrec@5 98.000 (97.969)\n",
            "Test: [140/261]\tTime 0.022 (0.026)\tLoss 1.0608 (0.8825)\tPrec@1 80.000 (82.546)\tPrec@5 96.000 (97.972)\n",
            "Test: [150/261]\tTime 0.011 (0.025)\tLoss 0.5134 (0.8776)\tPrec@1 89.000 (82.510)\tPrec@5 98.000 (97.974)\n",
            "Test: [160/261]\tTime 0.028 (0.025)\tLoss 0.4182 (0.8728)\tPrec@1 91.000 (82.590)\tPrec@5 100.000 (97.969)\n",
            "Test: [170/261]\tTime 0.020 (0.025)\tLoss 0.8090 (0.8669)\tPrec@1 86.000 (82.678)\tPrec@5 97.000 (97.971)\n",
            "Test: [180/261]\tTime 0.010 (0.025)\tLoss 0.7490 (0.8650)\tPrec@1 86.000 (82.707)\tPrec@5 95.000 (97.917)\n",
            "Test: [190/261]\tTime 0.021 (0.025)\tLoss 0.5710 (0.8628)\tPrec@1 85.000 (82.654)\tPrec@5 100.000 (97.942)\n",
            "Test: [200/261]\tTime 0.012 (0.025)\tLoss 0.9739 (0.8620)\tPrec@1 83.000 (82.617)\tPrec@5 98.000 (97.930)\n",
            "Test: [210/261]\tTime 0.021 (0.025)\tLoss 0.7394 (0.8590)\tPrec@1 86.000 (82.692)\tPrec@5 98.000 (97.953)\n",
            "Test: [220/261]\tTime 0.023 (0.025)\tLoss 0.7034 (0.8562)\tPrec@1 85.000 (82.697)\tPrec@5 98.000 (97.977)\n",
            "Test: [230/261]\tTime 0.025 (0.025)\tLoss 0.9565 (0.8605)\tPrec@1 77.000 (82.632)\tPrec@5 98.000 (97.948)\n",
            "Test: [240/261]\tTime 0.011 (0.025)\tLoss 1.0138 (0.8634)\tPrec@1 88.000 (82.631)\tPrec@5 98.000 (97.950)\n",
            "Test: [250/261]\tTime 0.017 (0.025)\tLoss 0.6669 (0.8614)\tPrec@1 79.000 (82.689)\tPrec@5 100.000 (97.952)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4147 (0.8651)\tPrec@1 90.625 (82.664)\tPrec@5 100.000 (97.945)\n",
            "val Results: Prec@1 82.664 Prec@5 97.945 Loss 0.86515\n",
            "val Class Accuracy: [0.707,0.951,0.952,0.858,0.927,0.702,0.723,0.705,0.746,0.570]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [121][0/66], lr: 0.01000\tTime 0.594 (0.594)\tData 0.537 (0.537)\tLoss 0.0317 (0.0317)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][10/66], lr: 0.01000\tTime 0.099 (0.136)\tData 0.004 (0.058)\tLoss 0.0228 (0.0363)\tPrec@1 99.609 (98.757)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][20/66], lr: 0.01000\tTime 0.088 (0.115)\tData 0.007 (0.035)\tLoss 0.0224 (0.0387)\tPrec@1 98.828 (98.772)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][30/66], lr: 0.01000\tTime 0.105 (0.108)\tData 0.000 (0.025)\tLoss 0.0361 (0.0390)\tPrec@1 98.828 (98.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][40/66], lr: 0.01000\tTime 0.111 (0.105)\tData 0.005 (0.020)\tLoss 0.0687 (0.0401)\tPrec@1 97.656 (98.704)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][50/66], lr: 0.01000\tTime 0.101 (0.102)\tData 0.007 (0.017)\tLoss 0.0253 (0.0381)\tPrec@1 98.828 (98.721)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [121][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.015)\tLoss 0.0409 (0.0391)\tPrec@1 98.047 (98.706)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.247 (0.247)\tLoss 0.7540 (0.7540)\tPrec@1 83.000 (83.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.033 (0.049)\tLoss 1.2481 (0.8664)\tPrec@1 80.000 (82.091)\tPrec@5 96.000 (97.273)\n",
            "Test: [20/261]\tTime 0.009 (0.035)\tLoss 1.1162 (0.8698)\tPrec@1 80.000 (81.952)\tPrec@5 94.000 (97.286)\n",
            "Test: [30/261]\tTime 0.019 (0.032)\tLoss 0.5113 (0.8069)\tPrec@1 88.000 (83.129)\tPrec@5 99.000 (97.710)\n",
            "Test: [40/261]\tTime 0.020 (0.030)\tLoss 0.8108 (0.7843)\tPrec@1 82.000 (83.463)\tPrec@5 96.000 (97.829)\n",
            "Test: [50/261]\tTime 0.023 (0.029)\tLoss 0.8101 (0.7793)\tPrec@1 82.000 (83.588)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/261]\tTime 0.027 (0.028)\tLoss 0.6583 (0.7774)\tPrec@1 84.000 (83.705)\tPrec@5 98.000 (97.803)\n",
            "Test: [70/261]\tTime 0.014 (0.027)\tLoss 0.7458 (0.7865)\tPrec@1 82.000 (83.676)\tPrec@5 98.000 (97.789)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 0.8996 (0.8003)\tPrec@1 81.000 (83.605)\tPrec@5 98.000 (97.753)\n",
            "Test: [90/261]\tTime 0.016 (0.027)\tLoss 0.9700 (0.8285)\tPrec@1 84.000 (83.341)\tPrec@5 96.000 (97.648)\n",
            "Test: [100/261]\tTime 0.021 (0.026)\tLoss 0.8159 (0.8166)\tPrec@1 79.000 (83.535)\tPrec@5 99.000 (97.703)\n",
            "Test: [110/261]\tTime 0.024 (0.027)\tLoss 0.8560 (0.8140)\tPrec@1 82.000 (83.541)\tPrec@5 97.000 (97.676)\n",
            "Test: [120/261]\tTime 0.012 (0.026)\tLoss 1.1427 (0.8173)\tPrec@1 84.000 (83.562)\tPrec@5 95.000 (97.645)\n",
            "Test: [130/261]\tTime 0.018 (0.026)\tLoss 1.0063 (0.8202)\tPrec@1 79.000 (83.473)\tPrec@5 99.000 (97.641)\n",
            "Test: [140/261]\tTime 0.026 (0.026)\tLoss 0.8606 (0.8143)\tPrec@1 80.000 (83.518)\tPrec@5 95.000 (97.631)\n",
            "Test: [150/261]\tTime 0.018 (0.026)\tLoss 0.5158 (0.8131)\tPrec@1 86.000 (83.589)\tPrec@5 100.000 (97.642)\n",
            "Test: [160/261]\tTime 0.024 (0.026)\tLoss 0.5075 (0.8076)\tPrec@1 88.000 (83.689)\tPrec@5 99.000 (97.652)\n",
            "Test: [170/261]\tTime 0.046 (0.026)\tLoss 0.7327 (0.8061)\tPrec@1 89.000 (83.737)\tPrec@5 97.000 (97.667)\n",
            "Test: [180/261]\tTime 0.028 (0.025)\tLoss 0.9435 (0.8076)\tPrec@1 87.000 (83.785)\tPrec@5 93.000 (97.635)\n",
            "Test: [190/261]\tTime 0.031 (0.025)\tLoss 0.8200 (0.8074)\tPrec@1 80.000 (83.723)\tPrec@5 99.000 (97.644)\n",
            "Test: [200/261]\tTime 0.029 (0.025)\tLoss 0.8864 (0.8060)\tPrec@1 83.000 (83.726)\tPrec@5 96.000 (97.632)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.6969 (0.8064)\tPrec@1 82.000 (83.735)\tPrec@5 98.000 (97.630)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.7481 (0.8062)\tPrec@1 84.000 (83.769)\tPrec@5 100.000 (97.679)\n",
            "Test: [230/261]\tTime 0.026 (0.025)\tLoss 0.7706 (0.8063)\tPrec@1 79.000 (83.723)\tPrec@5 98.000 (97.667)\n",
            "Test: [240/261]\tTime 0.024 (0.025)\tLoss 0.7783 (0.8095)\tPrec@1 86.000 (83.705)\tPrec@5 98.000 (97.656)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.7213 (0.8073)\tPrec@1 86.000 (83.801)\tPrec@5 100.000 (97.645)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2270 (0.8086)\tPrec@1 96.875 (83.820)\tPrec@5 96.875 (97.622)\n",
            "val Results: Prec@1 83.820 Prec@5 97.622 Loss 0.80859\n",
            "val Class Accuracy: [0.706,0.977,0.919,0.788,0.912,0.859,0.782,0.796,0.673,0.567]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [122][0/66], lr: 0.01000\tTime 0.604 (0.604)\tData 0.511 (0.511)\tLoss 0.0726 (0.0726)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][10/66], lr: 0.01000\tTime 0.107 (0.145)\tData 0.000 (0.050)\tLoss 0.0326 (0.0466)\tPrec@1 98.828 (98.544)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][20/66], lr: 0.01000\tTime 0.072 (0.120)\tData 0.003 (0.029)\tLoss 0.0443 (0.0471)\tPrec@1 98.438 (98.512)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][30/66], lr: 0.01000\tTime 0.089 (0.110)\tData 0.000 (0.021)\tLoss 0.0186 (0.0463)\tPrec@1 99.609 (98.589)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][40/66], lr: 0.01000\tTime 0.084 (0.105)\tData 0.000 (0.018)\tLoss 0.0345 (0.0477)\tPrec@1 98.828 (98.514)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][50/66], lr: 0.01000\tTime 0.090 (0.102)\tData 0.003 (0.016)\tLoss 0.0323 (0.0483)\tPrec@1 98.828 (98.430)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [122][60/66], lr: 0.01000\tTime 0.076 (0.100)\tData 0.000 (0.014)\tLoss 0.0228 (0.0493)\tPrec@1 99.219 (98.386)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.214 (0.214)\tLoss 0.5232 (0.5232)\tPrec@1 87.000 (87.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.032 (0.048)\tLoss 1.4296 (0.7753)\tPrec@1 79.000 (84.455)\tPrec@5 99.000 (97.909)\n",
            "Test: [20/261]\tTime 0.018 (0.036)\tLoss 0.9983 (0.7601)\tPrec@1 83.000 (85.000)\tPrec@5 94.000 (97.714)\n",
            "Test: [30/261]\tTime 0.023 (0.032)\tLoss 0.5371 (0.7014)\tPrec@1 88.000 (85.484)\tPrec@5 99.000 (98.032)\n",
            "Test: [40/261]\tTime 0.041 (0.031)\tLoss 0.8343 (0.6917)\tPrec@1 86.000 (85.707)\tPrec@5 98.000 (98.098)\n",
            "Test: [50/261]\tTime 0.015 (0.029)\tLoss 0.6393 (0.7032)\tPrec@1 82.000 (85.451)\tPrec@5 98.000 (98.059)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 0.6110 (0.7085)\tPrec@1 86.000 (85.262)\tPrec@5 99.000 (98.016)\n",
            "Test: [70/261]\tTime 0.033 (0.027)\tLoss 0.7369 (0.7144)\tPrec@1 82.000 (85.099)\tPrec@5 99.000 (98.000)\n",
            "Test: [80/261]\tTime 0.016 (0.027)\tLoss 0.6220 (0.7197)\tPrec@1 84.000 (85.012)\tPrec@5 97.000 (97.963)\n",
            "Test: [90/261]\tTime 0.031 (0.027)\tLoss 0.5638 (0.7388)\tPrec@1 88.000 (84.769)\tPrec@5 98.000 (97.934)\n",
            "Test: [100/261]\tTime 0.040 (0.026)\tLoss 0.9978 (0.7348)\tPrec@1 79.000 (84.792)\tPrec@5 95.000 (97.911)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.8547 (0.7315)\tPrec@1 82.000 (84.784)\tPrec@5 97.000 (97.946)\n",
            "Test: [120/261]\tTime 0.010 (0.026)\tLoss 0.9243 (0.7298)\tPrec@1 86.000 (84.802)\tPrec@5 97.000 (97.950)\n",
            "Test: [130/261]\tTime 0.025 (0.025)\tLoss 0.9676 (0.7364)\tPrec@1 80.000 (84.641)\tPrec@5 98.000 (97.954)\n",
            "Test: [140/261]\tTime 0.031 (0.026)\tLoss 0.9188 (0.7365)\tPrec@1 78.000 (84.525)\tPrec@5 99.000 (98.014)\n",
            "Test: [150/261]\tTime 0.035 (0.025)\tLoss 0.5811 (0.7355)\tPrec@1 87.000 (84.550)\tPrec@5 99.000 (98.007)\n",
            "Test: [160/261]\tTime 0.031 (0.026)\tLoss 0.4600 (0.7340)\tPrec@1 87.000 (84.516)\tPrec@5 99.000 (98.000)\n",
            "Test: [170/261]\tTime 0.022 (0.025)\tLoss 0.5550 (0.7289)\tPrec@1 92.000 (84.655)\tPrec@5 98.000 (98.012)\n",
            "Test: [180/261]\tTime 0.031 (0.025)\tLoss 0.5974 (0.7333)\tPrec@1 88.000 (84.569)\tPrec@5 97.000 (97.978)\n",
            "Test: [190/261]\tTime 0.018 (0.025)\tLoss 0.6657 (0.7329)\tPrec@1 83.000 (84.513)\tPrec@5 99.000 (98.010)\n",
            "Test: [200/261]\tTime 0.029 (0.025)\tLoss 0.7805 (0.7336)\tPrec@1 83.000 (84.463)\tPrec@5 98.000 (98.005)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.5282 (0.7309)\tPrec@1 85.000 (84.488)\tPrec@5 99.000 (97.991)\n",
            "Test: [220/261]\tTime 0.019 (0.025)\tLoss 0.7943 (0.7305)\tPrec@1 86.000 (84.511)\tPrec@5 100.000 (98.018)\n",
            "Test: [230/261]\tTime 0.009 (0.025)\tLoss 0.8721 (0.7321)\tPrec@1 85.000 (84.437)\tPrec@5 97.000 (97.996)\n",
            "Test: [240/261]\tTime 0.017 (0.025)\tLoss 0.7354 (0.7360)\tPrec@1 86.000 (84.444)\tPrec@5 96.000 (97.954)\n",
            "Test: [250/261]\tTime 0.029 (0.025)\tLoss 0.6622 (0.7339)\tPrec@1 86.000 (84.466)\tPrec@5 100.000 (97.956)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.2703 (0.7337)\tPrec@1 90.625 (84.481)\tPrec@5 100.000 (97.964)\n",
            "val Results: Prec@1 84.481 Prec@5 97.964 Loss 0.73373\n",
            "val Class Accuracy: [0.826,0.959,0.849,0.839,0.891,0.884,0.816,0.807,0.622,0.682]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [123][0/66], lr: 0.01000\tTime 0.553 (0.553)\tData 0.473 (0.473)\tLoss 0.0632 (0.0632)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][10/66], lr: 0.01000\tTime 0.101 (0.137)\tData 0.005 (0.048)\tLoss 0.0328 (0.0546)\tPrec@1 99.609 (98.331)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][20/66], lr: 0.01000\tTime 0.082 (0.115)\tData 0.007 (0.028)\tLoss 0.0409 (0.0535)\tPrec@1 98.438 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][30/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.004 (0.021)\tLoss 0.0791 (0.0577)\tPrec@1 97.656 (98.009)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][40/66], lr: 0.01000\tTime 0.089 (0.102)\tData 0.000 (0.017)\tLoss 0.0691 (0.0642)\tPrec@1 97.266 (97.904)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][50/66], lr: 0.01000\tTime 0.087 (0.100)\tData 0.004 (0.015)\tLoss 0.0938 (0.0654)\tPrec@1 96.484 (97.809)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [123][60/66], lr: 0.01000\tTime 0.070 (0.098)\tData 0.000 (0.013)\tLoss 0.1350 (0.0650)\tPrec@1 95.703 (97.784)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.237 (0.237)\tLoss 0.4398 (0.4398)\tPrec@1 88.000 (88.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.035 (0.051)\tLoss 1.0787 (0.7428)\tPrec@1 79.000 (82.636)\tPrec@5 99.000 (97.727)\n",
            "Test: [20/261]\tTime 0.016 (0.037)\tLoss 0.9209 (0.7434)\tPrec@1 78.000 (82.952)\tPrec@5 96.000 (97.810)\n",
            "Test: [30/261]\tTime 0.009 (0.032)\tLoss 0.3750 (0.6740)\tPrec@1 89.000 (84.581)\tPrec@5 99.000 (98.129)\n",
            "Test: [40/261]\tTime 0.033 (0.030)\tLoss 0.9451 (0.6674)\tPrec@1 82.000 (84.927)\tPrec@5 97.000 (98.220)\n",
            "Test: [50/261]\tTime 0.016 (0.028)\tLoss 0.6976 (0.6642)\tPrec@1 84.000 (84.961)\tPrec@5 100.000 (98.294)\n",
            "Test: [60/261]\tTime 0.017 (0.028)\tLoss 0.5766 (0.6556)\tPrec@1 85.000 (85.148)\tPrec@5 99.000 (98.230)\n",
            "Test: [70/261]\tTime 0.023 (0.027)\tLoss 0.8046 (0.6562)\tPrec@1 81.000 (85.070)\tPrec@5 100.000 (98.296)\n",
            "Test: [80/261]\tTime 0.027 (0.027)\tLoss 0.5138 (0.6502)\tPrec@1 88.000 (85.235)\tPrec@5 98.000 (98.296)\n",
            "Test: [90/261]\tTime 0.027 (0.026)\tLoss 0.6623 (0.6794)\tPrec@1 89.000 (85.066)\tPrec@5 97.000 (98.209)\n",
            "Test: [100/261]\tTime 0.024 (0.026)\tLoss 0.9641 (0.6766)\tPrec@1 82.000 (85.158)\tPrec@5 98.000 (98.178)\n",
            "Test: [110/261]\tTime 0.020 (0.026)\tLoss 0.7350 (0.6704)\tPrec@1 85.000 (85.189)\tPrec@5 98.000 (98.216)\n",
            "Test: [120/261]\tTime 0.033 (0.026)\tLoss 0.4930 (0.6691)\tPrec@1 90.000 (85.157)\tPrec@5 98.000 (98.182)\n",
            "Test: [130/261]\tTime 0.024 (0.026)\tLoss 0.6616 (0.6733)\tPrec@1 83.000 (85.107)\tPrec@5 97.000 (98.168)\n",
            "Test: [140/261]\tTime 0.046 (0.026)\tLoss 0.7715 (0.6703)\tPrec@1 83.000 (85.113)\tPrec@5 98.000 (98.170)\n",
            "Test: [150/261]\tTime 0.024 (0.026)\tLoss 0.4827 (0.6689)\tPrec@1 88.000 (85.093)\tPrec@5 97.000 (98.159)\n",
            "Test: [160/261]\tTime 0.020 (0.026)\tLoss 0.2655 (0.6684)\tPrec@1 91.000 (85.081)\tPrec@5 100.000 (98.174)\n",
            "Test: [170/261]\tTime 0.018 (0.026)\tLoss 0.6975 (0.6627)\tPrec@1 87.000 (85.205)\tPrec@5 99.000 (98.199)\n",
            "Test: [180/261]\tTime 0.038 (0.026)\tLoss 0.6411 (0.6630)\tPrec@1 84.000 (85.155)\tPrec@5 96.000 (98.166)\n",
            "Test: [190/261]\tTime 0.026 (0.026)\tLoss 0.4427 (0.6629)\tPrec@1 89.000 (85.079)\tPrec@5 100.000 (98.199)\n",
            "Test: [200/261]\tTime 0.049 (0.026)\tLoss 0.7450 (0.6634)\tPrec@1 85.000 (84.980)\tPrec@5 97.000 (98.164)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 0.7398 (0.6638)\tPrec@1 80.000 (85.005)\tPrec@5 98.000 (98.156)\n",
            "Test: [220/261]\tTime 0.013 (0.026)\tLoss 0.5681 (0.6596)\tPrec@1 85.000 (85.023)\tPrec@5 98.000 (98.181)\n",
            "Test: [230/261]\tTime 0.034 (0.026)\tLoss 0.8996 (0.6604)\tPrec@1 78.000 (84.974)\tPrec@5 97.000 (98.160)\n",
            "Test: [240/261]\tTime 0.038 (0.026)\tLoss 0.6471 (0.6617)\tPrec@1 87.000 (85.012)\tPrec@5 97.000 (98.137)\n",
            "Test: [250/261]\tTime 0.026 (0.026)\tLoss 0.4479 (0.6562)\tPrec@1 85.000 (85.092)\tPrec@5 100.000 (98.159)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2477 (0.6596)\tPrec@1 93.750 (85.026)\tPrec@5 96.875 (98.152)\n",
            "val Results: Prec@1 85.026 Prec@5 98.152 Loss 0.65962\n",
            "val Class Accuracy: [0.685,0.933,0.959,0.775,0.943,0.856,0.826,0.872,0.764,0.557]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [124][0/66], lr: 0.01000\tTime 0.571 (0.571)\tData 0.483 (0.483)\tLoss 0.0153 (0.0153)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [124][10/66], lr: 0.01000\tTime 0.068 (0.139)\tData 0.000 (0.050)\tLoss 0.0380 (0.0538)\tPrec@1 98.828 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [124][20/66], lr: 0.01000\tTime 0.112 (0.120)\tData 0.036 (0.032)\tLoss 0.0213 (0.0536)\tPrec@1 99.219 (98.363)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [124][30/66], lr: 0.01000\tTime 0.097 (0.111)\tData 0.000 (0.023)\tLoss 0.0873 (0.0559)\tPrec@1 97.656 (98.122)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [124][40/66], lr: 0.01000\tTime 0.102 (0.108)\tData 0.031 (0.022)\tLoss 0.0194 (0.0531)\tPrec@1 99.219 (98.199)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [124][50/66], lr: 0.01000\tTime 0.107 (0.105)\tData 0.006 (0.019)\tLoss 0.0695 (0.0533)\tPrec@1 96.484 (98.154)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [124][60/66], lr: 0.01000\tTime 0.082 (0.103)\tData 0.000 (0.017)\tLoss 0.0630 (0.0516)\tPrec@1 98.047 (98.188)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.309 (0.309)\tLoss 1.0655 (1.0655)\tPrec@1 75.000 (75.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.022 (0.046)\tLoss 1.6199 (1.0261)\tPrec@1 80.000 (79.545)\tPrec@5 97.000 (97.091)\n",
            "Test: [20/261]\tTime 0.017 (0.035)\tLoss 1.2076 (1.0111)\tPrec@1 79.000 (80.000)\tPrec@5 96.000 (97.000)\n",
            "Test: [30/261]\tTime 0.022 (0.032)\tLoss 0.8643 (0.9660)\tPrec@1 81.000 (81.000)\tPrec@5 96.000 (97.194)\n",
            "Test: [40/261]\tTime 0.036 (0.030)\tLoss 0.7303 (0.9127)\tPrec@1 90.000 (81.585)\tPrec@5 97.000 (97.293)\n",
            "Test: [50/261]\tTime 0.010 (0.028)\tLoss 1.0342 (0.9012)\tPrec@1 78.000 (81.647)\tPrec@5 98.000 (97.373)\n",
            "Test: [60/261]\tTime 0.029 (0.028)\tLoss 0.7915 (0.9022)\tPrec@1 83.000 (81.623)\tPrec@5 97.000 (97.328)\n",
            "Test: [70/261]\tTime 0.022 (0.027)\tLoss 0.8803 (0.9076)\tPrec@1 81.000 (81.563)\tPrec@5 96.000 (97.338)\n",
            "Test: [80/261]\tTime 0.027 (0.027)\tLoss 0.9931 (0.9146)\tPrec@1 79.000 (81.543)\tPrec@5 97.000 (97.383)\n",
            "Test: [90/261]\tTime 0.043 (0.027)\tLoss 1.2459 (0.9379)\tPrec@1 79.000 (81.275)\tPrec@5 96.000 (97.286)\n",
            "Test: [100/261]\tTime 0.017 (0.026)\tLoss 0.9641 (0.9305)\tPrec@1 79.000 (81.297)\tPrec@5 96.000 (97.307)\n",
            "Test: [110/261]\tTime 0.033 (0.026)\tLoss 1.1701 (0.9273)\tPrec@1 79.000 (81.270)\tPrec@5 97.000 (97.324)\n",
            "Test: [120/261]\tTime 0.044 (0.025)\tLoss 1.0234 (0.9240)\tPrec@1 83.000 (81.355)\tPrec@5 96.000 (97.306)\n",
            "Test: [130/261]\tTime 0.021 (0.026)\tLoss 0.8790 (0.9266)\tPrec@1 82.000 (81.359)\tPrec@5 98.000 (97.328)\n",
            "Test: [140/261]\tTime 0.009 (0.025)\tLoss 1.3171 (0.9280)\tPrec@1 78.000 (81.390)\tPrec@5 95.000 (97.333)\n",
            "Test: [150/261]\tTime 0.020 (0.025)\tLoss 0.7517 (0.9323)\tPrec@1 82.000 (81.358)\tPrec@5 98.000 (97.318)\n",
            "Test: [160/261]\tTime 0.036 (0.025)\tLoss 0.5827 (0.9315)\tPrec@1 88.000 (81.422)\tPrec@5 99.000 (97.335)\n",
            "Test: [170/261]\tTime 0.015 (0.025)\tLoss 0.6094 (0.9269)\tPrec@1 89.000 (81.550)\tPrec@5 96.000 (97.339)\n",
            "Test: [180/261]\tTime 0.024 (0.025)\tLoss 0.8286 (0.9306)\tPrec@1 84.000 (81.525)\tPrec@5 94.000 (97.320)\n",
            "Test: [190/261]\tTime 0.031 (0.025)\tLoss 0.7067 (0.9272)\tPrec@1 81.000 (81.524)\tPrec@5 99.000 (97.346)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 0.9490 (0.9267)\tPrec@1 83.000 (81.493)\tPrec@5 95.000 (97.338)\n",
            "Test: [210/261]\tTime 0.023 (0.025)\tLoss 0.6840 (0.9263)\tPrec@1 88.000 (81.555)\tPrec@5 99.000 (97.327)\n",
            "Test: [220/261]\tTime 0.027 (0.025)\tLoss 1.0348 (0.9262)\tPrec@1 74.000 (81.475)\tPrec@5 97.000 (97.357)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 1.1793 (0.9283)\tPrec@1 79.000 (81.394)\tPrec@5 98.000 (97.333)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.9348 (0.9314)\tPrec@1 81.000 (81.361)\tPrec@5 97.000 (97.307)\n",
            "Test: [250/261]\tTime 0.035 (0.025)\tLoss 0.7417 (0.9280)\tPrec@1 81.000 (81.363)\tPrec@5 98.000 (97.315)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.2316 (0.9301)\tPrec@1 96.875 (81.346)\tPrec@5 100.000 (97.319)\n",
            "val Results: Prec@1 81.346 Prec@5 97.319 Loss 0.93008\n",
            "val Class Accuracy: [0.818,0.967,0.854,0.922,0.859,0.784,0.828,0.750,0.420,0.460]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [125][0/66], lr: 0.01000\tTime 0.466 (0.466)\tData 0.401 (0.401)\tLoss 0.0551 (0.0551)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][10/66], lr: 0.01000\tTime 0.103 (0.142)\tData 0.000 (0.048)\tLoss 0.0306 (0.0461)\tPrec@1 98.828 (98.331)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][20/66], lr: 0.01000\tTime 0.095 (0.119)\tData 0.005 (0.028)\tLoss 0.0442 (0.0485)\tPrec@1 98.828 (98.270)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][30/66], lr: 0.01000\tTime 0.092 (0.111)\tData 0.007 (0.020)\tLoss 0.0516 (0.0501)\tPrec@1 98.438 (98.261)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][40/66], lr: 0.01000\tTime 0.086 (0.106)\tData 0.005 (0.016)\tLoss 0.0321 (0.0481)\tPrec@1 98.828 (98.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][50/66], lr: 0.01000\tTime 0.105 (0.104)\tData 0.000 (0.014)\tLoss 0.0289 (0.0459)\tPrec@1 99.609 (98.399)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [125][60/66], lr: 0.01000\tTime 0.077 (0.101)\tData 0.000 (0.013)\tLoss 0.0548 (0.0450)\tPrec@1 98.047 (98.405)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.292 (0.292)\tLoss 0.7818 (0.7818)\tPrec@1 85.000 (85.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.016 (0.048)\tLoss 1.4537 (0.9424)\tPrec@1 79.000 (81.818)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/261]\tTime 0.024 (0.038)\tLoss 1.1114 (0.9175)\tPrec@1 82.000 (82.048)\tPrec@5 96.000 (97.333)\n",
            "Test: [30/261]\tTime 0.016 (0.032)\tLoss 0.6040 (0.8564)\tPrec@1 86.000 (82.774)\tPrec@5 98.000 (97.677)\n",
            "Test: [40/261]\tTime 0.025 (0.030)\tLoss 0.7268 (0.8239)\tPrec@1 86.000 (83.024)\tPrec@5 97.000 (97.854)\n",
            "Test: [50/261]\tTime 0.032 (0.029)\tLoss 0.9113 (0.8145)\tPrec@1 83.000 (83.275)\tPrec@5 96.000 (98.000)\n",
            "Test: [60/261]\tTime 0.029 (0.028)\tLoss 0.6414 (0.8138)\tPrec@1 86.000 (83.492)\tPrec@5 98.000 (97.967)\n",
            "Test: [70/261]\tTime 0.016 (0.028)\tLoss 0.9029 (0.8120)\tPrec@1 80.000 (83.549)\tPrec@5 99.000 (97.972)\n",
            "Test: [80/261]\tTime 0.031 (0.027)\tLoss 0.9005 (0.8170)\tPrec@1 81.000 (83.420)\tPrec@5 99.000 (98.049)\n",
            "Test: [90/261]\tTime 0.023 (0.027)\tLoss 0.9546 (0.8424)\tPrec@1 83.000 (83.264)\tPrec@5 95.000 (97.901)\n",
            "Test: [100/261]\tTime 0.018 (0.027)\tLoss 0.9597 (0.8311)\tPrec@1 80.000 (83.436)\tPrec@5 97.000 (97.931)\n",
            "Test: [110/261]\tTime 0.011 (0.026)\tLoss 0.8669 (0.8272)\tPrec@1 85.000 (83.423)\tPrec@5 99.000 (97.973)\n",
            "Test: [120/261]\tTime 0.014 (0.026)\tLoss 0.7017 (0.8233)\tPrec@1 87.000 (83.430)\tPrec@5 98.000 (97.967)\n",
            "Test: [130/261]\tTime 0.034 (0.026)\tLoss 0.7159 (0.8293)\tPrec@1 85.000 (83.450)\tPrec@5 98.000 (97.939)\n",
            "Test: [140/261]\tTime 0.030 (0.026)\tLoss 0.9730 (0.8223)\tPrec@1 84.000 (83.518)\tPrec@5 99.000 (97.957)\n",
            "Test: [150/261]\tTime 0.018 (0.025)\tLoss 0.5150 (0.8239)\tPrec@1 87.000 (83.536)\tPrec@5 99.000 (97.974)\n",
            "Test: [160/261]\tTime 0.019 (0.026)\tLoss 0.4583 (0.8222)\tPrec@1 87.000 (83.547)\tPrec@5 100.000 (97.994)\n",
            "Test: [170/261]\tTime 0.022 (0.026)\tLoss 0.7157 (0.8185)\tPrec@1 86.000 (83.591)\tPrec@5 97.000 (97.994)\n",
            "Test: [180/261]\tTime 0.038 (0.026)\tLoss 0.8880 (0.8179)\tPrec@1 86.000 (83.586)\tPrec@5 94.000 (97.956)\n",
            "Test: [190/261]\tTime 0.015 (0.025)\tLoss 0.6921 (0.8169)\tPrec@1 83.000 (83.581)\tPrec@5 99.000 (97.984)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 0.8068 (0.8163)\tPrec@1 85.000 (83.572)\tPrec@5 97.000 (97.985)\n",
            "Test: [210/261]\tTime 0.039 (0.025)\tLoss 0.4803 (0.8157)\tPrec@1 87.000 (83.616)\tPrec@5 99.000 (97.972)\n",
            "Test: [220/261]\tTime 0.036 (0.025)\tLoss 0.7696 (0.8132)\tPrec@1 83.000 (83.584)\tPrec@5 98.000 (98.000)\n",
            "Test: [230/261]\tTime 0.015 (0.025)\tLoss 1.0636 (0.8151)\tPrec@1 75.000 (83.554)\tPrec@5 98.000 (97.983)\n",
            "Test: [240/261]\tTime 0.022 (0.025)\tLoss 0.7627 (0.8184)\tPrec@1 86.000 (83.552)\tPrec@5 98.000 (97.959)\n",
            "Test: [250/261]\tTime 0.023 (0.025)\tLoss 0.6897 (0.8137)\tPrec@1 82.000 (83.614)\tPrec@5 99.000 (97.984)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3027 (0.8180)\tPrec@1 96.875 (83.566)\tPrec@5 96.875 (97.972)\n",
            "val Results: Prec@1 83.566 Prec@5 97.972 Loss 0.81795\n",
            "val Class Accuracy: [0.712,0.967,0.941,0.897,0.906,0.804,0.717,0.770,0.758,0.413]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [126][0/66], lr: 0.01000\tTime 0.621 (0.621)\tData 0.520 (0.520)\tLoss 0.0389 (0.0389)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][10/66], lr: 0.01000\tTime 0.092 (0.146)\tData 0.004 (0.054)\tLoss 0.0414 (0.0398)\tPrec@1 98.438 (98.509)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][20/66], lr: 0.01000\tTime 0.106 (0.122)\tData 0.000 (0.031)\tLoss 0.0943 (0.0460)\tPrec@1 97.266 (98.363)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][30/66], lr: 0.01000\tTime 0.102 (0.112)\tData 0.000 (0.023)\tLoss 0.0625 (0.0470)\tPrec@1 98.047 (98.387)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][40/66], lr: 0.01000\tTime 0.070 (0.107)\tData 0.000 (0.019)\tLoss 0.0367 (0.0459)\tPrec@1 98.828 (98.409)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [126][50/66], lr: 0.01000\tTime 0.097 (0.103)\tData 0.004 (0.016)\tLoss 0.0510 (0.0468)\tPrec@1 97.656 (98.407)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [126][60/66], lr: 0.01000\tTime 0.079 (0.101)\tData 0.000 (0.015)\tLoss 0.0263 (0.0462)\tPrec@1 99.219 (98.450)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.264 (0.264)\tLoss 0.7295 (0.7295)\tPrec@1 82.000 (82.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.020 (0.050)\tLoss 1.2715 (0.7999)\tPrec@1 75.000 (81.818)\tPrec@5 93.000 (97.364)\n",
            "Test: [20/261]\tTime 0.020 (0.037)\tLoss 1.1109 (0.8128)\tPrec@1 77.000 (81.571)\tPrec@5 96.000 (97.095)\n",
            "Test: [30/261]\tTime 0.026 (0.033)\tLoss 0.5537 (0.7710)\tPrec@1 91.000 (83.097)\tPrec@5 97.000 (97.258)\n",
            "Test: [40/261]\tTime 0.035 (0.032)\tLoss 0.7271 (0.7529)\tPrec@1 80.000 (83.220)\tPrec@5 98.000 (97.439)\n",
            "Test: [50/261]\tTime 0.019 (0.031)\tLoss 0.5708 (0.7388)\tPrec@1 83.000 (83.549)\tPrec@5 98.000 (97.490)\n",
            "Test: [60/261]\tTime 0.024 (0.029)\tLoss 0.7351 (0.7371)\tPrec@1 80.000 (83.508)\tPrec@5 99.000 (97.459)\n",
            "Test: [70/261]\tTime 0.014 (0.028)\tLoss 0.6461 (0.7405)\tPrec@1 82.000 (83.493)\tPrec@5 99.000 (97.408)\n",
            "Test: [80/261]\tTime 0.021 (0.028)\tLoss 0.7514 (0.7451)\tPrec@1 81.000 (83.420)\tPrec@5 98.000 (97.395)\n",
            "Test: [90/261]\tTime 0.027 (0.027)\tLoss 0.6927 (0.7765)\tPrec@1 87.000 (83.132)\tPrec@5 98.000 (97.275)\n",
            "Test: [100/261]\tTime 0.031 (0.027)\tLoss 1.0124 (0.7751)\tPrec@1 78.000 (83.119)\tPrec@5 96.000 (97.297)\n",
            "Test: [110/261]\tTime 0.020 (0.027)\tLoss 0.8203 (0.7699)\tPrec@1 83.000 (83.153)\tPrec@5 96.000 (97.297)\n",
            "Test: [120/261]\tTime 0.027 (0.026)\tLoss 0.7572 (0.7682)\tPrec@1 84.000 (83.165)\tPrec@5 97.000 (97.273)\n",
            "Test: [130/261]\tTime 0.019 (0.026)\tLoss 0.8178 (0.7680)\tPrec@1 81.000 (83.183)\tPrec@5 96.000 (97.214)\n",
            "Test: [140/261]\tTime 0.027 (0.026)\tLoss 0.9894 (0.7637)\tPrec@1 78.000 (83.234)\tPrec@5 97.000 (97.262)\n",
            "Test: [150/261]\tTime 0.025 (0.026)\tLoss 0.7390 (0.7586)\tPrec@1 82.000 (83.272)\tPrec@5 98.000 (97.325)\n",
            "Test: [160/261]\tTime 0.039 (0.026)\tLoss 0.4752 (0.7588)\tPrec@1 87.000 (83.304)\tPrec@5 100.000 (97.317)\n",
            "Test: [170/261]\tTime 0.025 (0.026)\tLoss 0.7258 (0.7537)\tPrec@1 86.000 (83.374)\tPrec@5 97.000 (97.310)\n",
            "Test: [180/261]\tTime 0.015 (0.026)\tLoss 0.6336 (0.7534)\tPrec@1 85.000 (83.331)\tPrec@5 96.000 (97.343)\n",
            "Test: [190/261]\tTime 0.035 (0.026)\tLoss 0.6558 (0.7526)\tPrec@1 83.000 (83.319)\tPrec@5 99.000 (97.372)\n",
            "Test: [200/261]\tTime 0.069 (0.026)\tLoss 0.5447 (0.7511)\tPrec@1 86.000 (83.358)\tPrec@5 98.000 (97.348)\n",
            "Test: [210/261]\tTime 0.036 (0.027)\tLoss 0.9302 (0.7520)\tPrec@1 79.000 (83.327)\tPrec@5 99.000 (97.336)\n",
            "Test: [220/261]\tTime 0.032 (0.027)\tLoss 0.6916 (0.7497)\tPrec@1 82.000 (83.308)\tPrec@5 96.000 (97.335)\n",
            "Test: [230/261]\tTime 0.019 (0.028)\tLoss 0.9902 (0.7510)\tPrec@1 78.000 (83.260)\tPrec@5 94.000 (97.329)\n",
            "Test: [240/261]\tTime 0.041 (0.028)\tLoss 0.8432 (0.7563)\tPrec@1 83.000 (83.245)\tPrec@5 98.000 (97.332)\n",
            "Test: [250/261]\tTime 0.050 (0.029)\tLoss 0.5804 (0.7518)\tPrec@1 83.000 (83.299)\tPrec@5 98.000 (97.347)\n",
            "Test: [260/261]\tTime 0.008 (0.028)\tLoss 0.4979 (0.7532)\tPrec@1 87.500 (83.286)\tPrec@5 96.875 (97.334)\n",
            "val Results: Prec@1 83.286 Prec@5 97.334 Loss 0.75321\n",
            "val Class Accuracy: [0.415,0.963,0.919,0.764,0.923,0.874,0.702,0.873,0.708,0.814]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [127][0/66], lr: 0.01000\tTime 0.845 (0.845)\tData 0.755 (0.755)\tLoss 0.0217 (0.0217)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][10/66], lr: 0.01000\tTime 0.073 (0.163)\tData 0.004 (0.075)\tLoss 0.0760 (0.0477)\tPrec@1 97.656 (98.331)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [127][20/66], lr: 0.01000\tTime 0.083 (0.129)\tData 0.006 (0.042)\tLoss 0.0247 (0.0450)\tPrec@1 99.219 (98.512)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [127][30/66], lr: 0.01000\tTime 0.092 (0.117)\tData 0.007 (0.033)\tLoss 0.0586 (0.0462)\tPrec@1 97.656 (98.438)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [127][40/66], lr: 0.01000\tTime 0.085 (0.112)\tData 0.000 (0.026)\tLoss 0.0800 (0.0474)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [127][50/66], lr: 0.01000\tTime 0.094 (0.108)\tData 0.007 (0.022)\tLoss 0.0285 (0.0477)\tPrec@1 99.219 (98.415)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [127][60/66], lr: 0.01000\tTime 0.078 (0.105)\tData 0.000 (0.020)\tLoss 0.1057 (0.0489)\tPrec@1 97.656 (98.393)\tPrec@5 99.609 (99.981)\n",
            "Test: [0/261]\tTime 0.286 (0.286)\tLoss 0.7726 (0.7726)\tPrec@1 86.000 (86.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.020 (0.055)\tLoss 1.2267 (0.9316)\tPrec@1 77.000 (81.545)\tPrec@5 97.000 (96.909)\n",
            "Test: [20/261]\tTime 0.028 (0.040)\tLoss 1.2164 (0.9128)\tPrec@1 79.000 (81.476)\tPrec@5 95.000 (97.095)\n",
            "Test: [30/261]\tTime 0.047 (0.032)\tLoss 0.8534 (0.8625)\tPrec@1 84.000 (82.452)\tPrec@5 98.000 (97.516)\n",
            "Test: [40/261]\tTime 0.023 (0.031)\tLoss 0.6554 (0.8212)\tPrec@1 87.000 (83.341)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/261]\tTime 0.036 (0.031)\tLoss 0.8697 (0.8105)\tPrec@1 79.000 (83.451)\tPrec@5 97.000 (97.745)\n",
            "Test: [60/261]\tTime 0.031 (0.029)\tLoss 0.8029 (0.8103)\tPrec@1 83.000 (83.607)\tPrec@5 99.000 (97.820)\n",
            "Test: [70/261]\tTime 0.015 (0.028)\tLoss 0.6875 (0.8098)\tPrec@1 81.000 (83.535)\tPrec@5 99.000 (97.817)\n",
            "Test: [80/261]\tTime 0.029 (0.027)\tLoss 0.8035 (0.8180)\tPrec@1 83.000 (83.321)\tPrec@5 98.000 (97.864)\n",
            "Test: [90/261]\tTime 0.021 (0.027)\tLoss 0.7646 (0.8430)\tPrec@1 86.000 (83.055)\tPrec@5 97.000 (97.780)\n",
            "Test: [100/261]\tTime 0.016 (0.027)\tLoss 1.1019 (0.8373)\tPrec@1 78.000 (83.059)\tPrec@5 95.000 (97.792)\n",
            "Test: [110/261]\tTime 0.014 (0.026)\tLoss 0.7308 (0.8283)\tPrec@1 83.000 (83.099)\tPrec@5 98.000 (97.802)\n",
            "Test: [120/261]\tTime 0.025 (0.026)\tLoss 0.7452 (0.8259)\tPrec@1 87.000 (83.091)\tPrec@5 97.000 (97.760)\n",
            "Test: [130/261]\tTime 0.021 (0.026)\tLoss 0.9416 (0.8317)\tPrec@1 80.000 (83.031)\tPrec@5 97.000 (97.748)\n",
            "Test: [140/261]\tTime 0.033 (0.026)\tLoss 1.2255 (0.8353)\tPrec@1 74.000 (82.922)\tPrec@5 98.000 (97.809)\n",
            "Test: [150/261]\tTime 0.019 (0.026)\tLoss 0.5706 (0.8336)\tPrec@1 86.000 (83.026)\tPrec@5 98.000 (97.834)\n",
            "Test: [160/261]\tTime 0.026 (0.026)\tLoss 0.5377 (0.8326)\tPrec@1 88.000 (83.087)\tPrec@5 98.000 (97.863)\n",
            "Test: [170/261]\tTime 0.028 (0.026)\tLoss 0.8354 (0.8306)\tPrec@1 84.000 (83.076)\tPrec@5 97.000 (97.865)\n",
            "Test: [180/261]\tTime 0.029 (0.026)\tLoss 0.5865 (0.8299)\tPrec@1 87.000 (83.033)\tPrec@5 96.000 (97.862)\n",
            "Test: [190/261]\tTime 0.017 (0.025)\tLoss 0.7709 (0.8257)\tPrec@1 80.000 (83.052)\tPrec@5 100.000 (97.906)\n",
            "Test: [200/261]\tTime 0.027 (0.025)\tLoss 0.7252 (0.8249)\tPrec@1 84.000 (82.995)\tPrec@5 98.000 (97.905)\n",
            "Test: [210/261]\tTime 0.020 (0.025)\tLoss 0.5326 (0.8260)\tPrec@1 84.000 (82.972)\tPrec@5 99.000 (97.919)\n",
            "Test: [220/261]\tTime 0.023 (0.025)\tLoss 0.6949 (0.8248)\tPrec@1 85.000 (82.973)\tPrec@5 97.000 (97.914)\n",
            "Test: [230/261]\tTime 0.019 (0.025)\tLoss 0.8302 (0.8249)\tPrec@1 84.000 (82.996)\tPrec@5 98.000 (97.892)\n",
            "Test: [240/261]\tTime 0.021 (0.025)\tLoss 0.9169 (0.8284)\tPrec@1 82.000 (82.946)\tPrec@5 98.000 (97.900)\n",
            "Test: [250/261]\tTime 0.019 (0.025)\tLoss 0.7194 (0.8236)\tPrec@1 86.000 (83.020)\tPrec@5 100.000 (97.920)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2804 (0.8243)\tPrec@1 93.750 (83.013)\tPrec@5 100.000 (97.914)\n",
            "val Results: Prec@1 83.013 Prec@5 97.914 Loss 0.82432\n",
            "val Class Accuracy: [0.651,0.958,0.861,0.870,0.898,0.901,0.650,0.835,0.642,0.667]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [128][0/66], lr: 0.01000\tTime 0.554 (0.554)\tData 0.478 (0.478)\tLoss 0.0376 (0.0376)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][10/66], lr: 0.01000\tTime 0.084 (0.130)\tData 0.000 (0.047)\tLoss 0.0584 (0.0557)\tPrec@1 97.656 (98.402)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][20/66], lr: 0.01000\tTime 0.101 (0.114)\tData 0.005 (0.027)\tLoss 0.0355 (0.0514)\tPrec@1 99.219 (98.493)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][30/66], lr: 0.01000\tTime 0.094 (0.107)\tData 0.000 (0.020)\tLoss 0.0232 (0.0470)\tPrec@1 99.609 (98.564)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][40/66], lr: 0.01000\tTime 0.121 (0.102)\tData 0.000 (0.016)\tLoss 0.0256 (0.0470)\tPrec@1 99.609 (98.552)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][50/66], lr: 0.01000\tTime 0.103 (0.101)\tData 0.000 (0.014)\tLoss 0.0420 (0.0467)\tPrec@1 98.828 (98.529)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [128][60/66], lr: 0.01000\tTime 0.078 (0.099)\tData 0.000 (0.012)\tLoss 0.0706 (0.0481)\tPrec@1 96.875 (98.412)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.223 (0.223)\tLoss 0.8951 (0.8951)\tPrec@1 83.000 (83.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.023 (0.046)\tLoss 1.4794 (1.0673)\tPrec@1 78.000 (80.000)\tPrec@5 96.000 (96.636)\n",
            "Test: [20/261]\tTime 0.018 (0.036)\tLoss 1.3608 (1.0248)\tPrec@1 79.000 (80.095)\tPrec@5 95.000 (96.857)\n",
            "Test: [30/261]\tTime 0.019 (0.032)\tLoss 0.9203 (0.9573)\tPrec@1 81.000 (81.387)\tPrec@5 98.000 (97.323)\n",
            "Test: [40/261]\tTime 0.023 (0.030)\tLoss 0.8176 (0.9185)\tPrec@1 82.000 (81.878)\tPrec@5 99.000 (97.488)\n",
            "Test: [50/261]\tTime 0.027 (0.029)\tLoss 0.9642 (0.9001)\tPrec@1 79.000 (82.216)\tPrec@5 99.000 (97.569)\n",
            "Test: [60/261]\tTime 0.017 (0.028)\tLoss 0.7267 (0.8939)\tPrec@1 82.000 (82.295)\tPrec@5 98.000 (97.541)\n",
            "Test: [70/261]\tTime 0.029 (0.027)\tLoss 0.8319 (0.8901)\tPrec@1 81.000 (82.394)\tPrec@5 99.000 (97.549)\n",
            "Test: [80/261]\tTime 0.030 (0.027)\tLoss 0.8731 (0.9026)\tPrec@1 81.000 (82.272)\tPrec@5 99.000 (97.556)\n",
            "Test: [90/261]\tTime 0.017 (0.027)\tLoss 1.0033 (0.9244)\tPrec@1 84.000 (82.143)\tPrec@5 96.000 (97.505)\n",
            "Test: [100/261]\tTime 0.025 (0.027)\tLoss 1.1417 (0.9172)\tPrec@1 74.000 (82.129)\tPrec@5 98.000 (97.465)\n",
            "Test: [110/261]\tTime 0.010 (0.027)\tLoss 1.1232 (0.9154)\tPrec@1 80.000 (82.018)\tPrec@5 97.000 (97.486)\n",
            "Test: [120/261]\tTime 0.027 (0.027)\tLoss 0.9054 (0.9123)\tPrec@1 86.000 (82.083)\tPrec@5 96.000 (97.512)\n",
            "Test: [130/261]\tTime 0.009 (0.027)\tLoss 1.1081 (0.9198)\tPrec@1 80.000 (82.046)\tPrec@5 97.000 (97.473)\n",
            "Test: [140/261]\tTime 0.041 (0.027)\tLoss 1.2125 (0.9188)\tPrec@1 78.000 (81.993)\tPrec@5 98.000 (97.504)\n",
            "Test: [150/261]\tTime 0.017 (0.026)\tLoss 0.7294 (0.9161)\tPrec@1 83.000 (82.026)\tPrec@5 96.000 (97.517)\n",
            "Test: [160/261]\tTime 0.025 (0.026)\tLoss 0.6506 (0.9135)\tPrec@1 82.000 (82.081)\tPrec@5 99.000 (97.553)\n",
            "Test: [170/261]\tTime 0.020 (0.026)\tLoss 0.9481 (0.9072)\tPrec@1 83.000 (82.158)\tPrec@5 98.000 (97.579)\n",
            "Test: [180/261]\tTime 0.019 (0.026)\tLoss 0.9512 (0.9081)\tPrec@1 78.000 (82.138)\tPrec@5 96.000 (97.608)\n",
            "Test: [190/261]\tTime 0.023 (0.026)\tLoss 0.9249 (0.9049)\tPrec@1 77.000 (82.162)\tPrec@5 99.000 (97.644)\n",
            "Test: [200/261]\tTime 0.023 (0.026)\tLoss 0.7175 (0.9031)\tPrec@1 85.000 (82.119)\tPrec@5 96.000 (97.627)\n",
            "Test: [210/261]\tTime 0.014 (0.025)\tLoss 0.9609 (0.9037)\tPrec@1 79.000 (82.137)\tPrec@5 98.000 (97.616)\n",
            "Test: [220/261]\tTime 0.016 (0.025)\tLoss 0.8386 (0.8989)\tPrec@1 84.000 (82.149)\tPrec@5 99.000 (97.624)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 0.8327 (0.8986)\tPrec@1 83.000 (82.186)\tPrec@5 95.000 (97.606)\n",
            "Test: [240/261]\tTime 0.034 (0.025)\tLoss 0.9920 (0.9020)\tPrec@1 85.000 (82.183)\tPrec@5 97.000 (97.585)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.8270 (0.8979)\tPrec@1 81.000 (82.263)\tPrec@5 99.000 (97.586)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.8611 (0.8990)\tPrec@1 78.125 (82.283)\tPrec@5 96.875 (97.557)\n",
            "val Results: Prec@1 82.283 Prec@5 97.557 Loss 0.89901\n",
            "val Class Accuracy: [0.624,0.990,0.880,0.837,0.837,0.868,0.650,0.757,0.675,0.692]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [129][0/66], lr: 0.01000\tTime 0.606 (0.606)\tData 0.542 (0.542)\tLoss 0.0829 (0.0829)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [129][10/66], lr: 0.01000\tTime 0.075 (0.141)\tData 0.000 (0.053)\tLoss 0.0604 (0.0496)\tPrec@1 98.438 (98.224)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [129][20/66], lr: 0.01000\tTime 0.091 (0.119)\tData 0.000 (0.031)\tLoss 0.0271 (0.0539)\tPrec@1 99.219 (98.196)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [129][30/66], lr: 0.01000\tTime 0.095 (0.110)\tData 0.007 (0.024)\tLoss 0.0390 (0.0549)\tPrec@1 97.656 (98.122)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [129][40/66], lr: 0.01000\tTime 0.068 (0.105)\tData 0.005 (0.020)\tLoss 0.0431 (0.0537)\tPrec@1 99.219 (98.199)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [129][50/66], lr: 0.01000\tTime 0.103 (0.103)\tData 0.004 (0.017)\tLoss 0.0681 (0.0535)\tPrec@1 97.656 (98.200)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [129][60/66], lr: 0.01000\tTime 0.076 (0.101)\tData 0.000 (0.015)\tLoss 0.0342 (0.0511)\tPrec@1 99.219 (98.265)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.290 (0.290)\tLoss 0.5843 (0.5843)\tPrec@1 83.000 (83.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.009 (0.049)\tLoss 1.1321 (0.7371)\tPrec@1 81.000 (84.364)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.027 (0.035)\tLoss 0.8404 (0.7487)\tPrec@1 80.000 (84.190)\tPrec@5 97.000 (98.238)\n",
            "Test: [30/261]\tTime 0.039 (0.034)\tLoss 0.5445 (0.6979)\tPrec@1 87.000 (85.194)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.045 (0.032)\tLoss 0.6737 (0.6881)\tPrec@1 86.000 (85.341)\tPrec@5 99.000 (98.463)\n",
            "Test: [50/261]\tTime 0.028 (0.030)\tLoss 0.5816 (0.6830)\tPrec@1 84.000 (85.392)\tPrec@5 98.000 (98.451)\n",
            "Test: [60/261]\tTime 0.017 (0.029)\tLoss 0.6497 (0.6861)\tPrec@1 86.000 (85.361)\tPrec@5 100.000 (98.410)\n",
            "Test: [70/261]\tTime 0.024 (0.028)\tLoss 0.6872 (0.6836)\tPrec@1 84.000 (85.423)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.027 (0.028)\tLoss 0.5977 (0.6898)\tPrec@1 85.000 (85.309)\tPrec@5 99.000 (98.444)\n",
            "Test: [90/261]\tTime 0.021 (0.027)\tLoss 0.6076 (0.7079)\tPrec@1 89.000 (85.165)\tPrec@5 97.000 (98.319)\n",
            "Test: [100/261]\tTime 0.026 (0.027)\tLoss 1.0139 (0.7082)\tPrec@1 85.000 (85.228)\tPrec@5 98.000 (98.327)\n",
            "Test: [110/261]\tTime 0.020 (0.027)\tLoss 0.7396 (0.7018)\tPrec@1 85.000 (85.243)\tPrec@5 99.000 (98.342)\n",
            "Test: [120/261]\tTime 0.025 (0.027)\tLoss 0.7476 (0.7040)\tPrec@1 86.000 (85.248)\tPrec@5 99.000 (98.347)\n",
            "Test: [130/261]\tTime 0.009 (0.026)\tLoss 0.8376 (0.7068)\tPrec@1 82.000 (85.229)\tPrec@5 99.000 (98.359)\n",
            "Test: [140/261]\tTime 0.019 (0.026)\tLoss 0.9189 (0.7053)\tPrec@1 82.000 (85.234)\tPrec@5 97.000 (98.369)\n",
            "Test: [150/261]\tTime 0.020 (0.026)\tLoss 0.5565 (0.7066)\tPrec@1 87.000 (85.298)\tPrec@5 98.000 (98.325)\n",
            "Test: [160/261]\tTime 0.025 (0.026)\tLoss 0.4005 (0.7087)\tPrec@1 89.000 (85.317)\tPrec@5 100.000 (98.323)\n",
            "Test: [170/261]\tTime 0.025 (0.026)\tLoss 0.6450 (0.7027)\tPrec@1 90.000 (85.462)\tPrec@5 97.000 (98.316)\n",
            "Test: [180/261]\tTime 0.020 (0.025)\tLoss 0.7716 (0.7034)\tPrec@1 86.000 (85.436)\tPrec@5 95.000 (98.260)\n",
            "Test: [190/261]\tTime 0.046 (0.025)\tLoss 0.4898 (0.6979)\tPrec@1 89.000 (85.529)\tPrec@5 98.000 (98.262)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 1.0332 (0.7024)\tPrec@1 83.000 (85.398)\tPrec@5 96.000 (98.244)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.8142 (0.7040)\tPrec@1 84.000 (85.412)\tPrec@5 97.000 (98.242)\n",
            "Test: [220/261]\tTime 0.036 (0.025)\tLoss 0.7343 (0.7029)\tPrec@1 86.000 (85.389)\tPrec@5 98.000 (98.276)\n",
            "Test: [230/261]\tTime 0.020 (0.025)\tLoss 0.8044 (0.7066)\tPrec@1 79.000 (85.303)\tPrec@5 98.000 (98.255)\n",
            "Test: [240/261]\tTime 0.050 (0.025)\tLoss 0.7694 (0.7086)\tPrec@1 86.000 (85.299)\tPrec@5 100.000 (98.270)\n",
            "Test: [250/261]\tTime 0.034 (0.025)\tLoss 0.5591 (0.7056)\tPrec@1 87.000 (85.347)\tPrec@5 100.000 (98.279)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.0963 (0.7077)\tPrec@1 96.875 (85.356)\tPrec@5 100.000 (98.275)\n",
            "val Results: Prec@1 85.356 Prec@5 98.275 Loss 0.70766\n",
            "val Class Accuracy: [0.880,0.948,0.940,0.839,0.908,0.760,0.762,0.734,0.811,0.685]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [130][0/66], lr: 0.01000\tTime 0.599 (0.599)\tData 0.519 (0.519)\tLoss 0.0629 (0.0629)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][10/66], lr: 0.01000\tTime 0.102 (0.139)\tData 0.000 (0.052)\tLoss 0.0495 (0.0657)\tPrec@1 98.438 (97.834)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][20/66], lr: 0.01000\tTime 0.079 (0.116)\tData 0.000 (0.029)\tLoss 0.0377 (0.0569)\tPrec@1 98.438 (98.121)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][30/66], lr: 0.01000\tTime 0.091 (0.108)\tData 0.003 (0.022)\tLoss 0.0570 (0.0618)\tPrec@1 98.438 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][40/66], lr: 0.01000\tTime 0.098 (0.104)\tData 0.000 (0.018)\tLoss 0.0497 (0.0601)\tPrec@1 97.656 (98.123)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][50/66], lr: 0.01000\tTime 0.096 (0.102)\tData 0.004 (0.015)\tLoss 0.0623 (0.0593)\tPrec@1 98.828 (98.177)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [130][60/66], lr: 0.01000\tTime 0.076 (0.099)\tData 0.000 (0.014)\tLoss 0.0450 (0.0568)\tPrec@1 98.438 (98.265)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.283 (0.283)\tLoss 0.5917 (0.5917)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.031 (0.049)\tLoss 1.0045 (0.7659)\tPrec@1 81.000 (82.364)\tPrec@5 99.000 (97.909)\n",
            "Test: [20/261]\tTime 0.024 (0.034)\tLoss 0.9054 (0.7429)\tPrec@1 81.000 (83.476)\tPrec@5 97.000 (97.762)\n",
            "Test: [30/261]\tTime 0.038 (0.032)\tLoss 0.5352 (0.7024)\tPrec@1 86.000 (84.548)\tPrec@5 98.000 (97.935)\n",
            "Test: [40/261]\tTime 0.019 (0.029)\tLoss 0.7411 (0.6888)\tPrec@1 84.000 (84.683)\tPrec@5 97.000 (98.024)\n",
            "Test: [50/261]\tTime 0.045 (0.029)\tLoss 0.5730 (0.6726)\tPrec@1 84.000 (84.902)\tPrec@5 97.000 (97.980)\n",
            "Test: [60/261]\tTime 0.017 (0.028)\tLoss 0.4742 (0.6613)\tPrec@1 86.000 (85.131)\tPrec@5 99.000 (98.016)\n",
            "Test: [70/261]\tTime 0.014 (0.027)\tLoss 0.6202 (0.6618)\tPrec@1 84.000 (85.099)\tPrec@5 97.000 (98.014)\n",
            "Test: [80/261]\tTime 0.045 (0.027)\tLoss 0.5587 (0.6611)\tPrec@1 84.000 (85.074)\tPrec@5 99.000 (98.000)\n",
            "Test: [90/261]\tTime 0.020 (0.026)\tLoss 0.7269 (0.6840)\tPrec@1 83.000 (84.802)\tPrec@5 96.000 (97.912)\n",
            "Test: [100/261]\tTime 0.018 (0.026)\tLoss 0.9518 (0.6814)\tPrec@1 84.000 (84.792)\tPrec@5 95.000 (97.921)\n",
            "Test: [110/261]\tTime 0.016 (0.026)\tLoss 0.6894 (0.6798)\tPrec@1 84.000 (84.838)\tPrec@5 99.000 (97.964)\n",
            "Test: [120/261]\tTime 0.038 (0.026)\tLoss 0.7031 (0.6756)\tPrec@1 89.000 (84.917)\tPrec@5 97.000 (97.917)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.6279 (0.6800)\tPrec@1 83.000 (84.855)\tPrec@5 97.000 (97.878)\n",
            "Test: [140/261]\tTime 0.021 (0.025)\tLoss 0.7982 (0.6783)\tPrec@1 81.000 (84.809)\tPrec@5 97.000 (97.887)\n",
            "Test: [150/261]\tTime 0.034 (0.025)\tLoss 0.3694 (0.6802)\tPrec@1 90.000 (84.795)\tPrec@5 98.000 (97.874)\n",
            "Test: [160/261]\tTime 0.032 (0.025)\tLoss 0.1816 (0.6798)\tPrec@1 92.000 (84.783)\tPrec@5 100.000 (97.876)\n",
            "Test: [170/261]\tTime 0.029 (0.025)\tLoss 0.5304 (0.6730)\tPrec@1 86.000 (84.842)\tPrec@5 97.000 (97.865)\n",
            "Test: [180/261]\tTime 0.020 (0.025)\tLoss 0.6933 (0.6729)\tPrec@1 89.000 (84.862)\tPrec@5 95.000 (97.834)\n",
            "Test: [190/261]\tTime 0.030 (0.025)\tLoss 0.6367 (0.6739)\tPrec@1 82.000 (84.827)\tPrec@5 99.000 (97.853)\n",
            "Test: [200/261]\tTime 0.021 (0.025)\tLoss 0.5873 (0.6731)\tPrec@1 85.000 (84.741)\tPrec@5 99.000 (97.876)\n",
            "Test: [210/261]\tTime 0.020 (0.025)\tLoss 0.4696 (0.6721)\tPrec@1 85.000 (84.701)\tPrec@5 98.000 (97.872)\n",
            "Test: [220/261]\tTime 0.018 (0.025)\tLoss 0.6523 (0.6696)\tPrec@1 84.000 (84.715)\tPrec@5 100.000 (97.900)\n",
            "Test: [230/261]\tTime 0.046 (0.025)\tLoss 0.6619 (0.6709)\tPrec@1 84.000 (84.649)\tPrec@5 98.000 (97.892)\n",
            "Test: [240/261]\tTime 0.017 (0.025)\tLoss 0.6979 (0.6738)\tPrec@1 82.000 (84.577)\tPrec@5 99.000 (97.892)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.6027 (0.6699)\tPrec@1 86.000 (84.653)\tPrec@5 99.000 (97.888)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4948 (0.6714)\tPrec@1 90.625 (84.619)\tPrec@5 100.000 (97.891)\n",
            "val Results: Prec@1 84.619 Prec@5 97.891 Loss 0.67137\n",
            "val Class Accuracy: [0.738,0.964,0.930,0.832,0.871,0.898,0.763,0.825,0.751,0.509]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [131][0/66], lr: 0.01000\tTime 0.492 (0.492)\tData 0.397 (0.397)\tLoss 0.0342 (0.0342)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][10/66], lr: 0.01000\tTime 0.098 (0.140)\tData 0.000 (0.046)\tLoss 0.0640 (0.0490)\tPrec@1 97.266 (98.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][20/66], lr: 0.01000\tTime 0.096 (0.118)\tData 0.005 (0.029)\tLoss 0.0469 (0.0470)\tPrec@1 98.438 (98.270)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][30/66], lr: 0.01000\tTime 0.076 (0.110)\tData 0.000 (0.022)\tLoss 0.0287 (0.0450)\tPrec@1 98.438 (98.463)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][40/66], lr: 0.01000\tTime 0.078 (0.105)\tData 0.004 (0.017)\tLoss 0.0485 (0.0448)\tPrec@1 97.656 (98.485)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][50/66], lr: 0.01000\tTime 0.101 (0.103)\tData 0.000 (0.015)\tLoss 0.0658 (0.0452)\tPrec@1 98.438 (98.506)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [131][60/66], lr: 0.01000\tTime 0.067 (0.100)\tData 0.000 (0.013)\tLoss 0.0785 (0.0453)\tPrec@1 97.266 (98.514)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.240 (0.240)\tLoss 0.5903 (0.5903)\tPrec@1 86.000 (86.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.017 (0.045)\tLoss 1.3467 (0.8535)\tPrec@1 79.000 (81.636)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/261]\tTime 0.012 (0.036)\tLoss 1.0419 (0.8401)\tPrec@1 81.000 (81.952)\tPrec@5 97.000 (97.524)\n",
            "Test: [30/261]\tTime 0.042 (0.033)\tLoss 0.6074 (0.7813)\tPrec@1 86.000 (83.065)\tPrec@5 99.000 (97.806)\n",
            "Test: [40/261]\tTime 0.016 (0.029)\tLoss 0.7308 (0.7683)\tPrec@1 89.000 (83.293)\tPrec@5 97.000 (98.049)\n",
            "Test: [50/261]\tTime 0.012 (0.028)\tLoss 0.7002 (0.7663)\tPrec@1 84.000 (83.039)\tPrec@5 97.000 (98.078)\n",
            "Test: [60/261]\tTime 0.009 (0.028)\tLoss 0.5770 (0.7720)\tPrec@1 87.000 (83.246)\tPrec@5 98.000 (97.934)\n",
            "Test: [70/261]\tTime 0.016 (0.027)\tLoss 0.7218 (0.7676)\tPrec@1 80.000 (83.493)\tPrec@5 99.000 (97.930)\n",
            "Test: [80/261]\tTime 0.033 (0.027)\tLoss 0.6569 (0.7648)\tPrec@1 84.000 (83.481)\tPrec@5 99.000 (97.975)\n",
            "Test: [90/261]\tTime 0.038 (0.026)\tLoss 0.8325 (0.7879)\tPrec@1 85.000 (83.341)\tPrec@5 95.000 (97.868)\n",
            "Test: [100/261]\tTime 0.028 (0.026)\tLoss 1.0113 (0.7819)\tPrec@1 78.000 (83.396)\tPrec@5 95.000 (97.842)\n",
            "Test: [110/261]\tTime 0.024 (0.026)\tLoss 1.0527 (0.7800)\tPrec@1 80.000 (83.441)\tPrec@5 98.000 (97.928)\n",
            "Test: [120/261]\tTime 0.027 (0.026)\tLoss 0.7269 (0.7777)\tPrec@1 87.000 (83.471)\tPrec@5 97.000 (97.926)\n",
            "Test: [130/261]\tTime 0.022 (0.026)\tLoss 0.8167 (0.7807)\tPrec@1 85.000 (83.481)\tPrec@5 96.000 (97.878)\n",
            "Test: [140/261]\tTime 0.039 (0.026)\tLoss 0.9088 (0.7783)\tPrec@1 77.000 (83.433)\tPrec@5 98.000 (97.879)\n",
            "Test: [150/261]\tTime 0.034 (0.026)\tLoss 0.5546 (0.7799)\tPrec@1 84.000 (83.424)\tPrec@5 98.000 (97.841)\n",
            "Test: [160/261]\tTime 0.019 (0.026)\tLoss 0.3289 (0.7760)\tPrec@1 90.000 (83.528)\tPrec@5 99.000 (97.857)\n",
            "Test: [170/261]\tTime 0.022 (0.025)\tLoss 0.6388 (0.7694)\tPrec@1 85.000 (83.614)\tPrec@5 97.000 (97.871)\n",
            "Test: [180/261]\tTime 0.013 (0.025)\tLoss 0.6700 (0.7689)\tPrec@1 87.000 (83.613)\tPrec@5 95.000 (97.867)\n",
            "Test: [190/261]\tTime 0.030 (0.025)\tLoss 0.6680 (0.7679)\tPrec@1 83.000 (83.665)\tPrec@5 99.000 (97.895)\n",
            "Test: [200/261]\tTime 0.018 (0.025)\tLoss 0.7049 (0.7688)\tPrec@1 83.000 (83.592)\tPrec@5 98.000 (97.891)\n",
            "Test: [210/261]\tTime 0.017 (0.025)\tLoss 0.5782 (0.7683)\tPrec@1 87.000 (83.578)\tPrec@5 98.000 (97.891)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 0.6107 (0.7637)\tPrec@1 84.000 (83.597)\tPrec@5 98.000 (97.923)\n",
            "Test: [230/261]\tTime 0.027 (0.025)\tLoss 0.7856 (0.7671)\tPrec@1 80.000 (83.481)\tPrec@5 96.000 (97.913)\n",
            "Test: [240/261]\tTime 0.028 (0.025)\tLoss 0.9439 (0.7705)\tPrec@1 80.000 (83.402)\tPrec@5 98.000 (97.884)\n",
            "Test: [250/261]\tTime 0.023 (0.025)\tLoss 0.5770 (0.7681)\tPrec@1 86.000 (83.442)\tPrec@5 99.000 (97.888)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.5206 (0.7719)\tPrec@1 93.750 (83.405)\tPrec@5 96.875 (97.853)\n",
            "val Results: Prec@1 83.405 Prec@5 97.853 Loss 0.77194\n",
            "val Class Accuracy: [0.735,0.961,0.931,0.844,0.881,0.748,0.828,0.752,0.752,0.515]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [132][0/66], lr: 0.01000\tTime 0.576 (0.576)\tData 0.497 (0.497)\tLoss 0.0372 (0.0372)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][10/66], lr: 0.01000\tTime 0.101 (0.139)\tData 0.004 (0.049)\tLoss 0.0352 (0.0448)\tPrec@1 98.828 (98.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][20/66], lr: 0.01000\tTime 0.069 (0.118)\tData 0.000 (0.029)\tLoss 0.0276 (0.0471)\tPrec@1 99.609 (98.214)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][30/66], lr: 0.01000\tTime 0.103 (0.110)\tData 0.012 (0.022)\tLoss 0.0618 (0.0475)\tPrec@1 97.656 (98.299)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][40/66], lr: 0.01000\tTime 0.087 (0.106)\tData 0.000 (0.018)\tLoss 0.0480 (0.0467)\tPrec@1 99.219 (98.371)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][50/66], lr: 0.01000\tTime 0.096 (0.103)\tData 0.007 (0.016)\tLoss 0.0552 (0.0467)\tPrec@1 97.656 (98.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [132][60/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.014)\tLoss 0.0496 (0.0472)\tPrec@1 98.047 (98.361)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.263 (0.263)\tLoss 0.5367 (0.5367)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.036 (0.047)\tLoss 1.2116 (0.8493)\tPrec@1 81.000 (81.455)\tPrec@5 97.000 (97.364)\n",
            "Test: [20/261]\tTime 0.010 (0.036)\tLoss 0.8330 (0.8203)\tPrec@1 82.000 (82.048)\tPrec@5 97.000 (97.524)\n",
            "Test: [30/261]\tTime 0.027 (0.033)\tLoss 0.5809 (0.7331)\tPrec@1 86.000 (83.871)\tPrec@5 99.000 (97.903)\n",
            "Test: [40/261]\tTime 0.022 (0.031)\tLoss 0.6580 (0.7130)\tPrec@1 85.000 (84.195)\tPrec@5 99.000 (98.122)\n",
            "Test: [50/261]\tTime 0.025 (0.030)\tLoss 0.4706 (0.6955)\tPrec@1 85.000 (84.412)\tPrec@5 98.000 (98.294)\n",
            "Test: [60/261]\tTime 0.042 (0.029)\tLoss 0.7515 (0.6935)\tPrec@1 83.000 (84.541)\tPrec@5 99.000 (98.311)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 0.5455 (0.6861)\tPrec@1 82.000 (84.577)\tPrec@5 99.000 (98.324)\n",
            "Test: [80/261]\tTime 0.026 (0.027)\tLoss 0.5775 (0.6850)\tPrec@1 86.000 (84.580)\tPrec@5 99.000 (98.296)\n",
            "Test: [90/261]\tTime 0.026 (0.026)\tLoss 0.7195 (0.7067)\tPrec@1 83.000 (84.330)\tPrec@5 96.000 (98.198)\n",
            "Test: [100/261]\tTime 0.022 (0.026)\tLoss 0.9767 (0.7015)\tPrec@1 81.000 (84.535)\tPrec@5 97.000 (98.168)\n",
            "Test: [110/261]\tTime 0.032 (0.026)\tLoss 0.6597 (0.6973)\tPrec@1 84.000 (84.514)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.012 (0.026)\tLoss 0.7542 (0.6916)\tPrec@1 87.000 (84.628)\tPrec@5 98.000 (98.273)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.6720 (0.6958)\tPrec@1 86.000 (84.664)\tPrec@5 99.000 (98.260)\n",
            "Test: [140/261]\tTime 0.013 (0.026)\tLoss 0.9377 (0.6935)\tPrec@1 82.000 (84.667)\tPrec@5 98.000 (98.305)\n",
            "Test: [150/261]\tTime 0.022 (0.026)\tLoss 0.4810 (0.6937)\tPrec@1 87.000 (84.715)\tPrec@5 98.000 (98.278)\n",
            "Test: [160/261]\tTime 0.030 (0.025)\tLoss 0.3131 (0.6924)\tPrec@1 93.000 (84.739)\tPrec@5 100.000 (98.317)\n",
            "Test: [170/261]\tTime 0.016 (0.025)\tLoss 0.5439 (0.6865)\tPrec@1 90.000 (84.848)\tPrec@5 97.000 (98.322)\n",
            "Test: [180/261]\tTime 0.031 (0.025)\tLoss 0.6865 (0.6862)\tPrec@1 83.000 (84.862)\tPrec@5 96.000 (98.331)\n",
            "Test: [190/261]\tTime 0.023 (0.025)\tLoss 0.5263 (0.6844)\tPrec@1 87.000 (84.932)\tPrec@5 99.000 (98.356)\n",
            "Test: [200/261]\tTime 0.017 (0.025)\tLoss 0.6609 (0.6822)\tPrec@1 85.000 (84.905)\tPrec@5 98.000 (98.373)\n",
            "Test: [210/261]\tTime 0.044 (0.025)\tLoss 0.5257 (0.6799)\tPrec@1 87.000 (84.943)\tPrec@5 99.000 (98.370)\n",
            "Test: [220/261]\tTime 0.017 (0.025)\tLoss 0.5695 (0.6764)\tPrec@1 84.000 (84.959)\tPrec@5 100.000 (98.407)\n",
            "Test: [230/261]\tTime 0.025 (0.025)\tLoss 0.7385 (0.6784)\tPrec@1 80.000 (84.905)\tPrec@5 97.000 (98.390)\n",
            "Test: [240/261]\tTime 0.020 (0.025)\tLoss 0.5427 (0.6791)\tPrec@1 83.000 (84.888)\tPrec@5 99.000 (98.386)\n",
            "Test: [250/261]\tTime 0.018 (0.025)\tLoss 0.4567 (0.6749)\tPrec@1 86.000 (84.920)\tPrec@5 100.000 (98.406)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.4202 (0.6776)\tPrec@1 93.750 (84.907)\tPrec@5 100.000 (98.398)\n",
            "val Results: Prec@1 84.907 Prec@5 98.398 Loss 0.67755\n",
            "val Class Accuracy: [0.795,0.917,0.960,0.848,0.907,0.764,0.897,0.770,0.758,0.574]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [133][0/66], lr: 0.01000\tTime 0.530 (0.530)\tData 0.457 (0.457)\tLoss 0.0213 (0.0213)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][10/66], lr: 0.01000\tTime 0.093 (0.137)\tData 0.000 (0.045)\tLoss 0.0379 (0.0388)\tPrec@1 98.828 (98.686)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][20/66], lr: 0.01000\tTime 0.085 (0.118)\tData 0.001 (0.026)\tLoss 0.0474 (0.0477)\tPrec@1 98.047 (98.326)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][30/66], lr: 0.01000\tTime 0.103 (0.110)\tData 0.000 (0.019)\tLoss 0.0446 (0.0525)\tPrec@1 98.438 (98.223)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][40/66], lr: 0.01000\tTime 0.112 (0.105)\tData 0.000 (0.016)\tLoss 0.0595 (0.0516)\tPrec@1 98.047 (98.247)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][50/66], lr: 0.01000\tTime 0.091 (0.103)\tData 0.005 (0.014)\tLoss 0.0400 (0.0503)\tPrec@1 98.828 (98.277)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [133][60/66], lr: 0.01000\tTime 0.067 (0.100)\tData 0.000 (0.013)\tLoss 0.0311 (0.0502)\tPrec@1 98.828 (98.239)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.209 (0.209)\tLoss 0.8961 (0.8961)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.047 (0.046)\tLoss 1.2329 (0.9201)\tPrec@1 79.000 (81.091)\tPrec@5 99.000 (97.636)\n",
            "Test: [20/261]\tTime 0.026 (0.034)\tLoss 1.1424 (0.8668)\tPrec@1 79.000 (81.810)\tPrec@5 96.000 (97.714)\n",
            "Test: [30/261]\tTime 0.036 (0.031)\tLoss 0.6887 (0.8254)\tPrec@1 84.000 (82.258)\tPrec@5 99.000 (98.161)\n",
            "Test: [40/261]\tTime 0.028 (0.030)\tLoss 0.5149 (0.7824)\tPrec@1 87.000 (82.878)\tPrec@5 98.000 (98.341)\n",
            "Test: [50/261]\tTime 0.014 (0.027)\tLoss 0.4766 (0.7629)\tPrec@1 87.000 (83.235)\tPrec@5 98.000 (98.392)\n",
            "Test: [60/261]\tTime 0.023 (0.027)\tLoss 0.6560 (0.7594)\tPrec@1 81.000 (83.393)\tPrec@5 99.000 (98.311)\n",
            "Test: [70/261]\tTime 0.042 (0.027)\tLoss 0.5716 (0.7599)\tPrec@1 83.000 (83.507)\tPrec@5 99.000 (98.296)\n",
            "Test: [80/261]\tTime 0.009 (0.027)\tLoss 0.8437 (0.7675)\tPrec@1 82.000 (83.432)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/261]\tTime 0.019 (0.026)\tLoss 0.7885 (0.7867)\tPrec@1 84.000 (83.253)\tPrec@5 98.000 (98.264)\n",
            "Test: [100/261]\tTime 0.034 (0.026)\tLoss 0.9729 (0.7814)\tPrec@1 80.000 (83.287)\tPrec@5 99.000 (98.317)\n",
            "Test: [110/261]\tTime 0.016 (0.026)\tLoss 1.1058 (0.7749)\tPrec@1 81.000 (83.405)\tPrec@5 96.000 (98.342)\n",
            "Test: [120/261]\tTime 0.024 (0.026)\tLoss 0.9655 (0.7696)\tPrec@1 84.000 (83.603)\tPrec@5 98.000 (98.306)\n",
            "Test: [130/261]\tTime 0.025 (0.026)\tLoss 0.6702 (0.7713)\tPrec@1 82.000 (83.550)\tPrec@5 99.000 (98.305)\n",
            "Test: [140/261]\tTime 0.013 (0.025)\tLoss 0.7177 (0.7671)\tPrec@1 84.000 (83.603)\tPrec@5 99.000 (98.312)\n",
            "Test: [150/261]\tTime 0.026 (0.025)\tLoss 0.6394 (0.7696)\tPrec@1 85.000 (83.609)\tPrec@5 98.000 (98.265)\n",
            "Test: [160/261]\tTime 0.013 (0.025)\tLoss 0.3433 (0.7674)\tPrec@1 92.000 (83.646)\tPrec@5 100.000 (98.267)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.6054 (0.7613)\tPrec@1 87.000 (83.784)\tPrec@5 98.000 (98.287)\n",
            "Test: [180/261]\tTime 0.037 (0.025)\tLoss 0.6155 (0.7638)\tPrec@1 87.000 (83.740)\tPrec@5 96.000 (98.260)\n",
            "Test: [190/261]\tTime 0.029 (0.025)\tLoss 0.5337 (0.7590)\tPrec@1 83.000 (83.770)\tPrec@5 100.000 (98.277)\n",
            "Test: [200/261]\tTime 0.033 (0.025)\tLoss 0.7041 (0.7588)\tPrec@1 86.000 (83.741)\tPrec@5 98.000 (98.294)\n",
            "Test: [210/261]\tTime 0.018 (0.025)\tLoss 0.6729 (0.7584)\tPrec@1 85.000 (83.758)\tPrec@5 98.000 (98.275)\n",
            "Test: [220/261]\tTime 0.033 (0.025)\tLoss 0.7960 (0.7559)\tPrec@1 80.000 (83.765)\tPrec@5 99.000 (98.308)\n",
            "Test: [230/261]\tTime 0.039 (0.025)\tLoss 1.0172 (0.7597)\tPrec@1 80.000 (83.710)\tPrec@5 96.000 (98.268)\n",
            "Test: [240/261]\tTime 0.010 (0.025)\tLoss 0.7543 (0.7618)\tPrec@1 87.000 (83.730)\tPrec@5 98.000 (98.245)\n",
            "Test: [250/261]\tTime 0.022 (0.025)\tLoss 0.5078 (0.7569)\tPrec@1 86.000 (83.745)\tPrec@5 100.000 (98.251)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3796 (0.7570)\tPrec@1 90.625 (83.735)\tPrec@5 100.000 (98.248)\n",
            "val Results: Prec@1 83.735 Prec@5 98.248 Loss 0.75696\n",
            "val Class Accuracy: [0.690,0.974,0.859,0.892,0.854,0.740,0.855,0.769,0.675,0.760]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [134][0/66], lr: 0.01000\tTime 0.563 (0.563)\tData 0.470 (0.470)\tLoss 0.0568 (0.0568)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][10/66], lr: 0.01000\tTime 0.087 (0.140)\tData 0.000 (0.048)\tLoss 0.0667 (0.0485)\tPrec@1 96.875 (98.402)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][20/66], lr: 0.01000\tTime 0.085 (0.117)\tData 0.005 (0.027)\tLoss 0.0458 (0.0470)\tPrec@1 97.266 (98.251)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][30/66], lr: 0.01000\tTime 0.077 (0.109)\tData 0.000 (0.021)\tLoss 0.0475 (0.0455)\tPrec@1 98.438 (98.362)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][40/66], lr: 0.01000\tTime 0.089 (0.105)\tData 0.001 (0.017)\tLoss 0.0874 (0.0465)\tPrec@1 97.656 (98.342)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][50/66], lr: 0.01000\tTime 0.073 (0.102)\tData 0.006 (0.015)\tLoss 0.0558 (0.0505)\tPrec@1 98.047 (98.208)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [134][60/66], lr: 0.01000\tTime 0.081 (0.100)\tData 0.000 (0.014)\tLoss 0.0390 (0.0531)\tPrec@1 98.438 (98.156)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.268 (0.268)\tLoss 0.8085 (0.8085)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.009 (0.047)\tLoss 1.0453 (0.8689)\tPrec@1 78.000 (80.273)\tPrec@5 96.000 (96.727)\n",
            "Test: [20/261]\tTime 0.030 (0.035)\tLoss 1.2288 (0.8827)\tPrec@1 70.000 (80.333)\tPrec@5 95.000 (96.762)\n",
            "Test: [30/261]\tTime 0.041 (0.031)\tLoss 0.7654 (0.8273)\tPrec@1 84.000 (81.613)\tPrec@5 99.000 (97.258)\n",
            "Test: [40/261]\tTime 0.023 (0.029)\tLoss 0.7482 (0.8111)\tPrec@1 84.000 (82.024)\tPrec@5 98.000 (97.463)\n",
            "Test: [50/261]\tTime 0.018 (0.028)\tLoss 0.5876 (0.8023)\tPrec@1 84.000 (82.255)\tPrec@5 98.000 (97.569)\n",
            "Test: [60/261]\tTime 0.038 (0.028)\tLoss 0.8654 (0.7945)\tPrec@1 78.000 (82.508)\tPrec@5 97.000 (97.525)\n",
            "Test: [70/261]\tTime 0.010 (0.027)\tLoss 0.9952 (0.7982)\tPrec@1 80.000 (82.493)\tPrec@5 99.000 (97.577)\n",
            "Test: [80/261]\tTime 0.013 (0.026)\tLoss 1.0408 (0.8066)\tPrec@1 78.000 (82.247)\tPrec@5 99.000 (97.617)\n",
            "Test: [90/261]\tTime 0.017 (0.027)\tLoss 0.6337 (0.8334)\tPrec@1 86.000 (82.132)\tPrec@5 96.000 (97.538)\n",
            "Test: [100/261]\tTime 0.020 (0.026)\tLoss 1.1039 (0.8278)\tPrec@1 76.000 (82.198)\tPrec@5 96.000 (97.545)\n",
            "Test: [110/261]\tTime 0.035 (0.026)\tLoss 0.7729 (0.8217)\tPrec@1 83.000 (82.180)\tPrec@5 98.000 (97.559)\n",
            "Test: [120/261]\tTime 0.019 (0.026)\tLoss 0.7230 (0.8208)\tPrec@1 83.000 (82.165)\tPrec@5 98.000 (97.570)\n",
            "Test: [130/261]\tTime 0.048 (0.026)\tLoss 0.8724 (0.8218)\tPrec@1 80.000 (82.145)\tPrec@5 99.000 (97.573)\n",
            "Test: [140/261]\tTime 0.023 (0.025)\tLoss 0.8296 (0.8177)\tPrec@1 76.000 (82.092)\tPrec@5 97.000 (97.603)\n",
            "Test: [150/261]\tTime 0.015 (0.025)\tLoss 0.7256 (0.8166)\tPrec@1 85.000 (82.159)\tPrec@5 98.000 (97.623)\n",
            "Test: [160/261]\tTime 0.030 (0.025)\tLoss 0.5067 (0.8136)\tPrec@1 88.000 (82.168)\tPrec@5 98.000 (97.677)\n",
            "Test: [170/261]\tTime 0.038 (0.025)\tLoss 0.5443 (0.8096)\tPrec@1 89.000 (82.275)\tPrec@5 98.000 (97.678)\n",
            "Test: [180/261]\tTime 0.017 (0.025)\tLoss 0.7218 (0.8130)\tPrec@1 84.000 (82.260)\tPrec@5 94.000 (97.669)\n",
            "Test: [190/261]\tTime 0.027 (0.025)\tLoss 0.7348 (0.8098)\tPrec@1 84.000 (82.340)\tPrec@5 100.000 (97.696)\n",
            "Test: [200/261]\tTime 0.033 (0.025)\tLoss 0.7002 (0.8123)\tPrec@1 84.000 (82.279)\tPrec@5 97.000 (97.692)\n",
            "Test: [210/261]\tTime 0.018 (0.025)\tLoss 1.0860 (0.8109)\tPrec@1 76.000 (82.327)\tPrec@5 97.000 (97.659)\n",
            "Test: [220/261]\tTime 0.012 (0.025)\tLoss 0.9329 (0.8067)\tPrec@1 82.000 (82.385)\tPrec@5 98.000 (97.688)\n",
            "Test: [230/261]\tTime 0.034 (0.025)\tLoss 1.2597 (0.8096)\tPrec@1 74.000 (82.359)\tPrec@5 96.000 (97.714)\n",
            "Test: [240/261]\tTime 0.015 (0.025)\tLoss 0.7545 (0.8089)\tPrec@1 83.000 (82.407)\tPrec@5 97.000 (97.710)\n",
            "Test: [250/261]\tTime 0.013 (0.025)\tLoss 0.4780 (0.8059)\tPrec@1 86.000 (82.450)\tPrec@5 100.000 (97.705)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.5584 (0.8055)\tPrec@1 84.375 (82.475)\tPrec@5 96.875 (97.703)\n",
            "val Results: Prec@1 82.475 Prec@5 97.703 Loss 0.80554\n",
            "val Class Accuracy: [0.362,0.947,0.958,0.794,0.894,0.820,0.882,0.745,0.687,0.719]\n",
            "Best Prec@1: 85.787\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [135][0/66], lr: 0.01000\tTime 0.532 (0.532)\tData 0.454 (0.454)\tLoss 0.0704 (0.0704)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [135][10/66], lr: 0.01000\tTime 0.086 (0.134)\tData 0.001 (0.045)\tLoss 0.0623 (0.0593)\tPrec@1 98.047 (97.834)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [135][20/66], lr: 0.01000\tTime 0.094 (0.114)\tData 0.000 (0.026)\tLoss 0.0255 (0.0564)\tPrec@1 99.609 (97.991)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [135][30/66], lr: 0.01000\tTime 0.097 (0.108)\tData 0.000 (0.019)\tLoss 0.0521 (0.0557)\tPrec@1 97.656 (98.047)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [135][40/66], lr: 0.01000\tTime 0.084 (0.103)\tData 0.000 (0.015)\tLoss 0.0562 (0.0555)\tPrec@1 97.656 (98.009)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [135][50/66], lr: 0.01000\tTime 0.084 (0.100)\tData 0.000 (0.013)\tLoss 0.0510 (0.0539)\tPrec@1 98.438 (98.085)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [135][60/66], lr: 0.01000\tTime 0.077 (0.098)\tData 0.000 (0.012)\tLoss 0.0670 (0.0530)\tPrec@1 97.656 (98.143)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.213 (0.213)\tLoss 0.6435 (0.6435)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.017 (0.047)\tLoss 1.1968 (0.7490)\tPrec@1 80.000 (85.000)\tPrec@5 99.000 (97.909)\n",
            "Test: [20/261]\tTime 0.032 (0.037)\tLoss 1.1638 (0.7380)\tPrec@1 80.000 (84.762)\tPrec@5 96.000 (97.810)\n",
            "Test: [30/261]\tTime 0.027 (0.033)\tLoss 0.3557 (0.6553)\tPrec@1 90.000 (86.065)\tPrec@5 99.000 (98.194)\n",
            "Test: [40/261]\tTime 0.023 (0.031)\tLoss 0.6955 (0.6448)\tPrec@1 84.000 (85.976)\tPrec@5 97.000 (98.341)\n",
            "Test: [50/261]\tTime 0.019 (0.029)\tLoss 0.5383 (0.6567)\tPrec@1 86.000 (85.784)\tPrec@5 99.000 (98.392)\n",
            "Test: [60/261]\tTime 0.035 (0.029)\tLoss 0.6805 (0.6476)\tPrec@1 87.000 (86.033)\tPrec@5 97.000 (98.344)\n",
            "Test: [70/261]\tTime 0.023 (0.028)\tLoss 0.5102 (0.6505)\tPrec@1 90.000 (86.169)\tPrec@5 99.000 (98.352)\n",
            "Test: [80/261]\tTime 0.031 (0.028)\tLoss 0.6436 (0.6499)\tPrec@1 84.000 (86.198)\tPrec@5 99.000 (98.407)\n",
            "Test: [90/261]\tTime 0.031 (0.027)\tLoss 0.4825 (0.6742)\tPrec@1 90.000 (86.000)\tPrec@5 97.000 (98.286)\n",
            "Test: [100/261]\tTime 0.028 (0.027)\tLoss 1.0441 (0.6734)\tPrec@1 83.000 (86.000)\tPrec@5 98.000 (98.257)\n",
            "Test: [110/261]\tTime 0.025 (0.027)\tLoss 0.7178 (0.6682)\tPrec@1 86.000 (85.919)\tPrec@5 99.000 (98.342)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 0.7250 (0.6713)\tPrec@1 88.000 (85.950)\tPrec@5 98.000 (98.322)\n",
            "Test: [130/261]\tTime 0.032 (0.027)\tLoss 0.8921 (0.6774)\tPrec@1 85.000 (85.893)\tPrec@5 97.000 (98.305)\n",
            "Test: [140/261]\tTime 0.024 (0.027)\tLoss 0.7269 (0.6721)\tPrec@1 82.000 (85.879)\tPrec@5 99.000 (98.305)\n",
            "Test: [150/261]\tTime 0.016 (0.026)\tLoss 0.8020 (0.6742)\tPrec@1 85.000 (85.901)\tPrec@5 98.000 (98.305)\n",
            "Test: [160/261]\tTime 0.021 (0.026)\tLoss 0.4236 (0.6743)\tPrec@1 88.000 (85.938)\tPrec@5 100.000 (98.304)\n",
            "Test: [170/261]\tTime 0.027 (0.026)\tLoss 0.5628 (0.6688)\tPrec@1 92.000 (86.000)\tPrec@5 98.000 (98.316)\n",
            "Test: [180/261]\tTime 0.033 (0.026)\tLoss 0.5146 (0.6693)\tPrec@1 88.000 (85.961)\tPrec@5 95.000 (98.293)\n",
            "Test: [190/261]\tTime 0.021 (0.026)\tLoss 0.4584 (0.6695)\tPrec@1 87.000 (85.937)\tPrec@5 100.000 (98.314)\n",
            "Test: [200/261]\tTime 0.037 (0.026)\tLoss 0.6676 (0.6711)\tPrec@1 86.000 (85.915)\tPrec@5 98.000 (98.299)\n",
            "Test: [210/261]\tTime 0.016 (0.025)\tLoss 0.7673 (0.6719)\tPrec@1 85.000 (85.896)\tPrec@5 99.000 (98.303)\n",
            "Test: [220/261]\tTime 0.037 (0.025)\tLoss 0.7777 (0.6688)\tPrec@1 83.000 (85.900)\tPrec@5 99.000 (98.335)\n",
            "Test: [230/261]\tTime 0.024 (0.026)\tLoss 0.7640 (0.6698)\tPrec@1 87.000 (85.840)\tPrec@5 97.000 (98.325)\n",
            "Test: [240/261]\tTime 0.012 (0.025)\tLoss 0.7637 (0.6745)\tPrec@1 86.000 (85.793)\tPrec@5 97.000 (98.299)\n",
            "Test: [250/261]\tTime 0.020 (0.025)\tLoss 0.7031 (0.6706)\tPrec@1 81.000 (85.845)\tPrec@5 100.000 (98.311)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.1940 (0.6713)\tPrec@1 93.750 (85.825)\tPrec@5 100.000 (98.298)\n",
            "val Results: Prec@1 85.825 Prec@5 98.298 Loss 0.67128\n",
            "val Class Accuracy: [0.815,0.980,0.904,0.778,0.891,0.872,0.779,0.784,0.815,0.708]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [136][0/66], lr: 0.01000\tTime 0.533 (0.533)\tData 0.452 (0.452)\tLoss 0.0384 (0.0384)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][10/66], lr: 0.01000\tTime 0.101 (0.129)\tData 0.000 (0.047)\tLoss 0.0288 (0.0493)\tPrec@1 98.828 (98.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][20/66], lr: 0.01000\tTime 0.104 (0.113)\tData 0.054 (0.030)\tLoss 0.0718 (0.0445)\tPrec@1 98.047 (98.475)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][30/66], lr: 0.01000\tTime 0.087 (0.105)\tData 0.000 (0.022)\tLoss 0.0555 (0.0428)\tPrec@1 98.047 (98.513)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][40/66], lr: 0.01000\tTime 0.106 (0.103)\tData 0.000 (0.018)\tLoss 0.0551 (0.0445)\tPrec@1 98.828 (98.552)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][50/66], lr: 0.01000\tTime 0.083 (0.101)\tData 0.000 (0.015)\tLoss 0.0452 (0.0439)\tPrec@1 98.828 (98.583)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [136][60/66], lr: 0.01000\tTime 0.075 (0.099)\tData 0.000 (0.013)\tLoss 0.0330 (0.0432)\tPrec@1 99.219 (98.572)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.218 (0.218)\tLoss 0.6801 (0.6801)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.034 (0.050)\tLoss 1.4374 (0.8638)\tPrec@1 78.000 (81.909)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/261]\tTime 0.031 (0.037)\tLoss 1.0429 (0.8650)\tPrec@1 78.000 (81.714)\tPrec@5 97.000 (97.381)\n",
            "Test: [30/261]\tTime 0.034 (0.034)\tLoss 0.7677 (0.8280)\tPrec@1 87.000 (82.839)\tPrec@5 99.000 (97.484)\n",
            "Test: [40/261]\tTime 0.037 (0.031)\tLoss 0.7905 (0.8177)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (97.610)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.5731 (0.8186)\tPrec@1 88.000 (83.039)\tPrec@5 98.000 (97.667)\n",
            "Test: [60/261]\tTime 0.033 (0.029)\tLoss 0.9864 (0.8276)\tPrec@1 77.000 (82.967)\tPrec@5 98.000 (97.623)\n",
            "Test: [70/261]\tTime 0.031 (0.028)\tLoss 0.9366 (0.8293)\tPrec@1 80.000 (82.958)\tPrec@5 98.000 (97.592)\n",
            "Test: [80/261]\tTime 0.017 (0.027)\tLoss 0.8454 (0.8269)\tPrec@1 81.000 (82.975)\tPrec@5 99.000 (97.691)\n",
            "Test: [90/261]\tTime 0.014 (0.027)\tLoss 0.7254 (0.8521)\tPrec@1 83.000 (82.736)\tPrec@5 97.000 (97.549)\n",
            "Test: [100/261]\tTime 0.018 (0.027)\tLoss 1.1281 (0.8508)\tPrec@1 82.000 (82.772)\tPrec@5 97.000 (97.505)\n",
            "Test: [110/261]\tTime 0.027 (0.026)\tLoss 0.9402 (0.8440)\tPrec@1 81.000 (82.811)\tPrec@5 95.000 (97.468)\n",
            "Test: [120/261]\tTime 0.043 (0.026)\tLoss 0.8279 (0.8460)\tPrec@1 87.000 (82.843)\tPrec@5 97.000 (97.479)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 1.2240 (0.8461)\tPrec@1 78.000 (82.878)\tPrec@5 97.000 (97.473)\n",
            "Test: [140/261]\tTime 0.018 (0.026)\tLoss 1.0195 (0.8410)\tPrec@1 80.000 (82.865)\tPrec@5 97.000 (97.496)\n",
            "Test: [150/261]\tTime 0.043 (0.026)\tLoss 0.6977 (0.8433)\tPrec@1 85.000 (82.828)\tPrec@5 96.000 (97.444)\n",
            "Test: [160/261]\tTime 0.036 (0.026)\tLoss 0.4635 (0.8440)\tPrec@1 91.000 (82.894)\tPrec@5 98.000 (97.404)\n",
            "Test: [170/261]\tTime 0.012 (0.025)\tLoss 0.8259 (0.8386)\tPrec@1 86.000 (82.977)\tPrec@5 96.000 (97.427)\n",
            "Test: [180/261]\tTime 0.040 (0.025)\tLoss 0.5929 (0.8387)\tPrec@1 87.000 (82.961)\tPrec@5 97.000 (97.414)\n",
            "Test: [190/261]\tTime 0.012 (0.025)\tLoss 0.4765 (0.8331)\tPrec@1 85.000 (83.021)\tPrec@5 99.000 (97.461)\n",
            "Test: [200/261]\tTime 0.026 (0.025)\tLoss 0.6132 (0.8332)\tPrec@1 85.000 (82.995)\tPrec@5 98.000 (97.453)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.9134 (0.8321)\tPrec@1 80.000 (83.019)\tPrec@5 98.000 (97.450)\n",
            "Test: [220/261]\tTime 0.033 (0.025)\tLoss 0.9162 (0.8291)\tPrec@1 81.000 (83.059)\tPrec@5 96.000 (97.443)\n",
            "Test: [230/261]\tTime 0.021 (0.025)\tLoss 0.8869 (0.8303)\tPrec@1 81.000 (83.065)\tPrec@5 95.000 (97.429)\n",
            "Test: [240/261]\tTime 0.025 (0.025)\tLoss 0.8362 (0.8318)\tPrec@1 80.000 (83.058)\tPrec@5 97.000 (97.427)\n",
            "Test: [250/261]\tTime 0.016 (0.025)\tLoss 0.5484 (0.8277)\tPrec@1 81.000 (83.120)\tPrec@5 100.000 (97.458)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3494 (0.8304)\tPrec@1 90.625 (83.090)\tPrec@5 96.875 (97.449)\n",
            "val Results: Prec@1 83.090 Prec@5 97.449 Loss 0.83037\n",
            "val Class Accuracy: [0.451,0.945,0.925,0.870,0.910,0.822,0.743,0.706,0.852,0.699]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [137][0/66], lr: 0.01000\tTime 0.520 (0.520)\tData 0.446 (0.446)\tLoss 0.0395 (0.0395)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][10/66], lr: 0.01000\tTime 0.093 (0.131)\tData 0.000 (0.044)\tLoss 0.0915 (0.0536)\tPrec@1 97.266 (98.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][20/66], lr: 0.01000\tTime 0.083 (0.114)\tData 0.011 (0.029)\tLoss 0.0348 (0.0474)\tPrec@1 99.219 (98.549)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][30/66], lr: 0.01000\tTime 0.102 (0.107)\tData 0.000 (0.022)\tLoss 0.0434 (0.0462)\tPrec@1 99.219 (98.601)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [137][40/66], lr: 0.01000\tTime 0.092 (0.104)\tData 0.005 (0.018)\tLoss 0.0439 (0.0455)\tPrec@1 98.438 (98.580)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [137][50/66], lr: 0.01000\tTime 0.101 (0.102)\tData 0.000 (0.015)\tLoss 0.0479 (0.0454)\tPrec@1 98.438 (98.591)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [137][60/66], lr: 0.01000\tTime 0.075 (0.099)\tData 0.000 (0.013)\tLoss 0.0462 (0.0473)\tPrec@1 98.438 (98.508)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.235 (0.235)\tLoss 0.7936 (0.7936)\tPrec@1 80.000 (80.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.022 (0.051)\tLoss 1.2868 (0.9914)\tPrec@1 78.000 (79.818)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/261]\tTime 0.016 (0.037)\tLoss 1.1372 (0.9596)\tPrec@1 80.000 (80.286)\tPrec@5 96.000 (97.667)\n",
            "Test: [30/261]\tTime 0.030 (0.032)\tLoss 0.5581 (0.8860)\tPrec@1 88.000 (81.871)\tPrec@5 98.000 (97.871)\n",
            "Test: [40/261]\tTime 0.011 (0.030)\tLoss 0.9111 (0.8641)\tPrec@1 86.000 (82.341)\tPrec@5 97.000 (98.073)\n",
            "Test: [50/261]\tTime 0.025 (0.029)\tLoss 0.7637 (0.8520)\tPrec@1 84.000 (82.647)\tPrec@5 97.000 (98.020)\n",
            "Test: [60/261]\tTime 0.026 (0.028)\tLoss 0.7606 (0.8452)\tPrec@1 83.000 (82.885)\tPrec@5 99.000 (97.967)\n",
            "Test: [70/261]\tTime 0.018 (0.028)\tLoss 0.9080 (0.8491)\tPrec@1 80.000 (82.803)\tPrec@5 100.000 (98.014)\n",
            "Test: [80/261]\tTime 0.020 (0.028)\tLoss 0.7382 (0.8512)\tPrec@1 84.000 (82.765)\tPrec@5 99.000 (98.000)\n",
            "Test: [90/261]\tTime 0.025 (0.027)\tLoss 1.0234 (0.8797)\tPrec@1 78.000 (82.451)\tPrec@5 95.000 (97.846)\n",
            "Test: [100/261]\tTime 0.023 (0.027)\tLoss 1.2576 (0.8766)\tPrec@1 77.000 (82.505)\tPrec@5 96.000 (97.861)\n",
            "Test: [110/261]\tTime 0.015 (0.027)\tLoss 0.7487 (0.8728)\tPrec@1 86.000 (82.559)\tPrec@5 99.000 (97.955)\n",
            "Test: [120/261]\tTime 0.033 (0.026)\tLoss 0.7724 (0.8669)\tPrec@1 88.000 (82.587)\tPrec@5 99.000 (97.926)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8067 (0.8658)\tPrec@1 88.000 (82.641)\tPrec@5 98.000 (97.931)\n",
            "Test: [140/261]\tTime 0.020 (0.026)\tLoss 1.0866 (0.8617)\tPrec@1 78.000 (82.617)\tPrec@5 95.000 (97.950)\n",
            "Test: [150/261]\tTime 0.019 (0.026)\tLoss 0.5255 (0.8595)\tPrec@1 86.000 (82.642)\tPrec@5 98.000 (97.947)\n",
            "Test: [160/261]\tTime 0.020 (0.026)\tLoss 0.4264 (0.8558)\tPrec@1 88.000 (82.708)\tPrec@5 99.000 (97.975)\n",
            "Test: [170/261]\tTime 0.017 (0.026)\tLoss 0.6901 (0.8507)\tPrec@1 90.000 (82.754)\tPrec@5 95.000 (97.977)\n",
            "Test: [180/261]\tTime 0.015 (0.026)\tLoss 0.6859 (0.8526)\tPrec@1 88.000 (82.746)\tPrec@5 94.000 (97.950)\n",
            "Test: [190/261]\tTime 0.025 (0.026)\tLoss 0.6797 (0.8516)\tPrec@1 87.000 (82.707)\tPrec@5 100.000 (98.000)\n",
            "Test: [200/261]\tTime 0.036 (0.025)\tLoss 1.0267 (0.8538)\tPrec@1 78.000 (82.637)\tPrec@5 99.000 (97.985)\n",
            "Test: [210/261]\tTime 0.024 (0.025)\tLoss 0.6986 (0.8544)\tPrec@1 87.000 (82.678)\tPrec@5 99.000 (97.995)\n",
            "Test: [220/261]\tTime 0.021 (0.025)\tLoss 0.8483 (0.8503)\tPrec@1 83.000 (82.710)\tPrec@5 97.000 (98.005)\n",
            "Test: [230/261]\tTime 0.043 (0.025)\tLoss 1.2032 (0.8520)\tPrec@1 77.000 (82.675)\tPrec@5 98.000 (97.987)\n",
            "Test: [240/261]\tTime 0.010 (0.025)\tLoss 0.8615 (0.8538)\tPrec@1 80.000 (82.656)\tPrec@5 99.000 (97.971)\n",
            "Test: [250/261]\tTime 0.033 (0.025)\tLoss 0.7083 (0.8493)\tPrec@1 78.000 (82.685)\tPrec@5 99.000 (97.988)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.4608 (0.8525)\tPrec@1 93.750 (82.664)\tPrec@5 96.875 (97.968)\n",
            "val Results: Prec@1 82.664 Prec@5 97.968 Loss 0.85252\n",
            "val Class Accuracy: [0.624,0.971,0.945,0.837,0.885,0.840,0.826,0.684,0.709,0.451]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [138][0/66], lr: 0.01000\tTime 0.587 (0.587)\tData 0.499 (0.499)\tLoss 0.0302 (0.0302)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][10/66], lr: 0.01000\tTime 0.069 (0.138)\tData 0.006 (0.050)\tLoss 0.0838 (0.0602)\tPrec@1 96.875 (97.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][20/66], lr: 0.01000\tTime 0.095 (0.118)\tData 0.005 (0.029)\tLoss 0.0980 (0.0625)\tPrec@1 98.047 (97.954)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][30/66], lr: 0.01000\tTime 0.096 (0.110)\tData 0.009 (0.022)\tLoss 0.0415 (0.0587)\tPrec@1 98.438 (97.984)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][40/66], lr: 0.01000\tTime 0.101 (0.107)\tData 0.000 (0.018)\tLoss 0.0321 (0.0558)\tPrec@1 98.047 (98.142)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][50/66], lr: 0.01000\tTime 0.073 (0.104)\tData 0.005 (0.016)\tLoss 0.0529 (0.0535)\tPrec@1 98.438 (98.208)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [138][60/66], lr: 0.01000\tTime 0.076 (0.101)\tData 0.000 (0.015)\tLoss 0.0849 (0.0545)\tPrec@1 96.484 (98.188)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.286 (0.286)\tLoss 0.6276 (0.6276)\tPrec@1 86.000 (86.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.019 (0.049)\tLoss 1.3147 (0.8686)\tPrec@1 77.000 (80.636)\tPrec@5 99.000 (97.909)\n",
            "Test: [20/261]\tTime 0.049 (0.038)\tLoss 1.2145 (0.8721)\tPrec@1 76.000 (80.905)\tPrec@5 97.000 (97.952)\n",
            "Test: [30/261]\tTime 0.013 (0.032)\tLoss 0.6196 (0.8258)\tPrec@1 85.000 (82.194)\tPrec@5 97.000 (97.903)\n",
            "Test: [40/261]\tTime 0.019 (0.031)\tLoss 0.8839 (0.8120)\tPrec@1 82.000 (82.293)\tPrec@5 100.000 (98.122)\n",
            "Test: [50/261]\tTime 0.029 (0.029)\tLoss 0.6975 (0.8116)\tPrec@1 82.000 (82.431)\tPrec@5 97.000 (98.098)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.7737 (0.8132)\tPrec@1 80.000 (82.361)\tPrec@5 99.000 (98.082)\n",
            "Test: [70/261]\tTime 0.022 (0.027)\tLoss 0.8713 (0.8143)\tPrec@1 82.000 (82.451)\tPrec@5 99.000 (98.000)\n",
            "Test: [80/261]\tTime 0.020 (0.026)\tLoss 0.8185 (0.8206)\tPrec@1 80.000 (82.284)\tPrec@5 98.000 (98.062)\n",
            "Test: [90/261]\tTime 0.009 (0.026)\tLoss 0.8032 (0.8447)\tPrec@1 84.000 (82.209)\tPrec@5 98.000 (97.989)\n",
            "Test: [100/261]\tTime 0.011 (0.026)\tLoss 1.0811 (0.8399)\tPrec@1 77.000 (82.257)\tPrec@5 99.000 (97.970)\n",
            "Test: [110/261]\tTime 0.009 (0.025)\tLoss 0.7998 (0.8279)\tPrec@1 83.000 (82.486)\tPrec@5 97.000 (97.982)\n",
            "Test: [120/261]\tTime 0.027 (0.025)\tLoss 0.8577 (0.8260)\tPrec@1 82.000 (82.455)\tPrec@5 96.000 (97.975)\n",
            "Test: [130/261]\tTime 0.052 (0.025)\tLoss 0.9655 (0.8307)\tPrec@1 81.000 (82.405)\tPrec@5 95.000 (97.962)\n",
            "Test: [140/261]\tTime 0.030 (0.026)\tLoss 1.0851 (0.8333)\tPrec@1 77.000 (82.333)\tPrec@5 97.000 (97.965)\n",
            "Test: [150/261]\tTime 0.053 (0.025)\tLoss 0.7026 (0.8335)\tPrec@1 83.000 (82.338)\tPrec@5 98.000 (97.954)\n",
            "Test: [160/261]\tTime 0.022 (0.026)\tLoss 0.3146 (0.8342)\tPrec@1 87.000 (82.323)\tPrec@5 100.000 (97.950)\n",
            "Test: [170/261]\tTime 0.036 (0.027)\tLoss 0.8381 (0.8297)\tPrec@1 82.000 (82.374)\tPrec@5 97.000 (97.942)\n",
            "Test: [180/261]\tTime 0.023 (0.027)\tLoss 0.7728 (0.8292)\tPrec@1 83.000 (82.425)\tPrec@5 98.000 (97.972)\n",
            "Test: [190/261]\tTime 0.051 (0.028)\tLoss 0.3272 (0.8251)\tPrec@1 88.000 (82.534)\tPrec@5 100.000 (98.005)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 0.7341 (0.8247)\tPrec@1 84.000 (82.512)\tPrec@5 99.000 (97.990)\n",
            "Test: [210/261]\tTime 0.031 (0.029)\tLoss 0.5392 (0.8198)\tPrec@1 83.000 (82.588)\tPrec@5 99.000 (97.995)\n",
            "Test: [220/261]\tTime 0.052 (0.029)\tLoss 0.8005 (0.8149)\tPrec@1 83.000 (82.633)\tPrec@5 96.000 (98.009)\n",
            "Test: [230/261]\tTime 0.028 (0.030)\tLoss 0.6926 (0.8174)\tPrec@1 83.000 (82.580)\tPrec@5 96.000 (97.996)\n",
            "Test: [240/261]\tTime 0.047 (0.030)\tLoss 0.8302 (0.8221)\tPrec@1 84.000 (82.544)\tPrec@5 99.000 (98.004)\n",
            "Test: [250/261]\tTime 0.027 (0.030)\tLoss 0.5325 (0.8158)\tPrec@1 87.000 (82.661)\tPrec@5 100.000 (98.020)\n",
            "Test: [260/261]\tTime 0.005 (0.030)\tLoss 0.4562 (0.8176)\tPrec@1 87.500 (82.637)\tPrec@5 93.750 (98.018)\n",
            "val Results: Prec@1 82.637 Prec@5 98.018 Loss 0.81762\n",
            "val Class Accuracy: [0.548,0.927,0.931,0.887,0.916,0.857,0.521,0.723,0.802,0.777]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [139][0/66], lr: 0.01000\tTime 0.650 (0.650)\tData 0.556 (0.556)\tLoss 0.0541 (0.0541)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][10/66], lr: 0.01000\tTime 0.112 (0.145)\tData 0.005 (0.058)\tLoss 0.0467 (0.0531)\tPrec@1 98.047 (98.011)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][20/66], lr: 0.01000\tTime 0.100 (0.120)\tData 0.000 (0.032)\tLoss 0.0577 (0.0525)\tPrec@1 97.656 (98.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][30/66], lr: 0.01000\tTime 0.097 (0.110)\tData 0.005 (0.024)\tLoss 0.0896 (0.0506)\tPrec@1 97.266 (98.261)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][40/66], lr: 0.01000\tTime 0.095 (0.106)\tData 0.000 (0.020)\tLoss 0.0491 (0.0475)\tPrec@1 97.656 (98.361)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][50/66], lr: 0.01000\tTime 0.100 (0.103)\tData 0.004 (0.017)\tLoss 0.0436 (0.0492)\tPrec@1 98.047 (98.277)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [139][60/66], lr: 0.01000\tTime 0.071 (0.100)\tData 0.000 (0.015)\tLoss 0.0696 (0.0511)\tPrec@1 98.438 (98.226)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.247 (0.247)\tLoss 1.1048 (1.1048)\tPrec@1 77.000 (77.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.029 (0.047)\tLoss 1.7402 (1.1944)\tPrec@1 74.000 (75.909)\tPrec@5 95.000 (96.273)\n",
            "Test: [20/261]\tTime 0.023 (0.036)\tLoss 1.4176 (1.1128)\tPrec@1 75.000 (77.476)\tPrec@5 96.000 (96.524)\n",
            "Test: [30/261]\tTime 0.041 (0.032)\tLoss 0.8696 (1.0788)\tPrec@1 83.000 (78.032)\tPrec@5 97.000 (96.903)\n",
            "Test: [40/261]\tTime 0.018 (0.028)\tLoss 0.9007 (1.0529)\tPrec@1 85.000 (78.585)\tPrec@5 97.000 (96.976)\n",
            "Test: [50/261]\tTime 0.020 (0.027)\tLoss 1.0053 (1.0481)\tPrec@1 76.000 (78.902)\tPrec@5 97.000 (96.941)\n",
            "Test: [60/261]\tTime 0.037 (0.028)\tLoss 0.9765 (1.0399)\tPrec@1 77.000 (78.984)\tPrec@5 97.000 (96.869)\n",
            "Test: [70/261]\tTime 0.023 (0.027)\tLoss 1.1593 (1.0436)\tPrec@1 80.000 (79.113)\tPrec@5 96.000 (96.803)\n",
            "Test: [80/261]\tTime 0.031 (0.027)\tLoss 1.0223 (1.0448)\tPrec@1 80.000 (79.235)\tPrec@5 97.000 (96.914)\n",
            "Test: [90/261]\tTime 0.019 (0.026)\tLoss 0.9039 (1.0620)\tPrec@1 84.000 (79.132)\tPrec@5 95.000 (96.824)\n",
            "Test: [100/261]\tTime 0.036 (0.026)\tLoss 0.9061 (1.0552)\tPrec@1 81.000 (79.287)\tPrec@5 97.000 (96.921)\n",
            "Test: [110/261]\tTime 0.038 (0.026)\tLoss 1.2066 (1.0430)\tPrec@1 78.000 (79.414)\tPrec@5 96.000 (97.000)\n",
            "Test: [120/261]\tTime 0.015 (0.025)\tLoss 0.9133 (1.0427)\tPrec@1 82.000 (79.413)\tPrec@5 96.000 (96.992)\n",
            "Test: [130/261]\tTime 0.009 (0.025)\tLoss 1.0838 (1.0478)\tPrec@1 78.000 (79.382)\tPrec@5 96.000 (96.924)\n",
            "Test: [140/261]\tTime 0.034 (0.025)\tLoss 1.2810 (1.0442)\tPrec@1 77.000 (79.390)\tPrec@5 95.000 (96.922)\n",
            "Test: [150/261]\tTime 0.027 (0.025)\tLoss 0.7698 (1.0470)\tPrec@1 82.000 (79.437)\tPrec@5 96.000 (96.934)\n",
            "Test: [160/261]\tTime 0.015 (0.025)\tLoss 0.8890 (1.0480)\tPrec@1 82.000 (79.373)\tPrec@5 98.000 (96.907)\n",
            "Test: [170/261]\tTime 0.026 (0.025)\tLoss 1.0665 (1.0442)\tPrec@1 81.000 (79.497)\tPrec@5 97.000 (96.930)\n",
            "Test: [180/261]\tTime 0.016 (0.025)\tLoss 1.0980 (1.0442)\tPrec@1 79.000 (79.470)\tPrec@5 92.000 (96.945)\n",
            "Test: [190/261]\tTime 0.037 (0.025)\tLoss 0.8462 (1.0447)\tPrec@1 81.000 (79.435)\tPrec@5 98.000 (97.000)\n",
            "Test: [200/261]\tTime 0.014 (0.025)\tLoss 0.9307 (1.0442)\tPrec@1 82.000 (79.403)\tPrec@5 98.000 (97.000)\n",
            "Test: [210/261]\tTime 0.035 (0.025)\tLoss 0.8308 (1.0408)\tPrec@1 79.000 (79.493)\tPrec@5 98.000 (97.028)\n",
            "Test: [220/261]\tTime 0.014 (0.025)\tLoss 0.7333 (1.0376)\tPrec@1 82.000 (79.534)\tPrec@5 96.000 (96.995)\n",
            "Test: [230/261]\tTime 0.021 (0.025)\tLoss 1.1066 (1.0383)\tPrec@1 76.000 (79.597)\tPrec@5 95.000 (96.978)\n",
            "Test: [240/261]\tTime 0.029 (0.024)\tLoss 1.1769 (1.0386)\tPrec@1 79.000 (79.627)\tPrec@5 98.000 (96.971)\n",
            "Test: [250/261]\tTime 0.014 (0.024)\tLoss 0.8836 (1.0346)\tPrec@1 83.000 (79.673)\tPrec@5 99.000 (97.012)\n",
            "Test: [260/261]\tTime 0.006 (0.024)\tLoss 0.5599 (1.0346)\tPrec@1 87.500 (79.679)\tPrec@5 96.875 (96.977)\n",
            "val Results: Prec@1 79.679 Prec@5 96.977 Loss 1.03460\n",
            "val Class Accuracy: [0.382,0.936,0.901,0.859,0.955,0.774,0.547,0.842,0.618,0.643]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [140][0/66], lr: 0.01000\tTime 0.597 (0.597)\tData 0.516 (0.516)\tLoss 0.0706 (0.0706)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][10/66], lr: 0.01000\tTime 0.102 (0.138)\tData 0.004 (0.050)\tLoss 0.0265 (0.0568)\tPrec@1 99.219 (98.011)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][20/66], lr: 0.01000\tTime 0.099 (0.115)\tData 0.017 (0.029)\tLoss 0.0485 (0.0555)\tPrec@1 98.828 (98.140)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][30/66], lr: 0.01000\tTime 0.101 (0.109)\tData 0.002 (0.021)\tLoss 0.0455 (0.0562)\tPrec@1 98.047 (98.072)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][40/66], lr: 0.01000\tTime 0.090 (0.105)\tData 0.005 (0.017)\tLoss 0.0437 (0.0535)\tPrec@1 99.219 (98.190)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][50/66], lr: 0.01000\tTime 0.097 (0.103)\tData 0.000 (0.014)\tLoss 0.0528 (0.0523)\tPrec@1 96.484 (98.208)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [140][60/66], lr: 0.01000\tTime 0.077 (0.100)\tData 0.000 (0.013)\tLoss 0.0405 (0.0504)\tPrec@1 98.828 (98.290)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.229 (0.229)\tLoss 0.8936 (0.8936)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.037 (0.046)\tLoss 1.2019 (0.9135)\tPrec@1 77.000 (79.727)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/261]\tTime 0.023 (0.036)\tLoss 1.1307 (0.9056)\tPrec@1 76.000 (79.476)\tPrec@5 97.000 (97.524)\n",
            "Test: [30/261]\tTime 0.015 (0.033)\tLoss 0.9271 (0.8754)\tPrec@1 78.000 (80.097)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/261]\tTime 0.028 (0.030)\tLoss 0.7820 (0.8525)\tPrec@1 87.000 (80.805)\tPrec@5 97.000 (97.780)\n",
            "Test: [50/261]\tTime 0.020 (0.029)\tLoss 0.8720 (0.8363)\tPrec@1 78.000 (80.863)\tPrec@5 98.000 (97.882)\n",
            "Test: [60/261]\tTime 0.032 (0.028)\tLoss 0.9248 (0.8357)\tPrec@1 82.000 (81.164)\tPrec@5 97.000 (97.869)\n",
            "Test: [70/261]\tTime 0.014 (0.027)\tLoss 0.6783 (0.8493)\tPrec@1 76.000 (80.901)\tPrec@5 98.000 (97.915)\n",
            "Test: [80/261]\tTime 0.015 (0.027)\tLoss 0.9918 (0.8611)\tPrec@1 80.000 (80.938)\tPrec@5 98.000 (97.852)\n",
            "Test: [90/261]\tTime 0.016 (0.026)\tLoss 0.9158 (0.8775)\tPrec@1 83.000 (80.736)\tPrec@5 96.000 (97.692)\n",
            "Test: [100/261]\tTime 0.010 (0.026)\tLoss 1.2229 (0.8751)\tPrec@1 78.000 (80.861)\tPrec@5 96.000 (97.663)\n",
            "Test: [110/261]\tTime 0.029 (0.026)\tLoss 1.0620 (0.8684)\tPrec@1 80.000 (80.919)\tPrec@5 97.000 (97.667)\n",
            "Test: [120/261]\tTime 0.009 (0.025)\tLoss 1.1555 (0.8666)\tPrec@1 81.000 (80.926)\tPrec@5 95.000 (97.645)\n",
            "Test: [130/261]\tTime 0.021 (0.026)\tLoss 0.9140 (0.8669)\tPrec@1 81.000 (80.954)\tPrec@5 97.000 (97.649)\n",
            "Test: [140/261]\tTime 0.014 (0.025)\tLoss 1.1086 (0.8654)\tPrec@1 77.000 (80.986)\tPrec@5 97.000 (97.667)\n",
            "Test: [150/261]\tTime 0.027 (0.025)\tLoss 0.7407 (0.8693)\tPrec@1 83.000 (80.940)\tPrec@5 98.000 (97.662)\n",
            "Test: [160/261]\tTime 0.010 (0.025)\tLoss 0.6590 (0.8724)\tPrec@1 86.000 (80.857)\tPrec@5 99.000 (97.652)\n",
            "Test: [170/261]\tTime 0.009 (0.025)\tLoss 0.7319 (0.8664)\tPrec@1 85.000 (80.953)\tPrec@5 98.000 (97.649)\n",
            "Test: [180/261]\tTime 0.029 (0.025)\tLoss 0.7218 (0.8709)\tPrec@1 86.000 (80.994)\tPrec@5 97.000 (97.646)\n",
            "Test: [190/261]\tTime 0.017 (0.025)\tLoss 0.7189 (0.8654)\tPrec@1 84.000 (81.110)\tPrec@5 99.000 (97.660)\n",
            "Test: [200/261]\tTime 0.023 (0.025)\tLoss 0.9117 (0.8677)\tPrec@1 82.000 (81.100)\tPrec@5 96.000 (97.657)\n",
            "Test: [210/261]\tTime 0.041 (0.025)\tLoss 0.8590 (0.8673)\tPrec@1 82.000 (81.152)\tPrec@5 98.000 (97.664)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 1.0200 (0.8702)\tPrec@1 76.000 (81.059)\tPrec@5 98.000 (97.661)\n",
            "Test: [230/261]\tTime 0.022 (0.025)\tLoss 0.8477 (0.8713)\tPrec@1 85.000 (81.030)\tPrec@5 95.000 (97.662)\n",
            "Test: [240/261]\tTime 0.009 (0.025)\tLoss 0.9539 (0.8713)\tPrec@1 82.000 (81.066)\tPrec@5 96.000 (97.639)\n",
            "Test: [250/261]\tTime 0.028 (0.025)\tLoss 0.9479 (0.8691)\tPrec@1 81.000 (81.088)\tPrec@5 99.000 (97.649)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.6203 (0.8724)\tPrec@1 90.625 (81.089)\tPrec@5 100.000 (97.626)\n",
            "val Results: Prec@1 81.089 Prec@5 97.626 Loss 0.87243\n",
            "val Class Accuracy: [0.718,0.983,0.856,0.831,0.825,0.818,0.791,0.671,0.628,0.567]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [141][0/66], lr: 0.01000\tTime 0.573 (0.573)\tData 0.485 (0.485)\tLoss 0.0212 (0.0212)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [141][10/66], lr: 0.01000\tTime 0.102 (0.136)\tData 0.004 (0.052)\tLoss 0.0279 (0.0311)\tPrec@1 98.828 (99.006)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [141][20/66], lr: 0.01000\tTime 0.075 (0.117)\tData 0.000 (0.029)\tLoss 0.0176 (0.0376)\tPrec@1 100.000 (98.717)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [141][30/66], lr: 0.01000\tTime 0.084 (0.110)\tData 0.000 (0.021)\tLoss 0.0572 (0.0398)\tPrec@1 97.266 (98.664)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [141][40/66], lr: 0.01000\tTime 0.092 (0.106)\tData 0.006 (0.018)\tLoss 0.1228 (0.0436)\tPrec@1 96.484 (98.485)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [141][50/66], lr: 0.01000\tTime 0.100 (0.103)\tData 0.000 (0.015)\tLoss 0.0302 (0.0452)\tPrec@1 98.828 (98.415)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [141][60/66], lr: 0.01000\tTime 0.070 (0.100)\tData 0.000 (0.013)\tLoss 0.0672 (0.0450)\tPrec@1 98.438 (98.437)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.243 (0.243)\tLoss 0.8647 (0.8647)\tPrec@1 76.000 (76.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.046)\tLoss 1.1568 (0.9266)\tPrec@1 79.000 (79.273)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/261]\tTime 0.030 (0.037)\tLoss 1.0661 (0.9158)\tPrec@1 79.000 (79.381)\tPrec@5 95.000 (97.571)\n",
            "Test: [30/261]\tTime 0.024 (0.031)\tLoss 0.6786 (0.8718)\tPrec@1 87.000 (81.097)\tPrec@5 95.000 (97.613)\n",
            "Test: [40/261]\tTime 0.018 (0.030)\tLoss 0.9563 (0.8420)\tPrec@1 84.000 (81.829)\tPrec@5 97.000 (97.854)\n",
            "Test: [50/261]\tTime 0.027 (0.028)\tLoss 0.6215 (0.8312)\tPrec@1 82.000 (82.137)\tPrec@5 99.000 (97.902)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 0.8836 (0.8333)\tPrec@1 80.000 (82.213)\tPrec@5 96.000 (97.738)\n",
            "Test: [70/261]\tTime 0.022 (0.027)\tLoss 0.8648 (0.8348)\tPrec@1 80.000 (82.141)\tPrec@5 99.000 (97.690)\n",
            "Test: [80/261]\tTime 0.018 (0.027)\tLoss 0.9843 (0.8301)\tPrec@1 76.000 (82.111)\tPrec@5 97.000 (97.753)\n",
            "Test: [90/261]\tTime 0.029 (0.027)\tLoss 0.8979 (0.8564)\tPrec@1 83.000 (81.846)\tPrec@5 96.000 (97.692)\n",
            "Test: [100/261]\tTime 0.022 (0.026)\tLoss 1.1783 (0.8476)\tPrec@1 80.000 (81.881)\tPrec@5 95.000 (97.693)\n",
            "Test: [110/261]\tTime 0.009 (0.026)\tLoss 0.6905 (0.8450)\tPrec@1 83.000 (81.982)\tPrec@5 100.000 (97.766)\n",
            "Test: [120/261]\tTime 0.012 (0.026)\tLoss 0.7338 (0.8438)\tPrec@1 86.000 (82.008)\tPrec@5 97.000 (97.769)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.8678 (0.8466)\tPrec@1 82.000 (82.008)\tPrec@5 97.000 (97.756)\n",
            "Test: [140/261]\tTime 0.023 (0.026)\tLoss 1.0474 (0.8454)\tPrec@1 78.000 (82.057)\tPrec@5 95.000 (97.780)\n",
            "Test: [150/261]\tTime 0.035 (0.026)\tLoss 0.5032 (0.8501)\tPrec@1 86.000 (82.026)\tPrec@5 98.000 (97.762)\n",
            "Test: [160/261]\tTime 0.011 (0.025)\tLoss 0.3858 (0.8469)\tPrec@1 90.000 (82.081)\tPrec@5 100.000 (97.795)\n",
            "Test: [170/261]\tTime 0.012 (0.025)\tLoss 0.6141 (0.8435)\tPrec@1 87.000 (82.099)\tPrec@5 98.000 (97.784)\n",
            "Test: [180/261]\tTime 0.037 (0.025)\tLoss 0.6668 (0.8425)\tPrec@1 86.000 (82.144)\tPrec@5 97.000 (97.790)\n",
            "Test: [190/261]\tTime 0.012 (0.025)\tLoss 0.6187 (0.8420)\tPrec@1 84.000 (82.089)\tPrec@5 99.000 (97.806)\n",
            "Test: [200/261]\tTime 0.010 (0.025)\tLoss 0.6389 (0.8407)\tPrec@1 87.000 (82.134)\tPrec@5 97.000 (97.796)\n",
            "Test: [210/261]\tTime 0.025 (0.025)\tLoss 0.6075 (0.8386)\tPrec@1 83.000 (82.209)\tPrec@5 98.000 (97.801)\n",
            "Test: [220/261]\tTime 0.010 (0.025)\tLoss 0.7153 (0.8342)\tPrec@1 80.000 (82.190)\tPrec@5 97.000 (97.828)\n",
            "Test: [230/261]\tTime 0.019 (0.025)\tLoss 0.8872 (0.8333)\tPrec@1 80.000 (82.173)\tPrec@5 97.000 (97.818)\n",
            "Test: [240/261]\tTime 0.017 (0.025)\tLoss 0.9765 (0.8358)\tPrec@1 81.000 (82.104)\tPrec@5 97.000 (97.817)\n",
            "Test: [250/261]\tTime 0.009 (0.025)\tLoss 0.7265 (0.8299)\tPrec@1 78.000 (82.147)\tPrec@5 99.000 (97.845)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.3439 (0.8332)\tPrec@1 93.750 (82.122)\tPrec@5 96.875 (97.822)\n",
            "val Results: Prec@1 82.122 Prec@5 97.822 Loss 0.83316\n",
            "val Class Accuracy: [0.591,0.908,0.936,0.839,0.844,0.877,0.795,0.835,0.756,0.427]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [142][0/66], lr: 0.01000\tTime 0.540 (0.540)\tData 0.440 (0.440)\tLoss 0.0104 (0.0104)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][10/66], lr: 0.01000\tTime 0.096 (0.135)\tData 0.000 (0.043)\tLoss 0.0439 (0.0377)\tPrec@1 98.047 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][20/66], lr: 0.01000\tTime 0.076 (0.113)\tData 0.000 (0.024)\tLoss 0.0290 (0.0339)\tPrec@1 99.219 (98.847)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][30/66], lr: 0.01000\tTime 0.097 (0.107)\tData 0.001 (0.018)\tLoss 0.0721 (0.0352)\tPrec@1 97.266 (98.803)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][40/66], lr: 0.01000\tTime 0.102 (0.105)\tData 0.000 (0.016)\tLoss 0.0414 (0.0377)\tPrec@1 98.438 (98.714)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][50/66], lr: 0.01000\tTime 0.102 (0.104)\tData 0.000 (0.014)\tLoss 0.0229 (0.0387)\tPrec@1 98.828 (98.683)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [142][60/66], lr: 0.01000\tTime 0.063 (0.104)\tData 0.000 (0.015)\tLoss 0.0605 (0.0390)\tPrec@1 97.266 (98.668)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.288 (0.288)\tLoss 0.6622 (0.6622)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.025 (0.053)\tLoss 1.3274 (0.9252)\tPrec@1 79.000 (82.000)\tPrec@5 98.000 (97.455)\n",
            "Test: [20/261]\tTime 0.009 (0.038)\tLoss 1.2318 (0.8941)\tPrec@1 79.000 (81.857)\tPrec@5 94.000 (97.143)\n",
            "Test: [30/261]\tTime 0.026 (0.033)\tLoss 0.6290 (0.8341)\tPrec@1 85.000 (82.774)\tPrec@5 98.000 (97.516)\n",
            "Test: [40/261]\tTime 0.017 (0.031)\tLoss 0.7799 (0.8163)\tPrec@1 89.000 (83.024)\tPrec@5 96.000 (97.829)\n",
            "Test: [50/261]\tTime 0.033 (0.030)\tLoss 0.6628 (0.7987)\tPrec@1 80.000 (83.020)\tPrec@5 98.000 (97.941)\n",
            "Test: [60/261]\tTime 0.039 (0.029)\tLoss 0.9655 (0.7976)\tPrec@1 82.000 (83.279)\tPrec@5 96.000 (97.934)\n",
            "Test: [70/261]\tTime 0.011 (0.029)\tLoss 0.7409 (0.8006)\tPrec@1 82.000 (83.239)\tPrec@5 96.000 (97.845)\n",
            "Test: [80/261]\tTime 0.036 (0.028)\tLoss 0.9042 (0.8116)\tPrec@1 84.000 (83.309)\tPrec@5 98.000 (97.852)\n",
            "Test: [90/261]\tTime 0.024 (0.028)\tLoss 0.9967 (0.8330)\tPrec@1 83.000 (83.132)\tPrec@5 96.000 (97.769)\n",
            "Test: [100/261]\tTime 0.034 (0.028)\tLoss 0.9227 (0.8279)\tPrec@1 84.000 (83.248)\tPrec@5 96.000 (97.743)\n",
            "Test: [110/261]\tTime 0.030 (0.028)\tLoss 0.8597 (0.8205)\tPrec@1 83.000 (83.369)\tPrec@5 98.000 (97.784)\n",
            "Test: [120/261]\tTime 0.048 (0.028)\tLoss 0.8120 (0.8186)\tPrec@1 86.000 (83.397)\tPrec@5 97.000 (97.793)\n",
            "Test: [130/261]\tTime 0.012 (0.027)\tLoss 0.8925 (0.8210)\tPrec@1 83.000 (83.405)\tPrec@5 97.000 (97.832)\n",
            "Test: [140/261]\tTime 0.041 (0.027)\tLoss 1.0739 (0.8192)\tPrec@1 78.000 (83.390)\tPrec@5 97.000 (97.830)\n",
            "Test: [150/261]\tTime 0.037 (0.027)\tLoss 0.7238 (0.8202)\tPrec@1 85.000 (83.430)\tPrec@5 97.000 (97.788)\n",
            "Test: [160/261]\tTime 0.028 (0.027)\tLoss 0.5247 (0.8219)\tPrec@1 90.000 (83.422)\tPrec@5 99.000 (97.764)\n",
            "Test: [170/261]\tTime 0.017 (0.027)\tLoss 0.6071 (0.8170)\tPrec@1 90.000 (83.520)\tPrec@5 98.000 (97.778)\n",
            "Test: [180/261]\tTime 0.021 (0.027)\tLoss 0.6634 (0.8206)\tPrec@1 88.000 (83.453)\tPrec@5 94.000 (97.724)\n",
            "Test: [190/261]\tTime 0.017 (0.027)\tLoss 0.5618 (0.8142)\tPrec@1 86.000 (83.571)\tPrec@5 99.000 (97.743)\n",
            "Test: [200/261]\tTime 0.012 (0.027)\tLoss 0.9278 (0.8146)\tPrec@1 81.000 (83.468)\tPrec@5 97.000 (97.761)\n",
            "Test: [210/261]\tTime 0.018 (0.026)\tLoss 0.5574 (0.8131)\tPrec@1 87.000 (83.464)\tPrec@5 99.000 (97.763)\n",
            "Test: [220/261]\tTime 0.027 (0.026)\tLoss 0.8968 (0.8119)\tPrec@1 82.000 (83.398)\tPrec@5 100.000 (97.774)\n",
            "Test: [230/261]\tTime 0.033 (0.026)\tLoss 1.0497 (0.8155)\tPrec@1 78.000 (83.303)\tPrec@5 97.000 (97.775)\n",
            "Test: [240/261]\tTime 0.020 (0.026)\tLoss 0.5589 (0.8152)\tPrec@1 85.000 (83.353)\tPrec@5 99.000 (97.751)\n",
            "Test: [250/261]\tTime 0.034 (0.026)\tLoss 0.7198 (0.8112)\tPrec@1 79.000 (83.359)\tPrec@5 99.000 (97.737)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.4517 (0.8154)\tPrec@1 87.500 (83.355)\tPrec@5 100.000 (97.703)\n",
            "val Results: Prec@1 83.355 Prec@5 97.703 Loss 0.81542\n",
            "val Class Accuracy: [0.812,0.969,0.930,0.857,0.890,0.814,0.820,0.601,0.626,0.599]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [143][0/66], lr: 0.01000\tTime 0.599 (0.599)\tData 0.524 (0.524)\tLoss 0.0652 (0.0652)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][10/66], lr: 0.01000\tTime 0.088 (0.143)\tData 0.007 (0.055)\tLoss 0.0536 (0.0431)\tPrec@1 97.266 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][20/66], lr: 0.01000\tTime 0.098 (0.117)\tData 0.000 (0.031)\tLoss 0.0398 (0.0387)\tPrec@1 98.047 (98.605)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][30/66], lr: 0.01000\tTime 0.083 (0.109)\tData 0.000 (0.023)\tLoss 0.0456 (0.0455)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][40/66], lr: 0.01000\tTime 0.089 (0.105)\tData 0.005 (0.019)\tLoss 0.0653 (0.0458)\tPrec@1 97.266 (98.418)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][50/66], lr: 0.01000\tTime 0.107 (0.103)\tData 0.007 (0.017)\tLoss 0.0535 (0.0470)\tPrec@1 98.047 (98.430)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [143][60/66], lr: 0.01000\tTime 0.078 (0.100)\tData 0.000 (0.015)\tLoss 0.0564 (0.0451)\tPrec@1 98.438 (98.521)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.287 (0.287)\tLoss 0.8268 (0.8268)\tPrec@1 81.000 (81.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.028 (0.050)\tLoss 1.1818 (0.8769)\tPrec@1 77.000 (81.636)\tPrec@5 99.000 (97.000)\n",
            "Test: [20/261]\tTime 0.017 (0.038)\tLoss 1.2107 (0.8635)\tPrec@1 76.000 (81.476)\tPrec@5 96.000 (97.238)\n",
            "Test: [30/261]\tTime 0.013 (0.033)\tLoss 0.7731 (0.8380)\tPrec@1 86.000 (82.065)\tPrec@5 99.000 (97.581)\n",
            "Test: [40/261]\tTime 0.024 (0.031)\tLoss 0.8517 (0.8184)\tPrec@1 83.000 (82.439)\tPrec@5 98.000 (97.732)\n",
            "Test: [50/261]\tTime 0.017 (0.029)\tLoss 0.8104 (0.8160)\tPrec@1 79.000 (82.569)\tPrec@5 95.000 (97.549)\n",
            "Test: [60/261]\tTime 0.015 (0.028)\tLoss 0.6625 (0.8002)\tPrec@1 86.000 (82.836)\tPrec@5 99.000 (97.623)\n",
            "Test: [70/261]\tTime 0.017 (0.028)\tLoss 0.7755 (0.8024)\tPrec@1 83.000 (82.915)\tPrec@5 99.000 (97.676)\n",
            "Test: [80/261]\tTime 0.027 (0.027)\tLoss 0.9121 (0.8065)\tPrec@1 83.000 (82.963)\tPrec@5 97.000 (97.667)\n",
            "Test: [90/261]\tTime 0.026 (0.027)\tLoss 0.6749 (0.8288)\tPrec@1 87.000 (82.692)\tPrec@5 97.000 (97.582)\n",
            "Test: [100/261]\tTime 0.022 (0.027)\tLoss 1.0980 (0.8244)\tPrec@1 80.000 (82.802)\tPrec@5 96.000 (97.604)\n",
            "Test: [110/261]\tTime 0.016 (0.026)\tLoss 1.1558 (0.8211)\tPrec@1 82.000 (82.856)\tPrec@5 95.000 (97.658)\n",
            "Test: [120/261]\tTime 0.038 (0.026)\tLoss 0.6517 (0.8224)\tPrec@1 87.000 (82.777)\tPrec@5 97.000 (97.661)\n",
            "Test: [130/261]\tTime 0.033 (0.026)\tLoss 0.8070 (0.8273)\tPrec@1 81.000 (82.740)\tPrec@5 96.000 (97.626)\n",
            "Test: [140/261]\tTime 0.018 (0.026)\tLoss 0.9207 (0.8262)\tPrec@1 79.000 (82.738)\tPrec@5 98.000 (97.638)\n",
            "Test: [150/261]\tTime 0.038 (0.026)\tLoss 0.4669 (0.8248)\tPrec@1 86.000 (82.808)\tPrec@5 97.000 (97.629)\n",
            "Test: [160/261]\tTime 0.012 (0.026)\tLoss 0.6159 (0.8259)\tPrec@1 83.000 (82.807)\tPrec@5 98.000 (97.609)\n",
            "Test: [170/261]\tTime 0.045 (0.026)\tLoss 0.8534 (0.8226)\tPrec@1 81.000 (82.789)\tPrec@5 97.000 (97.602)\n",
            "Test: [180/261]\tTime 0.029 (0.025)\tLoss 0.5942 (0.8263)\tPrec@1 87.000 (82.713)\tPrec@5 96.000 (97.602)\n",
            "Test: [190/261]\tTime 0.040 (0.025)\tLoss 0.6118 (0.8229)\tPrec@1 86.000 (82.749)\tPrec@5 99.000 (97.644)\n",
            "Test: [200/261]\tTime 0.027 (0.025)\tLoss 0.6026 (0.8224)\tPrec@1 85.000 (82.756)\tPrec@5 97.000 (97.582)\n",
            "Test: [210/261]\tTime 0.027 (0.025)\tLoss 0.6429 (0.8233)\tPrec@1 83.000 (82.796)\tPrec@5 98.000 (97.569)\n",
            "Test: [220/261]\tTime 0.045 (0.025)\tLoss 0.9336 (0.8218)\tPrec@1 83.000 (82.814)\tPrec@5 96.000 (97.561)\n",
            "Test: [230/261]\tTime 0.017 (0.025)\tLoss 0.9775 (0.8241)\tPrec@1 77.000 (82.823)\tPrec@5 96.000 (97.519)\n",
            "Test: [240/261]\tTime 0.013 (0.025)\tLoss 0.7225 (0.8279)\tPrec@1 87.000 (82.826)\tPrec@5 97.000 (97.510)\n",
            "Test: [250/261]\tTime 0.064 (0.026)\tLoss 0.6055 (0.8205)\tPrec@1 79.000 (82.900)\tPrec@5 100.000 (97.518)\n",
            "Test: [260/261]\tTime 0.008 (0.025)\tLoss 0.4308 (0.8238)\tPrec@1 84.375 (82.898)\tPrec@5 96.875 (97.499)\n",
            "val Results: Prec@1 82.898 Prec@5 97.499 Loss 0.82380\n",
            "val Class Accuracy: [0.529,0.969,0.913,0.839,0.889,0.876,0.705,0.783,0.745,0.609]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [144][0/66], lr: 0.01000\tTime 0.615 (0.615)\tData 0.520 (0.520)\tLoss 0.0400 (0.0400)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][10/66], lr: 0.01000\tTime 0.107 (0.145)\tData 0.004 (0.054)\tLoss 0.0399 (0.0454)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][20/66], lr: 0.01000\tTime 0.131 (0.128)\tData 0.001 (0.031)\tLoss 0.0685 (0.0516)\tPrec@1 96.875 (98.196)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][30/66], lr: 0.01000\tTime 0.111 (0.120)\tData 0.004 (0.023)\tLoss 0.0322 (0.0447)\tPrec@1 98.828 (98.450)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][40/66], lr: 0.01000\tTime 0.095 (0.115)\tData 0.000 (0.019)\tLoss 0.0381 (0.0471)\tPrec@1 98.438 (98.409)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][50/66], lr: 0.01000\tTime 0.112 (0.112)\tData 0.005 (0.016)\tLoss 0.0501 (0.0459)\tPrec@1 98.047 (98.476)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [144][60/66], lr: 0.01000\tTime 0.077 (0.108)\tData 0.000 (0.015)\tLoss 0.0226 (0.0468)\tPrec@1 99.609 (98.425)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.267 (0.267)\tLoss 1.1400 (1.1400)\tPrec@1 76.000 (76.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.024 (0.052)\tLoss 2.0309 (1.3514)\tPrec@1 69.000 (74.273)\tPrec@5 97.000 (96.455)\n",
            "Test: [20/261]\tTime 0.013 (0.039)\tLoss 1.6848 (1.2895)\tPrec@1 72.000 (75.381)\tPrec@5 96.000 (96.857)\n",
            "Test: [30/261]\tTime 0.011 (0.034)\tLoss 1.0303 (1.2332)\tPrec@1 82.000 (76.323)\tPrec@5 98.000 (97.129)\n",
            "Test: [40/261]\tTime 0.014 (0.031)\tLoss 1.0431 (1.1971)\tPrec@1 85.000 (76.878)\tPrec@5 97.000 (97.415)\n",
            "Test: [50/261]\tTime 0.019 (0.031)\tLoss 0.9645 (1.1826)\tPrec@1 81.000 (77.314)\tPrec@5 96.000 (97.412)\n",
            "Test: [60/261]\tTime 0.027 (0.030)\tLoss 1.2025 (1.1709)\tPrec@1 70.000 (77.541)\tPrec@5 98.000 (97.361)\n",
            "Test: [70/261]\tTime 0.025 (0.030)\tLoss 1.2957 (1.1762)\tPrec@1 73.000 (77.634)\tPrec@5 99.000 (97.437)\n",
            "Test: [80/261]\tTime 0.036 (0.029)\tLoss 1.3048 (1.1933)\tPrec@1 74.000 (77.469)\tPrec@5 97.000 (97.296)\n",
            "Test: [90/261]\tTime 0.039 (0.029)\tLoss 1.4543 (1.2229)\tPrec@1 75.000 (77.176)\tPrec@5 94.000 (97.187)\n",
            "Test: [100/261]\tTime 0.018 (0.028)\tLoss 1.3265 (1.2188)\tPrec@1 75.000 (77.287)\tPrec@5 96.000 (97.208)\n",
            "Test: [110/261]\tTime 0.031 (0.028)\tLoss 1.7690 (1.2126)\tPrec@1 73.000 (77.243)\tPrec@5 95.000 (97.198)\n",
            "Test: [120/261]\tTime 0.038 (0.028)\tLoss 0.9559 (1.2028)\tPrec@1 81.000 (77.372)\tPrec@5 97.000 (97.231)\n",
            "Test: [130/261]\tTime 0.011 (0.028)\tLoss 1.4965 (1.2085)\tPrec@1 74.000 (77.336)\tPrec@5 94.000 (97.153)\n",
            "Test: [140/261]\tTime 0.031 (0.028)\tLoss 1.2883 (1.2069)\tPrec@1 77.000 (77.319)\tPrec@5 97.000 (97.191)\n",
            "Test: [150/261]\tTime 0.020 (0.027)\tLoss 1.2703 (1.2107)\tPrec@1 76.000 (77.258)\tPrec@5 95.000 (97.152)\n",
            "Test: [160/261]\tTime 0.024 (0.027)\tLoss 0.9202 (1.2078)\tPrec@1 82.000 (77.292)\tPrec@5 99.000 (97.186)\n",
            "Test: [170/261]\tTime 0.009 (0.027)\tLoss 1.2128 (1.1992)\tPrec@1 79.000 (77.374)\tPrec@5 96.000 (97.205)\n",
            "Test: [180/261]\tTime 0.049 (0.027)\tLoss 0.8420 (1.2003)\tPrec@1 85.000 (77.464)\tPrec@5 96.000 (97.160)\n",
            "Test: [190/261]\tTime 0.014 (0.027)\tLoss 0.8785 (1.1916)\tPrec@1 81.000 (77.571)\tPrec@5 99.000 (97.194)\n",
            "Test: [200/261]\tTime 0.029 (0.027)\tLoss 1.2427 (1.1923)\tPrec@1 76.000 (77.552)\tPrec@5 97.000 (97.164)\n",
            "Test: [210/261]\tTime 0.023 (0.027)\tLoss 1.0601 (1.1926)\tPrec@1 76.000 (77.564)\tPrec@5 98.000 (97.166)\n",
            "Test: [220/261]\tTime 0.016 (0.027)\tLoss 1.4036 (1.1922)\tPrec@1 71.000 (77.511)\tPrec@5 98.000 (97.167)\n",
            "Test: [230/261]\tTime 0.027 (0.027)\tLoss 1.2246 (1.1938)\tPrec@1 74.000 (77.528)\tPrec@5 96.000 (97.156)\n",
            "Test: [240/261]\tTime 0.012 (0.027)\tLoss 1.0974 (1.1993)\tPrec@1 80.000 (77.548)\tPrec@5 98.000 (97.145)\n",
            "Test: [250/261]\tTime 0.028 (0.027)\tLoss 0.9187 (1.1911)\tPrec@1 82.000 (77.633)\tPrec@5 99.000 (97.183)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.6545 (1.1946)\tPrec@1 78.125 (77.604)\tPrec@5 96.875 (97.154)\n",
            "val Results: Prec@1 77.604 Prec@5 97.154 Loss 1.19459\n",
            "val Class Accuracy: [0.487,0.977,0.823,0.913,0.846,0.812,0.603,0.587,0.626,0.525]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [145][0/66], lr: 0.01000\tTime 0.578 (0.578)\tData 0.500 (0.500)\tLoss 0.0232 (0.0232)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][10/66], lr: 0.01000\tTime 0.110 (0.141)\tData 0.000 (0.050)\tLoss 0.0096 (0.0309)\tPrec@1 100.000 (99.041)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][20/66], lr: 0.01000\tTime 0.106 (0.123)\tData 0.000 (0.029)\tLoss 0.0612 (0.0394)\tPrec@1 97.656 (98.642)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][30/66], lr: 0.01000\tTime 0.076 (0.113)\tData 0.000 (0.022)\tLoss 0.0545 (0.0411)\tPrec@1 98.047 (98.501)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [145][40/66], lr: 0.01000\tTime 0.102 (0.108)\tData 0.000 (0.018)\tLoss 0.0495 (0.0465)\tPrec@1 98.828 (98.371)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [145][50/66], lr: 0.01000\tTime 0.105 (0.104)\tData 0.004 (0.015)\tLoss 0.0427 (0.0493)\tPrec@1 98.438 (98.292)\tPrec@5 100.000 (99.985)\n",
            "Epoch: [145][60/66], lr: 0.01000\tTime 0.074 (0.103)\tData 0.000 (0.013)\tLoss 0.0376 (0.0489)\tPrec@1 98.438 (98.316)\tPrec@5 100.000 (99.987)\n",
            "Test: [0/261]\tTime 0.296 (0.296)\tLoss 0.7122 (0.7122)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.019 (0.049)\tLoss 1.0317 (0.7932)\tPrec@1 80.000 (81.182)\tPrec@5 100.000 (98.273)\n",
            "Test: [20/261]\tTime 0.011 (0.037)\tLoss 1.1598 (0.7784)\tPrec@1 75.000 (81.952)\tPrec@5 96.000 (98.143)\n",
            "Test: [30/261]\tTime 0.037 (0.032)\tLoss 0.4468 (0.7278)\tPrec@1 89.000 (82.935)\tPrec@5 100.000 (98.355)\n",
            "Test: [40/261]\tTime 0.036 (0.032)\tLoss 0.8414 (0.7151)\tPrec@1 85.000 (83.366)\tPrec@5 100.000 (98.512)\n",
            "Test: [50/261]\tTime 0.022 (0.031)\tLoss 0.5757 (0.7173)\tPrec@1 84.000 (83.353)\tPrec@5 99.000 (98.431)\n",
            "Test: [60/261]\tTime 0.031 (0.030)\tLoss 0.7497 (0.7178)\tPrec@1 83.000 (83.443)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.015 (0.029)\tLoss 0.8892 (0.7176)\tPrec@1 82.000 (83.577)\tPrec@5 99.000 (98.394)\n",
            "Test: [80/261]\tTime 0.022 (0.029)\tLoss 0.6054 (0.7184)\tPrec@1 84.000 (83.519)\tPrec@5 98.000 (98.370)\n",
            "Test: [90/261]\tTime 0.033 (0.029)\tLoss 0.7009 (0.7382)\tPrec@1 86.000 (83.319)\tPrec@5 96.000 (98.242)\n",
            "Test: [100/261]\tTime 0.010 (0.027)\tLoss 1.0625 (0.7296)\tPrec@1 80.000 (83.436)\tPrec@5 98.000 (98.208)\n",
            "Test: [110/261]\tTime 0.027 (0.027)\tLoss 0.7362 (0.7236)\tPrec@1 84.000 (83.505)\tPrec@5 99.000 (98.225)\n",
            "Test: [120/261]\tTime 0.038 (0.027)\tLoss 0.7028 (0.7246)\tPrec@1 88.000 (83.504)\tPrec@5 98.000 (98.264)\n",
            "Test: [130/261]\tTime 0.038 (0.027)\tLoss 0.9297 (0.7325)\tPrec@1 81.000 (83.420)\tPrec@5 97.000 (98.252)\n",
            "Test: [140/261]\tTime 0.010 (0.027)\tLoss 0.7378 (0.7301)\tPrec@1 84.000 (83.489)\tPrec@5 97.000 (98.277)\n",
            "Test: [150/261]\tTime 0.017 (0.027)\tLoss 0.4846 (0.7316)\tPrec@1 87.000 (83.596)\tPrec@5 98.000 (98.232)\n",
            "Test: [160/261]\tTime 0.019 (0.027)\tLoss 0.2995 (0.7304)\tPrec@1 87.000 (83.565)\tPrec@5 100.000 (98.273)\n",
            "Test: [170/261]\tTime 0.022 (0.027)\tLoss 0.6272 (0.7263)\tPrec@1 88.000 (83.626)\tPrec@5 96.000 (98.263)\n",
            "Test: [180/261]\tTime 0.018 (0.027)\tLoss 0.5346 (0.7283)\tPrec@1 86.000 (83.558)\tPrec@5 96.000 (98.232)\n",
            "Test: [190/261]\tTime 0.018 (0.026)\tLoss 0.4777 (0.7250)\tPrec@1 88.000 (83.613)\tPrec@5 99.000 (98.230)\n",
            "Test: [200/261]\tTime 0.025 (0.026)\tLoss 0.8264 (0.7248)\tPrec@1 83.000 (83.577)\tPrec@5 97.000 (98.209)\n",
            "Test: [210/261]\tTime 0.010 (0.026)\tLoss 0.7046 (0.7241)\tPrec@1 82.000 (83.597)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.025 (0.026)\tLoss 0.7488 (0.7200)\tPrec@1 84.000 (83.656)\tPrec@5 99.000 (98.240)\n",
            "Test: [230/261]\tTime 0.018 (0.026)\tLoss 0.6281 (0.7219)\tPrec@1 82.000 (83.636)\tPrec@5 98.000 (98.234)\n",
            "Test: [240/261]\tTime 0.027 (0.026)\tLoss 1.0958 (0.7248)\tPrec@1 81.000 (83.585)\tPrec@5 98.000 (98.203)\n",
            "Test: [250/261]\tTime 0.027 (0.026)\tLoss 0.4727 (0.7213)\tPrec@1 86.000 (83.622)\tPrec@5 100.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.3042 (0.7227)\tPrec@1 90.625 (83.597)\tPrec@5 100.000 (98.198)\n",
            "val Results: Prec@1 83.597 Prec@5 98.198 Loss 0.72273\n",
            "val Class Accuracy: [0.719,0.914,0.941,0.775,0.917,0.807,0.804,0.776,0.786,0.633]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [146][0/66], lr: 0.01000\tTime 0.523 (0.523)\tData 0.435 (0.435)\tLoss 0.0273 (0.0273)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [146][10/66], lr: 0.01000\tTime 0.097 (0.134)\tData 0.004 (0.048)\tLoss 0.0422 (0.0475)\tPrec@1 97.656 (98.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [146][20/66], lr: 0.01000\tTime 0.095 (0.115)\tData 0.028 (0.030)\tLoss 0.0634 (0.0536)\tPrec@1 97.656 (98.158)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [146][30/66], lr: 0.01000\tTime 0.075 (0.108)\tData 0.004 (0.025)\tLoss 0.0321 (0.0503)\tPrec@1 99.609 (98.337)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [146][40/66], lr: 0.01000\tTime 0.081 (0.105)\tData 0.022 (0.022)\tLoss 0.0294 (0.0478)\tPrec@1 98.828 (98.380)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [146][50/66], lr: 0.01000\tTime 0.094 (0.103)\tData 0.007 (0.019)\tLoss 0.0291 (0.0465)\tPrec@1 98.828 (98.430)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [146][60/66], lr: 0.01000\tTime 0.068 (0.101)\tData 0.000 (0.019)\tLoss 0.0364 (0.0464)\tPrec@1 98.828 (98.431)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.316 (0.316)\tLoss 1.1347 (1.1347)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.010 (0.046)\tLoss 1.2483 (1.0339)\tPrec@1 80.000 (79.727)\tPrec@5 97.000 (96.636)\n",
            "Test: [20/261]\tTime 0.029 (0.037)\tLoss 0.9653 (0.9856)\tPrec@1 81.000 (80.238)\tPrec@5 97.000 (97.143)\n",
            "Test: [30/261]\tTime 0.038 (0.034)\tLoss 0.8470 (0.9319)\tPrec@1 85.000 (81.548)\tPrec@5 98.000 (97.323)\n",
            "Test: [40/261]\tTime 0.028 (0.032)\tLoss 0.6646 (0.9008)\tPrec@1 87.000 (81.902)\tPrec@5 97.000 (97.561)\n",
            "Test: [50/261]\tTime 0.010 (0.030)\tLoss 0.7203 (0.8851)\tPrec@1 81.000 (82.118)\tPrec@5 98.000 (97.667)\n",
            "Test: [60/261]\tTime 0.029 (0.030)\tLoss 0.7918 (0.8844)\tPrec@1 81.000 (81.951)\tPrec@5 98.000 (97.689)\n",
            "Test: [70/261]\tTime 0.015 (0.029)\tLoss 1.1107 (0.8975)\tPrec@1 77.000 (81.859)\tPrec@5 98.000 (97.676)\n",
            "Test: [80/261]\tTime 0.036 (0.028)\tLoss 1.0051 (0.8979)\tPrec@1 76.000 (81.741)\tPrec@5 97.000 (97.605)\n",
            "Test: [90/261]\tTime 0.015 (0.028)\tLoss 0.9142 (0.9216)\tPrec@1 82.000 (81.429)\tPrec@5 97.000 (97.549)\n",
            "Test: [100/261]\tTime 0.040 (0.028)\tLoss 0.9971 (0.9137)\tPrec@1 82.000 (81.535)\tPrec@5 97.000 (97.574)\n",
            "Test: [110/261]\tTime 0.020 (0.028)\tLoss 0.6377 (0.9010)\tPrec@1 87.000 (81.739)\tPrec@5 98.000 (97.613)\n",
            "Test: [120/261]\tTime 0.032 (0.027)\tLoss 0.9180 (0.9047)\tPrec@1 83.000 (81.636)\tPrec@5 97.000 (97.587)\n",
            "Test: [130/261]\tTime 0.033 (0.027)\tLoss 1.0267 (0.9048)\tPrec@1 80.000 (81.634)\tPrec@5 96.000 (97.588)\n",
            "Test: [140/261]\tTime 0.024 (0.027)\tLoss 0.9995 (0.9023)\tPrec@1 80.000 (81.652)\tPrec@5 97.000 (97.631)\n",
            "Test: [150/261]\tTime 0.010 (0.027)\tLoss 0.7403 (0.9017)\tPrec@1 78.000 (81.629)\tPrec@5 98.000 (97.636)\n",
            "Test: [160/261]\tTime 0.030 (0.027)\tLoss 0.4782 (0.9025)\tPrec@1 88.000 (81.671)\tPrec@5 100.000 (97.602)\n",
            "Test: [170/261]\tTime 0.048 (0.027)\tLoss 0.7372 (0.8966)\tPrec@1 88.000 (81.743)\tPrec@5 97.000 (97.596)\n",
            "Test: [180/261]\tTime 0.021 (0.026)\tLoss 0.9763 (0.9007)\tPrec@1 81.000 (81.635)\tPrec@5 95.000 (97.552)\n",
            "Test: [190/261]\tTime 0.024 (0.026)\tLoss 0.8438 (0.9011)\tPrec@1 81.000 (81.628)\tPrec@5 100.000 (97.592)\n",
            "Test: [200/261]\tTime 0.029 (0.026)\tLoss 0.7782 (0.9018)\tPrec@1 81.000 (81.577)\tPrec@5 98.000 (97.552)\n",
            "Test: [210/261]\tTime 0.039 (0.026)\tLoss 0.6571 (0.9024)\tPrec@1 82.000 (81.583)\tPrec@5 99.000 (97.564)\n",
            "Test: [220/261]\tTime 0.034 (0.026)\tLoss 0.7929 (0.8974)\tPrec@1 80.000 (81.643)\tPrec@5 97.000 (97.566)\n",
            "Test: [230/261]\tTime 0.027 (0.026)\tLoss 0.9133 (0.8979)\tPrec@1 79.000 (81.632)\tPrec@5 98.000 (97.563)\n",
            "Test: [240/261]\tTime 0.022 (0.026)\tLoss 0.9905 (0.9012)\tPrec@1 81.000 (81.577)\tPrec@5 98.000 (97.535)\n",
            "Test: [250/261]\tTime 0.039 (0.026)\tLoss 0.6262 (0.8941)\tPrec@1 85.000 (81.697)\tPrec@5 99.000 (97.570)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.3308 (0.8955)\tPrec@1 93.750 (81.676)\tPrec@5 100.000 (97.561)\n",
            "val Results: Prec@1 81.676 Prec@5 97.561 Loss 0.89551\n",
            "val Class Accuracy: [0.550,0.929,0.944,0.850,0.900,0.880,0.656,0.775,0.656,0.552]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [147][0/66], lr: 0.01000\tTime 0.567 (0.567)\tData 0.476 (0.476)\tLoss 0.0274 (0.0274)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][10/66], lr: 0.01000\tTime 0.098 (0.139)\tData 0.000 (0.047)\tLoss 0.0994 (0.0458)\tPrec@1 97.266 (98.473)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][20/66], lr: 0.01000\tTime 0.092 (0.117)\tData 0.001 (0.027)\tLoss 0.0532 (0.0447)\tPrec@1 98.047 (98.493)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][30/66], lr: 0.01000\tTime 0.100 (0.110)\tData 0.000 (0.020)\tLoss 0.0530 (0.0461)\tPrec@1 97.266 (98.425)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][40/66], lr: 0.01000\tTime 0.092 (0.106)\tData 0.005 (0.016)\tLoss 0.0708 (0.0480)\tPrec@1 98.438 (98.457)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][50/66], lr: 0.01000\tTime 0.077 (0.104)\tData 0.000 (0.014)\tLoss 0.0478 (0.0463)\tPrec@1 98.828 (98.568)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [147][60/66], lr: 0.01000\tTime 0.073 (0.101)\tData 0.000 (0.013)\tLoss 0.0262 (0.0462)\tPrec@1 99.609 (98.559)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.261 (0.261)\tLoss 0.6227 (0.6227)\tPrec@1 86.000 (86.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.017 (0.043)\tLoss 0.9433 (0.7313)\tPrec@1 83.000 (84.000)\tPrec@5 99.000 (97.818)\n",
            "Test: [20/261]\tTime 0.029 (0.037)\tLoss 0.9442 (0.7295)\tPrec@1 82.000 (84.190)\tPrec@5 97.000 (97.952)\n",
            "Test: [30/261]\tTime 0.028 (0.033)\tLoss 0.5463 (0.6823)\tPrec@1 85.000 (84.839)\tPrec@5 98.000 (98.194)\n",
            "Test: [40/261]\tTime 0.017 (0.030)\tLoss 0.7807 (0.6628)\tPrec@1 87.000 (85.049)\tPrec@5 98.000 (98.390)\n",
            "Test: [50/261]\tTime 0.026 (0.028)\tLoss 0.6813 (0.6670)\tPrec@1 81.000 (85.059)\tPrec@5 97.000 (98.353)\n",
            "Test: [60/261]\tTime 0.026 (0.029)\tLoss 0.6200 (0.6615)\tPrec@1 86.000 (85.262)\tPrec@5 98.000 (98.246)\n",
            "Test: [70/261]\tTime 0.048 (0.028)\tLoss 0.5535 (0.6636)\tPrec@1 86.000 (85.239)\tPrec@5 99.000 (98.254)\n",
            "Test: [80/261]\tTime 0.033 (0.027)\tLoss 0.6676 (0.6685)\tPrec@1 86.000 (85.259)\tPrec@5 98.000 (98.160)\n",
            "Test: [90/261]\tTime 0.025 (0.027)\tLoss 0.7969 (0.6904)\tPrec@1 84.000 (85.011)\tPrec@5 96.000 (98.066)\n",
            "Test: [100/261]\tTime 0.032 (0.027)\tLoss 0.8245 (0.6887)\tPrec@1 84.000 (85.069)\tPrec@5 96.000 (98.030)\n",
            "Test: [110/261]\tTime 0.010 (0.027)\tLoss 0.7251 (0.6840)\tPrec@1 85.000 (85.072)\tPrec@5 98.000 (98.054)\n",
            "Test: [120/261]\tTime 0.028 (0.026)\tLoss 0.6651 (0.6868)\tPrec@1 88.000 (85.033)\tPrec@5 98.000 (98.041)\n",
            "Test: [130/261]\tTime 0.010 (0.026)\tLoss 0.7823 (0.6937)\tPrec@1 81.000 (84.908)\tPrec@5 97.000 (98.008)\n",
            "Test: [140/261]\tTime 0.022 (0.026)\tLoss 0.8195 (0.6917)\tPrec@1 79.000 (84.865)\tPrec@5 96.000 (97.993)\n",
            "Test: [150/261]\tTime 0.010 (0.026)\tLoss 0.6736 (0.6904)\tPrec@1 84.000 (84.881)\tPrec@5 98.000 (98.000)\n",
            "Test: [160/261]\tTime 0.033 (0.026)\tLoss 0.3921 (0.6901)\tPrec@1 89.000 (84.857)\tPrec@5 99.000 (98.006)\n",
            "Test: [170/261]\tTime 0.009 (0.026)\tLoss 0.5828 (0.6835)\tPrec@1 87.000 (85.023)\tPrec@5 99.000 (98.041)\n",
            "Test: [180/261]\tTime 0.022 (0.026)\tLoss 0.6485 (0.6867)\tPrec@1 87.000 (84.978)\tPrec@5 95.000 (97.994)\n",
            "Test: [190/261]\tTime 0.023 (0.026)\tLoss 0.4920 (0.6838)\tPrec@1 86.000 (85.026)\tPrec@5 100.000 (98.021)\n",
            "Test: [200/261]\tTime 0.039 (0.026)\tLoss 0.6391 (0.6830)\tPrec@1 85.000 (85.030)\tPrec@5 97.000 (98.005)\n",
            "Test: [210/261]\tTime 0.015 (0.025)\tLoss 0.6247 (0.6836)\tPrec@1 87.000 (85.057)\tPrec@5 97.000 (98.009)\n",
            "Test: [220/261]\tTime 0.046 (0.025)\tLoss 0.6352 (0.6815)\tPrec@1 88.000 (85.045)\tPrec@5 98.000 (98.041)\n",
            "Test: [230/261]\tTime 0.039 (0.025)\tLoss 0.8327 (0.6817)\tPrec@1 83.000 (85.043)\tPrec@5 97.000 (98.022)\n",
            "Test: [240/261]\tTime 0.036 (0.025)\tLoss 0.7620 (0.6847)\tPrec@1 85.000 (85.012)\tPrec@5 98.000 (97.983)\n",
            "Test: [250/261]\tTime 0.028 (0.025)\tLoss 0.4299 (0.6801)\tPrec@1 87.000 (85.096)\tPrec@5 99.000 (97.980)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3775 (0.6815)\tPrec@1 84.375 (85.088)\tPrec@5 96.875 (97.976)\n",
            "val Results: Prec@1 85.088 Prec@5 97.976 Loss 0.68150\n",
            "val Class Accuracy: [0.768,0.956,0.930,0.829,0.920,0.848,0.687,0.841,0.718,0.690]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [148][0/66], lr: 0.01000\tTime 0.539 (0.539)\tData 0.459 (0.459)\tLoss 0.0260 (0.0260)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][10/66], lr: 0.01000\tTime 0.090 (0.138)\tData 0.004 (0.048)\tLoss 0.0224 (0.0340)\tPrec@1 99.609 (98.970)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][20/66], lr: 0.01000\tTime 0.089 (0.117)\tData 0.000 (0.027)\tLoss 0.0323 (0.0379)\tPrec@1 98.828 (98.754)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][30/66], lr: 0.01000\tTime 0.103 (0.110)\tData 0.005 (0.021)\tLoss 0.0549 (0.0400)\tPrec@1 98.047 (98.677)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][40/66], lr: 0.01000\tTime 0.102 (0.106)\tData 0.005 (0.017)\tLoss 0.0606 (0.0431)\tPrec@1 97.656 (98.542)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][50/66], lr: 0.01000\tTime 0.080 (0.103)\tData 0.002 (0.015)\tLoss 0.0715 (0.0447)\tPrec@1 98.047 (98.476)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [148][60/66], lr: 0.01000\tTime 0.071 (0.101)\tData 0.000 (0.014)\tLoss 0.0713 (0.0470)\tPrec@1 97.266 (98.399)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.300 (0.300)\tLoss 1.0171 (1.0171)\tPrec@1 80.000 (80.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.027 (0.051)\tLoss 1.2883 (1.0926)\tPrec@1 75.000 (78.000)\tPrec@5 99.000 (97.182)\n",
            "Test: [20/261]\tTime 0.017 (0.037)\tLoss 1.3278 (1.0562)\tPrec@1 74.000 (78.524)\tPrec@5 94.000 (97.143)\n",
            "Test: [30/261]\tTime 0.024 (0.034)\tLoss 0.8497 (1.0085)\tPrec@1 81.000 (79.452)\tPrec@5 98.000 (97.387)\n",
            "Test: [40/261]\tTime 0.015 (0.032)\tLoss 1.1818 (0.9986)\tPrec@1 81.000 (79.439)\tPrec@5 96.000 (97.610)\n",
            "Test: [50/261]\tTime 0.028 (0.030)\tLoss 0.7735 (0.9831)\tPrec@1 82.000 (79.725)\tPrec@5 99.000 (97.627)\n",
            "Test: [60/261]\tTime 0.050 (0.030)\tLoss 0.8180 (0.9804)\tPrec@1 81.000 (79.803)\tPrec@5 98.000 (97.623)\n",
            "Test: [70/261]\tTime 0.024 (0.029)\tLoss 1.2007 (0.9891)\tPrec@1 75.000 (79.775)\tPrec@5 97.000 (97.592)\n",
            "Test: [80/261]\tTime 0.023 (0.028)\tLoss 1.1275 (0.9987)\tPrec@1 80.000 (79.654)\tPrec@5 96.000 (97.556)\n",
            "Test: [90/261]\tTime 0.025 (0.027)\tLoss 1.0322 (1.0259)\tPrec@1 78.000 (79.396)\tPrec@5 96.000 (97.407)\n",
            "Test: [100/261]\tTime 0.035 (0.027)\tLoss 0.9738 (1.0180)\tPrec@1 82.000 (79.436)\tPrec@5 98.000 (97.436)\n",
            "Test: [110/261]\tTime 0.015 (0.027)\tLoss 0.9192 (1.0073)\tPrec@1 88.000 (79.640)\tPrec@5 99.000 (97.468)\n",
            "Test: [120/261]\tTime 0.017 (0.026)\tLoss 1.0939 (1.0089)\tPrec@1 78.000 (79.529)\tPrec@5 97.000 (97.471)\n",
            "Test: [130/261]\tTime 0.019 (0.026)\tLoss 1.4591 (1.0090)\tPrec@1 72.000 (79.527)\tPrec@5 94.000 (97.412)\n",
            "Test: [140/261]\tTime 0.023 (0.026)\tLoss 0.9804 (1.0077)\tPrec@1 80.000 (79.532)\tPrec@5 96.000 (97.433)\n",
            "Test: [150/261]\tTime 0.025 (0.026)\tLoss 0.7770 (1.0089)\tPrec@1 83.000 (79.543)\tPrec@5 98.000 (97.450)\n",
            "Test: [160/261]\tTime 0.027 (0.026)\tLoss 0.5173 (1.0085)\tPrec@1 84.000 (79.602)\tPrec@5 99.000 (97.491)\n",
            "Test: [170/261]\tTime 0.023 (0.026)\tLoss 0.7398 (1.0030)\tPrec@1 83.000 (79.702)\tPrec@5 97.000 (97.532)\n",
            "Test: [180/261]\tTime 0.010 (0.026)\tLoss 1.0342 (1.0042)\tPrec@1 82.000 (79.619)\tPrec@5 95.000 (97.497)\n",
            "Test: [190/261]\tTime 0.012 (0.025)\tLoss 0.5697 (0.9945)\tPrec@1 89.000 (79.775)\tPrec@5 99.000 (97.539)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 1.2546 (0.9977)\tPrec@1 76.000 (79.771)\tPrec@5 95.000 (97.488)\n",
            "Test: [210/261]\tTime 0.020 (0.025)\tLoss 0.9043 (0.9960)\tPrec@1 82.000 (79.791)\tPrec@5 98.000 (97.498)\n",
            "Test: [220/261]\tTime 0.009 (0.025)\tLoss 0.9686 (0.9908)\tPrec@1 78.000 (79.833)\tPrec@5 98.000 (97.538)\n",
            "Test: [230/261]\tTime 0.025 (0.025)\tLoss 1.1295 (0.9928)\tPrec@1 74.000 (79.771)\tPrec@5 99.000 (97.537)\n",
            "Test: [240/261]\tTime 0.017 (0.025)\tLoss 1.2254 (0.9984)\tPrec@1 78.000 (79.722)\tPrec@5 99.000 (97.515)\n",
            "Test: [250/261]\tTime 0.022 (0.025)\tLoss 0.7940 (0.9927)\tPrec@1 79.000 (79.789)\tPrec@5 100.000 (97.530)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.5601 (0.9949)\tPrec@1 87.500 (79.794)\tPrec@5 100.000 (97.538)\n",
            "val Results: Prec@1 79.794 Prec@5 97.538 Loss 0.99489\n",
            "val Class Accuracy: [0.615,0.907,0.950,0.891,0.832,0.800,0.584,0.592,0.727,0.630]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [149][0/66], lr: 0.01000\tTime 0.619 (0.619)\tData 0.550 (0.550)\tLoss 0.0406 (0.0406)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][10/66], lr: 0.01000\tTime 0.086 (0.142)\tData 0.000 (0.054)\tLoss 0.0395 (0.0510)\tPrec@1 98.828 (98.153)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][20/66], lr: 0.01000\tTime 0.078 (0.120)\tData 0.003 (0.031)\tLoss 0.0253 (0.0514)\tPrec@1 99.219 (98.307)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][30/66], lr: 0.01000\tTime 0.109 (0.111)\tData 0.000 (0.023)\tLoss 0.0595 (0.0539)\tPrec@1 98.047 (98.236)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][40/66], lr: 0.01000\tTime 0.106 (0.106)\tData 0.000 (0.018)\tLoss 0.0725 (0.0533)\tPrec@1 98.047 (98.285)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][50/66], lr: 0.01000\tTime 0.106 (0.104)\tData 0.002 (0.015)\tLoss 0.0582 (0.0528)\tPrec@1 96.875 (98.269)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [149][60/66], lr: 0.01000\tTime 0.066 (0.102)\tData 0.000 (0.014)\tLoss 0.0489 (0.0529)\tPrec@1 98.438 (98.271)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.281 (0.281)\tLoss 0.6050 (0.6050)\tPrec@1 87.000 (87.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.028 (0.051)\tLoss 1.0742 (0.7232)\tPrec@1 84.000 (84.727)\tPrec@5 96.000 (97.818)\n",
            "Test: [20/261]\tTime 0.016 (0.038)\tLoss 1.0779 (0.7115)\tPrec@1 77.000 (84.143)\tPrec@5 97.000 (98.143)\n",
            "Test: [30/261]\tTime 0.021 (0.034)\tLoss 0.6984 (0.6589)\tPrec@1 85.000 (85.065)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.013 (0.032)\tLoss 0.7191 (0.6610)\tPrec@1 84.000 (85.220)\tPrec@5 99.000 (98.390)\n",
            "Test: [50/261]\tTime 0.034 (0.030)\tLoss 0.5731 (0.6733)\tPrec@1 83.000 (84.784)\tPrec@5 100.000 (98.314)\n",
            "Test: [60/261]\tTime 0.026 (0.029)\tLoss 0.5220 (0.6833)\tPrec@1 86.000 (84.852)\tPrec@5 98.000 (98.279)\n",
            "Test: [70/261]\tTime 0.025 (0.028)\tLoss 0.7692 (0.6981)\tPrec@1 81.000 (84.775)\tPrec@5 99.000 (98.282)\n",
            "Test: [80/261]\tTime 0.029 (0.028)\tLoss 0.6428 (0.7032)\tPrec@1 81.000 (84.519)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/261]\tTime 0.033 (0.028)\tLoss 0.6701 (0.7254)\tPrec@1 86.000 (84.396)\tPrec@5 98.000 (98.308)\n",
            "Test: [100/261]\tTime 0.032 (0.027)\tLoss 1.0873 (0.7287)\tPrec@1 76.000 (84.238)\tPrec@5 97.000 (98.257)\n",
            "Test: [110/261]\tTime 0.017 (0.027)\tLoss 0.6893 (0.7229)\tPrec@1 85.000 (84.261)\tPrec@5 99.000 (98.306)\n",
            "Test: [120/261]\tTime 0.034 (0.027)\tLoss 0.8275 (0.7234)\tPrec@1 87.000 (84.306)\tPrec@5 95.000 (98.264)\n",
            "Test: [130/261]\tTime 0.012 (0.027)\tLoss 0.7936 (0.7313)\tPrec@1 83.000 (84.244)\tPrec@5 99.000 (98.206)\n",
            "Test: [140/261]\tTime 0.036 (0.027)\tLoss 0.8235 (0.7314)\tPrec@1 79.000 (84.177)\tPrec@5 99.000 (98.213)\n",
            "Test: [150/261]\tTime 0.052 (0.026)\tLoss 0.7114 (0.7303)\tPrec@1 84.000 (84.179)\tPrec@5 100.000 (98.258)\n",
            "Test: [160/261]\tTime 0.015 (0.026)\tLoss 0.6071 (0.7311)\tPrec@1 85.000 (84.230)\tPrec@5 99.000 (98.230)\n",
            "Test: [170/261]\tTime 0.019 (0.026)\tLoss 0.6759 (0.7260)\tPrec@1 88.000 (84.287)\tPrec@5 97.000 (98.234)\n",
            "Test: [180/261]\tTime 0.016 (0.026)\tLoss 0.7488 (0.7306)\tPrec@1 84.000 (84.232)\tPrec@5 95.000 (98.199)\n",
            "Test: [190/261]\tTime 0.019 (0.026)\tLoss 0.7726 (0.7294)\tPrec@1 77.000 (84.262)\tPrec@5 99.000 (98.220)\n",
            "Test: [200/261]\tTime 0.013 (0.026)\tLoss 0.6123 (0.7280)\tPrec@1 89.000 (84.279)\tPrec@5 95.000 (98.174)\n",
            "Test: [210/261]\tTime 0.045 (0.026)\tLoss 0.6826 (0.7280)\tPrec@1 84.000 (84.261)\tPrec@5 99.000 (98.175)\n",
            "Test: [220/261]\tTime 0.018 (0.026)\tLoss 0.8952 (0.7271)\tPrec@1 81.000 (84.258)\tPrec@5 98.000 (98.217)\n",
            "Test: [230/261]\tTime 0.027 (0.026)\tLoss 0.7519 (0.7285)\tPrec@1 82.000 (84.212)\tPrec@5 98.000 (98.212)\n",
            "Test: [240/261]\tTime 0.021 (0.026)\tLoss 0.6340 (0.7323)\tPrec@1 87.000 (84.228)\tPrec@5 98.000 (98.183)\n",
            "Test: [250/261]\tTime 0.026 (0.026)\tLoss 0.4674 (0.7281)\tPrec@1 88.000 (84.299)\tPrec@5 100.000 (98.191)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.7513 (0.7275)\tPrec@1 84.375 (84.342)\tPrec@5 100.000 (98.179)\n",
            "val Results: Prec@1 84.342 Prec@5 98.179 Loss 0.72746\n",
            "val Class Accuracy: [0.830,0.975,0.814,0.785,0.838,0.816,0.818,0.847,0.687,0.855]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [150][0/66], lr: 0.01000\tTime 0.544 (0.544)\tData 0.461 (0.461)\tLoss 0.0456 (0.0456)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][10/66], lr: 0.01000\tTime 0.099 (0.135)\tData 0.000 (0.046)\tLoss 0.0564 (0.0532)\tPrec@1 98.828 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][20/66], lr: 0.01000\tTime 0.124 (0.114)\tData 0.000 (0.026)\tLoss 0.0199 (0.0468)\tPrec@1 99.219 (98.531)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][30/66], lr: 0.01000\tTime 0.100 (0.107)\tData 0.000 (0.019)\tLoss 0.0709 (0.0479)\tPrec@1 98.828 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][40/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.006 (0.017)\tLoss 0.0295 (0.0471)\tPrec@1 98.828 (98.399)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][50/66], lr: 0.01000\tTime 0.114 (0.112)\tData 0.005 (0.020)\tLoss 0.0431 (0.0464)\tPrec@1 98.047 (98.422)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [150][60/66], lr: 0.01000\tTime 0.076 (0.116)\tData 0.000 (0.025)\tLoss 0.0315 (0.0455)\tPrec@1 98.828 (98.476)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.265 (0.265)\tLoss 0.7554 (0.7554)\tPrec@1 81.000 (81.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.026 (0.053)\tLoss 0.9769 (0.8379)\tPrec@1 81.000 (80.455)\tPrec@5 97.000 (97.727)\n",
            "Test: [20/261]\tTime 0.037 (0.041)\tLoss 0.9803 (0.8419)\tPrec@1 80.000 (80.762)\tPrec@5 96.000 (97.524)\n",
            "Test: [30/261]\tTime 0.025 (0.034)\tLoss 0.6295 (0.7999)\tPrec@1 88.000 (81.613)\tPrec@5 98.000 (97.774)\n",
            "Test: [40/261]\tTime 0.009 (0.032)\tLoss 0.7469 (0.7796)\tPrec@1 82.000 (82.073)\tPrec@5 98.000 (97.951)\n",
            "Test: [50/261]\tTime 0.026 (0.030)\tLoss 0.6183 (0.7727)\tPrec@1 83.000 (82.216)\tPrec@5 98.000 (97.980)\n",
            "Test: [60/261]\tTime 0.031 (0.030)\tLoss 0.8773 (0.7730)\tPrec@1 78.000 (82.426)\tPrec@5 99.000 (97.885)\n",
            "Test: [70/261]\tTime 0.009 (0.029)\tLoss 0.7958 (0.7738)\tPrec@1 82.000 (82.451)\tPrec@5 98.000 (97.873)\n",
            "Test: [80/261]\tTime 0.031 (0.028)\tLoss 0.6911 (0.7753)\tPrec@1 84.000 (82.346)\tPrec@5 99.000 (97.963)\n",
            "Test: [90/261]\tTime 0.010 (0.028)\tLoss 0.7234 (0.8007)\tPrec@1 82.000 (81.967)\tPrec@5 98.000 (97.890)\n",
            "Test: [100/261]\tTime 0.011 (0.027)\tLoss 1.0680 (0.7930)\tPrec@1 79.000 (82.089)\tPrec@5 95.000 (97.851)\n",
            "Test: [110/261]\tTime 0.028 (0.027)\tLoss 0.6435 (0.7900)\tPrec@1 87.000 (82.270)\tPrec@5 98.000 (97.838)\n",
            "Test: [120/261]\tTime 0.017 (0.027)\tLoss 0.7870 (0.7882)\tPrec@1 80.000 (82.273)\tPrec@5 98.000 (97.843)\n",
            "Test: [130/261]\tTime 0.023 (0.027)\tLoss 0.7435 (0.7905)\tPrec@1 84.000 (82.290)\tPrec@5 97.000 (97.824)\n",
            "Test: [140/261]\tTime 0.028 (0.027)\tLoss 1.1518 (0.7934)\tPrec@1 77.000 (82.206)\tPrec@5 95.000 (97.844)\n",
            "Test: [150/261]\tTime 0.024 (0.027)\tLoss 0.5510 (0.7937)\tPrec@1 88.000 (82.205)\tPrec@5 97.000 (97.788)\n",
            "Test: [160/261]\tTime 0.025 (0.027)\tLoss 0.4360 (0.7955)\tPrec@1 90.000 (82.255)\tPrec@5 99.000 (97.795)\n",
            "Test: [170/261]\tTime 0.017 (0.026)\tLoss 0.6542 (0.7914)\tPrec@1 88.000 (82.415)\tPrec@5 98.000 (97.819)\n",
            "Test: [180/261]\tTime 0.026 (0.026)\tLoss 0.6088 (0.7934)\tPrec@1 89.000 (82.425)\tPrec@5 95.000 (97.807)\n",
            "Test: [190/261]\tTime 0.014 (0.026)\tLoss 0.6568 (0.7926)\tPrec@1 82.000 (82.476)\tPrec@5 99.000 (97.822)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 0.7750 (0.7934)\tPrec@1 81.000 (82.428)\tPrec@5 97.000 (97.816)\n",
            "Test: [210/261]\tTime 0.034 (0.026)\tLoss 0.5848 (0.7921)\tPrec@1 84.000 (82.464)\tPrec@5 98.000 (97.820)\n",
            "Test: [220/261]\tTime 0.016 (0.026)\tLoss 0.7101 (0.7869)\tPrec@1 80.000 (82.525)\tPrec@5 98.000 (97.837)\n",
            "Test: [230/261]\tTime 0.051 (0.026)\tLoss 0.9689 (0.7892)\tPrec@1 75.000 (82.463)\tPrec@5 96.000 (97.827)\n",
            "Test: [240/261]\tTime 0.019 (0.026)\tLoss 0.8462 (0.7911)\tPrec@1 84.000 (82.510)\tPrec@5 98.000 (97.813)\n",
            "Test: [250/261]\tTime 0.014 (0.026)\tLoss 0.6636 (0.7864)\tPrec@1 81.000 (82.586)\tPrec@5 100.000 (97.841)\n",
            "Test: [260/261]\tTime 0.008 (0.025)\tLoss 0.3366 (0.7905)\tPrec@1 93.750 (82.571)\tPrec@5 96.875 (97.814)\n",
            "val Results: Prec@1 82.571 Prec@5 97.814 Loss 0.79051\n",
            "val Class Accuracy: [0.578,0.894,0.916,0.873,0.901,0.872,0.784,0.778,0.741,0.571]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [151][0/66], lr: 0.01000\tTime 0.641 (0.641)\tData 0.570 (0.570)\tLoss 0.0450 (0.0450)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][10/66], lr: 0.01000\tTime 0.083 (0.145)\tData 0.000 (0.058)\tLoss 0.0834 (0.0432)\tPrec@1 96.875 (98.580)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][20/66], lr: 0.01000\tTime 0.101 (0.122)\tData 0.008 (0.033)\tLoss 0.0525 (0.0382)\tPrec@1 98.828 (98.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][30/66], lr: 0.01000\tTime 0.089 (0.113)\tData 0.005 (0.024)\tLoss 0.0305 (0.0386)\tPrec@1 98.438 (98.664)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][40/66], lr: 0.01000\tTime 0.113 (0.108)\tData 0.007 (0.020)\tLoss 0.0235 (0.0410)\tPrec@1 100.000 (98.628)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][50/66], lr: 0.01000\tTime 0.115 (0.106)\tData 0.000 (0.017)\tLoss 0.0252 (0.0391)\tPrec@1 99.219 (98.706)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [151][60/66], lr: 0.01000\tTime 0.074 (0.103)\tData 0.000 (0.015)\tLoss 0.0219 (0.0387)\tPrec@1 99.219 (98.719)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.269 (0.269)\tLoss 1.3467 (1.3467)\tPrec@1 76.000 (76.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.049)\tLoss 1.7497 (1.2201)\tPrec@1 77.000 (78.455)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/261]\tTime 0.023 (0.037)\tLoss 1.5559 (1.2094)\tPrec@1 76.000 (78.238)\tPrec@5 96.000 (97.429)\n",
            "Test: [30/261]\tTime 0.020 (0.033)\tLoss 1.0115 (1.1382)\tPrec@1 81.000 (79.387)\tPrec@5 97.000 (97.774)\n",
            "Test: [40/261]\tTime 0.024 (0.032)\tLoss 1.0575 (1.0948)\tPrec@1 82.000 (80.073)\tPrec@5 97.000 (97.951)\n",
            "Test: [50/261]\tTime 0.021 (0.030)\tLoss 0.8223 (1.0701)\tPrec@1 82.000 (80.353)\tPrec@5 99.000 (98.059)\n",
            "Test: [60/261]\tTime 0.016 (0.029)\tLoss 1.0899 (1.0780)\tPrec@1 79.000 (80.328)\tPrec@5 98.000 (97.951)\n",
            "Test: [70/261]\tTime 0.015 (0.029)\tLoss 1.1321 (1.0913)\tPrec@1 76.000 (80.169)\tPrec@5 99.000 (97.972)\n",
            "Test: [80/261]\tTime 0.018 (0.028)\tLoss 1.0539 (1.0924)\tPrec@1 77.000 (80.099)\tPrec@5 99.000 (98.025)\n",
            "Test: [90/261]\tTime 0.015 (0.028)\tLoss 1.2980 (1.1222)\tPrec@1 75.000 (79.802)\tPrec@5 97.000 (97.868)\n",
            "Test: [100/261]\tTime 0.020 (0.027)\tLoss 1.2488 (1.1225)\tPrec@1 80.000 (79.891)\tPrec@5 94.000 (97.812)\n",
            "Test: [110/261]\tTime 0.039 (0.027)\tLoss 1.5802 (1.1172)\tPrec@1 76.000 (79.955)\tPrec@5 96.000 (97.838)\n",
            "Test: [120/261]\tTime 0.021 (0.027)\tLoss 1.2545 (1.1121)\tPrec@1 80.000 (80.058)\tPrec@5 95.000 (97.818)\n",
            "Test: [130/261]\tTime 0.029 (0.027)\tLoss 1.2871 (1.1117)\tPrec@1 79.000 (80.168)\tPrec@5 97.000 (97.740)\n",
            "Test: [140/261]\tTime 0.014 (0.027)\tLoss 1.1646 (1.1102)\tPrec@1 80.000 (80.106)\tPrec@5 97.000 (97.780)\n",
            "Test: [150/261]\tTime 0.017 (0.027)\tLoss 0.8361 (1.1104)\tPrec@1 80.000 (80.126)\tPrec@5 98.000 (97.781)\n",
            "Test: [160/261]\tTime 0.012 (0.026)\tLoss 0.8137 (1.1105)\tPrec@1 78.000 (80.106)\tPrec@5 100.000 (97.764)\n",
            "Test: [170/261]\tTime 0.021 (0.026)\tLoss 1.0135 (1.0993)\tPrec@1 82.000 (80.205)\tPrec@5 97.000 (97.789)\n",
            "Test: [180/261]\tTime 0.014 (0.027)\tLoss 1.0549 (1.0994)\tPrec@1 82.000 (80.171)\tPrec@5 95.000 (97.773)\n",
            "Test: [190/261]\tTime 0.015 (0.026)\tLoss 1.2333 (1.0982)\tPrec@1 75.000 (80.168)\tPrec@5 98.000 (97.791)\n",
            "Test: [200/261]\tTime 0.019 (0.026)\tLoss 0.9985 (1.0966)\tPrec@1 81.000 (80.164)\tPrec@5 98.000 (97.821)\n",
            "Test: [210/261]\tTime 0.020 (0.026)\tLoss 0.9249 (1.0975)\tPrec@1 81.000 (80.152)\tPrec@5 98.000 (97.815)\n",
            "Test: [220/261]\tTime 0.027 (0.026)\tLoss 1.0220 (1.0935)\tPrec@1 81.000 (80.140)\tPrec@5 96.000 (97.842)\n",
            "Test: [230/261]\tTime 0.014 (0.026)\tLoss 1.2873 (1.0958)\tPrec@1 82.000 (80.147)\tPrec@5 96.000 (97.823)\n",
            "Test: [240/261]\tTime 0.033 (0.026)\tLoss 0.8799 (1.1030)\tPrec@1 80.000 (80.133)\tPrec@5 98.000 (97.822)\n",
            "Test: [250/261]\tTime 0.025 (0.026)\tLoss 0.8808 (1.0967)\tPrec@1 83.000 (80.191)\tPrec@5 100.000 (97.825)\n",
            "Test: [260/261]\tTime 0.007 (0.025)\tLoss 0.3037 (1.0962)\tPrec@1 93.750 (80.217)\tPrec@5 100.000 (97.810)\n",
            "val Results: Prec@1 80.217 Prec@5 97.810 Loss 1.09622\n",
            "val Class Accuracy: [0.553,0.985,0.881,0.918,0.789,0.671,0.711,0.717,0.636,0.688]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [152][0/66], lr: 0.01000\tTime 0.619 (0.619)\tData 0.547 (0.547)\tLoss 0.0548 (0.0548)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][10/66], lr: 0.01000\tTime 0.091 (0.144)\tData 0.000 (0.053)\tLoss 0.0407 (0.0516)\tPrec@1 98.438 (98.082)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][20/66], lr: 0.01000\tTime 0.096 (0.119)\tData 0.004 (0.030)\tLoss 0.0400 (0.0461)\tPrec@1 98.047 (98.233)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][30/66], lr: 0.01000\tTime 0.072 (0.110)\tData 0.000 (0.022)\tLoss 0.0615 (0.0462)\tPrec@1 96.875 (98.286)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][40/66], lr: 0.01000\tTime 0.088 (0.105)\tData 0.000 (0.018)\tLoss 0.0464 (0.0457)\tPrec@1 98.047 (98.304)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][50/66], lr: 0.01000\tTime 0.083 (0.103)\tData 0.003 (0.016)\tLoss 0.0779 (0.0477)\tPrec@1 98.047 (98.269)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [152][60/66], lr: 0.01000\tTime 0.076 (0.101)\tData 0.000 (0.014)\tLoss 0.0368 (0.0482)\tPrec@1 98.047 (98.252)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.300 (0.300)\tLoss 0.6801 (0.6801)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.025 (0.049)\tLoss 1.2884 (0.9958)\tPrec@1 78.000 (80.182)\tPrec@5 99.000 (96.545)\n",
            "Test: [20/261]\tTime 0.014 (0.036)\tLoss 1.4573 (0.9942)\tPrec@1 75.000 (80.286)\tPrec@5 92.000 (96.524)\n",
            "Test: [30/261]\tTime 0.030 (0.034)\tLoss 0.7293 (0.9335)\tPrec@1 87.000 (81.419)\tPrec@5 96.000 (96.871)\n",
            "Test: [40/261]\tTime 0.028 (0.031)\tLoss 0.9061 (0.9393)\tPrec@1 85.000 (81.098)\tPrec@5 98.000 (97.000)\n",
            "Test: [50/261]\tTime 0.029 (0.030)\tLoss 0.8870 (0.9339)\tPrec@1 82.000 (81.373)\tPrec@5 95.000 (97.059)\n",
            "Test: [60/261]\tTime 0.033 (0.029)\tLoss 0.8266 (0.9304)\tPrec@1 80.000 (81.328)\tPrec@5 98.000 (97.033)\n",
            "Test: [70/261]\tTime 0.020 (0.029)\tLoss 1.0399 (0.9359)\tPrec@1 80.000 (81.197)\tPrec@5 96.000 (97.070)\n",
            "Test: [80/261]\tTime 0.033 (0.028)\tLoss 1.0799 (0.9452)\tPrec@1 76.000 (80.914)\tPrec@5 98.000 (97.173)\n",
            "Test: [90/261]\tTime 0.023 (0.027)\tLoss 1.1160 (0.9678)\tPrec@1 83.000 (80.923)\tPrec@5 96.000 (97.055)\n",
            "Test: [100/261]\tTime 0.021 (0.027)\tLoss 1.0062 (0.9598)\tPrec@1 80.000 (81.099)\tPrec@5 97.000 (97.040)\n",
            "Test: [110/261]\tTime 0.012 (0.027)\tLoss 1.0510 (0.9536)\tPrec@1 83.000 (81.189)\tPrec@5 98.000 (97.063)\n",
            "Test: [120/261]\tTime 0.040 (0.027)\tLoss 0.7825 (0.9479)\tPrec@1 81.000 (81.248)\tPrec@5 97.000 (97.083)\n",
            "Test: [130/261]\tTime 0.025 (0.027)\tLoss 0.8989 (0.9492)\tPrec@1 77.000 (81.267)\tPrec@5 98.000 (97.046)\n",
            "Test: [140/261]\tTime 0.010 (0.026)\tLoss 0.9742 (0.9473)\tPrec@1 80.000 (81.234)\tPrec@5 97.000 (97.078)\n",
            "Test: [150/261]\tTime 0.010 (0.026)\tLoss 0.6626 (0.9491)\tPrec@1 82.000 (81.258)\tPrec@5 97.000 (97.106)\n",
            "Test: [160/261]\tTime 0.017 (0.026)\tLoss 0.6186 (0.9486)\tPrec@1 84.000 (81.261)\tPrec@5 98.000 (97.112)\n",
            "Test: [170/261]\tTime 0.023 (0.026)\tLoss 1.0524 (0.9431)\tPrec@1 81.000 (81.269)\tPrec@5 98.000 (97.158)\n",
            "Test: [180/261]\tTime 0.010 (0.026)\tLoss 0.8328 (0.9413)\tPrec@1 83.000 (81.238)\tPrec@5 97.000 (97.177)\n",
            "Test: [190/261]\tTime 0.024 (0.026)\tLoss 0.6011 (0.9370)\tPrec@1 85.000 (81.225)\tPrec@5 100.000 (97.209)\n",
            "Test: [200/261]\tTime 0.037 (0.026)\tLoss 0.9360 (0.9386)\tPrec@1 80.000 (81.194)\tPrec@5 98.000 (97.199)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 1.1077 (0.9391)\tPrec@1 77.000 (81.237)\tPrec@5 98.000 (97.223)\n",
            "Test: [220/261]\tTime 0.032 (0.025)\tLoss 0.8197 (0.9350)\tPrec@1 80.000 (81.276)\tPrec@5 96.000 (97.222)\n",
            "Test: [230/261]\tTime 0.039 (0.025)\tLoss 1.0229 (0.9378)\tPrec@1 80.000 (81.238)\tPrec@5 95.000 (97.199)\n",
            "Test: [240/261]\tTime 0.009 (0.025)\tLoss 0.8324 (0.9387)\tPrec@1 84.000 (81.278)\tPrec@5 98.000 (97.170)\n",
            "Test: [250/261]\tTime 0.040 (0.025)\tLoss 0.7193 (0.9309)\tPrec@1 82.000 (81.375)\tPrec@5 98.000 (97.191)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.6198 (0.9326)\tPrec@1 78.125 (81.323)\tPrec@5 100.000 (97.169)\n",
            "val Results: Prec@1 81.323 Prec@5 97.169 Loss 0.93259\n",
            "val Class Accuracy: [0.577,0.953,0.948,0.845,0.908,0.710,0.584,0.758,0.726,0.666]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [153][0/66], lr: 0.01000\tTime 0.595 (0.595)\tData 0.510 (0.510)\tLoss 0.0262 (0.0262)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][10/66], lr: 0.01000\tTime 0.088 (0.141)\tData 0.005 (0.054)\tLoss 0.0702 (0.0547)\tPrec@1 98.047 (98.331)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][20/66], lr: 0.01000\tTime 0.095 (0.119)\tData 0.001 (0.030)\tLoss 0.0475 (0.0478)\tPrec@1 97.656 (98.419)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][30/66], lr: 0.01000\tTime 0.093 (0.110)\tData 0.000 (0.022)\tLoss 0.0578 (0.0512)\tPrec@1 98.828 (98.311)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][40/66], lr: 0.01000\tTime 0.097 (0.106)\tData 0.005 (0.018)\tLoss 0.0543 (0.0539)\tPrec@1 98.828 (98.161)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][50/66], lr: 0.01000\tTime 0.084 (0.103)\tData 0.000 (0.015)\tLoss 0.0214 (0.0523)\tPrec@1 99.609 (98.215)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [153][60/66], lr: 0.01000\tTime 0.074 (0.100)\tData 0.000 (0.014)\tLoss 0.0566 (0.0506)\tPrec@1 97.656 (98.284)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.269 (0.269)\tLoss 0.6601 (0.6601)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.015 (0.051)\tLoss 1.0150 (0.7985)\tPrec@1 81.000 (82.091)\tPrec@5 100.000 (97.818)\n",
            "Test: [20/261]\tTime 0.028 (0.035)\tLoss 1.0796 (0.8254)\tPrec@1 80.000 (82.381)\tPrec@5 97.000 (97.667)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.6828 (0.7889)\tPrec@1 88.000 (83.355)\tPrec@5 99.000 (98.000)\n",
            "Test: [40/261]\tTime 0.026 (0.031)\tLoss 0.6803 (0.7778)\tPrec@1 87.000 (83.683)\tPrec@5 99.000 (98.146)\n",
            "Test: [50/261]\tTime 0.018 (0.030)\tLoss 0.6654 (0.7707)\tPrec@1 84.000 (83.725)\tPrec@5 98.000 (98.196)\n",
            "Test: [60/261]\tTime 0.017 (0.030)\tLoss 0.8893 (0.7707)\tPrec@1 83.000 (83.820)\tPrec@5 97.000 (98.115)\n",
            "Test: [70/261]\tTime 0.030 (0.029)\tLoss 0.6634 (0.7657)\tPrec@1 83.000 (83.930)\tPrec@5 97.000 (98.113)\n",
            "Test: [80/261]\tTime 0.023 (0.028)\tLoss 0.6629 (0.7618)\tPrec@1 82.000 (83.963)\tPrec@5 98.000 (98.111)\n",
            "Test: [90/261]\tTime 0.017 (0.028)\tLoss 0.8459 (0.7869)\tPrec@1 82.000 (83.681)\tPrec@5 96.000 (98.033)\n",
            "Test: [100/261]\tTime 0.010 (0.028)\tLoss 0.9400 (0.7906)\tPrec@1 85.000 (83.624)\tPrec@5 96.000 (97.980)\n",
            "Test: [110/261]\tTime 0.035 (0.028)\tLoss 1.0137 (0.7888)\tPrec@1 81.000 (83.676)\tPrec@5 98.000 (98.027)\n",
            "Test: [120/261]\tTime 0.017 (0.027)\tLoss 0.6755 (0.7836)\tPrec@1 84.000 (83.669)\tPrec@5 97.000 (97.959)\n",
            "Test: [130/261]\tTime 0.031 (0.027)\tLoss 0.8262 (0.7890)\tPrec@1 83.000 (83.718)\tPrec@5 99.000 (97.893)\n",
            "Test: [140/261]\tTime 0.009 (0.027)\tLoss 0.8108 (0.7875)\tPrec@1 78.000 (83.695)\tPrec@5 99.000 (97.879)\n",
            "Test: [150/261]\tTime 0.028 (0.027)\tLoss 0.4909 (0.7892)\tPrec@1 88.000 (83.695)\tPrec@5 98.000 (97.868)\n",
            "Test: [160/261]\tTime 0.016 (0.026)\tLoss 0.4058 (0.7896)\tPrec@1 89.000 (83.702)\tPrec@5 99.000 (97.876)\n",
            "Test: [170/261]\tTime 0.018 (0.026)\tLoss 0.6919 (0.7849)\tPrec@1 90.000 (83.848)\tPrec@5 97.000 (97.906)\n",
            "Test: [180/261]\tTime 0.012 (0.026)\tLoss 0.6283 (0.7883)\tPrec@1 91.000 (83.873)\tPrec@5 96.000 (97.890)\n",
            "Test: [190/261]\tTime 0.027 (0.026)\tLoss 0.5692 (0.7835)\tPrec@1 87.000 (83.958)\tPrec@5 99.000 (97.921)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 0.7494 (0.7850)\tPrec@1 83.000 (83.905)\tPrec@5 97.000 (97.925)\n",
            "Test: [210/261]\tTime 0.018 (0.026)\tLoss 0.5904 (0.7851)\tPrec@1 85.000 (83.867)\tPrec@5 99.000 (97.929)\n",
            "Test: [220/261]\tTime 0.017 (0.026)\tLoss 0.6953 (0.7814)\tPrec@1 85.000 (83.882)\tPrec@5 98.000 (97.959)\n",
            "Test: [230/261]\tTime 0.019 (0.026)\tLoss 1.1058 (0.7840)\tPrec@1 77.000 (83.857)\tPrec@5 96.000 (97.948)\n",
            "Test: [240/261]\tTime 0.034 (0.025)\tLoss 1.0335 (0.7852)\tPrec@1 82.000 (83.867)\tPrec@5 99.000 (97.938)\n",
            "Test: [250/261]\tTime 0.023 (0.025)\tLoss 0.6316 (0.7794)\tPrec@1 81.000 (83.908)\tPrec@5 100.000 (97.952)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.1866 (0.7795)\tPrec@1 90.625 (83.912)\tPrec@5 100.000 (97.953)\n",
            "val Results: Prec@1 83.912 Prec@5 97.953 Loss 0.77950\n",
            "val Class Accuracy: [0.733,0.919,0.932,0.860,0.933,0.782,0.819,0.727,0.749,0.618]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [154][0/66], lr: 0.01000\tTime 0.457 (0.457)\tData 0.376 (0.376)\tLoss 0.0222 (0.0222)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][10/66], lr: 0.01000\tTime 0.082 (0.138)\tData 0.000 (0.048)\tLoss 0.0323 (0.0473)\tPrec@1 99.219 (98.473)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][20/66], lr: 0.01000\tTime 0.089 (0.119)\tData 0.000 (0.028)\tLoss 0.0783 (0.0559)\tPrec@1 97.266 (98.103)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][30/66], lr: 0.01000\tTime 0.095 (0.111)\tData 0.005 (0.021)\tLoss 0.0740 (0.0521)\tPrec@1 97.266 (98.261)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [154][40/66], lr: 0.01000\tTime 0.086 (0.107)\tData 0.000 (0.018)\tLoss 0.0315 (0.0514)\tPrec@1 99.219 (98.304)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [154][50/66], lr: 0.01000\tTime 0.055 (0.104)\tData 0.000 (0.016)\tLoss 0.0473 (0.0496)\tPrec@1 98.828 (98.415)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [154][60/66], lr: 0.01000\tTime 0.068 (0.101)\tData 0.000 (0.016)\tLoss 0.0204 (0.0493)\tPrec@1 99.609 (98.405)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.293 (0.293)\tLoss 0.9857 (0.9857)\tPrec@1 78.000 (78.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.027 (0.048)\tLoss 1.0616 (0.8178)\tPrec@1 81.000 (81.818)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/261]\tTime 0.021 (0.036)\tLoss 1.1251 (0.8532)\tPrec@1 74.000 (81.619)\tPrec@5 98.000 (97.619)\n",
            "Test: [30/261]\tTime 0.024 (0.033)\tLoss 0.5971 (0.8029)\tPrec@1 89.000 (82.903)\tPrec@5 98.000 (97.903)\n",
            "Test: [40/261]\tTime 0.021 (0.030)\tLoss 1.0348 (0.7969)\tPrec@1 83.000 (83.341)\tPrec@5 97.000 (97.951)\n",
            "Test: [50/261]\tTime 0.036 (0.029)\tLoss 0.6366 (0.7888)\tPrec@1 81.000 (83.333)\tPrec@5 99.000 (98.020)\n",
            "Test: [60/261]\tTime 0.034 (0.029)\tLoss 0.6501 (0.7830)\tPrec@1 83.000 (83.459)\tPrec@5 99.000 (98.082)\n",
            "Test: [70/261]\tTime 0.031 (0.028)\tLoss 0.8353 (0.7953)\tPrec@1 77.000 (83.254)\tPrec@5 98.000 (98.113)\n",
            "Test: [80/261]\tTime 0.022 (0.027)\tLoss 0.6971 (0.7949)\tPrec@1 83.000 (83.099)\tPrec@5 99.000 (98.160)\n",
            "Test: [90/261]\tTime 0.035 (0.027)\tLoss 0.7691 (0.8136)\tPrec@1 85.000 (82.890)\tPrec@5 96.000 (98.011)\n",
            "Test: [100/261]\tTime 0.030 (0.027)\tLoss 0.9911 (0.8098)\tPrec@1 83.000 (82.960)\tPrec@5 96.000 (97.931)\n",
            "Test: [110/261]\tTime 0.026 (0.027)\tLoss 0.8473 (0.8037)\tPrec@1 82.000 (82.937)\tPrec@5 98.000 (97.910)\n",
            "Test: [120/261]\tTime 0.026 (0.026)\tLoss 0.8157 (0.8040)\tPrec@1 85.000 (82.942)\tPrec@5 97.000 (97.917)\n",
            "Test: [130/261]\tTime 0.018 (0.026)\tLoss 0.8273 (0.8055)\tPrec@1 81.000 (82.901)\tPrec@5 99.000 (97.885)\n",
            "Test: [140/261]\tTime 0.018 (0.026)\tLoss 0.9593 (0.8037)\tPrec@1 80.000 (82.979)\tPrec@5 97.000 (97.879)\n",
            "Test: [150/261]\tTime 0.033 (0.026)\tLoss 0.7228 (0.8014)\tPrec@1 83.000 (83.026)\tPrec@5 97.000 (97.894)\n",
            "Test: [160/261]\tTime 0.030 (0.026)\tLoss 0.4306 (0.8038)\tPrec@1 85.000 (83.019)\tPrec@5 98.000 (97.845)\n",
            "Test: [170/261]\tTime 0.023 (0.025)\tLoss 0.5871 (0.7972)\tPrec@1 87.000 (83.088)\tPrec@5 96.000 (97.860)\n",
            "Test: [180/261]\tTime 0.015 (0.025)\tLoss 0.7982 (0.8012)\tPrec@1 85.000 (83.110)\tPrec@5 95.000 (97.829)\n",
            "Test: [190/261]\tTime 0.037 (0.025)\tLoss 0.5931 (0.7975)\tPrec@1 88.000 (83.162)\tPrec@5 99.000 (97.869)\n",
            "Test: [200/261]\tTime 0.018 (0.025)\tLoss 0.8608 (0.7959)\tPrec@1 84.000 (83.174)\tPrec@5 97.000 (97.851)\n",
            "Test: [210/261]\tTime 0.036 (0.025)\tLoss 0.6694 (0.7951)\tPrec@1 87.000 (83.237)\tPrec@5 99.000 (97.872)\n",
            "Test: [220/261]\tTime 0.010 (0.025)\tLoss 0.7133 (0.7904)\tPrec@1 83.000 (83.240)\tPrec@5 98.000 (97.878)\n",
            "Test: [230/261]\tTime 0.010 (0.025)\tLoss 0.9343 (0.7923)\tPrec@1 84.000 (83.199)\tPrec@5 97.000 (97.879)\n",
            "Test: [240/261]\tTime 0.015 (0.025)\tLoss 0.8695 (0.7958)\tPrec@1 85.000 (83.174)\tPrec@5 98.000 (97.855)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.4912 (0.7893)\tPrec@1 83.000 (83.263)\tPrec@5 100.000 (97.865)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.1232 (0.7907)\tPrec@1 93.750 (83.271)\tPrec@5 100.000 (97.872)\n",
            "val Results: Prec@1 83.271 Prec@5 97.872 Loss 0.79072\n",
            "val Class Accuracy: [0.739,0.956,0.901,0.804,0.864,0.863,0.700,0.758,0.675,0.742]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [155][0/66], lr: 0.01000\tTime 0.608 (0.608)\tData 0.530 (0.530)\tLoss 0.0594 (0.0594)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][10/66], lr: 0.01000\tTime 0.089 (0.141)\tData 0.000 (0.051)\tLoss 0.0690 (0.0475)\tPrec@1 98.438 (98.366)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][20/66], lr: 0.01000\tTime 0.086 (0.116)\tData 0.001 (0.029)\tLoss 0.0493 (0.0486)\tPrec@1 98.828 (98.344)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][30/66], lr: 0.01000\tTime 0.090 (0.109)\tData 0.004 (0.021)\tLoss 0.0338 (0.0463)\tPrec@1 98.828 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][40/66], lr: 0.01000\tTime 0.105 (0.105)\tData 0.000 (0.017)\tLoss 0.0264 (0.0454)\tPrec@1 99.609 (98.514)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][50/66], lr: 0.01000\tTime 0.088 (0.103)\tData 0.004 (0.014)\tLoss 0.0412 (0.0446)\tPrec@1 98.047 (98.522)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [155][60/66], lr: 0.01000\tTime 0.067 (0.101)\tData 0.000 (0.013)\tLoss 0.0549 (0.0465)\tPrec@1 98.438 (98.482)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.221 (0.221)\tLoss 0.7436 (0.7436)\tPrec@1 84.000 (84.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.025 (0.050)\tLoss 1.4347 (0.9735)\tPrec@1 79.000 (81.364)\tPrec@5 100.000 (97.818)\n",
            "Test: [20/261]\tTime 0.035 (0.037)\tLoss 1.1098 (0.9035)\tPrec@1 81.000 (82.000)\tPrec@5 96.000 (97.810)\n",
            "Test: [30/261]\tTime 0.025 (0.032)\tLoss 0.4917 (0.8230)\tPrec@1 88.000 (83.419)\tPrec@5 99.000 (98.032)\n",
            "Test: [40/261]\tTime 0.028 (0.031)\tLoss 0.8212 (0.8073)\tPrec@1 84.000 (83.585)\tPrec@5 95.000 (98.073)\n",
            "Test: [50/261]\tTime 0.031 (0.030)\tLoss 0.7760 (0.8049)\tPrec@1 78.000 (83.647)\tPrec@5 98.000 (98.098)\n",
            "Test: [60/261]\tTime 0.022 (0.029)\tLoss 0.7023 (0.8054)\tPrec@1 87.000 (83.672)\tPrec@5 98.000 (98.016)\n",
            "Test: [70/261]\tTime 0.026 (0.028)\tLoss 0.9683 (0.8060)\tPrec@1 80.000 (83.620)\tPrec@5 98.000 (98.056)\n",
            "Test: [80/261]\tTime 0.021 (0.028)\tLoss 0.8723 (0.8011)\tPrec@1 79.000 (83.691)\tPrec@5 98.000 (98.037)\n",
            "Test: [90/261]\tTime 0.021 (0.028)\tLoss 0.8567 (0.8267)\tPrec@1 83.000 (83.440)\tPrec@5 97.000 (97.846)\n",
            "Test: [100/261]\tTime 0.040 (0.027)\tLoss 0.9876 (0.8295)\tPrec@1 81.000 (83.465)\tPrec@5 94.000 (97.762)\n",
            "Test: [110/261]\tTime 0.012 (0.027)\tLoss 0.7636 (0.8208)\tPrec@1 83.000 (83.459)\tPrec@5 99.000 (97.838)\n",
            "Test: [120/261]\tTime 0.022 (0.027)\tLoss 0.6831 (0.8177)\tPrec@1 85.000 (83.446)\tPrec@5 97.000 (97.843)\n",
            "Test: [130/261]\tTime 0.034 (0.027)\tLoss 0.8401 (0.8217)\tPrec@1 83.000 (83.473)\tPrec@5 100.000 (97.786)\n",
            "Test: [140/261]\tTime 0.032 (0.027)\tLoss 0.9270 (0.8204)\tPrec@1 83.000 (83.511)\tPrec@5 96.000 (97.794)\n",
            "Test: [150/261]\tTime 0.030 (0.027)\tLoss 0.5282 (0.8206)\tPrec@1 86.000 (83.536)\tPrec@5 98.000 (97.748)\n",
            "Test: [160/261]\tTime 0.012 (0.026)\tLoss 0.5139 (0.8196)\tPrec@1 89.000 (83.522)\tPrec@5 99.000 (97.752)\n",
            "Test: [170/261]\tTime 0.016 (0.026)\tLoss 0.7934 (0.8160)\tPrec@1 88.000 (83.567)\tPrec@5 97.000 (97.778)\n",
            "Test: [180/261]\tTime 0.017 (0.026)\tLoss 0.7299 (0.8167)\tPrec@1 86.000 (83.525)\tPrec@5 95.000 (97.740)\n",
            "Test: [190/261]\tTime 0.031 (0.026)\tLoss 0.5982 (0.8146)\tPrec@1 85.000 (83.560)\tPrec@5 100.000 (97.770)\n",
            "Test: [200/261]\tTime 0.032 (0.026)\tLoss 0.8991 (0.8130)\tPrec@1 84.000 (83.542)\tPrec@5 98.000 (97.741)\n",
            "Test: [210/261]\tTime 0.039 (0.026)\tLoss 0.5040 (0.8121)\tPrec@1 89.000 (83.578)\tPrec@5 98.000 (97.744)\n",
            "Test: [220/261]\tTime 0.010 (0.026)\tLoss 0.6781 (0.8070)\tPrec@1 85.000 (83.620)\tPrec@5 99.000 (97.783)\n",
            "Test: [230/261]\tTime 0.024 (0.026)\tLoss 0.8929 (0.8061)\tPrec@1 79.000 (83.602)\tPrec@5 97.000 (97.771)\n",
            "Test: [240/261]\tTime 0.032 (0.026)\tLoss 0.8798 (0.8098)\tPrec@1 86.000 (83.573)\tPrec@5 97.000 (97.755)\n",
            "Test: [250/261]\tTime 0.029 (0.026)\tLoss 0.7903 (0.8047)\tPrec@1 86.000 (83.665)\tPrec@5 98.000 (97.765)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.1693 (0.8051)\tPrec@1 87.500 (83.655)\tPrec@5 100.000 (97.768)\n",
            "val Results: Prec@1 83.655 Prec@5 97.768 Loss 0.80507\n",
            "val Class Accuracy: [0.772,0.953,0.922,0.831,0.915,0.754,0.775,0.811,0.723,0.546]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [156][0/66], lr: 0.01000\tTime 0.585 (0.585)\tData 0.496 (0.496)\tLoss 0.0379 (0.0379)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][10/66], lr: 0.01000\tTime 0.102 (0.140)\tData 0.005 (0.052)\tLoss 0.0551 (0.0316)\tPrec@1 98.047 (98.935)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][20/66], lr: 0.01000\tTime 0.099 (0.117)\tData 0.000 (0.030)\tLoss 0.1121 (0.0411)\tPrec@1 95.703 (98.493)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][30/66], lr: 0.01000\tTime 0.081 (0.108)\tData 0.000 (0.022)\tLoss 0.0322 (0.0421)\tPrec@1 99.219 (98.551)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][40/66], lr: 0.01000\tTime 0.102 (0.107)\tData 0.040 (0.023)\tLoss 0.0579 (0.0438)\tPrec@1 98.438 (98.552)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][50/66], lr: 0.01000\tTime 0.121 (0.104)\tData 0.003 (0.020)\tLoss 0.0234 (0.0429)\tPrec@1 99.609 (98.568)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [156][60/66], lr: 0.01000\tTime 0.077 (0.102)\tData 0.000 (0.017)\tLoss 0.0266 (0.0426)\tPrec@1 98.828 (98.578)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.303 (0.303)\tLoss 0.7669 (0.7669)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.022 (0.047)\tLoss 1.4803 (0.8813)\tPrec@1 78.000 (81.909)\tPrec@5 98.000 (97.818)\n",
            "Test: [20/261]\tTime 0.017 (0.038)\tLoss 1.3141 (0.9192)\tPrec@1 78.000 (81.857)\tPrec@5 94.000 (97.429)\n",
            "Test: [30/261]\tTime 0.031 (0.034)\tLoss 0.7187 (0.8547)\tPrec@1 87.000 (82.645)\tPrec@5 98.000 (97.839)\n",
            "Test: [40/261]\tTime 0.009 (0.031)\tLoss 0.9117 (0.8630)\tPrec@1 85.000 (82.561)\tPrec@5 97.000 (97.902)\n",
            "Test: [50/261]\tTime 0.024 (0.030)\tLoss 0.9195 (0.8656)\tPrec@1 80.000 (82.647)\tPrec@5 96.000 (97.941)\n",
            "Test: [60/261]\tTime 0.040 (0.029)\tLoss 0.8312 (0.8652)\tPrec@1 80.000 (82.705)\tPrec@5 98.000 (97.967)\n",
            "Test: [70/261]\tTime 0.010 (0.029)\tLoss 1.0170 (0.8693)\tPrec@1 77.000 (82.620)\tPrec@5 97.000 (97.845)\n",
            "Test: [80/261]\tTime 0.018 (0.027)\tLoss 0.8141 (0.8771)\tPrec@1 81.000 (82.568)\tPrec@5 98.000 (97.901)\n",
            "Test: [90/261]\tTime 0.018 (0.027)\tLoss 0.7449 (0.8987)\tPrec@1 88.000 (82.429)\tPrec@5 98.000 (97.802)\n",
            "Test: [100/261]\tTime 0.016 (0.027)\tLoss 1.0878 (0.8968)\tPrec@1 79.000 (82.396)\tPrec@5 98.000 (97.792)\n",
            "Test: [110/261]\tTime 0.032 (0.027)\tLoss 0.9303 (0.8904)\tPrec@1 82.000 (82.432)\tPrec@5 99.000 (97.766)\n",
            "Test: [120/261]\tTime 0.033 (0.027)\tLoss 0.9795 (0.8937)\tPrec@1 83.000 (82.380)\tPrec@5 98.000 (97.793)\n",
            "Test: [130/261]\tTime 0.037 (0.027)\tLoss 0.8522 (0.8947)\tPrec@1 84.000 (82.412)\tPrec@5 97.000 (97.756)\n",
            "Test: [140/261]\tTime 0.034 (0.027)\tLoss 0.9853 (0.8893)\tPrec@1 82.000 (82.468)\tPrec@5 97.000 (97.702)\n",
            "Test: [150/261]\tTime 0.016 (0.026)\tLoss 0.5448 (0.8868)\tPrec@1 86.000 (82.536)\tPrec@5 98.000 (97.669)\n",
            "Test: [160/261]\tTime 0.026 (0.026)\tLoss 0.4747 (0.8893)\tPrec@1 89.000 (82.522)\tPrec@5 99.000 (97.665)\n",
            "Test: [170/261]\tTime 0.026 (0.026)\tLoss 0.8142 (0.8816)\tPrec@1 88.000 (82.632)\tPrec@5 98.000 (97.725)\n",
            "Test: [180/261]\tTime 0.037 (0.026)\tLoss 0.7100 (0.8822)\tPrec@1 83.000 (82.564)\tPrec@5 97.000 (97.740)\n",
            "Test: [190/261]\tTime 0.035 (0.026)\tLoss 0.6583 (0.8764)\tPrec@1 86.000 (82.602)\tPrec@5 100.000 (97.743)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 1.0012 (0.8783)\tPrec@1 83.000 (82.577)\tPrec@5 97.000 (97.716)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 0.7241 (0.8780)\tPrec@1 81.000 (82.592)\tPrec@5 99.000 (97.720)\n",
            "Test: [220/261]\tTime 0.029 (0.026)\tLoss 0.9105 (0.8756)\tPrec@1 82.000 (82.561)\tPrec@5 98.000 (97.742)\n",
            "Test: [230/261]\tTime 0.023 (0.026)\tLoss 0.8704 (0.8753)\tPrec@1 80.000 (82.545)\tPrec@5 96.000 (97.719)\n",
            "Test: [240/261]\tTime 0.025 (0.026)\tLoss 0.8308 (0.8797)\tPrec@1 85.000 (82.531)\tPrec@5 98.000 (97.718)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.8137 (0.8747)\tPrec@1 82.000 (82.602)\tPrec@5 99.000 (97.741)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3808 (0.8755)\tPrec@1 87.500 (82.637)\tPrec@5 100.000 (97.749)\n",
            "val Results: Prec@1 82.637 Prec@5 97.749 Loss 0.87555\n",
            "val Class Accuracy: [0.674,0.973,0.941,0.819,0.876,0.802,0.670,0.615,0.778,0.711]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [157][0/66], lr: 0.01000\tTime 0.602 (0.602)\tData 0.524 (0.524)\tLoss 0.0415 (0.0415)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][10/66], lr: 0.01000\tTime 0.088 (0.143)\tData 0.000 (0.052)\tLoss 0.0184 (0.0420)\tPrec@1 99.609 (98.686)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][20/66], lr: 0.01000\tTime 0.074 (0.119)\tData 0.000 (0.029)\tLoss 0.0131 (0.0402)\tPrec@1 99.609 (98.679)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][30/66], lr: 0.01000\tTime 0.090 (0.111)\tData 0.000 (0.022)\tLoss 0.0446 (0.0393)\tPrec@1 98.047 (98.727)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][40/66], lr: 0.01000\tTime 0.088 (0.107)\tData 0.004 (0.018)\tLoss 0.0308 (0.0409)\tPrec@1 99.219 (98.657)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][50/66], lr: 0.01000\tTime 0.095 (0.104)\tData 0.000 (0.016)\tLoss 0.0267 (0.0416)\tPrec@1 98.828 (98.667)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [157][60/66], lr: 0.01000\tTime 0.066 (0.102)\tData 0.000 (0.014)\tLoss 0.0335 (0.0409)\tPrec@1 98.047 (98.649)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.237 (0.237)\tLoss 0.5026 (0.5026)\tPrec@1 89.000 (89.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.036 (0.049)\tLoss 1.2288 (0.8227)\tPrec@1 80.000 (81.455)\tPrec@5 100.000 (97.727)\n",
            "Test: [20/261]\tTime 0.022 (0.038)\tLoss 1.2280 (0.7843)\tPrec@1 79.000 (82.429)\tPrec@5 94.000 (97.762)\n",
            "Test: [30/261]\tTime 0.023 (0.034)\tLoss 0.5526 (0.7301)\tPrec@1 85.000 (83.548)\tPrec@5 100.000 (98.097)\n",
            "Test: [40/261]\tTime 0.024 (0.031)\tLoss 0.7577 (0.7218)\tPrec@1 86.000 (84.024)\tPrec@5 98.000 (98.293)\n",
            "Test: [50/261]\tTime 0.009 (0.031)\tLoss 0.4467 (0.7240)\tPrec@1 84.000 (83.863)\tPrec@5 100.000 (98.275)\n",
            "Test: [60/261]\tTime 0.020 (0.029)\tLoss 0.8334 (0.7221)\tPrec@1 87.000 (84.164)\tPrec@5 96.000 (98.213)\n",
            "Test: [70/261]\tTime 0.034 (0.028)\tLoss 0.4726 (0.7186)\tPrec@1 82.000 (84.155)\tPrec@5 99.000 (98.310)\n",
            "Test: [80/261]\tTime 0.025 (0.028)\tLoss 0.6936 (0.7194)\tPrec@1 84.000 (84.123)\tPrec@5 98.000 (98.222)\n",
            "Test: [90/261]\tTime 0.039 (0.028)\tLoss 0.6105 (0.7423)\tPrec@1 89.000 (84.055)\tPrec@5 100.000 (98.132)\n",
            "Test: [100/261]\tTime 0.022 (0.028)\tLoss 0.9644 (0.7413)\tPrec@1 82.000 (84.089)\tPrec@5 96.000 (98.119)\n",
            "Test: [110/261]\tTime 0.028 (0.027)\tLoss 0.8410 (0.7370)\tPrec@1 84.000 (84.171)\tPrec@5 98.000 (98.126)\n",
            "Test: [120/261]\tTime 0.020 (0.027)\tLoss 0.7920 (0.7301)\tPrec@1 86.000 (84.331)\tPrec@5 97.000 (98.132)\n",
            "Test: [130/261]\tTime 0.017 (0.027)\tLoss 0.9542 (0.7368)\tPrec@1 85.000 (84.298)\tPrec@5 99.000 (98.092)\n",
            "Test: [140/261]\tTime 0.014 (0.027)\tLoss 1.0902 (0.7372)\tPrec@1 81.000 (84.277)\tPrec@5 98.000 (98.064)\n",
            "Test: [150/261]\tTime 0.021 (0.027)\tLoss 0.4266 (0.7375)\tPrec@1 89.000 (84.272)\tPrec@5 99.000 (98.040)\n",
            "Test: [160/261]\tTime 0.024 (0.026)\tLoss 0.4088 (0.7375)\tPrec@1 89.000 (84.360)\tPrec@5 100.000 (98.043)\n",
            "Test: [170/261]\tTime 0.040 (0.026)\tLoss 0.7388 (0.7301)\tPrec@1 86.000 (84.480)\tPrec@5 97.000 (98.053)\n",
            "Test: [180/261]\tTime 0.012 (0.026)\tLoss 0.5904 (0.7294)\tPrec@1 88.000 (84.547)\tPrec@5 97.000 (98.039)\n",
            "Test: [190/261]\tTime 0.018 (0.026)\tLoss 0.4832 (0.7283)\tPrec@1 87.000 (84.503)\tPrec@5 99.000 (98.089)\n",
            "Test: [200/261]\tTime 0.022 (0.026)\tLoss 0.6358 (0.7291)\tPrec@1 85.000 (84.488)\tPrec@5 97.000 (98.045)\n",
            "Test: [210/261]\tTime 0.017 (0.026)\tLoss 0.6305 (0.7291)\tPrec@1 82.000 (84.460)\tPrec@5 99.000 (98.076)\n",
            "Test: [220/261]\tTime 0.038 (0.026)\tLoss 0.8208 (0.7268)\tPrec@1 86.000 (84.480)\tPrec@5 98.000 (98.077)\n",
            "Test: [230/261]\tTime 0.013 (0.026)\tLoss 0.8472 (0.7286)\tPrec@1 83.000 (84.424)\tPrec@5 98.000 (98.074)\n",
            "Test: [240/261]\tTime 0.021 (0.026)\tLoss 0.8139 (0.7312)\tPrec@1 87.000 (84.436)\tPrec@5 99.000 (98.050)\n",
            "Test: [250/261]\tTime 0.030 (0.026)\tLoss 0.7401 (0.7291)\tPrec@1 83.000 (84.482)\tPrec@5 98.000 (98.032)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.5215 (0.7297)\tPrec@1 84.375 (84.450)\tPrec@5 100.000 (98.022)\n",
            "val Results: Prec@1 84.450 Prec@5 98.022 Loss 0.72967\n",
            "val Class Accuracy: [0.748,0.937,0.913,0.812,0.877,0.831,0.806,0.701,0.847,0.731]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [158][0/66], lr: 0.01000\tTime 0.585 (0.585)\tData 0.494 (0.494)\tLoss 0.0468 (0.0468)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][10/66], lr: 0.01000\tTime 0.095 (0.138)\tData 0.000 (0.052)\tLoss 0.0339 (0.0378)\tPrec@1 98.828 (98.757)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [158][20/66], lr: 0.01000\tTime 0.093 (0.118)\tData 0.005 (0.031)\tLoss 0.0247 (0.0388)\tPrec@1 99.219 (98.698)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [158][30/66], lr: 0.01000\tTime 0.106 (0.113)\tData 0.000 (0.023)\tLoss 0.0218 (0.0372)\tPrec@1 99.609 (98.765)\tPrec@5 100.000 (99.987)\n",
            "Epoch: [158][40/66], lr: 0.01000\tTime 0.082 (0.107)\tData 0.007 (0.018)\tLoss 0.0411 (0.0386)\tPrec@1 98.438 (98.733)\tPrec@5 100.000 (99.990)\n",
            "Epoch: [158][50/66], lr: 0.01000\tTime 0.094 (0.105)\tData 0.000 (0.016)\tLoss 0.0110 (0.0390)\tPrec@1 99.609 (98.721)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [158][60/66], lr: 0.01000\tTime 0.075 (0.103)\tData 0.000 (0.014)\tLoss 0.0231 (0.0394)\tPrec@1 98.828 (98.706)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.260 (0.260)\tLoss 1.0049 (1.0049)\tPrec@1 81.000 (81.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.010 (0.052)\tLoss 1.3729 (0.9307)\tPrec@1 77.000 (80.727)\tPrec@5 98.000 (97.636)\n",
            "Test: [20/261]\tTime 0.034 (0.038)\tLoss 1.4938 (0.9456)\tPrec@1 74.000 (80.238)\tPrec@5 95.000 (97.524)\n",
            "Test: [30/261]\tTime 0.010 (0.034)\tLoss 0.8021 (0.8860)\tPrec@1 79.000 (81.194)\tPrec@5 98.000 (97.742)\n",
            "Test: [40/261]\tTime 0.023 (0.030)\tLoss 0.6750 (0.8538)\tPrec@1 83.000 (81.756)\tPrec@5 99.000 (97.951)\n",
            "Test: [50/261]\tTime 0.033 (0.030)\tLoss 0.7042 (0.8365)\tPrec@1 80.000 (82.157)\tPrec@5 99.000 (97.980)\n",
            "Test: [60/261]\tTime 0.018 (0.029)\tLoss 1.1298 (0.8431)\tPrec@1 78.000 (82.180)\tPrec@5 99.000 (97.934)\n",
            "Test: [70/261]\tTime 0.022 (0.028)\tLoss 1.0162 (0.8608)\tPrec@1 76.000 (82.169)\tPrec@5 97.000 (97.958)\n",
            "Test: [80/261]\tTime 0.023 (0.028)\tLoss 0.9729 (0.8708)\tPrec@1 80.000 (82.012)\tPrec@5 98.000 (97.951)\n",
            "Test: [90/261]\tTime 0.019 (0.027)\tLoss 0.9954 (0.8969)\tPrec@1 81.000 (81.758)\tPrec@5 98.000 (97.846)\n",
            "Test: [100/261]\tTime 0.021 (0.027)\tLoss 0.8519 (0.8931)\tPrec@1 80.000 (81.663)\tPrec@5 97.000 (97.792)\n",
            "Test: [110/261]\tTime 0.036 (0.027)\tLoss 1.1028 (0.8883)\tPrec@1 79.000 (81.649)\tPrec@5 98.000 (97.820)\n",
            "Test: [120/261]\tTime 0.039 (0.027)\tLoss 1.1154 (0.8895)\tPrec@1 82.000 (81.628)\tPrec@5 97.000 (97.851)\n",
            "Test: [130/261]\tTime 0.023 (0.027)\tLoss 0.8535 (0.8967)\tPrec@1 82.000 (81.573)\tPrec@5 99.000 (97.863)\n",
            "Test: [140/261]\tTime 0.015 (0.027)\tLoss 0.9495 (0.8899)\tPrec@1 79.000 (81.681)\tPrec@5 97.000 (97.887)\n",
            "Test: [150/261]\tTime 0.025 (0.027)\tLoss 0.7489 (0.8903)\tPrec@1 83.000 (81.742)\tPrec@5 98.000 (97.887)\n",
            "Test: [160/261]\tTime 0.026 (0.027)\tLoss 0.4902 (0.8920)\tPrec@1 85.000 (81.727)\tPrec@5 99.000 (97.894)\n",
            "Test: [170/261]\tTime 0.026 (0.026)\tLoss 0.7500 (0.8817)\tPrec@1 85.000 (81.871)\tPrec@5 95.000 (97.901)\n",
            "Test: [180/261]\tTime 0.024 (0.026)\tLoss 0.8819 (0.8837)\tPrec@1 84.000 (81.840)\tPrec@5 93.000 (97.878)\n",
            "Test: [190/261]\tTime 0.031 (0.026)\tLoss 0.7332 (0.8797)\tPrec@1 78.000 (81.906)\tPrec@5 99.000 (97.927)\n",
            "Test: [200/261]\tTime 0.025 (0.026)\tLoss 0.9768 (0.8835)\tPrec@1 80.000 (81.826)\tPrec@5 98.000 (97.910)\n",
            "Test: [210/261]\tTime 0.021 (0.026)\tLoss 0.6987 (0.8823)\tPrec@1 84.000 (81.806)\tPrec@5 98.000 (97.919)\n",
            "Test: [220/261]\tTime 0.024 (0.026)\tLoss 0.9930 (0.8783)\tPrec@1 80.000 (81.814)\tPrec@5 98.000 (97.941)\n",
            "Test: [230/261]\tTime 0.016 (0.026)\tLoss 0.9859 (0.8793)\tPrec@1 81.000 (81.758)\tPrec@5 95.000 (97.918)\n",
            "Test: [240/261]\tTime 0.019 (0.026)\tLoss 0.8132 (0.8845)\tPrec@1 84.000 (81.714)\tPrec@5 98.000 (97.900)\n",
            "Test: [250/261]\tTime 0.020 (0.026)\tLoss 1.0371 (0.8807)\tPrec@1 82.000 (81.785)\tPrec@5 99.000 (97.904)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.5865 (0.8795)\tPrec@1 84.375 (81.811)\tPrec@5 100.000 (97.887)\n",
            "val Results: Prec@1 81.811 Prec@5 97.887 Loss 0.87952\n",
            "val Class Accuracy: [0.735,0.986,0.885,0.846,0.797,0.889,0.642,0.598,0.634,0.766]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [159][0/66], lr: 0.01000\tTime 0.610 (0.610)\tData 0.536 (0.536)\tLoss 0.0295 (0.0295)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][10/66], lr: 0.01000\tTime 0.108 (0.144)\tData 0.002 (0.055)\tLoss 0.0266 (0.0376)\tPrec@1 98.828 (98.615)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][20/66], lr: 0.01000\tTime 0.083 (0.118)\tData 0.008 (0.032)\tLoss 0.0680 (0.0400)\tPrec@1 98.047 (98.549)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][30/66], lr: 0.01000\tTime 0.112 (0.111)\tData 0.005 (0.024)\tLoss 0.0325 (0.0423)\tPrec@1 99.219 (98.551)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][40/66], lr: 0.01000\tTime 0.086 (0.107)\tData 0.005 (0.020)\tLoss 0.0177 (0.0404)\tPrec@1 99.219 (98.619)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][50/66], lr: 0.01000\tTime 0.094 (0.104)\tData 0.000 (0.017)\tLoss 0.0174 (0.0384)\tPrec@1 99.219 (98.713)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [159][60/66], lr: 0.01000\tTime 0.073 (0.102)\tData 0.000 (0.015)\tLoss 0.0375 (0.0392)\tPrec@1 98.828 (98.668)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.246 (0.246)\tLoss 0.8288 (0.8288)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.052)\tLoss 1.2645 (0.8691)\tPrec@1 80.000 (81.909)\tPrec@5 98.000 (97.727)\n",
            "Test: [20/261]\tTime 0.023 (0.038)\tLoss 1.1401 (0.8805)\tPrec@1 77.000 (82.000)\tPrec@5 95.000 (97.524)\n",
            "Test: [30/261]\tTime 0.029 (0.034)\tLoss 0.8440 (0.8362)\tPrec@1 83.000 (82.548)\tPrec@5 98.000 (97.871)\n",
            "Test: [40/261]\tTime 0.021 (0.031)\tLoss 0.6799 (0.8078)\tPrec@1 87.000 (83.293)\tPrec@5 97.000 (98.122)\n",
            "Test: [50/261]\tTime 0.032 (0.030)\tLoss 0.5299 (0.7993)\tPrec@1 82.000 (83.216)\tPrec@5 98.000 (98.098)\n",
            "Test: [60/261]\tTime 0.010 (0.029)\tLoss 0.9847 (0.8104)\tPrec@1 81.000 (83.295)\tPrec@5 97.000 (97.967)\n",
            "Test: [70/261]\tTime 0.010 (0.029)\tLoss 0.7988 (0.8160)\tPrec@1 81.000 (83.141)\tPrec@5 98.000 (97.972)\n",
            "Test: [80/261]\tTime 0.024 (0.027)\tLoss 0.7958 (0.8159)\tPrec@1 81.000 (83.148)\tPrec@5 99.000 (97.951)\n",
            "Test: [90/261]\tTime 0.024 (0.028)\tLoss 0.8688 (0.8400)\tPrec@1 83.000 (82.736)\tPrec@5 97.000 (97.934)\n",
            "Test: [100/261]\tTime 0.017 (0.027)\tLoss 1.0112 (0.8334)\tPrec@1 78.000 (82.762)\tPrec@5 97.000 (97.941)\n",
            "Test: [110/261]\tTime 0.021 (0.027)\tLoss 1.0532 (0.8301)\tPrec@1 82.000 (82.856)\tPrec@5 96.000 (97.874)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 0.9176 (0.8257)\tPrec@1 85.000 (82.959)\tPrec@5 95.000 (97.901)\n",
            "Test: [130/261]\tTime 0.019 (0.027)\tLoss 0.9541 (0.8299)\tPrec@1 84.000 (82.947)\tPrec@5 95.000 (97.878)\n",
            "Test: [140/261]\tTime 0.026 (0.027)\tLoss 1.0796 (0.8272)\tPrec@1 79.000 (82.957)\tPrec@5 96.000 (97.865)\n",
            "Test: [150/261]\tTime 0.018 (0.027)\tLoss 0.7195 (0.8282)\tPrec@1 83.000 (83.020)\tPrec@5 98.000 (97.828)\n",
            "Test: [160/261]\tTime 0.026 (0.026)\tLoss 0.4350 (0.8344)\tPrec@1 90.000 (82.969)\tPrec@5 98.000 (97.801)\n",
            "Test: [170/261]\tTime 0.019 (0.026)\tLoss 0.5934 (0.8291)\tPrec@1 89.000 (83.070)\tPrec@5 98.000 (97.813)\n",
            "Test: [180/261]\tTime 0.017 (0.026)\tLoss 0.5641 (0.8280)\tPrec@1 87.000 (83.083)\tPrec@5 97.000 (97.812)\n",
            "Test: [190/261]\tTime 0.017 (0.026)\tLoss 0.7133 (0.8221)\tPrec@1 85.000 (83.136)\tPrec@5 98.000 (97.885)\n",
            "Test: [200/261]\tTime 0.030 (0.026)\tLoss 0.7748 (0.8254)\tPrec@1 85.000 (83.070)\tPrec@5 97.000 (97.881)\n",
            "Test: [210/261]\tTime 0.028 (0.026)\tLoss 0.6875 (0.8262)\tPrec@1 82.000 (83.066)\tPrec@5 99.000 (97.877)\n",
            "Test: [220/261]\tTime 0.009 (0.026)\tLoss 0.8293 (0.8236)\tPrec@1 82.000 (83.009)\tPrec@5 96.000 (97.882)\n",
            "Test: [230/261]\tTime 0.040 (0.026)\tLoss 0.8828 (0.8244)\tPrec@1 79.000 (82.974)\tPrec@5 96.000 (97.844)\n",
            "Test: [240/261]\tTime 0.023 (0.026)\tLoss 0.7772 (0.8271)\tPrec@1 85.000 (82.988)\tPrec@5 99.000 (97.830)\n",
            "Test: [250/261]\tTime 0.031 (0.026)\tLoss 0.4736 (0.8232)\tPrec@1 91.000 (83.044)\tPrec@5 100.000 (97.857)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3170 (0.8226)\tPrec@1 93.750 (83.052)\tPrec@5 96.875 (97.845)\n",
            "val Results: Prec@1 83.052 Prec@5 97.845 Loss 0.82264\n",
            "val Class Accuracy: [0.717,0.926,0.874,0.919,0.859,0.812,0.723,0.744,0.694,0.743]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [160][0/66], lr: 0.00010\tTime 0.549 (0.549)\tData 0.452 (0.452)\tLoss 0.0174 (0.0174)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][10/66], lr: 0.00010\tTime 0.094 (0.133)\tData 0.000 (0.048)\tLoss 0.0363 (0.0243)\tPrec@1 98.828 (99.183)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][20/66], lr: 0.00010\tTime 0.124 (0.116)\tData 0.019 (0.028)\tLoss 0.0333 (0.0279)\tPrec@1 98.828 (99.014)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][30/66], lr: 0.00010\tTime 0.085 (0.110)\tData 0.004 (0.021)\tLoss 0.0136 (0.0297)\tPrec@1 100.000 (98.967)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][40/66], lr: 0.00010\tTime 0.104 (0.107)\tData 0.000 (0.017)\tLoss 0.0203 (0.0304)\tPrec@1 99.609 (98.942)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [160][50/66], lr: 0.00010\tTime 0.088 (0.105)\tData 0.000 (0.015)\tLoss 0.0141 (0.0299)\tPrec@1 99.609 (98.989)\tPrec@5 100.000 (99.992)\n",
            "Epoch: [160][60/66], lr: 0.00010\tTime 0.082 (0.102)\tData 0.000 (0.013)\tLoss 0.0315 (0.0304)\tPrec@1 99.609 (98.982)\tPrec@5 100.000 (99.994)\n",
            "Test: [0/261]\tTime 0.278 (0.278)\tLoss 0.6906 (0.6906)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.022 (0.052)\tLoss 1.2322 (0.8093)\tPrec@1 82.000 (83.273)\tPrec@5 99.000 (98.091)\n",
            "Test: [20/261]\tTime 0.023 (0.038)\tLoss 1.1660 (0.8178)\tPrec@1 79.000 (83.333)\tPrec@5 96.000 (97.762)\n",
            "Test: [30/261]\tTime 0.020 (0.033)\tLoss 0.6132 (0.7636)\tPrec@1 86.000 (84.452)\tPrec@5 98.000 (98.065)\n",
            "Test: [40/261]\tTime 0.030 (0.032)\tLoss 0.7494 (0.7373)\tPrec@1 87.000 (85.000)\tPrec@5 98.000 (98.293)\n",
            "Test: [50/261]\tTime 0.033 (0.031)\tLoss 0.5193 (0.7307)\tPrec@1 86.000 (84.941)\tPrec@5 99.000 (98.275)\n",
            "Test: [60/261]\tTime 0.012 (0.029)\tLoss 0.8514 (0.7399)\tPrec@1 84.000 (84.951)\tPrec@5 99.000 (98.148)\n",
            "Test: [70/261]\tTime 0.030 (0.029)\tLoss 0.6928 (0.7465)\tPrec@1 82.000 (84.873)\tPrec@5 98.000 (98.155)\n",
            "Test: [80/261]\tTime 0.018 (0.028)\tLoss 0.7132 (0.7502)\tPrec@1 81.000 (84.901)\tPrec@5 98.000 (98.074)\n",
            "Test: [90/261]\tTime 0.019 (0.028)\tLoss 0.8830 (0.7751)\tPrec@1 84.000 (84.549)\tPrec@5 97.000 (98.033)\n",
            "Test: [100/261]\tTime 0.028 (0.027)\tLoss 0.9446 (0.7678)\tPrec@1 83.000 (84.663)\tPrec@5 96.000 (98.010)\n",
            "Test: [110/261]\tTime 0.037 (0.027)\tLoss 0.9204 (0.7648)\tPrec@1 84.000 (84.721)\tPrec@5 97.000 (97.982)\n",
            "Test: [120/261]\tTime 0.018 (0.027)\tLoss 0.8697 (0.7647)\tPrec@1 87.000 (84.777)\tPrec@5 97.000 (97.983)\n",
            "Test: [130/261]\tTime 0.015 (0.027)\tLoss 0.8799 (0.7693)\tPrec@1 87.000 (84.748)\tPrec@5 96.000 (97.969)\n",
            "Test: [140/261]\tTime 0.038 (0.027)\tLoss 1.0038 (0.7669)\tPrec@1 82.000 (84.723)\tPrec@5 96.000 (97.957)\n",
            "Test: [150/261]\tTime 0.013 (0.026)\tLoss 0.6213 (0.7686)\tPrec@1 87.000 (84.748)\tPrec@5 97.000 (97.940)\n",
            "Test: [160/261]\tTime 0.048 (0.026)\tLoss 0.4464 (0.7719)\tPrec@1 88.000 (84.702)\tPrec@5 100.000 (97.919)\n",
            "Test: [170/261]\tTime 0.027 (0.026)\tLoss 0.6142 (0.7673)\tPrec@1 89.000 (84.807)\tPrec@5 98.000 (97.918)\n",
            "Test: [180/261]\tTime 0.023 (0.026)\tLoss 0.5619 (0.7670)\tPrec@1 90.000 (84.834)\tPrec@5 96.000 (97.912)\n",
            "Test: [190/261]\tTime 0.021 (0.026)\tLoss 0.6776 (0.7634)\tPrec@1 83.000 (84.838)\tPrec@5 98.000 (97.958)\n",
            "Test: [200/261]\tTime 0.039 (0.026)\tLoss 0.6261 (0.7651)\tPrec@1 88.000 (84.771)\tPrec@5 97.000 (97.960)\n",
            "Test: [210/261]\tTime 0.020 (0.026)\tLoss 0.5756 (0.7670)\tPrec@1 88.000 (84.754)\tPrec@5 98.000 (97.948)\n",
            "Test: [220/261]\tTime 0.032 (0.026)\tLoss 0.7203 (0.7634)\tPrec@1 83.000 (84.719)\tPrec@5 97.000 (97.964)\n",
            "Test: [230/261]\tTime 0.019 (0.026)\tLoss 0.8873 (0.7643)\tPrec@1 84.000 (84.658)\tPrec@5 96.000 (97.939)\n",
            "Test: [240/261]\tTime 0.010 (0.026)\tLoss 0.7479 (0.7678)\tPrec@1 85.000 (84.656)\tPrec@5 98.000 (97.921)\n",
            "Test: [250/261]\tTime 0.022 (0.026)\tLoss 0.4993 (0.7629)\tPrec@1 87.000 (84.701)\tPrec@5 100.000 (97.944)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.3009 (0.7630)\tPrec@1 90.625 (84.707)\tPrec@5 96.875 (97.918)\n",
            "val Results: Prec@1 84.707 Prec@5 97.918 Loss 0.76296\n",
            "val Class Accuracy: [0.724,0.960,0.923,0.851,0.876,0.851,0.774,0.779,0.709,0.687]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [161][0/66], lr: 0.00010\tTime 0.554 (0.554)\tData 0.477 (0.477)\tLoss 0.0114 (0.0114)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][10/66], lr: 0.00010\tTime 0.077 (0.138)\tData 0.000 (0.049)\tLoss 0.0340 (0.0324)\tPrec@1 99.219 (98.899)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][20/66], lr: 0.00010\tTime 0.099 (0.119)\tData 0.000 (0.030)\tLoss 0.0591 (0.0315)\tPrec@1 97.656 (98.977)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][30/66], lr: 0.00010\tTime 0.075 (0.110)\tData 0.000 (0.022)\tLoss 0.0134 (0.0286)\tPrec@1 100.000 (99.080)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][40/66], lr: 0.00010\tTime 0.088 (0.107)\tData 0.000 (0.018)\tLoss 0.0123 (0.0260)\tPrec@1 99.609 (99.181)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][50/66], lr: 0.00010\tTime 0.098 (0.105)\tData 0.005 (0.016)\tLoss 0.0129 (0.0258)\tPrec@1 99.609 (99.196)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [161][60/66], lr: 0.00010\tTime 0.078 (0.102)\tData 0.000 (0.015)\tLoss 0.0153 (0.0252)\tPrec@1 99.609 (99.206)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.285 (0.285)\tLoss 0.6696 (0.6696)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.037 (0.053)\tLoss 1.2152 (0.7889)\tPrec@1 82.000 (83.273)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.027 (0.040)\tLoss 1.1419 (0.7964)\tPrec@1 79.000 (83.429)\tPrec@5 96.000 (97.857)\n",
            "Test: [30/261]\tTime 0.023 (0.035)\tLoss 0.6076 (0.7442)\tPrec@1 85.000 (84.548)\tPrec@5 98.000 (98.129)\n",
            "Test: [40/261]\tTime 0.022 (0.033)\tLoss 0.7504 (0.7180)\tPrec@1 87.000 (85.122)\tPrec@5 98.000 (98.366)\n",
            "Test: [50/261]\tTime 0.022 (0.031)\tLoss 0.5036 (0.7123)\tPrec@1 88.000 (85.098)\tPrec@5 99.000 (98.353)\n",
            "Test: [60/261]\tTime 0.010 (0.030)\tLoss 0.8157 (0.7215)\tPrec@1 84.000 (85.213)\tPrec@5 99.000 (98.230)\n",
            "Test: [70/261]\tTime 0.019 (0.029)\tLoss 0.6496 (0.7267)\tPrec@1 85.000 (85.239)\tPrec@5 98.000 (98.268)\n",
            "Test: [80/261]\tTime 0.029 (0.029)\tLoss 0.6846 (0.7299)\tPrec@1 86.000 (85.370)\tPrec@5 99.000 (98.185)\n",
            "Test: [90/261]\tTime 0.030 (0.029)\tLoss 0.8397 (0.7555)\tPrec@1 84.000 (84.956)\tPrec@5 97.000 (98.132)\n",
            "Test: [100/261]\tTime 0.021 (0.028)\tLoss 0.9250 (0.7478)\tPrec@1 83.000 (85.089)\tPrec@5 97.000 (98.109)\n",
            "Test: [110/261]\tTime 0.025 (0.028)\tLoss 0.8814 (0.7445)\tPrec@1 86.000 (85.144)\tPrec@5 97.000 (98.072)\n",
            "Test: [120/261]\tTime 0.009 (0.027)\tLoss 0.8488 (0.7447)\tPrec@1 87.000 (85.182)\tPrec@5 97.000 (98.058)\n",
            "Test: [130/261]\tTime 0.022 (0.027)\tLoss 0.8679 (0.7493)\tPrec@1 88.000 (85.153)\tPrec@5 96.000 (98.038)\n",
            "Test: [140/261]\tTime 0.034 (0.027)\tLoss 0.9574 (0.7466)\tPrec@1 82.000 (85.128)\tPrec@5 96.000 (98.028)\n",
            "Test: [150/261]\tTime 0.023 (0.027)\tLoss 0.5763 (0.7486)\tPrec@1 88.000 (85.179)\tPrec@5 98.000 (98.026)\n",
            "Test: [160/261]\tTime 0.030 (0.027)\tLoss 0.4294 (0.7518)\tPrec@1 88.000 (85.143)\tPrec@5 100.000 (98.006)\n",
            "Test: [170/261]\tTime 0.021 (0.027)\tLoss 0.6050 (0.7471)\tPrec@1 89.000 (85.222)\tPrec@5 98.000 (98.000)\n",
            "Test: [180/261]\tTime 0.022 (0.027)\tLoss 0.5465 (0.7468)\tPrec@1 89.000 (85.221)\tPrec@5 96.000 (97.989)\n",
            "Test: [190/261]\tTime 0.043 (0.027)\tLoss 0.6509 (0.7434)\tPrec@1 84.000 (85.230)\tPrec@5 98.000 (98.037)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 0.6128 (0.7452)\tPrec@1 89.000 (85.169)\tPrec@5 98.000 (98.040)\n",
            "Test: [210/261]\tTime 0.056 (0.028)\tLoss 0.5654 (0.7471)\tPrec@1 87.000 (85.147)\tPrec@5 98.000 (98.024)\n",
            "Test: [220/261]\tTime 0.057 (0.029)\tLoss 0.6911 (0.7433)\tPrec@1 84.000 (85.140)\tPrec@5 97.000 (98.032)\n",
            "Test: [230/261]\tTime 0.048 (0.029)\tLoss 0.8778 (0.7440)\tPrec@1 84.000 (85.087)\tPrec@5 96.000 (98.013)\n",
            "Test: [240/261]\tTime 0.053 (0.030)\tLoss 0.7343 (0.7473)\tPrec@1 86.000 (85.100)\tPrec@5 98.000 (97.996)\n",
            "Test: [250/261]\tTime 0.041 (0.030)\tLoss 0.4607 (0.7421)\tPrec@1 87.000 (85.143)\tPrec@5 100.000 (98.008)\n",
            "Test: [260/261]\tTime 0.007 (0.030)\tLoss 0.2872 (0.7426)\tPrec@1 90.625 (85.149)\tPrec@5 96.875 (97.995)\n",
            "val Results: Prec@1 85.149 Prec@5 97.995 Loss 0.74257\n",
            "val Class Accuracy: [0.719,0.960,0.926,0.855,0.886,0.849,0.790,0.785,0.727,0.687]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [162][0/66], lr: 0.00010\tTime 0.823 (0.823)\tData 0.739 (0.739)\tLoss 0.0216 (0.0216)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][10/66], lr: 0.00010\tTime 0.090 (0.167)\tData 0.000 (0.073)\tLoss 0.0242 (0.0208)\tPrec@1 98.438 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][20/66], lr: 0.00010\tTime 0.091 (0.131)\tData 0.000 (0.040)\tLoss 0.0326 (0.0189)\tPrec@1 98.047 (99.330)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][30/66], lr: 0.00010\tTime 0.085 (0.120)\tData 0.002 (0.029)\tLoss 0.0213 (0.0203)\tPrec@1 99.609 (99.345)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][40/66], lr: 0.00010\tTime 0.111 (0.113)\tData 0.000 (0.024)\tLoss 0.0457 (0.0214)\tPrec@1 98.438 (99.314)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][50/66], lr: 0.00010\tTime 0.110 (0.110)\tData 0.005 (0.020)\tLoss 0.0090 (0.0207)\tPrec@1 100.000 (99.326)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [162][60/66], lr: 0.00010\tTime 0.076 (0.106)\tData 0.000 (0.017)\tLoss 0.0304 (0.0208)\tPrec@1 99.219 (99.302)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.301 (0.301)\tLoss 0.7014 (0.7014)\tPrec@1 81.000 (81.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.032 (0.056)\tLoss 1.1985 (0.7969)\tPrec@1 82.000 (82.636)\tPrec@5 99.000 (98.091)\n",
            "Test: [20/261]\tTime 0.023 (0.039)\tLoss 1.1549 (0.8068)\tPrec@1 79.000 (82.905)\tPrec@5 96.000 (97.762)\n",
            "Test: [30/261]\tTime 0.021 (0.035)\tLoss 0.6037 (0.7579)\tPrec@1 85.000 (84.097)\tPrec@5 98.000 (98.032)\n",
            "Test: [40/261]\tTime 0.017 (0.032)\tLoss 0.7634 (0.7305)\tPrec@1 86.000 (84.756)\tPrec@5 97.000 (98.268)\n",
            "Test: [50/261]\tTime 0.018 (0.031)\tLoss 0.5088 (0.7227)\tPrec@1 86.000 (84.843)\tPrec@5 99.000 (98.235)\n",
            "Test: [60/261]\tTime 0.009 (0.030)\tLoss 0.8068 (0.7301)\tPrec@1 84.000 (84.918)\tPrec@5 99.000 (98.115)\n",
            "Test: [70/261]\tTime 0.036 (0.030)\tLoss 0.6768 (0.7348)\tPrec@1 83.000 (84.915)\tPrec@5 98.000 (98.169)\n",
            "Test: [80/261]\tTime 0.025 (0.029)\tLoss 0.6915 (0.7373)\tPrec@1 85.000 (85.049)\tPrec@5 99.000 (98.111)\n",
            "Test: [90/261]\tTime 0.024 (0.028)\tLoss 0.8248 (0.7634)\tPrec@1 84.000 (84.670)\tPrec@5 97.000 (98.044)\n",
            "Test: [100/261]\tTime 0.022 (0.028)\tLoss 0.9294 (0.7553)\tPrec@1 82.000 (84.812)\tPrec@5 96.000 (98.030)\n",
            "Test: [110/261]\tTime 0.022 (0.028)\tLoss 0.8629 (0.7512)\tPrec@1 88.000 (84.910)\tPrec@5 97.000 (98.018)\n",
            "Test: [120/261]\tTime 0.019 (0.027)\tLoss 0.8426 (0.7518)\tPrec@1 86.000 (84.959)\tPrec@5 97.000 (98.008)\n",
            "Test: [130/261]\tTime 0.023 (0.027)\tLoss 0.8640 (0.7559)\tPrec@1 88.000 (84.947)\tPrec@5 97.000 (97.992)\n",
            "Test: [140/261]\tTime 0.035 (0.027)\tLoss 0.9643 (0.7534)\tPrec@1 82.000 (84.929)\tPrec@5 97.000 (98.000)\n",
            "Test: [150/261]\tTime 0.032 (0.027)\tLoss 0.5619 (0.7552)\tPrec@1 88.000 (84.954)\tPrec@5 98.000 (98.007)\n",
            "Test: [160/261]\tTime 0.014 (0.026)\tLoss 0.4322 (0.7580)\tPrec@1 88.000 (84.950)\tPrec@5 100.000 (97.988)\n",
            "Test: [170/261]\tTime 0.016 (0.026)\tLoss 0.6139 (0.7533)\tPrec@1 89.000 (85.006)\tPrec@5 98.000 (97.977)\n",
            "Test: [180/261]\tTime 0.060 (0.026)\tLoss 0.5592 (0.7527)\tPrec@1 89.000 (85.022)\tPrec@5 96.000 (97.967)\n",
            "Test: [190/261]\tTime 0.010 (0.026)\tLoss 0.6557 (0.7496)\tPrec@1 84.000 (85.016)\tPrec@5 98.000 (98.010)\n",
            "Test: [200/261]\tTime 0.019 (0.026)\tLoss 0.5967 (0.7514)\tPrec@1 89.000 (84.965)\tPrec@5 98.000 (98.020)\n",
            "Test: [210/261]\tTime 0.015 (0.026)\tLoss 0.5780 (0.7529)\tPrec@1 87.000 (84.953)\tPrec@5 98.000 (98.005)\n",
            "Test: [220/261]\tTime 0.051 (0.026)\tLoss 0.6849 (0.7488)\tPrec@1 85.000 (84.946)\tPrec@5 97.000 (98.018)\n",
            "Test: [230/261]\tTime 0.022 (0.026)\tLoss 0.8914 (0.7495)\tPrec@1 83.000 (84.887)\tPrec@5 96.000 (98.000)\n",
            "Test: [240/261]\tTime 0.025 (0.026)\tLoss 0.7609 (0.7530)\tPrec@1 85.000 (84.900)\tPrec@5 98.000 (97.983)\n",
            "Test: [250/261]\tTime 0.050 (0.026)\tLoss 0.4648 (0.7476)\tPrec@1 86.000 (84.952)\tPrec@5 100.000 (97.996)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2760 (0.7483)\tPrec@1 90.625 (84.945)\tPrec@5 96.875 (97.987)\n",
            "val Results: Prec@1 84.945 Prec@5 97.987 Loss 0.74834\n",
            "val Class Accuracy: [0.684,0.960,0.929,0.861,0.889,0.857,0.782,0.794,0.720,0.664]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [163][0/66], lr: 0.00010\tTime 0.521 (0.521)\tData 0.429 (0.429)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][10/66], lr: 0.00010\tTime 0.091 (0.137)\tData 0.000 (0.044)\tLoss 0.0139 (0.0175)\tPrec@1 99.609 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][20/66], lr: 0.00010\tTime 0.120 (0.117)\tData 0.000 (0.025)\tLoss 0.0076 (0.0206)\tPrec@1 100.000 (99.349)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][30/66], lr: 0.00010\tTime 0.113 (0.110)\tData 0.000 (0.019)\tLoss 0.0377 (0.0206)\tPrec@1 98.438 (99.307)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][40/66], lr: 0.00010\tTime 0.085 (0.106)\tData 0.000 (0.016)\tLoss 0.0108 (0.0198)\tPrec@1 100.000 (99.362)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][50/66], lr: 0.00010\tTime 0.093 (0.104)\tData 0.000 (0.014)\tLoss 0.0112 (0.0194)\tPrec@1 99.609 (99.380)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [163][60/66], lr: 0.00010\tTime 0.077 (0.102)\tData 0.000 (0.013)\tLoss 0.0096 (0.0197)\tPrec@1 99.609 (99.379)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.322 (0.322)\tLoss 0.7008 (0.7008)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.034 (0.051)\tLoss 1.1852 (0.7871)\tPrec@1 82.000 (83.091)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.042 (0.040)\tLoss 1.1542 (0.7963)\tPrec@1 79.000 (83.286)\tPrec@5 96.000 (97.857)\n",
            "Test: [30/261]\tTime 0.033 (0.035)\tLoss 0.5974 (0.7470)\tPrec@1 85.000 (84.548)\tPrec@5 98.000 (98.129)\n",
            "Test: [40/261]\tTime 0.025 (0.032)\tLoss 0.7686 (0.7198)\tPrec@1 85.000 (85.122)\tPrec@5 97.000 (98.341)\n",
            "Test: [50/261]\tTime 0.021 (0.031)\tLoss 0.5040 (0.7134)\tPrec@1 87.000 (85.235)\tPrec@5 99.000 (98.314)\n",
            "Test: [60/261]\tTime 0.022 (0.030)\tLoss 0.7884 (0.7216)\tPrec@1 83.000 (85.279)\tPrec@5 99.000 (98.197)\n",
            "Test: [70/261]\tTime 0.039 (0.029)\tLoss 0.6530 (0.7259)\tPrec@1 84.000 (85.282)\tPrec@5 98.000 (98.239)\n",
            "Test: [80/261]\tTime 0.023 (0.029)\tLoss 0.6786 (0.7286)\tPrec@1 84.000 (85.370)\tPrec@5 98.000 (98.173)\n",
            "Test: [90/261]\tTime 0.027 (0.028)\tLoss 0.8122 (0.7549)\tPrec@1 87.000 (85.000)\tPrec@5 97.000 (98.110)\n",
            "Test: [100/261]\tTime 0.035 (0.028)\tLoss 0.9080 (0.7469)\tPrec@1 82.000 (85.158)\tPrec@5 97.000 (98.099)\n",
            "Test: [110/261]\tTime 0.026 (0.027)\tLoss 0.8452 (0.7427)\tPrec@1 88.000 (85.216)\tPrec@5 97.000 (98.081)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 0.8441 (0.7437)\tPrec@1 86.000 (85.256)\tPrec@5 97.000 (98.066)\n",
            "Test: [130/261]\tTime 0.028 (0.027)\tLoss 0.8537 (0.7482)\tPrec@1 88.000 (85.214)\tPrec@5 97.000 (98.046)\n",
            "Test: [140/261]\tTime 0.017 (0.027)\tLoss 0.9524 (0.7456)\tPrec@1 82.000 (85.206)\tPrec@5 98.000 (98.057)\n",
            "Test: [150/261]\tTime 0.009 (0.027)\tLoss 0.5347 (0.7472)\tPrec@1 88.000 (85.232)\tPrec@5 98.000 (98.060)\n",
            "Test: [160/261]\tTime 0.018 (0.027)\tLoss 0.4207 (0.7500)\tPrec@1 87.000 (85.211)\tPrec@5 100.000 (98.050)\n",
            "Test: [170/261]\tTime 0.017 (0.027)\tLoss 0.6037 (0.7454)\tPrec@1 90.000 (85.298)\tPrec@5 98.000 (98.041)\n",
            "Test: [180/261]\tTime 0.024 (0.026)\tLoss 0.5626 (0.7447)\tPrec@1 89.000 (85.298)\tPrec@5 96.000 (98.039)\n",
            "Test: [190/261]\tTime 0.027 (0.026)\tLoss 0.6295 (0.7413)\tPrec@1 84.000 (85.304)\tPrec@5 99.000 (98.089)\n",
            "Test: [200/261]\tTime 0.014 (0.026)\tLoss 0.6158 (0.7432)\tPrec@1 88.000 (85.239)\tPrec@5 98.000 (98.095)\n",
            "Test: [210/261]\tTime 0.025 (0.026)\tLoss 0.5611 (0.7450)\tPrec@1 87.000 (85.218)\tPrec@5 98.000 (98.081)\n",
            "Test: [220/261]\tTime 0.037 (0.026)\tLoss 0.6723 (0.7408)\tPrec@1 86.000 (85.222)\tPrec@5 97.000 (98.090)\n",
            "Test: [230/261]\tTime 0.023 (0.026)\tLoss 0.8997 (0.7413)\tPrec@1 83.000 (85.152)\tPrec@5 96.000 (98.069)\n",
            "Test: [240/261]\tTime 0.018 (0.026)\tLoss 0.7517 (0.7448)\tPrec@1 85.000 (85.158)\tPrec@5 98.000 (98.058)\n",
            "Test: [250/261]\tTime 0.016 (0.026)\tLoss 0.4451 (0.7392)\tPrec@1 86.000 (85.203)\tPrec@5 100.000 (98.068)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2663 (0.7401)\tPrec@1 90.625 (85.191)\tPrec@5 96.875 (98.052)\n",
            "val Results: Prec@1 85.191 Prec@5 98.052 Loss 0.74013\n",
            "val Class Accuracy: [0.706,0.961,0.935,0.860,0.888,0.852,0.785,0.788,0.731,0.665]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [164][0/66], lr: 0.00010\tTime 0.559 (0.559)\tData 0.467 (0.467)\tLoss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][10/66], lr: 0.00010\tTime 0.111 (0.139)\tData 0.000 (0.048)\tLoss 0.0179 (0.0175)\tPrec@1 99.219 (99.467)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][20/66], lr: 0.00010\tTime 0.077 (0.117)\tData 0.005 (0.028)\tLoss 0.0112 (0.0164)\tPrec@1 99.609 (99.498)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][30/66], lr: 0.00010\tTime 0.123 (0.110)\tData 0.004 (0.021)\tLoss 0.0177 (0.0174)\tPrec@1 99.219 (99.433)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][40/66], lr: 0.00010\tTime 0.085 (0.107)\tData 0.016 (0.017)\tLoss 0.0075 (0.0172)\tPrec@1 100.000 (99.428)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][50/66], lr: 0.00010\tTime 0.092 (0.104)\tData 0.005 (0.015)\tLoss 0.0450 (0.0180)\tPrec@1 99.219 (99.403)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [164][60/66], lr: 0.00010\tTime 0.067 (0.101)\tData 0.000 (0.013)\tLoss 0.0059 (0.0173)\tPrec@1 100.000 (99.443)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.241 (0.241)\tLoss 0.7152 (0.7152)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.021 (0.051)\tLoss 1.2007 (0.7788)\tPrec@1 81.000 (83.636)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.032 (0.038)\tLoss 1.1513 (0.7850)\tPrec@1 78.000 (83.619)\tPrec@5 96.000 (97.952)\n",
            "Test: [30/261]\tTime 0.027 (0.034)\tLoss 0.6183 (0.7372)\tPrec@1 85.000 (84.677)\tPrec@5 98.000 (98.194)\n",
            "Test: [40/261]\tTime 0.009 (0.031)\tLoss 0.7348 (0.7085)\tPrec@1 86.000 (85.317)\tPrec@5 97.000 (98.390)\n",
            "Test: [50/261]\tTime 0.038 (0.030)\tLoss 0.4987 (0.7034)\tPrec@1 87.000 (85.333)\tPrec@5 99.000 (98.373)\n",
            "Test: [60/261]\tTime 0.042 (0.030)\tLoss 0.7746 (0.7119)\tPrec@1 85.000 (85.377)\tPrec@5 99.000 (98.246)\n",
            "Test: [70/261]\tTime 0.035 (0.029)\tLoss 0.6287 (0.7159)\tPrec@1 85.000 (85.423)\tPrec@5 98.000 (98.254)\n",
            "Test: [80/261]\tTime 0.036 (0.028)\tLoss 0.6683 (0.7193)\tPrec@1 85.000 (85.481)\tPrec@5 99.000 (98.210)\n",
            "Test: [90/261]\tTime 0.035 (0.028)\tLoss 0.8047 (0.7459)\tPrec@1 86.000 (85.110)\tPrec@5 97.000 (98.132)\n",
            "Test: [100/261]\tTime 0.028 (0.027)\tLoss 0.8946 (0.7376)\tPrec@1 83.000 (85.297)\tPrec@5 97.000 (98.109)\n",
            "Test: [110/261]\tTime 0.027 (0.027)\tLoss 0.8434 (0.7327)\tPrec@1 88.000 (85.351)\tPrec@5 98.000 (98.108)\n",
            "Test: [120/261]\tTime 0.017 (0.027)\tLoss 0.8615 (0.7339)\tPrec@1 87.000 (85.397)\tPrec@5 97.000 (98.091)\n",
            "Test: [130/261]\tTime 0.010 (0.027)\tLoss 0.8443 (0.7385)\tPrec@1 87.000 (85.321)\tPrec@5 97.000 (98.069)\n",
            "Test: [140/261]\tTime 0.041 (0.027)\tLoss 0.9473 (0.7358)\tPrec@1 82.000 (85.326)\tPrec@5 96.000 (98.071)\n",
            "Test: [150/261]\tTime 0.021 (0.027)\tLoss 0.5180 (0.7375)\tPrec@1 88.000 (85.351)\tPrec@5 98.000 (98.079)\n",
            "Test: [160/261]\tTime 0.017 (0.027)\tLoss 0.4227 (0.7405)\tPrec@1 87.000 (85.323)\tPrec@5 100.000 (98.068)\n",
            "Test: [170/261]\tTime 0.039 (0.027)\tLoss 0.5998 (0.7359)\tPrec@1 90.000 (85.404)\tPrec@5 98.000 (98.070)\n",
            "Test: [180/261]\tTime 0.039 (0.027)\tLoss 0.5538 (0.7353)\tPrec@1 89.000 (85.420)\tPrec@5 96.000 (98.061)\n",
            "Test: [190/261]\tTime 0.025 (0.027)\tLoss 0.6247 (0.7318)\tPrec@1 84.000 (85.435)\tPrec@5 99.000 (98.110)\n",
            "Test: [200/261]\tTime 0.022 (0.026)\tLoss 0.6076 (0.7335)\tPrec@1 88.000 (85.368)\tPrec@5 98.000 (98.114)\n",
            "Test: [210/261]\tTime 0.035 (0.026)\tLoss 0.5507 (0.7353)\tPrec@1 88.000 (85.374)\tPrec@5 98.000 (98.104)\n",
            "Test: [220/261]\tTime 0.014 (0.026)\tLoss 0.6650 (0.7312)\tPrec@1 86.000 (85.380)\tPrec@5 98.000 (98.118)\n",
            "Test: [230/261]\tTime 0.018 (0.026)\tLoss 0.8836 (0.7317)\tPrec@1 83.000 (85.325)\tPrec@5 96.000 (98.095)\n",
            "Test: [240/261]\tTime 0.028 (0.026)\tLoss 0.7362 (0.7353)\tPrec@1 87.000 (85.336)\tPrec@5 98.000 (98.079)\n",
            "Test: [250/261]\tTime 0.032 (0.026)\tLoss 0.4306 (0.7298)\tPrec@1 87.000 (85.375)\tPrec@5 100.000 (98.092)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.2474 (0.7307)\tPrec@1 93.750 (85.372)\tPrec@5 96.875 (98.075)\n",
            "val Results: Prec@1 85.372 Prec@5 98.075 Loss 0.73070\n",
            "val Class Accuracy: [0.719,0.964,0.929,0.868,0.889,0.850,0.782,0.790,0.732,0.673]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [165][0/66], lr: 0.00010\tTime 0.543 (0.543)\tData 0.456 (0.456)\tLoss 0.0157 (0.0157)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][10/66], lr: 0.00010\tTime 0.090 (0.141)\tData 0.005 (0.047)\tLoss 0.0181 (0.0198)\tPrec@1 99.609 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][20/66], lr: 0.00010\tTime 0.095 (0.120)\tData 0.000 (0.028)\tLoss 0.0195 (0.0175)\tPrec@1 99.609 (99.647)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][30/66], lr: 0.00010\tTime 0.083 (0.109)\tData 0.005 (0.020)\tLoss 0.0096 (0.0166)\tPrec@1 100.000 (99.622)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][40/66], lr: 0.00010\tTime 0.099 (0.106)\tData 0.000 (0.017)\tLoss 0.0129 (0.0162)\tPrec@1 99.219 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][50/66], lr: 0.00010\tTime 0.071 (0.104)\tData 0.000 (0.015)\tLoss 0.0118 (0.0148)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [165][60/66], lr: 0.00010\tTime 0.076 (0.101)\tData 0.000 (0.014)\tLoss 0.0319 (0.0156)\tPrec@1 99.219 (99.616)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.287 (0.287)\tLoss 0.6985 (0.6985)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.051 (0.051)\tLoss 1.1825 (0.7705)\tPrec@1 82.000 (83.636)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.031 (0.036)\tLoss 1.1402 (0.7796)\tPrec@1 79.000 (83.714)\tPrec@5 95.000 (97.905)\n",
            "Test: [30/261]\tTime 0.033 (0.033)\tLoss 0.6121 (0.7323)\tPrec@1 85.000 (84.806)\tPrec@5 98.000 (98.161)\n",
            "Test: [40/261]\tTime 0.058 (0.032)\tLoss 0.7458 (0.7037)\tPrec@1 85.000 (85.390)\tPrec@5 98.000 (98.415)\n",
            "Test: [50/261]\tTime 0.041 (0.031)\tLoss 0.4862 (0.6980)\tPrec@1 87.000 (85.471)\tPrec@5 99.000 (98.392)\n",
            "Test: [60/261]\tTime 0.025 (0.028)\tLoss 0.7677 (0.7066)\tPrec@1 84.000 (85.492)\tPrec@5 99.000 (98.262)\n",
            "Test: [70/261]\tTime 0.028 (0.028)\tLoss 0.6079 (0.7100)\tPrec@1 85.000 (85.521)\tPrec@5 98.000 (98.268)\n",
            "Test: [80/261]\tTime 0.033 (0.028)\tLoss 0.6482 (0.7130)\tPrec@1 85.000 (85.605)\tPrec@5 99.000 (98.222)\n",
            "Test: [90/261]\tTime 0.034 (0.028)\tLoss 0.7946 (0.7399)\tPrec@1 88.000 (85.231)\tPrec@5 97.000 (98.143)\n",
            "Test: [100/261]\tTime 0.033 (0.028)\tLoss 0.9067 (0.7317)\tPrec@1 83.000 (85.416)\tPrec@5 97.000 (98.129)\n",
            "Test: [110/261]\tTime 0.043 (0.027)\tLoss 0.8316 (0.7271)\tPrec@1 89.000 (85.477)\tPrec@5 97.000 (98.117)\n",
            "Test: [120/261]\tTime 0.034 (0.027)\tLoss 0.8454 (0.7284)\tPrec@1 87.000 (85.496)\tPrec@5 97.000 (98.116)\n",
            "Test: [130/261]\tTime 0.009 (0.027)\tLoss 0.8387 (0.7330)\tPrec@1 88.000 (85.458)\tPrec@5 97.000 (98.099)\n",
            "Test: [140/261]\tTime 0.021 (0.026)\tLoss 0.9303 (0.7304)\tPrec@1 82.000 (85.475)\tPrec@5 97.000 (98.113)\n",
            "Test: [150/261]\tTime 0.015 (0.026)\tLoss 0.5124 (0.7321)\tPrec@1 88.000 (85.510)\tPrec@5 98.000 (98.119)\n",
            "Test: [160/261]\tTime 0.020 (0.026)\tLoss 0.4056 (0.7351)\tPrec@1 87.000 (85.484)\tPrec@5 100.000 (98.106)\n",
            "Test: [170/261]\tTime 0.031 (0.026)\tLoss 0.5906 (0.7305)\tPrec@1 90.000 (85.579)\tPrec@5 98.000 (98.099)\n",
            "Test: [180/261]\tTime 0.028 (0.026)\tLoss 0.5542 (0.7299)\tPrec@1 89.000 (85.586)\tPrec@5 96.000 (98.094)\n",
            "Test: [190/261]\tTime 0.029 (0.026)\tLoss 0.6075 (0.7264)\tPrec@1 85.000 (85.602)\tPrec@5 99.000 (98.141)\n",
            "Test: [200/261]\tTime 0.010 (0.026)\tLoss 0.6079 (0.7284)\tPrec@1 88.000 (85.542)\tPrec@5 98.000 (98.154)\n",
            "Test: [210/261]\tTime 0.044 (0.026)\tLoss 0.5582 (0.7302)\tPrec@1 89.000 (85.536)\tPrec@5 98.000 (98.142)\n",
            "Test: [220/261]\tTime 0.027 (0.026)\tLoss 0.6629 (0.7260)\tPrec@1 86.000 (85.534)\tPrec@5 98.000 (98.154)\n",
            "Test: [230/261]\tTime 0.019 (0.026)\tLoss 0.8807 (0.7265)\tPrec@1 83.000 (85.463)\tPrec@5 96.000 (98.130)\n",
            "Test: [240/261]\tTime 0.020 (0.026)\tLoss 0.7279 (0.7300)\tPrec@1 87.000 (85.469)\tPrec@5 98.000 (98.116)\n",
            "Test: [250/261]\tTime 0.020 (0.026)\tLoss 0.4056 (0.7243)\tPrec@1 87.000 (85.514)\tPrec@5 100.000 (98.127)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2505 (0.7253)\tPrec@1 93.750 (85.514)\tPrec@5 96.875 (98.114)\n",
            "val Results: Prec@1 85.514 Prec@5 98.114 Loss 0.72530\n",
            "val Class Accuracy: [0.717,0.964,0.933,0.867,0.890,0.854,0.789,0.787,0.733,0.676]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [166][0/66], lr: 0.00010\tTime 0.546 (0.546)\tData 0.462 (0.462)\tLoss 0.0179 (0.0179)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][10/66], lr: 0.00010\tTime 0.081 (0.135)\tData 0.000 (0.048)\tLoss 0.0174 (0.0174)\tPrec@1 99.609 (99.503)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][20/66], lr: 0.00010\tTime 0.087 (0.116)\tData 0.027 (0.032)\tLoss 0.0222 (0.0164)\tPrec@1 98.828 (99.498)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][30/66], lr: 0.00010\tTime 0.096 (0.108)\tData 0.005 (0.023)\tLoss 0.0081 (0.0172)\tPrec@1 100.000 (99.446)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][40/66], lr: 0.00010\tTime 0.077 (0.105)\tData 0.000 (0.021)\tLoss 0.0117 (0.0166)\tPrec@1 99.609 (99.476)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][50/66], lr: 0.00010\tTime 0.102 (0.104)\tData 0.001 (0.018)\tLoss 0.0121 (0.0156)\tPrec@1 99.609 (99.525)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [166][60/66], lr: 0.00010\tTime 0.079 (0.101)\tData 0.000 (0.016)\tLoss 0.0071 (0.0153)\tPrec@1 100.000 (99.552)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.279 (0.279)\tLoss 0.7066 (0.7066)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.017 (0.052)\tLoss 1.1698 (0.7596)\tPrec@1 83.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.015 (0.037)\tLoss 1.1260 (0.7666)\tPrec@1 79.000 (84.048)\tPrec@5 96.000 (98.000)\n",
            "Test: [30/261]\tTime 0.017 (0.033)\tLoss 0.6081 (0.7204)\tPrec@1 86.000 (85.032)\tPrec@5 98.000 (98.226)\n",
            "Test: [40/261]\tTime 0.017 (0.031)\tLoss 0.7237 (0.6907)\tPrec@1 87.000 (85.707)\tPrec@5 97.000 (98.439)\n",
            "Test: [50/261]\tTime 0.026 (0.030)\tLoss 0.4739 (0.6855)\tPrec@1 86.000 (85.745)\tPrec@5 99.000 (98.412)\n",
            "Test: [60/261]\tTime 0.020 (0.029)\tLoss 0.7372 (0.6939)\tPrec@1 86.000 (85.787)\tPrec@5 99.000 (98.279)\n",
            "Test: [70/261]\tTime 0.031 (0.028)\tLoss 0.5847 (0.6972)\tPrec@1 85.000 (85.817)\tPrec@5 98.000 (98.282)\n",
            "Test: [80/261]\tTime 0.019 (0.028)\tLoss 0.6361 (0.7001)\tPrec@1 85.000 (85.889)\tPrec@5 99.000 (98.222)\n",
            "Test: [90/261]\tTime 0.009 (0.027)\tLoss 0.7755 (0.7271)\tPrec@1 88.000 (85.495)\tPrec@5 97.000 (98.154)\n",
            "Test: [100/261]\tTime 0.021 (0.027)\tLoss 0.8973 (0.7189)\tPrec@1 84.000 (85.693)\tPrec@5 97.000 (98.139)\n",
            "Test: [110/261]\tTime 0.021 (0.027)\tLoss 0.8193 (0.7141)\tPrec@1 88.000 (85.721)\tPrec@5 98.000 (98.135)\n",
            "Test: [120/261]\tTime 0.022 (0.027)\tLoss 0.8391 (0.7156)\tPrec@1 87.000 (85.744)\tPrec@5 97.000 (98.132)\n",
            "Test: [130/261]\tTime 0.024 (0.026)\tLoss 0.8283 (0.7206)\tPrec@1 88.000 (85.702)\tPrec@5 97.000 (98.115)\n",
            "Test: [140/261]\tTime 0.010 (0.026)\tLoss 0.9227 (0.7181)\tPrec@1 82.000 (85.702)\tPrec@5 98.000 (98.128)\n",
            "Test: [150/261]\tTime 0.009 (0.026)\tLoss 0.4927 (0.7197)\tPrec@1 89.000 (85.735)\tPrec@5 98.000 (98.126)\n",
            "Test: [160/261]\tTime 0.022 (0.026)\tLoss 0.3917 (0.7226)\tPrec@1 87.000 (85.720)\tPrec@5 100.000 (98.112)\n",
            "Test: [170/261]\tTime 0.035 (0.026)\tLoss 0.5786 (0.7181)\tPrec@1 90.000 (85.801)\tPrec@5 98.000 (98.117)\n",
            "Test: [180/261]\tTime 0.032 (0.026)\tLoss 0.5514 (0.7175)\tPrec@1 89.000 (85.818)\tPrec@5 96.000 (98.110)\n",
            "Test: [190/261]\tTime 0.023 (0.026)\tLoss 0.5962 (0.7143)\tPrec@1 86.000 (85.859)\tPrec@5 100.000 (98.162)\n",
            "Test: [200/261]\tTime 0.031 (0.026)\tLoss 0.5855 (0.7163)\tPrec@1 88.000 (85.791)\tPrec@5 98.000 (98.169)\n",
            "Test: [210/261]\tTime 0.019 (0.025)\tLoss 0.5421 (0.7181)\tPrec@1 89.000 (85.768)\tPrec@5 98.000 (98.161)\n",
            "Test: [220/261]\tTime 0.017 (0.025)\tLoss 0.6487 (0.7138)\tPrec@1 86.000 (85.778)\tPrec@5 98.000 (98.172)\n",
            "Test: [230/261]\tTime 0.028 (0.025)\tLoss 0.8706 (0.7143)\tPrec@1 83.000 (85.719)\tPrec@5 96.000 (98.152)\n",
            "Test: [240/261]\tTime 0.015 (0.025)\tLoss 0.7187 (0.7180)\tPrec@1 87.000 (85.730)\tPrec@5 98.000 (98.133)\n",
            "Test: [250/261]\tTime 0.009 (0.025)\tLoss 0.3901 (0.7121)\tPrec@1 89.000 (85.781)\tPrec@5 100.000 (98.139)\n",
            "Test: [260/261]\tTime 0.008 (0.025)\tLoss 0.2456 (0.7131)\tPrec@1 93.750 (85.779)\tPrec@5 96.875 (98.129)\n",
            "val Results: Prec@1 85.779 Prec@5 98.129 Loss 0.71312\n",
            "val Class Accuracy: [0.729,0.965,0.930,0.870,0.889,0.863,0.790,0.800,0.734,0.677]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [167][0/66], lr: 0.00010\tTime 0.611 (0.611)\tData 0.527 (0.527)\tLoss 0.0135 (0.0135)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][10/66], lr: 0.00010\tTime 0.105 (0.149)\tData 0.000 (0.054)\tLoss 0.0105 (0.0168)\tPrec@1 99.609 (99.467)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][20/66], lr: 0.00010\tTime 0.071 (0.121)\tData 0.005 (0.030)\tLoss 0.0057 (0.0147)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][30/66], lr: 0.00010\tTime 0.106 (0.114)\tData 0.000 (0.022)\tLoss 0.0077 (0.0138)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][40/66], lr: 0.00010\tTime 0.100 (0.109)\tData 0.004 (0.018)\tLoss 0.0158 (0.0131)\tPrec@1 99.609 (99.619)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][50/66], lr: 0.00010\tTime 0.099 (0.106)\tData 0.002 (0.015)\tLoss 0.0099 (0.0134)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [167][60/66], lr: 0.00010\tTime 0.078 (0.104)\tData 0.000 (0.013)\tLoss 0.0166 (0.0138)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.291 (0.291)\tLoss 0.7231 (0.7231)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.025 (0.050)\tLoss 1.1917 (0.7850)\tPrec@1 81.000 (83.182)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.029 (0.039)\tLoss 1.1396 (0.7931)\tPrec@1 78.000 (83.381)\tPrec@5 95.000 (97.952)\n",
            "Test: [30/261]\tTime 0.027 (0.034)\tLoss 0.6321 (0.7484)\tPrec@1 86.000 (84.452)\tPrec@5 98.000 (98.194)\n",
            "Test: [40/261]\tTime 0.037 (0.032)\tLoss 0.7440 (0.7182)\tPrec@1 87.000 (85.073)\tPrec@5 97.000 (98.415)\n",
            "Test: [50/261]\tTime 0.023 (0.031)\tLoss 0.4967 (0.7120)\tPrec@1 87.000 (85.294)\tPrec@5 99.000 (98.431)\n",
            "Test: [60/261]\tTime 0.023 (0.030)\tLoss 0.7704 (0.7189)\tPrec@1 84.000 (85.311)\tPrec@5 99.000 (98.295)\n",
            "Test: [70/261]\tTime 0.025 (0.029)\tLoss 0.6265 (0.7214)\tPrec@1 84.000 (85.366)\tPrec@5 98.000 (98.282)\n",
            "Test: [80/261]\tTime 0.014 (0.028)\tLoss 0.6655 (0.7236)\tPrec@1 85.000 (85.444)\tPrec@5 99.000 (98.247)\n",
            "Test: [90/261]\tTime 0.030 (0.028)\tLoss 0.7909 (0.7507)\tPrec@1 85.000 (85.022)\tPrec@5 97.000 (98.165)\n",
            "Test: [100/261]\tTime 0.024 (0.028)\tLoss 0.9031 (0.7423)\tPrec@1 82.000 (85.178)\tPrec@5 97.000 (98.139)\n",
            "Test: [110/261]\tTime 0.018 (0.027)\tLoss 0.8328 (0.7369)\tPrec@1 89.000 (85.252)\tPrec@5 97.000 (98.126)\n",
            "Test: [120/261]\tTime 0.031 (0.027)\tLoss 0.8394 (0.7381)\tPrec@1 87.000 (85.289)\tPrec@5 97.000 (98.116)\n",
            "Test: [130/261]\tTime 0.014 (0.026)\tLoss 0.8443 (0.7424)\tPrec@1 88.000 (85.275)\tPrec@5 97.000 (98.099)\n",
            "Test: [140/261]\tTime 0.029 (0.027)\tLoss 0.9484 (0.7398)\tPrec@1 82.000 (85.284)\tPrec@5 98.000 (98.113)\n",
            "Test: [150/261]\tTime 0.014 (0.027)\tLoss 0.5010 (0.7415)\tPrec@1 88.000 (85.305)\tPrec@5 98.000 (98.099)\n",
            "Test: [160/261]\tTime 0.038 (0.027)\tLoss 0.4051 (0.7443)\tPrec@1 87.000 (85.273)\tPrec@5 100.000 (98.081)\n",
            "Test: [170/261]\tTime 0.030 (0.027)\tLoss 0.6080 (0.7396)\tPrec@1 91.000 (85.345)\tPrec@5 98.000 (98.088)\n",
            "Test: [180/261]\tTime 0.019 (0.026)\tLoss 0.5561 (0.7389)\tPrec@1 89.000 (85.348)\tPrec@5 96.000 (98.077)\n",
            "Test: [190/261]\tTime 0.027 (0.026)\tLoss 0.6042 (0.7355)\tPrec@1 84.000 (85.356)\tPrec@5 100.000 (98.126)\n",
            "Test: [200/261]\tTime 0.028 (0.026)\tLoss 0.5965 (0.7374)\tPrec@1 88.000 (85.303)\tPrec@5 98.000 (98.124)\n",
            "Test: [210/261]\tTime 0.025 (0.026)\tLoss 0.5574 (0.7388)\tPrec@1 89.000 (85.294)\tPrec@5 99.000 (98.123)\n",
            "Test: [220/261]\tTime 0.009 (0.026)\tLoss 0.6658 (0.7345)\tPrec@1 86.000 (85.299)\tPrec@5 98.000 (98.136)\n",
            "Test: [230/261]\tTime 0.023 (0.026)\tLoss 0.8977 (0.7350)\tPrec@1 83.000 (85.234)\tPrec@5 96.000 (98.113)\n",
            "Test: [240/261]\tTime 0.037 (0.026)\tLoss 0.7487 (0.7386)\tPrec@1 86.000 (85.249)\tPrec@5 98.000 (98.095)\n",
            "Test: [250/261]\tTime 0.031 (0.026)\tLoss 0.4125 (0.7327)\tPrec@1 87.000 (85.307)\tPrec@5 100.000 (98.108)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2455 (0.7341)\tPrec@1 93.750 (85.299)\tPrec@5 96.875 (98.087)\n",
            "val Results: Prec@1 85.299 Prec@5 98.087 Loss 0.73413\n",
            "val Class Accuracy: [0.687,0.963,0.933,0.874,0.896,0.859,0.785,0.790,0.728,0.653]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [168][0/66], lr: 0.00010\tTime 0.590 (0.590)\tData 0.501 (0.501)\tLoss 0.0101 (0.0101)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][10/66], lr: 0.00010\tTime 0.094 (0.142)\tData 0.000 (0.050)\tLoss 0.0086 (0.0171)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][20/66], lr: 0.00010\tTime 0.082 (0.119)\tData 0.007 (0.029)\tLoss 0.0058 (0.0142)\tPrec@1 100.000 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][30/66], lr: 0.00010\tTime 0.089 (0.110)\tData 0.007 (0.022)\tLoss 0.0138 (0.0140)\tPrec@1 99.219 (99.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][40/66], lr: 0.00010\tTime 0.105 (0.106)\tData 0.004 (0.019)\tLoss 0.0111 (0.0136)\tPrec@1 99.609 (99.686)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][50/66], lr: 0.00010\tTime 0.095 (0.104)\tData 0.004 (0.016)\tLoss 0.0115 (0.0138)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [168][60/66], lr: 0.00010\tTime 0.077 (0.101)\tData 0.000 (0.015)\tLoss 0.0076 (0.0137)\tPrec@1 100.000 (99.641)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.277 (0.277)\tLoss 0.7492 (0.7492)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.018 (0.047)\tLoss 1.2031 (0.7839)\tPrec@1 81.000 (83.273)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.027 (0.038)\tLoss 1.1653 (0.7933)\tPrec@1 78.000 (83.381)\tPrec@5 95.000 (97.810)\n",
            "Test: [30/261]\tTime 0.014 (0.032)\tLoss 0.6312 (0.7484)\tPrec@1 87.000 (84.484)\tPrec@5 98.000 (98.097)\n",
            "Test: [40/261]\tTime 0.026 (0.031)\tLoss 0.7414 (0.7180)\tPrec@1 87.000 (85.195)\tPrec@5 97.000 (98.317)\n",
            "Test: [50/261]\tTime 0.035 (0.030)\tLoss 0.5098 (0.7129)\tPrec@1 86.000 (85.294)\tPrec@5 99.000 (98.333)\n",
            "Test: [60/261]\tTime 0.039 (0.029)\tLoss 0.7698 (0.7193)\tPrec@1 85.000 (85.344)\tPrec@5 99.000 (98.213)\n",
            "Test: [70/261]\tTime 0.026 (0.028)\tLoss 0.6140 (0.7223)\tPrec@1 84.000 (85.394)\tPrec@5 98.000 (98.211)\n",
            "Test: [80/261]\tTime 0.010 (0.028)\tLoss 0.6677 (0.7251)\tPrec@1 85.000 (85.494)\tPrec@5 98.000 (98.185)\n",
            "Test: [90/261]\tTime 0.024 (0.028)\tLoss 0.7811 (0.7521)\tPrec@1 87.000 (85.088)\tPrec@5 97.000 (98.099)\n",
            "Test: [100/261]\tTime 0.024 (0.027)\tLoss 0.9137 (0.7441)\tPrec@1 82.000 (85.287)\tPrec@5 97.000 (98.079)\n",
            "Test: [110/261]\tTime 0.024 (0.027)\tLoss 0.8343 (0.7381)\tPrec@1 88.000 (85.369)\tPrec@5 97.000 (98.072)\n",
            "Test: [120/261]\tTime 0.010 (0.027)\tLoss 0.8421 (0.7395)\tPrec@1 87.000 (85.388)\tPrec@5 97.000 (98.058)\n",
            "Test: [130/261]\tTime 0.015 (0.027)\tLoss 0.8480 (0.7441)\tPrec@1 87.000 (85.366)\tPrec@5 97.000 (98.046)\n",
            "Test: [140/261]\tTime 0.039 (0.026)\tLoss 0.9606 (0.7415)\tPrec@1 83.000 (85.376)\tPrec@5 98.000 (98.064)\n",
            "Test: [150/261]\tTime 0.024 (0.026)\tLoss 0.4940 (0.7432)\tPrec@1 89.000 (85.404)\tPrec@5 98.000 (98.060)\n",
            "Test: [160/261]\tTime 0.023 (0.026)\tLoss 0.4136 (0.7462)\tPrec@1 87.000 (85.373)\tPrec@5 100.000 (98.050)\n",
            "Test: [170/261]\tTime 0.015 (0.026)\tLoss 0.6174 (0.7415)\tPrec@1 91.000 (85.456)\tPrec@5 98.000 (98.064)\n",
            "Test: [180/261]\tTime 0.017 (0.026)\tLoss 0.5585 (0.7406)\tPrec@1 89.000 (85.453)\tPrec@5 96.000 (98.055)\n",
            "Test: [190/261]\tTime 0.022 (0.026)\tLoss 0.5916 (0.7369)\tPrec@1 84.000 (85.461)\tPrec@5 99.000 (98.110)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 0.6027 (0.7389)\tPrec@1 87.000 (85.403)\tPrec@5 98.000 (98.109)\n",
            "Test: [210/261]\tTime 0.020 (0.026)\tLoss 0.5517 (0.7403)\tPrec@1 89.000 (85.403)\tPrec@5 99.000 (98.104)\n",
            "Test: [220/261]\tTime 0.018 (0.026)\tLoss 0.6638 (0.7360)\tPrec@1 87.000 (85.416)\tPrec@5 97.000 (98.113)\n",
            "Test: [230/261]\tTime 0.015 (0.026)\tLoss 0.8866 (0.7364)\tPrec@1 83.000 (85.359)\tPrec@5 95.000 (98.087)\n",
            "Test: [240/261]\tTime 0.017 (0.026)\tLoss 0.7445 (0.7403)\tPrec@1 86.000 (85.369)\tPrec@5 98.000 (98.071)\n",
            "Test: [250/261]\tTime 0.015 (0.026)\tLoss 0.4189 (0.7345)\tPrec@1 87.000 (85.438)\tPrec@5 100.000 (98.084)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2384 (0.7357)\tPrec@1 93.750 (85.426)\tPrec@5 96.875 (98.068)\n",
            "val Results: Prec@1 85.426 Prec@5 98.068 Loss 0.73570\n",
            "val Class Accuracy: [0.693,0.965,0.930,0.873,0.898,0.863,0.768,0.793,0.742,0.666]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [169][0/66], lr: 0.00010\tTime 0.581 (0.581)\tData 0.507 (0.507)\tLoss 0.0139 (0.0139)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][10/66], lr: 0.00010\tTime 0.121 (0.145)\tData 0.005 (0.054)\tLoss 0.0099 (0.0166)\tPrec@1 100.000 (99.432)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][20/66], lr: 0.00010\tTime 0.076 (0.121)\tData 0.000 (0.030)\tLoss 0.0108 (0.0144)\tPrec@1 100.000 (99.591)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][30/66], lr: 0.00010\tTime 0.093 (0.113)\tData 0.000 (0.022)\tLoss 0.0255 (0.0166)\tPrec@1 99.219 (99.509)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][40/66], lr: 0.00010\tTime 0.070 (0.109)\tData 0.000 (0.019)\tLoss 0.0250 (0.0152)\tPrec@1 99.219 (99.571)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][50/66], lr: 0.00010\tTime 0.103 (0.105)\tData 0.006 (0.016)\tLoss 0.0161 (0.0153)\tPrec@1 99.609 (99.571)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [169][60/66], lr: 0.00010\tTime 0.069 (0.103)\tData 0.000 (0.014)\tLoss 0.0126 (0.0152)\tPrec@1 99.609 (99.571)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.298 (0.298)\tLoss 0.7379 (0.7379)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.052)\tLoss 1.1973 (0.7812)\tPrec@1 82.000 (83.455)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.024 (0.035)\tLoss 1.1525 (0.7875)\tPrec@1 78.000 (83.619)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.036 (0.033)\tLoss 0.6266 (0.7429)\tPrec@1 87.000 (84.774)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.024 (0.030)\tLoss 0.7470 (0.7124)\tPrec@1 87.000 (85.317)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.019 (0.029)\tLoss 0.4967 (0.7068)\tPrec@1 86.000 (85.451)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.044 (0.029)\tLoss 0.7563 (0.7138)\tPrec@1 85.000 (85.459)\tPrec@5 99.000 (98.361)\n",
            "Test: [70/261]\tTime 0.033 (0.028)\tLoss 0.6097 (0.7162)\tPrec@1 84.000 (85.507)\tPrec@5 99.000 (98.352)\n",
            "Test: [80/261]\tTime 0.014 (0.028)\tLoss 0.6554 (0.7187)\tPrec@1 85.000 (85.617)\tPrec@5 98.000 (98.296)\n",
            "Test: [90/261]\tTime 0.020 (0.028)\tLoss 0.7857 (0.7459)\tPrec@1 87.000 (85.220)\tPrec@5 97.000 (98.198)\n",
            "Test: [100/261]\tTime 0.019 (0.027)\tLoss 0.8992 (0.7377)\tPrec@1 84.000 (85.416)\tPrec@5 97.000 (98.158)\n",
            "Test: [110/261]\tTime 0.009 (0.027)\tLoss 0.8286 (0.7323)\tPrec@1 89.000 (85.450)\tPrec@5 97.000 (98.144)\n",
            "Test: [120/261]\tTime 0.033 (0.027)\tLoss 0.8413 (0.7340)\tPrec@1 87.000 (85.471)\tPrec@5 97.000 (98.132)\n",
            "Test: [130/261]\tTime 0.018 (0.026)\tLoss 0.8388 (0.7386)\tPrec@1 87.000 (85.443)\tPrec@5 97.000 (98.115)\n",
            "Test: [140/261]\tTime 0.012 (0.026)\tLoss 0.9453 (0.7361)\tPrec@1 82.000 (85.426)\tPrec@5 98.000 (98.121)\n",
            "Test: [150/261]\tTime 0.025 (0.026)\tLoss 0.4816 (0.7375)\tPrec@1 89.000 (85.464)\tPrec@5 98.000 (98.113)\n",
            "Test: [160/261]\tTime 0.029 (0.026)\tLoss 0.3957 (0.7405)\tPrec@1 87.000 (85.435)\tPrec@5 100.000 (98.099)\n",
            "Test: [170/261]\tTime 0.039 (0.026)\tLoss 0.6018 (0.7359)\tPrec@1 91.000 (85.491)\tPrec@5 98.000 (98.117)\n",
            "Test: [180/261]\tTime 0.015 (0.026)\tLoss 0.5594 (0.7350)\tPrec@1 89.000 (85.497)\tPrec@5 96.000 (98.105)\n",
            "Test: [190/261]\tTime 0.013 (0.026)\tLoss 0.5912 (0.7314)\tPrec@1 84.000 (85.518)\tPrec@5 100.000 (98.162)\n",
            "Test: [200/261]\tTime 0.021 (0.026)\tLoss 0.6093 (0.7334)\tPrec@1 88.000 (85.468)\tPrec@5 98.000 (98.164)\n",
            "Test: [210/261]\tTime 0.030 (0.026)\tLoss 0.5527 (0.7349)\tPrec@1 89.000 (85.464)\tPrec@5 99.000 (98.156)\n",
            "Test: [220/261]\tTime 0.041 (0.026)\tLoss 0.6599 (0.7306)\tPrec@1 86.000 (85.475)\tPrec@5 98.000 (98.167)\n",
            "Test: [230/261]\tTime 0.010 (0.025)\tLoss 0.8972 (0.7311)\tPrec@1 83.000 (85.424)\tPrec@5 96.000 (98.139)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.7424 (0.7348)\tPrec@1 86.000 (85.440)\tPrec@5 98.000 (98.124)\n",
            "Test: [250/261]\tTime 0.014 (0.025)\tLoss 0.4017 (0.7287)\tPrec@1 87.000 (85.498)\tPrec@5 100.000 (98.135)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2360 (0.7302)\tPrec@1 93.750 (85.483)\tPrec@5 96.875 (98.122)\n",
            "val Results: Prec@1 85.483 Prec@5 98.122 Loss 0.73020\n",
            "val Class Accuracy: [0.705,0.965,0.936,0.873,0.893,0.858,0.776,0.790,0.742,0.651]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [170][0/66], lr: 0.00010\tTime 0.503 (0.503)\tData 0.425 (0.425)\tLoss 0.0030 (0.0030)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][10/66], lr: 0.00010\tTime 0.101 (0.136)\tData 0.005 (0.047)\tLoss 0.0143 (0.0129)\tPrec@1 99.609 (99.574)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][20/66], lr: 0.00010\tTime 0.107 (0.118)\tData 0.000 (0.026)\tLoss 0.0071 (0.0123)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][30/66], lr: 0.00010\tTime 0.081 (0.110)\tData 0.000 (0.020)\tLoss 0.0207 (0.0129)\tPrec@1 98.828 (99.572)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][40/66], lr: 0.00010\tTime 0.092 (0.106)\tData 0.005 (0.017)\tLoss 0.0103 (0.0125)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][50/66], lr: 0.00010\tTime 0.105 (0.104)\tData 0.005 (0.015)\tLoss 0.0155 (0.0124)\tPrec@1 99.219 (99.640)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [170][60/66], lr: 0.00010\tTime 0.078 (0.100)\tData 0.000 (0.014)\tLoss 0.0107 (0.0124)\tPrec@1 99.219 (99.635)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.260 (0.260)\tLoss 0.7235 (0.7235)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.009 (0.050)\tLoss 1.1981 (0.7765)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.024 (0.037)\tLoss 1.1784 (0.7867)\tPrec@1 78.000 (83.667)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.021 (0.032)\tLoss 0.6051 (0.7409)\tPrec@1 86.000 (84.774)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/261]\tTime 0.018 (0.031)\tLoss 0.7515 (0.7118)\tPrec@1 86.000 (85.293)\tPrec@5 97.000 (98.439)\n",
            "Test: [50/261]\tTime 0.036 (0.030)\tLoss 0.5096 (0.7067)\tPrec@1 87.000 (85.412)\tPrec@5 99.000 (98.431)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.7651 (0.7130)\tPrec@1 87.000 (85.525)\tPrec@5 99.000 (98.295)\n",
            "Test: [70/261]\tTime 0.038 (0.028)\tLoss 0.6031 (0.7164)\tPrec@1 85.000 (85.521)\tPrec@5 99.000 (98.296)\n",
            "Test: [80/261]\tTime 0.044 (0.028)\tLoss 0.6603 (0.7207)\tPrec@1 85.000 (85.580)\tPrec@5 99.000 (98.222)\n",
            "Test: [90/261]\tTime 0.039 (0.027)\tLoss 0.7912 (0.7479)\tPrec@1 88.000 (85.209)\tPrec@5 97.000 (98.132)\n",
            "Test: [100/261]\tTime 0.010 (0.027)\tLoss 0.9247 (0.7406)\tPrec@1 83.000 (85.406)\tPrec@5 97.000 (98.109)\n",
            "Test: [110/261]\tTime 0.022 (0.027)\tLoss 0.8283 (0.7347)\tPrec@1 89.000 (85.459)\tPrec@5 98.000 (98.108)\n",
            "Test: [120/261]\tTime 0.041 (0.027)\tLoss 0.8488 (0.7366)\tPrec@1 87.000 (85.479)\tPrec@5 97.000 (98.099)\n",
            "Test: [130/261]\tTime 0.035 (0.026)\tLoss 0.8444 (0.7411)\tPrec@1 87.000 (85.427)\tPrec@5 97.000 (98.084)\n",
            "Test: [140/261]\tTime 0.025 (0.026)\tLoss 0.9475 (0.7384)\tPrec@1 84.000 (85.447)\tPrec@5 98.000 (98.099)\n",
            "Test: [150/261]\tTime 0.029 (0.026)\tLoss 0.4975 (0.7401)\tPrec@1 89.000 (85.464)\tPrec@5 98.000 (98.086)\n",
            "Test: [160/261]\tTime 0.021 (0.026)\tLoss 0.4067 (0.7428)\tPrec@1 87.000 (85.435)\tPrec@5 100.000 (98.087)\n",
            "Test: [170/261]\tTime 0.033 (0.026)\tLoss 0.6251 (0.7382)\tPrec@1 90.000 (85.509)\tPrec@5 98.000 (98.094)\n",
            "Test: [180/261]\tTime 0.026 (0.026)\tLoss 0.5622 (0.7374)\tPrec@1 89.000 (85.519)\tPrec@5 96.000 (98.077)\n",
            "Test: [190/261]\tTime 0.019 (0.026)\tLoss 0.5766 (0.7338)\tPrec@1 84.000 (85.550)\tPrec@5 100.000 (98.136)\n",
            "Test: [200/261]\tTime 0.036 (0.026)\tLoss 0.6179 (0.7356)\tPrec@1 87.000 (85.488)\tPrec@5 98.000 (98.139)\n",
            "Test: [210/261]\tTime 0.021 (0.026)\tLoss 0.5483 (0.7372)\tPrec@1 89.000 (85.479)\tPrec@5 99.000 (98.128)\n",
            "Test: [220/261]\tTime 0.031 (0.026)\tLoss 0.6588 (0.7330)\tPrec@1 86.000 (85.498)\tPrec@5 98.000 (98.140)\n",
            "Test: [230/261]\tTime 0.019 (0.026)\tLoss 0.8891 (0.7335)\tPrec@1 83.000 (85.468)\tPrec@5 96.000 (98.121)\n",
            "Test: [240/261]\tTime 0.030 (0.026)\tLoss 0.7344 (0.7373)\tPrec@1 86.000 (85.465)\tPrec@5 98.000 (98.108)\n",
            "Test: [250/261]\tTime 0.014 (0.026)\tLoss 0.4291 (0.7315)\tPrec@1 87.000 (85.534)\tPrec@5 100.000 (98.120)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2460 (0.7328)\tPrec@1 93.750 (85.541)\tPrec@5 96.875 (98.102)\n",
            "val Results: Prec@1 85.541 Prec@5 98.102 Loss 0.73279\n",
            "val Class Accuracy: [0.708,0.968,0.933,0.861,0.897,0.867,0.774,0.786,0.746,0.663]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [171][0/66], lr: 0.00010\tTime 0.542 (0.542)\tData 0.458 (0.458)\tLoss 0.0130 (0.0130)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][10/66], lr: 0.00010\tTime 0.088 (0.128)\tData 0.001 (0.051)\tLoss 0.0066 (0.0135)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][20/66], lr: 0.00010\tTime 0.099 (0.114)\tData 0.000 (0.028)\tLoss 0.0103 (0.0124)\tPrec@1 99.609 (99.702)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][30/66], lr: 0.00010\tTime 0.097 (0.108)\tData 0.003 (0.021)\tLoss 0.0339 (0.0127)\tPrec@1 99.609 (99.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][40/66], lr: 0.00010\tTime 0.095 (0.104)\tData 0.000 (0.017)\tLoss 0.0191 (0.0129)\tPrec@1 99.609 (99.676)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][50/66], lr: 0.00010\tTime 0.100 (0.103)\tData 0.003 (0.015)\tLoss 0.0124 (0.0124)\tPrec@1 100.000 (99.694)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [171][60/66], lr: 0.00010\tTime 0.063 (0.099)\tData 0.000 (0.013)\tLoss 0.0087 (0.0118)\tPrec@1 99.609 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.273 (0.273)\tLoss 0.7116 (0.7116)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.026 (0.050)\tLoss 1.1908 (0.7792)\tPrec@1 82.000 (83.818)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.025 (0.038)\tLoss 1.1449 (0.7856)\tPrec@1 79.000 (83.810)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.024 (0.034)\tLoss 0.6164 (0.7411)\tPrec@1 86.000 (84.839)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.010 (0.032)\tLoss 0.7428 (0.7119)\tPrec@1 86.000 (85.293)\tPrec@5 98.000 (98.488)\n",
            "Test: [50/261]\tTime 0.051 (0.030)\tLoss 0.4892 (0.7057)\tPrec@1 87.000 (85.431)\tPrec@5 99.000 (98.471)\n",
            "Test: [60/261]\tTime 0.021 (0.029)\tLoss 0.7400 (0.7116)\tPrec@1 87.000 (85.557)\tPrec@5 99.000 (98.328)\n",
            "Test: [70/261]\tTime 0.025 (0.028)\tLoss 0.6003 (0.7141)\tPrec@1 84.000 (85.563)\tPrec@5 99.000 (98.310)\n",
            "Test: [80/261]\tTime 0.018 (0.028)\tLoss 0.6509 (0.7168)\tPrec@1 84.000 (85.654)\tPrec@5 99.000 (98.272)\n",
            "Test: [90/261]\tTime 0.022 (0.028)\tLoss 0.7753 (0.7438)\tPrec@1 88.000 (85.286)\tPrec@5 97.000 (98.187)\n",
            "Test: [100/261]\tTime 0.025 (0.027)\tLoss 0.9051 (0.7360)\tPrec@1 83.000 (85.495)\tPrec@5 97.000 (98.158)\n",
            "Test: [110/261]\tTime 0.030 (0.027)\tLoss 0.8289 (0.7307)\tPrec@1 89.000 (85.541)\tPrec@5 98.000 (98.153)\n",
            "Test: [120/261]\tTime 0.027 (0.027)\tLoss 0.8244 (0.7322)\tPrec@1 86.000 (85.554)\tPrec@5 97.000 (98.149)\n",
            "Test: [130/261]\tTime 0.036 (0.027)\tLoss 0.8399 (0.7364)\tPrec@1 87.000 (85.511)\tPrec@5 97.000 (98.130)\n",
            "Test: [140/261]\tTime 0.029 (0.027)\tLoss 0.9333 (0.7339)\tPrec@1 82.000 (85.511)\tPrec@5 98.000 (98.142)\n",
            "Test: [150/261]\tTime 0.033 (0.027)\tLoss 0.4924 (0.7355)\tPrec@1 89.000 (85.530)\tPrec@5 98.000 (98.126)\n",
            "Test: [160/261]\tTime 0.015 (0.026)\tLoss 0.3939 (0.7381)\tPrec@1 88.000 (85.509)\tPrec@5 100.000 (98.124)\n",
            "Test: [170/261]\tTime 0.021 (0.026)\tLoss 0.6295 (0.7337)\tPrec@1 90.000 (85.585)\tPrec@5 98.000 (98.129)\n",
            "Test: [180/261]\tTime 0.026 (0.026)\tLoss 0.5603 (0.7328)\tPrec@1 89.000 (85.591)\tPrec@5 96.000 (98.116)\n",
            "Test: [190/261]\tTime 0.030 (0.026)\tLoss 0.5779 (0.7294)\tPrec@1 84.000 (85.607)\tPrec@5 100.000 (98.173)\n",
            "Test: [200/261]\tTime 0.029 (0.026)\tLoss 0.6019 (0.7311)\tPrec@1 88.000 (85.562)\tPrec@5 98.000 (98.174)\n",
            "Test: [210/261]\tTime 0.026 (0.026)\tLoss 0.5712 (0.7327)\tPrec@1 89.000 (85.550)\tPrec@5 99.000 (98.161)\n",
            "Test: [220/261]\tTime 0.017 (0.026)\tLoss 0.6442 (0.7281)\tPrec@1 87.000 (85.575)\tPrec@5 98.000 (98.172)\n",
            "Test: [230/261]\tTime 0.024 (0.026)\tLoss 0.9011 (0.7286)\tPrec@1 83.000 (85.515)\tPrec@5 96.000 (98.156)\n",
            "Test: [240/261]\tTime 0.027 (0.026)\tLoss 0.7513 (0.7324)\tPrec@1 86.000 (85.535)\tPrec@5 98.000 (98.137)\n",
            "Test: [250/261]\tTime 0.024 (0.026)\tLoss 0.4105 (0.7263)\tPrec@1 87.000 (85.602)\tPrec@5 100.000 (98.147)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2464 (0.7279)\tPrec@1 93.750 (85.591)\tPrec@5 96.875 (98.129)\n",
            "val Results: Prec@1 85.591 Prec@5 98.129 Loss 0.72790\n",
            "val Class Accuracy: [0.691,0.965,0.938,0.868,0.903,0.855,0.785,0.801,0.737,0.660]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [172][0/66], lr: 0.00010\tTime 0.538 (0.538)\tData 0.472 (0.472)\tLoss 0.0179 (0.0179)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][10/66], lr: 0.00010\tTime 0.099 (0.140)\tData 0.004 (0.049)\tLoss 0.0219 (0.0158)\tPrec@1 98.828 (99.467)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][20/66], lr: 0.00010\tTime 0.098 (0.118)\tData 0.000 (0.027)\tLoss 0.0176 (0.0140)\tPrec@1 99.609 (99.628)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][30/66], lr: 0.00010\tTime 0.094 (0.110)\tData 0.000 (0.020)\tLoss 0.0053 (0.0127)\tPrec@1 100.000 (99.685)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][40/66], lr: 0.00010\tTime 0.078 (0.105)\tData 0.000 (0.016)\tLoss 0.0105 (0.0120)\tPrec@1 100.000 (99.733)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][50/66], lr: 0.00010\tTime 0.091 (0.103)\tData 0.000 (0.015)\tLoss 0.0091 (0.0121)\tPrec@1 99.609 (99.724)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [172][60/66], lr: 0.00010\tTime 0.082 (0.100)\tData 0.000 (0.015)\tLoss 0.0094 (0.0118)\tPrec@1 100.000 (99.737)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.309 (0.309)\tLoss 0.7339 (0.7339)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.052)\tLoss 1.2030 (0.7813)\tPrec@1 82.000 (83.636)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.010 (0.039)\tLoss 1.1481 (0.7882)\tPrec@1 78.000 (83.810)\tPrec@5 96.000 (98.000)\n",
            "Test: [30/261]\tTime 0.024 (0.034)\tLoss 0.6325 (0.7442)\tPrec@1 87.000 (84.935)\tPrec@5 98.000 (98.226)\n",
            "Test: [40/261]\tTime 0.052 (0.033)\tLoss 0.7469 (0.7148)\tPrec@1 87.000 (85.366)\tPrec@5 98.000 (98.439)\n",
            "Test: [50/261]\tTime 0.032 (0.031)\tLoss 0.4959 (0.7094)\tPrec@1 87.000 (85.510)\tPrec@5 99.000 (98.431)\n",
            "Test: [60/261]\tTime 0.026 (0.030)\tLoss 0.7431 (0.7148)\tPrec@1 87.000 (85.574)\tPrec@5 99.000 (98.295)\n",
            "Test: [70/261]\tTime 0.028 (0.029)\tLoss 0.6006 (0.7170)\tPrec@1 84.000 (85.606)\tPrec@5 99.000 (98.282)\n",
            "Test: [80/261]\tTime 0.015 (0.029)\tLoss 0.6486 (0.7195)\tPrec@1 84.000 (85.691)\tPrec@5 99.000 (98.247)\n",
            "Test: [90/261]\tTime 0.033 (0.028)\tLoss 0.7650 (0.7464)\tPrec@1 87.000 (85.308)\tPrec@5 97.000 (98.165)\n",
            "Test: [100/261]\tTime 0.021 (0.028)\tLoss 0.9094 (0.7385)\tPrec@1 83.000 (85.525)\tPrec@5 97.000 (98.129)\n",
            "Test: [110/261]\tTime 0.029 (0.028)\tLoss 0.8304 (0.7326)\tPrec@1 89.000 (85.595)\tPrec@5 98.000 (98.126)\n",
            "Test: [120/261]\tTime 0.031 (0.027)\tLoss 0.8276 (0.7342)\tPrec@1 86.000 (85.628)\tPrec@5 97.000 (98.124)\n",
            "Test: [130/261]\tTime 0.029 (0.027)\tLoss 0.8442 (0.7385)\tPrec@1 87.000 (85.588)\tPrec@5 97.000 (98.107)\n",
            "Test: [140/261]\tTime 0.016 (0.027)\tLoss 0.9429 (0.7361)\tPrec@1 83.000 (85.617)\tPrec@5 98.000 (98.135)\n",
            "Test: [150/261]\tTime 0.025 (0.027)\tLoss 0.4839 (0.7377)\tPrec@1 88.000 (85.623)\tPrec@5 98.000 (98.119)\n",
            "Test: [160/261]\tTime 0.026 (0.027)\tLoss 0.3959 (0.7406)\tPrec@1 88.000 (85.609)\tPrec@5 100.000 (98.118)\n",
            "Test: [170/261]\tTime 0.026 (0.027)\tLoss 0.6289 (0.7360)\tPrec@1 91.000 (85.690)\tPrec@5 98.000 (98.129)\n",
            "Test: [180/261]\tTime 0.032 (0.026)\tLoss 0.5632 (0.7349)\tPrec@1 89.000 (85.691)\tPrec@5 96.000 (98.116)\n",
            "Test: [190/261]\tTime 0.030 (0.026)\tLoss 0.5658 (0.7312)\tPrec@1 85.000 (85.702)\tPrec@5 100.000 (98.173)\n",
            "Test: [200/261]\tTime 0.028 (0.026)\tLoss 0.6124 (0.7330)\tPrec@1 88.000 (85.647)\tPrec@5 98.000 (98.174)\n",
            "Test: [210/261]\tTime 0.010 (0.026)\tLoss 0.5673 (0.7346)\tPrec@1 89.000 (85.630)\tPrec@5 99.000 (98.161)\n",
            "Test: [220/261]\tTime 0.017 (0.026)\tLoss 0.6437 (0.7300)\tPrec@1 87.000 (85.643)\tPrec@5 97.000 (98.163)\n",
            "Test: [230/261]\tTime 0.029 (0.026)\tLoss 0.8968 (0.7304)\tPrec@1 82.000 (85.567)\tPrec@5 95.000 (98.143)\n",
            "Test: [240/261]\tTime 0.018 (0.026)\tLoss 0.7546 (0.7344)\tPrec@1 86.000 (85.577)\tPrec@5 98.000 (98.129)\n",
            "Test: [250/261]\tTime 0.021 (0.026)\tLoss 0.4023 (0.7282)\tPrec@1 87.000 (85.649)\tPrec@5 100.000 (98.139)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2312 (0.7298)\tPrec@1 96.875 (85.633)\tPrec@5 96.875 (98.122)\n",
            "val Results: Prec@1 85.633 Prec@5 98.122 Loss 0.72980\n",
            "val Class Accuracy: [0.694,0.965,0.937,0.872,0.904,0.852,0.776,0.799,0.748,0.664]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [173][0/66], lr: 0.00010\tTime 0.552 (0.552)\tData 0.468 (0.468)\tLoss 0.0089 (0.0089)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][10/66], lr: 0.00010\tTime 0.102 (0.138)\tData 0.000 (0.047)\tLoss 0.0045 (0.0117)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][20/66], lr: 0.00010\tTime 0.085 (0.119)\tData 0.005 (0.028)\tLoss 0.0162 (0.0124)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][30/66], lr: 0.00010\tTime 0.092 (0.110)\tData 0.000 (0.021)\tLoss 0.0122 (0.0114)\tPrec@1 100.000 (99.761)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][40/66], lr: 0.00010\tTime 0.093 (0.106)\tData 0.005 (0.017)\tLoss 0.0108 (0.0121)\tPrec@1 99.609 (99.714)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][50/66], lr: 0.00010\tTime 0.083 (0.104)\tData 0.000 (0.014)\tLoss 0.0083 (0.0120)\tPrec@1 100.000 (99.694)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [173][60/66], lr: 0.00010\tTime 0.069 (0.102)\tData 0.000 (0.013)\tLoss 0.0066 (0.0118)\tPrec@1 99.609 (99.699)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.239 (0.239)\tLoss 0.7245 (0.7245)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.021 (0.052)\tLoss 1.1952 (0.7856)\tPrec@1 82.000 (83.818)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.039 (0.040)\tLoss 1.1583 (0.7949)\tPrec@1 79.000 (83.762)\tPrec@5 96.000 (98.048)\n",
            "Test: [30/261]\tTime 0.017 (0.035)\tLoss 0.6217 (0.7506)\tPrec@1 86.000 (84.806)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/261]\tTime 0.029 (0.032)\tLoss 0.7578 (0.7211)\tPrec@1 86.000 (85.244)\tPrec@5 98.000 (98.463)\n",
            "Test: [50/261]\tTime 0.016 (0.031)\tLoss 0.4915 (0.7147)\tPrec@1 87.000 (85.392)\tPrec@5 99.000 (98.451)\n",
            "Test: [60/261]\tTime 0.024 (0.030)\tLoss 0.7554 (0.7200)\tPrec@1 87.000 (85.492)\tPrec@5 99.000 (98.328)\n",
            "Test: [70/261]\tTime 0.018 (0.029)\tLoss 0.6137 (0.7227)\tPrec@1 84.000 (85.507)\tPrec@5 99.000 (98.310)\n",
            "Test: [80/261]\tTime 0.040 (0.028)\tLoss 0.6511 (0.7256)\tPrec@1 84.000 (85.617)\tPrec@5 99.000 (98.272)\n",
            "Test: [90/261]\tTime 0.033 (0.028)\tLoss 0.7798 (0.7524)\tPrec@1 87.000 (85.231)\tPrec@5 97.000 (98.187)\n",
            "Test: [100/261]\tTime 0.017 (0.027)\tLoss 0.9144 (0.7447)\tPrec@1 82.000 (85.406)\tPrec@5 97.000 (98.158)\n",
            "Test: [110/261]\tTime 0.027 (0.028)\tLoss 0.8360 (0.7393)\tPrec@1 89.000 (85.450)\tPrec@5 98.000 (98.144)\n",
            "Test: [120/261]\tTime 0.019 (0.027)\tLoss 0.8168 (0.7408)\tPrec@1 86.000 (85.463)\tPrec@5 97.000 (98.124)\n",
            "Test: [130/261]\tTime 0.030 (0.027)\tLoss 0.8429 (0.7449)\tPrec@1 87.000 (85.427)\tPrec@5 97.000 (98.115)\n",
            "Test: [140/261]\tTime 0.013 (0.027)\tLoss 0.9411 (0.7424)\tPrec@1 83.000 (85.447)\tPrec@5 98.000 (98.128)\n",
            "Test: [150/261]\tTime 0.050 (0.027)\tLoss 0.4938 (0.7440)\tPrec@1 89.000 (85.450)\tPrec@5 98.000 (98.113)\n",
            "Test: [160/261]\tTime 0.015 (0.028)\tLoss 0.3964 (0.7466)\tPrec@1 88.000 (85.422)\tPrec@5 100.000 (98.112)\n",
            "Test: [170/261]\tTime 0.038 (0.028)\tLoss 0.6328 (0.7421)\tPrec@1 91.000 (85.515)\tPrec@5 98.000 (98.111)\n",
            "Test: [180/261]\tTime 0.035 (0.029)\tLoss 0.5696 (0.7412)\tPrec@1 89.000 (85.514)\tPrec@5 96.000 (98.099)\n",
            "Test: [190/261]\tTime 0.040 (0.029)\tLoss 0.5697 (0.7375)\tPrec@1 84.000 (85.529)\tPrec@5 100.000 (98.157)\n",
            "Test: [200/261]\tTime 0.037 (0.030)\tLoss 0.6316 (0.7396)\tPrec@1 88.000 (85.473)\tPrec@5 98.000 (98.159)\n",
            "Test: [210/261]\tTime 0.053 (0.030)\tLoss 0.5780 (0.7411)\tPrec@1 89.000 (85.460)\tPrec@5 99.000 (98.147)\n",
            "Test: [220/261]\tTime 0.039 (0.031)\tLoss 0.6621 (0.7366)\tPrec@1 87.000 (85.484)\tPrec@5 98.000 (98.158)\n",
            "Test: [230/261]\tTime 0.039 (0.031)\tLoss 0.9230 (0.7372)\tPrec@1 83.000 (85.429)\tPrec@5 95.000 (98.134)\n",
            "Test: [240/261]\tTime 0.037 (0.031)\tLoss 0.7570 (0.7410)\tPrec@1 86.000 (85.448)\tPrec@5 98.000 (98.116)\n",
            "Test: [250/261]\tTime 0.030 (0.032)\tLoss 0.4121 (0.7348)\tPrec@1 87.000 (85.518)\tPrec@5 100.000 (98.127)\n",
            "Test: [260/261]\tTime 0.009 (0.031)\tLoss 0.2397 (0.7364)\tPrec@1 93.750 (85.510)\tPrec@5 96.875 (98.110)\n",
            "val Results: Prec@1 85.510 Prec@5 98.110 Loss 0.73645\n",
            "val Class Accuracy: [0.682,0.967,0.942,0.867,0.901,0.857,0.781,0.793,0.739,0.656]\n",
            "Best Prec@1: 85.825\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [174][0/66], lr: 0.00010\tTime 0.582 (0.582)\tData 0.509 (0.509)\tLoss 0.0231 (0.0231)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][10/66], lr: 0.00010\tTime 0.081 (0.145)\tData 0.001 (0.053)\tLoss 0.0119 (0.0121)\tPrec@1 99.609 (99.645)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][20/66], lr: 0.00010\tTime 0.096 (0.120)\tData 0.000 (0.031)\tLoss 0.0104 (0.0113)\tPrec@1 100.000 (99.721)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][30/66], lr: 0.00010\tTime 0.082 (0.111)\tData 0.005 (0.023)\tLoss 0.0128 (0.0106)\tPrec@1 99.609 (99.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][40/66], lr: 0.00010\tTime 0.093 (0.107)\tData 0.000 (0.019)\tLoss 0.0155 (0.0116)\tPrec@1 99.609 (99.667)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][50/66], lr: 0.00010\tTime 0.090 (0.104)\tData 0.000 (0.016)\tLoss 0.0180 (0.0123)\tPrec@1 99.609 (99.655)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [174][60/66], lr: 0.00010\tTime 0.078 (0.102)\tData 0.000 (0.014)\tLoss 0.0081 (0.0126)\tPrec@1 99.609 (99.654)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.222 (0.222)\tLoss 0.7227 (0.7227)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.050)\tLoss 1.1867 (0.7609)\tPrec@1 82.000 (84.182)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/261]\tTime 0.024 (0.038)\tLoss 1.1453 (0.7709)\tPrec@1 79.000 (84.048)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.022 (0.034)\tLoss 0.6312 (0.7275)\tPrec@1 87.000 (85.161)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.015 (0.031)\tLoss 0.7258 (0.6966)\tPrec@1 87.000 (85.683)\tPrec@5 99.000 (98.512)\n",
            "Test: [50/261]\tTime 0.029 (0.030)\tLoss 0.4665 (0.6911)\tPrec@1 87.000 (85.824)\tPrec@5 99.000 (98.490)\n",
            "Test: [60/261]\tTime 0.025 (0.030)\tLoss 0.7283 (0.6976)\tPrec@1 86.000 (85.869)\tPrec@5 99.000 (98.361)\n",
            "Test: [70/261]\tTime 0.027 (0.029)\tLoss 0.5679 (0.6998)\tPrec@1 85.000 (85.901)\tPrec@5 99.000 (98.366)\n",
            "Test: [80/261]\tTime 0.022 (0.029)\tLoss 0.6222 (0.7026)\tPrec@1 86.000 (85.963)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/261]\tTime 0.018 (0.028)\tLoss 0.7652 (0.7301)\tPrec@1 87.000 (85.527)\tPrec@5 97.000 (98.231)\n",
            "Test: [100/261]\tTime 0.010 (0.027)\tLoss 0.9216 (0.7226)\tPrec@1 84.000 (85.752)\tPrec@5 97.000 (98.208)\n",
            "Test: [110/261]\tTime 0.029 (0.028)\tLoss 0.8109 (0.7170)\tPrec@1 88.000 (85.775)\tPrec@5 98.000 (98.189)\n",
            "Test: [120/261]\tTime 0.016 (0.027)\tLoss 0.8196 (0.7185)\tPrec@1 87.000 (85.793)\tPrec@5 97.000 (98.198)\n",
            "Test: [130/261]\tTime 0.025 (0.027)\tLoss 0.8256 (0.7232)\tPrec@1 87.000 (85.733)\tPrec@5 97.000 (98.183)\n",
            "Test: [140/261]\tTime 0.014 (0.027)\tLoss 0.9197 (0.7209)\tPrec@1 83.000 (85.759)\tPrec@5 98.000 (98.184)\n",
            "Test: [150/261]\tTime 0.025 (0.027)\tLoss 0.4737 (0.7224)\tPrec@1 89.000 (85.808)\tPrec@5 98.000 (98.172)\n",
            "Test: [160/261]\tTime 0.016 (0.027)\tLoss 0.3700 (0.7255)\tPrec@1 87.000 (85.789)\tPrec@5 100.000 (98.155)\n",
            "Test: [170/261]\tTime 0.033 (0.026)\tLoss 0.6081 (0.7208)\tPrec@1 91.000 (85.889)\tPrec@5 98.000 (98.164)\n",
            "Test: [180/261]\tTime 0.023 (0.026)\tLoss 0.5486 (0.7200)\tPrec@1 89.000 (85.912)\tPrec@5 97.000 (98.160)\n",
            "Test: [190/261]\tTime 0.031 (0.026)\tLoss 0.5575 (0.7163)\tPrec@1 84.000 (85.937)\tPrec@5 100.000 (98.215)\n",
            "Test: [200/261]\tTime 0.023 (0.026)\tLoss 0.6068 (0.7185)\tPrec@1 88.000 (85.861)\tPrec@5 98.000 (98.214)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 0.5564 (0.7201)\tPrec@1 89.000 (85.853)\tPrec@5 98.000 (98.199)\n",
            "Test: [220/261]\tTime 0.033 (0.026)\tLoss 0.6509 (0.7157)\tPrec@1 87.000 (85.855)\tPrec@5 98.000 (98.208)\n",
            "Test: [230/261]\tTime 0.018 (0.026)\tLoss 0.8841 (0.7162)\tPrec@1 83.000 (85.792)\tPrec@5 95.000 (98.186)\n",
            "Test: [240/261]\tTime 0.031 (0.026)\tLoss 0.7211 (0.7201)\tPrec@1 86.000 (85.793)\tPrec@5 98.000 (98.183)\n",
            "Test: [250/261]\tTime 0.010 (0.026)\tLoss 0.3725 (0.7139)\tPrec@1 88.000 (85.869)\tPrec@5 100.000 (98.191)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2310 (0.7152)\tPrec@1 93.750 (85.875)\tPrec@5 96.875 (98.171)\n",
            "val Results: Prec@1 85.875 Prec@5 98.171 Loss 0.71523\n",
            "val Class Accuracy: [0.703,0.967,0.935,0.873,0.895,0.867,0.781,0.792,0.747,0.686]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [175][0/66], lr: 0.00010\tTime 0.559 (0.559)\tData 0.487 (0.487)\tLoss 0.0067 (0.0067)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][10/66], lr: 0.00010\tTime 0.119 (0.141)\tData 0.000 (0.052)\tLoss 0.0085 (0.0098)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][20/66], lr: 0.00010\tTime 0.086 (0.119)\tData 0.005 (0.031)\tLoss 0.0125 (0.0107)\tPrec@1 99.609 (99.777)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][30/66], lr: 0.00010\tTime 0.090 (0.110)\tData 0.005 (0.022)\tLoss 0.0084 (0.0128)\tPrec@1 99.609 (99.647)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][40/66], lr: 0.00010\tTime 0.086 (0.105)\tData 0.000 (0.018)\tLoss 0.0033 (0.0120)\tPrec@1 100.000 (99.695)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][50/66], lr: 0.00010\tTime 0.089 (0.104)\tData 0.000 (0.016)\tLoss 0.0053 (0.0116)\tPrec@1 100.000 (99.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [175][60/66], lr: 0.00010\tTime 0.075 (0.101)\tData 0.000 (0.014)\tLoss 0.0052 (0.0118)\tPrec@1 100.000 (99.693)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.285 (0.285)\tLoss 0.7381 (0.7381)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.048)\tLoss 1.2021 (0.7736)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.026 (0.037)\tLoss 1.1588 (0.7815)\tPrec@1 79.000 (83.905)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.030 (0.035)\tLoss 0.6359 (0.7383)\tPrec@1 87.000 (85.000)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.024 (0.033)\tLoss 0.7427 (0.7075)\tPrec@1 87.000 (85.488)\tPrec@5 98.000 (98.585)\n",
            "Test: [50/261]\tTime 0.017 (0.032)\tLoss 0.4759 (0.7021)\tPrec@1 87.000 (85.667)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.027 (0.031)\tLoss 0.7219 (0.7075)\tPrec@1 87.000 (85.803)\tPrec@5 99.000 (98.426)\n",
            "Test: [70/261]\tTime 0.014 (0.030)\tLoss 0.5867 (0.7095)\tPrec@1 85.000 (85.789)\tPrec@5 99.000 (98.408)\n",
            "Test: [80/261]\tTime 0.023 (0.029)\tLoss 0.6392 (0.7120)\tPrec@1 85.000 (85.864)\tPrec@5 99.000 (98.358)\n",
            "Test: [90/261]\tTime 0.028 (0.029)\tLoss 0.7714 (0.7394)\tPrec@1 87.000 (85.440)\tPrec@5 97.000 (98.253)\n",
            "Test: [100/261]\tTime 0.021 (0.028)\tLoss 0.9188 (0.7317)\tPrec@1 84.000 (85.634)\tPrec@5 97.000 (98.208)\n",
            "Test: [110/261]\tTime 0.026 (0.028)\tLoss 0.8282 (0.7262)\tPrec@1 88.000 (85.658)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.026 (0.028)\tLoss 0.8220 (0.7278)\tPrec@1 87.000 (85.702)\tPrec@5 97.000 (98.207)\n",
            "Test: [130/261]\tTime 0.041 (0.027)\tLoss 0.8302 (0.7325)\tPrec@1 88.000 (85.664)\tPrec@5 97.000 (98.198)\n",
            "Test: [140/261]\tTime 0.034 (0.028)\tLoss 0.9293 (0.7302)\tPrec@1 83.000 (85.660)\tPrec@5 98.000 (98.206)\n",
            "Test: [150/261]\tTime 0.023 (0.027)\tLoss 0.4791 (0.7317)\tPrec@1 89.000 (85.695)\tPrec@5 98.000 (98.199)\n",
            "Test: [160/261]\tTime 0.010 (0.027)\tLoss 0.3734 (0.7345)\tPrec@1 88.000 (85.702)\tPrec@5 100.000 (98.186)\n",
            "Test: [170/261]\tTime 0.044 (0.027)\tLoss 0.6213 (0.7299)\tPrec@1 91.000 (85.789)\tPrec@5 98.000 (98.187)\n",
            "Test: [180/261]\tTime 0.026 (0.027)\tLoss 0.5612 (0.7292)\tPrec@1 89.000 (85.807)\tPrec@5 96.000 (98.177)\n",
            "Test: [190/261]\tTime 0.031 (0.027)\tLoss 0.5715 (0.7256)\tPrec@1 84.000 (85.822)\tPrec@5 100.000 (98.230)\n",
            "Test: [200/261]\tTime 0.037 (0.027)\tLoss 0.6071 (0.7277)\tPrec@1 88.000 (85.771)\tPrec@5 98.000 (98.229)\n",
            "Test: [210/261]\tTime 0.010 (0.026)\tLoss 0.5693 (0.7293)\tPrec@1 89.000 (85.758)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.020 (0.027)\tLoss 0.6482 (0.7247)\tPrec@1 87.000 (85.783)\tPrec@5 98.000 (98.226)\n",
            "Test: [230/261]\tTime 0.024 (0.027)\tLoss 0.8918 (0.7251)\tPrec@1 83.000 (85.727)\tPrec@5 96.000 (98.208)\n",
            "Test: [240/261]\tTime 0.021 (0.027)\tLoss 0.7362 (0.7291)\tPrec@1 86.000 (85.734)\tPrec@5 98.000 (98.195)\n",
            "Test: [250/261]\tTime 0.038 (0.027)\tLoss 0.3890 (0.7228)\tPrec@1 87.000 (85.797)\tPrec@5 100.000 (98.203)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.2360 (0.7244)\tPrec@1 93.750 (85.794)\tPrec@5 96.875 (98.183)\n",
            "val Results: Prec@1 85.794 Prec@5 98.183 Loss 0.72439\n",
            "val Class Accuracy: [0.695,0.968,0.936,0.871,0.895,0.863,0.782,0.804,0.749,0.670]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [176][0/66], lr: 0.00010\tTime 0.503 (0.503)\tData 0.414 (0.414)\tLoss 0.0221 (0.0221)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][10/66], lr: 0.00010\tTime 0.097 (0.137)\tData 0.005 (0.043)\tLoss 0.0201 (0.0105)\tPrec@1 99.219 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][20/66], lr: 0.00010\tTime 0.093 (0.119)\tData 0.000 (0.024)\tLoss 0.0109 (0.0117)\tPrec@1 100.000 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][30/66], lr: 0.00010\tTime 0.116 (0.111)\tData 0.003 (0.018)\tLoss 0.0043 (0.0113)\tPrec@1 100.000 (99.698)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][40/66], lr: 0.00010\tTime 0.098 (0.107)\tData 0.004 (0.015)\tLoss 0.0102 (0.0109)\tPrec@1 99.609 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][50/66], lr: 0.00010\tTime 0.096 (0.104)\tData 0.005 (0.013)\tLoss 0.0037 (0.0114)\tPrec@1 100.000 (99.701)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [176][60/66], lr: 0.00010\tTime 0.069 (0.102)\tData 0.000 (0.012)\tLoss 0.0278 (0.0111)\tPrec@1 98.828 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.306 (0.306)\tLoss 0.7370 (0.7370)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.021 (0.049)\tLoss 1.1989 (0.7755)\tPrec@1 81.000 (83.818)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/261]\tTime 0.028 (0.039)\tLoss 1.1599 (0.7854)\tPrec@1 79.000 (83.810)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.018 (0.034)\tLoss 0.6422 (0.7435)\tPrec@1 87.000 (84.903)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.030 (0.033)\tLoss 0.7510 (0.7132)\tPrec@1 87.000 (85.390)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.020 (0.031)\tLoss 0.4747 (0.7070)\tPrec@1 87.000 (85.588)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.031 (0.030)\tLoss 0.7423 (0.7124)\tPrec@1 86.000 (85.721)\tPrec@5 99.000 (98.426)\n",
            "Test: [70/261]\tTime 0.029 (0.029)\tLoss 0.5896 (0.7142)\tPrec@1 85.000 (85.732)\tPrec@5 99.000 (98.408)\n",
            "Test: [80/261]\tTime 0.032 (0.029)\tLoss 0.6276 (0.7165)\tPrec@1 85.000 (85.790)\tPrec@5 98.000 (98.370)\n",
            "Test: [90/261]\tTime 0.020 (0.028)\tLoss 0.7751 (0.7442)\tPrec@1 87.000 (85.385)\tPrec@5 97.000 (98.275)\n",
            "Test: [100/261]\tTime 0.017 (0.028)\tLoss 0.9266 (0.7366)\tPrec@1 83.000 (85.564)\tPrec@5 97.000 (98.238)\n",
            "Test: [110/261]\tTime 0.036 (0.027)\tLoss 0.8315 (0.7311)\tPrec@1 88.000 (85.586)\tPrec@5 98.000 (98.207)\n",
            "Test: [120/261]\tTime 0.021 (0.028)\tLoss 0.8115 (0.7325)\tPrec@1 88.000 (85.620)\tPrec@5 97.000 (98.207)\n",
            "Test: [130/261]\tTime 0.036 (0.027)\tLoss 0.8328 (0.7370)\tPrec@1 88.000 (85.573)\tPrec@5 97.000 (98.198)\n",
            "Test: [140/261]\tTime 0.027 (0.027)\tLoss 0.9344 (0.7347)\tPrec@1 83.000 (85.589)\tPrec@5 98.000 (98.213)\n",
            "Test: [150/261]\tTime 0.035 (0.027)\tLoss 0.4754 (0.7362)\tPrec@1 89.000 (85.603)\tPrec@5 98.000 (98.192)\n",
            "Test: [160/261]\tTime 0.039 (0.027)\tLoss 0.3663 (0.7390)\tPrec@1 88.000 (85.590)\tPrec@5 100.000 (98.180)\n",
            "Test: [170/261]\tTime 0.025 (0.027)\tLoss 0.6200 (0.7344)\tPrec@1 91.000 (85.684)\tPrec@5 98.000 (98.181)\n",
            "Test: [180/261]\tTime 0.017 (0.027)\tLoss 0.5537 (0.7335)\tPrec@1 89.000 (85.674)\tPrec@5 96.000 (98.171)\n",
            "Test: [190/261]\tTime 0.027 (0.027)\tLoss 0.5524 (0.7298)\tPrec@1 84.000 (85.686)\tPrec@5 100.000 (98.225)\n",
            "Test: [200/261]\tTime 0.009 (0.026)\tLoss 0.6266 (0.7321)\tPrec@1 88.000 (85.637)\tPrec@5 98.000 (98.229)\n",
            "Test: [210/261]\tTime 0.039 (0.026)\tLoss 0.5690 (0.7336)\tPrec@1 88.000 (85.635)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.024 (0.026)\tLoss 0.6665 (0.7291)\tPrec@1 87.000 (85.647)\tPrec@5 98.000 (98.222)\n",
            "Test: [230/261]\tTime 0.038 (0.026)\tLoss 0.9024 (0.7296)\tPrec@1 83.000 (85.584)\tPrec@5 95.000 (98.199)\n",
            "Test: [240/261]\tTime 0.020 (0.026)\tLoss 0.7393 (0.7334)\tPrec@1 86.000 (85.589)\tPrec@5 98.000 (98.191)\n",
            "Test: [250/261]\tTime 0.020 (0.026)\tLoss 0.3903 (0.7272)\tPrec@1 87.000 (85.649)\tPrec@5 100.000 (98.203)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.2364 (0.7288)\tPrec@1 93.750 (85.664)\tPrec@5 96.875 (98.179)\n",
            "val Results: Prec@1 85.664 Prec@5 98.179 Loss 0.72882\n",
            "val Class Accuracy: [0.690,0.967,0.936,0.872,0.897,0.865,0.780,0.789,0.749,0.669]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [177][0/66], lr: 0.00010\tTime 0.640 (0.640)\tData 0.551 (0.551)\tLoss 0.0034 (0.0034)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][10/66], lr: 0.00010\tTime 0.106 (0.149)\tData 0.009 (0.057)\tLoss 0.0080 (0.0114)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][20/66], lr: 0.00010\tTime 0.105 (0.122)\tData 0.003 (0.034)\tLoss 0.0071 (0.0104)\tPrec@1 100.000 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][30/66], lr: 0.00010\tTime 0.094 (0.113)\tData 0.010 (0.026)\tLoss 0.0158 (0.0098)\tPrec@1 99.609 (99.698)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][40/66], lr: 0.00010\tTime 0.120 (0.108)\tData 0.001 (0.021)\tLoss 0.0043 (0.0099)\tPrec@1 100.000 (99.714)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][50/66], lr: 0.00010\tTime 0.084 (0.105)\tData 0.006 (0.019)\tLoss 0.0061 (0.0108)\tPrec@1 100.000 (99.678)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [177][60/66], lr: 0.00010\tTime 0.078 (0.103)\tData 0.000 (0.017)\tLoss 0.0064 (0.0108)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.291 (0.291)\tLoss 0.7294 (0.7294)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.034 (0.052)\tLoss 1.2036 (0.7766)\tPrec@1 82.000 (83.818)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.027 (0.038)\tLoss 1.1572 (0.7848)\tPrec@1 78.000 (83.619)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.018 (0.034)\tLoss 0.6309 (0.7417)\tPrec@1 87.000 (84.774)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.022 (0.032)\tLoss 0.7378 (0.7112)\tPrec@1 87.000 (85.390)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/261]\tTime 0.057 (0.031)\tLoss 0.4822 (0.7051)\tPrec@1 87.000 (85.569)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.020 (0.030)\tLoss 0.7345 (0.7102)\tPrec@1 87.000 (85.689)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.026 (0.029)\tLoss 0.5896 (0.7123)\tPrec@1 85.000 (85.690)\tPrec@5 99.000 (98.366)\n",
            "Test: [80/261]\tTime 0.024 (0.028)\tLoss 0.6276 (0.7153)\tPrec@1 85.000 (85.778)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/261]\tTime 0.019 (0.028)\tLoss 0.7778 (0.7426)\tPrec@1 88.000 (85.407)\tPrec@5 97.000 (98.231)\n",
            "Test: [100/261]\tTime 0.024 (0.027)\tLoss 0.9179 (0.7350)\tPrec@1 84.000 (85.594)\tPrec@5 97.000 (98.178)\n",
            "Test: [110/261]\tTime 0.024 (0.027)\tLoss 0.8249 (0.7294)\tPrec@1 88.000 (85.613)\tPrec@5 98.000 (98.171)\n",
            "Test: [120/261]\tTime 0.015 (0.027)\tLoss 0.8277 (0.7310)\tPrec@1 86.000 (85.628)\tPrec@5 97.000 (98.165)\n",
            "Test: [130/261]\tTime 0.020 (0.026)\tLoss 0.8296 (0.7355)\tPrec@1 87.000 (85.588)\tPrec@5 97.000 (98.153)\n",
            "Test: [140/261]\tTime 0.017 (0.026)\tLoss 0.9412 (0.7332)\tPrec@1 83.000 (85.603)\tPrec@5 98.000 (98.163)\n",
            "Test: [150/261]\tTime 0.021 (0.026)\tLoss 0.4819 (0.7347)\tPrec@1 89.000 (85.629)\tPrec@5 98.000 (98.152)\n",
            "Test: [160/261]\tTime 0.037 (0.026)\tLoss 0.3671 (0.7373)\tPrec@1 88.000 (85.621)\tPrec@5 100.000 (98.149)\n",
            "Test: [170/261]\tTime 0.016 (0.026)\tLoss 0.6266 (0.7328)\tPrec@1 91.000 (85.713)\tPrec@5 98.000 (98.158)\n",
            "Test: [180/261]\tTime 0.016 (0.026)\tLoss 0.5657 (0.7320)\tPrec@1 89.000 (85.729)\tPrec@5 96.000 (98.149)\n",
            "Test: [190/261]\tTime 0.016 (0.026)\tLoss 0.5554 (0.7282)\tPrec@1 83.000 (85.733)\tPrec@5 100.000 (98.204)\n",
            "Test: [200/261]\tTime 0.020 (0.026)\tLoss 0.6219 (0.7302)\tPrec@1 88.000 (85.672)\tPrec@5 98.000 (98.204)\n",
            "Test: [210/261]\tTime 0.023 (0.026)\tLoss 0.5544 (0.7316)\tPrec@1 89.000 (85.668)\tPrec@5 99.000 (98.185)\n",
            "Test: [220/261]\tTime 0.038 (0.026)\tLoss 0.6512 (0.7271)\tPrec@1 87.000 (85.679)\tPrec@5 98.000 (98.190)\n",
            "Test: [230/261]\tTime 0.034 (0.026)\tLoss 0.9092 (0.7275)\tPrec@1 83.000 (85.632)\tPrec@5 96.000 (98.173)\n",
            "Test: [240/261]\tTime 0.030 (0.026)\tLoss 0.7417 (0.7315)\tPrec@1 86.000 (85.635)\tPrec@5 98.000 (98.154)\n",
            "Test: [250/261]\tTime 0.034 (0.026)\tLoss 0.3951 (0.7252)\tPrec@1 87.000 (85.705)\tPrec@5 100.000 (98.163)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2351 (0.7269)\tPrec@1 93.750 (85.695)\tPrec@5 96.875 (98.145)\n",
            "val Results: Prec@1 85.695 Prec@5 98.145 Loss 0.72686\n",
            "val Class Accuracy: [0.701,0.967,0.934,0.872,0.902,0.863,0.781,0.795,0.740,0.661]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [178][0/66], lr: 0.00010\tTime 0.641 (0.641)\tData 0.571 (0.571)\tLoss 0.0132 (0.0132)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][10/66], lr: 0.00010\tTime 0.081 (0.149)\tData 0.000 (0.061)\tLoss 0.0097 (0.0107)\tPrec@1 99.609 (99.716)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][20/66], lr: 0.00010\tTime 0.079 (0.122)\tData 0.000 (0.035)\tLoss 0.0125 (0.0110)\tPrec@1 99.609 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][30/66], lr: 0.00010\tTime 0.091 (0.114)\tData 0.000 (0.026)\tLoss 0.0106 (0.0102)\tPrec@1 100.000 (99.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][40/66], lr: 0.00010\tTime 0.088 (0.109)\tData 0.008 (0.021)\tLoss 0.0046 (0.0102)\tPrec@1 100.000 (99.743)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][50/66], lr: 0.00010\tTime 0.106 (0.106)\tData 0.000 (0.018)\tLoss 0.0073 (0.0096)\tPrec@1 100.000 (99.786)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [178][60/66], lr: 0.00010\tTime 0.074 (0.103)\tData 0.000 (0.016)\tLoss 0.0187 (0.0100)\tPrec@1 99.219 (99.776)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.255 (0.255)\tLoss 0.7572 (0.7572)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.033 (0.050)\tLoss 1.2312 (0.7916)\tPrec@1 82.000 (83.545)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.021 (0.037)\tLoss 1.1743 (0.7969)\tPrec@1 78.000 (83.619)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.024 (0.033)\tLoss 0.6653 (0.7538)\tPrec@1 86.000 (84.742)\tPrec@5 98.000 (98.323)\n",
            "Test: [40/261]\tTime 0.019 (0.031)\tLoss 0.7353 (0.7211)\tPrec@1 86.000 (85.220)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.019 (0.030)\tLoss 0.4862 (0.7154)\tPrec@1 87.000 (85.373)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.028 (0.029)\tLoss 0.7372 (0.7205)\tPrec@1 87.000 (85.525)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.035 (0.029)\tLoss 0.5995 (0.7222)\tPrec@1 84.000 (85.563)\tPrec@5 99.000 (98.380)\n",
            "Test: [80/261]\tTime 0.024 (0.028)\tLoss 0.6415 (0.7244)\tPrec@1 85.000 (85.642)\tPrec@5 99.000 (98.346)\n",
            "Test: [90/261]\tTime 0.017 (0.028)\tLoss 0.7904 (0.7523)\tPrec@1 87.000 (85.253)\tPrec@5 97.000 (98.264)\n",
            "Test: [100/261]\tTime 0.030 (0.027)\tLoss 0.9173 (0.7441)\tPrec@1 83.000 (85.446)\tPrec@5 97.000 (98.218)\n",
            "Test: [110/261]\tTime 0.014 (0.027)\tLoss 0.8379 (0.7383)\tPrec@1 88.000 (85.468)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.015 (0.027)\tLoss 0.8327 (0.7398)\tPrec@1 87.000 (85.488)\tPrec@5 97.000 (98.198)\n",
            "Test: [130/261]\tTime 0.021 (0.026)\tLoss 0.8273 (0.7441)\tPrec@1 87.000 (85.435)\tPrec@5 97.000 (98.183)\n",
            "Test: [140/261]\tTime 0.037 (0.026)\tLoss 0.9512 (0.7418)\tPrec@1 83.000 (85.461)\tPrec@5 98.000 (98.191)\n",
            "Test: [150/261]\tTime 0.012 (0.026)\tLoss 0.4845 (0.7432)\tPrec@1 88.000 (85.464)\tPrec@5 98.000 (98.179)\n",
            "Test: [160/261]\tTime 0.024 (0.026)\tLoss 0.3743 (0.7461)\tPrec@1 88.000 (85.472)\tPrec@5 100.000 (98.168)\n",
            "Test: [170/261]\tTime 0.031 (0.026)\tLoss 0.6265 (0.7415)\tPrec@1 91.000 (85.567)\tPrec@5 98.000 (98.170)\n",
            "Test: [180/261]\tTime 0.018 (0.026)\tLoss 0.5716 (0.7408)\tPrec@1 89.000 (85.580)\tPrec@5 96.000 (98.160)\n",
            "Test: [190/261]\tTime 0.046 (0.026)\tLoss 0.5849 (0.7368)\tPrec@1 84.000 (85.607)\tPrec@5 100.000 (98.215)\n",
            "Test: [200/261]\tTime 0.022 (0.026)\tLoss 0.6281 (0.7389)\tPrec@1 88.000 (85.567)\tPrec@5 98.000 (98.219)\n",
            "Test: [210/261]\tTime 0.023 (0.026)\tLoss 0.5702 (0.7402)\tPrec@1 89.000 (85.536)\tPrec@5 98.000 (98.199)\n",
            "Test: [220/261]\tTime 0.016 (0.026)\tLoss 0.6616 (0.7356)\tPrec@1 87.000 (85.557)\tPrec@5 98.000 (98.208)\n",
            "Test: [230/261]\tTime 0.029 (0.026)\tLoss 0.9177 (0.7361)\tPrec@1 82.000 (85.511)\tPrec@5 95.000 (98.186)\n",
            "Test: [240/261]\tTime 0.024 (0.026)\tLoss 0.7429 (0.7401)\tPrec@1 86.000 (85.523)\tPrec@5 98.000 (98.174)\n",
            "Test: [250/261]\tTime 0.017 (0.026)\tLoss 0.3855 (0.7337)\tPrec@1 87.000 (85.582)\tPrec@5 100.000 (98.187)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2295 (0.7355)\tPrec@1 96.875 (85.587)\tPrec@5 96.875 (98.168)\n",
            "val Results: Prec@1 85.587 Prec@5 98.168 Loss 0.73555\n",
            "val Class Accuracy: [0.689,0.968,0.935,0.881,0.893,0.852,0.781,0.797,0.741,0.663]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [179][0/66], lr: 0.00010\tTime 0.581 (0.581)\tData 0.505 (0.505)\tLoss 0.0039 (0.0039)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][10/66], lr: 0.00010\tTime 0.092 (0.140)\tData 0.003 (0.051)\tLoss 0.0160 (0.0118)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][20/66], lr: 0.00010\tTime 0.082 (0.118)\tData 0.002 (0.029)\tLoss 0.0058 (0.0123)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][30/66], lr: 0.00010\tTime 0.105 (0.112)\tData 0.012 (0.022)\tLoss 0.0148 (0.0118)\tPrec@1 99.219 (99.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][40/66], lr: 0.00010\tTime 0.101 (0.108)\tData 0.009 (0.019)\tLoss 0.0068 (0.0108)\tPrec@1 100.000 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][50/66], lr: 0.00010\tTime 0.099 (0.105)\tData 0.007 (0.016)\tLoss 0.0083 (0.0111)\tPrec@1 99.609 (99.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [179][60/66], lr: 0.00010\tTime 0.077 (0.102)\tData 0.000 (0.015)\tLoss 0.0124 (0.0107)\tPrec@1 100.000 (99.737)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.313 (0.313)\tLoss 0.7276 (0.7276)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.048)\tLoss 1.2044 (0.7739)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.050 (0.037)\tLoss 1.1631 (0.7828)\tPrec@1 77.000 (83.952)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.021 (0.034)\tLoss 0.6436 (0.7405)\tPrec@1 86.000 (85.000)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.011 (0.031)\tLoss 0.7321 (0.7090)\tPrec@1 87.000 (85.585)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/261]\tTime 0.025 (0.030)\tLoss 0.4693 (0.7029)\tPrec@1 89.000 (85.725)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.053 (0.030)\tLoss 0.7335 (0.7086)\tPrec@1 86.000 (85.869)\tPrec@5 99.000 (98.443)\n",
            "Test: [70/261]\tTime 0.010 (0.029)\tLoss 0.5751 (0.7103)\tPrec@1 84.000 (85.859)\tPrec@5 99.000 (98.408)\n",
            "Test: [80/261]\tTime 0.025 (0.028)\tLoss 0.6170 (0.7130)\tPrec@1 85.000 (85.914)\tPrec@5 99.000 (98.370)\n",
            "Test: [90/261]\tTime 0.028 (0.028)\tLoss 0.7763 (0.7408)\tPrec@1 88.000 (85.527)\tPrec@5 97.000 (98.286)\n",
            "Test: [100/261]\tTime 0.040 (0.028)\tLoss 0.9226 (0.7332)\tPrec@1 84.000 (85.743)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.040 (0.028)\tLoss 0.8189 (0.7274)\tPrec@1 88.000 (85.793)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.028 (0.027)\tLoss 0.8269 (0.7288)\tPrec@1 86.000 (85.810)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.027 (0.027)\tLoss 0.8237 (0.7334)\tPrec@1 87.000 (85.748)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.040 (0.027)\tLoss 0.9383 (0.7310)\tPrec@1 83.000 (85.773)\tPrec@5 98.000 (98.234)\n",
            "Test: [150/261]\tTime 0.035 (0.027)\tLoss 0.4813 (0.7327)\tPrec@1 88.000 (85.821)\tPrec@5 98.000 (98.219)\n",
            "Test: [160/261]\tTime 0.031 (0.027)\tLoss 0.3581 (0.7356)\tPrec@1 88.000 (85.801)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.039 (0.027)\tLoss 0.6246 (0.7309)\tPrec@1 91.000 (85.901)\tPrec@5 98.000 (98.216)\n",
            "Test: [180/261]\tTime 0.043 (0.026)\tLoss 0.5652 (0.7302)\tPrec@1 89.000 (85.901)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.010 (0.027)\tLoss 0.5562 (0.7262)\tPrec@1 85.000 (85.906)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.027 (0.026)\tLoss 0.6304 (0.7284)\tPrec@1 88.000 (85.846)\tPrec@5 98.000 (98.259)\n",
            "Test: [210/261]\tTime 0.026 (0.026)\tLoss 0.5545 (0.7297)\tPrec@1 89.000 (85.848)\tPrec@5 99.000 (98.237)\n",
            "Test: [220/261]\tTime 0.030 (0.026)\tLoss 0.6537 (0.7251)\tPrec@1 87.000 (85.846)\tPrec@5 98.000 (98.240)\n",
            "Test: [230/261]\tTime 0.017 (0.026)\tLoss 0.9025 (0.7256)\tPrec@1 82.000 (85.784)\tPrec@5 96.000 (98.225)\n",
            "Test: [240/261]\tTime 0.042 (0.026)\tLoss 0.7341 (0.7296)\tPrec@1 86.000 (85.793)\tPrec@5 98.000 (98.207)\n",
            "Test: [250/261]\tTime 0.013 (0.026)\tLoss 0.3847 (0.7233)\tPrec@1 87.000 (85.849)\tPrec@5 100.000 (98.215)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.2289 (0.7250)\tPrec@1 93.750 (85.840)\tPrec@5 96.875 (98.195)\n",
            "val Results: Prec@1 85.840 Prec@5 98.195 Loss 0.72500\n",
            "val Class Accuracy: [0.706,0.967,0.932,0.875,0.903,0.863,0.783,0.791,0.740,0.680]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [180][0/66], lr: 0.00000\tTime 0.561 (0.561)\tData 0.479 (0.479)\tLoss 0.0224 (0.0224)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][10/66], lr: 0.00000\tTime 0.108 (0.144)\tData 0.012 (0.051)\tLoss 0.0098 (0.0105)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][20/66], lr: 0.00000\tTime 0.076 (0.121)\tData 0.000 (0.029)\tLoss 0.0156 (0.0094)\tPrec@1 99.219 (99.758)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][30/66], lr: 0.00000\tTime 0.086 (0.111)\tData 0.000 (0.021)\tLoss 0.0094 (0.0099)\tPrec@1 100.000 (99.761)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][40/66], lr: 0.00000\tTime 0.076 (0.107)\tData 0.004 (0.018)\tLoss 0.0070 (0.0092)\tPrec@1 100.000 (99.790)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][50/66], lr: 0.00000\tTime 0.102 (0.105)\tData 0.005 (0.016)\tLoss 0.0165 (0.0098)\tPrec@1 99.219 (99.770)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [180][60/66], lr: 0.00000\tTime 0.082 (0.102)\tData 0.000 (0.015)\tLoss 0.0034 (0.0096)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.319 (0.319)\tLoss 0.7600 (0.7600)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.031 (0.052)\tLoss 1.2168 (0.7927)\tPrec@1 82.000 (83.818)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/261]\tTime 0.020 (0.039)\tLoss 1.1905 (0.8019)\tPrec@1 77.000 (83.619)\tPrec@5 96.000 (98.143)\n",
            "Test: [30/261]\tTime 0.019 (0.034)\tLoss 0.6341 (0.7582)\tPrec@1 86.000 (84.774)\tPrec@5 98.000 (98.323)\n",
            "Test: [40/261]\tTime 0.019 (0.032)\tLoss 0.7424 (0.7257)\tPrec@1 87.000 (85.366)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.043 (0.030)\tLoss 0.4987 (0.7192)\tPrec@1 86.000 (85.471)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.018 (0.030)\tLoss 0.7529 (0.7241)\tPrec@1 86.000 (85.557)\tPrec@5 99.000 (98.377)\n",
            "Test: [70/261]\tTime 0.025 (0.029)\tLoss 0.6069 (0.7266)\tPrec@1 86.000 (85.549)\tPrec@5 99.000 (98.352)\n",
            "Test: [80/261]\tTime 0.010 (0.028)\tLoss 0.6471 (0.7303)\tPrec@1 85.000 (85.568)\tPrec@5 99.000 (98.321)\n",
            "Test: [90/261]\tTime 0.022 (0.028)\tLoss 0.7987 (0.7578)\tPrec@1 88.000 (85.198)\tPrec@5 97.000 (98.231)\n",
            "Test: [100/261]\tTime 0.047 (0.027)\tLoss 0.9193 (0.7501)\tPrec@1 83.000 (85.366)\tPrec@5 97.000 (98.198)\n",
            "Test: [110/261]\tTime 0.042 (0.027)\tLoss 0.8346 (0.7441)\tPrec@1 88.000 (85.414)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.029 (0.027)\tLoss 0.8394 (0.7458)\tPrec@1 86.000 (85.413)\tPrec@5 97.000 (98.182)\n",
            "Test: [130/261]\tTime 0.021 (0.027)\tLoss 0.8263 (0.7501)\tPrec@1 87.000 (85.351)\tPrec@5 97.000 (98.160)\n",
            "Test: [140/261]\tTime 0.018 (0.026)\tLoss 0.9725 (0.7478)\tPrec@1 82.000 (85.383)\tPrec@5 98.000 (98.170)\n",
            "Test: [150/261]\tTime 0.039 (0.027)\tLoss 0.4921 (0.7494)\tPrec@1 87.000 (85.404)\tPrec@5 98.000 (98.159)\n",
            "Test: [160/261]\tTime 0.034 (0.027)\tLoss 0.3843 (0.7520)\tPrec@1 88.000 (85.398)\tPrec@5 100.000 (98.155)\n",
            "Test: [170/261]\tTime 0.023 (0.026)\tLoss 0.6376 (0.7473)\tPrec@1 91.000 (85.485)\tPrec@5 98.000 (98.158)\n",
            "Test: [180/261]\tTime 0.010 (0.026)\tLoss 0.5804 (0.7466)\tPrec@1 89.000 (85.514)\tPrec@5 96.000 (98.144)\n",
            "Test: [190/261]\tTime 0.026 (0.026)\tLoss 0.5784 (0.7426)\tPrec@1 83.000 (85.524)\tPrec@5 100.000 (98.199)\n",
            "Test: [200/261]\tTime 0.024 (0.026)\tLoss 0.6463 (0.7446)\tPrec@1 87.000 (85.458)\tPrec@5 98.000 (98.199)\n",
            "Test: [210/261]\tTime 0.016 (0.026)\tLoss 0.5505 (0.7458)\tPrec@1 89.000 (85.464)\tPrec@5 99.000 (98.175)\n",
            "Test: [220/261]\tTime 0.019 (0.026)\tLoss 0.6687 (0.7414)\tPrec@1 87.000 (85.475)\tPrec@5 98.000 (98.176)\n",
            "Test: [230/261]\tTime 0.031 (0.026)\tLoss 0.9352 (0.7421)\tPrec@1 83.000 (85.424)\tPrec@5 96.000 (98.152)\n",
            "Test: [240/261]\tTime 0.037 (0.026)\tLoss 0.7441 (0.7461)\tPrec@1 86.000 (85.440)\tPrec@5 98.000 (98.129)\n",
            "Test: [250/261]\tTime 0.019 (0.026)\tLoss 0.4146 (0.7398)\tPrec@1 87.000 (85.510)\tPrec@5 100.000 (98.139)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2336 (0.7415)\tPrec@1 93.750 (85.502)\tPrec@5 96.875 (98.125)\n",
            "val Results: Prec@1 85.502 Prec@5 98.125 Loss 0.74152\n",
            "val Class Accuracy: [0.698,0.969,0.935,0.875,0.898,0.865,0.773,0.789,0.726,0.655]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [181][0/66], lr: 0.00000\tTime 0.588 (0.588)\tData 0.503 (0.503)\tLoss 0.0100 (0.0100)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][10/66], lr: 0.00000\tTime 0.101 (0.143)\tData 0.001 (0.050)\tLoss 0.0040 (0.0095)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][20/66], lr: 0.00000\tTime 0.094 (0.119)\tData 0.000 (0.028)\tLoss 0.0060 (0.0085)\tPrec@1 100.000 (99.833)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][30/66], lr: 0.00000\tTime 0.087 (0.110)\tData 0.007 (0.021)\tLoss 0.0119 (0.0094)\tPrec@1 99.609 (99.761)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][40/66], lr: 0.00000\tTime 0.069 (0.105)\tData 0.000 (0.018)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (99.762)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][50/66], lr: 0.00000\tTime 0.139 (0.103)\tData 0.007 (0.015)\tLoss 0.0091 (0.0103)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [181][60/66], lr: 0.00000\tTime 0.063 (0.100)\tData 0.000 (0.014)\tLoss 0.0049 (0.0099)\tPrec@1 100.000 (99.789)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.226 (0.226)\tLoss 0.7390 (0.7390)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.018 (0.051)\tLoss 1.2245 (0.7827)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.027 (0.037)\tLoss 1.1816 (0.7887)\tPrec@1 79.000 (83.952)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.017 (0.033)\tLoss 0.6594 (0.7463)\tPrec@1 85.000 (85.032)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.020 (0.031)\tLoss 0.7415 (0.7151)\tPrec@1 86.000 (85.439)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/261]\tTime 0.017 (0.028)\tLoss 0.4853 (0.7102)\tPrec@1 87.000 (85.588)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.038 (0.028)\tLoss 0.7335 (0.7155)\tPrec@1 86.000 (85.689)\tPrec@5 99.000 (98.459)\n",
            "Test: [70/261]\tTime 0.017 (0.027)\tLoss 0.5899 (0.7172)\tPrec@1 86.000 (85.775)\tPrec@5 99.000 (98.423)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 0.6292 (0.7195)\tPrec@1 85.000 (85.802)\tPrec@5 99.000 (98.395)\n",
            "Test: [90/261]\tTime 0.021 (0.027)\tLoss 0.7826 (0.7470)\tPrec@1 87.000 (85.440)\tPrec@5 97.000 (98.308)\n",
            "Test: [100/261]\tTime 0.014 (0.026)\tLoss 0.9233 (0.7394)\tPrec@1 84.000 (85.634)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.029 (0.026)\tLoss 0.8361 (0.7334)\tPrec@1 88.000 (85.667)\tPrec@5 98.000 (98.225)\n",
            "Test: [120/261]\tTime 0.021 (0.026)\tLoss 0.8292 (0.7351)\tPrec@1 87.000 (85.686)\tPrec@5 97.000 (98.223)\n",
            "Test: [130/261]\tTime 0.022 (0.026)\tLoss 0.8272 (0.7395)\tPrec@1 87.000 (85.618)\tPrec@5 97.000 (98.206)\n",
            "Test: [140/261]\tTime 0.030 (0.026)\tLoss 0.9441 (0.7372)\tPrec@1 83.000 (85.645)\tPrec@5 98.000 (98.220)\n",
            "Test: [150/261]\tTime 0.024 (0.025)\tLoss 0.4819 (0.7388)\tPrec@1 88.000 (85.662)\tPrec@5 98.000 (98.199)\n",
            "Test: [160/261]\tTime 0.022 (0.025)\tLoss 0.3601 (0.7417)\tPrec@1 87.000 (85.634)\tPrec@5 100.000 (98.193)\n",
            "Test: [170/261]\tTime 0.019 (0.025)\tLoss 0.6289 (0.7372)\tPrec@1 91.000 (85.737)\tPrec@5 98.000 (98.199)\n",
            "Test: [180/261]\tTime 0.034 (0.026)\tLoss 0.5755 (0.7362)\tPrec@1 89.000 (85.740)\tPrec@5 96.000 (98.188)\n",
            "Test: [190/261]\tTime 0.032 (0.025)\tLoss 0.5572 (0.7321)\tPrec@1 84.000 (85.749)\tPrec@5 100.000 (98.241)\n",
            "Test: [200/261]\tTime 0.020 (0.025)\tLoss 0.6490 (0.7342)\tPrec@1 88.000 (85.697)\tPrec@5 98.000 (98.234)\n",
            "Test: [210/261]\tTime 0.045 (0.025)\tLoss 0.5617 (0.7356)\tPrec@1 89.000 (85.706)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.027 (0.025)\tLoss 0.6547 (0.7310)\tPrec@1 87.000 (85.719)\tPrec@5 98.000 (98.217)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.9109 (0.7314)\tPrec@1 82.000 (85.662)\tPrec@5 95.000 (98.190)\n",
            "Test: [240/261]\tTime 0.036 (0.025)\tLoss 0.7455 (0.7355)\tPrec@1 86.000 (85.672)\tPrec@5 98.000 (98.174)\n",
            "Test: [250/261]\tTime 0.037 (0.025)\tLoss 0.3820 (0.7291)\tPrec@1 87.000 (85.737)\tPrec@5 100.000 (98.187)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2254 (0.7310)\tPrec@1 96.875 (85.744)\tPrec@5 96.875 (98.168)\n",
            "val Results: Prec@1 85.744 Prec@5 98.168 Loss 0.73096\n",
            "val Class Accuracy: [0.705,0.967,0.939,0.879,0.898,0.849,0.778,0.790,0.752,0.666]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [182][0/66], lr: 0.00000\tTime 0.573 (0.573)\tData 0.486 (0.486)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][10/66], lr: 0.00000\tTime 0.085 (0.139)\tData 0.004 (0.051)\tLoss 0.0335 (0.0122)\tPrec@1 99.609 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][20/66], lr: 0.00000\tTime 0.097 (0.121)\tData 0.000 (0.031)\tLoss 0.0130 (0.0123)\tPrec@1 99.609 (99.647)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][30/66], lr: 0.00000\tTime 0.100 (0.112)\tData 0.005 (0.023)\tLoss 0.0063 (0.0114)\tPrec@1 100.000 (99.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][40/66], lr: 0.00000\tTime 0.075 (0.107)\tData 0.000 (0.019)\tLoss 0.0087 (0.0108)\tPrec@1 99.609 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][50/66], lr: 0.00000\tTime 0.132 (0.104)\tData 0.006 (0.016)\tLoss 0.0034 (0.0105)\tPrec@1 100.000 (99.717)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [182][60/66], lr: 0.00000\tTime 0.076 (0.102)\tData 0.000 (0.014)\tLoss 0.0071 (0.0105)\tPrec@1 100.000 (99.731)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.231 (0.231)\tLoss 0.7360 (0.7360)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.040 (0.048)\tLoss 1.2292 (0.7820)\tPrec@1 82.000 (83.545)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.025 (0.039)\tLoss 1.1844 (0.7883)\tPrec@1 77.000 (83.524)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.028 (0.034)\tLoss 0.6570 (0.7453)\tPrec@1 87.000 (84.774)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.019 (0.031)\tLoss 0.7231 (0.7129)\tPrec@1 87.000 (85.317)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.025 (0.031)\tLoss 0.4869 (0.7079)\tPrec@1 87.000 (85.490)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.030 (0.030)\tLoss 0.7424 (0.7134)\tPrec@1 87.000 (85.689)\tPrec@5 99.000 (98.459)\n",
            "Test: [70/261]\tTime 0.033 (0.029)\tLoss 0.5847 (0.7152)\tPrec@1 83.000 (85.704)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.034 (0.029)\tLoss 0.6347 (0.7183)\tPrec@1 85.000 (85.765)\tPrec@5 99.000 (98.395)\n",
            "Test: [90/261]\tTime 0.016 (0.028)\tLoss 0.7923 (0.7464)\tPrec@1 87.000 (85.352)\tPrec@5 97.000 (98.330)\n",
            "Test: [100/261]\tTime 0.060 (0.028)\tLoss 0.9232 (0.7387)\tPrec@1 85.000 (85.584)\tPrec@5 97.000 (98.287)\n",
            "Test: [110/261]\tTime 0.028 (0.028)\tLoss 0.8321 (0.7327)\tPrec@1 88.000 (85.604)\tPrec@5 98.000 (98.270)\n",
            "Test: [120/261]\tTime 0.023 (0.028)\tLoss 0.8402 (0.7345)\tPrec@1 87.000 (85.603)\tPrec@5 97.000 (98.256)\n",
            "Test: [130/261]\tTime 0.039 (0.027)\tLoss 0.8274 (0.7388)\tPrec@1 87.000 (85.550)\tPrec@5 97.000 (98.237)\n",
            "Test: [140/261]\tTime 0.021 (0.027)\tLoss 0.9433 (0.7364)\tPrec@1 83.000 (85.574)\tPrec@5 98.000 (98.248)\n",
            "Test: [150/261]\tTime 0.016 (0.027)\tLoss 0.4829 (0.7382)\tPrec@1 87.000 (85.596)\tPrec@5 98.000 (98.232)\n",
            "Test: [160/261]\tTime 0.033 (0.027)\tLoss 0.3719 (0.7410)\tPrec@1 87.000 (85.596)\tPrec@5 100.000 (98.224)\n",
            "Test: [170/261]\tTime 0.034 (0.027)\tLoss 0.6221 (0.7362)\tPrec@1 91.000 (85.684)\tPrec@5 98.000 (98.222)\n",
            "Test: [180/261]\tTime 0.012 (0.026)\tLoss 0.5658 (0.7357)\tPrec@1 89.000 (85.691)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.020 (0.026)\tLoss 0.5794 (0.7318)\tPrec@1 83.000 (85.702)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.020 (0.026)\tLoss 0.6365 (0.7340)\tPrec@1 88.000 (85.647)\tPrec@5 98.000 (98.254)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 0.5573 (0.7352)\tPrec@1 89.000 (85.635)\tPrec@5 99.000 (98.232)\n",
            "Test: [220/261]\tTime 0.027 (0.026)\tLoss 0.6617 (0.7309)\tPrec@1 87.000 (85.629)\tPrec@5 98.000 (98.240)\n",
            "Test: [230/261]\tTime 0.014 (0.026)\tLoss 0.9098 (0.7316)\tPrec@1 82.000 (85.580)\tPrec@5 96.000 (98.212)\n",
            "Test: [240/261]\tTime 0.029 (0.026)\tLoss 0.7313 (0.7356)\tPrec@1 86.000 (85.589)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.028 (0.026)\tLoss 0.3881 (0.7293)\tPrec@1 87.000 (85.641)\tPrec@5 100.000 (98.215)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2313 (0.7311)\tPrec@1 93.750 (85.633)\tPrec@5 96.875 (98.195)\n",
            "val Results: Prec@1 85.633 Prec@5 98.195 Loss 0.73113\n",
            "val Class Accuracy: [0.700,0.969,0.931,0.879,0.895,0.859,0.784,0.790,0.745,0.658]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [183][0/66], lr: 0.00000\tTime 0.584 (0.584)\tData 0.512 (0.512)\tLoss 0.0117 (0.0117)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][10/66], lr: 0.00000\tTime 0.088 (0.140)\tData 0.006 (0.052)\tLoss 0.0099 (0.0121)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][20/66], lr: 0.00000\tTime 0.098 (0.117)\tData 0.000 (0.031)\tLoss 0.0122 (0.0124)\tPrec@1 99.609 (99.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][30/66], lr: 0.00000\tTime 0.075 (0.108)\tData 0.000 (0.022)\tLoss 0.0230 (0.0117)\tPrec@1 98.828 (99.723)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][40/66], lr: 0.00000\tTime 0.077 (0.105)\tData 0.000 (0.019)\tLoss 0.0137 (0.0116)\tPrec@1 99.609 (99.705)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][50/66], lr: 0.00000\tTime 0.075 (0.102)\tData 0.000 (0.016)\tLoss 0.0146 (0.0115)\tPrec@1 99.609 (99.701)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [183][60/66], lr: 0.00000\tTime 0.077 (0.100)\tData 0.000 (0.014)\tLoss 0.0173 (0.0116)\tPrec@1 99.609 (99.699)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.261 (0.261)\tLoss 0.7223 (0.7223)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.017 (0.047)\tLoss 1.2039 (0.7789)\tPrec@1 82.000 (83.727)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.009 (0.038)\tLoss 1.1918 (0.7890)\tPrec@1 79.000 (83.667)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.6294 (0.7447)\tPrec@1 86.000 (84.871)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.014 (0.031)\tLoss 0.7441 (0.7134)\tPrec@1 87.000 (85.488)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.009 (0.029)\tLoss 0.4822 (0.7075)\tPrec@1 87.000 (85.686)\tPrec@5 99.000 (98.490)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.7401 (0.7132)\tPrec@1 87.000 (85.836)\tPrec@5 99.000 (98.410)\n",
            "Test: [70/261]\tTime 0.038 (0.027)\tLoss 0.5877 (0.7154)\tPrec@1 85.000 (85.831)\tPrec@5 99.000 (98.394)\n",
            "Test: [80/261]\tTime 0.025 (0.028)\tLoss 0.6325 (0.7188)\tPrec@1 85.000 (85.852)\tPrec@5 99.000 (98.358)\n",
            "Test: [90/261]\tTime 0.014 (0.027)\tLoss 0.7932 (0.7465)\tPrec@1 88.000 (85.418)\tPrec@5 97.000 (98.242)\n",
            "Test: [100/261]\tTime 0.017 (0.027)\tLoss 0.9348 (0.7392)\tPrec@1 83.000 (85.614)\tPrec@5 97.000 (98.208)\n",
            "Test: [110/261]\tTime 0.017 (0.026)\tLoss 0.8244 (0.7337)\tPrec@1 89.000 (85.658)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.028 (0.026)\tLoss 0.8281 (0.7355)\tPrec@1 87.000 (85.653)\tPrec@5 97.000 (98.190)\n",
            "Test: [130/261]\tTime 0.022 (0.026)\tLoss 0.8199 (0.7400)\tPrec@1 87.000 (85.573)\tPrec@5 97.000 (98.176)\n",
            "Test: [140/261]\tTime 0.027 (0.026)\tLoss 0.9350 (0.7377)\tPrec@1 83.000 (85.574)\tPrec@5 98.000 (98.184)\n",
            "Test: [150/261]\tTime 0.026 (0.026)\tLoss 0.4959 (0.7393)\tPrec@1 88.000 (85.596)\tPrec@5 98.000 (98.172)\n",
            "Test: [160/261]\tTime 0.026 (0.026)\tLoss 0.3698 (0.7419)\tPrec@1 88.000 (85.602)\tPrec@5 100.000 (98.161)\n",
            "Test: [170/261]\tTime 0.023 (0.026)\tLoss 0.6297 (0.7373)\tPrec@1 90.000 (85.696)\tPrec@5 98.000 (98.170)\n",
            "Test: [180/261]\tTime 0.032 (0.026)\tLoss 0.5751 (0.7367)\tPrec@1 89.000 (85.702)\tPrec@5 96.000 (98.155)\n",
            "Test: [190/261]\tTime 0.009 (0.026)\tLoss 0.5862 (0.7330)\tPrec@1 85.000 (85.749)\tPrec@5 100.000 (98.209)\n",
            "Test: [200/261]\tTime 0.027 (0.025)\tLoss 0.6391 (0.7352)\tPrec@1 88.000 (85.687)\tPrec@5 98.000 (98.209)\n",
            "Test: [210/261]\tTime 0.029 (0.025)\tLoss 0.5713 (0.7367)\tPrec@1 89.000 (85.673)\tPrec@5 98.000 (98.180)\n",
            "Test: [220/261]\tTime 0.018 (0.025)\tLoss 0.6621 (0.7321)\tPrec@1 87.000 (85.679)\tPrec@5 98.000 (98.186)\n",
            "Test: [230/261]\tTime 0.033 (0.025)\tLoss 0.9225 (0.7329)\tPrec@1 83.000 (85.615)\tPrec@5 96.000 (98.173)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.7285 (0.7368)\tPrec@1 86.000 (85.618)\tPrec@5 98.000 (98.154)\n",
            "Test: [250/261]\tTime 0.034 (0.025)\tLoss 0.3997 (0.7305)\tPrec@1 87.000 (85.689)\tPrec@5 100.000 (98.163)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2435 (0.7323)\tPrec@1 93.750 (85.687)\tPrec@5 96.875 (98.148)\n",
            "val Results: Prec@1 85.687 Prec@5 98.148 Loss 0.73227\n",
            "val Class Accuracy: [0.697,0.970,0.938,0.868,0.893,0.862,0.789,0.790,0.737,0.665]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [184][0/66], lr: 0.00000\tTime 0.633 (0.633)\tData 0.570 (0.570)\tLoss 0.0105 (0.0105)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][10/66], lr: 0.00000\tTime 0.083 (0.142)\tData 0.004 (0.059)\tLoss 0.0128 (0.0100)\tPrec@1 99.609 (99.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][20/66], lr: 0.00000\tTime 0.102 (0.118)\tData 0.000 (0.034)\tLoss 0.0047 (0.0097)\tPrec@1 100.000 (99.777)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][30/66], lr: 0.00000\tTime 0.080 (0.110)\tData 0.000 (0.025)\tLoss 0.0065 (0.0092)\tPrec@1 100.000 (99.798)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][40/66], lr: 0.00000\tTime 0.084 (0.106)\tData 0.006 (0.020)\tLoss 0.0058 (0.0097)\tPrec@1 100.000 (99.809)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][50/66], lr: 0.00000\tTime 0.098 (0.103)\tData 0.000 (0.018)\tLoss 0.0048 (0.0096)\tPrec@1 100.000 (99.809)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [184][60/66], lr: 0.00000\tTime 0.078 (0.100)\tData 0.000 (0.016)\tLoss 0.0059 (0.0095)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.222 (0.222)\tLoss 0.7409 (0.7409)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.032 (0.047)\tLoss 1.2126 (0.7739)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.455)\n",
            "Test: [20/261]\tTime 0.028 (0.036)\tLoss 1.1682 (0.7797)\tPrec@1 78.000 (83.905)\tPrec@5 96.000 (98.286)\n",
            "Test: [30/261]\tTime 0.021 (0.032)\tLoss 0.6613 (0.7378)\tPrec@1 87.000 (85.032)\tPrec@5 98.000 (98.452)\n",
            "Test: [40/261]\tTime 0.016 (0.030)\tLoss 0.7212 (0.7052)\tPrec@1 87.000 (85.561)\tPrec@5 98.000 (98.610)\n",
            "Test: [50/261]\tTime 0.034 (0.029)\tLoss 0.4709 (0.6999)\tPrec@1 88.000 (85.725)\tPrec@5 99.000 (98.588)\n",
            "Test: [60/261]\tTime 0.027 (0.028)\tLoss 0.7195 (0.7057)\tPrec@1 87.000 (85.869)\tPrec@5 99.000 (98.492)\n",
            "Test: [70/261]\tTime 0.031 (0.028)\tLoss 0.5709 (0.7073)\tPrec@1 84.000 (85.901)\tPrec@5 99.000 (98.465)\n",
            "Test: [80/261]\tTime 0.018 (0.027)\tLoss 0.6235 (0.7095)\tPrec@1 85.000 (85.914)\tPrec@5 99.000 (98.432)\n",
            "Test: [90/261]\tTime 0.034 (0.027)\tLoss 0.7742 (0.7375)\tPrec@1 88.000 (85.495)\tPrec@5 97.000 (98.341)\n",
            "Test: [100/261]\tTime 0.034 (0.027)\tLoss 0.9246 (0.7298)\tPrec@1 84.000 (85.693)\tPrec@5 97.000 (98.287)\n",
            "Test: [110/261]\tTime 0.016 (0.026)\tLoss 0.8246 (0.7240)\tPrec@1 88.000 (85.712)\tPrec@5 98.000 (98.261)\n",
            "Test: [120/261]\tTime 0.028 (0.026)\tLoss 0.8248 (0.7255)\tPrec@1 88.000 (85.736)\tPrec@5 97.000 (98.248)\n",
            "Test: [130/261]\tTime 0.014 (0.026)\tLoss 0.8151 (0.7301)\tPrec@1 87.000 (85.672)\tPrec@5 97.000 (98.229)\n",
            "Test: [140/261]\tTime 0.047 (0.026)\tLoss 0.9331 (0.7279)\tPrec@1 83.000 (85.702)\tPrec@5 98.000 (98.241)\n",
            "Test: [150/261]\tTime 0.012 (0.025)\tLoss 0.4752 (0.7295)\tPrec@1 88.000 (85.742)\tPrec@5 98.000 (98.232)\n",
            "Test: [160/261]\tTime 0.039 (0.025)\tLoss 0.3569 (0.7325)\tPrec@1 88.000 (85.745)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.028 (0.025)\tLoss 0.6120 (0.7278)\tPrec@1 91.000 (85.825)\tPrec@5 98.000 (98.216)\n",
            "Test: [180/261]\tTime 0.020 (0.025)\tLoss 0.5619 (0.7272)\tPrec@1 89.000 (85.823)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.018 (0.025)\tLoss 0.5739 (0.7234)\tPrec@1 84.000 (85.832)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.016 (0.025)\tLoss 0.6185 (0.7256)\tPrec@1 88.000 (85.791)\tPrec@5 98.000 (98.254)\n",
            "Test: [210/261]\tTime 0.009 (0.025)\tLoss 0.5617 (0.7269)\tPrec@1 89.000 (85.777)\tPrec@5 98.000 (98.227)\n",
            "Test: [220/261]\tTime 0.028 (0.025)\tLoss 0.6530 (0.7224)\tPrec@1 87.000 (85.783)\tPrec@5 98.000 (98.235)\n",
            "Test: [230/261]\tTime 0.019 (0.025)\tLoss 0.8992 (0.7230)\tPrec@1 82.000 (85.727)\tPrec@5 96.000 (98.208)\n",
            "Test: [240/261]\tTime 0.023 (0.025)\tLoss 0.7250 (0.7270)\tPrec@1 86.000 (85.739)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.025 (0.025)\tLoss 0.3724 (0.7207)\tPrec@1 87.000 (85.785)\tPrec@5 100.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2276 (0.7224)\tPrec@1 93.750 (85.783)\tPrec@5 96.875 (98.187)\n",
            "val Results: Prec@1 85.783 Prec@5 98.187 Loss 0.72242\n",
            "val Class Accuracy: [0.698,0.968,0.932,0.879,0.893,0.857,0.784,0.799,0.746,0.676]\n",
            "Best Prec@1: 85.875\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [185][0/66], lr: 0.00000\tTime 0.462 (0.462)\tData 0.367 (0.367)\tLoss 0.0088 (0.0088)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][10/66], lr: 0.00000\tTime 0.071 (0.132)\tData 0.000 (0.050)\tLoss 0.0117 (0.0101)\tPrec@1 99.609 (99.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][20/66], lr: 0.00000\tTime 0.094 (0.114)\tData 0.005 (0.034)\tLoss 0.0056 (0.0102)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][30/66], lr: 0.00000\tTime 0.154 (0.111)\tData 0.077 (0.029)\tLoss 0.0035 (0.0094)\tPrec@1 100.000 (99.811)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][40/66], lr: 0.00000\tTime 0.137 (0.118)\tData 0.011 (0.033)\tLoss 0.0083 (0.0094)\tPrec@1 100.000 (99.790)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][50/66], lr: 0.00000\tTime 0.197 (0.123)\tData 0.143 (0.037)\tLoss 0.0103 (0.0095)\tPrec@1 99.609 (99.786)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [185][60/66], lr: 0.00000\tTime 0.075 (0.121)\tData 0.000 (0.036)\tLoss 0.0121 (0.0099)\tPrec@1 99.609 (99.776)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.285 (0.285)\tLoss 0.7146 (0.7146)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.032 (0.048)\tLoss 1.1935 (0.7658)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.023 (0.037)\tLoss 1.1663 (0.7750)\tPrec@1 79.000 (84.000)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.039 (0.032)\tLoss 0.6340 (0.7329)\tPrec@1 87.000 (85.161)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.046 (0.031)\tLoss 0.7396 (0.7022)\tPrec@1 87.000 (85.659)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.022 (0.029)\tLoss 0.4669 (0.6970)\tPrec@1 88.000 (85.843)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.029 (0.029)\tLoss 0.7132 (0.7022)\tPrec@1 87.000 (85.951)\tPrec@5 99.000 (98.475)\n",
            "Test: [70/261]\tTime 0.023 (0.027)\tLoss 0.5781 (0.7040)\tPrec@1 84.000 (85.930)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.022 (0.028)\tLoss 0.6172 (0.7066)\tPrec@1 85.000 (85.988)\tPrec@5 99.000 (98.395)\n",
            "Test: [90/261]\tTime 0.050 (0.027)\tLoss 0.7686 (0.7343)\tPrec@1 87.000 (85.549)\tPrec@5 97.000 (98.308)\n",
            "Test: [100/261]\tTime 0.024 (0.027)\tLoss 0.9343 (0.7271)\tPrec@1 83.000 (85.752)\tPrec@5 97.000 (98.257)\n",
            "Test: [110/261]\tTime 0.024 (0.027)\tLoss 0.8093 (0.7214)\tPrec@1 88.000 (85.784)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.027 (0.026)\tLoss 0.8144 (0.7231)\tPrec@1 87.000 (85.785)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8183 (0.7276)\tPrec@1 88.000 (85.725)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.027 (0.026)\tLoss 0.9188 (0.7253)\tPrec@1 84.000 (85.759)\tPrec@5 98.000 (98.234)\n",
            "Test: [150/261]\tTime 0.026 (0.026)\tLoss 0.4777 (0.7270)\tPrec@1 88.000 (85.808)\tPrec@5 98.000 (98.225)\n",
            "Test: [160/261]\tTime 0.045 (0.026)\tLoss 0.3531 (0.7297)\tPrec@1 88.000 (85.807)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.012 (0.026)\tLoss 0.6229 (0.7251)\tPrec@1 91.000 (85.901)\tPrec@5 98.000 (98.216)\n",
            "Test: [180/261]\tTime 0.025 (0.026)\tLoss 0.5625 (0.7243)\tPrec@1 89.000 (85.906)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.013 (0.026)\tLoss 0.5556 (0.7207)\tPrec@1 85.000 (85.937)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.021 (0.026)\tLoss 0.6274 (0.7229)\tPrec@1 88.000 (85.881)\tPrec@5 98.000 (98.254)\n",
            "Test: [210/261]\tTime 0.010 (0.026)\tLoss 0.5696 (0.7244)\tPrec@1 89.000 (85.896)\tPrec@5 98.000 (98.227)\n",
            "Test: [220/261]\tTime 0.023 (0.026)\tLoss 0.6453 (0.7197)\tPrec@1 87.000 (85.910)\tPrec@5 98.000 (98.235)\n",
            "Test: [230/261]\tTime 0.024 (0.025)\tLoss 0.9006 (0.7202)\tPrec@1 82.000 (85.840)\tPrec@5 96.000 (98.221)\n",
            "Test: [240/261]\tTime 0.031 (0.025)\tLoss 0.7320 (0.7242)\tPrec@1 86.000 (85.838)\tPrec@5 98.000 (98.212)\n",
            "Test: [250/261]\tTime 0.042 (0.025)\tLoss 0.3906 (0.7179)\tPrec@1 87.000 (85.904)\tPrec@5 100.000 (98.223)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2335 (0.7196)\tPrec@1 93.750 (85.906)\tPrec@5 96.875 (98.206)\n",
            "val Results: Prec@1 85.906 Prec@5 98.206 Loss 0.71957\n",
            "val Class Accuracy: [0.695,0.968,0.936,0.871,0.899,0.860,0.787,0.796,0.754,0.682]\n",
            "Best Prec@1: 85.906\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [186][0/66], lr: 0.00000\tTime 0.612 (0.612)\tData 0.529 (0.529)\tLoss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][10/66], lr: 0.00000\tTime 0.087 (0.143)\tData 0.000 (0.056)\tLoss 0.0114 (0.0106)\tPrec@1 99.609 (99.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][20/66], lr: 0.00000\tTime 0.074 (0.119)\tData 0.005 (0.032)\tLoss 0.0086 (0.0108)\tPrec@1 100.000 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][30/66], lr: 0.00000\tTime 0.078 (0.112)\tData 0.009 (0.024)\tLoss 0.0044 (0.0111)\tPrec@1 100.000 (99.698)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][40/66], lr: 0.00000\tTime 0.078 (0.107)\tData 0.005 (0.020)\tLoss 0.0023 (0.0100)\tPrec@1 100.000 (99.743)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][50/66], lr: 0.00000\tTime 0.092 (0.104)\tData 0.003 (0.018)\tLoss 0.0058 (0.0096)\tPrec@1 100.000 (99.778)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [186][60/66], lr: 0.00000\tTime 0.068 (0.101)\tData 0.000 (0.016)\tLoss 0.0026 (0.0097)\tPrec@1 100.000 (99.757)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.284 (0.284)\tLoss 0.7286 (0.7286)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.067 (0.053)\tLoss 1.1958 (0.7665)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.043 (0.041)\tLoss 1.1611 (0.7744)\tPrec@1 78.000 (83.952)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.023 (0.034)\tLoss 0.6373 (0.7323)\tPrec@1 87.000 (85.097)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.030 (0.032)\tLoss 0.7305 (0.7012)\tPrec@1 87.000 (85.707)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.010 (0.031)\tLoss 0.4637 (0.6959)\tPrec@1 89.000 (85.882)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.022 (0.030)\tLoss 0.7109 (0.7014)\tPrec@1 87.000 (86.049)\tPrec@5 99.000 (98.475)\n",
            "Test: [70/261]\tTime 0.029 (0.029)\tLoss 0.5655 (0.7031)\tPrec@1 88.000 (86.099)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.022 (0.029)\tLoss 0.6154 (0.7055)\tPrec@1 85.000 (86.160)\tPrec@5 99.000 (98.383)\n",
            "Test: [90/261]\tTime 0.026 (0.028)\tLoss 0.7618 (0.7332)\tPrec@1 87.000 (85.725)\tPrec@5 97.000 (98.297)\n",
            "Test: [100/261]\tTime 0.017 (0.028)\tLoss 0.9309 (0.7259)\tPrec@1 84.000 (85.921)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.035 (0.028)\tLoss 0.8094 (0.7201)\tPrec@1 88.000 (85.946)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.029 (0.027)\tLoss 0.8189 (0.7216)\tPrec@1 87.000 (85.983)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.025 (0.027)\tLoss 0.8190 (0.7265)\tPrec@1 87.000 (85.916)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.028 (0.027)\tLoss 0.9294 (0.7242)\tPrec@1 83.000 (85.922)\tPrec@5 98.000 (98.227)\n",
            "Test: [150/261]\tTime 0.016 (0.026)\tLoss 0.4754 (0.7259)\tPrec@1 88.000 (85.960)\tPrec@5 98.000 (98.219)\n",
            "Test: [160/261]\tTime 0.056 (0.027)\tLoss 0.3496 (0.7287)\tPrec@1 88.000 (85.932)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.032 (0.027)\tLoss 0.6212 (0.7241)\tPrec@1 91.000 (86.029)\tPrec@5 98.000 (98.216)\n",
            "Test: [180/261]\tTime 0.034 (0.026)\tLoss 0.5638 (0.7233)\tPrec@1 89.000 (86.044)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.021 (0.026)\tLoss 0.5567 (0.7196)\tPrec@1 85.000 (86.052)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.011 (0.026)\tLoss 0.6213 (0.7217)\tPrec@1 88.000 (86.010)\tPrec@5 98.000 (98.254)\n",
            "Test: [210/261]\tTime 0.015 (0.026)\tLoss 0.5515 (0.7231)\tPrec@1 89.000 (86.009)\tPrec@5 98.000 (98.227)\n",
            "Test: [220/261]\tTime 0.037 (0.026)\tLoss 0.6399 (0.7185)\tPrec@1 87.000 (86.018)\tPrec@5 98.000 (98.231)\n",
            "Test: [230/261]\tTime 0.026 (0.026)\tLoss 0.8972 (0.7189)\tPrec@1 82.000 (85.957)\tPrec@5 96.000 (98.216)\n",
            "Test: [240/261]\tTime 0.023 (0.026)\tLoss 0.7336 (0.7230)\tPrec@1 86.000 (85.959)\tPrec@5 98.000 (98.207)\n",
            "Test: [250/261]\tTime 0.030 (0.026)\tLoss 0.3838 (0.7167)\tPrec@1 87.000 (86.024)\tPrec@5 100.000 (98.219)\n",
            "Test: [260/261]\tTime 0.005 (0.026)\tLoss 0.2286 (0.7183)\tPrec@1 93.750 (86.029)\tPrec@5 96.875 (98.198)\n",
            "val Results: Prec@1 86.029 Prec@5 98.198 Loss 0.71835\n",
            "val Class Accuracy: [0.709,0.966,0.933,0.873,0.902,0.864,0.786,0.803,0.748,0.687]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [187][0/66], lr: 0.00000\tTime 0.588 (0.588)\tData 0.505 (0.505)\tLoss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][10/66], lr: 0.00000\tTime 0.083 (0.142)\tData 0.004 (0.052)\tLoss 0.0082 (0.0062)\tPrec@1 99.609 (99.893)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][20/66], lr: 0.00000\tTime 0.139 (0.120)\tData 0.080 (0.035)\tLoss 0.0057 (0.0081)\tPrec@1 100.000 (99.833)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][30/66], lr: 0.00000\tTime 0.109 (0.112)\tData 0.000 (0.026)\tLoss 0.0045 (0.0079)\tPrec@1 100.000 (99.849)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][40/66], lr: 0.00000\tTime 0.091 (0.108)\tData 0.012 (0.021)\tLoss 0.0277 (0.0088)\tPrec@1 99.609 (99.819)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][50/66], lr: 0.00000\tTime 0.101 (0.105)\tData 0.000 (0.018)\tLoss 0.0044 (0.0096)\tPrec@1 100.000 (99.770)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [187][60/66], lr: 0.00000\tTime 0.076 (0.102)\tData 0.000 (0.016)\tLoss 0.0132 (0.0102)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.293 (0.293)\tLoss 0.7448 (0.7448)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.025 (0.051)\tLoss 1.1852 (0.7764)\tPrec@1 81.000 (84.000)\tPrec@5 99.000 (98.364)\n",
            "Test: [20/261]\tTime 0.030 (0.038)\tLoss 1.1745 (0.7876)\tPrec@1 78.000 (83.810)\tPrec@5 96.000 (98.143)\n",
            "Test: [30/261]\tTime 0.027 (0.034)\tLoss 0.6226 (0.7444)\tPrec@1 87.000 (85.000)\tPrec@5 98.000 (98.323)\n",
            "Test: [40/261]\tTime 0.020 (0.030)\tLoss 0.7541 (0.7124)\tPrec@1 87.000 (85.537)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.016 (0.029)\tLoss 0.4842 (0.7060)\tPrec@1 87.000 (85.745)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.7318 (0.7114)\tPrec@1 86.000 (85.836)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.018 (0.028)\tLoss 0.5845 (0.7129)\tPrec@1 87.000 (85.887)\tPrec@5 99.000 (98.380)\n",
            "Test: [80/261]\tTime 0.015 (0.027)\tLoss 0.6210 (0.7149)\tPrec@1 85.000 (85.963)\tPrec@5 99.000 (98.358)\n",
            "Test: [90/261]\tTime 0.028 (0.028)\tLoss 0.7724 (0.7422)\tPrec@1 88.000 (85.571)\tPrec@5 97.000 (98.242)\n",
            "Test: [100/261]\tTime 0.018 (0.027)\tLoss 0.9286 (0.7347)\tPrec@1 83.000 (85.723)\tPrec@5 97.000 (98.208)\n",
            "Test: [110/261]\tTime 0.023 (0.027)\tLoss 0.8055 (0.7289)\tPrec@1 89.000 (85.757)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.027 (0.027)\tLoss 0.8147 (0.7308)\tPrec@1 87.000 (85.769)\tPrec@5 97.000 (98.198)\n",
            "Test: [130/261]\tTime 0.030 (0.027)\tLoss 0.8140 (0.7354)\tPrec@1 87.000 (85.695)\tPrec@5 97.000 (98.183)\n",
            "Test: [140/261]\tTime 0.025 (0.026)\tLoss 0.9434 (0.7333)\tPrec@1 83.000 (85.716)\tPrec@5 98.000 (98.206)\n",
            "Test: [150/261]\tTime 0.017 (0.026)\tLoss 0.4718 (0.7347)\tPrec@1 88.000 (85.742)\tPrec@5 98.000 (98.192)\n",
            "Test: [160/261]\tTime 0.019 (0.026)\tLoss 0.3511 (0.7375)\tPrec@1 89.000 (85.739)\tPrec@5 100.000 (98.180)\n",
            "Test: [170/261]\tTime 0.017 (0.026)\tLoss 0.6124 (0.7330)\tPrec@1 91.000 (85.819)\tPrec@5 98.000 (98.187)\n",
            "Test: [180/261]\tTime 0.034 (0.026)\tLoss 0.5781 (0.7320)\tPrec@1 89.000 (85.834)\tPrec@5 96.000 (98.177)\n",
            "Test: [190/261]\tTime 0.024 (0.026)\tLoss 0.5684 (0.7282)\tPrec@1 85.000 (85.848)\tPrec@5 100.000 (98.230)\n",
            "Test: [200/261]\tTime 0.023 (0.026)\tLoss 0.6310 (0.7305)\tPrec@1 88.000 (85.781)\tPrec@5 98.000 (98.234)\n",
            "Test: [210/261]\tTime 0.034 (0.026)\tLoss 0.5434 (0.7317)\tPrec@1 88.000 (85.777)\tPrec@5 98.000 (98.213)\n",
            "Test: [220/261]\tTime 0.022 (0.026)\tLoss 0.6518 (0.7272)\tPrec@1 87.000 (85.796)\tPrec@5 97.000 (98.217)\n",
            "Test: [230/261]\tTime 0.019 (0.026)\tLoss 0.9119 (0.7276)\tPrec@1 83.000 (85.732)\tPrec@5 96.000 (98.195)\n",
            "Test: [240/261]\tTime 0.032 (0.025)\tLoss 0.7296 (0.7317)\tPrec@1 86.000 (85.730)\tPrec@5 98.000 (98.183)\n",
            "Test: [250/261]\tTime 0.020 (0.025)\tLoss 0.3860 (0.7252)\tPrec@1 87.000 (85.801)\tPrec@5 100.000 (98.191)\n",
            "Test: [260/261]\tTime 0.006 (0.025)\tLoss 0.2269 (0.7268)\tPrec@1 96.875 (85.806)\tPrec@5 96.875 (98.171)\n",
            "val Results: Prec@1 85.806 Prec@5 98.171 Loss 0.72684\n",
            "val Class Accuracy: [0.708,0.966,0.941,0.875,0.893,0.868,0.775,0.797,0.746,0.656]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [188][0/66], lr: 0.00000\tTime 0.425 (0.425)\tData 0.353 (0.353)\tLoss 0.0076 (0.0076)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][10/66], lr: 0.00000\tTime 0.090 (0.138)\tData 0.004 (0.049)\tLoss 0.0151 (0.0105)\tPrec@1 100.000 (99.787)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][20/66], lr: 0.00000\tTime 0.077 (0.116)\tData 0.000 (0.028)\tLoss 0.0059 (0.0099)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][30/66], lr: 0.00000\tTime 0.088 (0.109)\tData 0.000 (0.020)\tLoss 0.0044 (0.0097)\tPrec@1 100.000 (99.811)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][40/66], lr: 0.00000\tTime 0.105 (0.105)\tData 0.000 (0.017)\tLoss 0.0158 (0.0107)\tPrec@1 99.609 (99.762)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][50/66], lr: 0.00000\tTime 0.072 (0.103)\tData 0.000 (0.014)\tLoss 0.0381 (0.0119)\tPrec@1 98.438 (99.701)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [188][60/66], lr: 0.00000\tTime 0.078 (0.100)\tData 0.000 (0.012)\tLoss 0.0143 (0.0120)\tPrec@1 99.609 (99.673)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.293 (0.293)\tLoss 0.7280 (0.7280)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.032 (0.049)\tLoss 1.1976 (0.7744)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.015 (0.036)\tLoss 1.1621 (0.7816)\tPrec@1 78.000 (83.952)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.036 (0.033)\tLoss 0.6358 (0.7389)\tPrec@1 87.000 (85.161)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.023 (0.031)\tLoss 0.7374 (0.7083)\tPrec@1 87.000 (85.585)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.024 (0.030)\tLoss 0.4851 (0.7031)\tPrec@1 87.000 (85.745)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 0.7200 (0.7080)\tPrec@1 87.000 (85.869)\tPrec@5 99.000 (98.475)\n",
            "Test: [70/261]\tTime 0.017 (0.028)\tLoss 0.5780 (0.7095)\tPrec@1 85.000 (85.887)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.037 (0.028)\tLoss 0.6213 (0.7115)\tPrec@1 85.000 (85.975)\tPrec@5 99.000 (98.420)\n",
            "Test: [90/261]\tTime 0.023 (0.027)\tLoss 0.7662 (0.7387)\tPrec@1 88.000 (85.593)\tPrec@5 97.000 (98.330)\n",
            "Test: [100/261]\tTime 0.016 (0.027)\tLoss 0.9268 (0.7314)\tPrec@1 83.000 (85.802)\tPrec@5 97.000 (98.267)\n",
            "Test: [110/261]\tTime 0.021 (0.027)\tLoss 0.8152 (0.7255)\tPrec@1 88.000 (85.820)\tPrec@5 98.000 (98.243)\n",
            "Test: [120/261]\tTime 0.010 (0.027)\tLoss 0.8109 (0.7272)\tPrec@1 87.000 (85.826)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.013 (0.026)\tLoss 0.8211 (0.7318)\tPrec@1 87.000 (85.763)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.019 (0.026)\tLoss 0.9392 (0.7294)\tPrec@1 83.000 (85.780)\tPrec@5 98.000 (98.234)\n",
            "Test: [150/261]\tTime 0.029 (0.026)\tLoss 0.4724 (0.7310)\tPrec@1 88.000 (85.775)\tPrec@5 98.000 (98.219)\n",
            "Test: [160/261]\tTime 0.012 (0.026)\tLoss 0.3542 (0.7337)\tPrec@1 88.000 (85.764)\tPrec@5 100.000 (98.217)\n",
            "Test: [170/261]\tTime 0.033 (0.026)\tLoss 0.6237 (0.7292)\tPrec@1 91.000 (85.871)\tPrec@5 98.000 (98.222)\n",
            "Test: [180/261]\tTime 0.021 (0.026)\tLoss 0.5770 (0.7283)\tPrec@1 89.000 (85.878)\tPrec@5 96.000 (98.210)\n",
            "Test: [190/261]\tTime 0.023 (0.026)\tLoss 0.5565 (0.7245)\tPrec@1 85.000 (85.874)\tPrec@5 100.000 (98.262)\n",
            "Test: [200/261]\tTime 0.010 (0.025)\tLoss 0.6278 (0.7266)\tPrec@1 88.000 (85.826)\tPrec@5 98.000 (98.259)\n",
            "Test: [210/261]\tTime 0.022 (0.025)\tLoss 0.5492 (0.7279)\tPrec@1 89.000 (85.844)\tPrec@5 99.000 (98.237)\n",
            "Test: [220/261]\tTime 0.012 (0.025)\tLoss 0.6361 (0.7233)\tPrec@1 87.000 (85.855)\tPrec@5 97.000 (98.235)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.9064 (0.7237)\tPrec@1 82.000 (85.805)\tPrec@5 96.000 (98.216)\n",
            "Test: [240/261]\tTime 0.058 (0.025)\tLoss 0.7392 (0.7277)\tPrec@1 86.000 (85.817)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.009 (0.025)\tLoss 0.3868 (0.7214)\tPrec@1 87.000 (85.876)\tPrec@5 100.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2280 (0.7232)\tPrec@1 93.750 (85.867)\tPrec@5 96.875 (98.195)\n",
            "val Results: Prec@1 85.867 Prec@5 98.195 Loss 0.72317\n",
            "val Class Accuracy: [0.702,0.966,0.939,0.876,0.902,0.857,0.777,0.801,0.752,0.663]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [189][0/66], lr: 0.00000\tTime 0.569 (0.569)\tData 0.478 (0.478)\tLoss 0.0044 (0.0044)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][10/66], lr: 0.00000\tTime 0.076 (0.140)\tData 0.006 (0.055)\tLoss 0.0063 (0.0090)\tPrec@1 100.000 (99.858)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][20/66], lr: 0.00000\tTime 0.118 (0.119)\tData 0.006 (0.032)\tLoss 0.0087 (0.0082)\tPrec@1 100.000 (99.888)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][30/66], lr: 0.00000\tTime 0.100 (0.109)\tData 0.004 (0.023)\tLoss 0.0067 (0.0096)\tPrec@1 100.000 (99.836)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][40/66], lr: 0.00000\tTime 0.097 (0.104)\tData 0.000 (0.019)\tLoss 0.0062 (0.0095)\tPrec@1 100.000 (99.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][50/66], lr: 0.00000\tTime 0.091 (0.102)\tData 0.005 (0.016)\tLoss 0.0275 (0.0100)\tPrec@1 98.828 (99.793)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [189][60/66], lr: 0.00000\tTime 0.078 (0.100)\tData 0.000 (0.015)\tLoss 0.0073 (0.0102)\tPrec@1 100.000 (99.769)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.285 (0.285)\tLoss 0.7472 (0.7472)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.017 (0.048)\tLoss 1.2188 (0.7868)\tPrec@1 82.000 (83.727)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.017 (0.036)\tLoss 1.1815 (0.7941)\tPrec@1 78.000 (83.762)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.025 (0.032)\tLoss 0.6439 (0.7509)\tPrec@1 87.000 (84.935)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.024 (0.030)\tLoss 0.7426 (0.7187)\tPrec@1 87.000 (85.390)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.037 (0.029)\tLoss 0.4955 (0.7129)\tPrec@1 87.000 (85.569)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.020 (0.028)\tLoss 0.7377 (0.7180)\tPrec@1 87.000 (85.721)\tPrec@5 99.000 (98.443)\n",
            "Test: [70/261]\tTime 0.027 (0.028)\tLoss 0.5960 (0.7197)\tPrec@1 84.000 (85.718)\tPrec@5 99.000 (98.423)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 0.6352 (0.7223)\tPrec@1 85.000 (85.815)\tPrec@5 99.000 (98.407)\n",
            "Test: [90/261]\tTime 0.024 (0.027)\tLoss 0.7918 (0.7500)\tPrec@1 87.000 (85.396)\tPrec@5 97.000 (98.297)\n",
            "Test: [100/261]\tTime 0.038 (0.027)\tLoss 0.9228 (0.7421)\tPrec@1 83.000 (85.574)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.017 (0.026)\tLoss 0.8279 (0.7363)\tPrec@1 88.000 (85.613)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.044 (0.027)\tLoss 0.8295 (0.7380)\tPrec@1 87.000 (85.603)\tPrec@5 97.000 (98.215)\n",
            "Test: [130/261]\tTime 0.031 (0.026)\tLoss 0.8229 (0.7423)\tPrec@1 87.000 (85.527)\tPrec@5 97.000 (98.198)\n",
            "Test: [140/261]\tTime 0.020 (0.026)\tLoss 0.9471 (0.7400)\tPrec@1 83.000 (85.560)\tPrec@5 98.000 (98.213)\n",
            "Test: [150/261]\tTime 0.023 (0.026)\tLoss 0.4806 (0.7415)\tPrec@1 87.000 (85.556)\tPrec@5 98.000 (98.199)\n",
            "Test: [160/261]\tTime 0.024 (0.026)\tLoss 0.3679 (0.7442)\tPrec@1 87.000 (85.553)\tPrec@5 100.000 (98.193)\n",
            "Test: [170/261]\tTime 0.021 (0.026)\tLoss 0.6219 (0.7395)\tPrec@1 91.000 (85.637)\tPrec@5 98.000 (98.199)\n",
            "Test: [180/261]\tTime 0.019 (0.026)\tLoss 0.5766 (0.7388)\tPrec@1 89.000 (85.657)\tPrec@5 96.000 (98.188)\n",
            "Test: [190/261]\tTime 0.026 (0.026)\tLoss 0.5784 (0.7350)\tPrec@1 84.000 (85.670)\tPrec@5 100.000 (98.241)\n",
            "Test: [200/261]\tTime 0.030 (0.026)\tLoss 0.6386 (0.7371)\tPrec@1 88.000 (85.607)\tPrec@5 98.000 (98.244)\n",
            "Test: [210/261]\tTime 0.022 (0.026)\tLoss 0.5558 (0.7383)\tPrec@1 89.000 (85.597)\tPrec@5 99.000 (98.218)\n",
            "Test: [220/261]\tTime 0.021 (0.026)\tLoss 0.6616 (0.7338)\tPrec@1 87.000 (85.602)\tPrec@5 98.000 (98.231)\n",
            "Test: [230/261]\tTime 0.016 (0.025)\tLoss 0.9228 (0.7344)\tPrec@1 82.000 (85.545)\tPrec@5 96.000 (98.203)\n",
            "Test: [240/261]\tTime 0.010 (0.025)\tLoss 0.7385 (0.7384)\tPrec@1 86.000 (85.552)\tPrec@5 98.000 (98.191)\n",
            "Test: [250/261]\tTime 0.043 (0.025)\tLoss 0.3919 (0.7320)\tPrec@1 87.000 (85.614)\tPrec@5 100.000 (98.203)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2317 (0.7339)\tPrec@1 93.750 (85.606)\tPrec@5 96.875 (98.183)\n",
            "val Results: Prec@1 85.606 Prec@5 98.183 Loss 0.73387\n",
            "val Class Accuracy: [0.696,0.969,0.936,0.878,0.893,0.860,0.780,0.791,0.743,0.654]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [190][0/66], lr: 0.00000\tTime 0.610 (0.610)\tData 0.530 (0.530)\tLoss 0.0179 (0.0179)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][10/66], lr: 0.00000\tTime 0.076 (0.138)\tData 0.000 (0.053)\tLoss 0.0063 (0.0088)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][20/66], lr: 0.00000\tTime 0.076 (0.117)\tData 0.000 (0.030)\tLoss 0.0207 (0.0107)\tPrec@1 99.219 (99.684)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][30/66], lr: 0.00000\tTime 0.116 (0.111)\tData 0.002 (0.023)\tLoss 0.0176 (0.0107)\tPrec@1 99.219 (99.660)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][40/66], lr: 0.00000\tTime 0.103 (0.106)\tData 0.006 (0.019)\tLoss 0.0092 (0.0107)\tPrec@1 100.000 (99.686)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][50/66], lr: 0.00000\tTime 0.077 (0.104)\tData 0.000 (0.016)\tLoss 0.0048 (0.0099)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [190][60/66], lr: 0.00000\tTime 0.077 (0.102)\tData 0.000 (0.015)\tLoss 0.0095 (0.0100)\tPrec@1 100.000 (99.712)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.208 (0.208)\tLoss 0.7544 (0.7544)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.025 (0.050)\tLoss 1.2162 (0.7849)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.028 (0.037)\tLoss 1.1910 (0.7942)\tPrec@1 77.000 (83.810)\tPrec@5 96.000 (98.143)\n",
            "Test: [30/261]\tTime 0.011 (0.032)\tLoss 0.6413 (0.7508)\tPrec@1 87.000 (84.935)\tPrec@5 98.000 (98.323)\n",
            "Test: [40/261]\tTime 0.039 (0.030)\tLoss 0.7383 (0.7192)\tPrec@1 87.000 (85.415)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.017 (0.029)\tLoss 0.4942 (0.7136)\tPrec@1 87.000 (85.569)\tPrec@5 99.000 (98.510)\n",
            "Test: [60/261]\tTime 0.018 (0.028)\tLoss 0.7434 (0.7185)\tPrec@1 87.000 (85.672)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.024 (0.027)\tLoss 0.5968 (0.7209)\tPrec@1 85.000 (85.690)\tPrec@5 99.000 (98.380)\n",
            "Test: [80/261]\tTime 0.029 (0.027)\tLoss 0.6428 (0.7243)\tPrec@1 85.000 (85.704)\tPrec@5 99.000 (98.358)\n",
            "Test: [90/261]\tTime 0.033 (0.027)\tLoss 0.7843 (0.7519)\tPrec@1 87.000 (85.319)\tPrec@5 97.000 (98.242)\n",
            "Test: [100/261]\tTime 0.021 (0.026)\tLoss 0.9250 (0.7444)\tPrec@1 83.000 (85.505)\tPrec@5 97.000 (98.198)\n",
            "Test: [110/261]\tTime 0.019 (0.026)\tLoss 0.8259 (0.7380)\tPrec@1 88.000 (85.541)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.027 (0.027)\tLoss 0.8366 (0.7398)\tPrec@1 86.000 (85.562)\tPrec@5 97.000 (98.207)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8288 (0.7442)\tPrec@1 87.000 (85.496)\tPrec@5 97.000 (98.183)\n",
            "Test: [140/261]\tTime 0.024 (0.026)\tLoss 0.9623 (0.7418)\tPrec@1 83.000 (85.518)\tPrec@5 98.000 (98.199)\n",
            "Test: [150/261]\tTime 0.019 (0.026)\tLoss 0.4876 (0.7435)\tPrec@1 88.000 (85.536)\tPrec@5 98.000 (98.185)\n",
            "Test: [160/261]\tTime 0.018 (0.026)\tLoss 0.3813 (0.7463)\tPrec@1 87.000 (85.528)\tPrec@5 100.000 (98.180)\n",
            "Test: [170/261]\tTime 0.018 (0.026)\tLoss 0.6363 (0.7416)\tPrec@1 91.000 (85.626)\tPrec@5 98.000 (98.181)\n",
            "Test: [180/261]\tTime 0.025 (0.026)\tLoss 0.5779 (0.7407)\tPrec@1 89.000 (85.646)\tPrec@5 96.000 (98.171)\n",
            "Test: [190/261]\tTime 0.028 (0.026)\tLoss 0.5664 (0.7367)\tPrec@1 84.000 (85.665)\tPrec@5 100.000 (98.225)\n",
            "Test: [200/261]\tTime 0.036 (0.026)\tLoss 0.6470 (0.7387)\tPrec@1 87.000 (85.602)\tPrec@5 98.000 (98.224)\n",
            "Test: [210/261]\tTime 0.026 (0.025)\tLoss 0.5547 (0.7400)\tPrec@1 89.000 (85.611)\tPrec@5 99.000 (98.199)\n",
            "Test: [220/261]\tTime 0.042 (0.025)\tLoss 0.6582 (0.7356)\tPrec@1 87.000 (85.620)\tPrec@5 98.000 (98.204)\n",
            "Test: [230/261]\tTime 0.019 (0.025)\tLoss 0.9208 (0.7362)\tPrec@1 82.000 (85.563)\tPrec@5 96.000 (98.177)\n",
            "Test: [240/261]\tTime 0.022 (0.025)\tLoss 0.7426 (0.7403)\tPrec@1 86.000 (85.564)\tPrec@5 98.000 (98.154)\n",
            "Test: [250/261]\tTime 0.023 (0.025)\tLoss 0.4086 (0.7340)\tPrec@1 87.000 (85.625)\tPrec@5 100.000 (98.167)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2280 (0.7357)\tPrec@1 93.750 (85.614)\tPrec@5 96.875 (98.145)\n",
            "val Results: Prec@1 85.614 Prec@5 98.145 Loss 0.73571\n",
            "val Class Accuracy: [0.698,0.968,0.933,0.875,0.901,0.860,0.770,0.790,0.741,0.667]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [191][0/66], lr: 0.00000\tTime 0.583 (0.583)\tData 0.532 (0.532)\tLoss 0.0075 (0.0075)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][10/66], lr: 0.00000\tTime 0.081 (0.138)\tData 0.012 (0.058)\tLoss 0.0109 (0.0097)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][20/66], lr: 0.00000\tTime 0.095 (0.116)\tData 0.031 (0.036)\tLoss 0.0129 (0.0109)\tPrec@1 99.219 (99.647)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][30/66], lr: 0.00000\tTime 0.093 (0.109)\tData 0.007 (0.027)\tLoss 0.0090 (0.0099)\tPrec@1 100.000 (99.710)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][40/66], lr: 0.00000\tTime 0.104 (0.106)\tData 0.000 (0.022)\tLoss 0.0044 (0.0098)\tPrec@1 100.000 (99.743)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][50/66], lr: 0.00000\tTime 0.094 (0.104)\tData 0.005 (0.018)\tLoss 0.0064 (0.0091)\tPrec@1 100.000 (99.770)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [191][60/66], lr: 0.00000\tTime 0.079 (0.101)\tData 0.000 (0.016)\tLoss 0.0110 (0.0090)\tPrec@1 99.609 (99.776)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.299 (0.299)\tLoss 0.7229 (0.7229)\tPrec@1 81.000 (81.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.022 (0.050)\tLoss 1.1965 (0.7850)\tPrec@1 82.000 (83.545)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.020 (0.036)\tLoss 1.1840 (0.7940)\tPrec@1 79.000 (83.524)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.027 (0.032)\tLoss 0.6201 (0.7492)\tPrec@1 86.000 (84.774)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.023 (0.031)\tLoss 0.7497 (0.7183)\tPrec@1 87.000 (85.366)\tPrec@5 98.000 (98.439)\n",
            "Test: [50/261]\tTime 0.020 (0.029)\tLoss 0.4978 (0.7121)\tPrec@1 87.000 (85.588)\tPrec@5 99.000 (98.431)\n",
            "Test: [60/261]\tTime 0.011 (0.028)\tLoss 0.7391 (0.7171)\tPrec@1 87.000 (85.705)\tPrec@5 99.000 (98.344)\n",
            "Test: [70/261]\tTime 0.023 (0.028)\tLoss 0.5948 (0.7191)\tPrec@1 85.000 (85.718)\tPrec@5 99.000 (98.324)\n",
            "Test: [80/261]\tTime 0.023 (0.027)\tLoss 0.6321 (0.7221)\tPrec@1 85.000 (85.790)\tPrec@5 99.000 (98.296)\n",
            "Test: [90/261]\tTime 0.010 (0.026)\tLoss 0.7899 (0.7493)\tPrec@1 88.000 (85.407)\tPrec@5 97.000 (98.187)\n",
            "Test: [100/261]\tTime 0.016 (0.027)\tLoss 0.9342 (0.7419)\tPrec@1 82.000 (85.594)\tPrec@5 97.000 (98.149)\n",
            "Test: [110/261]\tTime 0.033 (0.027)\tLoss 0.8162 (0.7363)\tPrec@1 89.000 (85.631)\tPrec@5 98.000 (98.162)\n",
            "Test: [120/261]\tTime 0.020 (0.027)\tLoss 0.8209 (0.7382)\tPrec@1 87.000 (85.628)\tPrec@5 97.000 (98.157)\n",
            "Test: [130/261]\tTime 0.017 (0.026)\tLoss 0.8180 (0.7426)\tPrec@1 87.000 (85.565)\tPrec@5 97.000 (98.145)\n",
            "Test: [140/261]\tTime 0.021 (0.026)\tLoss 0.9411 (0.7402)\tPrec@1 82.000 (85.574)\tPrec@5 98.000 (98.156)\n",
            "Test: [150/261]\tTime 0.039 (0.026)\tLoss 0.4887 (0.7417)\tPrec@1 87.000 (85.570)\tPrec@5 98.000 (98.146)\n",
            "Test: [160/261]\tTime 0.031 (0.026)\tLoss 0.3708 (0.7440)\tPrec@1 89.000 (85.571)\tPrec@5 100.000 (98.149)\n",
            "Test: [170/261]\tTime 0.029 (0.026)\tLoss 0.6356 (0.7397)\tPrec@1 91.000 (85.655)\tPrec@5 98.000 (98.158)\n",
            "Test: [180/261]\tTime 0.031 (0.026)\tLoss 0.5855 (0.7390)\tPrec@1 89.000 (85.669)\tPrec@5 96.000 (98.149)\n",
            "Test: [190/261]\tTime 0.036 (0.026)\tLoss 0.5918 (0.7354)\tPrec@1 85.000 (85.691)\tPrec@5 100.000 (98.199)\n",
            "Test: [200/261]\tTime 0.025 (0.025)\tLoss 0.6350 (0.7374)\tPrec@1 87.000 (85.637)\tPrec@5 98.000 (98.194)\n",
            "Test: [210/261]\tTime 0.018 (0.025)\tLoss 0.5643 (0.7389)\tPrec@1 89.000 (85.626)\tPrec@5 99.000 (98.171)\n",
            "Test: [220/261]\tTime 0.024 (0.025)\tLoss 0.6496 (0.7342)\tPrec@1 86.000 (85.647)\tPrec@5 98.000 (98.176)\n",
            "Test: [230/261]\tTime 0.018 (0.025)\tLoss 0.9349 (0.7348)\tPrec@1 81.000 (85.580)\tPrec@5 96.000 (98.156)\n",
            "Test: [240/261]\tTime 0.018 (0.025)\tLoss 0.7401 (0.7388)\tPrec@1 86.000 (85.581)\tPrec@5 98.000 (98.137)\n",
            "Test: [250/261]\tTime 0.026 (0.025)\tLoss 0.4066 (0.7324)\tPrec@1 87.000 (85.657)\tPrec@5 100.000 (98.147)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2419 (0.7342)\tPrec@1 93.750 (85.652)\tPrec@5 96.875 (98.133)\n",
            "val Results: Prec@1 85.652 Prec@5 98.133 Loss 0.73419\n",
            "val Class Accuracy: [0.696,0.968,0.942,0.868,0.895,0.860,0.789,0.800,0.735,0.650]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [192][0/66], lr: 0.00000\tTime 0.503 (0.503)\tData 0.426 (0.426)\tLoss 0.0118 (0.0118)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][10/66], lr: 0.00000\tTime 0.104 (0.137)\tData 0.000 (0.044)\tLoss 0.0085 (0.0102)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][20/66], lr: 0.00000\tTime 0.090 (0.116)\tData 0.006 (0.025)\tLoss 0.0034 (0.0096)\tPrec@1 100.000 (99.777)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][30/66], lr: 0.00000\tTime 0.107 (0.110)\tData 0.000 (0.018)\tLoss 0.0063 (0.0097)\tPrec@1 100.000 (99.786)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][40/66], lr: 0.00000\tTime 0.077 (0.105)\tData 0.000 (0.016)\tLoss 0.0044 (0.0095)\tPrec@1 100.000 (99.762)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][50/66], lr: 0.00000\tTime 0.095 (0.102)\tData 0.003 (0.014)\tLoss 0.0044 (0.0100)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [192][60/66], lr: 0.00000\tTime 0.077 (0.099)\tData 0.000 (0.012)\tLoss 0.0077 (0.0098)\tPrec@1 99.609 (99.757)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.255 (0.255)\tLoss 0.7453 (0.7453)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.040 (0.049)\tLoss 1.2105 (0.7772)\tPrec@1 82.000 (84.091)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.023 (0.038)\tLoss 1.1678 (0.7838)\tPrec@1 77.000 (84.048)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.009 (0.032)\tLoss 0.6533 (0.7416)\tPrec@1 85.000 (85.097)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.052 (0.031)\tLoss 0.7298 (0.7096)\tPrec@1 87.000 (85.610)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/261]\tTime 0.016 (0.030)\tLoss 0.4744 (0.7039)\tPrec@1 87.000 (85.725)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.043 (0.029)\tLoss 0.7316 (0.7100)\tPrec@1 87.000 (85.803)\tPrec@5 99.000 (98.459)\n",
            "Test: [70/261]\tTime 0.021 (0.028)\tLoss 0.5775 (0.7117)\tPrec@1 86.000 (85.859)\tPrec@5 99.000 (98.423)\n",
            "Test: [80/261]\tTime 0.024 (0.028)\tLoss 0.6201 (0.7142)\tPrec@1 85.000 (85.901)\tPrec@5 99.000 (98.395)\n",
            "Test: [90/261]\tTime 0.028 (0.028)\tLoss 0.7798 (0.7420)\tPrec@1 88.000 (85.505)\tPrec@5 97.000 (98.297)\n",
            "Test: [100/261]\tTime 0.031 (0.027)\tLoss 0.9155 (0.7342)\tPrec@1 84.000 (85.723)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.014 (0.027)\tLoss 0.8239 (0.7283)\tPrec@1 88.000 (85.757)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 0.8290 (0.7298)\tPrec@1 86.000 (85.769)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.023 (0.026)\tLoss 0.8187 (0.7344)\tPrec@1 87.000 (85.702)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.029 (0.026)\tLoss 0.9407 (0.7320)\tPrec@1 83.000 (85.723)\tPrec@5 98.000 (98.227)\n",
            "Test: [150/261]\tTime 0.024 (0.026)\tLoss 0.4778 (0.7336)\tPrec@1 87.000 (85.748)\tPrec@5 98.000 (98.219)\n",
            "Test: [160/261]\tTime 0.020 (0.026)\tLoss 0.3608 (0.7366)\tPrec@1 87.000 (85.733)\tPrec@5 100.000 (98.205)\n",
            "Test: [170/261]\tTime 0.022 (0.026)\tLoss 0.6171 (0.7320)\tPrec@1 91.000 (85.819)\tPrec@5 98.000 (98.211)\n",
            "Test: [180/261]\tTime 0.031 (0.025)\tLoss 0.5703 (0.7312)\tPrec@1 89.000 (85.834)\tPrec@5 96.000 (98.199)\n",
            "Test: [190/261]\tTime 0.028 (0.025)\tLoss 0.5631 (0.7271)\tPrec@1 84.000 (85.848)\tPrec@5 100.000 (98.251)\n",
            "Test: [200/261]\tTime 0.038 (0.025)\tLoss 0.6366 (0.7293)\tPrec@1 88.000 (85.801)\tPrec@5 98.000 (98.249)\n",
            "Test: [210/261]\tTime 0.028 (0.025)\tLoss 0.5545 (0.7306)\tPrec@1 89.000 (85.791)\tPrec@5 98.000 (98.223)\n",
            "Test: [220/261]\tTime 0.032 (0.025)\tLoss 0.6562 (0.7261)\tPrec@1 87.000 (85.801)\tPrec@5 98.000 (98.222)\n",
            "Test: [230/261]\tTime 0.028 (0.025)\tLoss 0.9123 (0.7266)\tPrec@1 82.000 (85.749)\tPrec@5 96.000 (98.208)\n",
            "Test: [240/261]\tTime 0.022 (0.025)\tLoss 0.7328 (0.7306)\tPrec@1 86.000 (85.755)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.033 (0.025)\tLoss 0.3766 (0.7242)\tPrec@1 87.000 (85.809)\tPrec@5 100.000 (98.207)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2234 (0.7260)\tPrec@1 96.875 (85.810)\tPrec@5 96.875 (98.187)\n",
            "val Results: Prec@1 85.810 Prec@5 98.187 Loss 0.72598\n",
            "val Class Accuracy: [0.712,0.967,0.934,0.881,0.899,0.856,0.780,0.792,0.739,0.675]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [193][0/66], lr: 0.00000\tTime 0.504 (0.504)\tData 0.430 (0.430)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][10/66], lr: 0.00000\tTime 0.095 (0.131)\tData 0.000 (0.047)\tLoss 0.0192 (0.0086)\tPrec@1 99.609 (99.787)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][20/66], lr: 0.00000\tTime 0.101 (0.112)\tData 0.004 (0.026)\tLoss 0.0165 (0.0094)\tPrec@1 99.609 (99.777)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][30/66], lr: 0.00000\tTime 0.101 (0.106)\tData 0.004 (0.019)\tLoss 0.0148 (0.0099)\tPrec@1 99.609 (99.798)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][40/66], lr: 0.00000\tTime 0.101 (0.102)\tData 0.004 (0.015)\tLoss 0.0131 (0.0097)\tPrec@1 99.609 (99.809)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][50/66], lr: 0.00000\tTime 0.088 (0.101)\tData 0.000 (0.013)\tLoss 0.0114 (0.0101)\tPrec@1 99.609 (99.778)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [193][60/66], lr: 0.00000\tTime 0.071 (0.099)\tData 0.000 (0.012)\tLoss 0.0056 (0.0102)\tPrec@1 100.000 (99.757)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.297 (0.297)\tLoss 0.7387 (0.7387)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.039 (0.050)\tLoss 1.2125 (0.7798)\tPrec@1 82.000 (83.818)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.030 (0.037)\tLoss 1.1821 (0.7862)\tPrec@1 78.000 (83.810)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.021 (0.032)\tLoss 0.6411 (0.7433)\tPrec@1 86.000 (84.935)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.014 (0.029)\tLoss 0.7403 (0.7122)\tPrec@1 87.000 (85.463)\tPrec@5 98.000 (98.537)\n",
            "Test: [50/261]\tTime 0.032 (0.029)\tLoss 0.4906 (0.7072)\tPrec@1 87.000 (85.647)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.022 (0.028)\tLoss 0.7214 (0.7120)\tPrec@1 87.000 (85.787)\tPrec@5 99.000 (98.443)\n",
            "Test: [70/261]\tTime 0.040 (0.028)\tLoss 0.5911 (0.7139)\tPrec@1 85.000 (85.775)\tPrec@5 99.000 (98.408)\n",
            "Test: [80/261]\tTime 0.016 (0.027)\tLoss 0.6345 (0.7165)\tPrec@1 85.000 (85.852)\tPrec@5 99.000 (98.395)\n",
            "Test: [90/261]\tTime 0.028 (0.026)\tLoss 0.7778 (0.7440)\tPrec@1 88.000 (85.462)\tPrec@5 97.000 (98.308)\n",
            "Test: [100/261]\tTime 0.016 (0.026)\tLoss 0.9282 (0.7366)\tPrec@1 84.000 (85.683)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.024 (0.026)\tLoss 0.8243 (0.7306)\tPrec@1 88.000 (85.721)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.021 (0.026)\tLoss 0.8249 (0.7326)\tPrec@1 87.000 (85.727)\tPrec@5 97.000 (98.223)\n",
            "Test: [130/261]\tTime 0.024 (0.026)\tLoss 0.8233 (0.7371)\tPrec@1 87.000 (85.656)\tPrec@5 97.000 (98.206)\n",
            "Test: [140/261]\tTime 0.031 (0.025)\tLoss 0.9453 (0.7349)\tPrec@1 83.000 (85.667)\tPrec@5 98.000 (98.220)\n",
            "Test: [150/261]\tTime 0.018 (0.025)\tLoss 0.4761 (0.7364)\tPrec@1 88.000 (85.669)\tPrec@5 98.000 (98.212)\n",
            "Test: [160/261]\tTime 0.030 (0.025)\tLoss 0.3646 (0.7390)\tPrec@1 88.000 (85.665)\tPrec@5 100.000 (98.217)\n",
            "Test: [170/261]\tTime 0.030 (0.025)\tLoss 0.6250 (0.7345)\tPrec@1 91.000 (85.766)\tPrec@5 98.000 (98.222)\n",
            "Test: [180/261]\tTime 0.029 (0.025)\tLoss 0.5749 (0.7336)\tPrec@1 89.000 (85.790)\tPrec@5 96.000 (98.210)\n",
            "Test: [190/261]\tTime 0.014 (0.025)\tLoss 0.5684 (0.7299)\tPrec@1 84.000 (85.791)\tPrec@5 100.000 (98.262)\n",
            "Test: [200/261]\tTime 0.026 (0.025)\tLoss 0.6390 (0.7320)\tPrec@1 87.000 (85.726)\tPrec@5 98.000 (98.264)\n",
            "Test: [210/261]\tTime 0.027 (0.025)\tLoss 0.5571 (0.7333)\tPrec@1 89.000 (85.744)\tPrec@5 99.000 (98.242)\n",
            "Test: [220/261]\tTime 0.034 (0.025)\tLoss 0.6466 (0.7288)\tPrec@1 87.000 (85.756)\tPrec@5 98.000 (98.244)\n",
            "Test: [230/261]\tTime 0.014 (0.025)\tLoss 0.9116 (0.7293)\tPrec@1 82.000 (85.714)\tPrec@5 96.000 (98.216)\n",
            "Test: [240/261]\tTime 0.040 (0.025)\tLoss 0.7433 (0.7334)\tPrec@1 86.000 (85.718)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.033 (0.025)\tLoss 0.3981 (0.7271)\tPrec@1 87.000 (85.777)\tPrec@5 100.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2312 (0.7288)\tPrec@1 93.750 (85.768)\tPrec@5 96.875 (98.195)\n",
            "val Results: Prec@1 85.768 Prec@5 98.195 Loss 0.72884\n",
            "val Class Accuracy: [0.700,0.968,0.937,0.874,0.897,0.857,0.776,0.803,0.754,0.658]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [194][0/66], lr: 0.00000\tTime 0.632 (0.632)\tData 0.538 (0.538)\tLoss 0.0070 (0.0070)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][10/66], lr: 0.00000\tTime 0.108 (0.142)\tData 0.000 (0.053)\tLoss 0.0020 (0.0061)\tPrec@1 100.000 (99.929)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][20/66], lr: 0.00000\tTime 0.087 (0.119)\tData 0.002 (0.030)\tLoss 0.0053 (0.0073)\tPrec@1 100.000 (99.870)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][30/66], lr: 0.00000\tTime 0.083 (0.110)\tData 0.000 (0.021)\tLoss 0.0109 (0.0079)\tPrec@1 99.609 (99.836)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][40/66], lr: 0.00000\tTime 0.077 (0.106)\tData 0.000 (0.017)\tLoss 0.0060 (0.0077)\tPrec@1 100.000 (99.848)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][50/66], lr: 0.00000\tTime 0.093 (0.103)\tData 0.003 (0.016)\tLoss 0.0047 (0.0085)\tPrec@1 100.000 (99.824)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [194][60/66], lr: 0.00000\tTime 0.076 (0.100)\tData 0.000 (0.014)\tLoss 0.0054 (0.0085)\tPrec@1 100.000 (99.821)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.238 (0.238)\tLoss 0.7442 (0.7442)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.015 (0.045)\tLoss 1.2149 (0.7773)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.024 (0.037)\tLoss 1.1850 (0.7848)\tPrec@1 77.000 (83.762)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.016 (0.032)\tLoss 0.6428 (0.7415)\tPrec@1 87.000 (84.968)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.017 (0.029)\tLoss 0.7344 (0.7098)\tPrec@1 87.000 (85.488)\tPrec@5 98.000 (98.585)\n",
            "Test: [50/261]\tTime 0.014 (0.029)\tLoss 0.4867 (0.7048)\tPrec@1 87.000 (85.686)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.035 (0.028)\tLoss 0.7296 (0.7101)\tPrec@1 87.000 (85.803)\tPrec@5 99.000 (98.475)\n",
            "Test: [70/261]\tTime 0.032 (0.027)\tLoss 0.5835 (0.7122)\tPrec@1 86.000 (85.845)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.021 (0.027)\tLoss 0.6282 (0.7152)\tPrec@1 85.000 (85.864)\tPrec@5 99.000 (98.407)\n",
            "Test: [90/261]\tTime 0.020 (0.026)\tLoss 0.7811 (0.7427)\tPrec@1 88.000 (85.462)\tPrec@5 97.000 (98.319)\n",
            "Test: [100/261]\tTime 0.029 (0.026)\tLoss 0.9269 (0.7352)\tPrec@1 83.000 (85.663)\tPrec@5 97.000 (98.257)\n",
            "Test: [110/261]\tTime 0.029 (0.025)\tLoss 0.8229 (0.7291)\tPrec@1 88.000 (85.694)\tPrec@5 98.000 (98.252)\n",
            "Test: [120/261]\tTime 0.014 (0.025)\tLoss 0.8305 (0.7309)\tPrec@1 87.000 (85.736)\tPrec@5 97.000 (98.264)\n",
            "Test: [130/261]\tTime 0.011 (0.025)\tLoss 0.8186 (0.7355)\tPrec@1 87.000 (85.679)\tPrec@5 97.000 (98.244)\n",
            "Test: [140/261]\tTime 0.017 (0.025)\tLoss 0.9441 (0.7332)\tPrec@1 83.000 (85.695)\tPrec@5 98.000 (98.248)\n",
            "Test: [150/261]\tTime 0.035 (0.025)\tLoss 0.4804 (0.7348)\tPrec@1 88.000 (85.709)\tPrec@5 98.000 (98.238)\n",
            "Test: [160/261]\tTime 0.021 (0.025)\tLoss 0.3659 (0.7376)\tPrec@1 87.000 (85.696)\tPrec@5 100.000 (98.230)\n",
            "Test: [170/261]\tTime 0.021 (0.025)\tLoss 0.6254 (0.7330)\tPrec@1 91.000 (85.789)\tPrec@5 98.000 (98.234)\n",
            "Test: [180/261]\tTime 0.026 (0.025)\tLoss 0.5759 (0.7322)\tPrec@1 89.000 (85.801)\tPrec@5 96.000 (98.221)\n",
            "Test: [190/261]\tTime 0.009 (0.025)\tLoss 0.5720 (0.7283)\tPrec@1 85.000 (85.822)\tPrec@5 100.000 (98.272)\n",
            "Test: [200/261]\tTime 0.025 (0.025)\tLoss 0.6362 (0.7303)\tPrec@1 87.000 (85.756)\tPrec@5 98.000 (98.269)\n",
            "Test: [210/261]\tTime 0.020 (0.025)\tLoss 0.5552 (0.7317)\tPrec@1 89.000 (85.758)\tPrec@5 98.000 (98.237)\n",
            "Test: [220/261]\tTime 0.031 (0.025)\tLoss 0.6498 (0.7272)\tPrec@1 87.000 (85.769)\tPrec@5 98.000 (98.240)\n",
            "Test: [230/261]\tTime 0.027 (0.025)\tLoss 0.9087 (0.7277)\tPrec@1 82.000 (85.719)\tPrec@5 96.000 (98.221)\n",
            "Test: [240/261]\tTime 0.027 (0.025)\tLoss 0.7307 (0.7319)\tPrec@1 86.000 (85.718)\tPrec@5 98.000 (98.199)\n",
            "Test: [250/261]\tTime 0.031 (0.025)\tLoss 0.3906 (0.7256)\tPrec@1 87.000 (85.773)\tPrec@5 100.000 (98.211)\n",
            "Test: [260/261]\tTime 0.005 (0.024)\tLoss 0.2301 (0.7272)\tPrec@1 93.750 (85.760)\tPrec@5 96.875 (98.191)\n",
            "val Results: Prec@1 85.760 Prec@5 98.191 Loss 0.72721\n",
            "val Class Accuracy: [0.706,0.969,0.935,0.875,0.897,0.859,0.774,0.797,0.746,0.668]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [195][0/66], lr: 0.00000\tTime 0.608 (0.608)\tData 0.529 (0.529)\tLoss 0.0110 (0.0110)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][10/66], lr: 0.00000\tTime 0.088 (0.137)\tData 0.000 (0.052)\tLoss 0.0102 (0.0080)\tPrec@1 99.609 (99.858)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][20/66], lr: 0.00000\tTime 0.088 (0.114)\tData 0.000 (0.030)\tLoss 0.0048 (0.0093)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][30/66], lr: 0.00000\tTime 0.092 (0.108)\tData 0.004 (0.022)\tLoss 0.0127 (0.0092)\tPrec@1 99.219 (99.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][40/66], lr: 0.00000\tTime 0.091 (0.103)\tData 0.000 (0.018)\tLoss 0.0033 (0.0096)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][50/66], lr: 0.00000\tTime 0.080 (0.101)\tData 0.004 (0.016)\tLoss 0.0079 (0.0090)\tPrec@1 100.000 (99.786)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [195][60/66], lr: 0.00000\tTime 0.069 (0.099)\tData 0.000 (0.014)\tLoss 0.0185 (0.0095)\tPrec@1 99.609 (99.763)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.224 (0.224)\tLoss 0.7589 (0.7589)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.020 (0.047)\tLoss 1.2302 (0.7956)\tPrec@1 82.000 (83.727)\tPrec@5 99.000 (98.182)\n",
            "Test: [20/261]\tTime 0.026 (0.037)\tLoss 1.1919 (0.8024)\tPrec@1 78.000 (83.571)\tPrec@5 96.000 (98.048)\n",
            "Test: [30/261]\tTime 0.033 (0.033)\tLoss 0.6560 (0.7595)\tPrec@1 86.000 (84.677)\tPrec@5 98.000 (98.258)\n",
            "Test: [40/261]\tTime 0.026 (0.030)\tLoss 0.7460 (0.7275)\tPrec@1 86.000 (85.146)\tPrec@5 98.000 (98.463)\n",
            "Test: [50/261]\tTime 0.049 (0.030)\tLoss 0.4974 (0.7219)\tPrec@1 87.000 (85.294)\tPrec@5 99.000 (98.471)\n",
            "Test: [60/261]\tTime 0.023 (0.028)\tLoss 0.7421 (0.7260)\tPrec@1 86.000 (85.459)\tPrec@5 99.000 (98.361)\n",
            "Test: [70/261]\tTime 0.030 (0.028)\tLoss 0.6162 (0.7283)\tPrec@1 83.000 (85.437)\tPrec@5 99.000 (98.338)\n",
            "Test: [80/261]\tTime 0.015 (0.028)\tLoss 0.6564 (0.7313)\tPrec@1 85.000 (85.506)\tPrec@5 99.000 (98.333)\n",
            "Test: [90/261]\tTime 0.038 (0.027)\tLoss 0.7960 (0.7590)\tPrec@1 87.000 (85.132)\tPrec@5 97.000 (98.231)\n",
            "Test: [100/261]\tTime 0.031 (0.027)\tLoss 0.9208 (0.7512)\tPrec@1 85.000 (85.347)\tPrec@5 97.000 (98.178)\n",
            "Test: [110/261]\tTime 0.011 (0.027)\tLoss 0.8432 (0.7451)\tPrec@1 88.000 (85.405)\tPrec@5 98.000 (98.180)\n",
            "Test: [120/261]\tTime 0.052 (0.026)\tLoss 0.8308 (0.7469)\tPrec@1 86.000 (85.380)\tPrec@5 97.000 (98.157)\n",
            "Test: [130/261]\tTime 0.030 (0.026)\tLoss 0.8289 (0.7509)\tPrec@1 87.000 (85.321)\tPrec@5 97.000 (98.145)\n",
            "Test: [140/261]\tTime 0.022 (0.026)\tLoss 0.9622 (0.7487)\tPrec@1 83.000 (85.348)\tPrec@5 98.000 (98.163)\n",
            "Test: [150/261]\tTime 0.024 (0.026)\tLoss 0.4886 (0.7502)\tPrec@1 88.000 (85.344)\tPrec@5 98.000 (98.152)\n",
            "Test: [160/261]\tTime 0.035 (0.026)\tLoss 0.3875 (0.7529)\tPrec@1 87.000 (85.360)\tPrec@5 100.000 (98.149)\n",
            "Test: [170/261]\tTime 0.032 (0.026)\tLoss 0.6405 (0.7482)\tPrec@1 91.000 (85.468)\tPrec@5 98.000 (98.158)\n",
            "Test: [180/261]\tTime 0.022 (0.026)\tLoss 0.5793 (0.7474)\tPrec@1 89.000 (85.464)\tPrec@5 96.000 (98.149)\n",
            "Test: [190/261]\tTime 0.041 (0.026)\tLoss 0.5815 (0.7434)\tPrec@1 84.000 (85.471)\tPrec@5 100.000 (98.199)\n",
            "Test: [200/261]\tTime 0.049 (0.026)\tLoss 0.6497 (0.7455)\tPrec@1 87.000 (85.413)\tPrec@5 98.000 (98.199)\n",
            "Test: [210/261]\tTime 0.037 (0.026)\tLoss 0.5772 (0.7468)\tPrec@1 89.000 (85.422)\tPrec@5 99.000 (98.175)\n",
            "Test: [220/261]\tTime 0.010 (0.026)\tLoss 0.6676 (0.7422)\tPrec@1 87.000 (85.434)\tPrec@5 98.000 (98.181)\n",
            "Test: [230/261]\tTime 0.010 (0.025)\tLoss 0.9315 (0.7429)\tPrec@1 82.000 (85.381)\tPrec@5 96.000 (98.152)\n",
            "Test: [240/261]\tTime 0.038 (0.025)\tLoss 0.7523 (0.7469)\tPrec@1 86.000 (85.394)\tPrec@5 98.000 (98.137)\n",
            "Test: [250/261]\tTime 0.028 (0.025)\tLoss 0.4146 (0.7406)\tPrec@1 87.000 (85.458)\tPrec@5 100.000 (98.151)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2355 (0.7425)\tPrec@1 93.750 (85.453)\tPrec@5 96.875 (98.129)\n",
            "val Results: Prec@1 85.453 Prec@5 98.129 Loss 0.74252\n",
            "val Class Accuracy: [0.674,0.969,0.937,0.878,0.897,0.854,0.775,0.790,0.745,0.657]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [196][0/66], lr: 0.00000\tTime 0.642 (0.642)\tData 0.567 (0.567)\tLoss 0.0098 (0.0098)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][10/66], lr: 0.00000\tTime 0.103 (0.142)\tData 0.002 (0.056)\tLoss 0.0105 (0.0102)\tPrec@1 99.609 (99.822)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][20/66], lr: 0.00000\tTime 0.107 (0.121)\tData 0.008 (0.032)\tLoss 0.0075 (0.0097)\tPrec@1 100.000 (99.851)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][30/66], lr: 0.00000\tTime 0.099 (0.112)\tData 0.005 (0.023)\tLoss 0.0070 (0.0094)\tPrec@1 100.000 (99.836)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][40/66], lr: 0.00000\tTime 0.093 (0.108)\tData 0.000 (0.019)\tLoss 0.0059 (0.0094)\tPrec@1 100.000 (99.838)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][50/66], lr: 0.00000\tTime 0.079 (0.105)\tData 0.002 (0.016)\tLoss 0.0056 (0.0096)\tPrec@1 100.000 (99.824)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [196][60/66], lr: 0.00000\tTime 0.075 (0.102)\tData 0.000 (0.015)\tLoss 0.0146 (0.0094)\tPrec@1 99.219 (99.833)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.252 (0.252)\tLoss 0.7575 (0.7575)\tPrec@1 82.000 (82.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.025 (0.049)\tLoss 1.2177 (0.7961)\tPrec@1 81.000 (83.455)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.019 (0.037)\tLoss 1.1787 (0.8032)\tPrec@1 79.000 (83.667)\tPrec@5 96.000 (98.095)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.6512 (0.7603)\tPrec@1 84.000 (84.774)\tPrec@5 98.000 (98.290)\n",
            "Test: [40/261]\tTime 0.027 (0.030)\tLoss 0.7553 (0.7285)\tPrec@1 87.000 (85.366)\tPrec@5 98.000 (98.488)\n",
            "Test: [50/261]\tTime 0.019 (0.029)\tLoss 0.4984 (0.7221)\tPrec@1 87.000 (85.490)\tPrec@5 99.000 (98.490)\n",
            "Test: [60/261]\tTime 0.011 (0.028)\tLoss 0.7418 (0.7269)\tPrec@1 87.000 (85.623)\tPrec@5 99.000 (98.393)\n",
            "Test: [70/261]\tTime 0.029 (0.028)\tLoss 0.6062 (0.7284)\tPrec@1 84.000 (85.620)\tPrec@5 99.000 (98.366)\n",
            "Test: [80/261]\tTime 0.009 (0.026)\tLoss 0.6381 (0.7303)\tPrec@1 85.000 (85.728)\tPrec@5 99.000 (98.358)\n",
            "Test: [90/261]\tTime 0.032 (0.026)\tLoss 0.7894 (0.7578)\tPrec@1 88.000 (85.330)\tPrec@5 97.000 (98.264)\n",
            "Test: [100/261]\tTime 0.021 (0.026)\tLoss 0.9196 (0.7499)\tPrec@1 83.000 (85.525)\tPrec@5 97.000 (98.218)\n",
            "Test: [110/261]\tTime 0.034 (0.026)\tLoss 0.8359 (0.7440)\tPrec@1 88.000 (85.559)\tPrec@5 98.000 (98.198)\n",
            "Test: [120/261]\tTime 0.052 (0.026)\tLoss 0.8244 (0.7456)\tPrec@1 86.000 (85.562)\tPrec@5 97.000 (98.182)\n",
            "Test: [130/261]\tTime 0.037 (0.027)\tLoss 0.8267 (0.7500)\tPrec@1 87.000 (85.504)\tPrec@5 97.000 (98.176)\n",
            "Test: [140/261]\tTime 0.047 (0.028)\tLoss 0.9601 (0.7477)\tPrec@1 83.000 (85.532)\tPrec@5 98.000 (98.191)\n",
            "Test: [150/261]\tTime 0.042 (0.029)\tLoss 0.4826 (0.7491)\tPrec@1 88.000 (85.536)\tPrec@5 98.000 (98.172)\n",
            "Test: [160/261]\tTime 0.051 (0.029)\tLoss 0.3718 (0.7519)\tPrec@1 88.000 (85.528)\tPrec@5 100.000 (98.161)\n",
            "Test: [170/261]\tTime 0.021 (0.029)\tLoss 0.6366 (0.7474)\tPrec@1 91.000 (85.626)\tPrec@5 98.000 (98.164)\n",
            "Test: [180/261]\tTime 0.032 (0.030)\tLoss 0.5865 (0.7465)\tPrec@1 89.000 (85.652)\tPrec@5 96.000 (98.155)\n",
            "Test: [190/261]\tTime 0.030 (0.030)\tLoss 0.5762 (0.7425)\tPrec@1 84.000 (85.660)\tPrec@5 100.000 (98.209)\n",
            "Test: [200/261]\tTime 0.043 (0.030)\tLoss 0.6406 (0.7446)\tPrec@1 88.000 (85.612)\tPrec@5 98.000 (98.214)\n",
            "Test: [210/261]\tTime 0.039 (0.031)\tLoss 0.5655 (0.7458)\tPrec@1 89.000 (85.611)\tPrec@5 98.000 (98.185)\n",
            "Test: [220/261]\tTime 0.021 (0.031)\tLoss 0.6614 (0.7412)\tPrec@1 87.000 (85.638)\tPrec@5 98.000 (98.195)\n",
            "Test: [230/261]\tTime 0.029 (0.031)\tLoss 0.9345 (0.7416)\tPrec@1 82.000 (85.576)\tPrec@5 95.000 (98.164)\n",
            "Test: [240/261]\tTime 0.036 (0.031)\tLoss 0.7573 (0.7457)\tPrec@1 86.000 (85.589)\tPrec@5 98.000 (98.145)\n",
            "Test: [250/261]\tTime 0.022 (0.030)\tLoss 0.4003 (0.7392)\tPrec@1 87.000 (85.661)\tPrec@5 100.000 (98.155)\n",
            "Test: [260/261]\tTime 0.005 (0.030)\tLoss 0.2316 (0.7412)\tPrec@1 96.875 (85.648)\tPrec@5 96.875 (98.137)\n",
            "val Results: Prec@1 85.648 Prec@5 98.137 Loss 0.74119\n",
            "val Class Accuracy: [0.692,0.966,0.940,0.881,0.899,0.854,0.779,0.797,0.739,0.653]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [197][0/66], lr: 0.00000\tTime 0.607 (0.607)\tData 0.528 (0.528)\tLoss 0.0101 (0.0101)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][10/66], lr: 0.00000\tTime 0.089 (0.138)\tData 0.005 (0.053)\tLoss 0.0056 (0.0073)\tPrec@1 100.000 (99.893)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][20/66], lr: 0.00000\tTime 0.095 (0.118)\tData 0.006 (0.031)\tLoss 0.0034 (0.0070)\tPrec@1 100.000 (99.870)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][30/66], lr: 0.00000\tTime 0.097 (0.110)\tData 0.000 (0.023)\tLoss 0.0105 (0.0083)\tPrec@1 100.000 (99.824)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][40/66], lr: 0.00000\tTime 0.093 (0.106)\tData 0.000 (0.019)\tLoss 0.0057 (0.0089)\tPrec@1 100.000 (99.800)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][50/66], lr: 0.00000\tTime 0.079 (0.103)\tData 0.004 (0.017)\tLoss 0.0180 (0.0089)\tPrec@1 99.219 (99.778)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [197][60/66], lr: 0.00000\tTime 0.072 (0.100)\tData 0.000 (0.015)\tLoss 0.0033 (0.0090)\tPrec@1 100.000 (99.776)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.217 (0.217)\tLoss 0.7282 (0.7282)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.038 (0.051)\tLoss 1.2024 (0.7734)\tPrec@1 81.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.017 (0.037)\tLoss 1.1740 (0.7825)\tPrec@1 78.000 (83.905)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.029 (0.033)\tLoss 0.6437 (0.7403)\tPrec@1 86.000 (85.032)\tPrec@5 98.000 (98.355)\n",
            "Test: [40/261]\tTime 0.012 (0.030)\tLoss 0.7505 (0.7093)\tPrec@1 87.000 (85.537)\tPrec@5 98.000 (98.512)\n",
            "Test: [50/261]\tTime 0.030 (0.029)\tLoss 0.4726 (0.7039)\tPrec@1 86.000 (85.706)\tPrec@5 99.000 (98.490)\n",
            "Test: [60/261]\tTime 0.010 (0.028)\tLoss 0.7296 (0.7094)\tPrec@1 86.000 (85.820)\tPrec@5 99.000 (98.426)\n",
            "Test: [70/261]\tTime 0.031 (0.028)\tLoss 0.5805 (0.7109)\tPrec@1 84.000 (85.845)\tPrec@5 99.000 (98.408)\n",
            "Test: [80/261]\tTime 0.026 (0.028)\tLoss 0.6195 (0.7132)\tPrec@1 85.000 (85.889)\tPrec@5 99.000 (98.383)\n",
            "Test: [90/261]\tTime 0.045 (0.027)\tLoss 0.7758 (0.7410)\tPrec@1 87.000 (85.505)\tPrec@5 97.000 (98.286)\n",
            "Test: [100/261]\tTime 0.016 (0.026)\tLoss 0.9330 (0.7337)\tPrec@1 83.000 (85.693)\tPrec@5 97.000 (98.257)\n",
            "Test: [110/261]\tTime 0.018 (0.027)\tLoss 0.8146 (0.7280)\tPrec@1 88.000 (85.721)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.024 (0.027)\tLoss 0.8162 (0.7296)\tPrec@1 87.000 (85.752)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.036 (0.026)\tLoss 0.8212 (0.7342)\tPrec@1 87.000 (85.656)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.025 (0.026)\tLoss 0.9304 (0.7320)\tPrec@1 84.000 (85.681)\tPrec@5 98.000 (98.241)\n",
            "Test: [150/261]\tTime 0.042 (0.026)\tLoss 0.4773 (0.7336)\tPrec@1 88.000 (85.702)\tPrec@5 98.000 (98.225)\n",
            "Test: [160/261]\tTime 0.015 (0.026)\tLoss 0.3528 (0.7364)\tPrec@1 88.000 (85.714)\tPrec@5 100.000 (98.217)\n",
            "Test: [170/261]\tTime 0.022 (0.026)\tLoss 0.6179 (0.7318)\tPrec@1 91.000 (85.813)\tPrec@5 98.000 (98.222)\n",
            "Test: [180/261]\tTime 0.016 (0.026)\tLoss 0.5656 (0.7309)\tPrec@1 89.000 (85.812)\tPrec@5 96.000 (98.210)\n",
            "Test: [190/261]\tTime 0.018 (0.026)\tLoss 0.5568 (0.7270)\tPrec@1 85.000 (85.832)\tPrec@5 100.000 (98.262)\n",
            "Test: [200/261]\tTime 0.032 (0.026)\tLoss 0.6465 (0.7294)\tPrec@1 88.000 (85.771)\tPrec@5 98.000 (98.264)\n",
            "Test: [210/261]\tTime 0.027 (0.026)\tLoss 0.5613 (0.7308)\tPrec@1 89.000 (85.773)\tPrec@5 98.000 (98.237)\n",
            "Test: [220/261]\tTime 0.025 (0.026)\tLoss 0.6597 (0.7262)\tPrec@1 87.000 (85.774)\tPrec@5 98.000 (98.244)\n",
            "Test: [230/261]\tTime 0.028 (0.026)\tLoss 0.9089 (0.7268)\tPrec@1 82.000 (85.727)\tPrec@5 96.000 (98.229)\n",
            "Test: [240/261]\tTime 0.017 (0.026)\tLoss 0.7363 (0.7307)\tPrec@1 86.000 (85.734)\tPrec@5 98.000 (98.220)\n",
            "Test: [250/261]\tTime 0.012 (0.025)\tLoss 0.3829 (0.7243)\tPrec@1 87.000 (85.797)\tPrec@5 100.000 (98.231)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2280 (0.7261)\tPrec@1 96.875 (85.810)\tPrec@5 96.875 (98.214)\n",
            "val Results: Prec@1 85.810 Prec@5 98.214 Loss 0.72610\n",
            "val Class Accuracy: [0.703,0.967,0.938,0.874,0.897,0.860,0.784,0.787,0.752,0.670]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [198][0/66], lr: 0.00000\tTime 0.587 (0.587)\tData 0.511 (0.511)\tLoss 0.0135 (0.0135)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][10/66], lr: 0.00000\tTime 0.077 (0.139)\tData 0.002 (0.051)\tLoss 0.0094 (0.0103)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][20/66], lr: 0.00000\tTime 0.081 (0.121)\tData 0.011 (0.030)\tLoss 0.0173 (0.0098)\tPrec@1 98.828 (99.740)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][30/66], lr: 0.00000\tTime 0.079 (0.110)\tData 0.006 (0.022)\tLoss 0.0045 (0.0096)\tPrec@1 100.000 (99.735)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][40/66], lr: 0.00000\tTime 0.083 (0.106)\tData 0.001 (0.018)\tLoss 0.0084 (0.0091)\tPrec@1 99.609 (99.762)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][50/66], lr: 0.00000\tTime 0.098 (0.104)\tData 0.005 (0.016)\tLoss 0.0095 (0.0091)\tPrec@1 99.609 (99.763)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [198][60/66], lr: 0.00000\tTime 0.069 (0.101)\tData 0.000 (0.014)\tLoss 0.0076 (0.0095)\tPrec@1 99.609 (99.757)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.288 (0.288)\tLoss 0.7466 (0.7466)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.010 (0.050)\tLoss 1.1886 (0.7769)\tPrec@1 81.000 (84.091)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.028 (0.035)\tLoss 1.1945 (0.7898)\tPrec@1 78.000 (83.762)\tPrec@5 96.000 (98.190)\n",
            "Test: [30/261]\tTime 0.032 (0.033)\tLoss 0.6156 (0.7470)\tPrec@1 87.000 (84.968)\tPrec@5 98.000 (98.323)\n",
            "Test: [40/261]\tTime 0.020 (0.032)\tLoss 0.7668 (0.7163)\tPrec@1 86.000 (85.488)\tPrec@5 98.000 (98.488)\n",
            "Test: [50/261]\tTime 0.026 (0.031)\tLoss 0.4872 (0.7102)\tPrec@1 86.000 (85.686)\tPrec@5 99.000 (98.471)\n",
            "Test: [60/261]\tTime 0.030 (0.030)\tLoss 0.7303 (0.7147)\tPrec@1 86.000 (85.803)\tPrec@5 99.000 (98.361)\n",
            "Test: [70/261]\tTime 0.021 (0.029)\tLoss 0.5951 (0.7171)\tPrec@1 86.000 (85.817)\tPrec@5 99.000 (98.338)\n",
            "Test: [80/261]\tTime 0.010 (0.029)\tLoss 0.6300 (0.7199)\tPrec@1 85.000 (85.827)\tPrec@5 99.000 (98.309)\n",
            "Test: [90/261]\tTime 0.020 (0.028)\tLoss 0.7760 (0.7471)\tPrec@1 87.000 (85.407)\tPrec@5 97.000 (98.187)\n",
            "Test: [100/261]\tTime 0.036 (0.028)\tLoss 0.9457 (0.7401)\tPrec@1 82.000 (85.574)\tPrec@5 97.000 (98.139)\n",
            "Test: [110/261]\tTime 0.017 (0.027)\tLoss 0.8146 (0.7342)\tPrec@1 89.000 (85.604)\tPrec@5 98.000 (98.144)\n",
            "Test: [120/261]\tTime 0.043 (0.027)\tLoss 0.8117 (0.7359)\tPrec@1 86.000 (85.587)\tPrec@5 97.000 (98.140)\n",
            "Test: [130/261]\tTime 0.019 (0.027)\tLoss 0.8230 (0.7406)\tPrec@1 87.000 (85.511)\tPrec@5 97.000 (98.137)\n",
            "Test: [140/261]\tTime 0.040 (0.027)\tLoss 0.9448 (0.7384)\tPrec@1 83.000 (85.539)\tPrec@5 98.000 (98.149)\n",
            "Test: [150/261]\tTime 0.030 (0.027)\tLoss 0.4841 (0.7399)\tPrec@1 89.000 (85.563)\tPrec@5 98.000 (98.139)\n",
            "Test: [160/261]\tTime 0.018 (0.026)\tLoss 0.3605 (0.7425)\tPrec@1 88.000 (85.553)\tPrec@5 100.000 (98.130)\n",
            "Test: [170/261]\tTime 0.020 (0.026)\tLoss 0.6318 (0.7379)\tPrec@1 91.000 (85.667)\tPrec@5 98.000 (98.140)\n",
            "Test: [180/261]\tTime 0.016 (0.026)\tLoss 0.5776 (0.7368)\tPrec@1 89.000 (85.680)\tPrec@5 96.000 (98.133)\n",
            "Test: [190/261]\tTime 0.053 (0.026)\tLoss 0.5612 (0.7332)\tPrec@1 86.000 (85.712)\tPrec@5 100.000 (98.194)\n",
            "Test: [200/261]\tTime 0.018 (0.026)\tLoss 0.6361 (0.7354)\tPrec@1 87.000 (85.652)\tPrec@5 98.000 (98.194)\n",
            "Test: [210/261]\tTime 0.037 (0.026)\tLoss 0.5570 (0.7368)\tPrec@1 89.000 (85.659)\tPrec@5 98.000 (98.171)\n",
            "Test: [220/261]\tTime 0.019 (0.026)\tLoss 0.6560 (0.7321)\tPrec@1 87.000 (85.665)\tPrec@5 98.000 (98.181)\n",
            "Test: [230/261]\tTime 0.039 (0.026)\tLoss 0.9119 (0.7326)\tPrec@1 83.000 (85.593)\tPrec@5 96.000 (98.169)\n",
            "Test: [240/261]\tTime 0.027 (0.026)\tLoss 0.7445 (0.7367)\tPrec@1 86.000 (85.593)\tPrec@5 98.000 (98.158)\n",
            "Test: [250/261]\tTime 0.014 (0.026)\tLoss 0.4182 (0.7304)\tPrec@1 87.000 (85.661)\tPrec@5 100.000 (98.171)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2392 (0.7320)\tPrec@1 93.750 (85.668)\tPrec@5 96.875 (98.152)\n",
            "val Results: Prec@1 85.668 Prec@5 98.152 Loss 0.73196\n",
            "val Class Accuracy: [0.697,0.966,0.939,0.865,0.898,0.868,0.772,0.795,0.748,0.668]\n",
            "Best Prec@1: 86.029\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [199][0/66], lr: 0.00000\tTime 0.612 (0.612)\tData 0.526 (0.526)\tLoss 0.0194 (0.0194)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][10/66], lr: 0.00000\tTime 0.085 (0.141)\tData 0.000 (0.053)\tLoss 0.0217 (0.0104)\tPrec@1 98.828 (99.680)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][20/66], lr: 0.00000\tTime 0.081 (0.120)\tData 0.000 (0.030)\tLoss 0.0036 (0.0090)\tPrec@1 100.000 (99.758)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][30/66], lr: 0.00000\tTime 0.080 (0.111)\tData 0.000 (0.022)\tLoss 0.0108 (0.0092)\tPrec@1 99.609 (99.761)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][40/66], lr: 0.00000\tTime 0.090 (0.106)\tData 0.007 (0.018)\tLoss 0.0057 (0.0097)\tPrec@1 100.000 (99.762)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][50/66], lr: 0.00000\tTime 0.100 (0.103)\tData 0.001 (0.016)\tLoss 0.0058 (0.0097)\tPrec@1 100.000 (99.778)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [199][60/66], lr: 0.00000\tTime 0.077 (0.101)\tData 0.000 (0.014)\tLoss 0.0068 (0.0099)\tPrec@1 99.609 (99.769)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/261]\tTime 0.241 (0.241)\tLoss 0.7213 (0.7213)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.022 (0.049)\tLoss 1.2017 (0.7734)\tPrec@1 82.000 (83.909)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.018 (0.036)\tLoss 1.1587 (0.7810)\tPrec@1 78.000 (84.000)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.025 (0.033)\tLoss 0.6412 (0.7394)\tPrec@1 86.000 (85.065)\tPrec@5 98.000 (98.387)\n",
            "Test: [40/261]\tTime 0.009 (0.030)\tLoss 0.7286 (0.7081)\tPrec@1 87.000 (85.634)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.032 (0.029)\tLoss 0.4678 (0.7020)\tPrec@1 87.000 (85.765)\tPrec@5 99.000 (98.549)\n",
            "Test: [60/261]\tTime 0.040 (0.028)\tLoss 0.7212 (0.7069)\tPrec@1 87.000 (85.902)\tPrec@5 99.000 (98.459)\n",
            "Test: [70/261]\tTime 0.011 (0.027)\tLoss 0.5820 (0.7087)\tPrec@1 84.000 (85.901)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.025 (0.027)\tLoss 0.6233 (0.7113)\tPrec@1 85.000 (85.963)\tPrec@5 99.000 (98.407)\n",
            "Test: [90/261]\tTime 0.017 (0.027)\tLoss 0.7774 (0.7391)\tPrec@1 87.000 (85.538)\tPrec@5 97.000 (98.319)\n",
            "Test: [100/261]\tTime 0.026 (0.026)\tLoss 0.9240 (0.7316)\tPrec@1 83.000 (85.733)\tPrec@5 97.000 (98.267)\n",
            "Test: [110/261]\tTime 0.029 (0.026)\tLoss 0.8198 (0.7259)\tPrec@1 88.000 (85.748)\tPrec@5 98.000 (98.252)\n",
            "Test: [120/261]\tTime 0.037 (0.026)\tLoss 0.8169 (0.7275)\tPrec@1 87.000 (85.760)\tPrec@5 97.000 (98.256)\n",
            "Test: [130/261]\tTime 0.020 (0.026)\tLoss 0.8238 (0.7319)\tPrec@1 87.000 (85.695)\tPrec@5 97.000 (98.237)\n",
            "Test: [140/261]\tTime 0.028 (0.026)\tLoss 0.9314 (0.7296)\tPrec@1 83.000 (85.702)\tPrec@5 98.000 (98.248)\n",
            "Test: [150/261]\tTime 0.031 (0.026)\tLoss 0.4779 (0.7313)\tPrec@1 88.000 (85.715)\tPrec@5 98.000 (98.238)\n",
            "Test: [160/261]\tTime 0.038 (0.025)\tLoss 0.3604 (0.7339)\tPrec@1 89.000 (85.720)\tPrec@5 100.000 (98.236)\n",
            "Test: [170/261]\tTime 0.032 (0.026)\tLoss 0.6251 (0.7293)\tPrec@1 91.000 (85.819)\tPrec@5 98.000 (98.234)\n",
            "Test: [180/261]\tTime 0.013 (0.025)\tLoss 0.5627 (0.7286)\tPrec@1 89.000 (85.823)\tPrec@5 96.000 (98.221)\n",
            "Test: [190/261]\tTime 0.034 (0.025)\tLoss 0.5587 (0.7249)\tPrec@1 84.000 (85.832)\tPrec@5 100.000 (98.272)\n",
            "Test: [200/261]\tTime 0.010 (0.025)\tLoss 0.6263 (0.7271)\tPrec@1 88.000 (85.776)\tPrec@5 98.000 (98.274)\n",
            "Test: [210/261]\tTime 0.027 (0.025)\tLoss 0.5634 (0.7284)\tPrec@1 89.000 (85.773)\tPrec@5 99.000 (98.246)\n",
            "Test: [220/261]\tTime 0.034 (0.026)\tLoss 0.6523 (0.7238)\tPrec@1 87.000 (85.778)\tPrec@5 98.000 (98.253)\n",
            "Test: [230/261]\tTime 0.023 (0.025)\tLoss 0.9103 (0.7245)\tPrec@1 82.000 (85.723)\tPrec@5 96.000 (98.234)\n",
            "Test: [240/261]\tTime 0.017 (0.025)\tLoss 0.7401 (0.7283)\tPrec@1 86.000 (85.726)\tPrec@5 98.000 (98.216)\n",
            "Test: [250/261]\tTime 0.030 (0.025)\tLoss 0.3913 (0.7221)\tPrec@1 87.000 (85.793)\tPrec@5 100.000 (98.223)\n",
            "Test: [260/261]\tTime 0.005 (0.025)\tLoss 0.2333 (0.7239)\tPrec@1 93.750 (85.783)\tPrec@5 96.875 (98.202)\n",
            "val Results: Prec@1 85.783 Prec@5 98.202 Loss 0.72387\n",
            "val Class Accuracy: [0.692,0.968,0.934,0.875,0.901,0.862,0.788,0.797,0.743,0.670]\n",
            "Best Prec@1: 86.029\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test a pretrained checkpoint (on SVHN)"
      ],
      "metadata": {
        "id": "25QfLTPNnJC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset svhn --resume '/content/drive/MyDrive/BDA_Pre-Files/imbalanced-semi-self-master/checkpoint/svhn_resnet32_CE_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' -e"
      ],
      "metadata": {
        "id": "FuOun75gHWJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419d593a-394d-4ac4-a1b7-271e5ca239f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Unlabeled est total:\t12390\n",
            "After processing:\t12385,\t[5000, 2994, 1795, 1073, 645, 383, 230, 137, 80, 48]\n",
            "Labeled data extracted:\t2478\n",
            "10\n",
            "1000\n",
            "599\n",
            "359\n",
            "215\n",
            "129\n",
            "77\n",
            "46\n",
            "27\n",
            "16\n",
            "tcmalloc: large alloc 1631641600 bytes == 0x60cee000 @  0x7f22a4a391e7 0x4b2150 0x5ac2ec 0x7f22180918ba 0x7f22182af9c6 0x7f22182af012 0x7f22182b9c8d 0x7f22182b7e84 0x7f22182ae647 0x4d1b90 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x51b221 0x58f2a7 0x517947 0x5b4a3e 0x4ba80a 0x537e46 0x58ff66 0x51bbc5 0x58f2a7 0x51740e 0x58f2a7 0x51740e\n",
            "Loading pseudo labels from ./data/pseudo_labeled_svhn.pickle\n",
            "Unlabeled data extracted:\t14863\n",
            "64\n",
            "6022\n",
            "3548\n",
            "2154\n",
            "1249\n",
            "815\n",
            "432\n",
            "293\n",
            "183\n",
            "103\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDA_Pre-Files/imbalanced-semi-self-master/checkpoint/svhn_resnet32_CE_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/261]\tTime 5.679 (5.679)\tLoss 0.7286 (0.7286)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.022 (0.535)\tLoss 1.1958 (0.7665)\tPrec@1 82.000 (84.000)\tPrec@5 99.000 (98.273)\n",
            "Test: [20/261]\tTime 0.023 (0.292)\tLoss 1.1611 (0.7744)\tPrec@1 78.000 (83.952)\tPrec@5 96.000 (98.238)\n",
            "Test: [30/261]\tTime 0.010 (0.206)\tLoss 0.6373 (0.7323)\tPrec@1 87.000 (85.097)\tPrec@5 98.000 (98.419)\n",
            "Test: [40/261]\tTime 0.037 (0.161)\tLoss 0.7305 (0.7012)\tPrec@1 87.000 (85.707)\tPrec@5 98.000 (98.561)\n",
            "Test: [50/261]\tTime 0.014 (0.135)\tLoss 0.4637 (0.6959)\tPrec@1 89.000 (85.882)\tPrec@5 99.000 (98.529)\n",
            "Test: [60/261]\tTime 0.013 (0.116)\tLoss 0.7109 (0.7014)\tPrec@1 87.000 (86.049)\tPrec@5 99.000 (98.475)\n",
            "Test: [70/261]\tTime 0.021 (0.103)\tLoss 0.5655 (0.7031)\tPrec@1 88.000 (86.099)\tPrec@5 99.000 (98.437)\n",
            "Test: [80/261]\tTime 0.018 (0.093)\tLoss 0.6154 (0.7055)\tPrec@1 85.000 (86.160)\tPrec@5 99.000 (98.383)\n",
            "Test: [90/261]\tTime 0.021 (0.086)\tLoss 0.7618 (0.7332)\tPrec@1 87.000 (85.725)\tPrec@5 97.000 (98.297)\n",
            "Test: [100/261]\tTime 0.027 (0.079)\tLoss 0.9309 (0.7259)\tPrec@1 84.000 (85.921)\tPrec@5 97.000 (98.248)\n",
            "Test: [110/261]\tTime 0.016 (0.074)\tLoss 0.8094 (0.7201)\tPrec@1 88.000 (85.946)\tPrec@5 98.000 (98.234)\n",
            "Test: [120/261]\tTime 0.025 (0.070)\tLoss 0.8189 (0.7216)\tPrec@1 87.000 (85.983)\tPrec@5 97.000 (98.240)\n",
            "Test: [130/261]\tTime 0.016 (0.066)\tLoss 0.8190 (0.7265)\tPrec@1 87.000 (85.916)\tPrec@5 97.000 (98.221)\n",
            "Test: [140/261]\tTime 0.021 (0.063)\tLoss 0.9294 (0.7242)\tPrec@1 83.000 (85.922)\tPrec@5 98.000 (98.227)\n",
            "Test: [150/261]\tTime 0.035 (0.062)\tLoss 0.4754 (0.7259)\tPrec@1 88.000 (85.960)\tPrec@5 98.000 (98.219)\n",
            "Test: [160/261]\tTime 0.036 (0.059)\tLoss 0.3496 (0.7287)\tPrec@1 88.000 (85.932)\tPrec@5 100.000 (98.211)\n",
            "Test: [170/261]\tTime 0.029 (0.057)\tLoss 0.6212 (0.7241)\tPrec@1 91.000 (86.029)\tPrec@5 98.000 (98.216)\n",
            "Test: [180/261]\tTime 0.053 (0.056)\tLoss 0.5638 (0.7233)\tPrec@1 89.000 (86.044)\tPrec@5 96.000 (98.204)\n",
            "Test: [190/261]\tTime 0.031 (0.054)\tLoss 0.5567 (0.7196)\tPrec@1 85.000 (86.052)\tPrec@5 100.000 (98.257)\n",
            "Test: [200/261]\tTime 0.038 (0.053)\tLoss 0.6213 (0.7217)\tPrec@1 88.000 (86.010)\tPrec@5 98.000 (98.254)\n",
            "Test: [210/261]\tTime 0.019 (0.052)\tLoss 0.5515 (0.7231)\tPrec@1 89.000 (86.009)\tPrec@5 98.000 (98.227)\n",
            "Test: [220/261]\tTime 0.047 (0.051)\tLoss 0.6399 (0.7185)\tPrec@1 87.000 (86.018)\tPrec@5 98.000 (98.231)\n",
            "Test: [230/261]\tTime 0.021 (0.049)\tLoss 0.8972 (0.7189)\tPrec@1 82.000 (85.957)\tPrec@5 96.000 (98.216)\n",
            "Test: [240/261]\tTime 0.047 (0.048)\tLoss 0.7336 (0.7230)\tPrec@1 86.000 (85.959)\tPrec@5 98.000 (98.207)\n",
            "Test: [250/261]\tTime 0.026 (0.047)\tLoss 0.3838 (0.7167)\tPrec@1 87.000 (86.024)\tPrec@5 100.000 (98.219)\n",
            "Test: [260/261]\tTime 0.007 (0.046)\tLoss 0.2286 (0.7183)\tPrec@1 93.750 (86.029)\tPrec@5 96.875 (98.198)\n",
            "val Results: Prec@1 86.029 Prec@5 98.198 Loss 0.71835\n",
            "val Class Accuracy: [0.709,0.966,0.933,0.873,0.902,0.864,0.786,0.803,0.748,0.687]\n"
          ]
        }
      ]
    }
  ]
}