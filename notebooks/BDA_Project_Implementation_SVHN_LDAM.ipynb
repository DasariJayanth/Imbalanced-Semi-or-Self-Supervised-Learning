{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMnf3Xqn6EgA",
        "outputId": "e576dcca-0965-4680-ce7a-075d6a5c69a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorBoardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1TX5LK2HYgx",
        "outputId": "f602a8de-ddda-4512-9b2c-b10e3e8fd501"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TensorBoardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TensorBoardX) (1.21.6)\n",
            "Installing collected packages: TensorBoardX\n",
            "Successfully installed TensorBoardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wlAfnk6HszO",
        "outputId": "00a3de91-4baf-4457-8265-abf96d2a0e88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import yaml\n",
        "import sklearn\n",
        "import tensorboardX"
      ],
      "metadata": {
        "id": "0ycPQC9iHxzo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/BDAProject/imbalanced-semi-self-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtceccWX_ool",
        "outputId": "1c6b90da-aef3-42ad-c060-f0e0fd9bd5bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CslK100MIylmBJU9zN4Vmh1BZXMZZloK/BDAProject/imbalanced-semi-self-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gen_pseudolabels.py --resume \"./checkpoint\" --data_dir \"./data\" --output_dir \"./data\" --output_filename \"./gen_pseudolabels_ouptut\""
      ],
      "metadata": {
        "id": "iHxhl8An7QUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbEuIaOG8GqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Semi-Supervised Imbalance Learning**"
      ],
      "metadata": {
        "id": "34MRc1R2m7-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss Function: LDAMLoss**"
      ],
      "metadata": {
        "id": "dd80OKV_fjvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset svhn --loss_type LDAM --imb_factor 0.02 --imb_factor_unlabel 0.02 --epochs=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq4ZIIkLfu1Y",
        "outputId": "6d999033-5a85-4407-a291-b5ab0523fe38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating folder: log/svhn_resnet32_LDAM_None_exp_0.02_0.02_semi\n",
            "Creating folder: ./checkpoint/svhn_resnet32_LDAM_None_exp_0.02_0.02_semi\n",
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Unlabeled est total:\t13975\n",
            "After processing:\t13970,\t[4998, 3234, 2093, 1355, 876, 565, 364, 236, 153, 96]\n",
            "Labeled data extracted:\t2795\n",
            "20\n",
            "1000\n",
            "647\n",
            "419\n",
            "271\n",
            "175\n",
            "113\n",
            "73\n",
            "47\n",
            "30\n",
            "tcmalloc: large alloc 1631641600 bytes == 0x5f958000 @  0x7f7ac3b681e7 0x4b2590 0x5ad01c 0x7f7a3755d8ba 0x7f7a3777b9c6 0x7f7a3777b012 0x7f7a37785c8d 0x7f7a37783e84 0x7f7a3777a647 0x4d23e0 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc\n",
            "Loading pseudo labels from ./data/pseudo_labeled_svhn.pickle\n",
            "Unlabeled data extracted:\t16765\n",
            "123\n",
            "6056\n",
            "3850\n",
            "2513\n",
            "1564\n",
            "1095\n",
            "637\n",
            "446\n",
            "303\n",
            "178\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "cls num list:\n",
            "[123, 6056, 3850, 2513, 1564, 1095, 637, 446, 303, 178]\n",
            "/content/drive/.shortcut-targets-by-id/1CslK100MIylmBJU9zN4Vmh1BZXMZZloK/BDAProject/imbalanced-semi-self-master/losses.py:45: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  output = torch.where(index, x_m, x)\n",
            "Epoch: [0][0/66], lr: 0.00200\tTime 6.937 (6.937)\tData 0.550 (0.550)\tLoss 14.1821 (14.1821)\tPrec@1 3.516 (3.516)\tPrec@5 42.969 (42.969)\n",
            "Epoch: [0][10/66], lr: 0.00200\tTime 0.086 (0.709)\tData 0.000 (0.053)\tLoss 9.2607 (10.8460)\tPrec@1 35.938 (26.207)\tPrec@5 74.609 (76.456)\n",
            "Epoch: [0][20/66], lr: 0.00200\tTime 0.083 (0.418)\tData 0.010 (0.033)\tLoss 8.3061 (9.9628)\tPrec@1 46.094 (31.696)\tPrec@5 87.109 (79.353)\n",
            "Epoch: [0][30/66], lr: 0.00200\tTime 0.115 (0.316)\tData 0.000 (0.024)\tLoss 7.6403 (9.5178)\tPrec@1 42.969 (34.325)\tPrec@5 87.891 (80.318)\n",
            "Epoch: [0][40/66], lr: 0.00200\tTime 0.153 (0.275)\tData 0.007 (0.026)\tLoss 6.7644 (9.0266)\tPrec@1 53.125 (38.081)\tPrec@5 88.281 (82.250)\n",
            "Epoch: [0][50/66], lr: 0.00200\tTime 0.093 (0.252)\tData 0.000 (0.026)\tLoss 7.2051 (8.6669)\tPrec@1 51.953 (41.253)\tPrec@5 90.234 (83.655)\n",
            "Epoch: [0][60/66], lr: 0.00200\tTime 0.067 (0.233)\tData 0.000 (0.029)\tLoss 7.2337 (8.3553)\tPrec@1 50.000 (43.744)\tPrec@5 92.578 (84.695)\n",
            "Test: [0/261]\tTime 0.373 (0.373)\tLoss 11.5070 (11.5070)\tPrec@1 39.000 (39.000)\tPrec@5 71.000 (71.000)\n",
            "Test: [10/261]\tTime 0.020 (0.055)\tLoss 12.6389 (12.4289)\tPrec@1 33.000 (34.364)\tPrec@5 74.000 (73.455)\n",
            "Test: [20/261]\tTime 0.016 (0.043)\tLoss 11.6489 (12.4905)\tPrec@1 38.000 (33.571)\tPrec@5 75.000 (72.000)\n",
            "Test: [30/261]\tTime 0.028 (0.037)\tLoss 11.1330 (12.3009)\tPrec@1 37.000 (34.613)\tPrec@5 73.000 (72.161)\n",
            "Test: [40/261]\tTime 0.018 (0.035)\tLoss 11.8318 (12.2225)\tPrec@1 36.000 (35.073)\tPrec@5 71.000 (72.610)\n",
            "Test: [50/261]\tTime 0.019 (0.033)\tLoss 12.6477 (12.2175)\tPrec@1 30.000 (35.216)\tPrec@5 69.000 (72.412)\n",
            "Test: [60/261]\tTime 0.028 (0.032)\tLoss 15.0255 (12.2623)\tPrec@1 33.000 (35.197)\tPrec@5 70.000 (72.557)\n",
            "Test: [70/261]\tTime 0.024 (0.031)\tLoss 12.2416 (12.2286)\tPrec@1 35.000 (35.408)\tPrec@5 76.000 (72.549)\n",
            "Test: [80/261]\tTime 0.017 (0.030)\tLoss 11.9072 (12.2307)\tPrec@1 38.000 (35.321)\tPrec@5 75.000 (72.481)\n",
            "Test: [90/261]\tTime 0.028 (0.029)\tLoss 12.1684 (12.2691)\tPrec@1 28.000 (35.363)\tPrec@5 75.000 (72.495)\n",
            "Test: [100/261]\tTime 0.030 (0.029)\tLoss 13.7120 (12.2216)\tPrec@1 34.000 (35.535)\tPrec@5 72.000 (72.772)\n",
            "Test: [110/261]\tTime 0.039 (0.029)\tLoss 13.2606 (12.2124)\tPrec@1 39.000 (35.613)\tPrec@5 74.000 (72.811)\n",
            "Test: [120/261]\tTime 0.019 (0.029)\tLoss 10.3651 (12.2001)\tPrec@1 43.000 (35.587)\tPrec@5 74.000 (72.884)\n",
            "Test: [130/261]\tTime 0.025 (0.029)\tLoss 12.0603 (12.1922)\tPrec@1 39.000 (35.649)\tPrec@5 81.000 (72.985)\n",
            "Test: [140/261]\tTime 0.011 (0.028)\tLoss 13.1003 (12.2056)\tPrec@1 30.000 (35.546)\tPrec@5 72.000 (72.823)\n",
            "Test: [150/261]\tTime 0.026 (0.028)\tLoss 11.7248 (12.2179)\tPrec@1 42.000 (35.477)\tPrec@5 69.000 (72.616)\n",
            "Test: [160/261]\tTime 0.011 (0.028)\tLoss 13.1496 (12.2519)\tPrec@1 38.000 (35.478)\tPrec@5 72.000 (72.590)\n",
            "Test: [170/261]\tTime 0.029 (0.028)\tLoss 11.4393 (12.2418)\tPrec@1 37.000 (35.567)\tPrec@5 78.000 (72.503)\n",
            "Test: [180/261]\tTime 0.036 (0.028)\tLoss 11.4054 (12.2219)\tPrec@1 39.000 (35.547)\tPrec@5 77.000 (72.613)\n",
            "Test: [190/261]\tTime 0.018 (0.028)\tLoss 12.7337 (12.2280)\tPrec@1 44.000 (35.529)\tPrec@5 72.000 (72.607)\n",
            "Test: [200/261]\tTime 0.024 (0.028)\tLoss 11.1647 (12.2243)\tPrec@1 31.000 (35.517)\tPrec@5 80.000 (72.677)\n",
            "Test: [210/261]\tTime 0.029 (0.028)\tLoss 12.5110 (12.2000)\tPrec@1 43.000 (35.654)\tPrec@5 78.000 (72.744)\n",
            "Test: [220/261]\tTime 0.025 (0.028)\tLoss 11.5111 (12.1773)\tPrec@1 49.000 (35.738)\tPrec@5 77.000 (72.828)\n",
            "Test: [230/261]\tTime 0.025 (0.027)\tLoss 13.0133 (12.1883)\tPrec@1 31.000 (35.658)\tPrec@5 66.000 (72.792)\n",
            "Test: [240/261]\tTime 0.037 (0.027)\tLoss 12.2928 (12.1729)\tPrec@1 35.000 (35.639)\tPrec@5 71.000 (72.867)\n",
            "Test: [250/261]\tTime 0.019 (0.027)\tLoss 13.8133 (12.1699)\tPrec@1 30.000 (35.649)\tPrec@5 69.000 (72.900)\n",
            "Test: [260/261]\tTime 0.022 (0.027)\tLoss 12.8106 (12.1747)\tPrec@1 43.750 (35.614)\tPrec@5 81.250 (72.945)\n",
            "val Results: Prec@1 35.614 Prec@5 72.945 Loss 12.17467\n",
            "val Class Accuracy: [0.000,0.963,0.738,0.158,0.010,0.299,0.044,0.007,0.000,0.000]\n",
            "Best Prec@1: 35.614\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [1][0/66], lr: 0.00400\tTime 0.563 (0.563)\tData 0.425 (0.425)\tLoss 7.0208 (7.0208)\tPrec@1 57.422 (57.422)\tPrec@5 90.625 (90.625)\n",
            "Epoch: [1][10/66], lr: 0.00400\tTime 0.091 (0.165)\tData 0.005 (0.072)\tLoss 6.3981 (6.6397)\tPrec@1 59.766 (58.097)\tPrec@5 93.750 (92.791)\n",
            "Epoch: [1][20/66], lr: 0.00400\tTime 0.113 (0.136)\tData 0.000 (0.045)\tLoss 6.0892 (6.3743)\tPrec@1 66.406 (60.677)\tPrec@5 92.969 (92.262)\n",
            "Epoch: [1][30/66], lr: 0.00400\tTime 0.104 (0.127)\tData 0.005 (0.035)\tLoss 5.5906 (6.1969)\tPrec@1 67.578 (62.046)\tPrec@5 92.578 (92.679)\n",
            "Epoch: [1][40/66], lr: 0.00400\tTime 0.095 (0.119)\tData 0.010 (0.028)\tLoss 5.2794 (6.0273)\tPrec@1 69.922 (63.338)\tPrec@5 96.094 (93.074)\n",
            "Epoch: [1][50/66], lr: 0.00400\tTime 0.124 (0.117)\tData 0.007 (0.024)\tLoss 4.8010 (5.8135)\tPrec@1 75.391 (65.035)\tPrec@5 95.703 (93.520)\n",
            "Epoch: [1][60/66], lr: 0.00400\tTime 0.081 (0.113)\tData 0.000 (0.021)\tLoss 4.7622 (5.6142)\tPrec@1 74.219 (66.477)\tPrec@5 94.922 (93.820)\n",
            "Test: [0/261]\tTime 0.323 (0.323)\tLoss 12.0335 (12.0335)\tPrec@1 41.000 (41.000)\tPrec@5 78.000 (78.000)\n",
            "Test: [10/261]\tTime 0.060 (0.058)\tLoss 13.0509 (12.4074)\tPrec@1 36.000 (36.364)\tPrec@5 82.000 (77.545)\n",
            "Test: [20/261]\tTime 0.027 (0.047)\tLoss 13.4326 (12.4295)\tPrec@1 32.000 (35.952)\tPrec@5 73.000 (77.476)\n",
            "Test: [30/261]\tTime 0.026 (0.041)\tLoss 11.8968 (12.2801)\tPrec@1 33.000 (36.581)\tPrec@5 80.000 (78.226)\n",
            "Test: [40/261]\tTime 0.022 (0.040)\tLoss 11.0545 (12.2052)\tPrec@1 41.000 (36.854)\tPrec@5 81.000 (78.268)\n",
            "Test: [50/261]\tTime 0.042 (0.037)\tLoss 12.8468 (12.1140)\tPrec@1 26.000 (37.333)\tPrec@5 82.000 (78.588)\n",
            "Test: [60/261]\tTime 0.027 (0.037)\tLoss 13.4876 (12.1263)\tPrec@1 34.000 (37.197)\tPrec@5 66.000 (78.410)\n",
            "Test: [70/261]\tTime 0.060 (0.036)\tLoss 12.5367 (12.0825)\tPrec@1 34.000 (37.211)\tPrec@5 79.000 (78.423)\n",
            "Test: [80/261]\tTime 0.030 (0.036)\tLoss 11.9607 (12.1155)\tPrec@1 36.000 (37.049)\tPrec@5 72.000 (78.210)\n",
            "Test: [90/261]\tTime 0.019 (0.035)\tLoss 13.0950 (12.1450)\tPrec@1 27.000 (36.736)\tPrec@5 73.000 (77.934)\n",
            "Test: [100/261]\tTime 0.032 (0.035)\tLoss 11.5945 (12.0700)\tPrec@1 39.000 (37.079)\tPrec@5 75.000 (77.901)\n",
            "Test: [110/261]\tTime 0.033 (0.034)\tLoss 13.4548 (12.1005)\tPrec@1 29.000 (36.946)\tPrec@5 76.000 (77.622)\n",
            "Test: [120/261]\tTime 0.043 (0.036)\tLoss 10.8409 (12.0908)\tPrec@1 42.000 (36.967)\tPrec@5 81.000 (77.612)\n",
            "Test: [130/261]\tTime 0.033 (0.035)\tLoss 12.0537 (12.0919)\tPrec@1 39.000 (36.893)\tPrec@5 72.000 (77.573)\n",
            "Test: [140/261]\tTime 0.036 (0.035)\tLoss 12.2185 (12.1032)\tPrec@1 35.000 (36.830)\tPrec@5 78.000 (77.553)\n",
            "Test: [150/261]\tTime 0.037 (0.034)\tLoss 13.2338 (12.1258)\tPrec@1 27.000 (36.695)\tPrec@5 70.000 (77.397)\n",
            "Test: [160/261]\tTime 0.031 (0.034)\tLoss 12.0927 (12.1269)\tPrec@1 34.000 (36.689)\tPrec@5 81.000 (77.317)\n",
            "Test: [170/261]\tTime 0.027 (0.034)\tLoss 12.0862 (12.1181)\tPrec@1 32.000 (36.696)\tPrec@5 78.000 (77.415)\n",
            "Test: [180/261]\tTime 0.028 (0.034)\tLoss 11.4632 (12.0871)\tPrec@1 36.000 (36.823)\tPrec@5 83.000 (77.541)\n",
            "Test: [190/261]\tTime 0.043 (0.034)\tLoss 12.0417 (12.0904)\tPrec@1 33.000 (36.754)\tPrec@5 73.000 (77.503)\n",
            "Test: [200/261]\tTime 0.017 (0.033)\tLoss 12.6200 (12.0856)\tPrec@1 31.000 (36.677)\tPrec@5 73.000 (77.507)\n",
            "Test: [210/261]\tTime 0.033 (0.033)\tLoss 9.9018 (12.0564)\tPrec@1 54.000 (36.820)\tPrec@5 80.000 (77.569)\n",
            "Test: [220/261]\tTime 0.031 (0.032)\tLoss 11.9114 (12.0360)\tPrec@1 37.000 (36.896)\tPrec@5 77.000 (77.679)\n",
            "Test: [230/261]\tTime 0.026 (0.032)\tLoss 12.2921 (12.0530)\tPrec@1 33.000 (36.779)\tPrec@5 81.000 (77.697)\n",
            "Test: [240/261]\tTime 0.013 (0.032)\tLoss 11.6934 (12.0517)\tPrec@1 41.000 (36.817)\tPrec@5 80.000 (77.813)\n",
            "Test: [250/261]\tTime 0.028 (0.032)\tLoss 13.5385 (12.0480)\tPrec@1 27.000 (36.813)\tPrec@5 80.000 (77.825)\n",
            "Test: [260/261]\tTime 0.006 (0.031)\tLoss 11.9453 (12.0500)\tPrec@1 40.625 (36.839)\tPrec@5 78.125 (77.843)\n",
            "val Results: Prec@1 36.839 Prec@5 77.843 Loss 12.05000\n",
            "val Class Accuracy: [0.000,0.939,0.265,0.900,0.180,0.234,0.049,0.000,0.000,0.000]\n",
            "Best Prec@1: 36.839\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [2][0/66], lr: 0.00600\tTime 0.668 (0.668)\tData 0.564 (0.564)\tLoss 4.3391 (4.3391)\tPrec@1 76.562 (76.562)\tPrec@5 97.266 (97.266)\n",
            "Epoch: [2][10/66], lr: 0.00600\tTime 0.095 (0.150)\tData 0.002 (0.060)\tLoss 3.9416 (4.2054)\tPrec@1 76.953 (77.131)\tPrec@5 96.484 (95.348)\n",
            "Epoch: [2][20/66], lr: 0.00600\tTime 0.087 (0.127)\tData 0.004 (0.035)\tLoss 3.2577 (4.0088)\tPrec@1 83.594 (78.274)\tPrec@5 96.484 (96.205)\n",
            "Epoch: [2][30/66], lr: 0.00600\tTime 0.083 (0.119)\tData 0.007 (0.026)\tLoss 3.7540 (3.8184)\tPrec@1 79.688 (79.284)\tPrec@5 98.047 (96.711)\n",
            "Epoch: [2][40/66], lr: 0.00600\tTime 0.094 (0.113)\tData 0.000 (0.022)\tLoss 3.1804 (3.7339)\tPrec@1 83.203 (79.792)\tPrec@5 97.656 (97.018)\n",
            "Epoch: [2][50/66], lr: 0.00600\tTime 0.098 (0.110)\tData 0.004 (0.018)\tLoss 2.7881 (3.6374)\tPrec@1 83.984 (80.476)\tPrec@5 98.438 (97.212)\n",
            "Epoch: [2][60/66], lr: 0.00600\tTime 0.071 (0.108)\tData 0.000 (0.016)\tLoss 3.2411 (3.5198)\tPrec@1 82.422 (81.250)\tPrec@5 98.828 (97.362)\n",
            "Test: [0/261]\tTime 0.321 (0.321)\tLoss 10.0415 (10.0415)\tPrec@1 47.000 (47.000)\tPrec@5 81.000 (81.000)\n",
            "Test: [10/261]\tTime 0.031 (0.060)\tLoss 11.7014 (11.5072)\tPrec@1 38.000 (39.091)\tPrec@5 83.000 (78.455)\n",
            "Test: [20/261]\tTime 0.027 (0.043)\tLoss 11.3070 (11.4914)\tPrec@1 40.000 (39.429)\tPrec@5 77.000 (78.095)\n",
            "Test: [30/261]\tTime 0.024 (0.038)\tLoss 9.2733 (11.3091)\tPrec@1 51.000 (40.129)\tPrec@5 87.000 (79.387)\n",
            "Test: [40/261]\tTime 0.045 (0.036)\tLoss 10.8749 (11.2022)\tPrec@1 42.000 (40.902)\tPrec@5 78.000 (79.561)\n",
            "Test: [50/261]\tTime 0.016 (0.034)\tLoss 11.5935 (11.1634)\tPrec@1 38.000 (41.157)\tPrec@5 84.000 (79.706)\n",
            "Test: [60/261]\tTime 0.026 (0.033)\tLoss 11.4963 (11.1894)\tPrec@1 41.000 (41.148)\tPrec@5 82.000 (79.377)\n",
            "Test: [70/261]\tTime 0.023 (0.031)\tLoss 11.0516 (11.1323)\tPrec@1 38.000 (41.437)\tPrec@5 80.000 (79.507)\n",
            "Test: [80/261]\tTime 0.013 (0.031)\tLoss 10.1006 (11.1730)\tPrec@1 48.000 (41.284)\tPrec@5 83.000 (79.333)\n",
            "Test: [90/261]\tTime 0.014 (0.030)\tLoss 11.8733 (11.1655)\tPrec@1 42.000 (41.462)\tPrec@5 79.000 (79.516)\n",
            "Test: [100/261]\tTime 0.011 (0.030)\tLoss 11.5226 (11.1593)\tPrec@1 36.000 (41.465)\tPrec@5 82.000 (79.386)\n",
            "Test: [110/261]\tTime 0.017 (0.030)\tLoss 11.4389 (11.1601)\tPrec@1 41.000 (41.441)\tPrec@5 77.000 (79.279)\n",
            "Test: [120/261]\tTime 0.011 (0.030)\tLoss 9.9268 (11.1468)\tPrec@1 50.000 (41.554)\tPrec@5 77.000 (79.165)\n",
            "Test: [130/261]\tTime 0.029 (0.029)\tLoss 10.8091 (11.1385)\tPrec@1 44.000 (41.611)\tPrec@5 82.000 (79.229)\n",
            "Test: [140/261]\tTime 0.039 (0.029)\tLoss 12.9742 (11.1631)\tPrec@1 26.000 (41.411)\tPrec@5 76.000 (79.128)\n",
            "Test: [150/261]\tTime 0.030 (0.029)\tLoss 9.8115 (11.1407)\tPrec@1 48.000 (41.550)\tPrec@5 88.000 (79.199)\n",
            "Test: [160/261]\tTime 0.033 (0.029)\tLoss 11.4317 (11.1530)\tPrec@1 40.000 (41.435)\tPrec@5 77.000 (79.186)\n",
            "Test: [170/261]\tTime 0.023 (0.029)\tLoss 9.1538 (11.1133)\tPrec@1 51.000 (41.579)\tPrec@5 83.000 (79.427)\n",
            "Test: [180/261]\tTime 0.022 (0.029)\tLoss 10.7842 (11.1181)\tPrec@1 43.000 (41.608)\tPrec@5 78.000 (79.271)\n",
            "Test: [190/261]\tTime 0.032 (0.028)\tLoss 10.5862 (11.1383)\tPrec@1 44.000 (41.529)\tPrec@5 81.000 (79.188)\n",
            "Test: [200/261]\tTime 0.023 (0.028)\tLoss 11.3585 (11.1502)\tPrec@1 46.000 (41.517)\tPrec@5 77.000 (79.139)\n",
            "Test: [210/261]\tTime 0.027 (0.028)\tLoss 10.8712 (11.1345)\tPrec@1 40.000 (41.583)\tPrec@5 78.000 (79.152)\n",
            "Test: [220/261]\tTime 0.024 (0.028)\tLoss 10.3494 (11.1350)\tPrec@1 45.000 (41.579)\tPrec@5 83.000 (79.086)\n",
            "Test: [230/261]\tTime 0.037 (0.028)\tLoss 10.8558 (11.1452)\tPrec@1 47.000 (41.558)\tPrec@5 82.000 (79.108)\n",
            "Test: [240/261]\tTime 0.018 (0.028)\tLoss 10.2894 (11.1488)\tPrec@1 46.000 (41.544)\tPrec@5 84.000 (79.108)\n",
            "Test: [250/261]\tTime 0.011 (0.028)\tLoss 11.2084 (11.1562)\tPrec@1 44.000 (41.526)\tPrec@5 81.000 (79.131)\n",
            "Test: [260/261]\tTime 0.007 (0.027)\tLoss 11.2654 (11.1521)\tPrec@1 31.250 (41.537)\tPrec@5 84.375 (79.176)\n",
            "val Results: Prec@1 41.537 Prec@5 79.176 Loss 11.15208\n",
            "val Class Accuracy: [0.013,0.948,0.404,0.003,0.855,0.056,0.711,0.282,0.000,0.002]\n",
            "Best Prec@1: 41.537\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [3][0/66], lr: 0.00800\tTime 0.473 (0.473)\tData 0.393 (0.393)\tLoss 2.7181 (2.7181)\tPrec@1 87.109 (87.109)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [3][10/66], lr: 0.00800\tTime 0.107 (0.157)\tData 0.010 (0.053)\tLoss 3.0506 (2.8946)\tPrec@1 84.766 (85.085)\tPrec@5 97.656 (98.438)\n",
            "Epoch: [3][20/66], lr: 0.00800\tTime 0.122 (0.141)\tData 0.003 (0.033)\tLoss 2.8840 (2.7483)\tPrec@1 83.594 (85.975)\tPrec@5 98.438 (98.605)\n",
            "Epoch: [3][30/66], lr: 0.00800\tTime 0.167 (0.151)\tData 0.063 (0.045)\tLoss 2.9935 (2.6471)\tPrec@1 84.766 (86.580)\tPrec@5 99.609 (98.727)\n",
            "Epoch: [3][40/66], lr: 0.00800\tTime 0.089 (0.149)\tData 0.000 (0.045)\tLoss 1.9836 (2.5768)\tPrec@1 90.234 (86.919)\tPrec@5 99.609 (98.800)\n",
            "Epoch: [3][50/66], lr: 0.00800\tTime 0.119 (0.140)\tData 0.005 (0.041)\tLoss 2.9174 (2.5714)\tPrec@1 84.766 (86.987)\tPrec@5 98.828 (98.813)\n",
            "Epoch: [3][60/66], lr: 0.00800\tTime 0.092 (0.133)\tData 0.000 (0.036)\tLoss 2.4563 (2.5713)\tPrec@1 87.500 (86.981)\tPrec@5 98.828 (98.841)\n",
            "Test: [0/261]\tTime 0.350 (0.350)\tLoss 7.1303 (7.1303)\tPrec@1 65.000 (65.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.035 (0.052)\tLoss 8.4101 (7.8563)\tPrec@1 59.000 (59.818)\tPrec@5 95.000 (95.636)\n",
            "Test: [20/261]\tTime 0.030 (0.042)\tLoss 8.7655 (7.9336)\tPrec@1 52.000 (59.762)\tPrec@5 91.000 (95.190)\n",
            "Test: [30/261]\tTime 0.030 (0.037)\tLoss 5.9810 (7.7883)\tPrec@1 70.000 (60.968)\tPrec@5 95.000 (95.323)\n",
            "Test: [40/261]\tTime 0.020 (0.033)\tLoss 6.8859 (7.7540)\tPrec@1 69.000 (61.634)\tPrec@5 99.000 (95.512)\n",
            "Test: [50/261]\tTime 0.020 (0.032)\tLoss 7.9197 (7.7457)\tPrec@1 63.000 (61.765)\tPrec@5 95.000 (95.490)\n",
            "Test: [60/261]\tTime 0.014 (0.031)\tLoss 8.5216 (7.8015)\tPrec@1 61.000 (61.639)\tPrec@5 94.000 (95.295)\n",
            "Test: [70/261]\tTime 0.026 (0.031)\tLoss 8.7703 (7.7830)\tPrec@1 58.000 (61.718)\tPrec@5 90.000 (95.155)\n",
            "Test: [80/261]\tTime 0.020 (0.030)\tLoss 7.1772 (7.8134)\tPrec@1 63.000 (61.469)\tPrec@5 93.000 (95.222)\n",
            "Test: [90/261]\tTime 0.027 (0.030)\tLoss 7.5269 (7.8496)\tPrec@1 65.000 (61.330)\tPrec@5 91.000 (95.132)\n",
            "Test: [100/261]\tTime 0.040 (0.030)\tLoss 8.4577 (7.8289)\tPrec@1 60.000 (61.515)\tPrec@5 94.000 (95.168)\n",
            "Test: [110/261]\tTime 0.022 (0.030)\tLoss 8.0352 (7.8175)\tPrec@1 62.000 (61.631)\tPrec@5 92.000 (95.081)\n",
            "Test: [120/261]\tTime 0.016 (0.029)\tLoss 6.9257 (7.8001)\tPrec@1 65.000 (61.835)\tPrec@5 96.000 (95.165)\n",
            "Test: [130/261]\tTime 0.028 (0.029)\tLoss 7.3709 (7.7917)\tPrec@1 65.000 (61.908)\tPrec@5 97.000 (95.206)\n",
            "Test: [140/261]\tTime 0.024 (0.029)\tLoss 9.2799 (7.7915)\tPrec@1 50.000 (61.972)\tPrec@5 94.000 (95.241)\n",
            "Test: [150/261]\tTime 0.011 (0.029)\tLoss 6.5567 (7.7729)\tPrec@1 65.000 (62.093)\tPrec@5 98.000 (95.252)\n",
            "Test: [160/261]\tTime 0.024 (0.029)\tLoss 8.2700 (7.7712)\tPrec@1 58.000 (62.106)\tPrec@5 96.000 (95.211)\n",
            "Test: [170/261]\tTime 0.031 (0.029)\tLoss 6.6247 (7.7572)\tPrec@1 68.000 (62.158)\tPrec@5 92.000 (95.187)\n",
            "Test: [180/261]\tTime 0.017 (0.029)\tLoss 6.5689 (7.7555)\tPrec@1 70.000 (62.144)\tPrec@5 94.000 (95.177)\n",
            "Test: [190/261]\tTime 0.039 (0.028)\tLoss 7.8547 (7.7608)\tPrec@1 59.000 (62.073)\tPrec@5 96.000 (95.194)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 7.3937 (7.7775)\tPrec@1 66.000 (61.930)\tPrec@5 95.000 (95.169)\n",
            "Test: [210/261]\tTime 0.022 (0.028)\tLoss 7.9224 (7.7526)\tPrec@1 58.000 (62.033)\tPrec@5 92.000 (95.209)\n",
            "Test: [220/261]\tTime 0.036 (0.028)\tLoss 8.0484 (7.7627)\tPrec@1 59.000 (61.905)\tPrec@5 94.000 (95.186)\n",
            "Test: [230/261]\tTime 0.043 (0.028)\tLoss 8.7470 (7.7784)\tPrec@1 57.000 (61.857)\tPrec@5 96.000 (95.156)\n",
            "Test: [240/261]\tTime 0.011 (0.028)\tLoss 7.7111 (7.7774)\tPrec@1 58.000 (61.867)\tPrec@5 98.000 (95.187)\n",
            "Test: [250/261]\tTime 0.033 (0.028)\tLoss 7.9508 (7.7692)\tPrec@1 63.000 (61.920)\tPrec@5 97.000 (95.243)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 5.4866 (7.7758)\tPrec@1 75.000 (61.928)\tPrec@5 100.000 (95.244)\n",
            "val Results: Prec@1 61.928 Prec@5 95.244 Loss 7.77576\n",
            "val Class Accuracy: [0.134,0.886,0.694,0.610,0.956,0.141,0.846,0.598,0.336,0.342]\n",
            "Best Prec@1: 61.928\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [4][0/66], lr: 0.01000\tTime 0.606 (0.606)\tData 0.496 (0.496)\tLoss 2.6682 (2.6682)\tPrec@1 86.719 (86.719)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [4][10/66], lr: 0.01000\tTime 0.089 (0.153)\tData 0.000 (0.052)\tLoss 2.0028 (2.3195)\tPrec@1 90.234 (88.494)\tPrec@5 99.609 (99.041)\n",
            "Epoch: [4][20/66], lr: 0.01000\tTime 0.086 (0.127)\tData 0.007 (0.030)\tLoss 2.7050 (2.2701)\tPrec@1 85.938 (88.690)\tPrec@5 99.219 (98.958)\n",
            "Epoch: [4][30/66], lr: 0.01000\tTime 0.123 (0.121)\tData 0.005 (0.022)\tLoss 2.3181 (2.2426)\tPrec@1 88.281 (88.962)\tPrec@5 98.828 (98.979)\n",
            "Epoch: [4][40/66], lr: 0.01000\tTime 0.103 (0.116)\tData 0.005 (0.018)\tLoss 1.6698 (2.1963)\tPrec@1 92.969 (89.367)\tPrec@5 99.219 (99.057)\n",
            "Epoch: [4][50/66], lr: 0.01000\tTime 0.093 (0.112)\tData 0.000 (0.015)\tLoss 1.8292 (2.1266)\tPrec@1 91.406 (89.714)\tPrec@5 99.609 (99.073)\n",
            "Epoch: [4][60/66], lr: 0.01000\tTime 0.082 (0.110)\tData 0.000 (0.015)\tLoss 2.1377 (2.0957)\tPrec@1 89.453 (89.786)\tPrec@5 98.438 (99.084)\n",
            "Test: [0/261]\tTime 0.275 (0.275)\tLoss 6.9292 (6.9292)\tPrec@1 65.000 (65.000)\tPrec@5 91.000 (91.000)\n",
            "Test: [10/261]\tTime 0.036 (0.057)\tLoss 6.9309 (7.1594)\tPrec@1 72.000 (67.364)\tPrec@5 91.000 (93.545)\n",
            "Test: [20/261]\tTime 0.018 (0.043)\tLoss 8.1138 (6.9849)\tPrec@1 61.000 (67.952)\tPrec@5 92.000 (94.238)\n",
            "Test: [30/261]\tTime 0.010 (0.036)\tLoss 6.3798 (6.8805)\tPrec@1 72.000 (69.000)\tPrec@5 92.000 (94.161)\n",
            "Test: [40/261]\tTime 0.027 (0.034)\tLoss 6.0421 (6.8474)\tPrec@1 75.000 (69.488)\tPrec@5 97.000 (94.268)\n",
            "Test: [50/261]\tTime 0.031 (0.033)\tLoss 7.5878 (6.7983)\tPrec@1 67.000 (69.765)\tPrec@5 92.000 (94.490)\n",
            "Test: [60/261]\tTime 0.018 (0.032)\tLoss 7.2572 (6.7865)\tPrec@1 65.000 (69.869)\tPrec@5 98.000 (94.738)\n",
            "Test: [70/261]\tTime 0.021 (0.031)\tLoss 6.6978 (6.8104)\tPrec@1 69.000 (69.577)\tPrec@5 96.000 (94.732)\n",
            "Test: [80/261]\tTime 0.011 (0.030)\tLoss 6.8426 (6.8233)\tPrec@1 65.000 (69.346)\tPrec@5 97.000 (94.864)\n",
            "Test: [90/261]\tTime 0.030 (0.030)\tLoss 7.1285 (6.8847)\tPrec@1 69.000 (68.923)\tPrec@5 95.000 (94.758)\n",
            "Test: [100/261]\tTime 0.021 (0.029)\tLoss 7.6300 (6.8925)\tPrec@1 63.000 (68.802)\tPrec@5 94.000 (94.733)\n",
            "Test: [110/261]\tTime 0.030 (0.028)\tLoss 6.8916 (6.8709)\tPrec@1 69.000 (68.892)\tPrec@5 96.000 (94.838)\n",
            "Test: [120/261]\tTime 0.036 (0.029)\tLoss 5.8628 (6.8601)\tPrec@1 73.000 (68.942)\tPrec@5 95.000 (94.884)\n",
            "Test: [130/261]\tTime 0.027 (0.029)\tLoss 7.4615 (6.8575)\tPrec@1 60.000 (68.863)\tPrec@5 94.000 (94.863)\n",
            "Test: [140/261]\tTime 0.025 (0.029)\tLoss 7.8654 (6.8506)\tPrec@1 58.000 (68.901)\tPrec@5 92.000 (94.915)\n",
            "Test: [150/261]\tTime 0.029 (0.029)\tLoss 6.6686 (6.8632)\tPrec@1 65.000 (68.874)\tPrec@5 93.000 (94.861)\n",
            "Test: [160/261]\tTime 0.026 (0.029)\tLoss 6.3512 (6.8717)\tPrec@1 71.000 (68.851)\tPrec@5 98.000 (94.795)\n",
            "Test: [170/261]\tTime 0.035 (0.029)\tLoss 6.8048 (6.8693)\tPrec@1 63.000 (68.789)\tPrec@5 92.000 (94.854)\n",
            "Test: [180/261]\tTime 0.013 (0.028)\tLoss 6.7586 (6.8673)\tPrec@1 73.000 (68.867)\tPrec@5 94.000 (94.862)\n",
            "Test: [190/261]\tTime 0.048 (0.028)\tLoss 7.2142 (6.8539)\tPrec@1 63.000 (68.901)\tPrec@5 94.000 (94.916)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 6.7010 (6.8557)\tPrec@1 72.000 (68.900)\tPrec@5 94.000 (94.900)\n",
            "Test: [210/261]\tTime 0.039 (0.028)\tLoss 6.5026 (6.8486)\tPrec@1 73.000 (68.929)\tPrec@5 94.000 (94.934)\n",
            "Test: [220/261]\tTime 0.029 (0.028)\tLoss 7.0835 (6.8314)\tPrec@1 68.000 (69.063)\tPrec@5 93.000 (94.937)\n",
            "Test: [230/261]\tTime 0.026 (0.028)\tLoss 6.6748 (6.8440)\tPrec@1 76.000 (69.035)\tPrec@5 96.000 (94.944)\n",
            "Test: [240/261]\tTime 0.028 (0.028)\tLoss 7.0479 (6.8403)\tPrec@1 67.000 (69.033)\tPrec@5 96.000 (95.004)\n",
            "Test: [250/261]\tTime 0.018 (0.028)\tLoss 6.2227 (6.8157)\tPrec@1 74.000 (69.207)\tPrec@5 96.000 (95.004)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 6.6345 (6.8115)\tPrec@1 68.750 (69.180)\tPrec@5 96.875 (94.995)\n",
            "val Results: Prec@1 69.180 Prec@5 94.995 Loss 6.81150\n",
            "val Class Accuracy: [0.400,0.794,0.798,0.588,0.745,0.570,0.529,0.613,0.778,0.903]\n",
            "Best Prec@1: 69.180\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [5][0/66], lr: 0.01000\tTime 0.602 (0.602)\tData 0.495 (0.495)\tLoss 1.7019 (1.7019)\tPrec@1 92.578 (92.578)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [5][10/66], lr: 0.01000\tTime 0.133 (0.153)\tData 0.004 (0.055)\tLoss 1.1985 (1.7947)\tPrec@1 93.359 (91.158)\tPrec@5 100.000 (99.361)\n",
            "Epoch: [5][20/66], lr: 0.01000\tTime 0.119 (0.131)\tData 0.003 (0.033)\tLoss 1.3871 (1.7647)\tPrec@1 93.359 (91.499)\tPrec@5 99.609 (99.368)\n",
            "Epoch: [5][30/66], lr: 0.01000\tTime 0.092 (0.122)\tData 0.005 (0.026)\tLoss 1.5276 (1.7435)\tPrec@1 90.625 (91.431)\tPrec@5 99.219 (99.332)\n",
            "Epoch: [5][40/66], lr: 0.01000\tTime 0.160 (0.119)\tData 0.041 (0.025)\tLoss 1.8749 (1.7045)\tPrec@1 91.016 (91.625)\tPrec@5 98.438 (99.314)\n",
            "Epoch: [5][50/66], lr: 0.01000\tTime 0.129 (0.117)\tData 0.005 (0.023)\tLoss 2.1583 (1.7054)\tPrec@1 87.891 (91.575)\tPrec@5 99.219 (99.380)\n",
            "Epoch: [5][60/66], lr: 0.01000\tTime 0.109 (0.115)\tData 0.000 (0.021)\tLoss 2.2264 (1.7125)\tPrec@1 89.844 (91.477)\tPrec@5 98.047 (99.360)\n",
            "Test: [0/261]\tTime 0.269 (0.269)\tLoss 5.3387 (5.3387)\tPrec@1 74.000 (74.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.026 (0.058)\tLoss 6.8404 (6.4927)\tPrec@1 71.000 (72.000)\tPrec@5 98.000 (96.909)\n",
            "Test: [20/261]\tTime 0.036 (0.043)\tLoss 6.4275 (6.3225)\tPrec@1 74.000 (72.810)\tPrec@5 94.000 (96.476)\n",
            "Test: [30/261]\tTime 0.013 (0.037)\tLoss 5.0582 (6.1394)\tPrec@1 77.000 (73.290)\tPrec@5 96.000 (96.613)\n",
            "Test: [40/261]\tTime 0.027 (0.036)\tLoss 5.6375 (6.1169)\tPrec@1 78.000 (73.537)\tPrec@5 97.000 (96.780)\n",
            "Test: [50/261]\tTime 0.026 (0.034)\tLoss 6.1226 (6.0835)\tPrec@1 76.000 (73.902)\tPrec@5 99.000 (96.824)\n",
            "Test: [60/261]\tTime 0.029 (0.032)\tLoss 6.4836 (6.0769)\tPrec@1 73.000 (73.836)\tPrec@5 98.000 (96.852)\n",
            "Test: [70/261]\tTime 0.025 (0.031)\tLoss 6.6529 (6.0718)\tPrec@1 74.000 (73.873)\tPrec@5 99.000 (96.831)\n",
            "Test: [80/261]\tTime 0.023 (0.031)\tLoss 6.0700 (6.0601)\tPrec@1 73.000 (73.667)\tPrec@5 95.000 (96.815)\n",
            "Test: [90/261]\tTime 0.023 (0.030)\tLoss 5.3805 (6.0821)\tPrec@1 76.000 (73.626)\tPrec@5 96.000 (96.670)\n",
            "Test: [100/261]\tTime 0.021 (0.030)\tLoss 7.0063 (6.0404)\tPrec@1 69.000 (73.772)\tPrec@5 95.000 (96.713)\n",
            "Test: [110/261]\tTime 0.016 (0.030)\tLoss 5.8403 (6.0182)\tPrec@1 78.000 (73.982)\tPrec@5 98.000 (96.775)\n",
            "Test: [120/261]\tTime 0.047 (0.030)\tLoss 4.5827 (6.0218)\tPrec@1 79.000 (73.926)\tPrec@5 97.000 (96.727)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 6.3814 (6.0115)\tPrec@1 73.000 (73.931)\tPrec@5 98.000 (96.718)\n",
            "Test: [140/261]\tTime 0.028 (0.029)\tLoss 6.5709 (6.0085)\tPrec@1 75.000 (74.085)\tPrec@5 96.000 (96.723)\n",
            "Test: [150/261]\tTime 0.023 (0.029)\tLoss 5.7796 (6.0198)\tPrec@1 73.000 (74.046)\tPrec@5 98.000 (96.649)\n",
            "Test: [160/261]\tTime 0.013 (0.028)\tLoss 4.6589 (6.0204)\tPrec@1 80.000 (74.019)\tPrec@5 99.000 (96.652)\n",
            "Test: [170/261]\tTime 0.035 (0.028)\tLoss 5.5818 (6.0199)\tPrec@1 75.000 (74.023)\tPrec@5 92.000 (96.643)\n",
            "Test: [180/261]\tTime 0.021 (0.028)\tLoss 4.8495 (6.0079)\tPrec@1 80.000 (74.061)\tPrec@5 96.000 (96.624)\n",
            "Test: [190/261]\tTime 0.023 (0.028)\tLoss 5.2378 (5.9868)\tPrec@1 78.000 (74.209)\tPrec@5 97.000 (96.639)\n",
            "Test: [200/261]\tTime 0.018 (0.028)\tLoss 5.1550 (5.9630)\tPrec@1 79.000 (74.313)\tPrec@5 97.000 (96.652)\n",
            "Test: [210/261]\tTime 0.026 (0.028)\tLoss 6.0277 (5.9501)\tPrec@1 77.000 (74.346)\tPrec@5 93.000 (96.673)\n",
            "Test: [220/261]\tTime 0.038 (0.028)\tLoss 5.4690 (5.9478)\tPrec@1 75.000 (74.303)\tPrec@5 98.000 (96.665)\n",
            "Test: [230/261]\tTime 0.043 (0.028)\tLoss 6.7212 (5.9581)\tPrec@1 69.000 (74.221)\tPrec@5 96.000 (96.662)\n",
            "Test: [240/261]\tTime 0.038 (0.028)\tLoss 6.0839 (5.9595)\tPrec@1 75.000 (74.212)\tPrec@5 96.000 (96.643)\n",
            "Test: [250/261]\tTime 0.015 (0.028)\tLoss 6.3146 (5.9407)\tPrec@1 76.000 (74.303)\tPrec@5 99.000 (96.669)\n",
            "Test: [260/261]\tTime 0.009 (0.028)\tLoss 4.8310 (5.9443)\tPrec@1 75.000 (74.285)\tPrec@5 100.000 (96.689)\n",
            "val Results: Prec@1 74.285 Prec@5 96.689 Loss 5.94429\n",
            "val Class Accuracy: [0.600,0.940,0.950,0.577,0.669,0.720,0.728,0.668,0.816,0.218]\n",
            "Best Prec@1: 74.285\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [6][0/66], lr: 0.01000\tTime 0.954 (0.954)\tData 0.856 (0.856)\tLoss 2.3430 (2.3430)\tPrec@1 87.891 (87.891)\tPrec@5 98.438 (98.438)\n",
            "Epoch: [6][10/66], lr: 0.01000\tTime 0.147 (0.212)\tData 0.000 (0.090)\tLoss 1.7868 (1.8436)\tPrec@1 91.016 (91.158)\tPrec@5 98.438 (99.183)\n",
            "Epoch: [6][20/66], lr: 0.01000\tTime 0.077 (0.183)\tData 0.000 (0.067)\tLoss 1.1919 (1.7407)\tPrec@1 94.531 (91.518)\tPrec@5 99.609 (99.144)\n",
            "Epoch: [6][30/66], lr: 0.01000\tTime 0.101 (0.155)\tData 0.005 (0.049)\tLoss 1.0262 (1.6765)\tPrec@1 94.141 (91.696)\tPrec@5 100.000 (99.244)\n",
            "Epoch: [6][40/66], lr: 0.01000\tTime 0.096 (0.141)\tData 0.020 (0.041)\tLoss 1.3871 (1.6262)\tPrec@1 92.188 (91.835)\tPrec@5 99.609 (99.276)\n",
            "Epoch: [6][50/66], lr: 0.01000\tTime 0.126 (0.134)\tData 0.005 (0.035)\tLoss 1.7439 (1.6114)\tPrec@1 91.016 (91.927)\tPrec@5 99.609 (99.334)\n",
            "Epoch: [6][60/66], lr: 0.01000\tTime 0.073 (0.129)\tData 0.000 (0.031)\tLoss 1.0706 (1.5916)\tPrec@1 94.922 (91.938)\tPrec@5 99.219 (99.347)\n",
            "Test: [0/261]\tTime 0.343 (0.343)\tLoss 5.0462 (5.0462)\tPrec@1 82.000 (82.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.030 (0.059)\tLoss 5.1918 (5.2823)\tPrec@1 78.000 (76.909)\tPrec@5 97.000 (94.818)\n",
            "Test: [20/261]\tTime 0.023 (0.043)\tLoss 5.4928 (5.1398)\tPrec@1 74.000 (78.190)\tPrec@5 92.000 (95.143)\n",
            "Test: [30/261]\tTime 0.032 (0.038)\tLoss 3.5581 (4.9156)\tPrec@1 84.000 (79.097)\tPrec@5 96.000 (95.677)\n",
            "Test: [40/261]\tTime 0.023 (0.035)\tLoss 4.1608 (4.8289)\tPrec@1 82.000 (79.366)\tPrec@5 97.000 (96.146)\n",
            "Test: [50/261]\tTime 0.027 (0.033)\tLoss 4.3190 (4.7879)\tPrec@1 83.000 (79.529)\tPrec@5 97.000 (96.137)\n",
            "Test: [60/261]\tTime 0.025 (0.032)\tLoss 4.9537 (4.7320)\tPrec@1 82.000 (79.803)\tPrec@5 96.000 (96.049)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 5.5104 (4.7639)\tPrec@1 77.000 (79.563)\tPrec@5 92.000 (95.972)\n",
            "Test: [80/261]\tTime 0.018 (0.031)\tLoss 5.3052 (4.7679)\tPrec@1 77.000 (79.420)\tPrec@5 94.000 (95.963)\n",
            "Test: [90/261]\tTime 0.028 (0.031)\tLoss 5.3495 (4.8211)\tPrec@1 75.000 (79.154)\tPrec@5 96.000 (95.945)\n",
            "Test: [100/261]\tTime 0.016 (0.030)\tLoss 4.8796 (4.8239)\tPrec@1 79.000 (79.099)\tPrec@5 94.000 (95.901)\n",
            "Test: [110/261]\tTime 0.051 (0.030)\tLoss 4.2528 (4.8050)\tPrec@1 82.000 (79.207)\tPrec@5 97.000 (95.901)\n",
            "Test: [120/261]\tTime 0.033 (0.030)\tLoss 3.3709 (4.7939)\tPrec@1 86.000 (79.231)\tPrec@5 97.000 (95.917)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 4.8842 (4.7962)\tPrec@1 79.000 (79.260)\tPrec@5 94.000 (95.924)\n",
            "Test: [140/261]\tTime 0.020 (0.029)\tLoss 5.0363 (4.7963)\tPrec@1 81.000 (79.291)\tPrec@5 95.000 (95.915)\n",
            "Test: [150/261]\tTime 0.024 (0.029)\tLoss 4.2349 (4.7952)\tPrec@1 80.000 (79.305)\tPrec@5 95.000 (95.874)\n",
            "Test: [160/261]\tTime 0.031 (0.029)\tLoss 3.7439 (4.8015)\tPrec@1 86.000 (79.311)\tPrec@5 99.000 (95.925)\n",
            "Test: [170/261]\tTime 0.017 (0.029)\tLoss 3.5156 (4.7877)\tPrec@1 87.000 (79.339)\tPrec@5 97.000 (95.912)\n",
            "Test: [180/261]\tTime 0.028 (0.029)\tLoss 4.0761 (4.7851)\tPrec@1 85.000 (79.376)\tPrec@5 95.000 (95.890)\n",
            "Test: [190/261]\tTime 0.026 (0.029)\tLoss 4.0438 (4.7633)\tPrec@1 83.000 (79.487)\tPrec@5 96.000 (95.963)\n",
            "Test: [200/261]\tTime 0.023 (0.028)\tLoss 4.5635 (4.7626)\tPrec@1 79.000 (79.498)\tPrec@5 95.000 (95.965)\n",
            "Test: [210/261]\tTime 0.020 (0.028)\tLoss 3.3804 (4.7367)\tPrec@1 85.000 (79.602)\tPrec@5 97.000 (96.019)\n",
            "Test: [220/261]\tTime 0.047 (0.028)\tLoss 5.2993 (4.7309)\tPrec@1 77.000 (79.593)\tPrec@5 94.000 (96.009)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 5.6761 (4.7347)\tPrec@1 78.000 (79.593)\tPrec@5 94.000 (95.978)\n",
            "Test: [240/261]\tTime 0.020 (0.028)\tLoss 4.3325 (4.7420)\tPrec@1 83.000 (79.593)\tPrec@5 96.000 (95.975)\n",
            "Test: [250/261]\tTime 0.035 (0.028)\tLoss 5.4458 (4.7284)\tPrec@1 79.000 (79.649)\tPrec@5 98.000 (96.012)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.7595 (4.7328)\tPrec@1 87.500 (79.637)\tPrec@5 96.875 (95.990)\n",
            "val Results: Prec@1 79.637 Prec@5 95.990 Loss 4.73279\n",
            "val Class Accuracy: [0.671,0.960,0.947,0.815,0.862,0.842,0.628,0.604,0.637,0.432]\n",
            "Best Prec@1: 79.637\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [7][0/66], lr: 0.01000\tTime 0.566 (0.566)\tData 0.474 (0.474)\tLoss 1.5314 (1.5314)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [7][10/66], lr: 0.01000\tTime 0.100 (0.149)\tData 0.008 (0.051)\tLoss 1.6581 (1.4785)\tPrec@1 91.406 (92.685)\tPrec@5 98.828 (99.503)\n",
            "Epoch: [7][20/66], lr: 0.01000\tTime 0.100 (0.130)\tData 0.002 (0.031)\tLoss 1.1031 (1.3801)\tPrec@1 93.750 (93.080)\tPrec@5 100.000 (99.423)\n",
            "Epoch: [7][30/66], lr: 0.01000\tTime 0.092 (0.121)\tData 0.012 (0.024)\tLoss 1.1375 (1.3456)\tPrec@1 94.531 (93.259)\tPrec@5 100.000 (99.483)\n",
            "Epoch: [7][40/66], lr: 0.01000\tTime 0.108 (0.116)\tData 0.000 (0.020)\tLoss 1.2172 (1.3090)\tPrec@1 93.750 (93.512)\tPrec@5 99.609 (99.533)\n",
            "Epoch: [7][50/66], lr: 0.01000\tTime 0.096 (0.114)\tData 0.011 (0.017)\tLoss 1.4035 (1.3126)\tPrec@1 91.797 (93.421)\tPrec@5 99.219 (99.548)\n",
            "Epoch: [7][60/66], lr: 0.01000\tTime 0.075 (0.110)\tData 0.000 (0.015)\tLoss 1.5784 (1.3558)\tPrec@1 93.359 (93.231)\tPrec@5 100.000 (99.558)\n",
            "Test: [0/261]\tTime 0.315 (0.315)\tLoss 7.3518 (7.3518)\tPrec@1 67.000 (67.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/261]\tTime 0.014 (0.055)\tLoss 8.3316 (7.7516)\tPrec@1 64.000 (66.091)\tPrec@5 93.000 (93.545)\n",
            "Test: [20/261]\tTime 0.027 (0.043)\tLoss 6.9622 (7.4561)\tPrec@1 65.000 (67.048)\tPrec@5 94.000 (93.762)\n",
            "Test: [30/261]\tTime 0.023 (0.039)\tLoss 5.5973 (7.1591)\tPrec@1 73.000 (68.742)\tPrec@5 99.000 (94.161)\n",
            "Test: [40/261]\tTime 0.011 (0.036)\tLoss 5.9374 (7.0608)\tPrec@1 74.000 (69.220)\tPrec@5 95.000 (94.341)\n",
            "Test: [50/261]\tTime 0.028 (0.034)\tLoss 7.3012 (6.9298)\tPrec@1 68.000 (69.686)\tPrec@5 92.000 (94.451)\n",
            "Test: [60/261]\tTime 0.033 (0.033)\tLoss 8.2144 (6.8718)\tPrec@1 63.000 (69.738)\tPrec@5 94.000 (94.623)\n",
            "Test: [70/261]\tTime 0.021 (0.032)\tLoss 7.0554 (6.8484)\tPrec@1 68.000 (69.972)\tPrec@5 92.000 (94.592)\n",
            "Test: [80/261]\tTime 0.032 (0.031)\tLoss 6.5905 (6.8408)\tPrec@1 71.000 (70.062)\tPrec@5 96.000 (94.593)\n",
            "Test: [90/261]\tTime 0.025 (0.031)\tLoss 6.7056 (6.8722)\tPrec@1 73.000 (70.066)\tPrec@5 92.000 (94.451)\n",
            "Test: [100/261]\tTime 0.027 (0.031)\tLoss 7.8478 (6.8419)\tPrec@1 70.000 (70.178)\tPrec@5 89.000 (94.505)\n",
            "Test: [110/261]\tTime 0.017 (0.030)\tLoss 7.2671 (6.8082)\tPrec@1 66.000 (70.306)\tPrec@5 93.000 (94.523)\n",
            "Test: [120/261]\tTime 0.023 (0.030)\tLoss 5.4143 (6.7815)\tPrec@1 76.000 (70.430)\tPrec@5 95.000 (94.504)\n",
            "Test: [130/261]\tTime 0.042 (0.030)\tLoss 6.7266 (6.7625)\tPrec@1 70.000 (70.580)\tPrec@5 94.000 (94.489)\n",
            "Test: [140/261]\tTime 0.031 (0.030)\tLoss 7.2070 (6.7540)\tPrec@1 69.000 (70.674)\tPrec@5 92.000 (94.461)\n",
            "Test: [150/261]\tTime 0.030 (0.029)\tLoss 5.5224 (6.7664)\tPrec@1 76.000 (70.570)\tPrec@5 94.000 (94.377)\n",
            "Test: [160/261]\tTime 0.025 (0.029)\tLoss 5.4056 (6.7660)\tPrec@1 78.000 (70.503)\tPrec@5 97.000 (94.453)\n",
            "Test: [170/261]\tTime 0.027 (0.029)\tLoss 5.3935 (6.7501)\tPrec@1 76.000 (70.608)\tPrec@5 96.000 (94.444)\n",
            "Test: [180/261]\tTime 0.022 (0.029)\tLoss 4.8304 (6.7381)\tPrec@1 80.000 (70.624)\tPrec@5 97.000 (94.481)\n",
            "Test: [190/261]\tTime 0.020 (0.029)\tLoss 5.8532 (6.7294)\tPrec@1 73.000 (70.665)\tPrec@5 94.000 (94.513)\n",
            "Test: [200/261]\tTime 0.027 (0.029)\tLoss 5.2775 (6.7267)\tPrec@1 78.000 (70.662)\tPrec@5 96.000 (94.517)\n",
            "Test: [210/261]\tTime 0.011 (0.028)\tLoss 6.1520 (6.6983)\tPrec@1 73.000 (70.820)\tPrec@5 97.000 (94.573)\n",
            "Test: [220/261]\tTime 0.048 (0.028)\tLoss 6.2014 (6.6853)\tPrec@1 70.000 (70.864)\tPrec@5 95.000 (94.597)\n",
            "Test: [230/261]\tTime 0.019 (0.028)\tLoss 8.9100 (6.7041)\tPrec@1 59.000 (70.758)\tPrec@5 93.000 (94.550)\n",
            "Test: [240/261]\tTime 0.024 (0.028)\tLoss 6.8545 (6.7083)\tPrec@1 71.000 (70.722)\tPrec@5 96.000 (94.535)\n",
            "Test: [250/261]\tTime 0.033 (0.028)\tLoss 7.4257 (6.6954)\tPrec@1 67.000 (70.777)\tPrec@5 93.000 (94.546)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 4.7893 (6.7042)\tPrec@1 71.875 (70.774)\tPrec@5 100.000 (94.526)\n",
            "val Results: Prec@1 70.774 Prec@5 94.526 Loss 6.70418\n",
            "val Class Accuracy: [0.447,0.820,0.943,0.873,0.927,0.418,0.597,0.742,0.573,0.044]\n",
            "Best Prec@1: 79.637\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [8][0/66], lr: 0.01000\tTime 0.650 (0.650)\tData 0.556 (0.556)\tLoss 1.9017 (1.9017)\tPrec@1 89.062 (89.062)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [8][10/66], lr: 0.01000\tTime 0.094 (0.153)\tData 0.000 (0.057)\tLoss 1.5796 (1.3221)\tPrec@1 91.016 (93.288)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [8][20/66], lr: 0.01000\tTime 0.179 (0.135)\tData 0.100 (0.042)\tLoss 1.4542 (1.3083)\tPrec@1 92.188 (93.155)\tPrec@5 99.219 (99.702)\n",
            "Epoch: [8][30/66], lr: 0.01000\tTime 0.118 (0.125)\tData 0.000 (0.030)\tLoss 1.2542 (1.2578)\tPrec@1 92.969 (93.473)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [8][40/66], lr: 0.01000\tTime 0.084 (0.120)\tData 0.003 (0.024)\tLoss 1.5190 (1.2764)\tPrec@1 92.188 (93.378)\tPrec@5 98.438 (99.590)\n",
            "Epoch: [8][50/66], lr: 0.01000\tTime 0.106 (0.117)\tData 0.005 (0.021)\tLoss 1.6976 (1.2722)\tPrec@1 92.188 (93.444)\tPrec@5 98.828 (99.556)\n",
            "Epoch: [8][60/66], lr: 0.01000\tTime 0.063 (0.113)\tData 0.000 (0.018)\tLoss 1.1887 (1.2814)\tPrec@1 94.141 (93.366)\tPrec@5 100.000 (99.571)\n",
            "Test: [0/261]\tTime 0.295 (0.295)\tLoss 4.5298 (4.5298)\tPrec@1 81.000 (81.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.024 (0.056)\tLoss 4.3624 (4.1843)\tPrec@1 83.000 (82.273)\tPrec@5 96.000 (96.455)\n",
            "Test: [20/261]\tTime 0.021 (0.043)\tLoss 5.6810 (4.3560)\tPrec@1 74.000 (81.524)\tPrec@5 94.000 (96.095)\n",
            "Test: [30/261]\tTime 0.023 (0.036)\tLoss 3.4871 (4.0615)\tPrec@1 86.000 (82.710)\tPrec@5 98.000 (96.387)\n",
            "Test: [40/261]\tTime 0.029 (0.034)\tLoss 3.2779 (3.9547)\tPrec@1 88.000 (83.244)\tPrec@5 99.000 (96.805)\n",
            "Test: [50/261]\tTime 0.044 (0.033)\tLoss 3.8758 (3.9009)\tPrec@1 85.000 (83.392)\tPrec@5 97.000 (96.804)\n",
            "Test: [60/261]\tTime 0.027 (0.033)\tLoss 3.6117 (3.8640)\tPrec@1 85.000 (83.607)\tPrec@5 99.000 (96.689)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 4.0133 (3.8839)\tPrec@1 83.000 (83.437)\tPrec@5 98.000 (96.676)\n",
            "Test: [80/261]\tTime 0.031 (0.031)\tLoss 3.7266 (3.9284)\tPrec@1 84.000 (83.235)\tPrec@5 97.000 (96.654)\n",
            "Test: [90/261]\tTime 0.022 (0.031)\tLoss 4.0953 (3.9596)\tPrec@1 86.000 (83.231)\tPrec@5 96.000 (96.615)\n",
            "Test: [100/261]\tTime 0.022 (0.030)\tLoss 3.8557 (3.9671)\tPrec@1 87.000 (83.178)\tPrec@5 96.000 (96.653)\n",
            "Test: [110/261]\tTime 0.019 (0.030)\tLoss 3.1017 (3.9291)\tPrec@1 90.000 (83.342)\tPrec@5 99.000 (96.685)\n",
            "Test: [120/261]\tTime 0.027 (0.030)\tLoss 3.5559 (3.9273)\tPrec@1 84.000 (83.339)\tPrec@5 97.000 (96.727)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 4.3823 (3.9397)\tPrec@1 80.000 (83.321)\tPrec@5 97.000 (96.672)\n",
            "Test: [140/261]\tTime 0.031 (0.029)\tLoss 5.3902 (3.9379)\tPrec@1 73.000 (83.333)\tPrec@5 94.000 (96.660)\n",
            "Test: [150/261]\tTime 0.014 (0.029)\tLoss 3.7875 (3.9333)\tPrec@1 82.000 (83.351)\tPrec@5 96.000 (96.662)\n",
            "Test: [160/261]\tTime 0.025 (0.029)\tLoss 3.8017 (3.9452)\tPrec@1 86.000 (83.273)\tPrec@5 96.000 (96.665)\n",
            "Test: [170/261]\tTime 0.025 (0.029)\tLoss 3.6828 (3.9331)\tPrec@1 84.000 (83.287)\tPrec@5 95.000 (96.667)\n",
            "Test: [180/261]\tTime 0.028 (0.029)\tLoss 4.3034 (3.9543)\tPrec@1 80.000 (83.144)\tPrec@5 96.000 (96.641)\n",
            "Test: [190/261]\tTime 0.035 (0.029)\tLoss 3.5943 (3.9456)\tPrec@1 86.000 (83.194)\tPrec@5 96.000 (96.691)\n",
            "Test: [200/261]\tTime 0.023 (0.028)\tLoss 3.3069 (3.9519)\tPrec@1 86.000 (83.174)\tPrec@5 98.000 (96.672)\n",
            "Test: [210/261]\tTime 0.032 (0.028)\tLoss 3.6645 (3.9341)\tPrec@1 86.000 (83.299)\tPrec@5 99.000 (96.697)\n",
            "Test: [220/261]\tTime 0.028 (0.028)\tLoss 4.7359 (3.9259)\tPrec@1 78.000 (83.294)\tPrec@5 97.000 (96.742)\n",
            "Test: [230/261]\tTime 0.037 (0.028)\tLoss 5.2097 (3.9363)\tPrec@1 77.000 (83.225)\tPrec@5 95.000 (96.723)\n",
            "Test: [240/261]\tTime 0.064 (0.028)\tLoss 3.6563 (3.9459)\tPrec@1 87.000 (83.203)\tPrec@5 96.000 (96.693)\n",
            "Test: [250/261]\tTime 0.037 (0.029)\tLoss 3.9071 (3.9382)\tPrec@1 83.000 (83.219)\tPrec@5 98.000 (96.693)\n",
            "Test: [260/261]\tTime 0.007 (0.028)\tLoss 2.5409 (3.9340)\tPrec@1 90.625 (83.251)\tPrec@5 100.000 (96.700)\n",
            "val Results: Prec@1 83.251 Prec@5 96.700 Loss 3.93395\n",
            "val Class Accuracy: [0.770,0.977,0.942,0.687,0.889,0.911,0.684,0.805,0.449,0.829]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [9][0/66], lr: 0.01000\tTime 0.956 (0.956)\tData 0.860 (0.860)\tLoss 1.5439 (1.5439)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [9][10/66], lr: 0.01000\tTime 0.134 (0.217)\tData 0.000 (0.103)\tLoss 1.2282 (1.2507)\tPrec@1 95.312 (93.572)\tPrec@5 99.219 (99.538)\n",
            "Epoch: [9][20/66], lr: 0.01000\tTime 0.116 (0.175)\tData 0.004 (0.065)\tLoss 1.3053 (1.1844)\tPrec@1 92.188 (94.066)\tPrec@5 98.828 (99.591)\n",
            "Epoch: [9][30/66], lr: 0.01000\tTime 0.095 (0.151)\tData 0.005 (0.046)\tLoss 1.2041 (1.2081)\tPrec@1 93.359 (93.876)\tPrec@5 99.609 (99.597)\n",
            "Epoch: [9][40/66], lr: 0.01000\tTime 0.100 (0.138)\tData 0.001 (0.036)\tLoss 1.4692 (1.1944)\tPrec@1 93.359 (93.960)\tPrec@5 99.609 (99.581)\n",
            "Epoch: [9][50/66], lr: 0.01000\tTime 0.115 (0.133)\tData 0.002 (0.032)\tLoss 1.0645 (1.1967)\tPrec@1 94.531 (93.934)\tPrec@5 99.219 (99.602)\n",
            "Epoch: [9][60/66], lr: 0.01000\tTime 0.076 (0.126)\tData 0.000 (0.027)\tLoss 1.0133 (1.1978)\tPrec@1 94.531 (93.910)\tPrec@5 99.609 (99.577)\n",
            "Test: [0/261]\tTime 0.330 (0.330)\tLoss 6.0665 (6.0665)\tPrec@1 77.000 (77.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.031 (0.059)\tLoss 6.4447 (6.6633)\tPrec@1 74.000 (71.000)\tPrec@5 95.000 (95.273)\n",
            "Test: [20/261]\tTime 0.027 (0.042)\tLoss 6.0302 (6.5736)\tPrec@1 74.000 (71.381)\tPrec@5 92.000 (94.857)\n",
            "Test: [30/261]\tTime 0.024 (0.038)\tLoss 4.9719 (6.2743)\tPrec@1 75.000 (72.774)\tPrec@5 98.000 (95.387)\n",
            "Test: [40/261]\tTime 0.010 (0.034)\tLoss 4.7150 (6.1711)\tPrec@1 82.000 (73.293)\tPrec@5 97.000 (95.732)\n",
            "Test: [50/261]\tTime 0.041 (0.033)\tLoss 4.8091 (6.0821)\tPrec@1 81.000 (73.667)\tPrec@5 98.000 (96.000)\n",
            "Test: [60/261]\tTime 0.022 (0.032)\tLoss 7.1066 (6.0864)\tPrec@1 74.000 (73.770)\tPrec@5 93.000 (95.852)\n",
            "Test: [70/261]\tTime 0.033 (0.031)\tLoss 6.6968 (6.0645)\tPrec@1 67.000 (73.662)\tPrec@5 97.000 (95.859)\n",
            "Test: [80/261]\tTime 0.027 (0.031)\tLoss 7.3033 (6.0682)\tPrec@1 69.000 (73.778)\tPrec@5 92.000 (95.741)\n",
            "Test: [90/261]\tTime 0.018 (0.030)\tLoss 8.0873 (6.1151)\tPrec@1 67.000 (73.549)\tPrec@5 93.000 (95.659)\n",
            "Test: [100/261]\tTime 0.031 (0.030)\tLoss 6.7578 (6.1012)\tPrec@1 71.000 (73.624)\tPrec@5 95.000 (95.644)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 5.3068 (6.0852)\tPrec@1 77.000 (73.703)\tPrec@5 99.000 (95.703)\n",
            "Test: [120/261]\tTime 0.034 (0.029)\tLoss 4.3575 (6.0926)\tPrec@1 85.000 (73.661)\tPrec@5 97.000 (95.727)\n",
            "Test: [130/261]\tTime 0.037 (0.029)\tLoss 5.8411 (6.0784)\tPrec@1 74.000 (73.740)\tPrec@5 95.000 (95.779)\n",
            "Test: [140/261]\tTime 0.029 (0.029)\tLoss 6.1649 (6.0687)\tPrec@1 77.000 (73.872)\tPrec@5 95.000 (95.745)\n",
            "Test: [150/261]\tTime 0.033 (0.029)\tLoss 5.2411 (6.0802)\tPrec@1 76.000 (73.868)\tPrec@5 96.000 (95.715)\n",
            "Test: [160/261]\tTime 0.048 (0.029)\tLoss 5.7009 (6.0907)\tPrec@1 76.000 (73.826)\tPrec@5 99.000 (95.739)\n",
            "Test: [170/261]\tTime 0.018 (0.029)\tLoss 4.4631 (6.0643)\tPrec@1 81.000 (73.912)\tPrec@5 97.000 (95.807)\n",
            "Test: [180/261]\tTime 0.035 (0.029)\tLoss 5.7885 (6.0870)\tPrec@1 76.000 (73.812)\tPrec@5 95.000 (95.807)\n",
            "Test: [190/261]\tTime 0.024 (0.029)\tLoss 4.4057 (6.0706)\tPrec@1 82.000 (73.874)\tPrec@5 97.000 (95.885)\n",
            "Test: [200/261]\tTime 0.025 (0.028)\tLoss 7.0978 (6.0858)\tPrec@1 71.000 (73.851)\tPrec@5 95.000 (95.856)\n",
            "Test: [210/261]\tTime 0.027 (0.028)\tLoss 4.8726 (6.0682)\tPrec@1 82.000 (73.948)\tPrec@5 94.000 (95.867)\n",
            "Test: [220/261]\tTime 0.017 (0.028)\tLoss 6.6431 (6.0653)\tPrec@1 72.000 (73.910)\tPrec@5 96.000 (95.896)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 6.4365 (6.0904)\tPrec@1 71.000 (73.775)\tPrec@5 92.000 (95.844)\n",
            "Test: [240/261]\tTime 0.031 (0.028)\tLoss 5.6333 (6.0874)\tPrec@1 78.000 (73.784)\tPrec@5 97.000 (95.846)\n",
            "Test: [250/261]\tTime 0.022 (0.028)\tLoss 6.0015 (6.0792)\tPrec@1 73.000 (73.817)\tPrec@5 98.000 (95.857)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.7495 (6.0803)\tPrec@1 84.375 (73.759)\tPrec@5 96.875 (95.867)\n",
            "val Results: Prec@1 73.759 Prec@5 95.867 Loss 6.08034\n",
            "val Class Accuracy: [0.622,0.903,0.978,0.704,0.878,0.674,0.874,0.125,0.495,0.503]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [10][0/66], lr: 0.01000\tTime 0.683 (0.683)\tData 0.576 (0.576)\tLoss 1.0195 (1.0195)\tPrec@1 94.531 (94.531)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [10][10/66], lr: 0.01000\tTime 0.097 (0.157)\tData 0.012 (0.060)\tLoss 1.7788 (1.3294)\tPrec@1 91.406 (93.217)\tPrec@5 98.438 (99.467)\n",
            "Epoch: [10][20/66], lr: 0.01000\tTime 0.089 (0.130)\tData 0.006 (0.034)\tLoss 1.4052 (1.2484)\tPrec@1 92.188 (93.583)\tPrec@5 99.219 (99.442)\n",
            "Epoch: [10][30/66], lr: 0.01000\tTime 0.106 (0.121)\tData 0.013 (0.026)\tLoss 1.3736 (1.2357)\tPrec@1 92.578 (93.687)\tPrec@5 99.219 (99.420)\n",
            "Epoch: [10][40/66], lr: 0.01000\tTime 0.081 (0.114)\tData 0.000 (0.021)\tLoss 1.4572 (1.2232)\tPrec@1 92.578 (93.769)\tPrec@5 100.000 (99.457)\n",
            "Epoch: [10][50/66], lr: 0.01000\tTime 0.111 (0.112)\tData 0.005 (0.018)\tLoss 1.0224 (1.1732)\tPrec@1 94.922 (94.003)\tPrec@5 100.000 (99.510)\n",
            "Epoch: [10][60/66], lr: 0.01000\tTime 0.065 (0.109)\tData 0.000 (0.016)\tLoss 0.9128 (1.1685)\tPrec@1 94.922 (94.025)\tPrec@5 99.609 (99.507)\n",
            "Test: [0/261]\tTime 0.304 (0.304)\tLoss 4.2174 (4.2174)\tPrec@1 80.000 (80.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.039 (0.060)\tLoss 4.8049 (4.9768)\tPrec@1 79.000 (76.545)\tPrec@5 95.000 (96.273)\n",
            "Test: [20/261]\tTime 0.017 (0.044)\tLoss 4.9010 (5.1128)\tPrec@1 75.000 (75.571)\tPrec@5 98.000 (96.667)\n",
            "Test: [30/261]\tTime 0.042 (0.038)\tLoss 4.2671 (4.8535)\tPrec@1 77.000 (76.806)\tPrec@5 97.000 (97.065)\n",
            "Test: [40/261]\tTime 0.016 (0.034)\tLoss 4.1090 (4.7069)\tPrec@1 82.000 (77.951)\tPrec@5 99.000 (97.171)\n",
            "Test: [50/261]\tTime 0.050 (0.034)\tLoss 4.4808 (4.7703)\tPrec@1 78.000 (77.627)\tPrec@5 97.000 (97.216)\n",
            "Test: [60/261]\tTime 0.011 (0.032)\tLoss 3.8865 (4.7504)\tPrec@1 82.000 (77.869)\tPrec@5 98.000 (97.115)\n",
            "Test: [70/261]\tTime 0.037 (0.032)\tLoss 3.5361 (4.7254)\tPrec@1 85.000 (78.028)\tPrec@5 98.000 (97.141)\n",
            "Test: [80/261]\tTime 0.031 (0.031)\tLoss 4.5905 (4.7722)\tPrec@1 78.000 (77.840)\tPrec@5 96.000 (97.123)\n",
            "Test: [90/261]\tTime 0.017 (0.031)\tLoss 4.6547 (4.7942)\tPrec@1 85.000 (77.802)\tPrec@5 96.000 (97.110)\n",
            "Test: [100/261]\tTime 0.018 (0.030)\tLoss 5.2528 (4.7822)\tPrec@1 74.000 (77.901)\tPrec@5 95.000 (97.119)\n",
            "Test: [110/261]\tTime 0.019 (0.030)\tLoss 3.7697 (4.7565)\tPrec@1 81.000 (77.946)\tPrec@5 96.000 (97.036)\n",
            "Test: [120/261]\tTime 0.046 (0.030)\tLoss 4.0192 (4.7494)\tPrec@1 82.000 (77.959)\tPrec@5 95.000 (96.959)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 4.9993 (4.7716)\tPrec@1 77.000 (77.878)\tPrec@5 97.000 (96.908)\n",
            "Test: [140/261]\tTime 0.036 (0.029)\tLoss 7.1884 (4.7807)\tPrec@1 64.000 (77.837)\tPrec@5 97.000 (96.872)\n",
            "Test: [150/261]\tTime 0.011 (0.029)\tLoss 5.2924 (4.7874)\tPrec@1 77.000 (77.868)\tPrec@5 97.000 (96.861)\n",
            "Test: [160/261]\tTime 0.022 (0.029)\tLoss 4.4730 (4.7835)\tPrec@1 81.000 (77.870)\tPrec@5 96.000 (96.876)\n",
            "Test: [170/261]\tTime 0.035 (0.029)\tLoss 4.6664 (4.7654)\tPrec@1 77.000 (77.930)\tPrec@5 96.000 (96.918)\n",
            "Test: [180/261]\tTime 0.023 (0.029)\tLoss 4.4933 (4.7721)\tPrec@1 77.000 (77.873)\tPrec@5 95.000 (96.884)\n",
            "Test: [190/261]\tTime 0.021 (0.029)\tLoss 4.1659 (4.7636)\tPrec@1 82.000 (77.901)\tPrec@5 97.000 (96.901)\n",
            "Test: [200/261]\tTime 0.028 (0.029)\tLoss 4.0002 (4.7592)\tPrec@1 80.000 (77.915)\tPrec@5 98.000 (96.935)\n",
            "Test: [210/261]\tTime 0.020 (0.028)\tLoss 4.2466 (4.7426)\tPrec@1 79.000 (77.995)\tPrec@5 96.000 (96.948)\n",
            "Test: [220/261]\tTime 0.017 (0.028)\tLoss 6.1032 (4.7517)\tPrec@1 72.000 (77.964)\tPrec@5 98.000 (96.973)\n",
            "Test: [230/261]\tTime 0.035 (0.028)\tLoss 5.3222 (4.7614)\tPrec@1 75.000 (77.939)\tPrec@5 96.000 (96.961)\n",
            "Test: [240/261]\tTime 0.040 (0.028)\tLoss 3.8639 (4.7637)\tPrec@1 82.000 (77.950)\tPrec@5 97.000 (96.934)\n",
            "Test: [250/261]\tTime 0.043 (0.028)\tLoss 5.5316 (4.7718)\tPrec@1 74.000 (77.888)\tPrec@5 97.000 (96.944)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.6515 (4.7596)\tPrec@1 90.625 (77.943)\tPrec@5 100.000 (96.965)\n",
            "val Results: Prec@1 77.943 Prec@5 96.965 Loss 4.75961\n",
            "val Class Accuracy: [0.920,0.981,0.716,0.681,0.769,0.827,0.821,0.608,0.481,0.745]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [11][0/66], lr: 0.01000\tTime 0.697 (0.697)\tData 0.599 (0.599)\tLoss 0.9450 (0.9450)\tPrec@1 94.531 (94.531)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [11][10/66], lr: 0.01000\tTime 0.098 (0.162)\tData 0.009 (0.062)\tLoss 0.7624 (1.0596)\tPrec@1 96.875 (94.425)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [11][20/66], lr: 0.01000\tTime 0.119 (0.133)\tData 0.006 (0.036)\tLoss 1.0870 (1.0378)\tPrec@1 94.922 (94.810)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [11][30/66], lr: 0.01000\tTime 0.094 (0.121)\tData 0.002 (0.026)\tLoss 1.0849 (1.0227)\tPrec@1 93.750 (94.771)\tPrec@5 100.000 (99.685)\n",
            "Epoch: [11][40/66], lr: 0.01000\tTime 0.091 (0.115)\tData 0.000 (0.021)\tLoss 0.9071 (1.0481)\tPrec@1 96.484 (94.627)\tPrec@5 99.219 (99.676)\n",
            "Epoch: [11][50/66], lr: 0.01000\tTime 0.103 (0.113)\tData 0.016 (0.018)\tLoss 1.2683 (1.0710)\tPrec@1 92.969 (94.501)\tPrec@5 98.828 (99.663)\n",
            "Epoch: [11][60/66], lr: 0.01000\tTime 0.081 (0.110)\tData 0.000 (0.016)\tLoss 1.2831 (1.0977)\tPrec@1 94.141 (94.346)\tPrec@5 100.000 (99.654)\n",
            "Test: [0/261]\tTime 0.271 (0.271)\tLoss 4.4203 (4.4203)\tPrec@1 82.000 (82.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.027 (0.055)\tLoss 4.7316 (4.2535)\tPrec@1 78.000 (80.455)\tPrec@5 98.000 (97.545)\n",
            "Test: [20/261]\tTime 0.043 (0.043)\tLoss 5.2383 (4.3817)\tPrec@1 77.000 (80.190)\tPrec@5 96.000 (97.381)\n",
            "Test: [30/261]\tTime 0.023 (0.037)\tLoss 3.6435 (4.1154)\tPrec@1 83.000 (81.484)\tPrec@5 99.000 (97.806)\n",
            "Test: [40/261]\tTime 0.021 (0.036)\tLoss 2.9279 (3.9812)\tPrec@1 88.000 (82.122)\tPrec@5 98.000 (98.073)\n",
            "Test: [50/261]\tTime 0.030 (0.034)\tLoss 2.6739 (3.9258)\tPrec@1 90.000 (82.471)\tPrec@5 99.000 (98.235)\n",
            "Test: [60/261]\tTime 0.013 (0.032)\tLoss 3.0473 (3.9122)\tPrec@1 86.000 (82.475)\tPrec@5 98.000 (98.098)\n",
            "Test: [70/261]\tTime 0.025 (0.032)\tLoss 3.8404 (3.9383)\tPrec@1 83.000 (82.338)\tPrec@5 98.000 (98.056)\n",
            "Test: [80/261]\tTime 0.019 (0.031)\tLoss 5.1909 (3.9487)\tPrec@1 74.000 (82.160)\tPrec@5 97.000 (98.037)\n",
            "Test: [90/261]\tTime 0.021 (0.031)\tLoss 4.1277 (3.9800)\tPrec@1 81.000 (82.033)\tPrec@5 97.000 (97.901)\n",
            "Test: [100/261]\tTime 0.040 (0.031)\tLoss 4.8442 (3.9783)\tPrec@1 78.000 (82.010)\tPrec@5 94.000 (97.851)\n",
            "Test: [110/261]\tTime 0.026 (0.030)\tLoss 3.3524 (3.9477)\tPrec@1 82.000 (82.153)\tPrec@5 99.000 (97.874)\n",
            "Test: [120/261]\tTime 0.024 (0.030)\tLoss 3.0087 (3.9480)\tPrec@1 87.000 (82.149)\tPrec@5 97.000 (97.909)\n",
            "Test: [130/261]\tTime 0.030 (0.030)\tLoss 4.5584 (3.9580)\tPrec@1 82.000 (82.046)\tPrec@5 96.000 (97.863)\n",
            "Test: [140/261]\tTime 0.021 (0.030)\tLoss 4.6359 (3.9385)\tPrec@1 80.000 (82.156)\tPrec@5 97.000 (97.858)\n",
            "Test: [150/261]\tTime 0.023 (0.029)\tLoss 4.0027 (3.9447)\tPrec@1 84.000 (82.199)\tPrec@5 99.000 (97.828)\n",
            "Test: [160/261]\tTime 0.031 (0.029)\tLoss 3.1574 (3.9379)\tPrec@1 87.000 (82.248)\tPrec@5 97.000 (97.826)\n",
            "Test: [170/261]\tTime 0.024 (0.029)\tLoss 3.7985 (3.9280)\tPrec@1 79.000 (82.240)\tPrec@5 97.000 (97.848)\n",
            "Test: [180/261]\tTime 0.011 (0.029)\tLoss 3.0022 (3.9309)\tPrec@1 86.000 (82.227)\tPrec@5 98.000 (97.812)\n",
            "Test: [190/261]\tTime 0.045 (0.029)\tLoss 3.4194 (3.9041)\tPrec@1 86.000 (82.346)\tPrec@5 98.000 (97.843)\n",
            "Test: [200/261]\tTime 0.043 (0.029)\tLoss 3.9198 (3.9156)\tPrec@1 82.000 (82.318)\tPrec@5 95.000 (97.791)\n",
            "Test: [210/261]\tTime 0.027 (0.029)\tLoss 3.7618 (3.9044)\tPrec@1 84.000 (82.403)\tPrec@5 98.000 (97.806)\n",
            "Test: [220/261]\tTime 0.021 (0.029)\tLoss 4.5890 (3.9019)\tPrec@1 81.000 (82.421)\tPrec@5 97.000 (97.824)\n",
            "Test: [230/261]\tTime 0.026 (0.029)\tLoss 5.6719 (3.9178)\tPrec@1 72.000 (82.312)\tPrec@5 93.000 (97.792)\n",
            "Test: [240/261]\tTime 0.049 (0.030)\tLoss 3.2343 (3.9140)\tPrec@1 86.000 (82.320)\tPrec@5 97.000 (97.780)\n",
            "Test: [250/261]\tTime 0.038 (0.030)\tLoss 3.4214 (3.9009)\tPrec@1 82.000 (82.398)\tPrec@5 99.000 (97.765)\n",
            "Test: [260/261]\tTime 0.007 (0.030)\tLoss 3.2770 (3.9014)\tPrec@1 84.375 (82.391)\tPrec@5 100.000 (97.753)\n",
            "val Results: Prec@1 82.391 Prec@5 97.753 Loss 3.90142\n",
            "val Class Accuracy: [0.758,0.964,0.915,0.730,0.825,0.772,0.844,0.612,0.664,0.868]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [12][0/66], lr: 0.01000\tTime 0.940 (0.940)\tData 0.791 (0.791)\tLoss 1.0829 (1.0829)\tPrec@1 94.531 (94.531)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [12][10/66], lr: 0.01000\tTime 0.121 (0.221)\tData 0.005 (0.092)\tLoss 1.2263 (0.9842)\tPrec@1 93.359 (94.851)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [12][20/66], lr: 0.01000\tTime 0.095 (0.167)\tData 0.008 (0.058)\tLoss 1.1821 (1.0472)\tPrec@1 92.578 (94.345)\tPrec@5 99.219 (99.740)\n",
            "Epoch: [12][30/66], lr: 0.01000\tTime 0.090 (0.147)\tData 0.005 (0.041)\tLoss 1.4524 (1.0524)\tPrec@1 92.969 (94.405)\tPrec@5 98.047 (99.635)\n",
            "Epoch: [12][40/66], lr: 0.01000\tTime 0.088 (0.137)\tData 0.000 (0.032)\tLoss 0.9336 (1.0362)\tPrec@1 94.531 (94.560)\tPrec@5 99.219 (99.619)\n",
            "Epoch: [12][50/66], lr: 0.01000\tTime 0.084 (0.130)\tData 0.007 (0.028)\tLoss 1.0484 (1.0445)\tPrec@1 94.531 (94.524)\tPrec@5 99.219 (99.632)\n",
            "Epoch: [12][60/66], lr: 0.01000\tTime 0.117 (0.125)\tData 0.000 (0.024)\tLoss 1.0021 (1.0623)\tPrec@1 94.531 (94.416)\tPrec@5 99.609 (99.635)\n",
            "Test: [0/261]\tTime 0.279 (0.279)\tLoss 5.2484 (5.2484)\tPrec@1 78.000 (78.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.019 (0.056)\tLoss 5.8336 (5.3979)\tPrec@1 75.000 (75.909)\tPrec@5 98.000 (97.000)\n",
            "Test: [20/261]\tTime 0.051 (0.043)\tLoss 6.3690 (5.5287)\tPrec@1 72.000 (75.667)\tPrec@5 96.000 (96.619)\n",
            "Test: [30/261]\tTime 0.037 (0.038)\tLoss 5.0176 (5.3776)\tPrec@1 77.000 (76.484)\tPrec@5 96.000 (96.516)\n",
            "Test: [40/261]\tTime 0.038 (0.034)\tLoss 4.2423 (5.3189)\tPrec@1 83.000 (76.634)\tPrec@5 97.000 (96.756)\n",
            "Test: [50/261]\tTime 0.036 (0.034)\tLoss 5.6275 (5.2472)\tPrec@1 75.000 (77.137)\tPrec@5 96.000 (96.843)\n",
            "Test: [60/261]\tTime 0.027 (0.032)\tLoss 5.3564 (5.1866)\tPrec@1 77.000 (77.557)\tPrec@5 98.000 (96.836)\n",
            "Test: [70/261]\tTime 0.011 (0.031)\tLoss 6.1550 (5.1858)\tPrec@1 73.000 (77.507)\tPrec@5 94.000 (96.803)\n",
            "Test: [80/261]\tTime 0.039 (0.031)\tLoss 4.8798 (5.2160)\tPrec@1 79.000 (77.395)\tPrec@5 95.000 (96.877)\n",
            "Test: [90/261]\tTime 0.032 (0.031)\tLoss 6.0853 (5.2667)\tPrec@1 76.000 (77.275)\tPrec@5 94.000 (96.725)\n",
            "Test: [100/261]\tTime 0.020 (0.030)\tLoss 5.2308 (5.2506)\tPrec@1 79.000 (77.376)\tPrec@5 95.000 (96.762)\n",
            "Test: [110/261]\tTime 0.028 (0.030)\tLoss 4.2941 (5.2050)\tPrec@1 82.000 (77.577)\tPrec@5 97.000 (96.811)\n",
            "Test: [120/261]\tTime 0.044 (0.030)\tLoss 4.2580 (5.2179)\tPrec@1 79.000 (77.504)\tPrec@5 97.000 (96.777)\n",
            "Test: [130/261]\tTime 0.028 (0.030)\tLoss 5.1180 (5.2134)\tPrec@1 77.000 (77.511)\tPrec@5 95.000 (96.725)\n",
            "Test: [140/261]\tTime 0.049 (0.029)\tLoss 5.4357 (5.2214)\tPrec@1 74.000 (77.461)\tPrec@5 96.000 (96.766)\n",
            "Test: [150/261]\tTime 0.037 (0.029)\tLoss 4.0033 (5.2134)\tPrec@1 83.000 (77.583)\tPrec@5 98.000 (96.755)\n",
            "Test: [160/261]\tTime 0.047 (0.029)\tLoss 4.5424 (5.2104)\tPrec@1 80.000 (77.547)\tPrec@5 97.000 (96.758)\n",
            "Test: [170/261]\tTime 0.041 (0.029)\tLoss 4.6599 (5.1949)\tPrec@1 77.000 (77.602)\tPrec@5 97.000 (96.795)\n",
            "Test: [180/261]\tTime 0.018 (0.029)\tLoss 4.4756 (5.1958)\tPrec@1 82.000 (77.630)\tPrec@5 95.000 (96.818)\n",
            "Test: [190/261]\tTime 0.023 (0.029)\tLoss 4.6770 (5.1752)\tPrec@1 79.000 (77.717)\tPrec@5 98.000 (96.869)\n",
            "Test: [200/261]\tTime 0.028 (0.029)\tLoss 4.8774 (5.1712)\tPrec@1 76.000 (77.672)\tPrec@5 99.000 (96.900)\n",
            "Test: [210/261]\tTime 0.041 (0.029)\tLoss 4.1341 (5.1510)\tPrec@1 83.000 (77.754)\tPrec@5 98.000 (96.915)\n",
            "Test: [220/261]\tTime 0.032 (0.028)\tLoss 6.2571 (5.1574)\tPrec@1 73.000 (77.670)\tPrec@5 96.000 (96.910)\n",
            "Test: [230/261]\tTime 0.028 (0.028)\tLoss 5.3204 (5.1604)\tPrec@1 76.000 (77.619)\tPrec@5 97.000 (96.909)\n",
            "Test: [240/261]\tTime 0.021 (0.028)\tLoss 5.0545 (5.1624)\tPrec@1 78.000 (77.581)\tPrec@5 97.000 (96.905)\n",
            "Test: [250/261]\tTime 0.034 (0.028)\tLoss 5.0832 (5.1545)\tPrec@1 78.000 (77.637)\tPrec@5 100.000 (96.916)\n",
            "Test: [260/261]\tTime 0.007 (0.028)\tLoss 5.0005 (5.1664)\tPrec@1 71.875 (77.585)\tPrec@5 96.875 (96.877)\n",
            "val Results: Prec@1 77.585 Prec@5 96.877 Loss 5.16638\n",
            "val Class Accuracy: [0.722,0.959,0.903,0.912,0.780,0.836,0.539,0.567,0.497,0.423]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [13][0/66], lr: 0.01000\tTime 0.719 (0.719)\tData 0.626 (0.626)\tLoss 1.3438 (1.3438)\tPrec@1 91.797 (91.797)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [13][10/66], lr: 0.01000\tTime 0.083 (0.153)\tData 0.003 (0.062)\tLoss 0.9415 (0.8761)\tPrec@1 94.141 (95.384)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [13][20/66], lr: 0.01000\tTime 0.106 (0.130)\tData 0.004 (0.035)\tLoss 0.9914 (0.9526)\tPrec@1 96.094 (95.033)\tPrec@5 99.219 (99.721)\n",
            "Epoch: [13][30/66], lr: 0.01000\tTime 0.114 (0.121)\tData 0.002 (0.025)\tLoss 0.8943 (1.0081)\tPrec@1 95.312 (94.695)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [13][40/66], lr: 0.01000\tTime 0.078 (0.116)\tData 0.002 (0.021)\tLoss 1.3562 (1.0341)\tPrec@1 93.359 (94.655)\tPrec@5 99.219 (99.667)\n",
            "Epoch: [13][50/66], lr: 0.01000\tTime 0.087 (0.114)\tData 0.000 (0.018)\tLoss 0.8715 (1.0268)\tPrec@1 96.484 (94.707)\tPrec@5 100.000 (99.671)\n",
            "Epoch: [13][60/66], lr: 0.01000\tTime 0.067 (0.111)\tData 0.000 (0.016)\tLoss 0.7786 (1.0223)\tPrec@1 96.484 (94.755)\tPrec@5 100.000 (99.686)\n",
            "Test: [0/261]\tTime 0.342 (0.342)\tLoss 4.7044 (4.7044)\tPrec@1 80.000 (80.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.034 (0.059)\tLoss 4.1607 (4.5992)\tPrec@1 84.000 (79.091)\tPrec@5 96.000 (96.273)\n",
            "Test: [20/261]\tTime 0.035 (0.042)\tLoss 4.4213 (4.3709)\tPrec@1 80.000 (80.667)\tPrec@5 92.000 (95.952)\n",
            "Test: [30/261]\tTime 0.025 (0.038)\tLoss 2.4593 (4.1472)\tPrec@1 91.000 (81.903)\tPrec@5 97.000 (96.419)\n",
            "Test: [40/261]\tTime 0.026 (0.036)\tLoss 2.7572 (4.0309)\tPrec@1 90.000 (82.341)\tPrec@5 97.000 (96.707)\n",
            "Test: [50/261]\tTime 0.032 (0.034)\tLoss 3.4937 (3.8910)\tPrec@1 89.000 (83.078)\tPrec@5 97.000 (96.843)\n",
            "Test: [60/261]\tTime 0.030 (0.033)\tLoss 3.4425 (3.8822)\tPrec@1 88.000 (83.115)\tPrec@5 97.000 (96.754)\n",
            "Test: [70/261]\tTime 0.011 (0.032)\tLoss 4.4231 (3.9089)\tPrec@1 80.000 (82.972)\tPrec@5 96.000 (96.789)\n",
            "Test: [80/261]\tTime 0.020 (0.031)\tLoss 4.0778 (3.9002)\tPrec@1 81.000 (83.000)\tPrec@5 91.000 (96.679)\n",
            "Test: [90/261]\tTime 0.033 (0.031)\tLoss 3.9809 (3.9677)\tPrec@1 83.000 (82.659)\tPrec@5 94.000 (96.571)\n",
            "Test: [100/261]\tTime 0.023 (0.031)\tLoss 4.4183 (3.9722)\tPrec@1 82.000 (82.644)\tPrec@5 94.000 (96.663)\n",
            "Test: [110/261]\tTime 0.044 (0.030)\tLoss 2.8935 (3.9310)\tPrec@1 88.000 (82.820)\tPrec@5 98.000 (96.667)\n",
            "Test: [120/261]\tTime 0.028 (0.030)\tLoss 3.1065 (3.9245)\tPrec@1 86.000 (82.793)\tPrec@5 97.000 (96.620)\n",
            "Test: [130/261]\tTime 0.035 (0.030)\tLoss 3.8776 (3.9205)\tPrec@1 81.000 (82.809)\tPrec@5 92.000 (96.626)\n",
            "Test: [140/261]\tTime 0.033 (0.030)\tLoss 5.0238 (3.9346)\tPrec@1 79.000 (82.759)\tPrec@5 95.000 (96.645)\n",
            "Test: [150/261]\tTime 0.011 (0.030)\tLoss 2.8451 (3.9385)\tPrec@1 88.000 (82.795)\tPrec@5 98.000 (96.636)\n",
            "Test: [160/261]\tTime 0.043 (0.030)\tLoss 3.8825 (3.9310)\tPrec@1 84.000 (82.820)\tPrec@5 97.000 (96.627)\n",
            "Test: [170/261]\tTime 0.034 (0.029)\tLoss 3.3839 (3.9044)\tPrec@1 82.000 (82.942)\tPrec@5 98.000 (96.643)\n",
            "Test: [180/261]\tTime 0.032 (0.029)\tLoss 3.2947 (3.9050)\tPrec@1 88.000 (82.917)\tPrec@5 95.000 (96.657)\n",
            "Test: [190/261]\tTime 0.014 (0.029)\tLoss 3.9673 (3.9044)\tPrec@1 83.000 (82.932)\tPrec@5 98.000 (96.665)\n",
            "Test: [200/261]\tTime 0.034 (0.029)\tLoss 2.5949 (3.9086)\tPrec@1 88.000 (82.896)\tPrec@5 99.000 (96.672)\n",
            "Test: [210/261]\tTime 0.039 (0.029)\tLoss 3.9672 (3.8999)\tPrec@1 81.000 (82.915)\tPrec@5 99.000 (96.678)\n",
            "Test: [220/261]\tTime 0.038 (0.029)\tLoss 4.3106 (3.8933)\tPrec@1 82.000 (82.937)\tPrec@5 96.000 (96.683)\n",
            "Test: [230/261]\tTime 0.029 (0.029)\tLoss 5.3501 (3.9113)\tPrec@1 75.000 (82.835)\tPrec@5 93.000 (96.662)\n",
            "Test: [240/261]\tTime 0.012 (0.029)\tLoss 3.7835 (3.9097)\tPrec@1 86.000 (82.859)\tPrec@5 94.000 (96.656)\n",
            "Test: [250/261]\tTime 0.011 (0.028)\tLoss 3.7238 (3.8823)\tPrec@1 81.000 (82.948)\tPrec@5 99.000 (96.685)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.2037 (3.8812)\tPrec@1 93.750 (82.906)\tPrec@5 100.000 (96.696)\n",
            "val Results: Prec@1 82.906 Prec@5 96.696 Loss 3.88124\n",
            "val Class Accuracy: [0.574,0.921,0.926,0.784,0.845,0.919,0.778,0.891,0.629,0.674]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [14][0/66], lr: 0.01000\tTime 0.652 (0.652)\tData 0.551 (0.551)\tLoss 0.8811 (0.8811)\tPrec@1 96.094 (96.094)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [14][10/66], lr: 0.01000\tTime 0.097 (0.148)\tData 0.004 (0.056)\tLoss 1.0145 (0.9690)\tPrec@1 94.141 (95.241)\tPrec@5 99.609 (99.574)\n",
            "Epoch: [14][20/66], lr: 0.01000\tTime 0.088 (0.128)\tData 0.005 (0.037)\tLoss 0.7037 (0.9876)\tPrec@1 96.484 (95.071)\tPrec@5 100.000 (99.702)\n",
            "Epoch: [14][30/66], lr: 0.01000\tTime 0.095 (0.120)\tData 0.005 (0.027)\tLoss 0.8073 (1.0017)\tPrec@1 96.094 (94.960)\tPrec@5 100.000 (99.710)\n",
            "Epoch: [14][40/66], lr: 0.01000\tTime 0.106 (0.116)\tData 0.000 (0.022)\tLoss 0.8027 (1.0178)\tPrec@1 96.094 (94.922)\tPrec@5 99.609 (99.705)\n",
            "Epoch: [14][50/66], lr: 0.01000\tTime 0.105 (0.113)\tData 0.005 (0.018)\tLoss 1.2590 (1.0236)\tPrec@1 93.359 (94.861)\tPrec@5 99.609 (99.671)\n",
            "Epoch: [14][60/66], lr: 0.01000\tTime 0.074 (0.111)\tData 0.000 (0.016)\tLoss 1.1237 (1.0493)\tPrec@1 93.750 (94.666)\tPrec@5 100.000 (99.641)\n",
            "Test: [0/261]\tTime 0.331 (0.331)\tLoss 4.2460 (4.2460)\tPrec@1 81.000 (81.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.057 (0.057)\tLoss 5.2588 (4.6895)\tPrec@1 79.000 (78.909)\tPrec@5 94.000 (95.818)\n",
            "Test: [20/261]\tTime 0.012 (0.043)\tLoss 4.6800 (4.7199)\tPrec@1 81.000 (79.143)\tPrec@5 93.000 (95.381)\n",
            "Test: [30/261]\tTime 0.020 (0.039)\tLoss 3.4338 (4.4520)\tPrec@1 83.000 (80.516)\tPrec@5 98.000 (95.935)\n",
            "Test: [40/261]\tTime 0.035 (0.037)\tLoss 3.7080 (4.3520)\tPrec@1 85.000 (80.976)\tPrec@5 96.000 (96.293)\n",
            "Test: [50/261]\tTime 0.042 (0.035)\tLoss 4.7639 (4.2797)\tPrec@1 77.000 (81.353)\tPrec@5 97.000 (96.235)\n",
            "Test: [60/261]\tTime 0.021 (0.034)\tLoss 4.4327 (4.2390)\tPrec@1 82.000 (81.574)\tPrec@5 97.000 (96.213)\n",
            "Test: [70/261]\tTime 0.011 (0.033)\tLoss 5.2352 (4.2459)\tPrec@1 79.000 (81.423)\tPrec@5 96.000 (96.155)\n",
            "Test: [80/261]\tTime 0.011 (0.032)\tLoss 3.8780 (4.2711)\tPrec@1 85.000 (81.321)\tPrec@5 98.000 (96.123)\n",
            "Test: [90/261]\tTime 0.051 (0.032)\tLoss 4.6208 (4.3245)\tPrec@1 81.000 (81.165)\tPrec@5 95.000 (95.989)\n",
            "Test: [100/261]\tTime 0.051 (0.031)\tLoss 4.7323 (4.3374)\tPrec@1 81.000 (81.168)\tPrec@5 96.000 (95.941)\n",
            "Test: [110/261]\tTime 0.031 (0.031)\tLoss 3.6316 (4.3120)\tPrec@1 86.000 (81.252)\tPrec@5 98.000 (95.946)\n",
            "Test: [120/261]\tTime 0.026 (0.031)\tLoss 3.6139 (4.3033)\tPrec@1 83.000 (81.289)\tPrec@5 97.000 (95.992)\n",
            "Test: [130/261]\tTime 0.033 (0.031)\tLoss 3.8935 (4.2859)\tPrec@1 83.000 (81.359)\tPrec@5 96.000 (95.962)\n",
            "Test: [140/261]\tTime 0.044 (0.030)\tLoss 5.7863 (4.2943)\tPrec@1 72.000 (81.298)\tPrec@5 94.000 (95.979)\n",
            "Test: [150/261]\tTime 0.023 (0.030)\tLoss 4.2142 (4.2860)\tPrec@1 82.000 (81.364)\tPrec@5 96.000 (96.007)\n",
            "Test: [160/261]\tTime 0.027 (0.030)\tLoss 3.9293 (4.2836)\tPrec@1 85.000 (81.385)\tPrec@5 98.000 (96.031)\n",
            "Test: [170/261]\tTime 0.023 (0.030)\tLoss 3.3189 (4.2741)\tPrec@1 88.000 (81.450)\tPrec@5 95.000 (96.029)\n",
            "Test: [180/261]\tTime 0.033 (0.031)\tLoss 3.3633 (4.2848)\tPrec@1 85.000 (81.337)\tPrec@5 95.000 (96.033)\n",
            "Test: [190/261]\tTime 0.055 (0.031)\tLoss 3.7870 (4.2737)\tPrec@1 82.000 (81.419)\tPrec@5 95.000 (96.079)\n",
            "Test: [200/261]\tTime 0.041 (0.032)\tLoss 3.4790 (4.2857)\tPrec@1 82.000 (81.338)\tPrec@5 98.000 (96.060)\n",
            "Test: [210/261]\tTime 0.026 (0.032)\tLoss 2.9597 (4.2674)\tPrec@1 86.000 (81.412)\tPrec@5 97.000 (96.062)\n",
            "Test: [220/261]\tTime 0.024 (0.032)\tLoss 4.4345 (4.2693)\tPrec@1 82.000 (81.398)\tPrec@5 95.000 (96.054)\n",
            "Test: [230/261]\tTime 0.059 (0.033)\tLoss 4.7229 (4.2702)\tPrec@1 81.000 (81.372)\tPrec@5 93.000 (96.039)\n",
            "Test: [240/261]\tTime 0.038 (0.033)\tLoss 3.9920 (4.2760)\tPrec@1 83.000 (81.336)\tPrec@5 95.000 (95.988)\n",
            "Test: [250/261]\tTime 0.018 (0.033)\tLoss 4.1040 (4.2631)\tPrec@1 84.000 (81.426)\tPrec@5 98.000 (96.004)\n",
            "Test: [260/261]\tTime 0.007 (0.033)\tLoss 2.9558 (4.2721)\tPrec@1 87.500 (81.388)\tPrec@5 100.000 (95.978)\n",
            "val Results: Prec@1 81.388 Prec@5 95.978 Loss 4.27212\n",
            "val Class Accuracy: [0.733,0.959,0.894,0.815,0.922,0.857,0.766,0.746,0.405,0.561]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [15][0/66], lr: 0.01000\tTime 0.795 (0.795)\tData 0.696 (0.696)\tLoss 0.9657 (0.9657)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [15][10/66], lr: 0.01000\tTime 0.113 (0.169)\tData 0.000 (0.069)\tLoss 0.6956 (0.8720)\tPrec@1 96.875 (95.739)\tPrec@5 99.219 (99.645)\n",
            "Epoch: [15][20/66], lr: 0.01000\tTime 0.128 (0.137)\tData 0.004 (0.039)\tLoss 0.9998 (0.8928)\tPrec@1 95.312 (95.443)\tPrec@5 99.609 (99.702)\n",
            "Epoch: [15][30/66], lr: 0.01000\tTime 0.106 (0.125)\tData 0.000 (0.028)\tLoss 0.7300 (0.9127)\tPrec@1 95.703 (95.312)\tPrec@5 99.609 (99.660)\n",
            "Epoch: [15][40/66], lr: 0.01000\tTime 0.080 (0.119)\tData 0.000 (0.023)\tLoss 0.9752 (0.8980)\tPrec@1 95.312 (95.398)\tPrec@5 100.000 (99.695)\n",
            "Epoch: [15][50/66], lr: 0.01000\tTime 0.081 (0.116)\tData 0.000 (0.020)\tLoss 0.8483 (0.8985)\tPrec@1 95.703 (95.427)\tPrec@5 99.609 (99.686)\n",
            "Epoch: [15][60/66], lr: 0.01000\tTime 0.057 (0.113)\tData 0.000 (0.017)\tLoss 1.0540 (0.9311)\tPrec@1 94.531 (95.197)\tPrec@5 99.609 (99.661)\n",
            "Test: [0/261]\tTime 0.344 (0.344)\tLoss 3.9331 (3.9331)\tPrec@1 84.000 (84.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.036 (0.058)\tLoss 5.0771 (4.5512)\tPrec@1 76.000 (80.182)\tPrec@5 97.000 (96.182)\n",
            "Test: [20/261]\tTime 0.020 (0.044)\tLoss 4.3097 (4.4586)\tPrec@1 81.000 (80.952)\tPrec@5 95.000 (95.810)\n",
            "Test: [30/261]\tTime 0.022 (0.036)\tLoss 2.6904 (4.2128)\tPrec@1 88.000 (82.258)\tPrec@5 97.000 (96.290)\n",
            "Test: [40/261]\tTime 0.025 (0.035)\tLoss 3.1146 (4.1523)\tPrec@1 89.000 (82.463)\tPrec@5 96.000 (96.585)\n",
            "Test: [50/261]\tTime 0.020 (0.033)\tLoss 3.7872 (4.1131)\tPrec@1 85.000 (82.529)\tPrec@5 97.000 (96.627)\n",
            "Test: [60/261]\tTime 0.042 (0.032)\tLoss 4.5843 (4.0813)\tPrec@1 81.000 (82.770)\tPrec@5 99.000 (96.672)\n",
            "Test: [70/261]\tTime 0.030 (0.031)\tLoss 4.6913 (4.0762)\tPrec@1 80.000 (82.817)\tPrec@5 97.000 (96.676)\n",
            "Test: [80/261]\tTime 0.048 (0.031)\tLoss 3.6767 (4.0903)\tPrec@1 87.000 (82.741)\tPrec@5 97.000 (96.691)\n",
            "Test: [90/261]\tTime 0.037 (0.030)\tLoss 4.5538 (4.1315)\tPrec@1 85.000 (82.593)\tPrec@5 96.000 (96.582)\n",
            "Test: [100/261]\tTime 0.030 (0.030)\tLoss 5.6721 (4.1341)\tPrec@1 76.000 (82.535)\tPrec@5 95.000 (96.644)\n",
            "Test: [110/261]\tTime 0.047 (0.030)\tLoss 3.6700 (4.0930)\tPrec@1 84.000 (82.712)\tPrec@5 97.000 (96.676)\n",
            "Test: [120/261]\tTime 0.027 (0.030)\tLoss 3.4218 (4.0948)\tPrec@1 86.000 (82.727)\tPrec@5 95.000 (96.620)\n",
            "Test: [130/261]\tTime 0.021 (0.029)\tLoss 3.5035 (4.0803)\tPrec@1 86.000 (82.695)\tPrec@5 96.000 (96.618)\n",
            "Test: [140/261]\tTime 0.028 (0.029)\tLoss 4.5018 (4.0764)\tPrec@1 81.000 (82.716)\tPrec@5 96.000 (96.660)\n",
            "Test: [150/261]\tTime 0.018 (0.029)\tLoss 3.6086 (4.0755)\tPrec@1 82.000 (82.742)\tPrec@5 97.000 (96.675)\n",
            "Test: [160/261]\tTime 0.045 (0.029)\tLoss 3.1045 (4.0572)\tPrec@1 89.000 (82.801)\tPrec@5 98.000 (96.708)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 3.8875 (4.0434)\tPrec@1 82.000 (82.848)\tPrec@5 94.000 (96.719)\n",
            "Test: [180/261]\tTime 0.029 (0.028)\tLoss 3.0542 (4.0458)\tPrec@1 89.000 (82.845)\tPrec@5 95.000 (96.707)\n",
            "Test: [190/261]\tTime 0.025 (0.029)\tLoss 3.5539 (4.0295)\tPrec@1 85.000 (82.885)\tPrec@5 97.000 (96.759)\n",
            "Test: [200/261]\tTime 0.043 (0.029)\tLoss 3.4011 (4.0232)\tPrec@1 84.000 (82.881)\tPrec@5 98.000 (96.781)\n",
            "Test: [210/261]\tTime 0.020 (0.029)\tLoss 3.4135 (4.0232)\tPrec@1 84.000 (82.839)\tPrec@5 99.000 (96.758)\n",
            "Test: [220/261]\tTime 0.039 (0.028)\tLoss 4.1472 (4.0227)\tPrec@1 83.000 (82.833)\tPrec@5 96.000 (96.738)\n",
            "Test: [230/261]\tTime 0.027 (0.028)\tLoss 5.0608 (4.0226)\tPrec@1 79.000 (82.827)\tPrec@5 94.000 (96.710)\n",
            "Test: [240/261]\tTime 0.032 (0.028)\tLoss 3.2188 (4.0272)\tPrec@1 85.000 (82.788)\tPrec@5 98.000 (96.689)\n",
            "Test: [250/261]\tTime 0.035 (0.028)\tLoss 5.0559 (4.0189)\tPrec@1 79.000 (82.813)\tPrec@5 99.000 (96.721)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.2346 (4.0347)\tPrec@1 90.625 (82.740)\tPrec@5 96.875 (96.677)\n",
            "val Results: Prec@1 82.740 Prec@5 96.677 Loss 4.03471\n",
            "val Class Accuracy: [0.659,0.976,0.923,0.799,0.896,0.898,0.791,0.629,0.716,0.537]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [16][0/66], lr: 0.01000\tTime 0.622 (0.622)\tData 0.503 (0.503)\tLoss 1.3441 (1.3441)\tPrec@1 93.359 (93.359)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [16][10/66], lr: 0.01000\tTime 0.088 (0.154)\tData 0.007 (0.050)\tLoss 0.8690 (1.0735)\tPrec@1 94.531 (94.247)\tPrec@5 100.000 (99.716)\n",
            "Epoch: [16][20/66], lr: 0.01000\tTime 0.088 (0.131)\tData 0.005 (0.031)\tLoss 1.0729 (0.9778)\tPrec@1 93.750 (94.810)\tPrec@5 99.609 (99.702)\n",
            "Epoch: [16][30/66], lr: 0.01000\tTime 0.120 (0.123)\tData 0.000 (0.022)\tLoss 1.1226 (0.9436)\tPrec@1 94.922 (95.023)\tPrec@5 99.219 (99.698)\n",
            "Epoch: [16][40/66], lr: 0.01000\tTime 0.094 (0.117)\tData 0.000 (0.018)\tLoss 1.2083 (0.9722)\tPrec@1 93.750 (94.941)\tPrec@5 99.609 (99.714)\n",
            "Epoch: [16][50/66], lr: 0.01000\tTime 0.105 (0.115)\tData 0.010 (0.016)\tLoss 1.3506 (0.9579)\tPrec@1 92.578 (95.006)\tPrec@5 99.219 (99.709)\n",
            "Epoch: [16][60/66], lr: 0.01000\tTime 0.075 (0.111)\tData 0.000 (0.014)\tLoss 0.9651 (0.9577)\tPrec@1 95.703 (95.056)\tPrec@5 100.000 (99.705)\n",
            "Test: [0/261]\tTime 0.300 (0.300)\tLoss 4.0044 (4.0044)\tPrec@1 83.000 (83.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.040 (0.055)\tLoss 4.9946 (4.5813)\tPrec@1 79.000 (79.727)\tPrec@5 99.000 (95.909)\n",
            "Test: [20/261]\tTime 0.046 (0.044)\tLoss 5.1889 (4.5024)\tPrec@1 77.000 (80.429)\tPrec@5 95.000 (95.905)\n",
            "Test: [30/261]\tTime 0.029 (0.040)\tLoss 3.9492 (4.2931)\tPrec@1 79.000 (81.194)\tPrec@5 97.000 (96.419)\n",
            "Test: [40/261]\tTime 0.023 (0.037)\tLoss 3.6386 (4.1858)\tPrec@1 85.000 (81.634)\tPrec@5 95.000 (96.610)\n",
            "Test: [50/261]\tTime 0.012 (0.035)\tLoss 3.6842 (4.0939)\tPrec@1 85.000 (82.059)\tPrec@5 98.000 (96.804)\n",
            "Test: [60/261]\tTime 0.042 (0.034)\tLoss 3.8994 (4.0516)\tPrec@1 86.000 (82.443)\tPrec@5 98.000 (96.770)\n",
            "Test: [70/261]\tTime 0.028 (0.032)\tLoss 4.8882 (4.0669)\tPrec@1 78.000 (82.296)\tPrec@5 94.000 (96.690)\n",
            "Test: [80/261]\tTime 0.019 (0.032)\tLoss 4.6060 (4.0895)\tPrec@1 79.000 (82.284)\tPrec@5 97.000 (96.728)\n",
            "Test: [90/261]\tTime 0.016 (0.032)\tLoss 4.2302 (4.1546)\tPrec@1 84.000 (82.055)\tPrec@5 96.000 (96.593)\n",
            "Test: [100/261]\tTime 0.033 (0.031)\tLoss 4.8229 (4.1565)\tPrec@1 80.000 (82.050)\tPrec@5 93.000 (96.594)\n",
            "Test: [110/261]\tTime 0.036 (0.031)\tLoss 4.0089 (4.1292)\tPrec@1 82.000 (82.144)\tPrec@5 96.000 (96.586)\n",
            "Test: [120/261]\tTime 0.038 (0.031)\tLoss 3.0061 (4.1201)\tPrec@1 88.000 (82.190)\tPrec@5 98.000 (96.545)\n",
            "Test: [130/261]\tTime 0.027 (0.030)\tLoss 3.6532 (4.0960)\tPrec@1 86.000 (82.321)\tPrec@5 96.000 (96.550)\n",
            "Test: [140/261]\tTime 0.051 (0.031)\tLoss 4.8532 (4.0987)\tPrec@1 77.000 (82.241)\tPrec@5 96.000 (96.567)\n",
            "Test: [150/261]\tTime 0.015 (0.030)\tLoss 3.3987 (4.0895)\tPrec@1 85.000 (82.344)\tPrec@5 97.000 (96.556)\n",
            "Test: [160/261]\tTime 0.026 (0.030)\tLoss 3.3751 (4.0951)\tPrec@1 86.000 (82.342)\tPrec@5 97.000 (96.578)\n",
            "Test: [170/261]\tTime 0.011 (0.030)\tLoss 3.3856 (4.0779)\tPrec@1 84.000 (82.421)\tPrec@5 96.000 (96.585)\n",
            "Test: [180/261]\tTime 0.032 (0.030)\tLoss 3.0616 (4.0690)\tPrec@1 86.000 (82.431)\tPrec@5 96.000 (96.552)\n",
            "Test: [190/261]\tTime 0.032 (0.029)\tLoss 3.8876 (4.0507)\tPrec@1 81.000 (82.524)\tPrec@5 97.000 (96.592)\n",
            "Test: [200/261]\tTime 0.012 (0.029)\tLoss 3.0849 (4.0510)\tPrec@1 85.000 (82.512)\tPrec@5 98.000 (96.577)\n",
            "Test: [210/261]\tTime 0.026 (0.029)\tLoss 3.3803 (4.0425)\tPrec@1 84.000 (82.526)\tPrec@5 99.000 (96.583)\n",
            "Test: [220/261]\tTime 0.039 (0.029)\tLoss 5.0293 (4.0363)\tPrec@1 77.000 (82.516)\tPrec@5 94.000 (96.579)\n",
            "Test: [230/261]\tTime 0.035 (0.029)\tLoss 4.7306 (4.0470)\tPrec@1 82.000 (82.481)\tPrec@5 93.000 (96.558)\n",
            "Test: [240/261]\tTime 0.012 (0.029)\tLoss 3.2449 (4.0515)\tPrec@1 87.000 (82.444)\tPrec@5 97.000 (96.556)\n",
            "Test: [250/261]\tTime 0.013 (0.029)\tLoss 3.3926 (4.0398)\tPrec@1 87.000 (82.526)\tPrec@5 99.000 (96.586)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 3.0526 (4.0451)\tPrec@1 87.500 (82.514)\tPrec@5 96.875 (96.562)\n",
            "val Results: Prec@1 82.514 Prec@5 96.562 Loss 4.04509\n",
            "val Class Accuracy: [0.619,0.973,0.932,0.853,0.864,0.816,0.806,0.761,0.517,0.626]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [17][0/66], lr: 0.01000\tTime 0.674 (0.674)\tData 0.575 (0.575)\tLoss 0.7891 (0.7891)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][10/66], lr: 0.01000\tTime 0.098 (0.156)\tData 0.004 (0.058)\tLoss 0.6553 (0.7705)\tPrec@1 96.875 (96.129)\tPrec@5 99.219 (99.680)\n",
            "Epoch: [17][20/66], lr: 0.01000\tTime 0.101 (0.132)\tData 0.004 (0.034)\tLoss 0.6671 (0.7718)\tPrec@1 96.875 (96.168)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [17][30/66], lr: 0.01000\tTime 0.092 (0.122)\tData 0.007 (0.026)\tLoss 0.7462 (0.7816)\tPrec@1 96.094 (96.018)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [17][40/66], lr: 0.01000\tTime 0.125 (0.118)\tData 0.014 (0.022)\tLoss 0.7635 (0.8279)\tPrec@1 96.094 (95.808)\tPrec@5 99.219 (99.781)\n",
            "Epoch: [17][50/66], lr: 0.01000\tTime 0.103 (0.114)\tData 0.001 (0.018)\tLoss 1.5578 (0.8848)\tPrec@1 91.797 (95.504)\tPrec@5 99.609 (99.770)\n",
            "Epoch: [17][60/66], lr: 0.01000\tTime 0.073 (0.110)\tData 0.000 (0.016)\tLoss 0.6169 (0.8909)\tPrec@1 96.484 (95.441)\tPrec@5 100.000 (99.744)\n",
            "Test: [0/261]\tTime 0.337 (0.337)\tLoss 3.7314 (3.7314)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.026 (0.059)\tLoss 5.1558 (4.3628)\tPrec@1 80.000 (80.091)\tPrec@5 97.000 (97.818)\n",
            "Test: [20/261]\tTime 0.016 (0.042)\tLoss 5.5039 (4.3691)\tPrec@1 75.000 (80.667)\tPrec@5 96.000 (97.524)\n",
            "Test: [30/261]\tTime 0.022 (0.038)\tLoss 3.7465 (4.1829)\tPrec@1 82.000 (81.226)\tPrec@5 98.000 (97.839)\n",
            "Test: [40/261]\tTime 0.027 (0.035)\tLoss 3.2720 (4.1116)\tPrec@1 85.000 (81.780)\tPrec@5 99.000 (97.878)\n",
            "Test: [50/261]\tTime 0.034 (0.034)\tLoss 3.7399 (4.0689)\tPrec@1 84.000 (81.882)\tPrec@5 98.000 (97.863)\n",
            "Test: [60/261]\tTime 0.020 (0.032)\tLoss 4.1324 (4.0845)\tPrec@1 81.000 (81.754)\tPrec@5 98.000 (97.705)\n",
            "Test: [70/261]\tTime 0.024 (0.032)\tLoss 5.1863 (4.1065)\tPrec@1 76.000 (81.563)\tPrec@5 98.000 (97.676)\n",
            "Test: [80/261]\tTime 0.011 (0.031)\tLoss 3.9123 (4.1216)\tPrec@1 84.000 (81.506)\tPrec@5 98.000 (97.691)\n",
            "Test: [90/261]\tTime 0.030 (0.031)\tLoss 4.6683 (4.1717)\tPrec@1 79.000 (81.264)\tPrec@5 96.000 (97.659)\n",
            "Test: [100/261]\tTime 0.037 (0.030)\tLoss 3.7850 (4.1454)\tPrec@1 82.000 (81.317)\tPrec@5 97.000 (97.673)\n",
            "Test: [110/261]\tTime 0.037 (0.030)\tLoss 4.2387 (4.1197)\tPrec@1 80.000 (81.441)\tPrec@5 98.000 (97.730)\n",
            "Test: [120/261]\tTime 0.031 (0.030)\tLoss 3.6355 (4.1293)\tPrec@1 82.000 (81.364)\tPrec@5 97.000 (97.719)\n",
            "Test: [130/261]\tTime 0.020 (0.030)\tLoss 5.0081 (4.1309)\tPrec@1 74.000 (81.366)\tPrec@5 98.000 (97.679)\n",
            "Test: [140/261]\tTime 0.051 (0.030)\tLoss 4.3370 (4.1363)\tPrec@1 82.000 (81.319)\tPrec@5 95.000 (97.645)\n",
            "Test: [150/261]\tTime 0.039 (0.031)\tLoss 3.5095 (4.1342)\tPrec@1 87.000 (81.397)\tPrec@5 98.000 (97.629)\n",
            "Test: [160/261]\tTime 0.050 (0.032)\tLoss 3.5303 (4.1242)\tPrec@1 85.000 (81.447)\tPrec@5 99.000 (97.634)\n",
            "Test: [170/261]\tTime 0.050 (0.032)\tLoss 3.4450 (4.0902)\tPrec@1 84.000 (81.591)\tPrec@5 97.000 (97.643)\n",
            "Test: [180/261]\tTime 0.048 (0.033)\tLoss 3.7762 (4.0885)\tPrec@1 83.000 (81.619)\tPrec@5 96.000 (97.641)\n",
            "Test: [190/261]\tTime 0.021 (0.033)\tLoss 3.7641 (4.0779)\tPrec@1 83.000 (81.660)\tPrec@5 99.000 (97.681)\n",
            "Test: [200/261]\tTime 0.042 (0.033)\tLoss 3.5690 (4.0739)\tPrec@1 81.000 (81.637)\tPrec@5 97.000 (97.692)\n",
            "Test: [210/261]\tTime 0.041 (0.034)\tLoss 3.8582 (4.0638)\tPrec@1 81.000 (81.659)\tPrec@5 98.000 (97.697)\n",
            "Test: [220/261]\tTime 0.054 (0.034)\tLoss 4.8126 (4.0759)\tPrec@1 77.000 (81.602)\tPrec@5 98.000 (97.706)\n",
            "Test: [230/261]\tTime 0.032 (0.034)\tLoss 5.2540 (4.0816)\tPrec@1 77.000 (81.606)\tPrec@5 94.000 (97.662)\n",
            "Test: [240/261]\tTime 0.042 (0.034)\tLoss 3.1819 (4.0913)\tPrec@1 86.000 (81.556)\tPrec@5 98.000 (97.647)\n",
            "Test: [250/261]\tTime 0.033 (0.034)\tLoss 3.6689 (4.0741)\tPrec@1 80.000 (81.645)\tPrec@5 99.000 (97.629)\n",
            "Test: [260/261]\tTime 0.006 (0.033)\tLoss 4.6851 (4.0778)\tPrec@1 78.125 (81.623)\tPrec@5 100.000 (97.611)\n",
            "val Results: Prec@1 81.623 Prec@5 97.611 Loss 4.07785\n",
            "val Class Accuracy: [0.796,0.969,0.938,0.877,0.857,0.559,0.600,0.790,0.628,0.741]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [18][0/66], lr: 0.01000\tTime 0.627 (0.627)\tData 0.522 (0.522)\tLoss 0.9943 (0.9943)\tPrec@1 95.312 (95.312)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [18][10/66], lr: 0.01000\tTime 0.095 (0.150)\tData 0.005 (0.054)\tLoss 1.2257 (0.9243)\tPrec@1 93.750 (95.277)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [18][20/66], lr: 0.01000\tTime 0.076 (0.125)\tData 0.000 (0.031)\tLoss 0.4989 (0.9043)\tPrec@1 97.656 (95.201)\tPrec@5 100.000 (99.721)\n",
            "Epoch: [18][30/66], lr: 0.01000\tTime 0.091 (0.119)\tData 0.000 (0.023)\tLoss 0.6725 (0.9030)\tPrec@1 96.875 (95.275)\tPrec@5 100.000 (99.723)\n",
            "Epoch: [18][40/66], lr: 0.01000\tTime 0.089 (0.116)\tData 0.010 (0.019)\tLoss 0.6268 (0.9079)\tPrec@1 97.266 (95.303)\tPrec@5 99.609 (99.695)\n",
            "Epoch: [18][50/66], lr: 0.01000\tTime 0.092 (0.113)\tData 0.007 (0.016)\tLoss 0.9273 (0.9146)\tPrec@1 94.922 (95.274)\tPrec@5 100.000 (99.709)\n",
            "Epoch: [18][60/66], lr: 0.01000\tTime 0.059 (0.110)\tData 0.000 (0.014)\tLoss 0.8573 (0.9037)\tPrec@1 95.312 (95.351)\tPrec@5 99.609 (99.718)\n",
            "Test: [0/261]\tTime 0.305 (0.305)\tLoss 4.0757 (4.0757)\tPrec@1 81.000 (81.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/261]\tTime 0.018 (0.057)\tLoss 5.1315 (4.4184)\tPrec@1 78.000 (81.364)\tPrec@5 94.000 (95.727)\n",
            "Test: [20/261]\tTime 0.024 (0.042)\tLoss 5.4181 (4.5105)\tPrec@1 76.000 (81.000)\tPrec@5 93.000 (95.714)\n",
            "Test: [30/261]\tTime 0.031 (0.037)\tLoss 3.5039 (4.2988)\tPrec@1 83.000 (81.968)\tPrec@5 97.000 (96.097)\n",
            "Test: [40/261]\tTime 0.033 (0.035)\tLoss 3.2808 (4.1994)\tPrec@1 87.000 (82.293)\tPrec@5 97.000 (96.390)\n",
            "Test: [50/261]\tTime 0.022 (0.033)\tLoss 3.8141 (4.1365)\tPrec@1 88.000 (82.647)\tPrec@5 95.000 (96.392)\n",
            "Test: [60/261]\tTime 0.034 (0.032)\tLoss 3.8101 (4.1202)\tPrec@1 84.000 (82.705)\tPrec@5 98.000 (96.410)\n",
            "Test: [70/261]\tTime 0.032 (0.032)\tLoss 4.5238 (4.1119)\tPrec@1 82.000 (82.732)\tPrec@5 96.000 (96.338)\n",
            "Test: [80/261]\tTime 0.022 (0.031)\tLoss 3.8103 (4.1091)\tPrec@1 82.000 (82.679)\tPrec@5 96.000 (96.284)\n",
            "Test: [90/261]\tTime 0.035 (0.031)\tLoss 4.0381 (4.1630)\tPrec@1 84.000 (82.527)\tPrec@5 94.000 (96.165)\n",
            "Test: [100/261]\tTime 0.025 (0.030)\tLoss 4.5842 (4.1683)\tPrec@1 83.000 (82.495)\tPrec@5 95.000 (96.287)\n",
            "Test: [110/261]\tTime 0.024 (0.030)\tLoss 3.3486 (4.1263)\tPrec@1 85.000 (82.604)\tPrec@5 97.000 (96.342)\n",
            "Test: [120/261]\tTime 0.020 (0.030)\tLoss 3.5995 (4.1261)\tPrec@1 82.000 (82.537)\tPrec@5 97.000 (96.331)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 3.9428 (4.1233)\tPrec@1 83.000 (82.504)\tPrec@5 96.000 (96.351)\n",
            "Test: [140/261]\tTime 0.022 (0.029)\tLoss 5.3251 (4.1400)\tPrec@1 77.000 (82.447)\tPrec@5 94.000 (96.376)\n",
            "Test: [150/261]\tTime 0.020 (0.029)\tLoss 3.4937 (4.1523)\tPrec@1 85.000 (82.417)\tPrec@5 97.000 (96.358)\n",
            "Test: [160/261]\tTime 0.025 (0.029)\tLoss 4.0219 (4.1554)\tPrec@1 83.000 (82.416)\tPrec@5 95.000 (96.379)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 3.1668 (4.1471)\tPrec@1 87.000 (82.450)\tPrec@5 99.000 (96.409)\n",
            "Test: [180/261]\tTime 0.023 (0.029)\tLoss 3.5114 (4.1361)\tPrec@1 84.000 (82.497)\tPrec@5 95.000 (96.448)\n",
            "Test: [190/261]\tTime 0.020 (0.029)\tLoss 3.7129 (4.1286)\tPrec@1 85.000 (82.503)\tPrec@5 96.000 (96.503)\n",
            "Test: [200/261]\tTime 0.021 (0.029)\tLoss 2.8908 (4.1156)\tPrec@1 88.000 (82.567)\tPrec@5 98.000 (96.517)\n",
            "Test: [210/261]\tTime 0.028 (0.029)\tLoss 3.9861 (4.1071)\tPrec@1 81.000 (82.597)\tPrec@5 98.000 (96.502)\n",
            "Test: [220/261]\tTime 0.039 (0.029)\tLoss 4.4719 (4.1017)\tPrec@1 82.000 (82.643)\tPrec@5 95.000 (96.507)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 5.2425 (4.1070)\tPrec@1 78.000 (82.623)\tPrec@5 94.000 (96.455)\n",
            "Test: [240/261]\tTime 0.019 (0.028)\tLoss 4.4127 (4.1046)\tPrec@1 82.000 (82.643)\tPrec@5 98.000 (96.448)\n",
            "Test: [250/261]\tTime 0.041 (0.028)\tLoss 3.6980 (4.0939)\tPrec@1 81.000 (82.693)\tPrec@5 100.000 (96.466)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.9857 (4.1064)\tPrec@1 84.375 (82.637)\tPrec@5 100.000 (96.458)\n",
            "val Results: Prec@1 82.637 Prec@5 96.458 Loss 4.10642\n",
            "val Class Accuracy: [0.560,0.934,0.935,0.913,0.936,0.839,0.751,0.835,0.447,0.620]\n",
            "Best Prec@1: 83.251\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [19][0/66], lr: 0.01000\tTime 0.675 (0.675)\tData 0.569 (0.569)\tLoss 0.8248 (0.8248)\tPrec@1 95.703 (95.703)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [19][10/66], lr: 0.01000\tTime 0.113 (0.159)\tData 0.004 (0.058)\tLoss 1.2293 (0.9575)\tPrec@1 93.750 (94.851)\tPrec@5 99.609 (99.751)\n",
            "Epoch: [19][20/66], lr: 0.01000\tTime 0.101 (0.131)\tData 0.005 (0.033)\tLoss 0.8084 (0.9543)\tPrec@1 96.094 (94.922)\tPrec@5 100.000 (99.758)\n",
            "Epoch: [19][30/66], lr: 0.01000\tTime 0.092 (0.121)\tData 0.017 (0.025)\tLoss 0.5171 (0.8975)\tPrec@1 96.875 (95.212)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [19][40/66], lr: 0.01000\tTime 0.078 (0.116)\tData 0.000 (0.020)\tLoss 0.9711 (0.9103)\tPrec@1 95.312 (95.151)\tPrec@5 99.609 (99.781)\n",
            "Epoch: [19][50/66], lr: 0.01000\tTime 0.112 (0.114)\tData 0.000 (0.017)\tLoss 1.1961 (0.9022)\tPrec@1 94.531 (95.213)\tPrec@5 98.438 (99.732)\n",
            "Epoch: [19][60/66], lr: 0.01000\tTime 0.075 (0.110)\tData 0.000 (0.015)\tLoss 0.7881 (0.8848)\tPrec@1 95.312 (95.287)\tPrec@5 99.609 (99.744)\n",
            "Test: [0/261]\tTime 0.275 (0.275)\tLoss 3.9439 (3.9439)\tPrec@1 81.000 (81.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.056)\tLoss 4.3087 (3.8395)\tPrec@1 79.000 (81.818)\tPrec@5 97.000 (97.364)\n",
            "Test: [20/261]\tTime 0.022 (0.042)\tLoss 4.0888 (3.7776)\tPrec@1 81.000 (82.190)\tPrec@5 98.000 (97.238)\n",
            "Test: [30/261]\tTime 0.024 (0.037)\tLoss 2.4703 (3.5914)\tPrec@1 89.000 (83.065)\tPrec@5 98.000 (97.419)\n",
            "Test: [40/261]\tTime 0.013 (0.034)\tLoss 3.2393 (3.5403)\tPrec@1 85.000 (83.415)\tPrec@5 98.000 (97.488)\n",
            "Test: [50/261]\tTime 0.025 (0.033)\tLoss 3.8192 (3.4740)\tPrec@1 82.000 (83.863)\tPrec@5 96.000 (97.510)\n",
            "Test: [60/261]\tTime 0.030 (0.032)\tLoss 2.3643 (3.4455)\tPrec@1 90.000 (84.131)\tPrec@5 99.000 (97.459)\n",
            "Test: [70/261]\tTime 0.037 (0.032)\tLoss 3.6609 (3.4631)\tPrec@1 82.000 (83.915)\tPrec@5 98.000 (97.479)\n",
            "Test: [80/261]\tTime 0.026 (0.031)\tLoss 3.4214 (3.4708)\tPrec@1 84.000 (83.901)\tPrec@5 97.000 (97.469)\n",
            "Test: [90/261]\tTime 0.032 (0.030)\tLoss 3.0856 (3.5188)\tPrec@1 89.000 (83.736)\tPrec@5 95.000 (97.374)\n",
            "Test: [100/261]\tTime 0.011 (0.029)\tLoss 3.8563 (3.4924)\tPrec@1 84.000 (83.822)\tPrec@5 97.000 (97.475)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 3.8035 (3.4777)\tPrec@1 80.000 (83.757)\tPrec@5 96.000 (97.514)\n",
            "Test: [120/261]\tTime 0.025 (0.029)\tLoss 3.5083 (3.4694)\tPrec@1 85.000 (83.860)\tPrec@5 95.000 (97.446)\n",
            "Test: [130/261]\tTime 0.039 (0.029)\tLoss 2.9594 (3.4565)\tPrec@1 87.000 (83.947)\tPrec@5 99.000 (97.443)\n",
            "Test: [140/261]\tTime 0.030 (0.029)\tLoss 4.4559 (3.4440)\tPrec@1 77.000 (83.986)\tPrec@5 95.000 (97.411)\n",
            "Test: [150/261]\tTime 0.041 (0.029)\tLoss 3.3578 (3.4340)\tPrec@1 84.000 (84.086)\tPrec@5 98.000 (97.417)\n",
            "Test: [160/261]\tTime 0.011 (0.029)\tLoss 3.3865 (3.4320)\tPrec@1 87.000 (84.106)\tPrec@5 97.000 (97.447)\n",
            "Test: [170/261]\tTime 0.019 (0.028)\tLoss 3.2728 (3.4140)\tPrec@1 83.000 (84.228)\tPrec@5 95.000 (97.444)\n",
            "Test: [180/261]\tTime 0.047 (0.028)\tLoss 3.0107 (3.4183)\tPrec@1 85.000 (84.199)\tPrec@5 96.000 (97.431)\n",
            "Test: [190/261]\tTime 0.039 (0.028)\tLoss 2.9013 (3.4084)\tPrec@1 87.000 (84.257)\tPrec@5 98.000 (97.487)\n",
            "Test: [200/261]\tTime 0.036 (0.028)\tLoss 2.8373 (3.4046)\tPrec@1 86.000 (84.239)\tPrec@5 97.000 (97.448)\n",
            "Test: [210/261]\tTime 0.022 (0.028)\tLoss 3.6776 (3.4080)\tPrec@1 82.000 (84.175)\tPrec@5 97.000 (97.464)\n",
            "Test: [220/261]\tTime 0.030 (0.028)\tLoss 4.0524 (3.4178)\tPrec@1 80.000 (84.136)\tPrec@5 98.000 (97.457)\n",
            "Test: [230/261]\tTime 0.022 (0.028)\tLoss 4.1556 (3.4249)\tPrec@1 81.000 (84.048)\tPrec@5 95.000 (97.442)\n",
            "Test: [240/261]\tTime 0.012 (0.028)\tLoss 2.9257 (3.4310)\tPrec@1 84.000 (84.037)\tPrec@5 97.000 (97.390)\n",
            "Test: [250/261]\tTime 0.030 (0.028)\tLoss 3.5948 (3.4236)\tPrec@1 81.000 (84.032)\tPrec@5 98.000 (97.418)\n",
            "Test: [260/261]\tTime 0.008 (0.027)\tLoss 1.5650 (3.4290)\tPrec@1 96.875 (84.004)\tPrec@5 100.000 (97.407)\n",
            "val Results: Prec@1 84.004 Prec@5 97.407 Loss 3.42902\n",
            "val Class Accuracy: [0.924,0.965,0.863,0.818,0.852,0.790,0.776,0.764,0.677,0.730]\n",
            "Best Prec@1: 84.004\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [20][0/66], lr: 0.01000\tTime 0.650 (0.650)\tData 0.547 (0.547)\tLoss 0.9597 (0.9597)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [20][10/66], lr: 0.01000\tTime 0.113 (0.156)\tData 0.007 (0.055)\tLoss 0.5319 (0.7699)\tPrec@1 96.875 (95.916)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [20][20/66], lr: 0.01000\tTime 0.115 (0.132)\tData 0.000 (0.032)\tLoss 0.8988 (0.8135)\tPrec@1 96.094 (95.647)\tPrec@5 99.219 (99.758)\n",
            "Epoch: [20][30/66], lr: 0.01000\tTime 0.103 (0.122)\tData 0.005 (0.023)\tLoss 1.2036 (0.8793)\tPrec@1 94.141 (95.287)\tPrec@5 99.609 (99.685)\n",
            "Epoch: [20][40/66], lr: 0.01000\tTime 0.090 (0.117)\tData 0.000 (0.019)\tLoss 1.0707 (0.8538)\tPrec@1 95.312 (95.436)\tPrec@5 99.609 (99.695)\n",
            "Epoch: [20][50/66], lr: 0.01000\tTime 0.133 (0.115)\tData 0.008 (0.016)\tLoss 0.7095 (0.8603)\tPrec@1 96.094 (95.443)\tPrec@5 100.000 (99.732)\n",
            "Epoch: [20][60/66], lr: 0.01000\tTime 0.064 (0.112)\tData 0.000 (0.014)\tLoss 0.8812 (0.8728)\tPrec@1 95.312 (95.409)\tPrec@5 99.609 (99.744)\n",
            "Test: [0/261]\tTime 0.325 (0.325)\tLoss 4.1899 (4.1899)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.012 (0.057)\tLoss 5.5792 (4.6442)\tPrec@1 72.000 (78.545)\tPrec@5 97.000 (96.364)\n",
            "Test: [20/261]\tTime 0.045 (0.043)\tLoss 4.6015 (4.5179)\tPrec@1 79.000 (79.476)\tPrec@5 96.000 (96.000)\n",
            "Test: [30/261]\tTime 0.020 (0.037)\tLoss 3.4988 (4.2874)\tPrec@1 82.000 (80.774)\tPrec@5 98.000 (96.323)\n",
            "Test: [40/261]\tTime 0.025 (0.035)\tLoss 3.4951 (4.2456)\tPrec@1 87.000 (80.902)\tPrec@5 96.000 (96.610)\n",
            "Test: [50/261]\tTime 0.014 (0.032)\tLoss 4.4547 (4.1950)\tPrec@1 81.000 (81.235)\tPrec@5 95.000 (96.627)\n",
            "Test: [60/261]\tTime 0.034 (0.032)\tLoss 4.0792 (4.1619)\tPrec@1 83.000 (81.508)\tPrec@5 96.000 (96.623)\n",
            "Test: [70/261]\tTime 0.031 (0.032)\tLoss 4.7231 (4.1515)\tPrec@1 78.000 (81.606)\tPrec@5 97.000 (96.662)\n",
            "Test: [80/261]\tTime 0.052 (0.031)\tLoss 4.5254 (4.1548)\tPrec@1 80.000 (81.642)\tPrec@5 96.000 (96.691)\n",
            "Test: [90/261]\tTime 0.031 (0.030)\tLoss 4.6338 (4.1843)\tPrec@1 79.000 (81.473)\tPrec@5 95.000 (96.582)\n",
            "Test: [100/261]\tTime 0.011 (0.030)\tLoss 4.8571 (4.1628)\tPrec@1 83.000 (81.594)\tPrec@5 94.000 (96.604)\n",
            "Test: [110/261]\tTime 0.021 (0.030)\tLoss 3.9982 (4.1333)\tPrec@1 78.000 (81.577)\tPrec@5 97.000 (96.658)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 2.9594 (4.1325)\tPrec@1 90.000 (81.603)\tPrec@5 98.000 (96.620)\n",
            "Test: [130/261]\tTime 0.011 (0.029)\tLoss 4.2118 (4.1212)\tPrec@1 82.000 (81.626)\tPrec@5 97.000 (96.626)\n",
            "Test: [140/261]\tTime 0.033 (0.029)\tLoss 4.3861 (4.1080)\tPrec@1 81.000 (81.738)\tPrec@5 95.000 (96.638)\n",
            "Test: [150/261]\tTime 0.033 (0.029)\tLoss 2.8420 (4.1037)\tPrec@1 89.000 (81.828)\tPrec@5 98.000 (96.662)\n",
            "Test: [160/261]\tTime 0.010 (0.029)\tLoss 2.7413 (4.0982)\tPrec@1 88.000 (81.832)\tPrec@5 99.000 (96.708)\n",
            "Test: [170/261]\tTime 0.045 (0.029)\tLoss 3.3993 (4.0829)\tPrec@1 85.000 (81.924)\tPrec@5 96.000 (96.708)\n",
            "Test: [180/261]\tTime 0.044 (0.030)\tLoss 3.2612 (4.0883)\tPrec@1 88.000 (81.928)\tPrec@5 97.000 (96.735)\n",
            "Test: [190/261]\tTime 0.044 (0.030)\tLoss 3.5015 (4.0790)\tPrec@1 87.000 (81.969)\tPrec@5 95.000 (96.749)\n",
            "Test: [200/261]\tTime 0.041 (0.031)\tLoss 3.3593 (4.0671)\tPrec@1 83.000 (82.030)\tPrec@5 98.000 (96.746)\n",
            "Test: [210/261]\tTime 0.062 (0.032)\tLoss 2.7989 (4.0427)\tPrec@1 87.000 (82.123)\tPrec@5 99.000 (96.768)\n",
            "Test: [220/261]\tTime 0.018 (0.032)\tLoss 3.5248 (4.0284)\tPrec@1 83.000 (82.204)\tPrec@5 95.000 (96.760)\n",
            "Test: [230/261]\tTime 0.039 (0.032)\tLoss 5.0762 (4.0344)\tPrec@1 78.000 (82.169)\tPrec@5 94.000 (96.736)\n",
            "Test: [240/261]\tTime 0.041 (0.033)\tLoss 3.9670 (4.0437)\tPrec@1 83.000 (82.129)\tPrec@5 97.000 (96.726)\n",
            "Test: [250/261]\tTime 0.020 (0.033)\tLoss 3.5172 (4.0228)\tPrec@1 84.000 (82.191)\tPrec@5 99.000 (96.789)\n",
            "Test: [260/261]\tTime 0.007 (0.033)\tLoss 2.4275 (4.0291)\tPrec@1 93.750 (82.180)\tPrec@5 96.875 (96.781)\n",
            "val Results: Prec@1 82.180 Prec@5 96.781 Loss 4.02915\n",
            "val Class Accuracy: [0.720,0.940,0.953,0.849,0.870,0.784,0.650,0.733,0.789,0.507]\n",
            "Best Prec@1: 84.004\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [21][0/66], lr: 0.01000\tTime 0.680 (0.680)\tData 0.583 (0.583)\tLoss 0.9305 (0.9305)\tPrec@1 94.922 (94.922)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [21][10/66], lr: 0.01000\tTime 0.095 (0.155)\tData 0.005 (0.061)\tLoss 0.6924 (0.8278)\tPrec@1 96.484 (95.597)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [21][20/66], lr: 0.01000\tTime 0.128 (0.130)\tData 0.060 (0.041)\tLoss 0.9287 (0.8153)\tPrec@1 96.094 (95.685)\tPrec@5 99.609 (99.814)\n",
            "Epoch: [21][30/66], lr: 0.01000\tTime 0.106 (0.120)\tData 0.000 (0.029)\tLoss 0.5417 (0.8185)\tPrec@1 96.484 (95.766)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [21][40/66], lr: 0.01000\tTime 0.093 (0.115)\tData 0.007 (0.024)\tLoss 0.9185 (0.8077)\tPrec@1 96.875 (95.913)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [21][50/66], lr: 0.01000\tTime 0.097 (0.112)\tData 0.000 (0.020)\tLoss 0.9885 (0.8149)\tPrec@1 94.922 (95.841)\tPrec@5 100.000 (99.847)\n",
            "Epoch: [21][60/66], lr: 0.01000\tTime 0.073 (0.109)\tData 0.000 (0.018)\tLoss 0.9538 (0.8306)\tPrec@1 95.703 (95.799)\tPrec@5 99.609 (99.769)\n",
            "Test: [0/261]\tTime 0.334 (0.334)\tLoss 3.6055 (3.6055)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.021 (0.058)\tLoss 4.0513 (3.9331)\tPrec@1 83.000 (81.636)\tPrec@5 97.000 (97.000)\n",
            "Test: [20/261]\tTime 0.011 (0.044)\tLoss 5.1107 (3.9579)\tPrec@1 75.000 (81.524)\tPrec@5 95.000 (96.905)\n",
            "Test: [30/261]\tTime 0.042 (0.038)\tLoss 2.1728 (3.6669)\tPrec@1 91.000 (83.387)\tPrec@5 98.000 (97.355)\n",
            "Test: [40/261]\tTime 0.021 (0.035)\tLoss 2.8204 (3.5889)\tPrec@1 89.000 (83.805)\tPrec@5 99.000 (97.585)\n",
            "Test: [50/261]\tTime 0.036 (0.034)\tLoss 3.0764 (3.5133)\tPrec@1 85.000 (84.137)\tPrec@5 98.000 (97.765)\n",
            "Test: [60/261]\tTime 0.045 (0.032)\tLoss 3.3282 (3.4908)\tPrec@1 85.000 (84.213)\tPrec@5 100.000 (97.672)\n",
            "Test: [70/261]\tTime 0.040 (0.032)\tLoss 4.0192 (3.5312)\tPrec@1 82.000 (84.070)\tPrec@5 99.000 (97.690)\n",
            "Test: [80/261]\tTime 0.030 (0.031)\tLoss 3.6587 (3.5426)\tPrec@1 84.000 (84.136)\tPrec@5 98.000 (97.716)\n",
            "Test: [90/261]\tTime 0.021 (0.030)\tLoss 4.2888 (3.6022)\tPrec@1 84.000 (84.011)\tPrec@5 96.000 (97.593)\n",
            "Test: [100/261]\tTime 0.034 (0.030)\tLoss 3.5301 (3.5846)\tPrec@1 87.000 (84.050)\tPrec@5 94.000 (97.535)\n",
            "Test: [110/261]\tTime 0.011 (0.030)\tLoss 2.8140 (3.5502)\tPrec@1 87.000 (84.216)\tPrec@5 99.000 (97.541)\n",
            "Test: [120/261]\tTime 0.019 (0.029)\tLoss 2.9586 (3.5451)\tPrec@1 86.000 (84.140)\tPrec@5 97.000 (97.562)\n",
            "Test: [130/261]\tTime 0.044 (0.029)\tLoss 3.6342 (3.5429)\tPrec@1 84.000 (84.191)\tPrec@5 96.000 (97.580)\n",
            "Test: [140/261]\tTime 0.021 (0.029)\tLoss 4.5891 (3.5332)\tPrec@1 78.000 (84.270)\tPrec@5 98.000 (97.610)\n",
            "Test: [150/261]\tTime 0.021 (0.029)\tLoss 2.8151 (3.5345)\tPrec@1 86.000 (84.225)\tPrec@5 98.000 (97.616)\n",
            "Test: [160/261]\tTime 0.018 (0.029)\tLoss 2.9231 (3.5358)\tPrec@1 88.000 (84.193)\tPrec@5 98.000 (97.621)\n",
            "Test: [170/261]\tTime 0.017 (0.029)\tLoss 2.9627 (3.5176)\tPrec@1 88.000 (84.327)\tPrec@5 97.000 (97.637)\n",
            "Test: [180/261]\tTime 0.040 (0.029)\tLoss 3.1291 (3.5304)\tPrec@1 84.000 (84.227)\tPrec@5 94.000 (97.602)\n",
            "Test: [190/261]\tTime 0.026 (0.028)\tLoss 3.3549 (3.5186)\tPrec@1 82.000 (84.288)\tPrec@5 97.000 (97.634)\n",
            "Test: [200/261]\tTime 0.020 (0.028)\tLoss 3.2982 (3.5165)\tPrec@1 83.000 (84.269)\tPrec@5 98.000 (97.642)\n",
            "Test: [210/261]\tTime 0.022 (0.028)\tLoss 2.8122 (3.5051)\tPrec@1 86.000 (84.294)\tPrec@5 98.000 (97.654)\n",
            "Test: [220/261]\tTime 0.033 (0.028)\tLoss 3.9035 (3.5077)\tPrec@1 83.000 (84.267)\tPrec@5 98.000 (97.665)\n",
            "Test: [230/261]\tTime 0.019 (0.028)\tLoss 4.2369 (3.5165)\tPrec@1 80.000 (84.216)\tPrec@5 97.000 (97.641)\n",
            "Test: [240/261]\tTime 0.031 (0.028)\tLoss 2.9243 (3.5199)\tPrec@1 88.000 (84.224)\tPrec@5 97.000 (97.610)\n",
            "Test: [250/261]\tTime 0.017 (0.028)\tLoss 3.1152 (3.5042)\tPrec@1 85.000 (84.287)\tPrec@5 99.000 (97.629)\n",
            "Test: [260/261]\tTime 0.009 (0.027)\tLoss 2.7183 (3.5011)\tPrec@1 87.500 (84.277)\tPrec@5 96.875 (97.634)\n",
            "val Results: Prec@1 84.277 Prec@5 97.634 Loss 3.50112\n",
            "val Class Accuracy: [0.754,0.941,0.942,0.821,0.910,0.849,0.784,0.764,0.611,0.705]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [22][0/66], lr: 0.01000\tTime 0.565 (0.565)\tData 0.480 (0.480)\tLoss 0.9598 (0.9598)\tPrec@1 94.922 (94.922)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [22][10/66], lr: 0.01000\tTime 0.092 (0.142)\tData 0.004 (0.050)\tLoss 1.0582 (0.9218)\tPrec@1 93.750 (94.780)\tPrec@5 98.828 (99.680)\n",
            "Epoch: [22][20/66], lr: 0.01000\tTime 0.101 (0.123)\tData 0.005 (0.029)\tLoss 1.0743 (0.9311)\tPrec@1 94.531 (94.996)\tPrec@5 99.219 (99.665)\n",
            "Epoch: [22][30/66], lr: 0.01000\tTime 0.102 (0.117)\tData 0.000 (0.021)\tLoss 0.7722 (0.9174)\tPrec@1 95.703 (95.149)\tPrec@5 99.609 (99.635)\n",
            "Epoch: [22][40/66], lr: 0.01000\tTime 0.091 (0.113)\tData 0.000 (0.017)\tLoss 1.0566 (0.9082)\tPrec@1 94.531 (95.198)\tPrec@5 100.000 (99.657)\n",
            "Epoch: [22][50/66], lr: 0.01000\tTime 0.068 (0.111)\tData 0.000 (0.015)\tLoss 1.0893 (0.8975)\tPrec@1 94.922 (95.351)\tPrec@5 100.000 (99.686)\n",
            "Epoch: [22][60/66], lr: 0.01000\tTime 0.055 (0.108)\tData 0.000 (0.013)\tLoss 1.3584 (0.8905)\tPrec@1 93.750 (95.428)\tPrec@5 100.000 (99.693)\n",
            "Test: [0/261]\tTime 0.285 (0.285)\tLoss 4.0599 (4.0599)\tPrec@1 81.000 (81.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.034 (0.055)\tLoss 4.3489 (4.3737)\tPrec@1 81.000 (80.091)\tPrec@5 97.000 (97.000)\n",
            "Test: [20/261]\tTime 0.036 (0.043)\tLoss 3.9192 (4.4042)\tPrec@1 82.000 (80.000)\tPrec@5 92.000 (96.952)\n",
            "Test: [30/261]\tTime 0.011 (0.038)\tLoss 2.4764 (4.1618)\tPrec@1 89.000 (81.516)\tPrec@5 96.000 (97.065)\n",
            "Test: [40/261]\tTime 0.035 (0.036)\tLoss 3.4641 (4.0351)\tPrec@1 84.000 (82.341)\tPrec@5 99.000 (97.244)\n",
            "Test: [50/261]\tTime 0.022 (0.034)\tLoss 3.4414 (3.9405)\tPrec@1 84.000 (82.804)\tPrec@5 98.000 (97.235)\n",
            "Test: [60/261]\tTime 0.036 (0.033)\tLoss 4.6986 (3.9221)\tPrec@1 82.000 (82.967)\tPrec@5 98.000 (97.180)\n",
            "Test: [70/261]\tTime 0.032 (0.032)\tLoss 4.3261 (3.9356)\tPrec@1 80.000 (82.831)\tPrec@5 98.000 (97.183)\n",
            "Test: [80/261]\tTime 0.030 (0.032)\tLoss 3.7164 (3.9382)\tPrec@1 85.000 (82.901)\tPrec@5 97.000 (97.185)\n",
            "Test: [90/261]\tTime 0.025 (0.031)\tLoss 4.1383 (3.9835)\tPrec@1 82.000 (82.769)\tPrec@5 95.000 (97.044)\n",
            "Test: [100/261]\tTime 0.034 (0.031)\tLoss 5.1475 (3.9990)\tPrec@1 77.000 (82.733)\tPrec@5 95.000 (97.030)\n",
            "Test: [110/261]\tTime 0.023 (0.030)\tLoss 2.3847 (3.9696)\tPrec@1 88.000 (82.802)\tPrec@5 98.000 (97.072)\n",
            "Test: [120/261]\tTime 0.030 (0.030)\tLoss 2.4625 (3.9598)\tPrec@1 91.000 (82.810)\tPrec@5 98.000 (97.041)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 4.1073 (3.9431)\tPrec@1 80.000 (82.855)\tPrec@5 96.000 (97.015)\n",
            "Test: [140/261]\tTime 0.041 (0.030)\tLoss 5.9159 (3.9517)\tPrec@1 74.000 (82.752)\tPrec@5 96.000 (97.021)\n",
            "Test: [150/261]\tTime 0.039 (0.030)\tLoss 3.8720 (3.9566)\tPrec@1 85.000 (82.808)\tPrec@5 96.000 (97.026)\n",
            "Test: [160/261]\tTime 0.011 (0.029)\tLoss 3.0441 (3.9601)\tPrec@1 88.000 (82.801)\tPrec@5 99.000 (97.068)\n",
            "Test: [170/261]\tTime 0.023 (0.029)\tLoss 3.1766 (3.9340)\tPrec@1 84.000 (82.889)\tPrec@5 97.000 (97.099)\n",
            "Test: [180/261]\tTime 0.022 (0.029)\tLoss 3.6149 (3.9458)\tPrec@1 82.000 (82.801)\tPrec@5 95.000 (97.066)\n",
            "Test: [190/261]\tTime 0.026 (0.029)\tLoss 3.6792 (3.9458)\tPrec@1 85.000 (82.801)\tPrec@5 98.000 (97.094)\n",
            "Test: [200/261]\tTime 0.026 (0.029)\tLoss 4.1610 (3.9602)\tPrec@1 79.000 (82.716)\tPrec@5 99.000 (97.085)\n",
            "Test: [210/261]\tTime 0.028 (0.029)\tLoss 4.0291 (3.9537)\tPrec@1 82.000 (82.796)\tPrec@5 97.000 (97.076)\n",
            "Test: [220/261]\tTime 0.051 (0.029)\tLoss 4.4664 (3.9472)\tPrec@1 81.000 (82.842)\tPrec@5 95.000 (97.072)\n",
            "Test: [230/261]\tTime 0.018 (0.029)\tLoss 5.0592 (3.9573)\tPrec@1 77.000 (82.775)\tPrec@5 92.000 (97.039)\n",
            "Test: [240/261]\tTime 0.025 (0.029)\tLoss 3.7918 (3.9661)\tPrec@1 84.000 (82.689)\tPrec@5 98.000 (97.008)\n",
            "Test: [250/261]\tTime 0.040 (0.029)\tLoss 3.2614 (3.9447)\tPrec@1 86.000 (82.785)\tPrec@5 100.000 (97.044)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.4299 (3.9436)\tPrec@1 90.625 (82.798)\tPrec@5 96.875 (97.031)\n",
            "val Results: Prec@1 82.798 Prec@5 97.031 Loss 3.94360\n",
            "val Class Accuracy: [0.565,0.914,0.945,0.774,0.945,0.910,0.809,0.765,0.555,0.712]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [23][0/66], lr: 0.01000\tTime 0.700 (0.700)\tData 0.627 (0.627)\tLoss 1.1178 (1.1178)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [23][10/66], lr: 0.01000\tTime 0.117 (0.158)\tData 0.002 (0.066)\tLoss 0.9445 (0.7987)\tPrec@1 94.922 (95.987)\tPrec@5 99.219 (99.822)\n",
            "Epoch: [23][20/66], lr: 0.01000\tTime 0.107 (0.135)\tData 0.000 (0.041)\tLoss 0.6972 (0.7447)\tPrec@1 95.703 (96.112)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [23][30/66], lr: 0.01000\tTime 0.122 (0.126)\tData 0.004 (0.029)\tLoss 0.8793 (0.7845)\tPrec@1 94.922 (95.930)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [23][40/66], lr: 0.01000\tTime 0.111 (0.120)\tData 0.003 (0.023)\tLoss 1.0548 (0.7956)\tPrec@1 94.141 (95.808)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [23][50/66], lr: 0.01000\tTime 0.067 (0.116)\tData 0.007 (0.020)\tLoss 0.7700 (0.8135)\tPrec@1 95.703 (95.642)\tPrec@5 99.609 (99.809)\n",
            "Epoch: [23][60/66], lr: 0.01000\tTime 0.078 (0.112)\tData 0.000 (0.018)\tLoss 0.7517 (0.8268)\tPrec@1 96.484 (95.645)\tPrec@5 99.219 (99.801)\n",
            "Test: [0/261]\tTime 0.343 (0.343)\tLoss 5.2910 (5.2910)\tPrec@1 79.000 (79.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.032 (0.059)\tLoss 5.7955 (5.1756)\tPrec@1 76.000 (77.091)\tPrec@5 95.000 (94.000)\n",
            "Test: [20/261]\tTime 0.032 (0.044)\tLoss 5.0564 (5.1426)\tPrec@1 75.000 (77.286)\tPrec@5 93.000 (94.476)\n",
            "Test: [30/261]\tTime 0.031 (0.035)\tLoss 3.3585 (4.8829)\tPrec@1 85.000 (78.742)\tPrec@5 97.000 (94.968)\n",
            "Test: [40/261]\tTime 0.033 (0.035)\tLoss 4.3858 (4.7432)\tPrec@1 84.000 (79.488)\tPrec@5 97.000 (95.366)\n",
            "Test: [50/261]\tTime 0.029 (0.033)\tLoss 5.0318 (4.6926)\tPrec@1 80.000 (79.667)\tPrec@5 97.000 (95.353)\n",
            "Test: [60/261]\tTime 0.026 (0.032)\tLoss 4.0524 (4.6627)\tPrec@1 83.000 (79.820)\tPrec@5 96.000 (95.344)\n",
            "Test: [70/261]\tTime 0.023 (0.031)\tLoss 4.5873 (4.6605)\tPrec@1 81.000 (79.704)\tPrec@5 96.000 (95.366)\n",
            "Test: [80/261]\tTime 0.028 (0.030)\tLoss 4.7548 (4.6899)\tPrec@1 78.000 (79.593)\tPrec@5 94.000 (95.309)\n",
            "Test: [90/261]\tTime 0.028 (0.030)\tLoss 4.4486 (4.7312)\tPrec@1 80.000 (79.484)\tPrec@5 94.000 (95.231)\n",
            "Test: [100/261]\tTime 0.019 (0.030)\tLoss 4.7115 (4.7259)\tPrec@1 82.000 (79.554)\tPrec@5 93.000 (95.238)\n",
            "Test: [110/261]\tTime 0.040 (0.029)\tLoss 3.9368 (4.6992)\tPrec@1 85.000 (79.712)\tPrec@5 94.000 (95.243)\n",
            "Test: [120/261]\tTime 0.047 (0.030)\tLoss 3.6169 (4.6981)\tPrec@1 85.000 (79.669)\tPrec@5 95.000 (95.198)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 4.7811 (4.7089)\tPrec@1 82.000 (79.626)\tPrec@5 94.000 (95.176)\n",
            "Test: [140/261]\tTime 0.020 (0.029)\tLoss 5.9495 (4.7202)\tPrec@1 71.000 (79.589)\tPrec@5 93.000 (95.220)\n",
            "Test: [150/261]\tTime 0.040 (0.029)\tLoss 4.7221 (4.7282)\tPrec@1 79.000 (79.570)\tPrec@5 94.000 (95.212)\n",
            "Test: [160/261]\tTime 0.029 (0.030)\tLoss 4.4521 (4.7335)\tPrec@1 81.000 (79.590)\tPrec@5 95.000 (95.211)\n",
            "Test: [170/261]\tTime 0.036 (0.031)\tLoss 4.5304 (4.7237)\tPrec@1 78.000 (79.591)\tPrec@5 93.000 (95.193)\n",
            "Test: [180/261]\tTime 0.047 (0.032)\tLoss 5.2416 (4.7271)\tPrec@1 79.000 (79.569)\tPrec@5 93.000 (95.204)\n",
            "Test: [190/261]\tTime 0.047 (0.032)\tLoss 4.9062 (4.7126)\tPrec@1 78.000 (79.607)\tPrec@5 94.000 (95.251)\n",
            "Test: [200/261]\tTime 0.025 (0.033)\tLoss 3.1049 (4.7057)\tPrec@1 85.000 (79.652)\tPrec@5 99.000 (95.289)\n",
            "Test: [210/261]\tTime 0.043 (0.033)\tLoss 3.9055 (4.6957)\tPrec@1 82.000 (79.692)\tPrec@5 98.000 (95.280)\n",
            "Test: [220/261]\tTime 0.019 (0.033)\tLoss 5.5805 (4.6894)\tPrec@1 73.000 (79.652)\tPrec@5 91.000 (95.285)\n",
            "Test: [230/261]\tTime 0.058 (0.034)\tLoss 6.6553 (4.7032)\tPrec@1 72.000 (79.584)\tPrec@5 91.000 (95.234)\n",
            "Test: [240/261]\tTime 0.037 (0.034)\tLoss 4.8935 (4.7218)\tPrec@1 76.000 (79.515)\tPrec@5 94.000 (95.212)\n",
            "Test: [250/261]\tTime 0.030 (0.034)\tLoss 4.0032 (4.6992)\tPrec@1 83.000 (79.598)\tPrec@5 98.000 (95.243)\n",
            "Test: [260/261]\tTime 0.007 (0.034)\tLoss 4.2843 (4.7033)\tPrec@1 81.250 (79.587)\tPrec@5 96.875 (95.233)\n",
            "val Results: Prec@1 79.587 Prec@5 95.233 Loss 4.70331\n",
            "val Class Accuracy: [0.629,0.981,0.919,0.775,0.777,0.924,0.463,0.877,0.401,0.664]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [24][0/66], lr: 0.01000\tTime 0.645 (0.645)\tData 0.560 (0.560)\tLoss 0.6809 (0.6809)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [24][10/66], lr: 0.01000\tTime 0.107 (0.154)\tData 0.006 (0.061)\tLoss 0.6120 (0.8386)\tPrec@1 97.266 (95.952)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [24][20/66], lr: 0.01000\tTime 0.087 (0.131)\tData 0.001 (0.039)\tLoss 0.5193 (0.7909)\tPrec@1 96.484 (96.131)\tPrec@5 99.609 (99.740)\n",
            "Epoch: [24][30/66], lr: 0.01000\tTime 0.085 (0.121)\tData 0.005 (0.030)\tLoss 0.7462 (0.7584)\tPrec@1 95.703 (96.132)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [24][40/66], lr: 0.01000\tTime 0.089 (0.118)\tData 0.007 (0.028)\tLoss 0.6652 (0.7499)\tPrec@1 95.703 (96.160)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [24][50/66], lr: 0.01000\tTime 0.131 (0.116)\tData 0.002 (0.023)\tLoss 0.9423 (0.7599)\tPrec@1 95.312 (96.117)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [24][60/66], lr: 0.01000\tTime 0.066 (0.113)\tData 0.000 (0.020)\tLoss 0.7986 (0.7614)\tPrec@1 96.094 (96.094)\tPrec@5 99.609 (99.827)\n",
            "Test: [0/261]\tTime 0.284 (0.284)\tLoss 4.3933 (4.3933)\tPrec@1 84.000 (84.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.028 (0.058)\tLoss 4.5780 (5.0265)\tPrec@1 80.000 (79.364)\tPrec@5 96.000 (95.636)\n",
            "Test: [20/261]\tTime 0.036 (0.044)\tLoss 5.4382 (4.9348)\tPrec@1 76.000 (79.143)\tPrec@5 96.000 (95.381)\n",
            "Test: [30/261]\tTime 0.021 (0.038)\tLoss 3.2817 (4.7159)\tPrec@1 82.000 (79.839)\tPrec@5 97.000 (95.839)\n",
            "Test: [40/261]\tTime 0.039 (0.035)\tLoss 4.3160 (4.6178)\tPrec@1 82.000 (80.512)\tPrec@5 96.000 (96.171)\n",
            "Test: [50/261]\tTime 0.034 (0.033)\tLoss 4.6582 (4.5187)\tPrec@1 81.000 (80.941)\tPrec@5 95.000 (96.157)\n",
            "Test: [60/261]\tTime 0.021 (0.032)\tLoss 5.2770 (4.4688)\tPrec@1 77.000 (81.115)\tPrec@5 97.000 (96.115)\n",
            "Test: [70/261]\tTime 0.018 (0.031)\tLoss 5.8915 (4.4859)\tPrec@1 73.000 (81.014)\tPrec@5 96.000 (96.155)\n",
            "Test: [80/261]\tTime 0.036 (0.030)\tLoss 4.3313 (4.4756)\tPrec@1 83.000 (81.086)\tPrec@5 97.000 (96.198)\n",
            "Test: [90/261]\tTime 0.011 (0.030)\tLoss 4.1707 (4.5282)\tPrec@1 84.000 (80.813)\tPrec@5 95.000 (96.088)\n",
            "Test: [100/261]\tTime 0.023 (0.030)\tLoss 6.1772 (4.5459)\tPrec@1 74.000 (80.752)\tPrec@5 94.000 (96.129)\n",
            "Test: [110/261]\tTime 0.017 (0.030)\tLoss 3.9761 (4.5076)\tPrec@1 82.000 (80.919)\tPrec@5 96.000 (96.189)\n",
            "Test: [120/261]\tTime 0.017 (0.029)\tLoss 3.2998 (4.5047)\tPrec@1 84.000 (80.942)\tPrec@5 97.000 (96.174)\n",
            "Test: [130/261]\tTime 0.044 (0.029)\tLoss 3.9504 (4.4681)\tPrec@1 81.000 (81.061)\tPrec@5 96.000 (96.260)\n",
            "Test: [140/261]\tTime 0.047 (0.029)\tLoss 5.7204 (4.4686)\tPrec@1 78.000 (81.035)\tPrec@5 94.000 (96.284)\n",
            "Test: [150/261]\tTime 0.030 (0.029)\tLoss 3.6757 (4.4729)\tPrec@1 81.000 (80.993)\tPrec@5 96.000 (96.278)\n",
            "Test: [160/261]\tTime 0.029 (0.029)\tLoss 3.4604 (4.4535)\tPrec@1 87.000 (81.087)\tPrec@5 98.000 (96.335)\n",
            "Test: [170/261]\tTime 0.014 (0.029)\tLoss 3.4630 (4.4450)\tPrec@1 83.000 (81.164)\tPrec@5 98.000 (96.345)\n",
            "Test: [180/261]\tTime 0.017 (0.029)\tLoss 3.7689 (4.4468)\tPrec@1 86.000 (81.188)\tPrec@5 95.000 (96.304)\n",
            "Test: [190/261]\tTime 0.037 (0.029)\tLoss 3.7229 (4.4376)\tPrec@1 84.000 (81.199)\tPrec@5 96.000 (96.314)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 4.5654 (4.4366)\tPrec@1 80.000 (81.159)\tPrec@5 97.000 (96.318)\n",
            "Test: [210/261]\tTime 0.025 (0.028)\tLoss 4.3875 (4.4262)\tPrec@1 80.000 (81.185)\tPrec@5 97.000 (96.318)\n",
            "Test: [220/261]\tTime 0.030 (0.028)\tLoss 4.2814 (4.4170)\tPrec@1 83.000 (81.213)\tPrec@5 96.000 (96.290)\n",
            "Test: [230/261]\tTime 0.038 (0.028)\tLoss 5.4807 (4.4310)\tPrec@1 77.000 (81.164)\tPrec@5 92.000 (96.251)\n",
            "Test: [240/261]\tTime 0.032 (0.028)\tLoss 4.4536 (4.4322)\tPrec@1 83.000 (81.162)\tPrec@5 98.000 (96.290)\n",
            "Test: [250/261]\tTime 0.033 (0.028)\tLoss 4.1214 (4.4086)\tPrec@1 84.000 (81.263)\tPrec@5 97.000 (96.347)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 1.6407 (4.4252)\tPrec@1 93.750 (81.212)\tPrec@5 96.875 (96.328)\n",
            "val Results: Prec@1 81.212 Prec@5 96.328 Loss 4.42517\n",
            "val Class Accuracy: [0.562,0.932,0.976,0.696,0.927,0.844,0.765,0.784,0.697,0.471]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [25][0/66], lr: 0.01000\tTime 0.669 (0.669)\tData 0.586 (0.586)\tLoss 0.6689 (0.6689)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [25][10/66], lr: 0.01000\tTime 0.103 (0.159)\tData 0.005 (0.060)\tLoss 1.4393 (0.9042)\tPrec@1 92.188 (95.241)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [25][20/66], lr: 0.01000\tTime 0.108 (0.132)\tData 0.001 (0.035)\tLoss 0.6368 (0.8152)\tPrec@1 96.875 (95.852)\tPrec@5 98.828 (99.721)\n",
            "Epoch: [25][30/66], lr: 0.01000\tTime 0.114 (0.120)\tData 0.005 (0.026)\tLoss 0.6508 (0.8187)\tPrec@1 96.875 (95.892)\tPrec@5 100.000 (99.811)\n",
            "Epoch: [25][40/66], lr: 0.01000\tTime 0.134 (0.117)\tData 0.007 (0.021)\tLoss 0.7156 (0.7897)\tPrec@1 96.484 (96.008)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [25][50/66], lr: 0.01000\tTime 0.100 (0.113)\tData 0.000 (0.018)\tLoss 1.1805 (0.8056)\tPrec@1 93.750 (95.910)\tPrec@5 99.609 (99.831)\n",
            "Epoch: [25][60/66], lr: 0.01000\tTime 0.071 (0.110)\tData 0.000 (0.015)\tLoss 0.9182 (0.8137)\tPrec@1 95.703 (95.914)\tPrec@5 99.219 (99.808)\n",
            "Test: [0/261]\tTime 0.359 (0.359)\tLoss 3.4946 (3.4946)\tPrec@1 85.000 (85.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.036 (0.058)\tLoss 4.2694 (4.0713)\tPrec@1 80.000 (81.091)\tPrec@5 97.000 (97.455)\n",
            "Test: [20/261]\tTime 0.011 (0.041)\tLoss 5.0639 (4.1646)\tPrec@1 76.000 (81.048)\tPrec@5 97.000 (97.143)\n",
            "Test: [30/261]\tTime 0.020 (0.038)\tLoss 3.3258 (3.9844)\tPrec@1 85.000 (82.000)\tPrec@5 97.000 (97.548)\n",
            "Test: [40/261]\tTime 0.020 (0.036)\tLoss 3.0476 (3.8292)\tPrec@1 85.000 (82.951)\tPrec@5 99.000 (97.780)\n",
            "Test: [50/261]\tTime 0.021 (0.034)\tLoss 3.4759 (3.7729)\tPrec@1 85.000 (83.196)\tPrec@5 97.000 (97.608)\n",
            "Test: [60/261]\tTime 0.026 (0.033)\tLoss 3.1544 (3.7661)\tPrec@1 88.000 (83.344)\tPrec@5 96.000 (97.393)\n",
            "Test: [70/261]\tTime 0.024 (0.032)\tLoss 3.9318 (3.7511)\tPrec@1 83.000 (83.479)\tPrec@5 98.000 (97.465)\n",
            "Test: [80/261]\tTime 0.035 (0.031)\tLoss 3.7289 (3.7523)\tPrec@1 84.000 (83.407)\tPrec@5 99.000 (97.531)\n",
            "Test: [90/261]\tTime 0.021 (0.031)\tLoss 4.4191 (3.8050)\tPrec@1 83.000 (83.231)\tPrec@5 97.000 (97.440)\n",
            "Test: [100/261]\tTime 0.028 (0.031)\tLoss 4.3327 (3.8124)\tPrec@1 81.000 (83.149)\tPrec@5 96.000 (97.485)\n",
            "Test: [110/261]\tTime 0.017 (0.030)\tLoss 2.7025 (3.7778)\tPrec@1 89.000 (83.270)\tPrec@5 98.000 (97.541)\n",
            "Test: [120/261]\tTime 0.021 (0.030)\tLoss 2.8742 (3.7730)\tPrec@1 86.000 (83.256)\tPrec@5 98.000 (97.562)\n",
            "Test: [130/261]\tTime 0.034 (0.029)\tLoss 3.7021 (3.7707)\tPrec@1 84.000 (83.282)\tPrec@5 97.000 (97.611)\n",
            "Test: [140/261]\tTime 0.028 (0.029)\tLoss 4.7525 (3.7911)\tPrec@1 80.000 (83.170)\tPrec@5 96.000 (97.589)\n",
            "Test: [150/261]\tTime 0.018 (0.029)\tLoss 3.1318 (3.7785)\tPrec@1 88.000 (83.278)\tPrec@5 98.000 (97.583)\n",
            "Test: [160/261]\tTime 0.038 (0.029)\tLoss 3.0766 (3.7774)\tPrec@1 87.000 (83.236)\tPrec@5 97.000 (97.602)\n",
            "Test: [170/261]\tTime 0.027 (0.029)\tLoss 3.3667 (3.7597)\tPrec@1 87.000 (83.351)\tPrec@5 96.000 (97.626)\n",
            "Test: [180/261]\tTime 0.015 (0.029)\tLoss 3.0455 (3.7696)\tPrec@1 87.000 (83.271)\tPrec@5 96.000 (97.613)\n",
            "Test: [190/261]\tTime 0.031 (0.029)\tLoss 3.7589 (3.7629)\tPrec@1 81.000 (83.241)\tPrec@5 96.000 (97.613)\n",
            "Test: [200/261]\tTime 0.037 (0.029)\tLoss 3.8439 (3.7612)\tPrec@1 79.000 (83.254)\tPrec@5 99.000 (97.617)\n",
            "Test: [210/261]\tTime 0.024 (0.029)\tLoss 3.8371 (3.7662)\tPrec@1 82.000 (83.227)\tPrec@5 97.000 (97.635)\n",
            "Test: [220/261]\tTime 0.024 (0.029)\tLoss 4.7323 (3.7677)\tPrec@1 79.000 (83.195)\tPrec@5 97.000 (97.620)\n",
            "Test: [230/261]\tTime 0.029 (0.028)\tLoss 4.9255 (3.7805)\tPrec@1 79.000 (83.143)\tPrec@5 95.000 (97.597)\n",
            "Test: [240/261]\tTime 0.010 (0.028)\tLoss 3.1228 (3.7757)\tPrec@1 85.000 (83.145)\tPrec@5 99.000 (97.560)\n",
            "Test: [250/261]\tTime 0.032 (0.028)\tLoss 3.1423 (3.7665)\tPrec@1 85.000 (83.187)\tPrec@5 98.000 (97.574)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.7189 (3.7664)\tPrec@1 90.625 (83.217)\tPrec@5 96.875 (97.545)\n",
            "val Results: Prec@1 83.217 Prec@5 97.545 Loss 3.76641\n",
            "val Class Accuracy: [0.696,0.964,0.918,0.713,0.866,0.898,0.770,0.666,0.653,0.871]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [26][0/66], lr: 0.01000\tTime 0.638 (0.638)\tData 0.527 (0.527)\tLoss 0.5905 (0.5905)\tPrec@1 97.266 (97.266)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [26][10/66], lr: 0.01000\tTime 0.095 (0.153)\tData 0.000 (0.052)\tLoss 1.2059 (0.8585)\tPrec@1 94.141 (95.774)\tPrec@5 99.219 (99.574)\n",
            "Epoch: [26][20/66], lr: 0.01000\tTime 0.099 (0.131)\tData 0.005 (0.030)\tLoss 0.8972 (0.8301)\tPrec@1 94.141 (95.833)\tPrec@5 100.000 (99.665)\n",
            "Epoch: [26][30/66], lr: 0.01000\tTime 0.101 (0.121)\tData 0.000 (0.023)\tLoss 0.9007 (0.8300)\tPrec@1 94.141 (95.703)\tPrec@5 100.000 (99.710)\n",
            "Epoch: [26][40/66], lr: 0.01000\tTime 0.120 (0.116)\tData 0.003 (0.018)\tLoss 1.0543 (0.7982)\tPrec@1 94.531 (95.846)\tPrec@5 100.000 (99.762)\n",
            "Epoch: [26][50/66], lr: 0.01000\tTime 0.074 (0.113)\tData 0.000 (0.016)\tLoss 0.7065 (0.8058)\tPrec@1 96.875 (95.864)\tPrec@5 99.609 (99.732)\n",
            "Epoch: [26][60/66], lr: 0.01000\tTime 0.062 (0.110)\tData 0.000 (0.014)\tLoss 0.8244 (0.8086)\tPrec@1 95.703 (95.812)\tPrec@5 99.609 (99.731)\n",
            "Test: [0/261]\tTime 0.299 (0.299)\tLoss 5.0626 (5.0626)\tPrec@1 76.000 (76.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/261]\tTime 0.029 (0.058)\tLoss 6.1361 (5.4761)\tPrec@1 75.000 (75.909)\tPrec@5 93.000 (95.455)\n",
            "Test: [20/261]\tTime 0.019 (0.045)\tLoss 5.4843 (5.3842)\tPrec@1 74.000 (76.810)\tPrec@5 95.000 (95.667)\n",
            "Test: [30/261]\tTime 0.024 (0.038)\tLoss 3.5266 (5.0990)\tPrec@1 86.000 (78.097)\tPrec@5 96.000 (95.968)\n",
            "Test: [40/261]\tTime 0.047 (0.036)\tLoss 4.9708 (5.0992)\tPrec@1 81.000 (78.098)\tPrec@5 95.000 (96.000)\n",
            "Test: [50/261]\tTime 0.012 (0.034)\tLoss 4.7224 (5.0654)\tPrec@1 81.000 (78.275)\tPrec@5 95.000 (96.000)\n",
            "Test: [60/261]\tTime 0.042 (0.033)\tLoss 5.1070 (5.0380)\tPrec@1 80.000 (78.426)\tPrec@5 94.000 (95.902)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 6.2516 (5.0504)\tPrec@1 73.000 (78.239)\tPrec@5 97.000 (95.944)\n",
            "Test: [80/261]\tTime 0.029 (0.031)\tLoss 5.4076 (5.0332)\tPrec@1 77.000 (78.284)\tPrec@5 94.000 (96.025)\n",
            "Test: [90/261]\tTime 0.035 (0.031)\tLoss 5.4558 (5.0566)\tPrec@1 76.000 (78.253)\tPrec@5 94.000 (95.923)\n",
            "Test: [100/261]\tTime 0.025 (0.030)\tLoss 6.3211 (5.0551)\tPrec@1 72.000 (78.248)\tPrec@5 92.000 (95.901)\n",
            "Test: [110/261]\tTime 0.034 (0.030)\tLoss 5.0220 (5.0291)\tPrec@1 80.000 (78.396)\tPrec@5 95.000 (95.937)\n",
            "Test: [120/261]\tTime 0.011 (0.029)\tLoss 4.6002 (5.0404)\tPrec@1 79.000 (78.289)\tPrec@5 97.000 (95.917)\n",
            "Test: [130/261]\tTime 0.025 (0.030)\tLoss 5.2090 (5.0369)\tPrec@1 75.000 (78.298)\tPrec@5 95.000 (95.863)\n",
            "Test: [140/261]\tTime 0.030 (0.030)\tLoss 6.6063 (5.0198)\tPrec@1 71.000 (78.355)\tPrec@5 95.000 (95.901)\n",
            "Test: [150/261]\tTime 0.020 (0.030)\tLoss 4.2657 (5.0307)\tPrec@1 82.000 (78.325)\tPrec@5 96.000 (95.907)\n",
            "Test: [160/261]\tTime 0.055 (0.031)\tLoss 3.9063 (5.0249)\tPrec@1 85.000 (78.354)\tPrec@5 99.000 (95.957)\n",
            "Test: [170/261]\tTime 0.029 (0.032)\tLoss 4.2479 (5.0097)\tPrec@1 82.000 (78.439)\tPrec@5 97.000 (95.942)\n",
            "Test: [180/261]\tTime 0.041 (0.032)\tLoss 4.8943 (5.0245)\tPrec@1 79.000 (78.354)\tPrec@5 93.000 (95.901)\n",
            "Test: [190/261]\tTime 0.039 (0.032)\tLoss 4.4090 (5.0173)\tPrec@1 80.000 (78.377)\tPrec@5 94.000 (95.916)\n",
            "Test: [200/261]\tTime 0.054 (0.032)\tLoss 5.3013 (5.0200)\tPrec@1 76.000 (78.343)\tPrec@5 97.000 (95.930)\n",
            "Test: [210/261]\tTime 0.048 (0.033)\tLoss 4.3076 (5.0017)\tPrec@1 80.000 (78.417)\tPrec@5 97.000 (95.929)\n",
            "Test: [220/261]\tTime 0.033 (0.033)\tLoss 4.9605 (5.0066)\tPrec@1 82.000 (78.389)\tPrec@5 95.000 (95.900)\n",
            "Test: [230/261]\tTime 0.051 (0.034)\tLoss 6.7679 (5.0254)\tPrec@1 72.000 (78.316)\tPrec@5 91.000 (95.861)\n",
            "Test: [240/261]\tTime 0.053 (0.034)\tLoss 4.8312 (5.0270)\tPrec@1 80.000 (78.290)\tPrec@5 97.000 (95.842)\n",
            "Test: [250/261]\tTime 0.018 (0.035)\tLoss 5.4293 (5.0088)\tPrec@1 78.000 (78.375)\tPrec@5 96.000 (95.873)\n",
            "Test: [260/261]\tTime 0.006 (0.034)\tLoss 3.2678 (5.0204)\tPrec@1 84.375 (78.357)\tPrec@5 96.875 (95.840)\n",
            "val Results: Prec@1 78.357 Prec@5 95.840 Loss 5.02037\n",
            "val Class Accuracy: [0.576,0.967,0.968,0.624,0.902,0.700,0.750,0.591,0.775,0.463]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [27][0/66], lr: 0.01000\tTime 0.657 (0.657)\tData 0.547 (0.547)\tLoss 0.6453 (0.6453)\tPrec@1 97.656 (97.656)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [27][10/66], lr: 0.01000\tTime 0.116 (0.152)\tData 0.000 (0.053)\tLoss 0.5752 (0.6896)\tPrec@1 96.484 (96.591)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [27][20/66], lr: 0.01000\tTime 0.094 (0.128)\tData 0.000 (0.030)\tLoss 0.4889 (0.7532)\tPrec@1 98.047 (96.187)\tPrec@5 100.000 (99.740)\n",
            "Epoch: [27][30/66], lr: 0.01000\tTime 0.105 (0.119)\tData 0.005 (0.025)\tLoss 0.9004 (0.7316)\tPrec@1 94.531 (96.270)\tPrec@5 99.609 (99.761)\n",
            "Epoch: [27][40/66], lr: 0.01000\tTime 0.122 (0.115)\tData 0.000 (0.021)\tLoss 1.0416 (0.7370)\tPrec@1 94.531 (96.227)\tPrec@5 99.609 (99.781)\n",
            "Epoch: [27][50/66], lr: 0.01000\tTime 0.122 (0.112)\tData 0.009 (0.018)\tLoss 0.7346 (0.7441)\tPrec@1 95.703 (96.232)\tPrec@5 99.609 (99.770)\n",
            "Epoch: [27][60/66], lr: 0.01000\tTime 0.062 (0.109)\tData 0.000 (0.016)\tLoss 0.8929 (0.7525)\tPrec@1 95.312 (96.190)\tPrec@5 100.000 (99.776)\n",
            "Test: [0/261]\tTime 0.292 (0.292)\tLoss 5.1218 (5.1218)\tPrec@1 78.000 (78.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/261]\tTime 0.023 (0.056)\tLoss 5.0083 (4.8725)\tPrec@1 78.000 (78.182)\tPrec@5 96.000 (94.364)\n",
            "Test: [20/261]\tTime 0.015 (0.043)\tLoss 4.9984 (4.6075)\tPrec@1 78.000 (79.619)\tPrec@5 97.000 (94.667)\n",
            "Test: [30/261]\tTime 0.010 (0.037)\tLoss 3.0126 (4.4493)\tPrec@1 86.000 (80.613)\tPrec@5 96.000 (95.194)\n",
            "Test: [40/261]\tTime 0.024 (0.034)\tLoss 3.6650 (4.3837)\tPrec@1 85.000 (81.146)\tPrec@5 95.000 (95.463)\n",
            "Test: [50/261]\tTime 0.025 (0.033)\tLoss 4.6630 (4.3109)\tPrec@1 79.000 (81.392)\tPrec@5 94.000 (95.569)\n",
            "Test: [60/261]\tTime 0.033 (0.032)\tLoss 4.6609 (4.2578)\tPrec@1 81.000 (81.803)\tPrec@5 95.000 (95.525)\n",
            "Test: [70/261]\tTime 0.018 (0.031)\tLoss 5.1220 (4.2698)\tPrec@1 77.000 (81.718)\tPrec@5 96.000 (95.606)\n",
            "Test: [80/261]\tTime 0.025 (0.031)\tLoss 4.7325 (4.2636)\tPrec@1 78.000 (81.716)\tPrec@5 97.000 (95.691)\n",
            "Test: [90/261]\tTime 0.030 (0.030)\tLoss 4.8061 (4.3187)\tPrec@1 80.000 (81.429)\tPrec@5 95.000 (95.659)\n",
            "Test: [100/261]\tTime 0.042 (0.030)\tLoss 4.8134 (4.3204)\tPrec@1 81.000 (81.416)\tPrec@5 94.000 (95.653)\n",
            "Test: [110/261]\tTime 0.033 (0.030)\tLoss 4.1297 (4.2865)\tPrec@1 83.000 (81.541)\tPrec@5 94.000 (95.694)\n",
            "Test: [120/261]\tTime 0.034 (0.029)\tLoss 2.8677 (4.2929)\tPrec@1 89.000 (81.521)\tPrec@5 98.000 (95.653)\n",
            "Test: [130/261]\tTime 0.022 (0.029)\tLoss 3.6539 (4.2760)\tPrec@1 87.000 (81.573)\tPrec@5 96.000 (95.687)\n",
            "Test: [140/261]\tTime 0.018 (0.029)\tLoss 4.7466 (4.2831)\tPrec@1 78.000 (81.511)\tPrec@5 94.000 (95.716)\n",
            "Test: [150/261]\tTime 0.033 (0.029)\tLoss 3.2705 (4.2821)\tPrec@1 85.000 (81.523)\tPrec@5 97.000 (95.755)\n",
            "Test: [160/261]\tTime 0.018 (0.029)\tLoss 3.3778 (4.2832)\tPrec@1 87.000 (81.540)\tPrec@5 97.000 (95.801)\n",
            "Test: [170/261]\tTime 0.044 (0.029)\tLoss 3.8751 (4.2735)\tPrec@1 84.000 (81.614)\tPrec@5 96.000 (95.825)\n",
            "Test: [180/261]\tTime 0.030 (0.028)\tLoss 3.9288 (4.2831)\tPrec@1 83.000 (81.525)\tPrec@5 94.000 (95.801)\n",
            "Test: [190/261]\tTime 0.018 (0.028)\tLoss 3.3130 (4.2700)\tPrec@1 87.000 (81.565)\tPrec@5 96.000 (95.848)\n",
            "Test: [200/261]\tTime 0.050 (0.028)\tLoss 3.3451 (4.2617)\tPrec@1 85.000 (81.572)\tPrec@5 97.000 (95.841)\n",
            "Test: [210/261]\tTime 0.017 (0.028)\tLoss 3.6068 (4.2468)\tPrec@1 83.000 (81.645)\tPrec@5 99.000 (95.839)\n",
            "Test: [220/261]\tTime 0.041 (0.028)\tLoss 4.6858 (4.2460)\tPrec@1 79.000 (81.611)\tPrec@5 95.000 (95.828)\n",
            "Test: [230/261]\tTime 0.026 (0.028)\tLoss 4.9988 (4.2414)\tPrec@1 79.000 (81.602)\tPrec@5 93.000 (95.792)\n",
            "Test: [240/261]\tTime 0.026 (0.028)\tLoss 4.3604 (4.2411)\tPrec@1 82.000 (81.627)\tPrec@5 96.000 (95.759)\n",
            "Test: [250/261]\tTime 0.038 (0.028)\tLoss 4.3037 (4.2231)\tPrec@1 82.000 (81.693)\tPrec@5 96.000 (95.789)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 2.5822 (4.2333)\tPrec@1 90.625 (81.657)\tPrec@5 96.875 (95.767)\n",
            "val Results: Prec@1 81.657 Prec@5 95.767 Loss 4.23328\n",
            "val Class Accuracy: [0.599,0.963,0.929,0.797,0.876,0.895,0.652,0.838,0.705,0.411]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [28][0/66], lr: 0.01000\tTime 0.685 (0.685)\tData 0.574 (0.574)\tLoss 0.8615 (0.8615)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [28][10/66], lr: 0.01000\tTime 0.094 (0.155)\tData 0.000 (0.055)\tLoss 0.8415 (0.7884)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [28][20/66], lr: 0.01000\tTime 0.097 (0.132)\tData 0.005 (0.033)\tLoss 0.8937 (0.7908)\tPrec@1 95.312 (95.833)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [28][30/66], lr: 0.01000\tTime 0.111 (0.123)\tData 0.000 (0.024)\tLoss 0.6623 (0.7779)\tPrec@1 96.094 (95.993)\tPrec@5 100.000 (99.748)\n",
            "Epoch: [28][40/66], lr: 0.01000\tTime 0.117 (0.117)\tData 0.004 (0.020)\tLoss 0.5503 (0.7687)\tPrec@1 97.266 (95.989)\tPrec@5 99.609 (99.743)\n",
            "Epoch: [28][50/66], lr: 0.01000\tTime 0.114 (0.116)\tData 0.001 (0.017)\tLoss 0.6190 (0.7639)\tPrec@1 96.484 (96.002)\tPrec@5 100.000 (99.770)\n",
            "Epoch: [28][60/66], lr: 0.01000\tTime 0.067 (0.113)\tData 0.000 (0.015)\tLoss 0.6078 (0.7568)\tPrec@1 97.656 (96.017)\tPrec@5 100.000 (99.782)\n",
            "Test: [0/261]\tTime 0.282 (0.282)\tLoss 3.5754 (3.5754)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.033 (0.060)\tLoss 4.5641 (4.0714)\tPrec@1 81.000 (82.091)\tPrec@5 99.000 (97.636)\n",
            "Test: [20/261]\tTime 0.025 (0.043)\tLoss 4.3131 (4.0642)\tPrec@1 80.000 (82.143)\tPrec@5 94.000 (97.048)\n",
            "Test: [30/261]\tTime 0.017 (0.036)\tLoss 3.1319 (3.8156)\tPrec@1 85.000 (83.419)\tPrec@5 96.000 (97.258)\n",
            "Test: [40/261]\tTime 0.028 (0.035)\tLoss 2.8830 (3.7065)\tPrec@1 88.000 (83.634)\tPrec@5 96.000 (97.512)\n",
            "Test: [50/261]\tTime 0.028 (0.033)\tLoss 3.0137 (3.6767)\tPrec@1 89.000 (83.784)\tPrec@5 97.000 (97.353)\n",
            "Test: [60/261]\tTime 0.032 (0.032)\tLoss 3.1687 (3.6363)\tPrec@1 86.000 (83.951)\tPrec@5 97.000 (97.328)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 3.8090 (3.6405)\tPrec@1 82.000 (84.028)\tPrec@5 98.000 (97.366)\n",
            "Test: [80/261]\tTime 0.015 (0.032)\tLoss 3.9596 (3.6379)\tPrec@1 83.000 (84.049)\tPrec@5 97.000 (97.333)\n",
            "Test: [90/261]\tTime 0.036 (0.031)\tLoss 3.9720 (3.6708)\tPrec@1 87.000 (83.923)\tPrec@5 96.000 (97.286)\n",
            "Test: [100/261]\tTime 0.031 (0.031)\tLoss 4.5928 (3.6561)\tPrec@1 81.000 (83.931)\tPrec@5 94.000 (97.297)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 3.1864 (3.6203)\tPrec@1 86.000 (84.108)\tPrec@5 98.000 (97.360)\n",
            "Test: [120/261]\tTime 0.030 (0.030)\tLoss 3.1524 (3.6208)\tPrec@1 87.000 (84.074)\tPrec@5 96.000 (97.355)\n",
            "Test: [130/261]\tTime 0.038 (0.030)\tLoss 3.7708 (3.6180)\tPrec@1 84.000 (84.023)\tPrec@5 95.000 (97.366)\n",
            "Test: [140/261]\tTime 0.036 (0.030)\tLoss 4.2534 (3.6011)\tPrec@1 84.000 (84.135)\tPrec@5 93.000 (97.376)\n",
            "Test: [150/261]\tTime 0.036 (0.030)\tLoss 3.8952 (3.6158)\tPrec@1 84.000 (84.119)\tPrec@5 97.000 (97.371)\n",
            "Test: [160/261]\tTime 0.019 (0.029)\tLoss 1.6646 (3.5983)\tPrec@1 94.000 (84.149)\tPrec@5 100.000 (97.391)\n",
            "Test: [170/261]\tTime 0.015 (0.029)\tLoss 2.8498 (3.5701)\tPrec@1 88.000 (84.263)\tPrec@5 97.000 (97.427)\n",
            "Test: [180/261]\tTime 0.027 (0.029)\tLoss 3.1130 (3.5707)\tPrec@1 86.000 (84.243)\tPrec@5 97.000 (97.392)\n",
            "Test: [190/261]\tTime 0.014 (0.029)\tLoss 3.0515 (3.5666)\tPrec@1 83.000 (84.257)\tPrec@5 96.000 (97.429)\n",
            "Test: [200/261]\tTime 0.029 (0.029)\tLoss 3.0457 (3.5627)\tPrec@1 85.000 (84.294)\tPrec@5 98.000 (97.418)\n",
            "Test: [210/261]\tTime 0.021 (0.029)\tLoss 3.1487 (3.5613)\tPrec@1 85.000 (84.299)\tPrec@5 98.000 (97.379)\n",
            "Test: [220/261]\tTime 0.025 (0.029)\tLoss 3.2256 (3.5545)\tPrec@1 86.000 (84.330)\tPrec@5 97.000 (97.376)\n",
            "Test: [230/261]\tTime 0.043 (0.029)\tLoss 4.8296 (3.5719)\tPrec@1 76.000 (84.225)\tPrec@5 95.000 (97.368)\n",
            "Test: [240/261]\tTime 0.045 (0.029)\tLoss 2.9775 (3.5700)\tPrec@1 87.000 (84.241)\tPrec@5 98.000 (97.344)\n",
            "Test: [250/261]\tTime 0.049 (0.029)\tLoss 3.1968 (3.5528)\tPrec@1 85.000 (84.295)\tPrec@5 98.000 (97.382)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.4531 (3.5626)\tPrec@1 93.750 (84.231)\tPrec@5 96.875 (97.380)\n",
            "val Results: Prec@1 84.231 Prec@5 97.380 Loss 3.56262\n",
            "val Class Accuracy: [0.720,0.950,0.952,0.786,0.924,0.778,0.817,0.766,0.758,0.633]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [29][0/66], lr: 0.01000\tTime 0.631 (0.631)\tData 0.546 (0.546)\tLoss 0.5431 (0.5431)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [29][10/66], lr: 0.01000\tTime 0.107 (0.153)\tData 0.000 (0.055)\tLoss 0.8570 (0.7831)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [29][20/66], lr: 0.01000\tTime 0.114 (0.131)\tData 0.001 (0.035)\tLoss 0.6240 (0.7439)\tPrec@1 96.875 (96.391)\tPrec@5 99.609 (99.907)\n",
            "Epoch: [29][30/66], lr: 0.01000\tTime 0.103 (0.120)\tData 0.011 (0.026)\tLoss 0.7635 (0.7353)\tPrec@1 96.484 (96.333)\tPrec@5 99.609 (99.874)\n",
            "Epoch: [29][40/66], lr: 0.01000\tTime 0.119 (0.114)\tData 0.003 (0.021)\tLoss 1.1327 (0.7535)\tPrec@1 94.531 (96.218)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [29][50/66], lr: 0.01000\tTime 0.107 (0.112)\tData 0.000 (0.018)\tLoss 0.8251 (0.7665)\tPrec@1 94.922 (96.101)\tPrec@5 99.609 (99.824)\n",
            "Epoch: [29][60/66], lr: 0.01000\tTime 0.086 (0.111)\tData 0.000 (0.017)\tLoss 1.2168 (0.7741)\tPrec@1 94.141 (96.043)\tPrec@5 98.828 (99.808)\n",
            "Test: [0/261]\tTime 0.380 (0.380)\tLoss 4.1566 (4.1566)\tPrec@1 84.000 (84.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.036 (0.057)\tLoss 5.4841 (4.4916)\tPrec@1 77.000 (80.455)\tPrec@5 96.000 (96.182)\n",
            "Test: [20/261]\tTime 0.020 (0.044)\tLoss 4.7673 (4.4648)\tPrec@1 79.000 (80.524)\tPrec@5 95.000 (96.000)\n",
            "Test: [30/261]\tTime 0.045 (0.039)\tLoss 3.2747 (4.2500)\tPrec@1 86.000 (81.645)\tPrec@5 94.000 (95.968)\n",
            "Test: [40/261]\tTime 0.011 (0.036)\tLoss 3.8626 (4.2376)\tPrec@1 85.000 (81.878)\tPrec@5 94.000 (96.024)\n",
            "Test: [50/261]\tTime 0.030 (0.035)\tLoss 3.8411 (4.1956)\tPrec@1 82.000 (82.059)\tPrec@5 97.000 (96.078)\n",
            "Test: [60/261]\tTime 0.025 (0.033)\tLoss 4.1037 (4.1437)\tPrec@1 83.000 (82.246)\tPrec@5 96.000 (96.148)\n",
            "Test: [70/261]\tTime 0.017 (0.032)\tLoss 5.3335 (4.1198)\tPrec@1 78.000 (82.324)\tPrec@5 96.000 (96.296)\n",
            "Test: [80/261]\tTime 0.036 (0.031)\tLoss 5.0337 (4.1461)\tPrec@1 79.000 (82.160)\tPrec@5 96.000 (96.222)\n",
            "Test: [90/261]\tTime 0.031 (0.031)\tLoss 4.5321 (4.1934)\tPrec@1 83.000 (81.978)\tPrec@5 95.000 (96.121)\n",
            "Test: [100/261]\tTime 0.038 (0.031)\tLoss 5.4712 (4.1991)\tPrec@1 79.000 (82.059)\tPrec@5 93.000 (96.119)\n",
            "Test: [110/261]\tTime 0.014 (0.030)\tLoss 4.1419 (4.1673)\tPrec@1 82.000 (82.216)\tPrec@5 94.000 (96.162)\n",
            "Test: [120/261]\tTime 0.041 (0.030)\tLoss 2.7333 (4.1606)\tPrec@1 87.000 (82.248)\tPrec@5 98.000 (96.157)\n",
            "Test: [130/261]\tTime 0.017 (0.029)\tLoss 4.9062 (4.1805)\tPrec@1 80.000 (82.145)\tPrec@5 94.000 (96.153)\n",
            "Test: [140/261]\tTime 0.023 (0.029)\tLoss 5.6142 (4.1633)\tPrec@1 76.000 (82.227)\tPrec@5 89.000 (96.156)\n",
            "Test: [150/261]\tTime 0.031 (0.030)\tLoss 3.7491 (4.1615)\tPrec@1 85.000 (82.258)\tPrec@5 94.000 (96.219)\n",
            "Test: [160/261]\tTime 0.015 (0.029)\tLoss 3.1641 (4.1541)\tPrec@1 87.000 (82.261)\tPrec@5 98.000 (96.230)\n",
            "Test: [170/261]\tTime 0.024 (0.029)\tLoss 3.8132 (4.1373)\tPrec@1 82.000 (82.310)\tPrec@5 95.000 (96.257)\n",
            "Test: [180/261]\tTime 0.039 (0.029)\tLoss 3.7115 (4.1504)\tPrec@1 85.000 (82.215)\tPrec@5 93.000 (96.276)\n",
            "Test: [190/261]\tTime 0.037 (0.029)\tLoss 3.5172 (4.1317)\tPrec@1 82.000 (82.319)\tPrec@5 96.000 (96.330)\n",
            "Test: [200/261]\tTime 0.038 (0.029)\tLoss 3.5440 (4.1279)\tPrec@1 86.000 (82.343)\tPrec@5 98.000 (96.328)\n",
            "Test: [210/261]\tTime 0.025 (0.029)\tLoss 2.9589 (4.1105)\tPrec@1 87.000 (82.384)\tPrec@5 98.000 (96.355)\n",
            "Test: [220/261]\tTime 0.026 (0.029)\tLoss 4.4485 (4.1045)\tPrec@1 79.000 (82.380)\tPrec@5 96.000 (96.353)\n",
            "Test: [230/261]\tTime 0.028 (0.029)\tLoss 4.9855 (4.1013)\tPrec@1 77.000 (82.368)\tPrec@5 95.000 (96.351)\n",
            "Test: [240/261]\tTime 0.026 (0.028)\tLoss 3.3123 (4.1038)\tPrec@1 85.000 (82.324)\tPrec@5 97.000 (96.332)\n",
            "Test: [250/261]\tTime 0.027 (0.028)\tLoss 4.2393 (4.0906)\tPrec@1 81.000 (82.386)\tPrec@5 98.000 (96.382)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.1066 (4.1005)\tPrec@1 87.500 (82.352)\tPrec@5 96.875 (96.370)\n",
            "val Results: Prec@1 82.352 Prec@5 96.370 Loss 4.10049\n",
            "val Class Accuracy: [0.670,0.972,0.950,0.779,0.901,0.846,0.672,0.567,0.782,0.667]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [30][0/66], lr: 0.01000\tTime 0.602 (0.602)\tData 0.500 (0.500)\tLoss 0.4575 (0.4575)\tPrec@1 98.047 (98.047)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [30][10/66], lr: 0.01000\tTime 0.097 (0.154)\tData 0.000 (0.059)\tLoss 0.7642 (0.7428)\tPrec@1 96.094 (96.236)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [30][20/66], lr: 0.01000\tTime 0.095 (0.128)\tData 0.005 (0.037)\tLoss 1.0656 (0.7645)\tPrec@1 95.312 (96.112)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [30][30/66], lr: 0.01000\tTime 0.134 (0.124)\tData 0.000 (0.032)\tLoss 0.9456 (0.7814)\tPrec@1 94.531 (95.993)\tPrec@5 100.000 (99.773)\n",
            "Epoch: [30][40/66], lr: 0.01000\tTime 0.182 (0.132)\tData 0.000 (0.035)\tLoss 1.1008 (0.8046)\tPrec@1 93.750 (95.865)\tPrec@5 100.000 (99.771)\n",
            "Epoch: [30][50/66], lr: 0.01000\tTime 0.140 (0.141)\tData 0.012 (0.040)\tLoss 0.5577 (0.7928)\tPrec@1 96.484 (95.895)\tPrec@5 100.000 (99.793)\n",
            "Epoch: [30][60/66], lr: 0.01000\tTime 0.075 (0.137)\tData 0.000 (0.037)\tLoss 0.3873 (0.7914)\tPrec@1 98.438 (95.914)\tPrec@5 100.000 (99.795)\n",
            "Test: [0/261]\tTime 0.343 (0.343)\tLoss 3.5760 (3.5760)\tPrec@1 83.000 (83.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.037 (0.060)\tLoss 4.5342 (4.3181)\tPrec@1 80.000 (79.909)\tPrec@5 97.000 (97.273)\n",
            "Test: [20/261]\tTime 0.032 (0.043)\tLoss 4.6951 (4.3015)\tPrec@1 79.000 (80.143)\tPrec@5 96.000 (97.000)\n",
            "Test: [30/261]\tTime 0.022 (0.038)\tLoss 3.5234 (4.1326)\tPrec@1 82.000 (80.968)\tPrec@5 98.000 (97.290)\n",
            "Test: [40/261]\tTime 0.036 (0.036)\tLoss 2.7191 (4.0506)\tPrec@1 89.000 (81.390)\tPrec@5 98.000 (97.415)\n",
            "Test: [50/261]\tTime 0.011 (0.034)\tLoss 3.5173 (3.9645)\tPrec@1 85.000 (81.922)\tPrec@5 97.000 (97.490)\n",
            "Test: [60/261]\tTime 0.014 (0.032)\tLoss 3.7935 (3.9440)\tPrec@1 84.000 (82.148)\tPrec@5 99.000 (97.492)\n",
            "Test: [70/261]\tTime 0.030 (0.032)\tLoss 4.3888 (3.9514)\tPrec@1 78.000 (82.000)\tPrec@5 98.000 (97.493)\n",
            "Test: [80/261]\tTime 0.026 (0.032)\tLoss 4.3502 (3.9436)\tPrec@1 81.000 (82.136)\tPrec@5 96.000 (97.469)\n",
            "Test: [90/261]\tTime 0.041 (0.031)\tLoss 4.5126 (3.9835)\tPrec@1 82.000 (81.912)\tPrec@5 94.000 (97.319)\n",
            "Test: [100/261]\tTime 0.019 (0.030)\tLoss 5.3419 (3.9965)\tPrec@1 76.000 (81.871)\tPrec@5 94.000 (97.287)\n",
            "Test: [110/261]\tTime 0.030 (0.030)\tLoss 3.9917 (3.9632)\tPrec@1 83.000 (82.054)\tPrec@5 98.000 (97.378)\n",
            "Test: [120/261]\tTime 0.047 (0.030)\tLoss 2.7814 (3.9387)\tPrec@1 86.000 (82.223)\tPrec@5 98.000 (97.413)\n",
            "Test: [130/261]\tTime 0.023 (0.030)\tLoss 4.2302 (3.9384)\tPrec@1 80.000 (82.191)\tPrec@5 98.000 (97.382)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 5.0215 (3.9309)\tPrec@1 83.000 (82.220)\tPrec@5 94.000 (97.355)\n",
            "Test: [150/261]\tTime 0.030 (0.030)\tLoss 3.9440 (3.9365)\tPrec@1 80.000 (82.199)\tPrec@5 96.000 (97.358)\n",
            "Test: [160/261]\tTime 0.034 (0.030)\tLoss 3.2779 (3.9388)\tPrec@1 85.000 (82.211)\tPrec@5 98.000 (97.385)\n",
            "Test: [170/261]\tTime 0.023 (0.030)\tLoss 2.6640 (3.9033)\tPrec@1 86.000 (82.392)\tPrec@5 96.000 (97.415)\n",
            "Test: [180/261]\tTime 0.040 (0.029)\tLoss 3.2794 (3.8998)\tPrec@1 85.000 (82.359)\tPrec@5 94.000 (97.409)\n",
            "Test: [190/261]\tTime 0.062 (0.029)\tLoss 3.7687 (3.8869)\tPrec@1 84.000 (82.429)\tPrec@5 97.000 (97.424)\n",
            "Test: [200/261]\tTime 0.017 (0.029)\tLoss 3.3776 (3.8882)\tPrec@1 88.000 (82.383)\tPrec@5 97.000 (97.428)\n",
            "Test: [210/261]\tTime 0.041 (0.029)\tLoss 3.5857 (3.8643)\tPrec@1 84.000 (82.502)\tPrec@5 97.000 (97.422)\n",
            "Test: [220/261]\tTime 0.030 (0.029)\tLoss 3.8832 (3.8569)\tPrec@1 82.000 (82.529)\tPrec@5 98.000 (97.439)\n",
            "Test: [230/261]\tTime 0.017 (0.029)\tLoss 4.5292 (3.8678)\tPrec@1 79.000 (82.450)\tPrec@5 97.000 (97.420)\n",
            "Test: [240/261]\tTime 0.033 (0.029)\tLoss 2.7520 (3.8623)\tPrec@1 88.000 (82.506)\tPrec@5 99.000 (97.423)\n",
            "Test: [250/261]\tTime 0.035 (0.029)\tLoss 2.9593 (3.8483)\tPrec@1 86.000 (82.566)\tPrec@5 99.000 (97.446)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.4266 (3.8526)\tPrec@1 90.625 (82.541)\tPrec@5 96.875 (97.434)\n",
            "val Results: Prec@1 82.541 Prec@5 97.434 Loss 3.85263\n",
            "val Class Accuracy: [0.732,0.853,0.918,0.841,0.966,0.648,0.814,0.865,0.698,0.713]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [31][0/66], lr: 0.01000\tTime 0.713 (0.713)\tData 0.600 (0.600)\tLoss 0.7124 (0.7124)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [31][10/66], lr: 0.01000\tTime 0.100 (0.160)\tData 0.005 (0.061)\tLoss 0.7685 (0.7003)\tPrec@1 95.703 (96.484)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [31][20/66], lr: 0.01000\tTime 0.094 (0.134)\tData 0.005 (0.034)\tLoss 0.5627 (0.6957)\tPrec@1 96.484 (96.317)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [31][30/66], lr: 0.01000\tTime 0.115 (0.123)\tData 0.000 (0.025)\tLoss 0.6042 (0.6883)\tPrec@1 97.266 (96.384)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [31][40/66], lr: 0.01000\tTime 0.108 (0.118)\tData 0.009 (0.021)\tLoss 0.9917 (0.7082)\tPrec@1 94.922 (96.361)\tPrec@5 99.609 (99.857)\n",
            "Epoch: [31][50/66], lr: 0.01000\tTime 0.095 (0.115)\tData 0.000 (0.018)\tLoss 1.3614 (0.7479)\tPrec@1 92.969 (96.178)\tPrec@5 98.828 (99.824)\n",
            "Epoch: [31][60/66], lr: 0.01000\tTime 0.075 (0.112)\tData 0.000 (0.016)\tLoss 0.9345 (0.7540)\tPrec@1 94.922 (96.126)\tPrec@5 100.000 (99.827)\n",
            "Test: [0/261]\tTime 0.337 (0.337)\tLoss 4.2633 (4.2633)\tPrec@1 84.000 (84.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.035 (0.058)\tLoss 5.4770 (4.8863)\tPrec@1 77.000 (78.818)\tPrec@5 97.000 (95.636)\n",
            "Test: [20/261]\tTime 0.029 (0.043)\tLoss 4.2904 (4.7606)\tPrec@1 80.000 (79.762)\tPrec@5 96.000 (95.143)\n",
            "Test: [30/261]\tTime 0.036 (0.039)\tLoss 2.8665 (4.4919)\tPrec@1 88.000 (81.290)\tPrec@5 97.000 (95.452)\n",
            "Test: [40/261]\tTime 0.015 (0.035)\tLoss 3.6735 (4.4130)\tPrec@1 84.000 (81.512)\tPrec@5 96.000 (95.634)\n",
            "Test: [50/261]\tTime 0.038 (0.034)\tLoss 3.6369 (4.3486)\tPrec@1 85.000 (81.765)\tPrec@5 96.000 (95.569)\n",
            "Test: [60/261]\tTime 0.018 (0.033)\tLoss 4.5023 (4.2914)\tPrec@1 83.000 (82.213)\tPrec@5 95.000 (95.590)\n",
            "Test: [70/261]\tTime 0.031 (0.032)\tLoss 5.5703 (4.2886)\tPrec@1 76.000 (82.113)\tPrec@5 93.000 (95.563)\n",
            "Test: [80/261]\tTime 0.024 (0.031)\tLoss 4.3214 (4.2896)\tPrec@1 85.000 (82.123)\tPrec@5 93.000 (95.506)\n",
            "Test: [90/261]\tTime 0.011 (0.031)\tLoss 4.9536 (4.3234)\tPrec@1 80.000 (82.000)\tPrec@5 93.000 (95.473)\n",
            "Test: [100/261]\tTime 0.013 (0.031)\tLoss 5.0797 (4.3062)\tPrec@1 80.000 (82.129)\tPrec@5 95.000 (95.535)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 4.2708 (4.2904)\tPrec@1 84.000 (82.162)\tPrec@5 95.000 (95.559)\n",
            "Test: [120/261]\tTime 0.031 (0.031)\tLoss 3.0900 (4.2987)\tPrec@1 85.000 (82.074)\tPrec@5 98.000 (95.521)\n",
            "Test: [130/261]\tTime 0.025 (0.031)\tLoss 4.2947 (4.2654)\tPrec@1 83.000 (82.237)\tPrec@5 95.000 (95.595)\n",
            "Test: [140/261]\tTime 0.039 (0.030)\tLoss 4.4107 (4.2549)\tPrec@1 83.000 (82.270)\tPrec@5 95.000 (95.652)\n",
            "Test: [150/261]\tTime 0.035 (0.030)\tLoss 4.1620 (4.2548)\tPrec@1 83.000 (82.245)\tPrec@5 95.000 (95.675)\n",
            "Test: [160/261]\tTime 0.014 (0.030)\tLoss 3.8081 (4.2589)\tPrec@1 84.000 (82.211)\tPrec@5 98.000 (95.708)\n",
            "Test: [170/261]\tTime 0.022 (0.030)\tLoss 3.4044 (4.2358)\tPrec@1 85.000 (82.292)\tPrec@5 94.000 (95.725)\n",
            "Test: [180/261]\tTime 0.050 (0.030)\tLoss 3.1020 (4.2340)\tPrec@1 87.000 (82.293)\tPrec@5 95.000 (95.713)\n",
            "Test: [190/261]\tTime 0.038 (0.030)\tLoss 4.2631 (4.2323)\tPrec@1 83.000 (82.319)\tPrec@5 95.000 (95.702)\n",
            "Test: [200/261]\tTime 0.038 (0.030)\tLoss 3.3462 (4.2309)\tPrec@1 86.000 (82.299)\tPrec@5 99.000 (95.726)\n",
            "Test: [210/261]\tTime 0.028 (0.029)\tLoss 3.7685 (4.2146)\tPrec@1 83.000 (82.336)\tPrec@5 98.000 (95.720)\n",
            "Test: [220/261]\tTime 0.045 (0.029)\tLoss 4.6576 (4.2107)\tPrec@1 80.000 (82.317)\tPrec@5 97.000 (95.729)\n",
            "Test: [230/261]\tTime 0.021 (0.029)\tLoss 5.4329 (4.2268)\tPrec@1 77.000 (82.225)\tPrec@5 94.000 (95.701)\n",
            "Test: [240/261]\tTime 0.015 (0.029)\tLoss 4.3100 (4.2378)\tPrec@1 82.000 (82.162)\tPrec@5 95.000 (95.672)\n",
            "Test: [250/261]\tTime 0.029 (0.029)\tLoss 3.6003 (4.2234)\tPrec@1 85.000 (82.227)\tPrec@5 97.000 (95.725)\n",
            "Test: [260/261]\tTime 0.006 (0.029)\tLoss 2.7111 (4.2348)\tPrec@1 84.375 (82.180)\tPrec@5 96.875 (95.709)\n",
            "val Results: Prec@1 82.180 Prec@5 95.709 Loss 4.23482\n",
            "val Class Accuracy: [0.549,0.974,0.969,0.836,0.860,0.677,0.832,0.764,0.776,0.489]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [32][0/66], lr: 0.01000\tTime 0.623 (0.623)\tData 0.539 (0.539)\tLoss 0.7243 (0.7243)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [32][10/66], lr: 0.01000\tTime 0.101 (0.157)\tData 0.000 (0.056)\tLoss 0.5142 (0.6857)\tPrec@1 96.094 (96.520)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [32][20/66], lr: 0.01000\tTime 0.089 (0.128)\tData 0.000 (0.031)\tLoss 0.4680 (0.7038)\tPrec@1 97.656 (96.447)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [32][30/66], lr: 0.01000\tTime 0.110 (0.122)\tData 0.007 (0.024)\tLoss 0.9049 (0.7093)\tPrec@1 94.922 (96.333)\tPrec@5 99.219 (99.824)\n",
            "Epoch: [32][40/66], lr: 0.01000\tTime 0.153 (0.118)\tData 0.000 (0.020)\tLoss 0.6455 (0.7389)\tPrec@1 96.484 (96.141)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [32][50/66], lr: 0.01000\tTime 0.093 (0.114)\tData 0.005 (0.017)\tLoss 0.7652 (0.7540)\tPrec@1 95.312 (96.063)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [32][60/66], lr: 0.01000\tTime 0.065 (0.112)\tData 0.000 (0.015)\tLoss 0.8564 (0.7531)\tPrec@1 96.094 (96.094)\tPrec@5 99.609 (99.840)\n",
            "Test: [0/261]\tTime 0.362 (0.362)\tLoss 4.2260 (4.2260)\tPrec@1 81.000 (81.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.012 (0.060)\tLoss 5.0021 (4.5209)\tPrec@1 79.000 (79.818)\tPrec@5 94.000 (96.182)\n",
            "Test: [20/261]\tTime 0.026 (0.043)\tLoss 4.0944 (4.3847)\tPrec@1 79.000 (80.190)\tPrec@5 96.000 (96.095)\n",
            "Test: [30/261]\tTime 0.027 (0.040)\tLoss 3.6869 (4.2298)\tPrec@1 82.000 (81.129)\tPrec@5 98.000 (96.387)\n",
            "Test: [40/261]\tTime 0.011 (0.037)\tLoss 3.5391 (4.1414)\tPrec@1 84.000 (81.610)\tPrec@5 96.000 (96.463)\n",
            "Test: [50/261]\tTime 0.039 (0.034)\tLoss 3.7132 (4.0886)\tPrec@1 85.000 (81.882)\tPrec@5 95.000 (96.431)\n",
            "Test: [60/261]\tTime 0.023 (0.033)\tLoss 3.9385 (4.0696)\tPrec@1 84.000 (81.934)\tPrec@5 97.000 (96.459)\n",
            "Test: [70/261]\tTime 0.036 (0.032)\tLoss 4.7679 (4.0896)\tPrec@1 79.000 (81.732)\tPrec@5 96.000 (96.606)\n",
            "Test: [80/261]\tTime 0.057 (0.032)\tLoss 4.2822 (4.0730)\tPrec@1 81.000 (81.827)\tPrec@5 95.000 (96.519)\n",
            "Test: [90/261]\tTime 0.017 (0.031)\tLoss 3.3457 (4.1068)\tPrec@1 87.000 (81.681)\tPrec@5 96.000 (96.407)\n",
            "Test: [100/261]\tTime 0.011 (0.031)\tLoss 4.8990 (4.1087)\tPrec@1 78.000 (81.604)\tPrec@5 92.000 (96.356)\n",
            "Test: [110/261]\tTime 0.024 (0.030)\tLoss 3.7732 (4.0913)\tPrec@1 85.000 (81.730)\tPrec@5 96.000 (96.351)\n",
            "Test: [120/261]\tTime 0.026 (0.030)\tLoss 3.1564 (4.0911)\tPrec@1 85.000 (81.744)\tPrec@5 97.000 (96.331)\n",
            "Test: [130/261]\tTime 0.032 (0.030)\tLoss 4.3104 (4.0771)\tPrec@1 77.000 (81.740)\tPrec@5 95.000 (96.344)\n",
            "Test: [140/261]\tTime 0.030 (0.030)\tLoss 4.0958 (4.0610)\tPrec@1 84.000 (81.858)\tPrec@5 96.000 (96.383)\n",
            "Test: [150/261]\tTime 0.034 (0.030)\tLoss 2.7147 (4.0616)\tPrec@1 88.000 (81.887)\tPrec@5 97.000 (96.397)\n",
            "Test: [160/261]\tTime 0.015 (0.030)\tLoss 2.9438 (4.0550)\tPrec@1 89.000 (81.907)\tPrec@5 97.000 (96.398)\n",
            "Test: [170/261]\tTime 0.026 (0.029)\tLoss 3.0381 (4.0328)\tPrec@1 86.000 (82.018)\tPrec@5 96.000 (96.386)\n",
            "Test: [180/261]\tTime 0.034 (0.029)\tLoss 2.9207 (4.0249)\tPrec@1 86.000 (81.994)\tPrec@5 96.000 (96.414)\n",
            "Test: [190/261]\tTime 0.018 (0.029)\tLoss 3.1234 (4.0092)\tPrec@1 85.000 (82.047)\tPrec@5 99.000 (96.450)\n",
            "Test: [200/261]\tTime 0.018 (0.029)\tLoss 3.1493 (4.0011)\tPrec@1 86.000 (82.109)\tPrec@5 99.000 (96.443)\n",
            "Test: [210/261]\tTime 0.039 (0.029)\tLoss 3.6688 (3.9889)\tPrec@1 82.000 (82.137)\tPrec@5 97.000 (96.417)\n",
            "Test: [220/261]\tTime 0.025 (0.029)\tLoss 4.1161 (3.9812)\tPrec@1 80.000 (82.149)\tPrec@5 97.000 (96.430)\n",
            "Test: [230/261]\tTime 0.028 (0.029)\tLoss 5.6137 (3.9881)\tPrec@1 74.000 (82.117)\tPrec@5 91.000 (96.398)\n",
            "Test: [240/261]\tTime 0.019 (0.029)\tLoss 3.6817 (3.9909)\tPrec@1 85.000 (82.129)\tPrec@5 96.000 (96.386)\n",
            "Test: [250/261]\tTime 0.016 (0.028)\tLoss 3.5432 (3.9815)\tPrec@1 84.000 (82.135)\tPrec@5 98.000 (96.426)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.8540 (3.9935)\tPrec@1 90.625 (82.068)\tPrec@5 96.875 (96.408)\n",
            "val Results: Prec@1 82.068 Prec@5 96.408 Loss 3.99348\n",
            "val Class Accuracy: [0.650,0.841,0.940,0.914,0.942,0.726,0.790,0.833,0.716,0.546]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [33][0/66], lr: 0.01000\tTime 0.635 (0.635)\tData 0.538 (0.538)\tLoss 0.5139 (0.5139)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [33][10/66], lr: 0.01000\tTime 0.123 (0.152)\tData 0.000 (0.052)\tLoss 0.7116 (0.7027)\tPrec@1 96.094 (96.307)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [33][20/66], lr: 0.01000\tTime 0.120 (0.132)\tData 0.000 (0.029)\tLoss 0.8041 (0.7257)\tPrec@1 95.703 (96.168)\tPrec@5 99.609 (99.833)\n",
            "Epoch: [33][30/66], lr: 0.01000\tTime 0.091 (0.136)\tData 0.000 (0.032)\tLoss 0.6884 (0.6866)\tPrec@1 96.484 (96.459)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [33][40/66], lr: 0.01000\tTime 0.133 (0.141)\tData 0.003 (0.032)\tLoss 0.5301 (0.6962)\tPrec@1 97.656 (96.418)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [33][50/66], lr: 0.01000\tTime 0.112 (0.141)\tData 0.005 (0.033)\tLoss 0.7330 (0.6971)\tPrec@1 95.703 (96.461)\tPrec@5 100.000 (99.854)\n",
            "Epoch: [33][60/66], lr: 0.01000\tTime 0.092 (0.134)\tData 0.007 (0.029)\tLoss 0.4605 (0.7006)\tPrec@1 96.484 (96.401)\tPrec@5 99.609 (99.840)\n",
            "Test: [0/261]\tTime 0.332 (0.332)\tLoss 4.0340 (4.0340)\tPrec@1 82.000 (82.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.028 (0.056)\tLoss 4.7294 (4.3171)\tPrec@1 78.000 (80.455)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/261]\tTime 0.030 (0.042)\tLoss 4.5537 (4.2612)\tPrec@1 79.000 (81.143)\tPrec@5 94.000 (96.476)\n",
            "Test: [30/261]\tTime 0.047 (0.037)\tLoss 3.3261 (4.0241)\tPrec@1 85.000 (82.516)\tPrec@5 98.000 (96.903)\n",
            "Test: [40/261]\tTime 0.025 (0.035)\tLoss 2.8522 (3.9568)\tPrec@1 88.000 (82.756)\tPrec@5 100.000 (97.195)\n",
            "Test: [50/261]\tTime 0.025 (0.035)\tLoss 2.4152 (3.8708)\tPrec@1 90.000 (83.000)\tPrec@5 99.000 (97.314)\n",
            "Test: [60/261]\tTime 0.020 (0.033)\tLoss 3.9147 (3.8693)\tPrec@1 84.000 (83.016)\tPrec@5 99.000 (97.377)\n",
            "Test: [70/261]\tTime 0.012 (0.032)\tLoss 4.5661 (3.8397)\tPrec@1 78.000 (83.099)\tPrec@5 97.000 (97.394)\n",
            "Test: [80/261]\tTime 0.022 (0.032)\tLoss 3.8486 (3.8427)\tPrec@1 82.000 (83.111)\tPrec@5 96.000 (97.469)\n",
            "Test: [90/261]\tTime 0.010 (0.031)\tLoss 4.4911 (3.9077)\tPrec@1 81.000 (82.912)\tPrec@5 96.000 (97.374)\n",
            "Test: [100/261]\tTime 0.019 (0.030)\tLoss 5.5541 (3.8956)\tPrec@1 76.000 (82.960)\tPrec@5 93.000 (97.376)\n",
            "Test: [110/261]\tTime 0.018 (0.030)\tLoss 4.1890 (3.8792)\tPrec@1 82.000 (83.009)\tPrec@5 97.000 (97.396)\n",
            "Test: [120/261]\tTime 0.022 (0.030)\tLoss 3.1010 (3.8777)\tPrec@1 85.000 (83.050)\tPrec@5 98.000 (97.413)\n",
            "Test: [130/261]\tTime 0.036 (0.030)\tLoss 4.4147 (3.8816)\tPrec@1 81.000 (82.962)\tPrec@5 96.000 (97.382)\n",
            "Test: [140/261]\tTime 0.026 (0.029)\tLoss 4.2836 (3.8615)\tPrec@1 83.000 (83.078)\tPrec@5 96.000 (97.426)\n",
            "Test: [150/261]\tTime 0.022 (0.030)\tLoss 2.6917 (3.8588)\tPrec@1 89.000 (83.119)\tPrec@5 97.000 (97.384)\n",
            "Test: [160/261]\tTime 0.029 (0.029)\tLoss 2.1004 (3.8549)\tPrec@1 91.000 (83.118)\tPrec@5 100.000 (97.410)\n",
            "Test: [170/261]\tTime 0.024 (0.029)\tLoss 3.6885 (3.8245)\tPrec@1 82.000 (83.228)\tPrec@5 96.000 (97.404)\n",
            "Test: [180/261]\tTime 0.026 (0.029)\tLoss 2.9794 (3.8172)\tPrec@1 87.000 (83.249)\tPrec@5 98.000 (97.414)\n",
            "Test: [190/261]\tTime 0.033 (0.029)\tLoss 3.2000 (3.8069)\tPrec@1 87.000 (83.309)\tPrec@5 97.000 (97.450)\n",
            "Test: [200/261]\tTime 0.020 (0.029)\tLoss 3.0881 (3.8092)\tPrec@1 85.000 (83.259)\tPrec@5 98.000 (97.413)\n",
            "Test: [210/261]\tTime 0.010 (0.028)\tLoss 4.0481 (3.8032)\tPrec@1 82.000 (83.294)\tPrec@5 99.000 (97.441)\n",
            "Test: [220/261]\tTime 0.019 (0.028)\tLoss 3.7641 (3.7926)\tPrec@1 83.000 (83.330)\tPrec@5 98.000 (97.475)\n",
            "Test: [230/261]\tTime 0.027 (0.028)\tLoss 4.8167 (3.7996)\tPrec@1 77.000 (83.312)\tPrec@5 98.000 (97.455)\n",
            "Test: [240/261]\tTime 0.032 (0.028)\tLoss 3.8325 (3.8046)\tPrec@1 84.000 (83.349)\tPrec@5 98.000 (97.436)\n",
            "Test: [250/261]\tTime 0.012 (0.028)\tLoss 2.8033 (3.7851)\tPrec@1 89.000 (83.454)\tPrec@5 100.000 (97.498)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.4054 (3.7856)\tPrec@1 96.875 (83.447)\tPrec@5 96.875 (97.480)\n",
            "val Results: Prec@1 83.447 Prec@5 97.480 Loss 3.78557\n",
            "val Class Accuracy: [0.579,0.916,0.952,0.915,0.915,0.596,0.790,0.800,0.828,0.735]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [34][0/66], lr: 0.01000\tTime 0.674 (0.674)\tData 0.563 (0.563)\tLoss 0.5440 (0.5440)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [34][10/66], lr: 0.01000\tTime 0.071 (0.146)\tData 0.004 (0.055)\tLoss 0.8312 (0.6541)\tPrec@1 95.312 (96.484)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [34][20/66], lr: 0.01000\tTime 0.107 (0.126)\tData 0.004 (0.040)\tLoss 0.6639 (0.6298)\tPrec@1 96.484 (96.726)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [34][30/66], lr: 0.01000\tTime 0.086 (0.117)\tData 0.010 (0.030)\tLoss 0.7458 (0.6587)\tPrec@1 96.094 (96.547)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [34][40/66], lr: 0.01000\tTime 0.067 (0.114)\tData 0.005 (0.027)\tLoss 0.8218 (0.6746)\tPrec@1 94.922 (96.465)\tPrec@5 99.609 (99.838)\n",
            "Epoch: [34][50/66], lr: 0.01000\tTime 0.065 (0.111)\tData 0.007 (0.023)\tLoss 0.7745 (0.6933)\tPrec@1 96.094 (96.369)\tPrec@5 99.219 (99.831)\n",
            "Epoch: [34][60/66], lr: 0.01000\tTime 0.073 (0.109)\tData 0.000 (0.021)\tLoss 0.4770 (0.6963)\tPrec@1 97.266 (96.369)\tPrec@5 99.609 (99.840)\n",
            "Test: [0/261]\tTime 0.337 (0.337)\tLoss 5.3538 (5.3538)\tPrec@1 77.000 (77.000)\tPrec@5 90.000 (90.000)\n",
            "Test: [10/261]\tTime 0.029 (0.060)\tLoss 6.2130 (5.5911)\tPrec@1 76.000 (76.727)\tPrec@5 91.000 (93.455)\n",
            "Test: [20/261]\tTime 0.021 (0.045)\tLoss 5.3410 (5.4474)\tPrec@1 77.000 (77.286)\tPrec@5 93.000 (93.476)\n",
            "Test: [30/261]\tTime 0.024 (0.039)\tLoss 4.3708 (5.2323)\tPrec@1 80.000 (78.161)\tPrec@5 98.000 (94.032)\n",
            "Test: [40/261]\tTime 0.024 (0.036)\tLoss 4.3626 (5.1459)\tPrec@1 83.000 (78.585)\tPrec@5 96.000 (94.268)\n",
            "Test: [50/261]\tTime 0.037 (0.035)\tLoss 5.7854 (5.0773)\tPrec@1 77.000 (78.902)\tPrec@5 94.000 (94.196)\n",
            "Test: [60/261]\tTime 0.037 (0.034)\tLoss 5.2970 (5.0649)\tPrec@1 82.000 (79.016)\tPrec@5 94.000 (94.246)\n",
            "Test: [70/261]\tTime 0.024 (0.032)\tLoss 6.2109 (5.0836)\tPrec@1 73.000 (78.859)\tPrec@5 94.000 (94.296)\n",
            "Test: [80/261]\tTime 0.025 (0.032)\tLoss 5.6676 (5.1078)\tPrec@1 76.000 (78.864)\tPrec@5 95.000 (94.309)\n",
            "Test: [90/261]\tTime 0.012 (0.031)\tLoss 5.5751 (5.1621)\tPrec@1 79.000 (78.681)\tPrec@5 94.000 (94.275)\n",
            "Test: [100/261]\tTime 0.021 (0.031)\tLoss 5.3851 (5.1722)\tPrec@1 81.000 (78.644)\tPrec@5 94.000 (94.297)\n",
            "Test: [110/261]\tTime 0.031 (0.030)\tLoss 5.3145 (5.1662)\tPrec@1 79.000 (78.568)\tPrec@5 93.000 (94.369)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 3.8483 (5.1689)\tPrec@1 84.000 (78.504)\tPrec@5 95.000 (94.339)\n",
            "Test: [130/261]\tTime 0.011 (0.030)\tLoss 4.5942 (5.1426)\tPrec@1 82.000 (78.618)\tPrec@5 94.000 (94.366)\n",
            "Test: [140/261]\tTime 0.061 (0.030)\tLoss 6.2115 (5.1554)\tPrec@1 74.000 (78.532)\tPrec@5 93.000 (94.390)\n",
            "Test: [150/261]\tTime 0.011 (0.030)\tLoss 4.7918 (5.1627)\tPrec@1 80.000 (78.510)\tPrec@5 95.000 (94.384)\n",
            "Test: [160/261]\tTime 0.023 (0.029)\tLoss 4.6783 (5.1817)\tPrec@1 82.000 (78.441)\tPrec@5 95.000 (94.416)\n",
            "Test: [170/261]\tTime 0.020 (0.030)\tLoss 4.1787 (5.1807)\tPrec@1 82.000 (78.404)\tPrec@5 96.000 (94.468)\n",
            "Test: [180/261]\tTime 0.017 (0.029)\tLoss 4.6381 (5.1910)\tPrec@1 80.000 (78.326)\tPrec@5 91.000 (94.403)\n",
            "Test: [190/261]\tTime 0.019 (0.029)\tLoss 4.9905 (5.1749)\tPrec@1 80.000 (78.351)\tPrec@5 94.000 (94.461)\n",
            "Test: [200/261]\tTime 0.026 (0.029)\tLoss 4.5601 (5.1675)\tPrec@1 81.000 (78.338)\tPrec@5 96.000 (94.483)\n",
            "Test: [210/261]\tTime 0.018 (0.029)\tLoss 4.2617 (5.1444)\tPrec@1 82.000 (78.436)\tPrec@5 98.000 (94.502)\n",
            "Test: [220/261]\tTime 0.020 (0.029)\tLoss 5.2228 (5.1403)\tPrec@1 78.000 (78.493)\tPrec@5 92.000 (94.493)\n",
            "Test: [230/261]\tTime 0.015 (0.029)\tLoss 6.6660 (5.1472)\tPrec@1 75.000 (78.442)\tPrec@5 92.000 (94.489)\n",
            "Test: [240/261]\tTime 0.025 (0.029)\tLoss 4.7769 (5.1497)\tPrec@1 77.000 (78.407)\tPrec@5 97.000 (94.510)\n",
            "Test: [250/261]\tTime 0.015 (0.029)\tLoss 5.5998 (5.1310)\tPrec@1 75.000 (78.470)\tPrec@5 95.000 (94.574)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.7130 (5.1404)\tPrec@1 90.625 (78.473)\tPrec@5 96.875 (94.557)\n",
            "val Results: Prec@1 78.473 Prec@5 94.557 Loss 5.14038\n",
            "val Class Accuracy: [0.576,0.969,0.918,0.765,0.907,0.767,0.752,0.704,0.598,0.283]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [35][0/66], lr: 0.01000\tTime 0.665 (0.665)\tData 0.565 (0.565)\tLoss 0.5308 (0.5308)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [35][10/66], lr: 0.01000\tTime 0.095 (0.156)\tData 0.002 (0.057)\tLoss 0.7367 (0.6701)\tPrec@1 96.484 (96.662)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [35][20/66], lr: 0.01000\tTime 0.110 (0.133)\tData 0.005 (0.033)\tLoss 0.5332 (0.6595)\tPrec@1 96.875 (96.577)\tPrec@5 99.609 (99.944)\n",
            "Epoch: [35][30/66], lr: 0.01000\tTime 0.099 (0.123)\tData 0.000 (0.023)\tLoss 0.9229 (0.6993)\tPrec@1 95.312 (96.346)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [35][40/66], lr: 0.01000\tTime 0.112 (0.119)\tData 0.006 (0.019)\tLoss 0.9098 (0.7134)\tPrec@1 95.312 (96.237)\tPrec@5 99.609 (99.886)\n",
            "Epoch: [35][50/66], lr: 0.01000\tTime 0.114 (0.115)\tData 0.004 (0.016)\tLoss 0.7156 (0.7213)\tPrec@1 95.312 (96.216)\tPrec@5 99.609 (99.839)\n",
            "Epoch: [35][60/66], lr: 0.01000\tTime 0.060 (0.111)\tData 0.000 (0.014)\tLoss 0.7819 (0.7145)\tPrec@1 96.094 (96.228)\tPrec@5 99.609 (99.840)\n",
            "Test: [0/261]\tTime 0.312 (0.312)\tLoss 3.6210 (3.6210)\tPrec@1 85.000 (85.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.032 (0.060)\tLoss 3.9218 (3.8806)\tPrec@1 86.000 (83.000)\tPrec@5 97.000 (96.000)\n",
            "Test: [20/261]\tTime 0.028 (0.043)\tLoss 4.7885 (4.0031)\tPrec@1 79.000 (82.524)\tPrec@5 96.000 (95.857)\n",
            "Test: [30/261]\tTime 0.023 (0.037)\tLoss 3.0661 (3.7830)\tPrec@1 86.000 (83.452)\tPrec@5 98.000 (96.290)\n",
            "Test: [40/261]\tTime 0.050 (0.036)\tLoss 2.8853 (3.7010)\tPrec@1 87.000 (83.512)\tPrec@5 96.000 (96.585)\n",
            "Test: [50/261]\tTime 0.027 (0.033)\tLoss 3.6045 (3.7097)\tPrec@1 81.000 (83.431)\tPrec@5 96.000 (96.608)\n",
            "Test: [60/261]\tTime 0.011 (0.032)\tLoss 3.3732 (3.6827)\tPrec@1 85.000 (83.607)\tPrec@5 93.000 (96.541)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 3.9021 (3.6581)\tPrec@1 82.000 (83.831)\tPrec@5 97.000 (96.648)\n",
            "Test: [80/261]\tTime 0.016 (0.031)\tLoss 3.6812 (3.6888)\tPrec@1 82.000 (83.630)\tPrec@5 96.000 (96.593)\n",
            "Test: [90/261]\tTime 0.020 (0.031)\tLoss 3.9616 (3.7134)\tPrec@1 84.000 (83.615)\tPrec@5 94.000 (96.527)\n",
            "Test: [100/261]\tTime 0.020 (0.030)\tLoss 4.6274 (3.7082)\tPrec@1 79.000 (83.604)\tPrec@5 95.000 (96.545)\n",
            "Test: [110/261]\tTime 0.021 (0.030)\tLoss 3.8545 (3.6768)\tPrec@1 85.000 (83.784)\tPrec@5 97.000 (96.667)\n",
            "Test: [120/261]\tTime 0.012 (0.029)\tLoss 3.3943 (3.6813)\tPrec@1 83.000 (83.760)\tPrec@5 96.000 (96.620)\n",
            "Test: [130/261]\tTime 0.019 (0.029)\tLoss 3.6912 (3.6865)\tPrec@1 85.000 (83.786)\tPrec@5 96.000 (96.611)\n",
            "Test: [140/261]\tTime 0.033 (0.029)\tLoss 5.0543 (3.6754)\tPrec@1 76.000 (83.780)\tPrec@5 94.000 (96.631)\n",
            "Test: [150/261]\tTime 0.010 (0.029)\tLoss 3.2970 (3.6712)\tPrec@1 83.000 (83.854)\tPrec@5 98.000 (96.629)\n",
            "Test: [160/261]\tTime 0.048 (0.029)\tLoss 3.4467 (3.6729)\tPrec@1 84.000 (83.789)\tPrec@5 97.000 (96.634)\n",
            "Test: [170/261]\tTime 0.029 (0.029)\tLoss 2.6725 (3.6434)\tPrec@1 88.000 (83.889)\tPrec@5 96.000 (96.643)\n",
            "Test: [180/261]\tTime 0.025 (0.029)\tLoss 3.0097 (3.6500)\tPrec@1 87.000 (83.901)\tPrec@5 95.000 (96.602)\n",
            "Test: [190/261]\tTime 0.027 (0.028)\tLoss 3.1835 (3.6450)\tPrec@1 86.000 (83.927)\tPrec@5 97.000 (96.618)\n",
            "Test: [200/261]\tTime 0.017 (0.028)\tLoss 3.2218 (3.6429)\tPrec@1 82.000 (83.905)\tPrec@5 99.000 (96.637)\n",
            "Test: [210/261]\tTime 0.058 (0.028)\tLoss 3.4044 (3.6325)\tPrec@1 84.000 (83.953)\tPrec@5 96.000 (96.635)\n",
            "Test: [220/261]\tTime 0.020 (0.028)\tLoss 4.4746 (3.6334)\tPrec@1 79.000 (83.955)\tPrec@5 97.000 (96.652)\n",
            "Test: [230/261]\tTime 0.048 (0.028)\tLoss 4.3970 (3.6519)\tPrec@1 83.000 (83.900)\tPrec@5 95.000 (96.623)\n",
            "Test: [240/261]\tTime 0.023 (0.028)\tLoss 3.2938 (3.6493)\tPrec@1 85.000 (83.942)\tPrec@5 96.000 (96.593)\n",
            "Test: [250/261]\tTime 0.011 (0.028)\tLoss 3.2017 (3.6226)\tPrec@1 86.000 (84.052)\tPrec@5 98.000 (96.637)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 2.0841 (3.6160)\tPrec@1 87.500 (84.073)\tPrec@5 100.000 (96.662)\n",
            "val Results: Prec@1 84.073 Prec@5 96.662 Loss 3.61602\n",
            "val Class Accuracy: [0.701,0.937,0.897,0.836,0.930,0.866,0.809,0.740,0.739,0.639]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [36][0/66], lr: 0.01000\tTime 0.670 (0.670)\tData 0.574 (0.574)\tLoss 0.4103 (0.4103)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [36][10/66], lr: 0.01000\tTime 0.107 (0.167)\tData 0.001 (0.055)\tLoss 0.4465 (0.7673)\tPrec@1 98.047 (96.307)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [36][20/66], lr: 0.01000\tTime 0.118 (0.159)\tData 0.000 (0.046)\tLoss 0.9062 (0.7611)\tPrec@1 96.094 (96.150)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [36][30/66], lr: 0.01000\tTime 0.352 (0.164)\tData 0.201 (0.049)\tLoss 0.6878 (0.7417)\tPrec@1 96.094 (96.144)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [36][40/66], lr: 0.01000\tTime 0.122 (0.155)\tData 0.004 (0.042)\tLoss 0.7308 (0.7259)\tPrec@1 96.875 (96.294)\tPrec@5 99.219 (99.838)\n",
            "Epoch: [36][50/66], lr: 0.01000\tTime 0.099 (0.145)\tData 0.005 (0.034)\tLoss 0.8171 (0.7190)\tPrec@1 96.094 (96.331)\tPrec@5 99.609 (99.839)\n",
            "Epoch: [36][60/66], lr: 0.01000\tTime 0.081 (0.138)\tData 0.000 (0.030)\tLoss 0.6761 (0.6999)\tPrec@1 96.094 (96.433)\tPrec@5 100.000 (99.846)\n",
            "Test: [0/261]\tTime 0.312 (0.312)\tLoss 4.2957 (4.2957)\tPrec@1 87.000 (87.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.028 (0.060)\tLoss 5.3456 (4.5294)\tPrec@1 80.000 (81.182)\tPrec@5 96.000 (96.273)\n",
            "Test: [20/261]\tTime 0.025 (0.042)\tLoss 5.9397 (4.5357)\tPrec@1 74.000 (81.190)\tPrec@5 93.000 (95.952)\n",
            "Test: [30/261]\tTime 0.043 (0.039)\tLoss 3.3874 (4.3426)\tPrec@1 87.000 (81.968)\tPrec@5 98.000 (96.355)\n",
            "Test: [40/261]\tTime 0.037 (0.037)\tLoss 4.8109 (4.2978)\tPrec@1 82.000 (82.317)\tPrec@5 98.000 (96.463)\n",
            "Test: [50/261]\tTime 0.030 (0.035)\tLoss 2.7031 (4.1998)\tPrec@1 90.000 (82.588)\tPrec@5 99.000 (96.608)\n",
            "Test: [60/261]\tTime 0.034 (0.034)\tLoss 4.3395 (4.1902)\tPrec@1 84.000 (82.738)\tPrec@5 97.000 (96.574)\n",
            "Test: [70/261]\tTime 0.028 (0.033)\tLoss 4.9094 (4.2000)\tPrec@1 81.000 (82.549)\tPrec@5 96.000 (96.507)\n",
            "Test: [80/261]\tTime 0.034 (0.032)\tLoss 4.3378 (4.2050)\tPrec@1 82.000 (82.519)\tPrec@5 95.000 (96.432)\n",
            "Test: [90/261]\tTime 0.042 (0.032)\tLoss 4.3080 (4.2527)\tPrec@1 84.000 (82.297)\tPrec@5 95.000 (96.385)\n",
            "Test: [100/261]\tTime 0.033 (0.032)\tLoss 4.8652 (4.2394)\tPrec@1 82.000 (82.356)\tPrec@5 95.000 (96.376)\n",
            "Test: [110/261]\tTime 0.011 (0.031)\tLoss 4.6248 (4.1993)\tPrec@1 80.000 (82.559)\tPrec@5 95.000 (96.369)\n",
            "Test: [120/261]\tTime 0.064 (0.031)\tLoss 3.7094 (4.2097)\tPrec@1 82.000 (82.430)\tPrec@5 96.000 (96.314)\n",
            "Test: [130/261]\tTime 0.019 (0.030)\tLoss 4.4674 (4.1953)\tPrec@1 84.000 (82.534)\tPrec@5 96.000 (96.275)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 4.8089 (4.2004)\tPrec@1 79.000 (82.468)\tPrec@5 97.000 (96.319)\n",
            "Test: [150/261]\tTime 0.011 (0.030)\tLoss 3.4329 (4.1873)\tPrec@1 84.000 (82.510)\tPrec@5 97.000 (96.318)\n",
            "Test: [160/261]\tTime 0.040 (0.030)\tLoss 3.5493 (4.1922)\tPrec@1 85.000 (82.453)\tPrec@5 97.000 (96.354)\n",
            "Test: [170/261]\tTime 0.043 (0.030)\tLoss 3.4507 (4.1691)\tPrec@1 85.000 (82.509)\tPrec@5 96.000 (96.339)\n",
            "Test: [180/261]\tTime 0.019 (0.029)\tLoss 4.5655 (4.1775)\tPrec@1 81.000 (82.475)\tPrec@5 95.000 (96.298)\n",
            "Test: [190/261]\tTime 0.043 (0.029)\tLoss 3.3519 (4.1521)\tPrec@1 86.000 (82.597)\tPrec@5 97.000 (96.340)\n",
            "Test: [200/261]\tTime 0.015 (0.029)\tLoss 3.1945 (4.1397)\tPrec@1 86.000 (82.667)\tPrec@5 99.000 (96.348)\n",
            "Test: [210/261]\tTime 0.021 (0.029)\tLoss 4.4319 (4.1353)\tPrec@1 81.000 (82.673)\tPrec@5 98.000 (96.360)\n",
            "Test: [220/261]\tTime 0.038 (0.029)\tLoss 5.5558 (4.1319)\tPrec@1 74.000 (82.647)\tPrec@5 94.000 (96.367)\n",
            "Test: [230/261]\tTime 0.025 (0.029)\tLoss 4.9179 (4.1390)\tPrec@1 79.000 (82.584)\tPrec@5 93.000 (96.316)\n",
            "Test: [240/261]\tTime 0.011 (0.029)\tLoss 3.8874 (4.1388)\tPrec@1 82.000 (82.568)\tPrec@5 96.000 (96.290)\n",
            "Test: [250/261]\tTime 0.045 (0.029)\tLoss 2.4266 (4.1210)\tPrec@1 91.000 (82.645)\tPrec@5 100.000 (96.327)\n",
            "Test: [260/261]\tTime 0.007 (0.028)\tLoss 2.8692 (4.1153)\tPrec@1 87.500 (82.675)\tPrec@5 96.875 (96.324)\n",
            "val Results: Prec@1 82.675 Prec@5 96.324 Loss 4.11527\n",
            "val Class Accuracy: [0.503,0.964,0.930,0.885,0.849,0.821,0.678,0.748,0.656,0.805]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [37][0/66], lr: 0.01000\tTime 0.646 (0.646)\tData 0.546 (0.546)\tLoss 0.6130 (0.6130)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [37][10/66], lr: 0.01000\tTime 0.108 (0.147)\tData 0.001 (0.055)\tLoss 0.4229 (0.6459)\tPrec@1 97.656 (96.484)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [37][20/66], lr: 0.01000\tTime 0.086 (0.127)\tData 0.005 (0.032)\tLoss 0.5754 (0.6364)\tPrec@1 97.266 (96.615)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [37][30/66], lr: 0.01000\tTime 0.090 (0.121)\tData 0.003 (0.024)\tLoss 0.6713 (0.6412)\tPrec@1 95.703 (96.648)\tPrec@5 100.000 (99.912)\n",
            "Epoch: [37][40/66], lr: 0.01000\tTime 0.090 (0.115)\tData 0.007 (0.020)\tLoss 0.8640 (0.6436)\tPrec@1 95.703 (96.732)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [37][50/66], lr: 0.01000\tTime 0.111 (0.112)\tData 0.010 (0.017)\tLoss 0.6988 (0.6613)\tPrec@1 96.484 (96.599)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [37][60/66], lr: 0.01000\tTime 0.077 (0.110)\tData 0.000 (0.015)\tLoss 0.6119 (0.6617)\tPrec@1 96.875 (96.612)\tPrec@5 99.609 (99.885)\n",
            "Test: [0/261]\tTime 0.334 (0.334)\tLoss 4.8843 (4.8843)\tPrec@1 78.000 (78.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.039 (0.059)\tLoss 5.4736 (5.1960)\tPrec@1 78.000 (77.909)\tPrec@5 95.000 (95.273)\n",
            "Test: [20/261]\tTime 0.020 (0.043)\tLoss 4.9989 (5.0108)\tPrec@1 79.000 (78.857)\tPrec@5 93.000 (95.095)\n",
            "Test: [30/261]\tTime 0.025 (0.038)\tLoss 3.3355 (4.7579)\tPrec@1 85.000 (79.935)\tPrec@5 96.000 (95.194)\n",
            "Test: [40/261]\tTime 0.038 (0.036)\tLoss 3.7654 (4.6833)\tPrec@1 86.000 (80.683)\tPrec@5 95.000 (95.415)\n",
            "Test: [50/261]\tTime 0.011 (0.033)\tLoss 4.9105 (4.6390)\tPrec@1 81.000 (80.902)\tPrec@5 96.000 (95.529)\n",
            "Test: [60/261]\tTime 0.038 (0.032)\tLoss 5.3179 (4.5904)\tPrec@1 80.000 (81.033)\tPrec@5 94.000 (95.508)\n",
            "Test: [70/261]\tTime 0.046 (0.032)\tLoss 5.9366 (4.6159)\tPrec@1 74.000 (80.831)\tPrec@5 96.000 (95.606)\n",
            "Test: [80/261]\tTime 0.025 (0.031)\tLoss 4.7727 (4.6106)\tPrec@1 81.000 (80.889)\tPrec@5 93.000 (95.568)\n",
            "Test: [90/261]\tTime 0.032 (0.031)\tLoss 3.6157 (4.6223)\tPrec@1 86.000 (80.879)\tPrec@5 96.000 (95.484)\n",
            "Test: [100/261]\tTime 0.023 (0.030)\tLoss 6.2888 (4.6020)\tPrec@1 74.000 (80.970)\tPrec@5 92.000 (95.515)\n",
            "Test: [110/261]\tTime 0.019 (0.030)\tLoss 4.4841 (4.5750)\tPrec@1 84.000 (81.090)\tPrec@5 95.000 (95.486)\n",
            "Test: [120/261]\tTime 0.028 (0.030)\tLoss 3.2346 (4.5813)\tPrec@1 88.000 (81.157)\tPrec@5 97.000 (95.421)\n",
            "Test: [130/261]\tTime 0.025 (0.030)\tLoss 4.8891 (4.5613)\tPrec@1 80.000 (81.282)\tPrec@5 93.000 (95.397)\n",
            "Test: [140/261]\tTime 0.025 (0.029)\tLoss 5.5091 (4.5500)\tPrec@1 77.000 (81.333)\tPrec@5 95.000 (95.433)\n",
            "Test: [150/261]\tTime 0.036 (0.029)\tLoss 3.8401 (4.5487)\tPrec@1 83.000 (81.291)\tPrec@5 97.000 (95.450)\n",
            "Test: [160/261]\tTime 0.030 (0.029)\tLoss 4.1700 (4.5581)\tPrec@1 84.000 (81.193)\tPrec@5 96.000 (95.503)\n",
            "Test: [170/261]\tTime 0.028 (0.029)\tLoss 3.7048 (4.5402)\tPrec@1 86.000 (81.322)\tPrec@5 97.000 (95.520)\n",
            "Test: [180/261]\tTime 0.046 (0.029)\tLoss 3.3858 (4.5353)\tPrec@1 87.000 (81.359)\tPrec@5 96.000 (95.558)\n",
            "Test: [190/261]\tTime 0.036 (0.029)\tLoss 4.0471 (4.5214)\tPrec@1 81.000 (81.356)\tPrec@5 96.000 (95.592)\n",
            "Test: [200/261]\tTime 0.017 (0.029)\tLoss 4.6655 (4.5291)\tPrec@1 77.000 (81.269)\tPrec@5 99.000 (95.607)\n",
            "Test: [210/261]\tTime 0.021 (0.029)\tLoss 3.8608 (4.5080)\tPrec@1 82.000 (81.360)\tPrec@5 99.000 (95.640)\n",
            "Test: [220/261]\tTime 0.011 (0.028)\tLoss 4.8038 (4.5005)\tPrec@1 80.000 (81.371)\tPrec@5 96.000 (95.647)\n",
            "Test: [230/261]\tTime 0.030 (0.029)\tLoss 5.6709 (4.5101)\tPrec@1 78.000 (81.342)\tPrec@5 89.000 (95.606)\n",
            "Test: [240/261]\tTime 0.027 (0.029)\tLoss 4.5027 (4.5044)\tPrec@1 82.000 (81.344)\tPrec@5 97.000 (95.614)\n",
            "Test: [250/261]\tTime 0.034 (0.028)\tLoss 4.2406 (4.4862)\tPrec@1 84.000 (81.410)\tPrec@5 96.000 (95.649)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.3082 (4.4935)\tPrec@1 90.625 (81.404)\tPrec@5 96.875 (95.652)\n",
            "val Results: Prec@1 81.404 Prec@5 95.652 Loss 4.49351\n",
            "val Class Accuracy: [0.499,0.964,0.958,0.791,0.922,0.796,0.770,0.684,0.750,0.485]\n",
            "Best Prec@1: 84.277\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [38][0/66], lr: 0.01000\tTime 0.668 (0.668)\tData 0.565 (0.565)\tLoss 0.7265 (0.7265)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [38][10/66], lr: 0.01000\tTime 0.093 (0.155)\tData 0.000 (0.055)\tLoss 0.7369 (0.6839)\tPrec@1 96.484 (96.555)\tPrec@5 99.609 (99.822)\n",
            "Epoch: [38][20/66], lr: 0.01000\tTime 0.107 (0.128)\tData 0.005 (0.031)\tLoss 1.1135 (0.6790)\tPrec@1 94.922 (96.596)\tPrec@5 99.219 (99.833)\n",
            "Epoch: [38][30/66], lr: 0.01000\tTime 0.086 (0.118)\tData 0.005 (0.023)\tLoss 0.7222 (0.6880)\tPrec@1 96.875 (96.535)\tPrec@5 99.609 (99.786)\n",
            "Epoch: [38][40/66], lr: 0.01000\tTime 0.109 (0.114)\tData 0.000 (0.019)\tLoss 0.6320 (0.6629)\tPrec@1 96.875 (96.675)\tPrec@5 100.000 (99.800)\n",
            "Epoch: [38][50/66], lr: 0.01000\tTime 0.101 (0.110)\tData 0.005 (0.017)\tLoss 0.2433 (0.6682)\tPrec@1 98.828 (96.684)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [38][60/66], lr: 0.01000\tTime 0.067 (0.109)\tData 0.009 (0.015)\tLoss 0.8855 (0.6666)\tPrec@1 95.703 (96.670)\tPrec@5 99.609 (99.833)\n",
            "Test: [0/261]\tTime 0.359 (0.359)\tLoss 3.9384 (3.9384)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.027 (0.061)\tLoss 4.3198 (3.8407)\tPrec@1 82.000 (83.000)\tPrec@5 96.000 (96.909)\n",
            "Test: [20/261]\tTime 0.010 (0.043)\tLoss 4.4588 (3.8408)\tPrec@1 81.000 (83.286)\tPrec@5 94.000 (96.714)\n",
            "Test: [30/261]\tTime 0.039 (0.040)\tLoss 2.6860 (3.5749)\tPrec@1 88.000 (84.613)\tPrec@5 97.000 (96.935)\n",
            "Test: [40/261]\tTime 0.011 (0.038)\tLoss 3.1436 (3.4480)\tPrec@1 86.000 (85.073)\tPrec@5 99.000 (97.195)\n",
            "Test: [50/261]\tTime 0.026 (0.035)\tLoss 2.5177 (3.4083)\tPrec@1 90.000 (85.196)\tPrec@5 98.000 (97.196)\n",
            "Test: [60/261]\tTime 0.025 (0.034)\tLoss 2.9448 (3.4110)\tPrec@1 85.000 (85.230)\tPrec@5 99.000 (97.131)\n",
            "Test: [70/261]\tTime 0.034 (0.033)\tLoss 3.9236 (3.3958)\tPrec@1 85.000 (85.366)\tPrec@5 97.000 (97.127)\n",
            "Test: [80/261]\tTime 0.031 (0.032)\tLoss 3.2335 (3.3952)\tPrec@1 87.000 (85.370)\tPrec@5 97.000 (97.148)\n",
            "Test: [90/261]\tTime 0.041 (0.032)\tLoss 4.4655 (3.4800)\tPrec@1 80.000 (84.945)\tPrec@5 96.000 (97.099)\n",
            "Test: [100/261]\tTime 0.040 (0.031)\tLoss 4.4574 (3.4616)\tPrec@1 85.000 (85.050)\tPrec@5 97.000 (97.168)\n",
            "Test: [110/261]\tTime 0.011 (0.031)\tLoss 3.7068 (3.4575)\tPrec@1 83.000 (84.982)\tPrec@5 95.000 (97.198)\n",
            "Test: [120/261]\tTime 0.034 (0.031)\tLoss 2.6185 (3.4618)\tPrec@1 88.000 (84.992)\tPrec@5 96.000 (97.124)\n",
            "Test: [130/261]\tTime 0.011 (0.030)\tLoss 3.5462 (3.4513)\tPrec@1 85.000 (85.015)\tPrec@5 94.000 (97.107)\n",
            "Test: [140/261]\tTime 0.034 (0.030)\tLoss 4.4038 (3.4307)\tPrec@1 85.000 (85.128)\tPrec@5 95.000 (97.135)\n",
            "Test: [150/261]\tTime 0.043 (0.030)\tLoss 2.6073 (3.4252)\tPrec@1 88.000 (85.159)\tPrec@5 97.000 (97.099)\n",
            "Test: [160/261]\tTime 0.036 (0.030)\tLoss 2.4559 (3.4219)\tPrec@1 87.000 (85.099)\tPrec@5 99.000 (97.112)\n",
            "Test: [170/261]\tTime 0.028 (0.030)\tLoss 2.8697 (3.4054)\tPrec@1 86.000 (85.140)\tPrec@5 97.000 (97.099)\n",
            "Test: [180/261]\tTime 0.013 (0.030)\tLoss 3.1503 (3.4131)\tPrec@1 88.000 (85.133)\tPrec@5 98.000 (97.116)\n",
            "Test: [190/261]\tTime 0.045 (0.030)\tLoss 3.0281 (3.3984)\tPrec@1 87.000 (85.188)\tPrec@5 98.000 (97.157)\n",
            "Test: [200/261]\tTime 0.013 (0.030)\tLoss 2.3902 (3.3923)\tPrec@1 89.000 (85.229)\tPrec@5 97.000 (97.129)\n",
            "Test: [210/261]\tTime 0.021 (0.029)\tLoss 3.2908 (3.3814)\tPrec@1 86.000 (85.303)\tPrec@5 99.000 (97.133)\n",
            "Test: [220/261]\tTime 0.018 (0.030)\tLoss 4.8519 (3.3822)\tPrec@1 81.000 (85.321)\tPrec@5 95.000 (97.109)\n",
            "Test: [230/261]\tTime 0.021 (0.029)\tLoss 4.9892 (3.3861)\tPrec@1 80.000 (85.294)\tPrec@5 92.000 (97.091)\n",
            "Test: [240/261]\tTime 0.029 (0.029)\tLoss 2.7901 (3.3806)\tPrec@1 86.000 (85.328)\tPrec@5 99.000 (97.095)\n",
            "Test: [250/261]\tTime 0.035 (0.029)\tLoss 2.4188 (3.3640)\tPrec@1 89.000 (85.359)\tPrec@5 100.000 (97.147)\n",
            "Test: [260/261]\tTime 0.006 (0.029)\tLoss 2.2044 (3.3537)\tPrec@1 90.625 (85.414)\tPrec@5 96.875 (97.130)\n",
            "val Results: Prec@1 85.414 Prec@5 97.130 Loss 3.35374\n",
            "val Class Accuracy: [0.649,0.956,0.936,0.850,0.889,0.826,0.824,0.777,0.765,0.762]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [39][0/66], lr: 0.01000\tTime 0.668 (0.668)\tData 0.563 (0.563)\tLoss 0.4653 (0.4653)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [39][10/66], lr: 0.01000\tTime 0.145 (0.166)\tData 0.000 (0.057)\tLoss 0.8282 (0.5903)\tPrec@1 95.312 (96.946)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [39][20/66], lr: 0.01000\tTime 0.293 (0.161)\tData 0.175 (0.047)\tLoss 0.7155 (0.6447)\tPrec@1 95.703 (96.615)\tPrec@5 100.000 (99.795)\n",
            "Epoch: [39][30/66], lr: 0.01000\tTime 0.117 (0.159)\tData 0.000 (0.044)\tLoss 0.8083 (0.6559)\tPrec@1 95.312 (96.547)\tPrec@5 100.000 (99.798)\n",
            "Epoch: [39][40/66], lr: 0.01000\tTime 0.116 (0.148)\tData 0.054 (0.041)\tLoss 0.6522 (0.6468)\tPrec@1 96.875 (96.599)\tPrec@5 100.000 (99.790)\n",
            "Epoch: [39][50/66], lr: 0.01000\tTime 0.126 (0.139)\tData 0.049 (0.038)\tLoss 0.3396 (0.6322)\tPrec@1 98.047 (96.684)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [39][60/66], lr: 0.01000\tTime 0.138 (0.134)\tData 0.000 (0.033)\tLoss 1.0170 (0.6567)\tPrec@1 95.703 (96.619)\tPrec@5 99.609 (99.827)\n",
            "Test: [0/261]\tTime 0.357 (0.357)\tLoss 5.0127 (5.0127)\tPrec@1 80.000 (80.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.023 (0.061)\tLoss 5.5253 (5.0078)\tPrec@1 77.000 (77.727)\tPrec@5 95.000 (95.909)\n",
            "Test: [20/261]\tTime 0.041 (0.045)\tLoss 5.1039 (4.9052)\tPrec@1 78.000 (78.762)\tPrec@5 94.000 (95.381)\n",
            "Test: [30/261]\tTime 0.021 (0.040)\tLoss 2.6196 (4.6542)\tPrec@1 91.000 (80.129)\tPrec@5 96.000 (95.710)\n",
            "Test: [40/261]\tTime 0.027 (0.037)\tLoss 4.0541 (4.5769)\tPrec@1 82.000 (80.463)\tPrec@5 94.000 (95.854)\n",
            "Test: [50/261]\tTime 0.044 (0.035)\tLoss 5.6982 (4.4882)\tPrec@1 76.000 (80.824)\tPrec@5 92.000 (95.745)\n",
            "Test: [60/261]\tTime 0.014 (0.033)\tLoss 5.0697 (4.4294)\tPrec@1 81.000 (81.180)\tPrec@5 96.000 (95.820)\n",
            "Test: [70/261]\tTime 0.043 (0.032)\tLoss 5.6864 (4.4452)\tPrec@1 77.000 (81.141)\tPrec@5 95.000 (95.831)\n",
            "Test: [80/261]\tTime 0.026 (0.032)\tLoss 4.5157 (4.4370)\tPrec@1 81.000 (81.198)\tPrec@5 93.000 (95.852)\n",
            "Test: [90/261]\tTime 0.029 (0.031)\tLoss 4.2907 (4.4772)\tPrec@1 81.000 (81.044)\tPrec@5 96.000 (95.791)\n",
            "Test: [100/261]\tTime 0.021 (0.031)\tLoss 5.8845 (4.4846)\tPrec@1 76.000 (81.079)\tPrec@5 92.000 (95.802)\n",
            "Test: [110/261]\tTime 0.041 (0.030)\tLoss 4.2655 (4.4586)\tPrec@1 82.000 (81.162)\tPrec@5 95.000 (95.820)\n",
            "Test: [120/261]\tTime 0.026 (0.030)\tLoss 3.2290 (4.4540)\tPrec@1 84.000 (81.190)\tPrec@5 96.000 (95.802)\n",
            "Test: [130/261]\tTime 0.027 (0.030)\tLoss 4.4944 (4.4308)\tPrec@1 83.000 (81.328)\tPrec@5 94.000 (95.847)\n",
            "Test: [140/261]\tTime 0.022 (0.030)\tLoss 4.4170 (4.4289)\tPrec@1 81.000 (81.270)\tPrec@5 95.000 (95.865)\n",
            "Test: [150/261]\tTime 0.045 (0.029)\tLoss 3.5430 (4.4193)\tPrec@1 86.000 (81.305)\tPrec@5 95.000 (95.868)\n",
            "Test: [160/261]\tTime 0.028 (0.029)\tLoss 4.4590 (4.4307)\tPrec@1 82.000 (81.267)\tPrec@5 95.000 (95.888)\n",
            "Test: [170/261]\tTime 0.025 (0.029)\tLoss 4.0928 (4.4209)\tPrec@1 84.000 (81.357)\tPrec@5 95.000 (95.901)\n",
            "Test: [180/261]\tTime 0.045 (0.029)\tLoss 3.9186 (4.4281)\tPrec@1 84.000 (81.348)\tPrec@5 94.000 (95.884)\n",
            "Test: [190/261]\tTime 0.036 (0.029)\tLoss 3.9604 (4.4153)\tPrec@1 84.000 (81.393)\tPrec@5 94.000 (95.916)\n",
            "Test: [200/261]\tTime 0.015 (0.029)\tLoss 3.5154 (4.4032)\tPrec@1 85.000 (81.438)\tPrec@5 98.000 (95.920)\n",
            "Test: [210/261]\tTime 0.027 (0.029)\tLoss 3.5787 (4.3835)\tPrec@1 85.000 (81.526)\tPrec@5 97.000 (95.943)\n",
            "Test: [220/261]\tTime 0.020 (0.029)\tLoss 4.4335 (4.3801)\tPrec@1 81.000 (81.548)\tPrec@5 95.000 (95.896)\n",
            "Test: [230/261]\tTime 0.031 (0.029)\tLoss 5.2214 (4.3862)\tPrec@1 78.000 (81.537)\tPrec@5 93.000 (95.870)\n",
            "Test: [240/261]\tTime 0.017 (0.029)\tLoss 4.4987 (4.3968)\tPrec@1 79.000 (81.481)\tPrec@5 96.000 (95.876)\n",
            "Test: [250/261]\tTime 0.019 (0.029)\tLoss 4.1456 (4.3729)\tPrec@1 82.000 (81.598)\tPrec@5 97.000 (95.928)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.6843 (4.3880)\tPrec@1 87.500 (81.542)\tPrec@5 96.875 (95.917)\n",
            "val Results: Prec@1 81.542 Prec@5 95.917 Loss 4.38797\n",
            "val Class Accuracy: [0.594,0.943,0.971,0.764,0.928,0.801,0.583,0.800,0.764,0.543]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [40][0/66], lr: 0.01000\tTime 0.656 (0.656)\tData 0.559 (0.559)\tLoss 0.4952 (0.4952)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [40][10/66], lr: 0.01000\tTime 0.102 (0.160)\tData 0.009 (0.060)\tLoss 1.2622 (0.9052)\tPrec@1 92.969 (95.419)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [40][20/66], lr: 0.01000\tTime 0.127 (0.133)\tData 0.000 (0.033)\tLoss 0.8231 (0.8344)\tPrec@1 96.094 (95.833)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [40][30/66], lr: 0.01000\tTime 0.083 (0.124)\tData 0.005 (0.024)\tLoss 0.8043 (0.7777)\tPrec@1 95.703 (96.056)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [40][40/66], lr: 0.01000\tTime 0.113 (0.119)\tData 0.041 (0.021)\tLoss 0.5426 (0.7598)\tPrec@1 96.094 (96.113)\tPrec@5 100.000 (99.838)\n",
            "Epoch: [40][50/66], lr: 0.01000\tTime 0.119 (0.116)\tData 0.002 (0.018)\tLoss 0.5730 (0.7289)\tPrec@1 97.266 (96.278)\tPrec@5 99.609 (99.847)\n",
            "Epoch: [40][60/66], lr: 0.01000\tTime 0.060 (0.113)\tData 0.000 (0.016)\tLoss 0.9056 (0.7316)\tPrec@1 96.484 (96.286)\tPrec@5 100.000 (99.866)\n",
            "Test: [0/261]\tTime 0.350 (0.350)\tLoss 4.0823 (4.0823)\tPrec@1 84.000 (84.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.027 (0.057)\tLoss 5.0472 (4.5434)\tPrec@1 80.000 (80.000)\tPrec@5 93.000 (94.727)\n",
            "Test: [20/261]\tTime 0.025 (0.042)\tLoss 4.3790 (4.4927)\tPrec@1 83.000 (80.762)\tPrec@5 93.000 (94.476)\n",
            "Test: [30/261]\tTime 0.017 (0.037)\tLoss 3.7115 (4.3614)\tPrec@1 82.000 (81.129)\tPrec@5 95.000 (94.548)\n",
            "Test: [40/261]\tTime 0.023 (0.035)\tLoss 2.7211 (4.3055)\tPrec@1 90.000 (81.366)\tPrec@5 98.000 (94.976)\n",
            "Test: [50/261]\tTime 0.030 (0.033)\tLoss 3.9534 (4.2877)\tPrec@1 84.000 (81.412)\tPrec@5 98.000 (95.216)\n",
            "Test: [60/261]\tTime 0.027 (0.033)\tLoss 4.8828 (4.2671)\tPrec@1 79.000 (81.475)\tPrec@5 88.000 (95.131)\n",
            "Test: [70/261]\tTime 0.018 (0.032)\tLoss 5.1352 (4.2322)\tPrec@1 76.000 (81.634)\tPrec@5 95.000 (95.225)\n",
            "Test: [80/261]\tTime 0.019 (0.031)\tLoss 5.1906 (4.2350)\tPrec@1 75.000 (81.617)\tPrec@5 95.000 (95.210)\n",
            "Test: [90/261]\tTime 0.024 (0.031)\tLoss 5.2811 (4.2872)\tPrec@1 79.000 (81.418)\tPrec@5 92.000 (94.989)\n",
            "Test: [100/261]\tTime 0.046 (0.031)\tLoss 5.3845 (4.2894)\tPrec@1 75.000 (81.356)\tPrec@5 96.000 (95.000)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 4.7927 (4.2784)\tPrec@1 77.000 (81.333)\tPrec@5 94.000 (95.099)\n",
            "Test: [120/261]\tTime 0.034 (0.030)\tLoss 3.6430 (4.2857)\tPrec@1 81.000 (81.281)\tPrec@5 97.000 (95.140)\n",
            "Test: [130/261]\tTime 0.024 (0.030)\tLoss 4.5479 (4.2816)\tPrec@1 81.000 (81.305)\tPrec@5 93.000 (95.122)\n",
            "Test: [140/261]\tTime 0.030 (0.030)\tLoss 4.6491 (4.2735)\tPrec@1 79.000 (81.270)\tPrec@5 92.000 (95.128)\n",
            "Test: [150/261]\tTime 0.019 (0.029)\tLoss 4.1982 (4.2886)\tPrec@1 83.000 (81.245)\tPrec@5 94.000 (95.086)\n",
            "Test: [160/261]\tTime 0.028 (0.029)\tLoss 2.3181 (4.2824)\tPrec@1 91.000 (81.248)\tPrec@5 99.000 (95.118)\n",
            "Test: [170/261]\tTime 0.018 (0.029)\tLoss 3.4107 (4.2424)\tPrec@1 85.000 (81.415)\tPrec@5 96.000 (95.199)\n",
            "Test: [180/261]\tTime 0.042 (0.029)\tLoss 3.1123 (4.2551)\tPrec@1 86.000 (81.320)\tPrec@5 95.000 (95.215)\n",
            "Test: [190/261]\tTime 0.036 (0.029)\tLoss 3.7216 (4.2414)\tPrec@1 83.000 (81.398)\tPrec@5 96.000 (95.236)\n",
            "Test: [200/261]\tTime 0.019 (0.029)\tLoss 5.0047 (4.2575)\tPrec@1 75.000 (81.318)\tPrec@5 94.000 (95.209)\n",
            "Test: [210/261]\tTime 0.024 (0.029)\tLoss 3.5040 (4.2416)\tPrec@1 82.000 (81.374)\tPrec@5 98.000 (95.237)\n",
            "Test: [220/261]\tTime 0.035 (0.029)\tLoss 4.6358 (4.2453)\tPrec@1 80.000 (81.398)\tPrec@5 93.000 (95.204)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 5.0091 (4.2699)\tPrec@1 75.000 (81.264)\tPrec@5 96.000 (95.199)\n",
            "Test: [240/261]\tTime 0.025 (0.029)\tLoss 3.9205 (4.2654)\tPrec@1 81.000 (81.278)\tPrec@5 98.000 (95.195)\n",
            "Test: [250/261]\tTime 0.017 (0.028)\tLoss 3.2154 (4.2477)\tPrec@1 88.000 (81.378)\tPrec@5 98.000 (95.243)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.2141 (4.2458)\tPrec@1 84.375 (81.411)\tPrec@5 96.875 (95.221)\n",
            "val Results: Prec@1 81.411 Prec@5 95.221 Loss 4.24576\n",
            "val Class Accuracy: [0.693,0.943,0.902,0.891,0.902,0.676,0.866,0.408,0.820,0.678]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [41][0/66], lr: 0.01000\tTime 0.659 (0.659)\tData 0.571 (0.571)\tLoss 0.3462 (0.3462)\tPrec@1 98.047 (98.047)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [41][10/66], lr: 0.01000\tTime 0.093 (0.152)\tData 0.005 (0.061)\tLoss 0.4261 (0.5769)\tPrec@1 97.656 (97.017)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [41][20/66], lr: 0.01000\tTime 0.097 (0.127)\tData 0.003 (0.034)\tLoss 0.8233 (0.5935)\tPrec@1 96.484 (97.005)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [41][30/66], lr: 0.01000\tTime 0.091 (0.119)\tData 0.000 (0.029)\tLoss 0.6656 (0.6032)\tPrec@1 96.094 (96.900)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [41][40/66], lr: 0.01000\tTime 0.107 (0.115)\tData 0.034 (0.025)\tLoss 0.9249 (0.6397)\tPrec@1 94.531 (96.723)\tPrec@5 99.219 (99.819)\n",
            "Epoch: [41][50/66], lr: 0.01000\tTime 0.082 (0.113)\tData 0.004 (0.022)\tLoss 0.4560 (0.6546)\tPrec@1 97.656 (96.630)\tPrec@5 100.000 (99.816)\n",
            "Epoch: [41][60/66], lr: 0.01000\tTime 0.079 (0.110)\tData 0.000 (0.019)\tLoss 0.7341 (0.6531)\tPrec@1 94.922 (96.593)\tPrec@5 100.000 (99.827)\n",
            "Test: [0/261]\tTime 0.312 (0.312)\tLoss 4.4582 (4.4582)\tPrec@1 82.000 (82.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.014 (0.058)\tLoss 4.6832 (4.7606)\tPrec@1 80.000 (78.091)\tPrec@5 95.000 (96.727)\n",
            "Test: [20/261]\tTime 0.022 (0.045)\tLoss 4.7428 (4.5961)\tPrec@1 77.000 (79.238)\tPrec@5 97.000 (96.381)\n",
            "Test: [30/261]\tTime 0.035 (0.038)\tLoss 2.6282 (4.3771)\tPrec@1 87.000 (80.355)\tPrec@5 98.000 (96.710)\n",
            "Test: [40/261]\tTime 0.042 (0.036)\tLoss 3.6467 (4.3507)\tPrec@1 85.000 (80.512)\tPrec@5 95.000 (96.854)\n",
            "Test: [50/261]\tTime 0.043 (0.034)\tLoss 4.5996 (4.2797)\tPrec@1 80.000 (80.843)\tPrec@5 96.000 (96.922)\n",
            "Test: [60/261]\tTime 0.038 (0.034)\tLoss 4.3622 (4.2521)\tPrec@1 81.000 (80.984)\tPrec@5 98.000 (96.852)\n",
            "Test: [70/261]\tTime 0.027 (0.032)\tLoss 4.9545 (4.2747)\tPrec@1 79.000 (80.831)\tPrec@5 94.000 (96.817)\n",
            "Test: [80/261]\tTime 0.020 (0.031)\tLoss 3.6344 (4.2534)\tPrec@1 85.000 (81.000)\tPrec@5 95.000 (96.728)\n",
            "Test: [90/261]\tTime 0.015 (0.030)\tLoss 3.7551 (4.2806)\tPrec@1 85.000 (81.000)\tPrec@5 95.000 (96.659)\n",
            "Test: [100/261]\tTime 0.018 (0.031)\tLoss 4.8318 (4.2706)\tPrec@1 78.000 (80.980)\tPrec@5 95.000 (96.683)\n",
            "Test: [110/261]\tTime 0.037 (0.031)\tLoss 4.0900 (4.2281)\tPrec@1 83.000 (81.225)\tPrec@5 96.000 (96.703)\n",
            "Test: [120/261]\tTime 0.052 (0.030)\tLoss 3.4521 (4.2164)\tPrec@1 82.000 (81.339)\tPrec@5 95.000 (96.694)\n",
            "Test: [130/261]\tTime 0.034 (0.030)\tLoss 4.4927 (4.2126)\tPrec@1 80.000 (81.389)\tPrec@5 96.000 (96.756)\n",
            "Test: [140/261]\tTime 0.022 (0.030)\tLoss 4.5472 (4.2069)\tPrec@1 81.000 (81.447)\tPrec@5 96.000 (96.745)\n",
            "Test: [150/261]\tTime 0.029 (0.030)\tLoss 3.9147 (4.2128)\tPrec@1 78.000 (81.424)\tPrec@5 96.000 (96.762)\n",
            "Test: [160/261]\tTime 0.034 (0.029)\tLoss 2.5851 (4.2052)\tPrec@1 90.000 (81.460)\tPrec@5 97.000 (96.795)\n",
            "Test: [170/261]\tTime 0.021 (0.029)\tLoss 3.1607 (4.1929)\tPrec@1 84.000 (81.520)\tPrec@5 97.000 (96.807)\n",
            "Test: [180/261]\tTime 0.028 (0.029)\tLoss 3.9988 (4.1881)\tPrec@1 81.000 (81.530)\tPrec@5 94.000 (96.796)\n",
            "Test: [190/261]\tTime 0.024 (0.029)\tLoss 3.2861 (4.1738)\tPrec@1 84.000 (81.545)\tPrec@5 96.000 (96.848)\n",
            "Test: [200/261]\tTime 0.035 (0.029)\tLoss 3.6263 (4.1658)\tPrec@1 83.000 (81.547)\tPrec@5 97.000 (96.861)\n",
            "Test: [210/261]\tTime 0.024 (0.029)\tLoss 2.8671 (4.1488)\tPrec@1 87.000 (81.649)\tPrec@5 98.000 (96.834)\n",
            "Test: [220/261]\tTime 0.029 (0.029)\tLoss 3.8440 (4.1504)\tPrec@1 83.000 (81.629)\tPrec@5 97.000 (96.824)\n",
            "Test: [230/261]\tTime 0.030 (0.029)\tLoss 5.0637 (4.1467)\tPrec@1 75.000 (81.619)\tPrec@5 94.000 (96.810)\n",
            "Test: [240/261]\tTime 0.039 (0.029)\tLoss 4.0269 (4.1534)\tPrec@1 84.000 (81.614)\tPrec@5 97.000 (96.788)\n",
            "Test: [250/261]\tTime 0.011 (0.028)\tLoss 3.7420 (4.1318)\tPrec@1 83.000 (81.713)\tPrec@5 99.000 (96.809)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.1674 (4.1386)\tPrec@1 81.250 (81.684)\tPrec@5 100.000 (96.792)\n",
            "val Results: Prec@1 81.684 Prec@5 96.792 Loss 4.13862\n",
            "val Class Accuracy: [0.748,0.911,0.951,0.795,0.929,0.829,0.613,0.804,0.637,0.540]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [42][0/66], lr: 0.01000\tTime 0.681 (0.681)\tData 0.566 (0.566)\tLoss 0.5900 (0.5900)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [42][10/66], lr: 0.01000\tTime 0.144 (0.168)\tData 0.007 (0.058)\tLoss 0.3885 (0.3861)\tPrec@1 97.266 (97.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [42][20/66], lr: 0.01000\tTime 0.112 (0.148)\tData 0.000 (0.032)\tLoss 0.8656 (0.4950)\tPrec@1 95.312 (97.321)\tPrec@5 99.609 (99.963)\n",
            "Epoch: [42][30/66], lr: 0.01000\tTime 0.128 (0.150)\tData 0.053 (0.036)\tLoss 0.2882 (0.5422)\tPrec@1 98.438 (97.177)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [42][40/66], lr: 0.01000\tTime 0.130 (0.151)\tData 0.042 (0.041)\tLoss 0.5461 (0.5758)\tPrec@1 96.875 (96.999)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [42][50/66], lr: 0.01000\tTime 0.120 (0.142)\tData 0.000 (0.033)\tLoss 0.9871 (0.5951)\tPrec@1 95.312 (96.913)\tPrec@5 99.219 (99.900)\n",
            "Epoch: [42][60/66], lr: 0.01000\tTime 0.097 (0.136)\tData 0.000 (0.029)\tLoss 0.5273 (0.6284)\tPrec@1 96.875 (96.760)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.361 (0.361)\tLoss 3.9827 (3.9827)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.011 (0.059)\tLoss 4.8567 (4.3076)\tPrec@1 80.000 (81.182)\tPrec@5 95.000 (96.636)\n",
            "Test: [20/261]\tTime 0.027 (0.046)\tLoss 4.6604 (4.1547)\tPrec@1 80.000 (81.810)\tPrec@5 97.000 (96.381)\n",
            "Test: [30/261]\tTime 0.041 (0.039)\tLoss 1.8661 (3.8869)\tPrec@1 90.000 (83.000)\tPrec@5 99.000 (96.806)\n",
            "Test: [40/261]\tTime 0.026 (0.037)\tLoss 3.5168 (3.9095)\tPrec@1 86.000 (82.902)\tPrec@5 95.000 (96.951)\n",
            "Test: [50/261]\tTime 0.023 (0.034)\tLoss 4.3434 (3.8779)\tPrec@1 82.000 (83.137)\tPrec@5 97.000 (97.059)\n",
            "Test: [60/261]\tTime 0.044 (0.033)\tLoss 4.2437 (3.8676)\tPrec@1 81.000 (83.230)\tPrec@5 96.000 (96.951)\n",
            "Test: [70/261]\tTime 0.034 (0.033)\tLoss 4.6872 (3.8797)\tPrec@1 78.000 (83.099)\tPrec@5 96.000 (97.028)\n",
            "Test: [80/261]\tTime 0.012 (0.032)\tLoss 3.8366 (3.8487)\tPrec@1 83.000 (83.222)\tPrec@5 97.000 (97.037)\n",
            "Test: [90/261]\tTime 0.036 (0.032)\tLoss 3.7277 (3.8864)\tPrec@1 85.000 (83.110)\tPrec@5 96.000 (96.945)\n",
            "Test: [100/261]\tTime 0.029 (0.031)\tLoss 5.1007 (3.8747)\tPrec@1 78.000 (83.109)\tPrec@5 93.000 (96.931)\n",
            "Test: [110/261]\tTime 0.029 (0.031)\tLoss 4.4905 (3.8576)\tPrec@1 82.000 (83.189)\tPrec@5 96.000 (97.000)\n",
            "Test: [120/261]\tTime 0.023 (0.030)\tLoss 2.6102 (3.8500)\tPrec@1 89.000 (83.264)\tPrec@5 97.000 (96.942)\n",
            "Test: [130/261]\tTime 0.022 (0.030)\tLoss 3.9635 (3.8357)\tPrec@1 84.000 (83.382)\tPrec@5 97.000 (96.924)\n",
            "Test: [140/261]\tTime 0.031 (0.030)\tLoss 4.1114 (3.8238)\tPrec@1 82.000 (83.390)\tPrec@5 96.000 (96.922)\n",
            "Test: [150/261]\tTime 0.032 (0.030)\tLoss 3.1695 (3.8180)\tPrec@1 85.000 (83.457)\tPrec@5 97.000 (96.894)\n",
            "Test: [160/261]\tTime 0.018 (0.030)\tLoss 2.4076 (3.8205)\tPrec@1 92.000 (83.441)\tPrec@5 98.000 (96.894)\n",
            "Test: [170/261]\tTime 0.045 (0.030)\tLoss 3.3803 (3.8041)\tPrec@1 86.000 (83.532)\tPrec@5 92.000 (96.877)\n",
            "Test: [180/261]\tTime 0.047 (0.030)\tLoss 3.4026 (3.8053)\tPrec@1 84.000 (83.508)\tPrec@5 96.000 (96.873)\n",
            "Test: [190/261]\tTime 0.024 (0.029)\tLoss 3.2823 (3.8059)\tPrec@1 86.000 (83.508)\tPrec@5 97.000 (96.911)\n",
            "Test: [200/261]\tTime 0.021 (0.029)\tLoss 3.3937 (3.8036)\tPrec@1 84.000 (83.517)\tPrec@5 97.000 (96.930)\n",
            "Test: [210/261]\tTime 0.023 (0.029)\tLoss 2.5342 (3.7973)\tPrec@1 87.000 (83.540)\tPrec@5 98.000 (96.924)\n",
            "Test: [220/261]\tTime 0.027 (0.029)\tLoss 4.3203 (3.7993)\tPrec@1 81.000 (83.548)\tPrec@5 96.000 (96.896)\n",
            "Test: [230/261]\tTime 0.017 (0.029)\tLoss 4.3516 (3.8062)\tPrec@1 79.000 (83.463)\tPrec@5 94.000 (96.887)\n",
            "Test: [240/261]\tTime 0.051 (0.029)\tLoss 4.2013 (3.8058)\tPrec@1 83.000 (83.481)\tPrec@5 96.000 (96.867)\n",
            "Test: [250/261]\tTime 0.028 (0.029)\tLoss 4.4610 (3.7871)\tPrec@1 82.000 (83.558)\tPrec@5 96.000 (96.896)\n",
            "Test: [260/261]\tTime 0.007 (0.028)\tLoss 1.3910 (3.7929)\tPrec@1 93.750 (83.559)\tPrec@5 100.000 (96.873)\n",
            "val Results: Prec@1 83.559 Prec@5 96.873 Loss 3.79286\n",
            "val Class Accuracy: [0.720,0.930,0.965,0.795,0.893,0.828,0.715,0.833,0.817,0.488]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [43][0/66], lr: 0.01000\tTime 0.673 (0.673)\tData 0.576 (0.576)\tLoss 0.7707 (0.7707)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [43][10/66], lr: 0.01000\tTime 0.101 (0.158)\tData 0.005 (0.060)\tLoss 0.8070 (0.7582)\tPrec@1 96.094 (96.413)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [43][20/66], lr: 0.01000\tTime 0.093 (0.131)\tData 0.002 (0.034)\tLoss 0.4574 (0.6783)\tPrec@1 96.875 (96.708)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [43][30/66], lr: 0.01000\tTime 0.079 (0.120)\tData 0.004 (0.025)\tLoss 0.6215 (0.6682)\tPrec@1 96.875 (96.673)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [43][40/66], lr: 0.01000\tTime 0.095 (0.116)\tData 0.007 (0.021)\tLoss 0.4180 (0.6728)\tPrec@1 97.656 (96.599)\tPrec@5 99.609 (99.876)\n",
            "Epoch: [43][50/66], lr: 0.01000\tTime 0.098 (0.112)\tData 0.002 (0.019)\tLoss 0.6618 (0.6604)\tPrec@1 96.094 (96.653)\tPrec@5 100.000 (99.862)\n",
            "Epoch: [43][60/66], lr: 0.01000\tTime 0.057 (0.108)\tData 0.000 (0.016)\tLoss 0.5271 (0.6739)\tPrec@1 97.656 (96.587)\tPrec@5 100.000 (99.878)\n",
            "Test: [0/261]\tTime 0.291 (0.291)\tLoss 4.4683 (4.4683)\tPrec@1 81.000 (81.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.035 (0.053)\tLoss 4.7027 (4.8214)\tPrec@1 81.000 (78.727)\tPrec@5 97.000 (95.818)\n",
            "Test: [20/261]\tTime 0.023 (0.042)\tLoss 5.1152 (4.7923)\tPrec@1 76.000 (79.286)\tPrec@5 94.000 (95.667)\n",
            "Test: [30/261]\tTime 0.033 (0.036)\tLoss 3.1545 (4.5886)\tPrec@1 87.000 (80.323)\tPrec@5 98.000 (95.935)\n",
            "Test: [40/261]\tTime 0.018 (0.034)\tLoss 3.2809 (4.3932)\tPrec@1 87.000 (81.195)\tPrec@5 97.000 (96.268)\n",
            "Test: [50/261]\tTime 0.024 (0.032)\tLoss 3.8987 (4.3129)\tPrec@1 83.000 (81.353)\tPrec@5 97.000 (96.392)\n",
            "Test: [60/261]\tTime 0.031 (0.031)\tLoss 4.3450 (4.3074)\tPrec@1 80.000 (81.410)\tPrec@5 97.000 (96.328)\n",
            "Test: [70/261]\tTime 0.024 (0.031)\tLoss 4.1219 (4.3179)\tPrec@1 84.000 (81.380)\tPrec@5 95.000 (96.282)\n",
            "Test: [80/261]\tTime 0.041 (0.031)\tLoss 4.8297 (4.3307)\tPrec@1 75.000 (81.235)\tPrec@5 99.000 (96.272)\n",
            "Test: [90/261]\tTime 0.020 (0.030)\tLoss 4.1406 (4.3917)\tPrec@1 85.000 (81.055)\tPrec@5 96.000 (96.198)\n",
            "Test: [100/261]\tTime 0.018 (0.029)\tLoss 4.8010 (4.3909)\tPrec@1 79.000 (81.069)\tPrec@5 94.000 (96.168)\n",
            "Test: [110/261]\tTime 0.046 (0.029)\tLoss 3.9925 (4.3705)\tPrec@1 81.000 (81.153)\tPrec@5 98.000 (96.216)\n",
            "Test: [120/261]\tTime 0.019 (0.029)\tLoss 3.4048 (4.3583)\tPrec@1 85.000 (81.256)\tPrec@5 97.000 (96.207)\n",
            "Test: [130/261]\tTime 0.028 (0.029)\tLoss 4.7132 (4.3497)\tPrec@1 79.000 (81.305)\tPrec@5 94.000 (96.198)\n",
            "Test: [140/261]\tTime 0.041 (0.029)\tLoss 5.0131 (4.3438)\tPrec@1 81.000 (81.348)\tPrec@5 93.000 (96.220)\n",
            "Test: [150/261]\tTime 0.044 (0.029)\tLoss 4.0830 (4.3546)\tPrec@1 81.000 (81.331)\tPrec@5 97.000 (96.185)\n",
            "Test: [160/261]\tTime 0.021 (0.028)\tLoss 2.7196 (4.3580)\tPrec@1 91.000 (81.323)\tPrec@5 97.000 (96.199)\n",
            "Test: [170/261]\tTime 0.024 (0.028)\tLoss 3.2133 (4.3430)\tPrec@1 86.000 (81.409)\tPrec@5 95.000 (96.193)\n",
            "Test: [180/261]\tTime 0.026 (0.028)\tLoss 4.0562 (4.3487)\tPrec@1 85.000 (81.381)\tPrec@5 96.000 (96.188)\n",
            "Test: [190/261]\tTime 0.036 (0.028)\tLoss 3.5583 (4.3369)\tPrec@1 86.000 (81.450)\tPrec@5 96.000 (96.230)\n",
            "Test: [200/261]\tTime 0.020 (0.028)\tLoss 3.5940 (4.3351)\tPrec@1 84.000 (81.488)\tPrec@5 98.000 (96.214)\n",
            "Test: [210/261]\tTime 0.025 (0.028)\tLoss 3.3801 (4.3172)\tPrec@1 85.000 (81.559)\tPrec@5 99.000 (96.223)\n",
            "Test: [220/261]\tTime 0.021 (0.028)\tLoss 5.6483 (4.3190)\tPrec@1 78.000 (81.566)\tPrec@5 95.000 (96.217)\n",
            "Test: [230/261]\tTime 0.025 (0.028)\tLoss 4.5822 (4.3347)\tPrec@1 82.000 (81.506)\tPrec@5 95.000 (96.216)\n",
            "Test: [240/261]\tTime 0.024 (0.028)\tLoss 3.5320 (4.3290)\tPrec@1 86.000 (81.539)\tPrec@5 98.000 (96.203)\n",
            "Test: [250/261]\tTime 0.032 (0.028)\tLoss 3.5426 (4.3119)\tPrec@1 82.000 (81.582)\tPrec@5 99.000 (96.239)\n",
            "Test: [260/261]\tTime 0.010 (0.027)\tLoss 2.2751 (4.3073)\tPrec@1 87.500 (81.642)\tPrec@5 96.875 (96.228)\n",
            "val Results: Prec@1 81.642 Prec@5 96.228 Loss 4.30726\n",
            "val Class Accuracy: [0.618,0.946,0.843,0.825,0.869,0.938,0.791,0.755,0.511,0.695]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [44][0/66], lr: 0.01000\tTime 0.677 (0.677)\tData 0.565 (0.565)\tLoss 0.3616 (0.3616)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [44][10/66], lr: 0.01000\tTime 0.095 (0.154)\tData 0.000 (0.063)\tLoss 0.5894 (0.6621)\tPrec@1 96.875 (96.697)\tPrec@5 100.000 (99.751)\n",
            "Epoch: [44][20/66], lr: 0.01000\tTime 0.097 (0.132)\tData 0.041 (0.041)\tLoss 0.7955 (0.6413)\tPrec@1 96.875 (96.782)\tPrec@5 99.219 (99.795)\n",
            "Epoch: [44][30/66], lr: 0.01000\tTime 0.091 (0.121)\tData 0.003 (0.033)\tLoss 0.9072 (0.6599)\tPrec@1 94.531 (96.636)\tPrec@5 100.000 (99.836)\n",
            "Epoch: [44][40/66], lr: 0.01000\tTime 0.118 (0.119)\tData 0.033 (0.030)\tLoss 0.5048 (0.6770)\tPrec@1 97.266 (96.475)\tPrec@5 100.000 (99.828)\n",
            "Epoch: [44][50/66], lr: 0.01000\tTime 0.106 (0.115)\tData 0.005 (0.027)\tLoss 0.4749 (0.6663)\tPrec@1 97.656 (96.530)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [44][60/66], lr: 0.01000\tTime 0.068 (0.111)\tData 0.001 (0.023)\tLoss 1.2818 (0.6597)\tPrec@1 92.969 (96.555)\tPrec@5 100.000 (99.846)\n",
            "Test: [0/261]\tTime 0.330 (0.330)\tLoss 4.3575 (4.3575)\tPrec@1 83.000 (83.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.012 (0.061)\tLoss 5.1934 (4.4687)\tPrec@1 78.000 (80.909)\tPrec@5 96.000 (95.818)\n",
            "Test: [20/261]\tTime 0.022 (0.042)\tLoss 4.7582 (4.3369)\tPrec@1 81.000 (81.810)\tPrec@5 94.000 (95.476)\n",
            "Test: [30/261]\tTime 0.018 (0.039)\tLoss 2.6679 (4.0924)\tPrec@1 86.000 (82.806)\tPrec@5 97.000 (95.871)\n",
            "Test: [40/261]\tTime 0.027 (0.037)\tLoss 3.7272 (3.9987)\tPrec@1 86.000 (83.293)\tPrec@5 95.000 (96.073)\n",
            "Test: [50/261]\tTime 0.029 (0.034)\tLoss 4.0750 (3.9490)\tPrec@1 82.000 (83.608)\tPrec@5 96.000 (95.961)\n",
            "Test: [60/261]\tTime 0.014 (0.033)\tLoss 3.9079 (3.8869)\tPrec@1 82.000 (83.984)\tPrec@5 96.000 (96.016)\n",
            "Test: [70/261]\tTime 0.052 (0.033)\tLoss 4.3806 (3.8936)\tPrec@1 81.000 (83.803)\tPrec@5 96.000 (96.113)\n",
            "Test: [80/261]\tTime 0.031 (0.032)\tLoss 4.0079 (3.8676)\tPrec@1 83.000 (83.926)\tPrec@5 94.000 (96.062)\n",
            "Test: [90/261]\tTime 0.041 (0.031)\tLoss 4.3409 (3.9272)\tPrec@1 83.000 (83.703)\tPrec@5 94.000 (95.989)\n",
            "Test: [100/261]\tTime 0.033 (0.031)\tLoss 4.9759 (3.9068)\tPrec@1 78.000 (83.743)\tPrec@5 95.000 (96.000)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 4.3602 (3.8953)\tPrec@1 82.000 (83.793)\tPrec@5 95.000 (96.009)\n",
            "Test: [120/261]\tTime 0.017 (0.030)\tLoss 3.1703 (3.8973)\tPrec@1 83.000 (83.793)\tPrec@5 96.000 (95.992)\n",
            "Test: [130/261]\tTime 0.023 (0.029)\tLoss 3.8249 (3.8961)\tPrec@1 84.000 (83.748)\tPrec@5 94.000 (96.000)\n",
            "Test: [140/261]\tTime 0.023 (0.030)\tLoss 4.4492 (3.8902)\tPrec@1 82.000 (83.773)\tPrec@5 93.000 (96.050)\n",
            "Test: [150/261]\tTime 0.018 (0.029)\tLoss 3.4996 (3.8773)\tPrec@1 85.000 (83.868)\tPrec@5 96.000 (96.053)\n",
            "Test: [160/261]\tTime 0.035 (0.029)\tLoss 3.1661 (3.8718)\tPrec@1 88.000 (83.870)\tPrec@5 99.000 (96.075)\n",
            "Test: [170/261]\tTime 0.038 (0.029)\tLoss 3.4414 (3.8407)\tPrec@1 85.000 (83.971)\tPrec@5 97.000 (96.105)\n",
            "Test: [180/261]\tTime 0.028 (0.029)\tLoss 3.2521 (3.8337)\tPrec@1 87.000 (84.017)\tPrec@5 97.000 (96.116)\n",
            "Test: [190/261]\tTime 0.027 (0.029)\tLoss 3.2368 (3.8202)\tPrec@1 87.000 (84.052)\tPrec@5 95.000 (96.141)\n",
            "Test: [200/261]\tTime 0.027 (0.029)\tLoss 3.6339 (3.8218)\tPrec@1 82.000 (84.020)\tPrec@5 98.000 (96.129)\n",
            "Test: [210/261]\tTime 0.013 (0.028)\tLoss 3.1699 (3.8098)\tPrec@1 87.000 (84.066)\tPrec@5 98.000 (96.166)\n",
            "Test: [220/261]\tTime 0.023 (0.028)\tLoss 4.2622 (3.8133)\tPrec@1 83.000 (84.018)\tPrec@5 94.000 (96.140)\n",
            "Test: [230/261]\tTime 0.017 (0.028)\tLoss 4.3206 (3.8229)\tPrec@1 81.000 (83.957)\tPrec@5 94.000 (96.134)\n",
            "Test: [240/261]\tTime 0.014 (0.028)\tLoss 3.7627 (3.8376)\tPrec@1 85.000 (83.876)\tPrec@5 96.000 (96.133)\n",
            "Test: [250/261]\tTime 0.023 (0.028)\tLoss 4.2229 (3.8213)\tPrec@1 84.000 (83.924)\tPrec@5 97.000 (96.195)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.6344 (3.8250)\tPrec@1 93.750 (83.924)\tPrec@5 96.875 (96.155)\n",
            "val Results: Prec@1 83.924 Prec@5 96.155 Loss 3.82497\n",
            "val Class Accuracy: [0.659,0.967,0.915,0.909,0.910,0.872,0.672,0.728,0.760,0.576]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [45][0/66], lr: 0.01000\tTime 0.713 (0.713)\tData 0.627 (0.627)\tLoss 0.3724 (0.3724)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [45][10/66], lr: 0.01000\tTime 0.135 (0.182)\tData 0.000 (0.062)\tLoss 0.4698 (0.5584)\tPrec@1 97.656 (97.266)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [45][20/66], lr: 0.01000\tTime 0.238 (0.163)\tData 0.135 (0.046)\tLoss 0.6754 (0.5686)\tPrec@1 96.094 (97.173)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [45][30/66], lr: 0.01000\tTime 0.116 (0.161)\tData 0.000 (0.047)\tLoss 0.5804 (0.5972)\tPrec@1 96.875 (96.976)\tPrec@5 99.609 (99.924)\n",
            "Epoch: [45][40/66], lr: 0.01000\tTime 0.136 (0.151)\tData 0.050 (0.041)\tLoss 0.5218 (0.6069)\tPrec@1 98.047 (96.894)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [45][50/66], lr: 0.01000\tTime 0.100 (0.142)\tData 0.000 (0.035)\tLoss 0.9567 (0.6169)\tPrec@1 95.312 (96.844)\tPrec@5 99.219 (99.893)\n",
            "Epoch: [45][60/66], lr: 0.01000\tTime 0.061 (0.134)\tData 0.000 (0.031)\tLoss 0.4675 (0.6261)\tPrec@1 96.875 (96.779)\tPrec@5 100.000 (99.866)\n",
            "Test: [0/261]\tTime 0.317 (0.317)\tLoss 4.5611 (4.5611)\tPrec@1 80.000 (80.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.023 (0.058)\tLoss 5.5632 (4.7674)\tPrec@1 79.000 (80.273)\tPrec@5 95.000 (95.091)\n",
            "Test: [20/261]\tTime 0.031 (0.044)\tLoss 4.9694 (4.7092)\tPrec@1 82.000 (81.048)\tPrec@5 95.000 (94.667)\n",
            "Test: [30/261]\tTime 0.020 (0.037)\tLoss 3.4145 (4.5130)\tPrec@1 86.000 (81.645)\tPrec@5 96.000 (94.839)\n",
            "Test: [40/261]\tTime 0.080 (0.035)\tLoss 4.0987 (4.4503)\tPrec@1 84.000 (81.902)\tPrec@5 97.000 (95.341)\n",
            "Test: [50/261]\tTime 0.029 (0.035)\tLoss 3.5217 (4.4226)\tPrec@1 85.000 (82.078)\tPrec@5 98.000 (95.451)\n",
            "Test: [60/261]\tTime 0.042 (0.034)\tLoss 4.6220 (4.4299)\tPrec@1 79.000 (82.000)\tPrec@5 95.000 (95.426)\n",
            "Test: [70/261]\tTime 0.017 (0.032)\tLoss 5.0329 (4.4490)\tPrec@1 78.000 (81.817)\tPrec@5 96.000 (95.437)\n",
            "Test: [80/261]\tTime 0.019 (0.032)\tLoss 5.0943 (4.4185)\tPrec@1 78.000 (81.975)\tPrec@5 96.000 (95.519)\n",
            "Test: [90/261]\tTime 0.022 (0.031)\tLoss 5.4462 (4.4770)\tPrec@1 78.000 (81.758)\tPrec@5 95.000 (95.451)\n",
            "Test: [100/261]\tTime 0.027 (0.031)\tLoss 5.6818 (4.4736)\tPrec@1 79.000 (81.733)\tPrec@5 94.000 (95.455)\n",
            "Test: [110/261]\tTime 0.020 (0.030)\tLoss 5.2415 (4.4541)\tPrec@1 78.000 (81.847)\tPrec@5 93.000 (95.523)\n",
            "Test: [120/261]\tTime 0.037 (0.030)\tLoss 3.2729 (4.4496)\tPrec@1 86.000 (81.851)\tPrec@5 95.000 (95.479)\n",
            "Test: [130/261]\tTime 0.019 (0.030)\tLoss 4.3648 (4.4231)\tPrec@1 82.000 (81.985)\tPrec@5 95.000 (95.496)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 5.4855 (4.4140)\tPrec@1 78.000 (82.014)\tPrec@5 96.000 (95.539)\n",
            "Test: [150/261]\tTime 0.026 (0.029)\tLoss 3.1225 (4.4179)\tPrec@1 87.000 (82.060)\tPrec@5 96.000 (95.483)\n",
            "Test: [160/261]\tTime 0.025 (0.029)\tLoss 4.2776 (4.4249)\tPrec@1 83.000 (81.969)\tPrec@5 93.000 (95.503)\n",
            "Test: [170/261]\tTime 0.031 (0.029)\tLoss 3.6265 (4.4098)\tPrec@1 85.000 (82.035)\tPrec@5 95.000 (95.515)\n",
            "Test: [180/261]\tTime 0.022 (0.029)\tLoss 3.9120 (4.4006)\tPrec@1 85.000 (82.033)\tPrec@5 93.000 (95.525)\n",
            "Test: [190/261]\tTime 0.018 (0.029)\tLoss 4.2379 (4.3941)\tPrec@1 83.000 (82.026)\tPrec@5 96.000 (95.565)\n",
            "Test: [200/261]\tTime 0.034 (0.029)\tLoss 3.2737 (4.3950)\tPrec@1 84.000 (81.970)\tPrec@5 98.000 (95.567)\n",
            "Test: [210/261]\tTime 0.016 (0.029)\tLoss 4.0502 (4.3841)\tPrec@1 83.000 (81.995)\tPrec@5 100.000 (95.597)\n",
            "Test: [220/261]\tTime 0.046 (0.029)\tLoss 4.6558 (4.3749)\tPrec@1 82.000 (81.991)\tPrec@5 95.000 (95.620)\n",
            "Test: [230/261]\tTime 0.031 (0.029)\tLoss 6.1429 (4.3894)\tPrec@1 76.000 (81.931)\tPrec@5 91.000 (95.606)\n",
            "Test: [240/261]\tTime 0.043 (0.029)\tLoss 4.6276 (4.3994)\tPrec@1 82.000 (81.913)\tPrec@5 95.000 (95.573)\n",
            "Test: [250/261]\tTime 0.026 (0.029)\tLoss 4.3841 (4.3828)\tPrec@1 83.000 (81.992)\tPrec@5 95.000 (95.586)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.2671 (4.3900)\tPrec@1 93.750 (81.984)\tPrec@5 96.875 (95.559)\n",
            "val Results: Prec@1 81.984 Prec@5 95.559 Loss 4.39001\n",
            "val Class Accuracy: [0.403,0.982,0.934,0.847,0.862,0.672,0.812,0.819,0.763,0.636]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [46][0/66], lr: 0.01000\tTime 0.659 (0.659)\tData 0.575 (0.575)\tLoss 0.4977 (0.4977)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [46][10/66], lr: 0.01000\tTime 0.130 (0.155)\tData 0.005 (0.057)\tLoss 0.6262 (0.5300)\tPrec@1 96.094 (97.301)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [46][20/66], lr: 0.01000\tTime 0.091 (0.128)\tData 0.008 (0.032)\tLoss 0.3225 (0.5991)\tPrec@1 98.828 (96.875)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [46][30/66], lr: 0.01000\tTime 0.105 (0.121)\tData 0.000 (0.024)\tLoss 0.4422 (0.6086)\tPrec@1 98.047 (96.825)\tPrec@5 99.609 (99.861)\n",
            "Epoch: [46][40/66], lr: 0.01000\tTime 0.120 (0.118)\tData 0.007 (0.020)\tLoss 0.4827 (0.6080)\tPrec@1 96.484 (96.799)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [46][50/66], lr: 0.01000\tTime 0.080 (0.115)\tData 0.000 (0.016)\tLoss 0.3047 (0.6083)\tPrec@1 98.438 (96.829)\tPrec@5 99.609 (99.862)\n",
            "Epoch: [46][60/66], lr: 0.01000\tTime 0.056 (0.112)\tData 0.000 (0.015)\tLoss 0.5390 (0.6184)\tPrec@1 96.875 (96.766)\tPrec@5 100.000 (99.866)\n",
            "Test: [0/261]\tTime 0.329 (0.329)\tLoss 5.0762 (5.0762)\tPrec@1 77.000 (77.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.042 (0.058)\tLoss 5.9112 (4.9954)\tPrec@1 76.000 (79.091)\tPrec@5 96.000 (94.545)\n",
            "Test: [20/261]\tTime 0.031 (0.045)\tLoss 5.1419 (4.8508)\tPrec@1 75.000 (79.238)\tPrec@5 95.000 (94.619)\n",
            "Test: [30/261]\tTime 0.026 (0.038)\tLoss 2.7548 (4.6414)\tPrec@1 87.000 (80.097)\tPrec@5 99.000 (95.000)\n",
            "Test: [40/261]\tTime 0.024 (0.035)\tLoss 4.2375 (4.6486)\tPrec@1 83.000 (80.146)\tPrec@5 94.000 (95.171)\n",
            "Test: [50/261]\tTime 0.018 (0.034)\tLoss 5.2161 (4.6311)\tPrec@1 79.000 (80.353)\tPrec@5 96.000 (95.275)\n",
            "Test: [60/261]\tTime 0.038 (0.033)\tLoss 4.6865 (4.5908)\tPrec@1 79.000 (80.443)\tPrec@5 96.000 (95.328)\n",
            "Test: [70/261]\tTime 0.029 (0.032)\tLoss 5.1718 (4.5792)\tPrec@1 80.000 (80.577)\tPrec@5 95.000 (95.451)\n",
            "Test: [80/261]\tTime 0.021 (0.031)\tLoss 5.3542 (4.5769)\tPrec@1 76.000 (80.593)\tPrec@5 96.000 (95.494)\n",
            "Test: [90/261]\tTime 0.019 (0.031)\tLoss 4.4549 (4.6388)\tPrec@1 84.000 (80.440)\tPrec@5 96.000 (95.407)\n",
            "Test: [100/261]\tTime 0.031 (0.031)\tLoss 6.1446 (4.6313)\tPrec@1 74.000 (80.475)\tPrec@5 95.000 (95.455)\n",
            "Test: [110/261]\tTime 0.028 (0.030)\tLoss 5.0925 (4.5953)\tPrec@1 78.000 (80.640)\tPrec@5 93.000 (95.486)\n",
            "Test: [120/261]\tTime 0.035 (0.030)\tLoss 4.1575 (4.5913)\tPrec@1 83.000 (80.711)\tPrec@5 97.000 (95.496)\n",
            "Test: [130/261]\tTime 0.041 (0.030)\tLoss 4.1570 (4.5908)\tPrec@1 86.000 (80.763)\tPrec@5 93.000 (95.466)\n",
            "Test: [140/261]\tTime 0.041 (0.030)\tLoss 5.7983 (4.5825)\tPrec@1 76.000 (80.780)\tPrec@5 95.000 (95.461)\n",
            "Test: [150/261]\tTime 0.037 (0.030)\tLoss 3.3001 (4.5762)\tPrec@1 86.000 (80.861)\tPrec@5 97.000 (95.430)\n",
            "Test: [160/261]\tTime 0.026 (0.030)\tLoss 4.0882 (4.5792)\tPrec@1 86.000 (80.851)\tPrec@5 96.000 (95.472)\n",
            "Test: [170/261]\tTime 0.024 (0.030)\tLoss 3.6540 (4.5540)\tPrec@1 85.000 (80.936)\tPrec@5 97.000 (95.503)\n",
            "Test: [180/261]\tTime 0.021 (0.030)\tLoss 3.2304 (4.5538)\tPrec@1 86.000 (80.939)\tPrec@5 95.000 (95.497)\n",
            "Test: [190/261]\tTime 0.029 (0.029)\tLoss 4.3640 (4.5618)\tPrec@1 80.000 (80.911)\tPrec@5 97.000 (95.539)\n",
            "Test: [200/261]\tTime 0.034 (0.029)\tLoss 5.3773 (4.5662)\tPrec@1 76.000 (80.896)\tPrec@5 97.000 (95.562)\n",
            "Test: [210/261]\tTime 0.024 (0.029)\tLoss 4.0194 (4.5472)\tPrec@1 82.000 (80.976)\tPrec@5 99.000 (95.597)\n",
            "Test: [220/261]\tTime 0.032 (0.029)\tLoss 5.5977 (4.5504)\tPrec@1 80.000 (80.986)\tPrec@5 94.000 (95.584)\n",
            "Test: [230/261]\tTime 0.027 (0.029)\tLoss 5.0614 (4.5616)\tPrec@1 80.000 (80.909)\tPrec@5 93.000 (95.580)\n",
            "Test: [240/261]\tTime 0.037 (0.029)\tLoss 4.3151 (4.5606)\tPrec@1 81.000 (80.884)\tPrec@5 97.000 (95.556)\n",
            "Test: [250/261]\tTime 0.011 (0.029)\tLoss 4.4500 (4.5409)\tPrec@1 79.000 (80.980)\tPrec@5 96.000 (95.598)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.4379 (4.5516)\tPrec@1 90.625 (80.927)\tPrec@5 96.875 (95.571)\n",
            "val Results: Prec@1 80.927 Prec@5 95.571 Loss 4.55160\n",
            "val Class Accuracy: [0.508,0.979,0.888,0.878,0.844,0.781,0.744,0.676,0.831,0.478]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [47][0/66], lr: 0.01000\tTime 0.722 (0.722)\tData 0.607 (0.607)\tLoss 0.4082 (0.4082)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [47][10/66], lr: 0.01000\tTime 0.085 (0.155)\tData 0.005 (0.061)\tLoss 0.6728 (0.6109)\tPrec@1 96.875 (97.195)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [47][20/66], lr: 0.01000\tTime 0.072 (0.128)\tData 0.005 (0.034)\tLoss 0.5035 (0.5842)\tPrec@1 96.484 (97.117)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [47][30/66], lr: 0.01000\tTime 0.100 (0.119)\tData 0.004 (0.026)\tLoss 0.2633 (0.5698)\tPrec@1 98.828 (97.190)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [47][40/66], lr: 0.01000\tTime 0.102 (0.115)\tData 0.050 (0.023)\tLoss 0.5272 (0.5600)\tPrec@1 97.266 (97.189)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [47][50/66], lr: 0.01000\tTime 0.109 (0.112)\tData 0.007 (0.020)\tLoss 0.3516 (0.5833)\tPrec@1 98.047 (97.066)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [47][60/66], lr: 0.01000\tTime 0.078 (0.109)\tData 0.000 (0.018)\tLoss 0.6005 (0.5928)\tPrec@1 97.266 (97.003)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.354 (0.354)\tLoss 3.8668 (3.8668)\tPrec@1 83.000 (83.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.025 (0.059)\tLoss 4.3684 (3.8081)\tPrec@1 82.000 (83.091)\tPrec@5 96.000 (96.727)\n",
            "Test: [20/261]\tTime 0.021 (0.043)\tLoss 5.3647 (3.8945)\tPrec@1 78.000 (82.857)\tPrec@5 97.000 (96.714)\n",
            "Test: [30/261]\tTime 0.043 (0.038)\tLoss 3.6948 (3.7303)\tPrec@1 83.000 (83.774)\tPrec@5 97.000 (97.194)\n",
            "Test: [40/261]\tTime 0.021 (0.034)\tLoss 3.3352 (3.6676)\tPrec@1 86.000 (84.146)\tPrec@5 99.000 (97.244)\n",
            "Test: [50/261]\tTime 0.013 (0.033)\tLoss 2.6300 (3.6199)\tPrec@1 90.000 (84.294)\tPrec@5 98.000 (97.176)\n",
            "Test: [60/261]\tTime 0.031 (0.032)\tLoss 3.5295 (3.6008)\tPrec@1 87.000 (84.623)\tPrec@5 97.000 (97.082)\n",
            "Test: [70/261]\tTime 0.027 (0.032)\tLoss 4.1066 (3.6081)\tPrec@1 83.000 (84.718)\tPrec@5 95.000 (97.014)\n",
            "Test: [80/261]\tTime 0.024 (0.031)\tLoss 3.9255 (3.6012)\tPrec@1 83.000 (84.802)\tPrec@5 96.000 (97.012)\n",
            "Test: [90/261]\tTime 0.027 (0.031)\tLoss 4.1348 (3.6543)\tPrec@1 81.000 (84.538)\tPrec@5 96.000 (96.890)\n",
            "Test: [100/261]\tTime 0.018 (0.030)\tLoss 3.8454 (3.6329)\tPrec@1 84.000 (84.564)\tPrec@5 96.000 (96.931)\n",
            "Test: [110/261]\tTime 0.023 (0.030)\tLoss 4.2260 (3.6189)\tPrec@1 82.000 (84.622)\tPrec@5 95.000 (96.910)\n",
            "Test: [120/261]\tTime 0.028 (0.029)\tLoss 2.7802 (3.5990)\tPrec@1 87.000 (84.711)\tPrec@5 96.000 (96.909)\n",
            "Test: [130/261]\tTime 0.026 (0.029)\tLoss 3.3440 (3.5925)\tPrec@1 87.000 (84.779)\tPrec@5 96.000 (96.885)\n",
            "Test: [140/261]\tTime 0.021 (0.029)\tLoss 4.5967 (3.5865)\tPrec@1 81.000 (84.780)\tPrec@5 98.000 (96.929)\n",
            "Test: [150/261]\tTime 0.022 (0.029)\tLoss 3.1739 (3.5772)\tPrec@1 87.000 (84.821)\tPrec@5 97.000 (96.940)\n",
            "Test: [160/261]\tTime 0.042 (0.029)\tLoss 2.1931 (3.5862)\tPrec@1 93.000 (84.770)\tPrec@5 98.000 (96.988)\n",
            "Test: [170/261]\tTime 0.024 (0.029)\tLoss 2.9182 (3.5578)\tPrec@1 86.000 (84.860)\tPrec@5 95.000 (96.988)\n",
            "Test: [180/261]\tTime 0.031 (0.029)\tLoss 3.5861 (3.5449)\tPrec@1 83.000 (84.906)\tPrec@5 95.000 (96.967)\n",
            "Test: [190/261]\tTime 0.016 (0.029)\tLoss 3.3188 (3.5334)\tPrec@1 88.000 (84.932)\tPrec@5 97.000 (97.042)\n",
            "Test: [200/261]\tTime 0.064 (0.029)\tLoss 2.5049 (3.5291)\tPrec@1 86.000 (84.930)\tPrec@5 97.000 (97.035)\n",
            "Test: [210/261]\tTime 0.032 (0.029)\tLoss 4.2802 (3.5296)\tPrec@1 83.000 (84.957)\tPrec@5 99.000 (97.028)\n",
            "Test: [220/261]\tTime 0.010 (0.028)\tLoss 4.3908 (3.5299)\tPrec@1 81.000 (84.950)\tPrec@5 98.000 (97.041)\n",
            "Test: [230/261]\tTime 0.034 (0.028)\tLoss 4.2485 (3.5265)\tPrec@1 83.000 (85.017)\tPrec@5 94.000 (97.000)\n",
            "Test: [240/261]\tTime 0.022 (0.028)\tLoss 3.0294 (3.5270)\tPrec@1 88.000 (84.996)\tPrec@5 99.000 (97.008)\n",
            "Test: [250/261]\tTime 0.014 (0.028)\tLoss 2.3861 (3.5183)\tPrec@1 89.000 (85.024)\tPrec@5 99.000 (97.028)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.5821 (3.5181)\tPrec@1 84.375 (85.034)\tPrec@5 96.875 (97.004)\n",
            "val Results: Prec@1 85.034 Prec@5 97.004 Loss 3.51806\n",
            "val Class Accuracy: [0.602,0.967,0.890,0.896,0.892,0.783,0.773,0.876,0.670,0.850]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [48][0/66], lr: 0.01000\tTime 0.776 (0.776)\tData 0.645 (0.645)\tLoss 0.5178 (0.5178)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [48][10/66], lr: 0.01000\tTime 0.155 (0.198)\tData 0.000 (0.075)\tLoss 0.6026 (0.5303)\tPrec@1 96.875 (97.372)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [48][20/66], lr: 0.01000\tTime 0.224 (0.183)\tData 0.099 (0.068)\tLoss 0.4967 (0.6184)\tPrec@1 96.875 (96.782)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [48][30/66], lr: 0.01000\tTime 0.122 (0.171)\tData 0.003 (0.060)\tLoss 0.5512 (0.6863)\tPrec@1 96.875 (96.547)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [48][40/66], lr: 0.01000\tTime 0.111 (0.156)\tData 0.005 (0.050)\tLoss 0.6389 (0.7104)\tPrec@1 97.266 (96.465)\tPrec@5 99.219 (99.867)\n",
            "Epoch: [48][50/66], lr: 0.01000\tTime 0.110 (0.146)\tData 0.005 (0.041)\tLoss 0.9728 (0.7126)\tPrec@1 94.922 (96.377)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [48][60/66], lr: 0.01000\tTime 0.059 (0.139)\tData 0.000 (0.035)\tLoss 0.3807 (0.6864)\tPrec@1 98.438 (96.478)\tPrec@5 100.000 (99.891)\n",
            "Test: [0/261]\tTime 0.351 (0.351)\tLoss 3.5417 (3.5417)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.024 (0.059)\tLoss 4.1158 (4.0015)\tPrec@1 82.000 (82.545)\tPrec@5 95.000 (96.182)\n",
            "Test: [20/261]\tTime 0.011 (0.045)\tLoss 3.7124 (3.8319)\tPrec@1 82.000 (83.476)\tPrec@5 96.000 (96.095)\n",
            "Test: [30/261]\tTime 0.036 (0.039)\tLoss 2.6486 (3.5495)\tPrec@1 88.000 (84.774)\tPrec@5 98.000 (96.774)\n",
            "Test: [40/261]\tTime 0.031 (0.036)\tLoss 3.5742 (3.5149)\tPrec@1 87.000 (84.951)\tPrec@5 93.000 (97.024)\n",
            "Test: [50/261]\tTime 0.031 (0.034)\tLoss 3.7502 (3.5378)\tPrec@1 84.000 (84.784)\tPrec@5 97.000 (97.039)\n",
            "Test: [60/261]\tTime 0.018 (0.033)\tLoss 3.8730 (3.5251)\tPrec@1 82.000 (84.754)\tPrec@5 96.000 (97.049)\n",
            "Test: [70/261]\tTime 0.021 (0.033)\tLoss 3.5577 (3.5088)\tPrec@1 81.000 (84.845)\tPrec@5 97.000 (97.113)\n",
            "Test: [80/261]\tTime 0.042 (0.032)\tLoss 3.4232 (3.5139)\tPrec@1 86.000 (84.840)\tPrec@5 97.000 (97.074)\n",
            "Test: [90/261]\tTime 0.040 (0.031)\tLoss 4.0844 (3.5504)\tPrec@1 84.000 (84.736)\tPrec@5 94.000 (96.945)\n",
            "Test: [100/261]\tTime 0.036 (0.031)\tLoss 4.6391 (3.5419)\tPrec@1 80.000 (84.713)\tPrec@5 93.000 (96.881)\n",
            "Test: [110/261]\tTime 0.022 (0.030)\tLoss 3.6091 (3.5302)\tPrec@1 81.000 (84.667)\tPrec@5 98.000 (96.928)\n",
            "Test: [120/261]\tTime 0.042 (0.030)\tLoss 2.9622 (3.5268)\tPrec@1 88.000 (84.711)\tPrec@5 97.000 (96.950)\n",
            "Test: [130/261]\tTime 0.051 (0.030)\tLoss 3.8524 (3.5349)\tPrec@1 84.000 (84.656)\tPrec@5 95.000 (96.908)\n",
            "Test: [140/261]\tTime 0.054 (0.030)\tLoss 4.0451 (3.5017)\tPrec@1 81.000 (84.766)\tPrec@5 95.000 (96.922)\n",
            "Test: [150/261]\tTime 0.017 (0.030)\tLoss 3.5438 (3.4986)\tPrec@1 83.000 (84.788)\tPrec@5 97.000 (96.934)\n",
            "Test: [160/261]\tTime 0.025 (0.029)\tLoss 2.8012 (3.5045)\tPrec@1 90.000 (84.727)\tPrec@5 98.000 (96.950)\n",
            "Test: [170/261]\tTime 0.037 (0.029)\tLoss 2.8446 (3.4829)\tPrec@1 87.000 (84.795)\tPrec@5 96.000 (96.959)\n",
            "Test: [180/261]\tTime 0.045 (0.029)\tLoss 2.7834 (3.4871)\tPrec@1 88.000 (84.762)\tPrec@5 96.000 (96.950)\n",
            "Test: [190/261]\tTime 0.047 (0.029)\tLoss 2.9709 (3.4852)\tPrec@1 86.000 (84.775)\tPrec@5 98.000 (96.990)\n",
            "Test: [200/261]\tTime 0.013 (0.029)\tLoss 3.3127 (3.4916)\tPrec@1 86.000 (84.736)\tPrec@5 96.000 (96.995)\n",
            "Test: [210/261]\tTime 0.019 (0.029)\tLoss 2.8874 (3.4720)\tPrec@1 86.000 (84.820)\tPrec@5 97.000 (97.014)\n",
            "Test: [220/261]\tTime 0.020 (0.029)\tLoss 4.8845 (3.4845)\tPrec@1 80.000 (84.778)\tPrec@5 97.000 (97.014)\n",
            "Test: [230/261]\tTime 0.039 (0.029)\tLoss 4.0984 (3.4964)\tPrec@1 83.000 (84.753)\tPrec@5 96.000 (97.000)\n",
            "Test: [240/261]\tTime 0.025 (0.029)\tLoss 2.9941 (3.4898)\tPrec@1 86.000 (84.793)\tPrec@5 96.000 (96.971)\n",
            "Test: [250/261]\tTime 0.026 (0.029)\tLoss 3.3010 (3.4759)\tPrec@1 87.000 (84.849)\tPrec@5 97.000 (96.976)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.8487 (3.4764)\tPrec@1 90.625 (84.838)\tPrec@5 100.000 (96.973)\n",
            "val Results: Prec@1 84.838 Prec@5 96.973 Loss 3.47643\n",
            "val Class Accuracy: [0.845,0.975,0.929,0.804,0.895,0.804,0.882,0.651,0.727,0.646]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [49][0/66], lr: 0.01000\tTime 0.665 (0.665)\tData 0.574 (0.574)\tLoss 0.6711 (0.6711)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [49][10/66], lr: 0.01000\tTime 0.122 (0.160)\tData 0.000 (0.056)\tLoss 0.9217 (0.6717)\tPrec@1 94.141 (96.484)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [49][20/66], lr: 0.01000\tTime 0.103 (0.131)\tData 0.004 (0.031)\tLoss 0.4905 (0.6853)\tPrec@1 98.438 (96.522)\tPrec@5 100.000 (99.777)\n",
            "Epoch: [49][30/66], lr: 0.01000\tTime 0.107 (0.124)\tData 0.005 (0.023)\tLoss 0.4897 (0.6693)\tPrec@1 98.047 (96.623)\tPrec@5 99.609 (99.811)\n",
            "Epoch: [49][40/66], lr: 0.01000\tTime 0.098 (0.118)\tData 0.000 (0.018)\tLoss 0.6275 (0.6341)\tPrec@1 96.875 (96.808)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [49][50/66], lr: 0.01000\tTime 0.083 (0.114)\tData 0.002 (0.016)\tLoss 0.5399 (0.6386)\tPrec@1 96.484 (96.768)\tPrec@5 100.000 (99.824)\n",
            "Epoch: [49][60/66], lr: 0.01000\tTime 0.074 (0.111)\tData 0.000 (0.015)\tLoss 0.7384 (0.6461)\tPrec@1 96.094 (96.747)\tPrec@5 100.000 (99.833)\n",
            "Test: [0/261]\tTime 0.321 (0.321)\tLoss 4.0316 (4.0316)\tPrec@1 84.000 (84.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.012 (0.059)\tLoss 4.5826 (4.1820)\tPrec@1 80.000 (81.273)\tPrec@5 94.000 (96.273)\n",
            "Test: [20/261]\tTime 0.019 (0.041)\tLoss 4.4480 (4.3079)\tPrec@1 77.000 (80.810)\tPrec@5 96.000 (96.048)\n",
            "Test: [30/261]\tTime 0.019 (0.038)\tLoss 2.8628 (4.0771)\tPrec@1 88.000 (82.000)\tPrec@5 98.000 (96.387)\n",
            "Test: [40/261]\tTime 0.020 (0.035)\tLoss 3.1055 (3.9632)\tPrec@1 87.000 (82.439)\tPrec@5 98.000 (96.634)\n",
            "Test: [50/261]\tTime 0.034 (0.035)\tLoss 4.5983 (3.9350)\tPrec@1 80.000 (82.490)\tPrec@5 96.000 (96.647)\n",
            "Test: [60/261]\tTime 0.011 (0.033)\tLoss 4.0483 (3.9197)\tPrec@1 83.000 (82.689)\tPrec@5 98.000 (96.607)\n",
            "Test: [70/261]\tTime 0.020 (0.032)\tLoss 3.4569 (3.9120)\tPrec@1 85.000 (82.746)\tPrec@5 96.000 (96.606)\n",
            "Test: [80/261]\tTime 0.046 (0.031)\tLoss 3.5530 (3.9375)\tPrec@1 85.000 (82.630)\tPrec@5 97.000 (96.617)\n",
            "Test: [90/261]\tTime 0.027 (0.030)\tLoss 4.2006 (3.9910)\tPrec@1 84.000 (82.385)\tPrec@5 95.000 (96.582)\n",
            "Test: [100/261]\tTime 0.044 (0.030)\tLoss 4.6234 (3.9972)\tPrec@1 80.000 (82.287)\tPrec@5 96.000 (96.614)\n",
            "Test: [110/261]\tTime 0.028 (0.030)\tLoss 3.2750 (3.9610)\tPrec@1 87.000 (82.432)\tPrec@5 98.000 (96.667)\n",
            "Test: [120/261]\tTime 0.020 (0.030)\tLoss 3.0375 (3.9617)\tPrec@1 85.000 (82.397)\tPrec@5 96.000 (96.678)\n",
            "Test: [130/261]\tTime 0.021 (0.030)\tLoss 4.0001 (3.9560)\tPrec@1 83.000 (82.473)\tPrec@5 96.000 (96.702)\n",
            "Test: [140/261]\tTime 0.027 (0.030)\tLoss 5.1892 (3.9728)\tPrec@1 77.000 (82.383)\tPrec@5 93.000 (96.702)\n",
            "Test: [150/261]\tTime 0.029 (0.030)\tLoss 3.3011 (3.9622)\tPrec@1 84.000 (82.464)\tPrec@5 97.000 (96.735)\n",
            "Test: [160/261]\tTime 0.022 (0.029)\tLoss 2.4259 (3.9576)\tPrec@1 90.000 (82.509)\tPrec@5 98.000 (96.739)\n",
            "Test: [170/261]\tTime 0.033 (0.029)\tLoss 3.6646 (3.9381)\tPrec@1 80.000 (82.602)\tPrec@5 98.000 (96.766)\n",
            "Test: [180/261]\tTime 0.046 (0.029)\tLoss 4.7752 (3.9358)\tPrec@1 81.000 (82.663)\tPrec@5 92.000 (96.740)\n",
            "Test: [190/261]\tTime 0.031 (0.029)\tLoss 3.9725 (3.9259)\tPrec@1 82.000 (82.712)\tPrec@5 96.000 (96.791)\n",
            "Test: [200/261]\tTime 0.045 (0.029)\tLoss 2.4113 (3.9156)\tPrec@1 89.000 (82.726)\tPrec@5 98.000 (96.831)\n",
            "Test: [210/261]\tTime 0.018 (0.029)\tLoss 2.5768 (3.9030)\tPrec@1 88.000 (82.820)\tPrec@5 100.000 (96.806)\n",
            "Test: [220/261]\tTime 0.019 (0.029)\tLoss 4.3901 (3.9012)\tPrec@1 79.000 (82.824)\tPrec@5 97.000 (96.810)\n",
            "Test: [230/261]\tTime 0.026 (0.029)\tLoss 5.1764 (3.9095)\tPrec@1 79.000 (82.797)\tPrec@5 94.000 (96.784)\n",
            "Test: [240/261]\tTime 0.040 (0.029)\tLoss 4.1872 (3.9287)\tPrec@1 81.000 (82.710)\tPrec@5 96.000 (96.768)\n",
            "Test: [250/261]\tTime 0.024 (0.029)\tLoss 3.5822 (3.9111)\tPrec@1 84.000 (82.773)\tPrec@5 99.000 (96.777)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.2218 (3.9176)\tPrec@1 90.625 (82.721)\tPrec@5 96.875 (96.804)\n",
            "val Results: Prec@1 82.721 Prec@5 96.804 Loss 3.91757\n",
            "val Class Accuracy: [0.767,0.899,0.939,0.822,0.922,0.873,0.576,0.895,0.519,0.711]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [50][0/66], lr: 0.01000\tTime 0.677 (0.677)\tData 0.576 (0.576)\tLoss 0.9567 (0.9567)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [50][10/66], lr: 0.01000\tTime 0.106 (0.157)\tData 0.005 (0.059)\tLoss 0.5681 (0.7252)\tPrec@1 96.484 (96.058)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [50][20/66], lr: 0.01000\tTime 0.074 (0.130)\tData 0.006 (0.033)\tLoss 0.5912 (0.6468)\tPrec@1 97.266 (96.522)\tPrec@5 99.609 (99.851)\n",
            "Epoch: [50][30/66], lr: 0.01000\tTime 0.113 (0.122)\tData 0.000 (0.025)\tLoss 0.5454 (0.6191)\tPrec@1 96.094 (96.736)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [50][40/66], lr: 0.01000\tTime 0.110 (0.117)\tData 0.002 (0.020)\tLoss 0.4975 (0.6393)\tPrec@1 97.656 (96.646)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [50][50/66], lr: 0.01000\tTime 0.096 (0.113)\tData 0.016 (0.017)\tLoss 0.7861 (0.6431)\tPrec@1 95.703 (96.576)\tPrec@5 99.609 (99.893)\n",
            "Epoch: [50][60/66], lr: 0.01000\tTime 0.088 (0.110)\tData 0.000 (0.015)\tLoss 0.4625 (0.6397)\tPrec@1 96.484 (96.600)\tPrec@5 100.000 (99.885)\n",
            "Test: [0/261]\tTime 0.367 (0.367)\tLoss 4.1128 (4.1128)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.033 (0.062)\tLoss 4.1344 (4.0601)\tPrec@1 81.000 (81.000)\tPrec@5 96.000 (97.182)\n",
            "Test: [20/261]\tTime 0.026 (0.046)\tLoss 4.9263 (4.0596)\tPrec@1 76.000 (81.667)\tPrec@5 96.000 (97.000)\n",
            "Test: [30/261]\tTime 0.027 (0.040)\tLoss 2.8763 (3.8235)\tPrec@1 87.000 (82.903)\tPrec@5 99.000 (97.226)\n",
            "Test: [40/261]\tTime 0.019 (0.037)\tLoss 4.0367 (3.7615)\tPrec@1 84.000 (83.171)\tPrec@5 96.000 (97.293)\n",
            "Test: [50/261]\tTime 0.024 (0.036)\tLoss 4.0156 (3.7399)\tPrec@1 82.000 (83.353)\tPrec@5 97.000 (97.098)\n",
            "Test: [60/261]\tTime 0.024 (0.034)\tLoss 2.8926 (3.7072)\tPrec@1 86.000 (83.443)\tPrec@5 97.000 (97.148)\n",
            "Test: [70/261]\tTime 0.019 (0.033)\tLoss 3.0316 (3.6878)\tPrec@1 90.000 (83.535)\tPrec@5 98.000 (97.183)\n",
            "Test: [80/261]\tTime 0.055 (0.033)\tLoss 3.2350 (3.7072)\tPrec@1 89.000 (83.469)\tPrec@5 97.000 (97.123)\n",
            "Test: [90/261]\tTime 0.022 (0.032)\tLoss 3.9674 (3.7489)\tPrec@1 84.000 (83.242)\tPrec@5 95.000 (97.099)\n",
            "Test: [100/261]\tTime 0.047 (0.032)\tLoss 4.0446 (3.7292)\tPrec@1 83.000 (83.356)\tPrec@5 97.000 (97.149)\n",
            "Test: [110/261]\tTime 0.017 (0.032)\tLoss 3.5143 (3.7207)\tPrec@1 85.000 (83.396)\tPrec@5 94.000 (97.117)\n",
            "Test: [120/261]\tTime 0.031 (0.031)\tLoss 3.0743 (3.7283)\tPrec@1 86.000 (83.331)\tPrec@5 96.000 (97.116)\n",
            "Test: [130/261]\tTime 0.019 (0.031)\tLoss 4.1130 (3.7382)\tPrec@1 82.000 (83.305)\tPrec@5 96.000 (97.122)\n",
            "Test: [140/261]\tTime 0.031 (0.031)\tLoss 4.4359 (3.7213)\tPrec@1 81.000 (83.369)\tPrec@5 95.000 (97.106)\n",
            "Test: [150/261]\tTime 0.041 (0.030)\tLoss 2.6941 (3.7072)\tPrec@1 88.000 (83.430)\tPrec@5 98.000 (97.106)\n",
            "Test: [160/261]\tTime 0.029 (0.031)\tLoss 3.1595 (3.7096)\tPrec@1 87.000 (83.404)\tPrec@5 98.000 (97.099)\n",
            "Test: [170/261]\tTime 0.010 (0.030)\tLoss 2.7146 (3.6902)\tPrec@1 88.000 (83.480)\tPrec@5 96.000 (97.088)\n",
            "Test: [180/261]\tTime 0.043 (0.030)\tLoss 3.9349 (3.6881)\tPrec@1 84.000 (83.514)\tPrec@5 92.000 (97.066)\n",
            "Test: [190/261]\tTime 0.057 (0.030)\tLoss 2.7685 (3.6757)\tPrec@1 85.000 (83.539)\tPrec@5 98.000 (97.136)\n",
            "Test: [200/261]\tTime 0.037 (0.030)\tLoss 2.8507 (3.6739)\tPrec@1 88.000 (83.532)\tPrec@5 96.000 (97.109)\n",
            "Test: [210/261]\tTime 0.029 (0.030)\tLoss 2.9383 (3.6652)\tPrec@1 87.000 (83.540)\tPrec@5 95.000 (97.095)\n",
            "Test: [220/261]\tTime 0.012 (0.029)\tLoss 3.8030 (3.6722)\tPrec@1 81.000 (83.520)\tPrec@5 98.000 (97.068)\n",
            "Test: [230/261]\tTime 0.011 (0.029)\tLoss 5.2182 (3.6840)\tPrec@1 81.000 (83.481)\tPrec@5 94.000 (97.069)\n",
            "Test: [240/261]\tTime 0.042 (0.030)\tLoss 3.1363 (3.6757)\tPrec@1 86.000 (83.515)\tPrec@5 99.000 (97.029)\n",
            "Test: [250/261]\tTime 0.055 (0.030)\tLoss 3.8962 (3.6681)\tPrec@1 82.000 (83.558)\tPrec@5 97.000 (97.020)\n",
            "Test: [260/261]\tTime 0.008 (0.030)\tLoss 1.8209 (3.6770)\tPrec@1 90.625 (83.516)\tPrec@5 96.875 (96.996)\n",
            "val Results: Prec@1 83.516 Prec@5 96.996 Loss 3.67704\n",
            "val Class Accuracy: [0.786,0.939,0.899,0.761,0.917,0.767,0.839,0.829,0.675,0.665]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [51][0/66], lr: 0.01000\tTime 0.906 (0.906)\tData 0.800 (0.800)\tLoss 0.5762 (0.5762)\tPrec@1 97.656 (97.656)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [51][10/66], lr: 0.01000\tTime 0.103 (0.215)\tData 0.000 (0.102)\tLoss 0.5156 (0.6032)\tPrec@1 98.047 (96.911)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [51][20/66], lr: 0.01000\tTime 0.107 (0.173)\tData 0.029 (0.065)\tLoss 0.7023 (0.6087)\tPrec@1 96.875 (96.745)\tPrec@5 100.000 (99.851)\n",
            "Epoch: [51][30/66], lr: 0.01000\tTime 0.103 (0.149)\tData 0.004 (0.046)\tLoss 0.5118 (0.5860)\tPrec@1 96.875 (96.913)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [51][40/66], lr: 0.01000\tTime 0.104 (0.138)\tData 0.007 (0.036)\tLoss 0.6258 (0.5772)\tPrec@1 96.875 (96.989)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [51][50/66], lr: 0.01000\tTime 0.107 (0.131)\tData 0.004 (0.031)\tLoss 0.4686 (0.5785)\tPrec@1 97.266 (97.013)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [51][60/66], lr: 0.01000\tTime 0.071 (0.125)\tData 0.000 (0.027)\tLoss 0.8630 (0.5975)\tPrec@1 94.922 (96.875)\tPrec@5 100.000 (99.878)\n",
            "Test: [0/261]\tTime 0.340 (0.340)\tLoss 3.6259 (3.6259)\tPrec@1 85.000 (85.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.026 (0.057)\tLoss 6.0284 (5.1717)\tPrec@1 75.000 (77.727)\tPrec@5 93.000 (94.818)\n",
            "Test: [20/261]\tTime 0.034 (0.043)\tLoss 5.0009 (5.1544)\tPrec@1 77.000 (77.952)\tPrec@5 95.000 (94.667)\n",
            "Test: [30/261]\tTime 0.036 (0.037)\tLoss 3.8210 (4.8818)\tPrec@1 82.000 (79.032)\tPrec@5 95.000 (95.032)\n",
            "Test: [40/261]\tTime 0.035 (0.035)\tLoss 3.9179 (4.7957)\tPrec@1 82.000 (79.390)\tPrec@5 93.000 (95.146)\n",
            "Test: [50/261]\tTime 0.022 (0.033)\tLoss 4.0086 (4.7314)\tPrec@1 84.000 (79.608)\tPrec@5 98.000 (95.196)\n",
            "Test: [60/261]\tTime 0.016 (0.032)\tLoss 5.1026 (4.7334)\tPrec@1 80.000 (79.689)\tPrec@5 92.000 (95.295)\n",
            "Test: [70/261]\tTime 0.033 (0.031)\tLoss 5.3572 (4.7058)\tPrec@1 77.000 (79.873)\tPrec@5 97.000 (95.324)\n",
            "Test: [80/261]\tTime 0.015 (0.031)\tLoss 5.4612 (4.7404)\tPrec@1 77.000 (79.802)\tPrec@5 93.000 (95.160)\n",
            "Test: [90/261]\tTime 0.028 (0.030)\tLoss 5.0187 (4.7653)\tPrec@1 81.000 (79.802)\tPrec@5 93.000 (94.989)\n",
            "Test: [100/261]\tTime 0.046 (0.030)\tLoss 6.1702 (4.7629)\tPrec@1 75.000 (79.832)\tPrec@5 91.000 (95.000)\n",
            "Test: [110/261]\tTime 0.024 (0.030)\tLoss 4.4272 (4.7365)\tPrec@1 80.000 (79.883)\tPrec@5 93.000 (95.063)\n",
            "Test: [120/261]\tTime 0.018 (0.029)\tLoss 3.7515 (4.7378)\tPrec@1 85.000 (79.843)\tPrec@5 95.000 (95.017)\n",
            "Test: [130/261]\tTime 0.033 (0.029)\tLoss 5.8032 (4.7578)\tPrec@1 76.000 (79.779)\tPrec@5 92.000 (94.985)\n",
            "Test: [140/261]\tTime 0.022 (0.030)\tLoss 5.3237 (4.7362)\tPrec@1 77.000 (79.865)\tPrec@5 92.000 (95.014)\n",
            "Test: [150/261]\tTime 0.028 (0.029)\tLoss 4.5293 (4.7553)\tPrec@1 79.000 (79.821)\tPrec@5 97.000 (95.013)\n",
            "Test: [160/261]\tTime 0.045 (0.029)\tLoss 3.7446 (4.7491)\tPrec@1 86.000 (79.876)\tPrec@5 96.000 (95.025)\n",
            "Test: [170/261]\tTime 0.019 (0.029)\tLoss 4.1881 (4.7206)\tPrec@1 83.000 (80.012)\tPrec@5 93.000 (95.041)\n",
            "Test: [180/261]\tTime 0.032 (0.029)\tLoss 4.2189 (4.7279)\tPrec@1 83.000 (79.994)\tPrec@5 94.000 (95.022)\n",
            "Test: [190/261]\tTime 0.030 (0.029)\tLoss 4.0393 (4.7183)\tPrec@1 82.000 (80.005)\tPrec@5 98.000 (95.105)\n",
            "Test: [200/261]\tTime 0.023 (0.029)\tLoss 5.0702 (4.7294)\tPrec@1 76.000 (79.920)\tPrec@5 95.000 (95.124)\n",
            "Test: [210/261]\tTime 0.039 (0.029)\tLoss 4.2799 (4.7202)\tPrec@1 81.000 (79.948)\tPrec@5 96.000 (95.133)\n",
            "Test: [220/261]\tTime 0.025 (0.029)\tLoss 4.8841 (4.7174)\tPrec@1 81.000 (79.959)\tPrec@5 91.000 (95.100)\n",
            "Test: [230/261]\tTime 0.028 (0.029)\tLoss 5.4584 (4.7260)\tPrec@1 78.000 (79.909)\tPrec@5 93.000 (95.113)\n",
            "Test: [240/261]\tTime 0.024 (0.029)\tLoss 4.1202 (4.7250)\tPrec@1 81.000 (79.896)\tPrec@5 97.000 (95.129)\n",
            "Test: [250/261]\tTime 0.030 (0.029)\tLoss 5.6276 (4.7122)\tPrec@1 77.000 (79.960)\tPrec@5 96.000 (95.143)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 4.5728 (4.7152)\tPrec@1 81.250 (79.955)\tPrec@5 100.000 (95.148)\n",
            "val Results: Prec@1 79.955 Prec@5 95.148 Loss 4.71516\n",
            "val Class Accuracy: [0.708,0.988,0.907,0.720,0.753,0.860,0.817,0.411,0.817,0.594]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [52][0/66], lr: 0.01000\tTime 0.706 (0.706)\tData 0.616 (0.616)\tLoss 0.5853 (0.5853)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [52][10/66], lr: 0.01000\tTime 0.111 (0.162)\tData 0.005 (0.062)\tLoss 0.9261 (0.6482)\tPrec@1 95.312 (96.875)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [52][20/66], lr: 0.01000\tTime 0.121 (0.135)\tData 0.000 (0.034)\tLoss 0.3473 (0.6689)\tPrec@1 98.828 (96.615)\tPrec@5 100.000 (99.833)\n",
            "Epoch: [52][30/66], lr: 0.01000\tTime 0.077 (0.125)\tData 0.005 (0.025)\tLoss 0.7244 (0.6778)\tPrec@1 96.094 (96.484)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [52][40/66], lr: 0.01000\tTime 0.100 (0.119)\tData 0.002 (0.020)\tLoss 0.6191 (0.6774)\tPrec@1 97.656 (96.589)\tPrec@5 100.000 (99.848)\n",
            "Epoch: [52][50/66], lr: 0.01000\tTime 0.101 (0.114)\tData 0.004 (0.017)\tLoss 0.8629 (0.6696)\tPrec@1 95.703 (96.630)\tPrec@5 100.000 (99.839)\n",
            "Epoch: [52][60/66], lr: 0.01000\tTime 0.065 (0.111)\tData 0.000 (0.015)\tLoss 0.9844 (0.6708)\tPrec@1 94.531 (96.625)\tPrec@5 99.609 (99.833)\n",
            "Test: [0/261]\tTime 0.344 (0.344)\tLoss 4.9808 (4.9808)\tPrec@1 79.000 (79.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/261]\tTime 0.027 (0.056)\tLoss 5.5491 (5.0537)\tPrec@1 77.000 (79.273)\tPrec@5 95.000 (94.909)\n",
            "Test: [20/261]\tTime 0.022 (0.042)\tLoss 6.1241 (5.0742)\tPrec@1 76.000 (79.381)\tPrec@5 93.000 (94.810)\n",
            "Test: [30/261]\tTime 0.026 (0.037)\tLoss 4.0099 (4.9141)\tPrec@1 84.000 (79.935)\tPrec@5 97.000 (95.419)\n",
            "Test: [40/261]\tTime 0.033 (0.035)\tLoss 4.2612 (4.8390)\tPrec@1 83.000 (80.244)\tPrec@5 95.000 (95.463)\n",
            "Test: [50/261]\tTime 0.023 (0.033)\tLoss 4.5785 (4.7640)\tPrec@1 79.000 (80.451)\tPrec@5 97.000 (95.588)\n",
            "Test: [60/261]\tTime 0.030 (0.032)\tLoss 5.6071 (4.7557)\tPrec@1 76.000 (80.557)\tPrec@5 96.000 (95.639)\n",
            "Test: [70/261]\tTime 0.028 (0.030)\tLoss 5.3202 (4.7691)\tPrec@1 78.000 (80.535)\tPrec@5 92.000 (95.620)\n",
            "Test: [80/261]\tTime 0.019 (0.030)\tLoss 5.4376 (4.7877)\tPrec@1 79.000 (80.494)\tPrec@5 96.000 (95.580)\n",
            "Test: [90/261]\tTime 0.030 (0.030)\tLoss 4.6710 (4.8358)\tPrec@1 80.000 (80.319)\tPrec@5 96.000 (95.560)\n",
            "Test: [100/261]\tTime 0.023 (0.029)\tLoss 4.6598 (4.8067)\tPrec@1 80.000 (80.277)\tPrec@5 96.000 (95.564)\n",
            "Test: [110/261]\tTime 0.037 (0.029)\tLoss 4.8194 (4.7716)\tPrec@1 78.000 (80.405)\tPrec@5 94.000 (95.595)\n",
            "Test: [120/261]\tTime 0.026 (0.029)\tLoss 4.2443 (4.7739)\tPrec@1 81.000 (80.322)\tPrec@5 96.000 (95.653)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 4.6506 (4.7460)\tPrec@1 81.000 (80.405)\tPrec@5 95.000 (95.710)\n",
            "Test: [140/261]\tTime 0.020 (0.028)\tLoss 5.4733 (4.7602)\tPrec@1 76.000 (80.270)\tPrec@5 94.000 (95.745)\n",
            "Test: [150/261]\tTime 0.040 (0.029)\tLoss 3.8871 (4.7782)\tPrec@1 85.000 (80.185)\tPrec@5 96.000 (95.781)\n",
            "Test: [160/261]\tTime 0.030 (0.028)\tLoss 4.1772 (4.7845)\tPrec@1 83.000 (80.087)\tPrec@5 97.000 (95.826)\n",
            "Test: [170/261]\tTime 0.030 (0.028)\tLoss 3.9948 (4.7691)\tPrec@1 81.000 (80.117)\tPrec@5 97.000 (95.877)\n",
            "Test: [180/261]\tTime 0.035 (0.028)\tLoss 4.2046 (4.7627)\tPrec@1 82.000 (80.188)\tPrec@5 94.000 (95.873)\n",
            "Test: [190/261]\tTime 0.030 (0.028)\tLoss 5.2879 (4.7487)\tPrec@1 78.000 (80.188)\tPrec@5 97.000 (95.937)\n",
            "Test: [200/261]\tTime 0.018 (0.028)\tLoss 3.7327 (4.7500)\tPrec@1 87.000 (80.204)\tPrec@5 97.000 (95.935)\n",
            "Test: [210/261]\tTime 0.022 (0.028)\tLoss 4.3897 (4.7364)\tPrec@1 83.000 (80.280)\tPrec@5 98.000 (95.972)\n",
            "Test: [220/261]\tTime 0.028 (0.028)\tLoss 5.4695 (4.7331)\tPrec@1 80.000 (80.290)\tPrec@5 94.000 (95.964)\n",
            "Test: [230/261]\tTime 0.036 (0.028)\tLoss 6.5927 (4.7437)\tPrec@1 74.000 (80.260)\tPrec@5 93.000 (95.935)\n",
            "Test: [240/261]\tTime 0.021 (0.027)\tLoss 4.9740 (4.7512)\tPrec@1 77.000 (80.195)\tPrec@5 97.000 (95.934)\n",
            "Test: [250/261]\tTime 0.039 (0.027)\tLoss 3.6742 (4.7337)\tPrec@1 85.000 (80.239)\tPrec@5 100.000 (95.992)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 3.3950 (4.7379)\tPrec@1 81.250 (80.255)\tPrec@5 96.875 (95.974)\n",
            "val Results: Prec@1 80.255 Prec@5 95.974 Loss 4.73790\n",
            "val Class Accuracy: [0.431,0.964,0.929,0.923,0.857,0.708,0.707,0.785,0.525,0.629]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [53][0/66], lr: 0.01000\tTime 0.641 (0.641)\tData 0.551 (0.551)\tLoss 0.6612 (0.6612)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [53][10/66], lr: 0.01000\tTime 0.092 (0.154)\tData 0.000 (0.055)\tLoss 0.3132 (0.6190)\tPrec@1 99.219 (97.230)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [53][20/66], lr: 0.01000\tTime 0.091 (0.126)\tData 0.005 (0.032)\tLoss 0.2966 (0.5914)\tPrec@1 98.828 (97.154)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [53][30/66], lr: 0.01000\tTime 0.140 (0.117)\tData 0.065 (0.025)\tLoss 0.7694 (0.5842)\tPrec@1 94.922 (97.102)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [53][40/66], lr: 0.01000\tTime 0.125 (0.114)\tData 0.000 (0.022)\tLoss 0.6261 (0.5751)\tPrec@1 96.875 (97.218)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [53][50/66], lr: 0.01000\tTime 0.089 (0.111)\tData 0.005 (0.020)\tLoss 0.7166 (0.5883)\tPrec@1 96.484 (97.120)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [53][60/66], lr: 0.01000\tTime 0.070 (0.109)\tData 0.000 (0.018)\tLoss 0.5776 (0.5942)\tPrec@1 96.875 (97.041)\tPrec@5 99.609 (99.904)\n",
            "Test: [0/261]\tTime 0.354 (0.354)\tLoss 5.1658 (5.1658)\tPrec@1 78.000 (78.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.030 (0.055)\tLoss 5.8155 (5.2550)\tPrec@1 76.000 (78.000)\tPrec@5 95.000 (94.455)\n",
            "Test: [20/261]\tTime 0.019 (0.041)\tLoss 5.2080 (5.1666)\tPrec@1 76.000 (78.667)\tPrec@5 94.000 (94.571)\n",
            "Test: [30/261]\tTime 0.024 (0.036)\tLoss 4.0574 (4.9756)\tPrec@1 80.000 (79.484)\tPrec@5 98.000 (95.194)\n",
            "Test: [40/261]\tTime 0.038 (0.035)\tLoss 3.9679 (4.9787)\tPrec@1 85.000 (79.537)\tPrec@5 96.000 (95.244)\n",
            "Test: [50/261]\tTime 0.015 (0.032)\tLoss 5.2078 (4.9354)\tPrec@1 81.000 (79.784)\tPrec@5 93.000 (95.176)\n",
            "Test: [60/261]\tTime 0.025 (0.031)\tLoss 5.4074 (4.9032)\tPrec@1 79.000 (79.934)\tPrec@5 95.000 (95.131)\n",
            "Test: [70/261]\tTime 0.017 (0.031)\tLoss 5.5309 (4.8974)\tPrec@1 77.000 (79.944)\tPrec@5 94.000 (95.085)\n",
            "Test: [80/261]\tTime 0.027 (0.030)\tLoss 4.7808 (4.8745)\tPrec@1 81.000 (80.037)\tPrec@5 95.000 (95.074)\n",
            "Test: [90/261]\tTime 0.021 (0.029)\tLoss 5.2632 (4.9024)\tPrec@1 81.000 (79.945)\tPrec@5 91.000 (94.978)\n",
            "Test: [100/261]\tTime 0.052 (0.029)\tLoss 5.5458 (4.8888)\tPrec@1 77.000 (80.010)\tPrec@5 92.000 (94.960)\n",
            "Test: [110/261]\tTime 0.021 (0.029)\tLoss 4.7564 (4.8658)\tPrec@1 80.000 (80.072)\tPrec@5 94.000 (95.018)\n",
            "Test: [120/261]\tTime 0.041 (0.029)\tLoss 3.2086 (4.8632)\tPrec@1 88.000 (80.149)\tPrec@5 95.000 (95.008)\n",
            "Test: [130/261]\tTime 0.049 (0.029)\tLoss 4.5717 (4.8453)\tPrec@1 80.000 (80.260)\tPrec@5 95.000 (95.053)\n",
            "Test: [140/261]\tTime 0.017 (0.028)\tLoss 5.3962 (4.8642)\tPrec@1 78.000 (80.142)\tPrec@5 93.000 (95.085)\n",
            "Test: [150/261]\tTime 0.044 (0.028)\tLoss 4.6395 (4.8824)\tPrec@1 82.000 (80.086)\tPrec@5 97.000 (95.066)\n",
            "Test: [160/261]\tTime 0.025 (0.028)\tLoss 3.2975 (4.8762)\tPrec@1 88.000 (80.056)\tPrec@5 96.000 (95.075)\n",
            "Test: [170/261]\tTime 0.022 (0.028)\tLoss 3.5361 (4.8562)\tPrec@1 84.000 (80.158)\tPrec@5 97.000 (95.111)\n",
            "Test: [180/261]\tTime 0.026 (0.028)\tLoss 4.1046 (4.8453)\tPrec@1 85.000 (80.249)\tPrec@5 93.000 (95.061)\n",
            "Test: [190/261]\tTime 0.033 (0.028)\tLoss 3.9894 (4.8242)\tPrec@1 83.000 (80.330)\tPrec@5 93.000 (95.058)\n",
            "Test: [200/261]\tTime 0.028 (0.028)\tLoss 4.2192 (4.8210)\tPrec@1 79.000 (80.274)\tPrec@5 97.000 (95.095)\n",
            "Test: [210/261]\tTime 0.021 (0.028)\tLoss 2.6799 (4.7979)\tPrec@1 90.000 (80.393)\tPrec@5 99.000 (95.137)\n",
            "Test: [220/261]\tTime 0.031 (0.028)\tLoss 4.9304 (4.7959)\tPrec@1 80.000 (80.430)\tPrec@5 96.000 (95.140)\n",
            "Test: [230/261]\tTime 0.044 (0.028)\tLoss 6.0311 (4.7998)\tPrec@1 75.000 (80.424)\tPrec@5 89.000 (95.091)\n",
            "Test: [240/261]\tTime 0.058 (0.029)\tLoss 4.9920 (4.8090)\tPrec@1 79.000 (80.398)\tPrec@5 93.000 (95.050)\n",
            "Test: [250/261]\tTime 0.043 (0.029)\tLoss 5.3054 (4.7942)\tPrec@1 78.000 (80.450)\tPrec@5 95.000 (95.084)\n",
            "Test: [260/261]\tTime 0.009 (0.029)\tLoss 1.9048 (4.8098)\tPrec@1 90.625 (80.405)\tPrec@5 100.000 (95.052)\n",
            "val Results: Prec@1 80.405 Prec@5 95.052 Loss 4.80983\n",
            "val Class Accuracy: [0.731,0.962,0.956,0.860,0.912,0.760,0.706,0.650,0.669,0.235]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [54][0/66], lr: 0.01000\tTime 0.884 (0.884)\tData 0.772 (0.772)\tLoss 0.5338 (0.5338)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [54][10/66], lr: 0.01000\tTime 0.085 (0.207)\tData 0.000 (0.101)\tLoss 0.6702 (0.5907)\tPrec@1 96.875 (96.839)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [54][20/66], lr: 0.01000\tTime 0.095 (0.159)\tData 0.005 (0.059)\tLoss 0.6013 (0.6245)\tPrec@1 97.656 (96.838)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [54][30/66], lr: 0.01000\tTime 0.086 (0.141)\tData 0.000 (0.045)\tLoss 0.7190 (0.5913)\tPrec@1 95.703 (96.963)\tPrec@5 99.609 (99.861)\n",
            "Epoch: [54][40/66], lr: 0.01000\tTime 0.095 (0.130)\tData 0.000 (0.036)\tLoss 0.6429 (0.6009)\tPrec@1 96.875 (96.923)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [54][50/66], lr: 0.01000\tTime 0.117 (0.124)\tData 0.005 (0.030)\tLoss 0.5077 (0.6042)\tPrec@1 98.438 (96.936)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [54][60/66], lr: 0.01000\tTime 0.065 (0.118)\tData 0.000 (0.026)\tLoss 0.6148 (0.6237)\tPrec@1 96.484 (96.824)\tPrec@5 100.000 (99.846)\n",
            "Test: [0/261]\tTime 0.338 (0.338)\tLoss 3.9884 (3.9884)\tPrec@1 84.000 (84.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.026 (0.062)\tLoss 4.3507 (3.9652)\tPrec@1 82.000 (83.000)\tPrec@5 98.000 (97.091)\n",
            "Test: [20/261]\tTime 0.018 (0.044)\tLoss 4.6815 (3.9904)\tPrec@1 78.000 (82.810)\tPrec@5 96.000 (96.810)\n",
            "Test: [30/261]\tTime 0.039 (0.038)\tLoss 3.4116 (3.8205)\tPrec@1 86.000 (83.645)\tPrec@5 97.000 (97.065)\n",
            "Test: [40/261]\tTime 0.024 (0.034)\tLoss 3.1653 (3.6773)\tPrec@1 88.000 (84.268)\tPrec@5 95.000 (97.220)\n",
            "Test: [50/261]\tTime 0.039 (0.033)\tLoss 3.3312 (3.6091)\tPrec@1 84.000 (84.471)\tPrec@5 98.000 (97.196)\n",
            "Test: [60/261]\tTime 0.024 (0.031)\tLoss 3.2636 (3.6194)\tPrec@1 85.000 (84.459)\tPrec@5 97.000 (97.098)\n",
            "Test: [70/261]\tTime 0.036 (0.031)\tLoss 4.1902 (3.6362)\tPrec@1 81.000 (84.465)\tPrec@5 99.000 (97.169)\n",
            "Test: [80/261]\tTime 0.027 (0.030)\tLoss 3.9463 (3.6650)\tPrec@1 82.000 (84.296)\tPrec@5 98.000 (97.136)\n",
            "Test: [90/261]\tTime 0.027 (0.030)\tLoss 4.5837 (3.7179)\tPrec@1 83.000 (84.110)\tPrec@5 94.000 (97.055)\n",
            "Test: [100/261]\tTime 0.038 (0.029)\tLoss 3.8202 (3.7076)\tPrec@1 84.000 (84.109)\tPrec@5 94.000 (97.050)\n",
            "Test: [110/261]\tTime 0.024 (0.029)\tLoss 3.8740 (3.7011)\tPrec@1 82.000 (84.036)\tPrec@5 97.000 (97.099)\n",
            "Test: [120/261]\tTime 0.052 (0.029)\tLoss 3.1845 (3.7015)\tPrec@1 84.000 (83.950)\tPrec@5 96.000 (97.058)\n",
            "Test: [130/261]\tTime 0.017 (0.029)\tLoss 3.8944 (3.7003)\tPrec@1 82.000 (83.924)\tPrec@5 96.000 (97.046)\n",
            "Test: [140/261]\tTime 0.048 (0.028)\tLoss 4.5519 (3.6913)\tPrec@1 80.000 (83.894)\tPrec@5 96.000 (97.071)\n",
            "Test: [150/261]\tTime 0.021 (0.028)\tLoss 3.3078 (3.6943)\tPrec@1 86.000 (83.914)\tPrec@5 97.000 (97.079)\n",
            "Test: [160/261]\tTime 0.032 (0.028)\tLoss 2.8806 (3.6923)\tPrec@1 88.000 (83.876)\tPrec@5 97.000 (97.106)\n",
            "Test: [170/261]\tTime 0.029 (0.028)\tLoss 3.8372 (3.6704)\tPrec@1 81.000 (83.965)\tPrec@5 98.000 (97.158)\n",
            "Test: [180/261]\tTime 0.021 (0.028)\tLoss 3.2626 (3.6691)\tPrec@1 87.000 (83.967)\tPrec@5 96.000 (97.133)\n",
            "Test: [190/261]\tTime 0.051 (0.028)\tLoss 3.0160 (3.6492)\tPrec@1 88.000 (84.042)\tPrec@5 97.000 (97.199)\n",
            "Test: [200/261]\tTime 0.025 (0.028)\tLoss 3.5791 (3.6504)\tPrec@1 84.000 (84.005)\tPrec@5 98.000 (97.234)\n",
            "Test: [210/261]\tTime 0.032 (0.028)\tLoss 2.5923 (3.6405)\tPrec@1 87.000 (84.052)\tPrec@5 99.000 (97.209)\n",
            "Test: [220/261]\tTime 0.010 (0.028)\tLoss 4.0931 (3.6588)\tPrec@1 82.000 (83.946)\tPrec@5 99.000 (97.204)\n",
            "Test: [230/261]\tTime 0.022 (0.027)\tLoss 4.6265 (3.6690)\tPrec@1 82.000 (83.926)\tPrec@5 95.000 (97.216)\n",
            "Test: [240/261]\tTime 0.025 (0.028)\tLoss 2.9583 (3.6737)\tPrec@1 87.000 (83.934)\tPrec@5 99.000 (97.187)\n",
            "Test: [250/261]\tTime 0.026 (0.028)\tLoss 3.3876 (3.6599)\tPrec@1 84.000 (83.984)\tPrec@5 97.000 (97.195)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 1.5981 (3.6552)\tPrec@1 93.750 (84.000)\tPrec@5 100.000 (97.211)\n",
            "val Results: Prec@1 84.000 Prec@5 97.211 Loss 3.65518\n",
            "val Class Accuracy: [0.830,0.959,0.906,0.922,0.928,0.759,0.763,0.677,0.608,0.676]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [55][0/66], lr: 0.01000\tTime 0.603 (0.603)\tData 0.513 (0.513)\tLoss 0.4261 (0.4261)\tPrec@1 98.438 (98.438)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [55][10/66], lr: 0.01000\tTime 0.107 (0.150)\tData 0.002 (0.052)\tLoss 0.8833 (0.5829)\tPrec@1 94.922 (97.159)\tPrec@5 100.000 (99.822)\n",
            "Epoch: [55][20/66], lr: 0.01000\tTime 0.105 (0.124)\tData 0.003 (0.029)\tLoss 0.5987 (0.5863)\tPrec@1 96.484 (97.024)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [55][30/66], lr: 0.01000\tTime 0.104 (0.116)\tData 0.003 (0.021)\tLoss 0.9539 (0.6210)\tPrec@1 96.094 (96.862)\tPrec@5 99.609 (99.887)\n",
            "Epoch: [55][40/66], lr: 0.01000\tTime 0.100 (0.113)\tData 0.004 (0.017)\tLoss 0.4677 (0.5912)\tPrec@1 97.656 (97.046)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [55][50/66], lr: 0.01000\tTime 0.099 (0.111)\tData 0.000 (0.015)\tLoss 0.4216 (0.5944)\tPrec@1 98.438 (97.044)\tPrec@5 100.000 (99.916)\n",
            "Epoch: [55][60/66], lr: 0.01000\tTime 0.077 (0.108)\tData 0.000 (0.013)\tLoss 0.5897 (0.6049)\tPrec@1 97.656 (97.016)\tPrec@5 100.000 (99.910)\n",
            "Test: [0/261]\tTime 0.339 (0.339)\tLoss 4.2563 (4.2563)\tPrec@1 82.000 (82.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.026 (0.056)\tLoss 5.1583 (4.6852)\tPrec@1 77.000 (79.182)\tPrec@5 97.000 (96.545)\n",
            "Test: [20/261]\tTime 0.025 (0.042)\tLoss 5.6422 (4.6203)\tPrec@1 75.000 (79.810)\tPrec@5 94.000 (96.190)\n",
            "Test: [30/261]\tTime 0.029 (0.036)\tLoss 2.4441 (4.3421)\tPrec@1 90.000 (81.290)\tPrec@5 97.000 (96.452)\n",
            "Test: [40/261]\tTime 0.017 (0.034)\tLoss 4.1486 (4.3126)\tPrec@1 85.000 (81.829)\tPrec@5 95.000 (96.439)\n",
            "Test: [50/261]\tTime 0.025 (0.033)\tLoss 3.5927 (4.2157)\tPrec@1 86.000 (82.451)\tPrec@5 99.000 (96.431)\n",
            "Test: [60/261]\tTime 0.018 (0.032)\tLoss 4.9272 (4.1842)\tPrec@1 79.000 (82.607)\tPrec@5 97.000 (96.344)\n",
            "Test: [70/261]\tTime 0.048 (0.031)\tLoss 5.0486 (4.1829)\tPrec@1 79.000 (82.620)\tPrec@5 95.000 (96.366)\n",
            "Test: [80/261]\tTime 0.025 (0.030)\tLoss 4.1810 (4.1488)\tPrec@1 84.000 (82.790)\tPrec@5 97.000 (96.432)\n",
            "Test: [90/261]\tTime 0.024 (0.030)\tLoss 3.9554 (4.1966)\tPrec@1 84.000 (82.560)\tPrec@5 96.000 (96.319)\n",
            "Test: [100/261]\tTime 0.034 (0.029)\tLoss 5.6980 (4.2032)\tPrec@1 77.000 (82.584)\tPrec@5 93.000 (96.248)\n",
            "Test: [110/261]\tTime 0.026 (0.029)\tLoss 4.6428 (4.1787)\tPrec@1 80.000 (82.640)\tPrec@5 95.000 (96.198)\n",
            "Test: [120/261]\tTime 0.022 (0.029)\tLoss 2.9684 (4.1755)\tPrec@1 89.000 (82.661)\tPrec@5 97.000 (96.157)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 4.4172 (4.1579)\tPrec@1 81.000 (82.695)\tPrec@5 94.000 (96.176)\n",
            "Test: [140/261]\tTime 0.010 (0.028)\tLoss 5.2827 (4.1591)\tPrec@1 78.000 (82.638)\tPrec@5 92.000 (96.213)\n",
            "Test: [150/261]\tTime 0.042 (0.029)\tLoss 4.2804 (4.1647)\tPrec@1 80.000 (82.623)\tPrec@5 96.000 (96.245)\n",
            "Test: [160/261]\tTime 0.036 (0.029)\tLoss 2.5237 (4.1626)\tPrec@1 92.000 (82.609)\tPrec@5 100.000 (96.280)\n",
            "Test: [170/261]\tTime 0.011 (0.028)\tLoss 3.8990 (4.1448)\tPrec@1 82.000 (82.684)\tPrec@5 98.000 (96.345)\n",
            "Test: [180/261]\tTime 0.015 (0.028)\tLoss 2.9091 (4.1396)\tPrec@1 88.000 (82.696)\tPrec@5 96.000 (96.331)\n",
            "Test: [190/261]\tTime 0.028 (0.028)\tLoss 3.4620 (4.1299)\tPrec@1 86.000 (82.754)\tPrec@5 96.000 (96.382)\n",
            "Test: [200/261]\tTime 0.012 (0.028)\tLoss 3.5873 (4.1290)\tPrec@1 84.000 (82.776)\tPrec@5 98.000 (96.368)\n",
            "Test: [210/261]\tTime 0.010 (0.028)\tLoss 4.0450 (4.1236)\tPrec@1 81.000 (82.782)\tPrec@5 99.000 (96.389)\n",
            "Test: [220/261]\tTime 0.037 (0.028)\tLoss 4.1192 (4.1158)\tPrec@1 85.000 (82.810)\tPrec@5 96.000 (96.394)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 5.4330 (4.1239)\tPrec@1 78.000 (82.762)\tPrec@5 88.000 (96.342)\n",
            "Test: [240/261]\tTime 0.011 (0.028)\tLoss 3.9549 (4.1222)\tPrec@1 84.000 (82.759)\tPrec@5 96.000 (96.369)\n",
            "Test: [250/261]\tTime 0.019 (0.028)\tLoss 3.2696 (4.1025)\tPrec@1 87.000 (82.869)\tPrec@5 97.000 (96.402)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 1.6908 (4.1142)\tPrec@1 93.750 (82.860)\tPrec@5 96.875 (96.370)\n",
            "val Results: Prec@1 82.860 Prec@5 96.370 Loss 4.11422\n",
            "val Class Accuracy: [0.588,0.951,0.953,0.800,0.924,0.853,0.707,0.731,0.785,0.561]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [56][0/66], lr: 0.01000\tTime 0.494 (0.494)\tData 0.430 (0.430)\tLoss 0.4187 (0.4187)\tPrec@1 98.047 (98.047)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [56][10/66], lr: 0.01000\tTime 0.108 (0.147)\tData 0.010 (0.053)\tLoss 0.7598 (0.6500)\tPrec@1 96.875 (96.697)\tPrec@5 100.000 (99.787)\n",
            "Epoch: [56][20/66], lr: 0.01000\tTime 0.103 (0.126)\tData 0.000 (0.031)\tLoss 0.5574 (0.5961)\tPrec@1 98.438 (97.005)\tPrec@5 100.000 (99.814)\n",
            "Epoch: [56][30/66], lr: 0.01000\tTime 0.079 (0.116)\tData 0.000 (0.022)\tLoss 0.7752 (0.5719)\tPrec@1 95.312 (97.001)\tPrec@5 100.000 (99.849)\n",
            "Epoch: [56][40/66], lr: 0.01000\tTime 0.105 (0.113)\tData 0.004 (0.019)\tLoss 0.8467 (0.5752)\tPrec@1 95.312 (96.980)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [56][50/66], lr: 0.01000\tTime 0.073 (0.109)\tData 0.000 (0.016)\tLoss 0.2962 (0.5752)\tPrec@1 98.828 (96.982)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [56][60/66], lr: 0.01000\tTime 0.096 (0.108)\tData 0.000 (0.014)\tLoss 0.6646 (0.5783)\tPrec@1 96.875 (97.003)\tPrec@5 100.000 (99.878)\n",
            "Test: [0/261]\tTime 0.328 (0.328)\tLoss 4.4398 (4.4398)\tPrec@1 79.000 (79.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.030 (0.057)\tLoss 5.1237 (4.4400)\tPrec@1 80.000 (80.545)\tPrec@5 96.000 (95.273)\n",
            "Test: [20/261]\tTime 0.010 (0.042)\tLoss 5.1494 (4.4086)\tPrec@1 78.000 (80.905)\tPrec@5 95.000 (95.524)\n",
            "Test: [30/261]\tTime 0.033 (0.037)\tLoss 2.8469 (4.2231)\tPrec@1 86.000 (81.903)\tPrec@5 98.000 (95.968)\n",
            "Test: [40/261]\tTime 0.051 (0.035)\tLoss 3.1073 (4.0427)\tPrec@1 87.000 (82.610)\tPrec@5 95.000 (96.024)\n",
            "Test: [50/261]\tTime 0.012 (0.033)\tLoss 3.6599 (3.9656)\tPrec@1 87.000 (83.118)\tPrec@5 98.000 (96.176)\n",
            "Test: [60/261]\tTime 0.025 (0.032)\tLoss 4.7128 (4.0016)\tPrec@1 81.000 (83.049)\tPrec@5 94.000 (95.984)\n",
            "Test: [70/261]\tTime 0.029 (0.032)\tLoss 3.8039 (4.0307)\tPrec@1 86.000 (82.831)\tPrec@5 94.000 (95.915)\n",
            "Test: [80/261]\tTime 0.027 (0.031)\tLoss 3.6488 (4.0041)\tPrec@1 87.000 (82.914)\tPrec@5 96.000 (95.889)\n",
            "Test: [90/261]\tTime 0.011 (0.030)\tLoss 4.0601 (4.0442)\tPrec@1 83.000 (82.758)\tPrec@5 96.000 (95.846)\n",
            "Test: [100/261]\tTime 0.032 (0.030)\tLoss 4.5903 (4.0272)\tPrec@1 80.000 (82.782)\tPrec@5 93.000 (95.881)\n",
            "Test: [110/261]\tTime 0.047 (0.030)\tLoss 4.3851 (4.0155)\tPrec@1 82.000 (82.784)\tPrec@5 94.000 (95.919)\n",
            "Test: [120/261]\tTime 0.025 (0.030)\tLoss 3.4225 (4.0215)\tPrec@1 84.000 (82.752)\tPrec@5 96.000 (95.893)\n",
            "Test: [130/261]\tTime 0.013 (0.030)\tLoss 3.7022 (4.0213)\tPrec@1 85.000 (82.771)\tPrec@5 95.000 (95.924)\n",
            "Test: [140/261]\tTime 0.017 (0.030)\tLoss 5.5870 (4.0394)\tPrec@1 76.000 (82.674)\tPrec@5 93.000 (95.922)\n",
            "Test: [150/261]\tTime 0.010 (0.029)\tLoss 2.9247 (4.0346)\tPrec@1 89.000 (82.728)\tPrec@5 97.000 (95.927)\n",
            "Test: [160/261]\tTime 0.030 (0.029)\tLoss 2.6468 (4.0335)\tPrec@1 89.000 (82.714)\tPrec@5 98.000 (95.944)\n",
            "Test: [170/261]\tTime 0.027 (0.029)\tLoss 3.5308 (4.0143)\tPrec@1 83.000 (82.754)\tPrec@5 95.000 (95.982)\n",
            "Test: [180/261]\tTime 0.043 (0.029)\tLoss 3.7010 (4.0194)\tPrec@1 84.000 (82.707)\tPrec@5 94.000 (95.983)\n",
            "Test: [190/261]\tTime 0.035 (0.029)\tLoss 4.1440 (4.0223)\tPrec@1 84.000 (82.691)\tPrec@5 95.000 (95.963)\n",
            "Test: [200/261]\tTime 0.011 (0.029)\tLoss 2.4860 (4.0169)\tPrec@1 88.000 (82.667)\tPrec@5 99.000 (95.990)\n",
            "Test: [210/261]\tTime 0.028 (0.028)\tLoss 3.8503 (4.0091)\tPrec@1 82.000 (82.682)\tPrec@5 96.000 (95.948)\n",
            "Test: [220/261]\tTime 0.029 (0.028)\tLoss 4.6846 (4.0019)\tPrec@1 80.000 (82.661)\tPrec@5 95.000 (95.968)\n",
            "Test: [230/261]\tTime 0.042 (0.028)\tLoss 5.1287 (4.0160)\tPrec@1 80.000 (82.606)\tPrec@5 91.000 (95.939)\n",
            "Test: [240/261]\tTime 0.028 (0.028)\tLoss 3.6162 (4.0248)\tPrec@1 84.000 (82.552)\tPrec@5 95.000 (95.909)\n",
            "Test: [250/261]\tTime 0.043 (0.028)\tLoss 3.0089 (3.9986)\tPrec@1 89.000 (82.677)\tPrec@5 98.000 (95.984)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.2555 (3.9994)\tPrec@1 90.625 (82.667)\tPrec@5 96.875 (95.978)\n",
            "val Results: Prec@1 82.667 Prec@5 95.978 Loss 3.99939\n",
            "val Class Accuracy: [0.596,0.962,0.853,0.867,0.847,0.878,0.703,0.883,0.671,0.639]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [57][0/66], lr: 0.01000\tTime 0.851 (0.851)\tData 0.722 (0.722)\tLoss 0.2953 (0.2953)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [57][10/66], lr: 0.01000\tTime 0.119 (0.201)\tData 0.010 (0.098)\tLoss 0.4797 (0.4188)\tPrec@1 98.047 (97.905)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [57][20/66], lr: 0.01000\tTime 0.166 (0.180)\tData 0.108 (0.079)\tLoss 0.4724 (0.5212)\tPrec@1 98.047 (97.433)\tPrec@5 99.609 (99.907)\n",
            "Epoch: [57][30/66], lr: 0.01000\tTime 0.094 (0.160)\tData 0.005 (0.061)\tLoss 0.4903 (0.5390)\tPrec@1 96.875 (97.291)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [57][40/66], lr: 0.01000\tTime 0.114 (0.146)\tData 0.015 (0.050)\tLoss 0.4115 (0.5715)\tPrec@1 97.266 (97.075)\tPrec@5 100.000 (99.867)\n",
            "Epoch: [57][50/66], lr: 0.01000\tTime 0.084 (0.138)\tData 0.005 (0.043)\tLoss 0.4068 (0.5700)\tPrec@1 97.656 (97.112)\tPrec@5 99.609 (99.854)\n",
            "Epoch: [57][60/66], lr: 0.01000\tTime 0.075 (0.131)\tData 0.000 (0.037)\tLoss 0.4997 (0.5767)\tPrec@1 97.656 (97.074)\tPrec@5 100.000 (99.866)\n",
            "Test: [0/261]\tTime 0.331 (0.331)\tLoss 4.1493 (4.1493)\tPrec@1 85.000 (85.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.026 (0.056)\tLoss 4.9244 (4.4074)\tPrec@1 78.000 (80.636)\tPrec@5 96.000 (95.909)\n",
            "Test: [20/261]\tTime 0.011 (0.042)\tLoss 4.9649 (4.3749)\tPrec@1 75.000 (80.810)\tPrec@5 95.000 (95.714)\n",
            "Test: [30/261]\tTime 0.018 (0.035)\tLoss 2.7801 (4.1285)\tPrec@1 88.000 (82.097)\tPrec@5 97.000 (96.032)\n",
            "Test: [40/261]\tTime 0.018 (0.035)\tLoss 2.9716 (3.9836)\tPrec@1 87.000 (82.732)\tPrec@5 97.000 (96.293)\n",
            "Test: [50/261]\tTime 0.044 (0.032)\tLoss 3.5821 (3.9333)\tPrec@1 86.000 (82.980)\tPrec@5 97.000 (96.176)\n",
            "Test: [60/261]\tTime 0.031 (0.032)\tLoss 3.7853 (3.9305)\tPrec@1 85.000 (83.000)\tPrec@5 96.000 (96.082)\n",
            "Test: [70/261]\tTime 0.030 (0.031)\tLoss 4.1849 (3.9384)\tPrec@1 83.000 (82.986)\tPrec@5 96.000 (96.141)\n",
            "Test: [80/261]\tTime 0.020 (0.031)\tLoss 3.8743 (3.9317)\tPrec@1 85.000 (83.037)\tPrec@5 95.000 (96.099)\n",
            "Test: [90/261]\tTime 0.030 (0.030)\tLoss 4.3478 (4.0082)\tPrec@1 82.000 (82.725)\tPrec@5 95.000 (95.989)\n",
            "Test: [100/261]\tTime 0.033 (0.030)\tLoss 3.8371 (3.9873)\tPrec@1 81.000 (82.772)\tPrec@5 95.000 (96.040)\n",
            "Test: [110/261]\tTime 0.034 (0.030)\tLoss 3.9601 (3.9594)\tPrec@1 81.000 (82.919)\tPrec@5 98.000 (96.045)\n",
            "Test: [120/261]\tTime 0.022 (0.030)\tLoss 2.8764 (3.9538)\tPrec@1 87.000 (82.934)\tPrec@5 96.000 (96.017)\n",
            "Test: [130/261]\tTime 0.031 (0.029)\tLoss 4.0084 (3.9407)\tPrec@1 83.000 (82.977)\tPrec@5 92.000 (96.046)\n",
            "Test: [140/261]\tTime 0.034 (0.029)\tLoss 5.0287 (3.9292)\tPrec@1 80.000 (83.050)\tPrec@5 95.000 (96.071)\n",
            "Test: [150/261]\tTime 0.025 (0.029)\tLoss 3.6802 (3.9308)\tPrec@1 84.000 (83.079)\tPrec@5 96.000 (96.053)\n",
            "Test: [160/261]\tTime 0.027 (0.029)\tLoss 3.1659 (3.9286)\tPrec@1 86.000 (83.056)\tPrec@5 96.000 (96.068)\n",
            "Test: [170/261]\tTime 0.033 (0.029)\tLoss 3.7621 (3.9074)\tPrec@1 81.000 (83.164)\tPrec@5 96.000 (96.070)\n",
            "Test: [180/261]\tTime 0.026 (0.029)\tLoss 3.5697 (3.9107)\tPrec@1 84.000 (83.144)\tPrec@5 96.000 (96.099)\n",
            "Test: [190/261]\tTime 0.034 (0.029)\tLoss 3.3985 (3.9106)\tPrec@1 87.000 (83.126)\tPrec@5 97.000 (96.147)\n",
            "Test: [200/261]\tTime 0.014 (0.028)\tLoss 2.2255 (3.9021)\tPrec@1 90.000 (83.134)\tPrec@5 98.000 (96.134)\n",
            "Test: [210/261]\tTime 0.034 (0.028)\tLoss 3.8015 (3.8919)\tPrec@1 87.000 (83.185)\tPrec@5 97.000 (96.175)\n",
            "Test: [220/261]\tTime 0.015 (0.028)\tLoss 4.4578 (3.8783)\tPrec@1 79.000 (83.249)\tPrec@5 96.000 (96.195)\n",
            "Test: [230/261]\tTime 0.011 (0.028)\tLoss 4.6383 (3.8796)\tPrec@1 80.000 (83.208)\tPrec@5 93.000 (96.195)\n",
            "Test: [240/261]\tTime 0.031 (0.028)\tLoss 3.2445 (3.8884)\tPrec@1 86.000 (83.149)\tPrec@5 98.000 (96.178)\n",
            "Test: [250/261]\tTime 0.019 (0.028)\tLoss 3.0545 (3.8666)\tPrec@1 85.000 (83.227)\tPrec@5 99.000 (96.227)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 3.7118 (3.8692)\tPrec@1 84.375 (83.232)\tPrec@5 96.875 (96.212)\n",
            "val Results: Prec@1 83.232 Prec@5 96.212 Loss 3.86917\n",
            "val Class Accuracy: [0.568,0.954,0.894,0.829,0.919,0.920,0.686,0.815,0.613,0.741]\n",
            "Best Prec@1: 85.414\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [58][0/66], lr: 0.01000\tTime 0.667 (0.667)\tData 0.580 (0.580)\tLoss 0.3320 (0.3320)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [58][10/66], lr: 0.01000\tTime 0.102 (0.156)\tData 0.000 (0.061)\tLoss 0.6501 (0.4925)\tPrec@1 96.875 (97.479)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [58][20/66], lr: 0.01000\tTime 0.109 (0.130)\tData 0.004 (0.034)\tLoss 0.5333 (0.5645)\tPrec@1 98.047 (97.210)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [58][30/66], lr: 0.01000\tTime 0.083 (0.120)\tData 0.006 (0.025)\tLoss 0.6193 (0.5395)\tPrec@1 96.875 (97.329)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [58][40/66], lr: 0.01000\tTime 0.100 (0.115)\tData 0.000 (0.021)\tLoss 0.5242 (0.5537)\tPrec@1 97.266 (97.256)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [58][50/66], lr: 0.01000\tTime 0.107 (0.113)\tData 0.000 (0.018)\tLoss 0.3878 (0.5391)\tPrec@1 98.047 (97.312)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [58][60/66], lr: 0.01000\tTime 0.076 (0.110)\tData 0.000 (0.016)\tLoss 0.9644 (0.5473)\tPrec@1 94.922 (97.278)\tPrec@5 99.609 (99.917)\n",
            "Test: [0/261]\tTime 0.353 (0.353)\tLoss 3.4230 (3.4230)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.034 (0.062)\tLoss 3.6233 (3.4343)\tPrec@1 85.000 (84.455)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/261]\tTime 0.013 (0.044)\tLoss 4.1307 (3.4168)\tPrec@1 80.000 (84.238)\tPrec@5 98.000 (97.381)\n",
            "Test: [30/261]\tTime 0.026 (0.042)\tLoss 2.0629 (3.2045)\tPrec@1 90.000 (85.452)\tPrec@5 99.000 (97.774)\n",
            "Test: [40/261]\tTime 0.046 (0.039)\tLoss 3.1656 (3.1351)\tPrec@1 86.000 (85.780)\tPrec@5 98.000 (97.756)\n",
            "Test: [50/261]\tTime 0.055 (0.037)\tLoss 2.9545 (3.1633)\tPrec@1 89.000 (85.569)\tPrec@5 98.000 (97.725)\n",
            "Test: [60/261]\tTime 0.023 (0.035)\tLoss 2.3933 (3.1639)\tPrec@1 90.000 (85.656)\tPrec@5 99.000 (97.639)\n",
            "Test: [70/261]\tTime 0.030 (0.034)\tLoss 3.2381 (3.1716)\tPrec@1 84.000 (85.606)\tPrec@5 95.000 (97.648)\n",
            "Test: [80/261]\tTime 0.031 (0.034)\tLoss 3.7376 (3.1830)\tPrec@1 82.000 (85.593)\tPrec@5 99.000 (97.716)\n",
            "Test: [90/261]\tTime 0.028 (0.033)\tLoss 2.5553 (3.2408)\tPrec@1 90.000 (85.297)\tPrec@5 96.000 (97.560)\n",
            "Test: [100/261]\tTime 0.034 (0.032)\tLoss 4.1471 (3.2317)\tPrec@1 81.000 (85.327)\tPrec@5 95.000 (97.594)\n",
            "Test: [110/261]\tTime 0.025 (0.033)\tLoss 3.3784 (3.2011)\tPrec@1 90.000 (85.423)\tPrec@5 98.000 (97.694)\n",
            "Test: [120/261]\tTime 0.031 (0.032)\tLoss 2.3298 (3.1984)\tPrec@1 91.000 (85.479)\tPrec@5 96.000 (97.661)\n",
            "Test: [130/261]\tTime 0.031 (0.032)\tLoss 3.8983 (3.2066)\tPrec@1 80.000 (85.420)\tPrec@5 96.000 (97.641)\n",
            "Test: [140/261]\tTime 0.018 (0.032)\tLoss 4.6882 (3.2104)\tPrec@1 77.000 (85.369)\tPrec@5 100.000 (97.667)\n",
            "Test: [150/261]\tTime 0.033 (0.032)\tLoss 3.4497 (3.2105)\tPrec@1 85.000 (85.358)\tPrec@5 96.000 (97.636)\n",
            "Test: [160/261]\tTime 0.038 (0.031)\tLoss 1.6533 (3.2024)\tPrec@1 91.000 (85.354)\tPrec@5 100.000 (97.689)\n",
            "Test: [170/261]\tTime 0.038 (0.031)\tLoss 4.1514 (3.2115)\tPrec@1 81.000 (85.316)\tPrec@5 93.000 (97.678)\n",
            "Test: [180/261]\tTime 0.017 (0.031)\tLoss 3.7784 (3.2112)\tPrec@1 84.000 (85.309)\tPrec@5 94.000 (97.680)\n",
            "Test: [190/261]\tTime 0.021 (0.031)\tLoss 2.6217 (3.1982)\tPrec@1 90.000 (85.377)\tPrec@5 98.000 (97.712)\n",
            "Test: [200/261]\tTime 0.028 (0.031)\tLoss 2.4550 (3.1975)\tPrec@1 86.000 (85.343)\tPrec@5 99.000 (97.716)\n",
            "Test: [210/261]\tTime 0.015 (0.030)\tLoss 2.9432 (3.1928)\tPrec@1 87.000 (85.374)\tPrec@5 98.000 (97.744)\n",
            "Test: [220/261]\tTime 0.032 (0.030)\tLoss 4.0746 (3.1895)\tPrec@1 80.000 (85.398)\tPrec@5 95.000 (97.738)\n",
            "Test: [230/261]\tTime 0.025 (0.030)\tLoss 3.6095 (3.1902)\tPrec@1 83.000 (85.403)\tPrec@5 95.000 (97.740)\n",
            "Test: [240/261]\tTime 0.025 (0.030)\tLoss 2.9358 (3.2063)\tPrec@1 86.000 (85.324)\tPrec@5 100.000 (97.718)\n",
            "Test: [250/261]\tTime 0.011 (0.030)\tLoss 2.3379 (3.1843)\tPrec@1 87.000 (85.402)\tPrec@5 99.000 (97.737)\n",
            "Test: [260/261]\tTime 0.006 (0.029)\tLoss 2.0048 (3.1854)\tPrec@1 90.625 (85.426)\tPrec@5 100.000 (97.726)\n",
            "val Results: Prec@1 85.426 Prec@5 97.726 Loss 3.18535\n",
            "val Class Accuracy: [0.841,0.874,0.956,0.826,0.849,0.870,0.706,0.872,0.807,0.789]\n",
            "Best Prec@1: 85.426\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [59][0/66], lr: 0.01000\tTime 0.694 (0.694)\tData 0.621 (0.621)\tLoss 0.6542 (0.6542)\tPrec@1 96.484 (96.484)\tPrec@5 99.219 (99.219)\n",
            "Epoch: [59][10/66], lr: 0.01000\tTime 0.094 (0.153)\tData 0.004 (0.064)\tLoss 0.9608 (0.6670)\tPrec@1 95.312 (96.484)\tPrec@5 99.609 (99.893)\n",
            "Epoch: [59][20/66], lr: 0.01000\tTime 0.092 (0.128)\tData 0.019 (0.036)\tLoss 0.7127 (0.6053)\tPrec@1 96.875 (97.042)\tPrec@5 99.609 (99.907)\n",
            "Epoch: [59][30/66], lr: 0.01000\tTime 0.131 (0.121)\tData 0.004 (0.028)\tLoss 0.3745 (0.5689)\tPrec@1 98.438 (97.228)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [59][40/66], lr: 0.01000\tTime 0.127 (0.117)\tData 0.006 (0.024)\tLoss 0.5797 (0.5827)\tPrec@1 96.875 (97.123)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [59][50/66], lr: 0.01000\tTime 0.104 (0.113)\tData 0.000 (0.021)\tLoss 0.6296 (0.5803)\tPrec@1 97.266 (97.128)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [59][60/66], lr: 0.01000\tTime 0.084 (0.110)\tData 0.000 (0.018)\tLoss 0.5572 (0.5984)\tPrec@1 96.094 (97.009)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.271 (0.271)\tLoss 4.4999 (4.4999)\tPrec@1 80.000 (80.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/261]\tTime 0.038 (0.060)\tLoss 5.1231 (4.3692)\tPrec@1 79.000 (81.636)\tPrec@5 93.000 (94.091)\n",
            "Test: [20/261]\tTime 0.018 (0.043)\tLoss 4.9717 (4.3190)\tPrec@1 76.000 (82.000)\tPrec@5 94.000 (94.333)\n",
            "Test: [30/261]\tTime 0.031 (0.039)\tLoss 3.3398 (4.0459)\tPrec@1 85.000 (83.032)\tPrec@5 96.000 (95.000)\n",
            "Test: [40/261]\tTime 0.035 (0.036)\tLoss 3.7955 (4.0660)\tPrec@1 84.000 (83.000)\tPrec@5 96.000 (95.220)\n",
            "Test: [50/261]\tTime 0.019 (0.034)\tLoss 4.6229 (4.0576)\tPrec@1 82.000 (83.118)\tPrec@5 93.000 (95.176)\n",
            "Test: [60/261]\tTime 0.012 (0.032)\tLoss 4.4913 (4.0535)\tPrec@1 82.000 (83.180)\tPrec@5 95.000 (95.180)\n",
            "Test: [70/261]\tTime 0.029 (0.032)\tLoss 5.2020 (4.0240)\tPrec@1 76.000 (83.254)\tPrec@5 96.000 (95.324)\n",
            "Test: [80/261]\tTime 0.032 (0.031)\tLoss 3.1778 (4.0164)\tPrec@1 87.000 (83.259)\tPrec@5 97.000 (95.333)\n",
            "Test: [90/261]\tTime 0.028 (0.031)\tLoss 5.2174 (4.0708)\tPrec@1 81.000 (83.022)\tPrec@5 91.000 (95.209)\n",
            "Test: [100/261]\tTime 0.016 (0.030)\tLoss 3.8835 (4.0600)\tPrec@1 82.000 (83.040)\tPrec@5 94.000 (95.267)\n",
            "Test: [110/261]\tTime 0.049 (0.030)\tLoss 3.8936 (4.0475)\tPrec@1 83.000 (83.045)\tPrec@5 96.000 (95.369)\n",
            "Test: [120/261]\tTime 0.040 (0.030)\tLoss 3.0341 (4.0527)\tPrec@1 87.000 (83.066)\tPrec@5 96.000 (95.298)\n",
            "Test: [130/261]\tTime 0.023 (0.030)\tLoss 4.0977 (4.0519)\tPrec@1 81.000 (83.031)\tPrec@5 97.000 (95.305)\n",
            "Test: [140/261]\tTime 0.024 (0.029)\tLoss 4.7167 (4.0501)\tPrec@1 81.000 (82.993)\tPrec@5 94.000 (95.369)\n",
            "Test: [150/261]\tTime 0.020 (0.029)\tLoss 3.1838 (4.0642)\tPrec@1 86.000 (83.007)\tPrec@5 97.000 (95.358)\n",
            "Test: [160/261]\tTime 0.058 (0.029)\tLoss 2.9770 (4.0600)\tPrec@1 89.000 (82.950)\tPrec@5 98.000 (95.404)\n",
            "Test: [170/261]\tTime 0.013 (0.029)\tLoss 3.5532 (4.0427)\tPrec@1 82.000 (82.994)\tPrec@5 99.000 (95.444)\n",
            "Test: [180/261]\tTime 0.021 (0.029)\tLoss 3.9293 (4.0351)\tPrec@1 86.000 (83.022)\tPrec@5 91.000 (95.409)\n",
            "Test: [190/261]\tTime 0.039 (0.029)\tLoss 3.7589 (4.0369)\tPrec@1 83.000 (83.010)\tPrec@5 96.000 (95.455)\n",
            "Test: [200/261]\tTime 0.011 (0.029)\tLoss 3.9904 (4.0348)\tPrec@1 81.000 (82.975)\tPrec@5 94.000 (95.478)\n",
            "Test: [210/261]\tTime 0.026 (0.028)\tLoss 3.3372 (4.0140)\tPrec@1 84.000 (83.057)\tPrec@5 97.000 (95.479)\n",
            "Test: [220/261]\tTime 0.021 (0.028)\tLoss 4.3235 (4.0145)\tPrec@1 82.000 (83.077)\tPrec@5 97.000 (95.471)\n",
            "Test: [230/261]\tTime 0.034 (0.028)\tLoss 5.0780 (4.0299)\tPrec@1 80.000 (82.996)\tPrec@5 91.000 (95.446)\n",
            "Test: [240/261]\tTime 0.023 (0.028)\tLoss 3.9152 (4.0388)\tPrec@1 83.000 (82.971)\tPrec@5 98.000 (95.415)\n",
            "Test: [250/261]\tTime 0.026 (0.028)\tLoss 2.9012 (4.0082)\tPrec@1 88.000 (83.076)\tPrec@5 96.000 (95.478)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.0873 (4.0290)\tPrec@1 93.750 (82.986)\tPrec@5 100.000 (95.448)\n",
            "val Results: Prec@1 82.986 Prec@5 95.448 Loss 4.02896\n",
            "val Class Accuracy: [0.833,0.957,0.926,0.870,0.906,0.705,0.706,0.735,0.862,0.404]\n",
            "Best Prec@1: 85.426\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [60][0/66], lr: 0.01000\tTime 0.713 (0.713)\tData 0.612 (0.612)\tLoss 0.5319 (0.5319)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [60][10/66], lr: 0.01000\tTime 0.102 (0.186)\tData 0.000 (0.068)\tLoss 0.5824 (0.6407)\tPrec@1 96.094 (96.697)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [60][20/66], lr: 0.01000\tTime 0.228 (0.176)\tData 0.140 (0.057)\tLoss 0.7026 (0.6146)\tPrec@1 96.484 (96.819)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [60][30/66], lr: 0.01000\tTime 0.104 (0.170)\tData 0.000 (0.051)\tLoss 0.5318 (0.5829)\tPrec@1 96.484 (96.988)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [60][40/66], lr: 0.01000\tTime 0.110 (0.155)\tData 0.002 (0.043)\tLoss 0.7949 (0.6088)\tPrec@1 96.094 (96.942)\tPrec@5 99.609 (99.914)\n",
            "Epoch: [60][50/66], lr: 0.01000\tTime 0.090 (0.145)\tData 0.000 (0.036)\tLoss 0.3182 (0.6144)\tPrec@1 98.438 (96.921)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [60][60/66], lr: 0.01000\tTime 0.072 (0.137)\tData 0.000 (0.031)\tLoss 0.2404 (0.6076)\tPrec@1 98.828 (96.965)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.283 (0.283)\tLoss 4.4887 (4.4887)\tPrec@1 82.000 (82.000)\tPrec@5 93.000 (93.000)\n",
            "Test: [10/261]\tTime 0.023 (0.057)\tLoss 5.9152 (4.8751)\tPrec@1 75.000 (79.273)\tPrec@5 93.000 (95.364)\n",
            "Test: [20/261]\tTime 0.025 (0.044)\tLoss 5.5033 (4.8663)\tPrec@1 77.000 (79.476)\tPrec@5 93.000 (95.333)\n",
            "Test: [30/261]\tTime 0.037 (0.037)\tLoss 4.6766 (4.6779)\tPrec@1 78.000 (80.258)\tPrec@5 97.000 (95.613)\n",
            "Test: [40/261]\tTime 0.024 (0.035)\tLoss 4.2783 (4.5413)\tPrec@1 83.000 (80.780)\tPrec@5 95.000 (95.854)\n",
            "Test: [50/261]\tTime 0.018 (0.034)\tLoss 3.7661 (4.5354)\tPrec@1 85.000 (80.608)\tPrec@5 97.000 (96.020)\n",
            "Test: [60/261]\tTime 0.019 (0.033)\tLoss 3.8625 (4.4993)\tPrec@1 85.000 (80.836)\tPrec@5 94.000 (95.951)\n",
            "Test: [70/261]\tTime 0.033 (0.032)\tLoss 5.7514 (4.4845)\tPrec@1 75.000 (80.915)\tPrec@5 95.000 (95.972)\n",
            "Test: [80/261]\tTime 0.022 (0.032)\tLoss 5.0549 (4.5260)\tPrec@1 79.000 (80.741)\tPrec@5 97.000 (95.914)\n",
            "Test: [90/261]\tTime 0.032 (0.031)\tLoss 5.5048 (4.5921)\tPrec@1 77.000 (80.527)\tPrec@5 94.000 (95.791)\n",
            "Test: [100/261]\tTime 0.041 (0.031)\tLoss 4.6490 (4.5677)\tPrec@1 80.000 (80.683)\tPrec@5 94.000 (95.802)\n",
            "Test: [110/261]\tTime 0.051 (0.031)\tLoss 4.5074 (4.5461)\tPrec@1 84.000 (80.694)\tPrec@5 94.000 (95.856)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 3.6485 (4.5313)\tPrec@1 86.000 (80.818)\tPrec@5 97.000 (95.893)\n",
            "Test: [130/261]\tTime 0.011 (0.030)\tLoss 4.3134 (4.5334)\tPrec@1 80.000 (80.786)\tPrec@5 95.000 (95.939)\n",
            "Test: [140/261]\tTime 0.023 (0.029)\tLoss 5.3411 (4.5291)\tPrec@1 79.000 (80.787)\tPrec@5 95.000 (95.965)\n",
            "Test: [150/261]\tTime 0.023 (0.030)\tLoss 4.1315 (4.5292)\tPrec@1 82.000 (80.808)\tPrec@5 98.000 (95.974)\n",
            "Test: [160/261]\tTime 0.034 (0.029)\tLoss 3.9100 (4.5274)\tPrec@1 86.000 (80.814)\tPrec@5 99.000 (96.031)\n",
            "Test: [170/261]\tTime 0.027 (0.030)\tLoss 4.1188 (4.5156)\tPrec@1 82.000 (80.860)\tPrec@5 96.000 (96.070)\n",
            "Test: [180/261]\tTime 0.026 (0.029)\tLoss 3.6189 (4.5110)\tPrec@1 86.000 (80.917)\tPrec@5 94.000 (96.066)\n",
            "Test: [190/261]\tTime 0.040 (0.029)\tLoss 4.1082 (4.4893)\tPrec@1 83.000 (80.984)\tPrec@5 95.000 (96.094)\n",
            "Test: [200/261]\tTime 0.023 (0.029)\tLoss 4.3743 (4.4973)\tPrec@1 82.000 (80.930)\tPrec@5 95.000 (96.080)\n",
            "Test: [210/261]\tTime 0.036 (0.029)\tLoss 4.2133 (4.4949)\tPrec@1 78.000 (80.924)\tPrec@5 97.000 (96.057)\n",
            "Test: [220/261]\tTime 0.029 (0.029)\tLoss 5.6766 (4.5073)\tPrec@1 75.000 (80.837)\tPrec@5 93.000 (96.068)\n",
            "Test: [230/261]\tTime 0.015 (0.029)\tLoss 6.3565 (4.5181)\tPrec@1 74.000 (80.766)\tPrec@5 91.000 (96.035)\n",
            "Test: [240/261]\tTime 0.017 (0.029)\tLoss 3.6346 (4.5201)\tPrec@1 83.000 (80.759)\tPrec@5 99.000 (96.054)\n",
            "Test: [250/261]\tTime 0.039 (0.029)\tLoss 3.4676 (4.5030)\tPrec@1 85.000 (80.813)\tPrec@5 98.000 (96.080)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 3.2421 (4.5027)\tPrec@1 87.500 (80.827)\tPrec@5 100.000 (96.093)\n",
            "val Results: Prec@1 80.827 Prec@5 96.093 Loss 4.50266\n",
            "val Class Accuracy: [0.649,0.990,0.889,0.894,0.748,0.764,0.770,0.660,0.508,0.745]\n",
            "Best Prec@1: 85.426\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [61][0/66], lr: 0.01000\tTime 0.681 (0.681)\tData 0.598 (0.598)\tLoss 0.5946 (0.5946)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [61][10/66], lr: 0.01000\tTime 0.109 (0.160)\tData 0.008 (0.062)\tLoss 0.7764 (0.5590)\tPrec@1 96.484 (97.443)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [61][20/66], lr: 0.01000\tTime 0.098 (0.132)\tData 0.003 (0.035)\tLoss 0.4578 (0.5603)\tPrec@1 98.047 (97.247)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [61][30/66], lr: 0.01000\tTime 0.090 (0.122)\tData 0.004 (0.026)\tLoss 0.5308 (0.5862)\tPrec@1 98.047 (97.152)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [61][40/66], lr: 0.01000\tTime 0.098 (0.117)\tData 0.000 (0.021)\tLoss 0.4829 (0.5874)\tPrec@1 98.047 (97.123)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [61][50/66], lr: 0.01000\tTime 0.072 (0.114)\tData 0.004 (0.018)\tLoss 0.7709 (0.6065)\tPrec@1 96.484 (97.021)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [61][60/66], lr: 0.01000\tTime 0.051 (0.111)\tData 0.000 (0.016)\tLoss 0.6737 (0.5889)\tPrec@1 97.266 (97.157)\tPrec@5 99.219 (99.859)\n",
            "Test: [0/261]\tTime 0.309 (0.309)\tLoss 4.0776 (4.0776)\tPrec@1 80.000 (80.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.021 (0.054)\tLoss 4.4853 (4.3972)\tPrec@1 84.000 (80.636)\tPrec@5 97.000 (97.545)\n",
            "Test: [20/261]\tTime 0.018 (0.041)\tLoss 5.4214 (4.2962)\tPrec@1 77.000 (81.714)\tPrec@5 96.000 (97.429)\n",
            "Test: [30/261]\tTime 0.030 (0.036)\tLoss 3.9001 (4.0926)\tPrec@1 81.000 (82.645)\tPrec@5 97.000 (97.484)\n",
            "Test: [40/261]\tTime 0.038 (0.035)\tLoss 3.0536 (4.0553)\tPrec@1 89.000 (82.780)\tPrec@5 95.000 (97.585)\n",
            "Test: [50/261]\tTime 0.037 (0.033)\tLoss 4.0032 (4.0120)\tPrec@1 83.000 (82.941)\tPrec@5 100.000 (97.686)\n",
            "Test: [60/261]\tTime 0.038 (0.032)\tLoss 4.4330 (3.9742)\tPrec@1 82.000 (83.197)\tPrec@5 98.000 (97.508)\n",
            "Test: [70/261]\tTime 0.025 (0.031)\tLoss 4.0456 (3.9333)\tPrec@1 83.000 (83.437)\tPrec@5 98.000 (97.606)\n",
            "Test: [80/261]\tTime 0.032 (0.031)\tLoss 4.1072 (3.9105)\tPrec@1 80.000 (83.469)\tPrec@5 98.000 (97.568)\n",
            "Test: [90/261]\tTime 0.020 (0.030)\tLoss 3.6741 (3.9567)\tPrec@1 88.000 (83.319)\tPrec@5 95.000 (97.451)\n",
            "Test: [100/261]\tTime 0.018 (0.030)\tLoss 5.0175 (3.9504)\tPrec@1 77.000 (83.297)\tPrec@5 97.000 (97.475)\n",
            "Test: [110/261]\tTime 0.025 (0.030)\tLoss 4.0678 (3.8963)\tPrec@1 83.000 (83.486)\tPrec@5 97.000 (97.514)\n",
            "Test: [120/261]\tTime 0.046 (0.029)\tLoss 3.3103 (3.8832)\tPrec@1 84.000 (83.521)\tPrec@5 97.000 (97.479)\n",
            "Test: [130/261]\tTime 0.019 (0.029)\tLoss 3.7732 (3.8780)\tPrec@1 85.000 (83.481)\tPrec@5 96.000 (97.443)\n",
            "Test: [140/261]\tTime 0.011 (0.029)\tLoss 4.1269 (3.8624)\tPrec@1 82.000 (83.525)\tPrec@5 97.000 (97.482)\n",
            "Test: [150/261]\tTime 0.051 (0.029)\tLoss 2.8380 (3.8557)\tPrec@1 87.000 (83.616)\tPrec@5 98.000 (97.503)\n",
            "Test: [160/261]\tTime 0.034 (0.029)\tLoss 2.0449 (3.8456)\tPrec@1 92.000 (83.596)\tPrec@5 100.000 (97.528)\n",
            "Test: [170/261]\tTime 0.027 (0.028)\tLoss 3.5486 (3.8217)\tPrec@1 86.000 (83.702)\tPrec@5 96.000 (97.561)\n",
            "Test: [180/261]\tTime 0.019 (0.028)\tLoss 3.1558 (3.8242)\tPrec@1 89.000 (83.713)\tPrec@5 95.000 (97.541)\n",
            "Test: [190/261]\tTime 0.029 (0.028)\tLoss 3.4489 (3.8152)\tPrec@1 85.000 (83.759)\tPrec@5 99.000 (97.576)\n",
            "Test: [200/261]\tTime 0.054 (0.028)\tLoss 3.8519 (3.8078)\tPrec@1 84.000 (83.796)\tPrec@5 97.000 (97.612)\n",
            "Test: [210/261]\tTime 0.028 (0.028)\tLoss 3.6518 (3.8032)\tPrec@1 86.000 (83.825)\tPrec@5 100.000 (97.588)\n",
            "Test: [220/261]\tTime 0.033 (0.028)\tLoss 3.5980 (3.7929)\tPrec@1 83.000 (83.860)\tPrec@5 98.000 (97.584)\n",
            "Test: [230/261]\tTime 0.032 (0.028)\tLoss 4.6554 (3.8021)\tPrec@1 80.000 (83.788)\tPrec@5 96.000 (97.597)\n",
            "Test: [240/261]\tTime 0.013 (0.028)\tLoss 3.5561 (3.8030)\tPrec@1 87.000 (83.797)\tPrec@5 98.000 (97.589)\n",
            "Test: [250/261]\tTime 0.022 (0.028)\tLoss 3.0067 (3.7911)\tPrec@1 88.000 (83.817)\tPrec@5 99.000 (97.614)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 1.8325 (3.8012)\tPrec@1 93.750 (83.797)\tPrec@5 100.000 (97.599)\n",
            "val Results: Prec@1 83.797 Prec@5 97.599 Loss 3.80116\n",
            "val Class Accuracy: [0.686,0.908,0.960,0.888,0.887,0.760,0.766,0.757,0.789,0.652]\n",
            "Best Prec@1: 85.426\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [62][0/66], lr: 0.01000\tTime 0.740 (0.740)\tData 0.638 (0.638)\tLoss 0.6861 (0.6861)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [62][10/66], lr: 0.01000\tTime 0.094 (0.155)\tData 0.000 (0.065)\tLoss 0.5533 (0.5175)\tPrec@1 97.266 (97.372)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [62][20/66], lr: 0.01000\tTime 0.090 (0.130)\tData 0.006 (0.040)\tLoss 0.3848 (0.5592)\tPrec@1 98.047 (97.061)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [62][30/66], lr: 0.01000\tTime 0.101 (0.119)\tData 0.000 (0.029)\tLoss 0.4596 (0.5770)\tPrec@1 96.875 (97.001)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [62][40/66], lr: 0.01000\tTime 0.097 (0.114)\tData 0.003 (0.023)\tLoss 0.8331 (0.5845)\tPrec@1 96.094 (97.018)\tPrec@5 99.609 (99.895)\n",
            "Epoch: [62][50/66], lr: 0.01000\tTime 0.098 (0.112)\tData 0.000 (0.020)\tLoss 0.7716 (0.5780)\tPrec@1 96.094 (97.021)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [62][60/66], lr: 0.01000\tTime 0.069 (0.110)\tData 0.000 (0.019)\tLoss 0.5436 (0.5731)\tPrec@1 97.266 (97.067)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.360 (0.360)\tLoss 4.5692 (4.5692)\tPrec@1 82.000 (82.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.062 (0.061)\tLoss 4.6286 (4.8832)\tPrec@1 80.000 (79.091)\tPrec@5 95.000 (95.455)\n",
            "Test: [20/261]\tTime 0.023 (0.044)\tLoss 4.6788 (4.6885)\tPrec@1 78.000 (79.762)\tPrec@5 94.000 (95.286)\n",
            "Test: [30/261]\tTime 0.027 (0.038)\tLoss 2.8834 (4.4202)\tPrec@1 85.000 (81.032)\tPrec@5 97.000 (95.968)\n",
            "Test: [40/261]\tTime 0.017 (0.036)\tLoss 3.3573 (4.2443)\tPrec@1 87.000 (81.756)\tPrec@5 95.000 (96.171)\n",
            "Test: [50/261]\tTime 0.011 (0.034)\tLoss 3.8719 (4.1904)\tPrec@1 83.000 (81.980)\tPrec@5 96.000 (96.294)\n",
            "Test: [60/261]\tTime 0.030 (0.033)\tLoss 4.4107 (4.1764)\tPrec@1 83.000 (82.230)\tPrec@5 97.000 (96.311)\n",
            "Test: [70/261]\tTime 0.022 (0.032)\tLoss 4.7591 (4.1688)\tPrec@1 81.000 (82.268)\tPrec@5 95.000 (96.423)\n",
            "Test: [80/261]\tTime 0.015 (0.031)\tLoss 4.4692 (4.1870)\tPrec@1 82.000 (82.235)\tPrec@5 96.000 (96.309)\n",
            "Test: [90/261]\tTime 0.028 (0.031)\tLoss 3.9809 (4.2548)\tPrec@1 84.000 (82.033)\tPrec@5 96.000 (96.242)\n",
            "Test: [100/261]\tTime 0.039 (0.031)\tLoss 5.4472 (4.2592)\tPrec@1 79.000 (82.089)\tPrec@5 94.000 (96.257)\n",
            "Test: [110/261]\tTime 0.042 (0.031)\tLoss 3.7504 (4.2261)\tPrec@1 84.000 (82.234)\tPrec@5 94.000 (96.270)\n",
            "Test: [120/261]\tTime 0.021 (0.030)\tLoss 3.5228 (4.2267)\tPrec@1 84.000 (82.248)\tPrec@5 95.000 (96.223)\n",
            "Test: [130/261]\tTime 0.024 (0.030)\tLoss 4.1462 (4.2032)\tPrec@1 86.000 (82.321)\tPrec@5 95.000 (96.229)\n",
            "Test: [140/261]\tTime 0.026 (0.030)\tLoss 5.3599 (4.1999)\tPrec@1 80.000 (82.397)\tPrec@5 95.000 (96.291)\n",
            "Test: [150/261]\tTime 0.055 (0.030)\tLoss 2.7795 (4.1823)\tPrec@1 89.000 (82.503)\tPrec@5 98.000 (96.278)\n",
            "Test: [160/261]\tTime 0.041 (0.029)\tLoss 3.3260 (4.1817)\tPrec@1 86.000 (82.534)\tPrec@5 97.000 (96.298)\n",
            "Test: [170/261]\tTime 0.027 (0.029)\tLoss 3.6868 (4.1600)\tPrec@1 83.000 (82.567)\tPrec@5 98.000 (96.345)\n",
            "Test: [180/261]\tTime 0.019 (0.029)\tLoss 4.3848 (4.1784)\tPrec@1 83.000 (82.497)\tPrec@5 94.000 (96.326)\n",
            "Test: [190/261]\tTime 0.028 (0.029)\tLoss 4.0675 (4.1777)\tPrec@1 83.000 (82.503)\tPrec@5 95.000 (96.361)\n",
            "Test: [200/261]\tTime 0.021 (0.029)\tLoss 4.0059 (4.1830)\tPrec@1 82.000 (82.448)\tPrec@5 96.000 (96.383)\n",
            "Test: [210/261]\tTime 0.023 (0.029)\tLoss 3.5692 (4.1796)\tPrec@1 86.000 (82.460)\tPrec@5 98.000 (96.379)\n",
            "Test: [220/261]\tTime 0.038 (0.029)\tLoss 4.9499 (4.1707)\tPrec@1 78.000 (82.484)\tPrec@5 96.000 (96.357)\n",
            "Test: [230/261]\tTime 0.040 (0.029)\tLoss 5.2235 (4.1954)\tPrec@1 80.000 (82.394)\tPrec@5 93.000 (96.333)\n",
            "Test: [240/261]\tTime 0.020 (0.029)\tLoss 3.6063 (4.1940)\tPrec@1 85.000 (82.415)\tPrec@5 96.000 (96.328)\n",
            "Test: [250/261]\tTime 0.030 (0.029)\tLoss 3.2985 (4.1637)\tPrec@1 86.000 (82.494)\tPrec@5 98.000 (96.375)\n",
            "Test: [260/261]\tTime 0.008 (0.028)\tLoss 1.6411 (4.1660)\tPrec@1 93.750 (82.487)\tPrec@5 96.875 (96.343)\n",
            "val Results: Prec@1 82.487 Prec@5 96.343 Loss 4.16596\n",
            "val Class Accuracy: [0.632,0.957,0.885,0.805,0.823,0.922,0.791,0.809,0.639,0.607]\n",
            "Best Prec@1: 85.426\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [63][0/66], lr: 0.01000\tTime 1.093 (1.093)\tData 0.998 (0.998)\tLoss 0.4445 (0.4445)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [63][10/66], lr: 0.01000\tTime 0.114 (0.227)\tData 0.000 (0.112)\tLoss 0.8932 (0.5994)\tPrec@1 94.922 (96.804)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [63][20/66], lr: 0.01000\tTime 0.177 (0.188)\tData 0.095 (0.077)\tLoss 0.6329 (0.6057)\tPrec@1 97.266 (96.912)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [63][30/66], lr: 0.01000\tTime 0.099 (0.160)\tData 0.000 (0.054)\tLoss 0.6210 (0.5870)\tPrec@1 96.484 (96.963)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [63][40/66], lr: 0.01000\tTime 0.092 (0.146)\tData 0.005 (0.042)\tLoss 0.5384 (0.5829)\tPrec@1 97.266 (96.885)\tPrec@5 99.609 (99.933)\n",
            "Epoch: [63][50/66], lr: 0.01000\tTime 0.111 (0.138)\tData 0.043 (0.036)\tLoss 0.8693 (0.5838)\tPrec@1 94.531 (96.883)\tPrec@5 100.000 (99.931)\n",
            "Epoch: [63][60/66], lr: 0.01000\tTime 0.055 (0.132)\tData 0.000 (0.032)\tLoss 0.9266 (0.6029)\tPrec@1 95.312 (96.817)\tPrec@5 99.609 (99.910)\n",
            "Test: [0/261]\tTime 0.306 (0.306)\tLoss 2.9599 (2.9599)\tPrec@1 87.000 (87.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.025 (0.057)\tLoss 3.9038 (3.4916)\tPrec@1 84.000 (84.909)\tPrec@5 97.000 (98.000)\n",
            "Test: [20/261]\tTime 0.040 (0.044)\tLoss 4.4102 (3.6078)\tPrec@1 81.000 (84.190)\tPrec@5 97.000 (97.619)\n",
            "Test: [30/261]\tTime 0.042 (0.038)\tLoss 3.4451 (3.4176)\tPrec@1 85.000 (85.258)\tPrec@5 99.000 (97.774)\n",
            "Test: [40/261]\tTime 0.034 (0.036)\tLoss 3.3312 (3.2958)\tPrec@1 85.000 (85.610)\tPrec@5 97.000 (97.805)\n",
            "Test: [50/261]\tTime 0.032 (0.034)\tLoss 2.1968 (3.2254)\tPrec@1 92.000 (85.902)\tPrec@5 99.000 (97.882)\n",
            "Test: [60/261]\tTime 0.013 (0.032)\tLoss 3.1333 (3.2677)\tPrec@1 86.000 (85.623)\tPrec@5 98.000 (97.852)\n",
            "Test: [70/261]\tTime 0.050 (0.032)\tLoss 3.4273 (3.2597)\tPrec@1 86.000 (85.563)\tPrec@5 98.000 (97.775)\n",
            "Test: [80/261]\tTime 0.049 (0.032)\tLoss 3.2970 (3.2315)\tPrec@1 87.000 (85.704)\tPrec@5 97.000 (97.790)\n",
            "Test: [90/261]\tTime 0.033 (0.031)\tLoss 4.9461 (3.2788)\tPrec@1 79.000 (85.451)\tPrec@5 95.000 (97.692)\n",
            "Test: [100/261]\tTime 0.025 (0.030)\tLoss 3.9128 (3.2640)\tPrec@1 82.000 (85.495)\tPrec@5 96.000 (97.703)\n",
            "Test: [110/261]\tTime 0.025 (0.030)\tLoss 3.5243 (3.2655)\tPrec@1 85.000 (85.495)\tPrec@5 98.000 (97.667)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 2.9102 (3.2560)\tPrec@1 86.000 (85.529)\tPrec@5 98.000 (97.669)\n",
            "Test: [130/261]\tTime 0.033 (0.030)\tLoss 3.7394 (3.2736)\tPrec@1 83.000 (85.450)\tPrec@5 98.000 (97.695)\n",
            "Test: [140/261]\tTime 0.018 (0.030)\tLoss 4.2098 (3.2798)\tPrec@1 81.000 (85.404)\tPrec@5 97.000 (97.674)\n",
            "Test: [150/261]\tTime 0.031 (0.029)\tLoss 2.9204 (3.2755)\tPrec@1 88.000 (85.444)\tPrec@5 98.000 (97.669)\n",
            "Test: [160/261]\tTime 0.024 (0.029)\tLoss 2.0517 (3.2817)\tPrec@1 90.000 (85.366)\tPrec@5 100.000 (97.677)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 3.0848 (3.2603)\tPrec@1 87.000 (85.485)\tPrec@5 97.000 (97.725)\n",
            "Test: [180/261]\tTime 0.023 (0.029)\tLoss 2.9798 (3.2625)\tPrec@1 87.000 (85.486)\tPrec@5 96.000 (97.663)\n",
            "Test: [190/261]\tTime 0.038 (0.029)\tLoss 3.0521 (3.2555)\tPrec@1 85.000 (85.503)\tPrec@5 98.000 (97.712)\n",
            "Test: [200/261]\tTime 0.031 (0.029)\tLoss 2.2867 (3.2558)\tPrec@1 90.000 (85.493)\tPrec@5 97.000 (97.701)\n",
            "Test: [210/261]\tTime 0.044 (0.029)\tLoss 3.3968 (3.2526)\tPrec@1 86.000 (85.502)\tPrec@5 99.000 (97.701)\n",
            "Test: [220/261]\tTime 0.027 (0.029)\tLoss 3.5510 (3.2499)\tPrec@1 83.000 (85.493)\tPrec@5 99.000 (97.706)\n",
            "Test: [230/261]\tTime 0.032 (0.029)\tLoss 4.5036 (3.2578)\tPrec@1 79.000 (85.463)\tPrec@5 96.000 (97.710)\n",
            "Test: [240/261]\tTime 0.038 (0.028)\tLoss 3.0543 (3.2577)\tPrec@1 87.000 (85.485)\tPrec@5 97.000 (97.689)\n",
            "Test: [250/261]\tTime 0.021 (0.028)\tLoss 2.0596 (3.2379)\tPrec@1 90.000 (85.586)\tPrec@5 99.000 (97.697)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.3971 (3.2379)\tPrec@1 87.500 (85.583)\tPrec@5 100.000 (97.691)\n",
            "val Results: Prec@1 85.583 Prec@5 97.691 Loss 3.23789\n",
            "val Class Accuracy: [0.775,0.935,0.952,0.857,0.891,0.753,0.803,0.835,0.676,0.816]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [64][0/66], lr: 0.01000\tTime 0.656 (0.656)\tData 0.570 (0.570)\tLoss 0.3490 (0.3490)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [64][10/66], lr: 0.01000\tTime 0.121 (0.159)\tData 0.003 (0.060)\tLoss 0.3592 (0.4819)\tPrec@1 98.047 (97.692)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [64][20/66], lr: 0.01000\tTime 0.126 (0.132)\tData 0.012 (0.037)\tLoss 0.5760 (0.5149)\tPrec@1 96.875 (97.433)\tPrec@5 99.609 (99.926)\n",
            "Epoch: [64][30/66], lr: 0.01000\tTime 0.104 (0.124)\tData 0.007 (0.027)\tLoss 0.3799 (0.5171)\tPrec@1 98.047 (97.404)\tPrec@5 99.609 (99.912)\n",
            "Epoch: [64][40/66], lr: 0.01000\tTime 0.082 (0.119)\tData 0.003 (0.021)\tLoss 0.6492 (0.5566)\tPrec@1 96.094 (97.142)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [64][50/66], lr: 0.01000\tTime 0.059 (0.116)\tData 0.007 (0.018)\tLoss 0.4503 (0.5591)\tPrec@1 98.047 (97.120)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [64][60/66], lr: 0.01000\tTime 0.065 (0.113)\tData 0.000 (0.016)\tLoss 0.4576 (0.5666)\tPrec@1 98.047 (97.080)\tPrec@5 100.000 (99.872)\n",
            "Test: [0/261]\tTime 0.315 (0.315)\tLoss 4.3546 (4.3546)\tPrec@1 81.000 (81.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.017 (0.058)\tLoss 5.0270 (4.4143)\tPrec@1 79.000 (81.091)\tPrec@5 96.000 (96.091)\n",
            "Test: [20/261]\tTime 0.019 (0.044)\tLoss 4.8851 (4.4003)\tPrec@1 78.000 (80.905)\tPrec@5 96.000 (96.048)\n",
            "Test: [30/261]\tTime 0.031 (0.039)\tLoss 2.3191 (4.1699)\tPrec@1 89.000 (82.065)\tPrec@5 97.000 (96.484)\n",
            "Test: [40/261]\tTime 0.010 (0.036)\tLoss 3.2461 (4.0013)\tPrec@1 87.000 (83.000)\tPrec@5 97.000 (96.707)\n",
            "Test: [50/261]\tTime 0.035 (0.035)\tLoss 2.8012 (3.9049)\tPrec@1 90.000 (83.353)\tPrec@5 99.000 (96.784)\n",
            "Test: [60/261]\tTime 0.018 (0.034)\tLoss 3.4643 (3.8692)\tPrec@1 86.000 (83.508)\tPrec@5 98.000 (96.869)\n",
            "Test: [70/261]\tTime 0.032 (0.033)\tLoss 4.7347 (3.9103)\tPrec@1 81.000 (83.310)\tPrec@5 95.000 (96.831)\n",
            "Test: [80/261]\tTime 0.041 (0.032)\tLoss 4.1099 (3.9070)\tPrec@1 82.000 (83.259)\tPrec@5 97.000 (96.889)\n",
            "Test: [90/261]\tTime 0.035 (0.032)\tLoss 3.4957 (3.9619)\tPrec@1 88.000 (82.967)\tPrec@5 96.000 (96.813)\n",
            "Test: [100/261]\tTime 0.018 (0.031)\tLoss 4.7288 (3.9559)\tPrec@1 84.000 (83.020)\tPrec@5 96.000 (96.851)\n",
            "Test: [110/261]\tTime 0.013 (0.031)\tLoss 3.7160 (3.9172)\tPrec@1 83.000 (83.234)\tPrec@5 96.000 (96.820)\n",
            "Test: [120/261]\tTime 0.022 (0.031)\tLoss 2.6372 (3.9094)\tPrec@1 89.000 (83.273)\tPrec@5 98.000 (96.785)\n",
            "Test: [130/261]\tTime 0.022 (0.030)\tLoss 4.0102 (3.9075)\tPrec@1 83.000 (83.252)\tPrec@5 96.000 (96.771)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 5.2339 (3.9056)\tPrec@1 77.000 (83.234)\tPrec@5 97.000 (96.837)\n",
            "Test: [150/261]\tTime 0.060 (0.030)\tLoss 3.4297 (3.9066)\tPrec@1 85.000 (83.219)\tPrec@5 97.000 (96.828)\n",
            "Test: [160/261]\tTime 0.026 (0.030)\tLoss 2.5216 (3.9119)\tPrec@1 90.000 (83.168)\tPrec@5 99.000 (96.876)\n",
            "Test: [170/261]\tTime 0.029 (0.030)\tLoss 3.5526 (3.8967)\tPrec@1 84.000 (83.211)\tPrec@5 98.000 (96.918)\n",
            "Test: [180/261]\tTime 0.033 (0.030)\tLoss 3.2522 (3.8884)\tPrec@1 88.000 (83.249)\tPrec@5 94.000 (96.884)\n",
            "Test: [190/261]\tTime 0.039 (0.030)\tLoss 3.4858 (3.8915)\tPrec@1 84.000 (83.194)\tPrec@5 97.000 (96.948)\n",
            "Test: [200/261]\tTime 0.020 (0.029)\tLoss 3.3431 (3.8971)\tPrec@1 85.000 (83.164)\tPrec@5 99.000 (96.945)\n",
            "Test: [210/261]\tTime 0.028 (0.029)\tLoss 3.3963 (3.8973)\tPrec@1 83.000 (83.128)\tPrec@5 100.000 (96.953)\n",
            "Test: [220/261]\tTime 0.015 (0.029)\tLoss 5.1680 (3.9035)\tPrec@1 74.000 (83.077)\tPrec@5 95.000 (96.923)\n",
            "Test: [230/261]\tTime 0.044 (0.029)\tLoss 5.0333 (3.9179)\tPrec@1 81.000 (83.039)\tPrec@5 93.000 (96.892)\n",
            "Test: [240/261]\tTime 0.052 (0.029)\tLoss 3.1316 (3.9181)\tPrec@1 85.000 (83.008)\tPrec@5 98.000 (96.896)\n",
            "Test: [250/261]\tTime 0.034 (0.029)\tLoss 3.3382 (3.9042)\tPrec@1 85.000 (83.028)\tPrec@5 98.000 (96.932)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.4255 (3.9016)\tPrec@1 93.750 (83.059)\tPrec@5 96.875 (96.911)\n",
            "val Results: Prec@1 83.059 Prec@5 96.911 Loss 3.90158\n",
            "val Class Accuracy: [0.626,0.938,0.907,0.817,0.902,0.927,0.774,0.656,0.668,0.740]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [65][0/66], lr: 0.01000\tTime 0.626 (0.626)\tData 0.542 (0.542)\tLoss 0.6643 (0.6643)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [65][10/66], lr: 0.01000\tTime 0.086 (0.154)\tData 0.000 (0.055)\tLoss 0.6156 (0.5792)\tPrec@1 96.875 (97.088)\tPrec@5 99.609 (99.858)\n",
            "Epoch: [65][20/66], lr: 0.01000\tTime 0.114 (0.133)\tData 0.000 (0.034)\tLoss 0.7223 (0.5315)\tPrec@1 96.484 (97.470)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [65][30/66], lr: 0.01000\tTime 0.114 (0.124)\tData 0.005 (0.025)\tLoss 0.3820 (0.5353)\tPrec@1 98.047 (97.404)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [65][40/66], lr: 0.01000\tTime 0.103 (0.119)\tData 0.002 (0.020)\tLoss 0.4559 (0.5153)\tPrec@1 97.266 (97.523)\tPrec@5 99.609 (99.848)\n",
            "Epoch: [65][50/66], lr: 0.01000\tTime 0.120 (0.116)\tData 0.002 (0.017)\tLoss 0.6780 (0.5526)\tPrec@1 96.484 (97.281)\tPrec@5 100.000 (99.877)\n",
            "Epoch: [65][60/66], lr: 0.01000\tTime 0.077 (0.112)\tData 0.000 (0.015)\tLoss 0.5163 (0.5501)\tPrec@1 96.875 (97.291)\tPrec@5 100.000 (99.891)\n",
            "Test: [0/261]\tTime 0.279 (0.279)\tLoss 4.9473 (4.9473)\tPrec@1 81.000 (81.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/261]\tTime 0.019 (0.057)\tLoss 5.2344 (5.5171)\tPrec@1 80.000 (78.455)\tPrec@5 94.000 (93.727)\n",
            "Test: [20/261]\tTime 0.022 (0.043)\tLoss 5.3788 (5.4762)\tPrec@1 76.000 (78.190)\tPrec@5 94.000 (93.429)\n",
            "Test: [30/261]\tTime 0.030 (0.036)\tLoss 3.8364 (5.2162)\tPrec@1 87.000 (79.516)\tPrec@5 95.000 (93.258)\n",
            "Test: [40/261]\tTime 0.024 (0.034)\tLoss 4.8563 (5.1159)\tPrec@1 83.000 (79.878)\tPrec@5 94.000 (93.512)\n",
            "Test: [50/261]\tTime 0.041 (0.032)\tLoss 5.0392 (5.0675)\tPrec@1 79.000 (79.980)\tPrec@5 95.000 (93.745)\n",
            "Test: [60/261]\tTime 0.044 (0.032)\tLoss 6.9336 (5.0495)\tPrec@1 75.000 (80.148)\tPrec@5 92.000 (93.738)\n",
            "Test: [70/261]\tTime 0.042 (0.032)\tLoss 5.5393 (5.0577)\tPrec@1 78.000 (80.000)\tPrec@5 92.000 (93.803)\n",
            "Test: [80/261]\tTime 0.024 (0.030)\tLoss 5.0404 (5.0588)\tPrec@1 80.000 (79.864)\tPrec@5 92.000 (93.741)\n",
            "Test: [90/261]\tTime 0.027 (0.030)\tLoss 5.6379 (5.1206)\tPrec@1 77.000 (79.604)\tPrec@5 92.000 (93.604)\n",
            "Test: [100/261]\tTime 0.033 (0.031)\tLoss 6.8412 (5.1275)\tPrec@1 70.000 (79.446)\tPrec@5 91.000 (93.673)\n",
            "Test: [110/261]\tTime 0.021 (0.030)\tLoss 4.5323 (5.1179)\tPrec@1 82.000 (79.495)\tPrec@5 95.000 (93.676)\n",
            "Test: [120/261]\tTime 0.023 (0.030)\tLoss 3.4819 (5.0995)\tPrec@1 84.000 (79.554)\tPrec@5 96.000 (93.636)\n",
            "Test: [130/261]\tTime 0.023 (0.029)\tLoss 4.8904 (5.0699)\tPrec@1 80.000 (79.634)\tPrec@5 92.000 (93.695)\n",
            "Test: [140/261]\tTime 0.044 (0.029)\tLoss 6.6191 (5.0681)\tPrec@1 75.000 (79.681)\tPrec@5 91.000 (93.730)\n",
            "Test: [150/261]\tTime 0.014 (0.029)\tLoss 3.9502 (5.0706)\tPrec@1 86.000 (79.735)\tPrec@5 95.000 (93.722)\n",
            "Test: [160/261]\tTime 0.023 (0.029)\tLoss 4.1011 (5.0884)\tPrec@1 83.000 (79.646)\tPrec@5 95.000 (93.758)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 3.1294 (5.0689)\tPrec@1 86.000 (79.719)\tPrec@5 94.000 (93.795)\n",
            "Test: [180/261]\tTime 0.026 (0.028)\tLoss 3.6277 (5.0709)\tPrec@1 86.000 (79.696)\tPrec@5 92.000 (93.757)\n",
            "Test: [190/261]\tTime 0.049 (0.029)\tLoss 5.1247 (5.0648)\tPrec@1 78.000 (79.686)\tPrec@5 92.000 (93.743)\n",
            "Test: [200/261]\tTime 0.035 (0.029)\tLoss 4.7837 (5.0713)\tPrec@1 79.000 (79.642)\tPrec@5 95.000 (93.741)\n",
            "Test: [210/261]\tTime 0.026 (0.029)\tLoss 5.1139 (5.0603)\tPrec@1 79.000 (79.659)\tPrec@5 95.000 (93.739)\n",
            "Test: [220/261]\tTime 0.033 (0.029)\tLoss 5.6647 (5.0467)\tPrec@1 77.000 (79.688)\tPrec@5 94.000 (93.751)\n",
            "Test: [230/261]\tTime 0.011 (0.028)\tLoss 6.4818 (5.0553)\tPrec@1 74.000 (79.667)\tPrec@5 88.000 (93.710)\n",
            "Test: [240/261]\tTime 0.027 (0.029)\tLoss 5.2118 (5.0562)\tPrec@1 79.000 (79.672)\tPrec@5 95.000 (93.722)\n",
            "Test: [250/261]\tTime 0.059 (0.029)\tLoss 3.7354 (5.0370)\tPrec@1 85.000 (79.765)\tPrec@5 97.000 (93.765)\n",
            "Test: [260/261]\tTime 0.009 (0.029)\tLoss 2.7471 (5.0404)\tPrec@1 90.625 (79.767)\tPrec@5 96.875 (93.758)\n",
            "val Results: Prec@1 79.767 Prec@5 93.758 Loss 5.04039\n",
            "val Class Accuracy: [0.282,0.948,0.956,0.780,0.930,0.873,0.880,0.764,0.420,0.510]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [66][0/66], lr: 0.01000\tTime 0.929 (0.929)\tData 0.796 (0.796)\tLoss 0.5491 (0.5491)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [66][10/66], lr: 0.01000\tTime 0.138 (0.234)\tData 0.023 (0.111)\tLoss 0.1919 (0.4371)\tPrec@1 99.219 (98.118)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [66][20/66], lr: 0.01000\tTime 0.106 (0.178)\tData 0.005 (0.066)\tLoss 0.6579 (0.4833)\tPrec@1 96.484 (97.675)\tPrec@5 99.609 (99.963)\n",
            "Epoch: [66][30/66], lr: 0.01000\tTime 0.103 (0.154)\tData 0.009 (0.047)\tLoss 0.3711 (0.4818)\tPrec@1 99.219 (97.719)\tPrec@5 99.609 (99.962)\n",
            "Epoch: [66][40/66], lr: 0.01000\tTime 0.078 (0.140)\tData 0.003 (0.037)\tLoss 0.3574 (0.5074)\tPrec@1 98.047 (97.494)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [66][50/66], lr: 0.01000\tTime 0.092 (0.133)\tData 0.000 (0.031)\tLoss 0.8584 (0.5215)\tPrec@1 95.703 (97.388)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [66][60/66], lr: 0.01000\tTime 0.082 (0.127)\tData 0.007 (0.028)\tLoss 0.8665 (0.5297)\tPrec@1 94.531 (97.336)\tPrec@5 100.000 (99.955)\n",
            "Test: [0/261]\tTime 0.297 (0.297)\tLoss 2.9420 (2.9420)\tPrec@1 84.000 (84.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.037 (0.059)\tLoss 3.9019 (3.6590)\tPrec@1 82.000 (82.545)\tPrec@5 95.000 (96.636)\n",
            "Test: [20/261]\tTime 0.030 (0.040)\tLoss 4.2446 (3.6619)\tPrec@1 85.000 (83.000)\tPrec@5 93.000 (96.429)\n",
            "Test: [30/261]\tTime 0.032 (0.038)\tLoss 3.1871 (3.4808)\tPrec@1 86.000 (83.903)\tPrec@5 96.000 (96.677)\n",
            "Test: [40/261]\tTime 0.027 (0.036)\tLoss 2.8507 (3.3499)\tPrec@1 88.000 (84.780)\tPrec@5 97.000 (96.829)\n",
            "Test: [50/261]\tTime 0.040 (0.034)\tLoss 3.8619 (3.3663)\tPrec@1 81.000 (84.608)\tPrec@5 96.000 (96.725)\n",
            "Test: [60/261]\tTime 0.019 (0.032)\tLoss 3.1169 (3.3817)\tPrec@1 86.000 (84.656)\tPrec@5 94.000 (96.754)\n",
            "Test: [70/261]\tTime 0.020 (0.032)\tLoss 3.3298 (3.3805)\tPrec@1 84.000 (84.718)\tPrec@5 98.000 (96.887)\n",
            "Test: [80/261]\tTime 0.010 (0.031)\tLoss 3.0122 (3.4039)\tPrec@1 88.000 (84.617)\tPrec@5 99.000 (96.951)\n",
            "Test: [90/261]\tTime 0.015 (0.031)\tLoss 3.2658 (3.4431)\tPrec@1 86.000 (84.396)\tPrec@5 96.000 (96.901)\n",
            "Test: [100/261]\tTime 0.023 (0.030)\tLoss 3.9003 (3.4452)\tPrec@1 81.000 (84.356)\tPrec@5 97.000 (96.911)\n",
            "Test: [110/261]\tTime 0.029 (0.030)\tLoss 3.9712 (3.4463)\tPrec@1 84.000 (84.342)\tPrec@5 94.000 (96.946)\n",
            "Test: [120/261]\tTime 0.030 (0.030)\tLoss 2.3304 (3.4368)\tPrec@1 88.000 (84.339)\tPrec@5 97.000 (96.959)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 3.8488 (3.4436)\tPrec@1 84.000 (84.313)\tPrec@5 96.000 (96.947)\n",
            "Test: [140/261]\tTime 0.016 (0.030)\tLoss 4.9274 (3.4489)\tPrec@1 76.000 (84.234)\tPrec@5 94.000 (96.972)\n",
            "Test: [150/261]\tTime 0.018 (0.030)\tLoss 2.7430 (3.4327)\tPrec@1 88.000 (84.351)\tPrec@5 98.000 (97.007)\n",
            "Test: [160/261]\tTime 0.026 (0.030)\tLoss 3.1395 (3.4342)\tPrec@1 86.000 (84.317)\tPrec@5 99.000 (97.019)\n",
            "Test: [170/261]\tTime 0.021 (0.029)\tLoss 2.3337 (3.3970)\tPrec@1 91.000 (84.480)\tPrec@5 98.000 (97.058)\n",
            "Test: [180/261]\tTime 0.032 (0.029)\tLoss 3.1076 (3.4007)\tPrec@1 85.000 (84.448)\tPrec@5 94.000 (97.055)\n",
            "Test: [190/261]\tTime 0.031 (0.029)\tLoss 4.2022 (3.4048)\tPrec@1 80.000 (84.450)\tPrec@5 93.000 (97.042)\n",
            "Test: [200/261]\tTime 0.033 (0.029)\tLoss 3.1327 (3.4059)\tPrec@1 86.000 (84.433)\tPrec@5 95.000 (97.050)\n",
            "Test: [210/261]\tTime 0.045 (0.029)\tLoss 3.3724 (3.4021)\tPrec@1 86.000 (84.460)\tPrec@5 97.000 (97.057)\n",
            "Test: [220/261]\tTime 0.034 (0.029)\tLoss 2.6388 (3.3937)\tPrec@1 91.000 (84.489)\tPrec@5 98.000 (97.027)\n",
            "Test: [230/261]\tTime 0.037 (0.029)\tLoss 3.5292 (3.4061)\tPrec@1 87.000 (84.429)\tPrec@5 98.000 (97.039)\n",
            "Test: [240/261]\tTime 0.026 (0.029)\tLoss 2.7131 (3.4093)\tPrec@1 86.000 (84.415)\tPrec@5 98.000 (97.008)\n",
            "Test: [250/261]\tTime 0.039 (0.029)\tLoss 3.3176 (3.3894)\tPrec@1 83.000 (84.474)\tPrec@5 96.000 (97.040)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.5934 (3.3876)\tPrec@1 93.750 (84.496)\tPrec@5 100.000 (97.031)\n",
            "val Results: Prec@1 84.496 Prec@5 97.031 Loss 3.38756\n",
            "val Class Accuracy: [0.846,0.938,0.837,0.745,0.924,0.811,0.804,0.861,0.785,0.764]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [67][0/66], lr: 0.01000\tTime 0.665 (0.665)\tData 0.562 (0.562)\tLoss 0.2760 (0.2760)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [67][10/66], lr: 0.01000\tTime 0.106 (0.155)\tData 0.005 (0.058)\tLoss 0.8171 (0.5128)\tPrec@1 96.094 (97.337)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [67][20/66], lr: 0.01000\tTime 0.100 (0.131)\tData 0.005 (0.033)\tLoss 0.5415 (0.5258)\tPrec@1 96.875 (97.340)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [67][30/66], lr: 0.01000\tTime 0.091 (0.120)\tData 0.005 (0.024)\tLoss 0.3338 (0.5387)\tPrec@1 98.438 (97.303)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [67][40/66], lr: 0.01000\tTime 0.122 (0.115)\tData 0.002 (0.020)\tLoss 0.3417 (0.5413)\tPrec@1 98.438 (97.275)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [67][50/66], lr: 0.01000\tTime 0.108 (0.113)\tData 0.004 (0.017)\tLoss 0.3613 (0.5381)\tPrec@1 98.438 (97.227)\tPrec@5 100.000 (99.900)\n",
            "Epoch: [67][60/66], lr: 0.01000\tTime 0.067 (0.109)\tData 0.000 (0.015)\tLoss 0.2686 (0.5238)\tPrec@1 98.438 (97.323)\tPrec@5 100.000 (99.910)\n",
            "Test: [0/261]\tTime 0.343 (0.343)\tLoss 3.6942 (3.6942)\tPrec@1 83.000 (83.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.032 (0.057)\tLoss 4.1525 (4.3083)\tPrec@1 83.000 (81.182)\tPrec@5 96.000 (96.364)\n",
            "Test: [20/261]\tTime 0.024 (0.041)\tLoss 4.8756 (4.3461)\tPrec@1 79.000 (80.952)\tPrec@5 95.000 (96.333)\n",
            "Test: [30/261]\tTime 0.015 (0.036)\tLoss 4.4046 (4.1503)\tPrec@1 80.000 (81.806)\tPrec@5 96.000 (96.613)\n",
            "Test: [40/261]\tTime 0.027 (0.034)\tLoss 2.8799 (3.9825)\tPrec@1 88.000 (82.317)\tPrec@5 95.000 (96.854)\n",
            "Test: [50/261]\tTime 0.029 (0.033)\tLoss 3.2399 (3.9665)\tPrec@1 88.000 (82.373)\tPrec@5 97.000 (96.784)\n",
            "Test: [60/261]\tTime 0.037 (0.032)\tLoss 3.9738 (3.9743)\tPrec@1 85.000 (82.443)\tPrec@5 95.000 (96.721)\n",
            "Test: [70/261]\tTime 0.020 (0.031)\tLoss 3.5450 (3.9544)\tPrec@1 88.000 (82.535)\tPrec@5 96.000 (96.732)\n",
            "Test: [80/261]\tTime 0.043 (0.030)\tLoss 3.6325 (3.9702)\tPrec@1 83.000 (82.481)\tPrec@5 96.000 (96.642)\n",
            "Test: [90/261]\tTime 0.020 (0.030)\tLoss 4.0160 (4.0211)\tPrec@1 84.000 (82.352)\tPrec@5 94.000 (96.626)\n",
            "Test: [100/261]\tTime 0.019 (0.029)\tLoss 4.6880 (4.0139)\tPrec@1 79.000 (82.257)\tPrec@5 95.000 (96.703)\n",
            "Test: [110/261]\tTime 0.042 (0.029)\tLoss 3.4372 (3.9782)\tPrec@1 85.000 (82.450)\tPrec@5 94.000 (96.739)\n",
            "Test: [120/261]\tTime 0.031 (0.029)\tLoss 3.3291 (3.9709)\tPrec@1 84.000 (82.496)\tPrec@5 98.000 (96.719)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 3.9459 (3.9566)\tPrec@1 83.000 (82.534)\tPrec@5 95.000 (96.740)\n",
            "Test: [140/261]\tTime 0.023 (0.029)\tLoss 4.9212 (3.9469)\tPrec@1 78.000 (82.596)\tPrec@5 96.000 (96.738)\n",
            "Test: [150/261]\tTime 0.045 (0.029)\tLoss 3.8101 (3.9502)\tPrec@1 83.000 (82.636)\tPrec@5 98.000 (96.715)\n",
            "Test: [160/261]\tTime 0.053 (0.029)\tLoss 2.5378 (3.9433)\tPrec@1 89.000 (82.671)\tPrec@5 99.000 (96.752)\n",
            "Test: [170/261]\tTime 0.020 (0.029)\tLoss 3.1934 (3.9192)\tPrec@1 85.000 (82.743)\tPrec@5 99.000 (96.784)\n",
            "Test: [180/261]\tTime 0.032 (0.029)\tLoss 2.9364 (3.9181)\tPrec@1 89.000 (82.746)\tPrec@5 96.000 (96.746)\n",
            "Test: [190/261]\tTime 0.010 (0.029)\tLoss 3.7791 (3.9055)\tPrec@1 83.000 (82.780)\tPrec@5 96.000 (96.775)\n",
            "Test: [200/261]\tTime 0.029 (0.028)\tLoss 2.8293 (3.8946)\tPrec@1 85.000 (82.781)\tPrec@5 99.000 (96.781)\n",
            "Test: [210/261]\tTime 0.023 (0.028)\tLoss 2.4983 (3.8855)\tPrec@1 88.000 (82.839)\tPrec@5 100.000 (96.777)\n",
            "Test: [220/261]\tTime 0.018 (0.028)\tLoss 4.6096 (3.8793)\tPrec@1 77.000 (82.851)\tPrec@5 97.000 (96.810)\n",
            "Test: [230/261]\tTime 0.044 (0.028)\tLoss 4.8125 (3.8818)\tPrec@1 79.000 (82.835)\tPrec@5 95.000 (96.814)\n",
            "Test: [240/261]\tTime 0.024 (0.028)\tLoss 3.8223 (3.8876)\tPrec@1 84.000 (82.830)\tPrec@5 98.000 (96.801)\n",
            "Test: [250/261]\tTime 0.023 (0.028)\tLoss 3.0912 (3.8698)\tPrec@1 86.000 (82.861)\tPrec@5 98.000 (96.821)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.9924 (3.8722)\tPrec@1 90.625 (82.848)\tPrec@5 96.875 (96.808)\n",
            "val Results: Prec@1 82.848 Prec@5 96.808 Loss 3.87222\n",
            "val Class Accuracy: [0.788,0.891,0.897,0.903,0.920,0.851,0.731,0.756,0.583,0.651]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [68][0/66], lr: 0.01000\tTime 0.588 (0.588)\tData 0.487 (0.487)\tLoss 0.3710 (0.3710)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [68][10/66], lr: 0.01000\tTime 0.103 (0.144)\tData 0.004 (0.050)\tLoss 0.5127 (0.4639)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [68][20/66], lr: 0.01000\tTime 0.102 (0.124)\tData 0.037 (0.032)\tLoss 0.5072 (0.4760)\tPrec@1 97.266 (97.489)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [68][30/66], lr: 0.01000\tTime 0.095 (0.117)\tData 0.011 (0.026)\tLoss 0.3150 (0.4696)\tPrec@1 98.438 (97.593)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [68][40/66], lr: 0.01000\tTime 0.079 (0.113)\tData 0.007 (0.023)\tLoss 0.3614 (0.4885)\tPrec@1 97.656 (97.428)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [68][50/66], lr: 0.01000\tTime 0.088 (0.109)\tData 0.000 (0.020)\tLoss 0.4027 (0.4901)\tPrec@1 98.047 (97.411)\tPrec@5 100.000 (99.931)\n",
            "Epoch: [68][60/66], lr: 0.01000\tTime 0.093 (0.108)\tData 0.018 (0.019)\tLoss 0.2306 (0.4914)\tPrec@1 98.828 (97.432)\tPrec@5 100.000 (99.930)\n",
            "Test: [0/261]\tTime 0.322 (0.322)\tLoss 4.4954 (4.4954)\tPrec@1 81.000 (81.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.019 (0.061)\tLoss 5.2547 (4.4129)\tPrec@1 77.000 (81.545)\tPrec@5 95.000 (96.091)\n",
            "Test: [20/261]\tTime 0.021 (0.043)\tLoss 5.1868 (4.3281)\tPrec@1 77.000 (81.810)\tPrec@5 97.000 (96.000)\n",
            "Test: [30/261]\tTime 0.027 (0.039)\tLoss 3.5521 (4.1078)\tPrec@1 84.000 (82.645)\tPrec@5 98.000 (96.484)\n",
            "Test: [40/261]\tTime 0.017 (0.036)\tLoss 3.3814 (3.9203)\tPrec@1 85.000 (83.268)\tPrec@5 95.000 (96.756)\n",
            "Test: [50/261]\tTime 0.043 (0.035)\tLoss 4.3969 (3.8417)\tPrec@1 81.000 (83.588)\tPrec@5 97.000 (96.706)\n",
            "Test: [60/261]\tTime 0.035 (0.034)\tLoss 3.2741 (3.8003)\tPrec@1 86.000 (83.918)\tPrec@5 98.000 (96.656)\n",
            "Test: [70/261]\tTime 0.034 (0.033)\tLoss 4.0247 (3.8018)\tPrec@1 84.000 (83.831)\tPrec@5 97.000 (96.746)\n",
            "Test: [80/261]\tTime 0.028 (0.032)\tLoss 3.7880 (3.8193)\tPrec@1 85.000 (83.852)\tPrec@5 96.000 (96.679)\n",
            "Test: [90/261]\tTime 0.042 (0.032)\tLoss 4.1082 (3.8809)\tPrec@1 85.000 (83.593)\tPrec@5 93.000 (96.571)\n",
            "Test: [100/261]\tTime 0.049 (0.032)\tLoss 3.8153 (3.8525)\tPrec@1 85.000 (83.693)\tPrec@5 96.000 (96.604)\n",
            "Test: [110/261]\tTime 0.036 (0.031)\tLoss 4.7905 (3.8444)\tPrec@1 79.000 (83.694)\tPrec@5 95.000 (96.667)\n",
            "Test: [120/261]\tTime 0.020 (0.031)\tLoss 3.1849 (3.8415)\tPrec@1 88.000 (83.702)\tPrec@5 95.000 (96.620)\n",
            "Test: [130/261]\tTime 0.028 (0.030)\tLoss 4.2343 (3.8325)\tPrec@1 81.000 (83.740)\tPrec@5 96.000 (96.641)\n",
            "Test: [140/261]\tTime 0.018 (0.030)\tLoss 5.2031 (3.8196)\tPrec@1 79.000 (83.738)\tPrec@5 95.000 (96.702)\n",
            "Test: [150/261]\tTime 0.020 (0.030)\tLoss 3.0372 (3.8117)\tPrec@1 86.000 (83.788)\tPrec@5 97.000 (96.715)\n",
            "Test: [160/261]\tTime 0.034 (0.030)\tLoss 3.2572 (3.8199)\tPrec@1 88.000 (83.689)\tPrec@5 96.000 (96.720)\n",
            "Test: [170/261]\tTime 0.028 (0.030)\tLoss 3.0765 (3.8014)\tPrec@1 87.000 (83.743)\tPrec@5 96.000 (96.766)\n",
            "Test: [180/261]\tTime 0.021 (0.030)\tLoss 3.8789 (3.8038)\tPrec@1 84.000 (83.768)\tPrec@5 93.000 (96.757)\n",
            "Test: [190/261]\tTime 0.026 (0.030)\tLoss 4.1627 (3.8031)\tPrec@1 84.000 (83.812)\tPrec@5 96.000 (96.754)\n",
            "Test: [200/261]\tTime 0.033 (0.029)\tLoss 2.8989 (3.7898)\tPrec@1 87.000 (83.846)\tPrec@5 96.000 (96.766)\n",
            "Test: [210/261]\tTime 0.031 (0.029)\tLoss 2.7757 (3.7782)\tPrec@1 88.000 (83.905)\tPrec@5 98.000 (96.782)\n",
            "Test: [220/261]\tTime 0.029 (0.029)\tLoss 4.1084 (3.7755)\tPrec@1 81.000 (83.896)\tPrec@5 97.000 (96.769)\n",
            "Test: [230/261]\tTime 0.028 (0.029)\tLoss 4.4011 (3.7775)\tPrec@1 81.000 (83.926)\tPrec@5 96.000 (96.753)\n",
            "Test: [240/261]\tTime 0.031 (0.029)\tLoss 3.6338 (3.7980)\tPrec@1 84.000 (83.813)\tPrec@5 97.000 (96.718)\n",
            "Test: [250/261]\tTime 0.032 (0.030)\tLoss 3.4549 (3.7794)\tPrec@1 84.000 (83.869)\tPrec@5 98.000 (96.757)\n",
            "Test: [260/261]\tTime 0.008 (0.029)\tLoss 2.7664 (3.7778)\tPrec@1 84.375 (83.874)\tPrec@5 100.000 (96.754)\n",
            "val Results: Prec@1 83.874 Prec@5 96.754 Loss 3.77783\n",
            "val Class Accuracy: [0.763,0.972,0.884,0.897,0.898,0.786,0.679,0.824,0.673,0.648]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [69][0/66], lr: 0.01000\tTime 0.973 (0.973)\tData 0.837 (0.837)\tLoss 0.6194 (0.6194)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [69][10/66], lr: 0.01000\tTime 0.119 (0.216)\tData 0.000 (0.101)\tLoss 0.6582 (0.5573)\tPrec@1 96.094 (97.230)\tPrec@5 99.219 (99.893)\n",
            "Epoch: [69][20/66], lr: 0.01000\tTime 0.075 (0.178)\tData 0.003 (0.068)\tLoss 0.5183 (0.5349)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [69][30/66], lr: 0.01000\tTime 0.077 (0.154)\tData 0.002 (0.048)\tLoss 0.6057 (0.5301)\tPrec@1 97.266 (97.316)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [69][40/66], lr: 0.01000\tTime 0.108 (0.142)\tData 0.005 (0.038)\tLoss 0.3074 (0.5226)\tPrec@1 98.438 (97.361)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [69][50/66], lr: 0.01000\tTime 0.096 (0.134)\tData 0.009 (0.032)\tLoss 0.6044 (0.5221)\tPrec@1 97.266 (97.350)\tPrec@5 100.000 (99.908)\n",
            "Epoch: [69][60/66], lr: 0.01000\tTime 0.101 (0.128)\tData 0.000 (0.027)\tLoss 0.5353 (0.5245)\tPrec@1 97.266 (97.330)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/261]\tTime 0.413 (0.413)\tLoss 4.3114 (4.3114)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.023 (0.064)\tLoss 5.0526 (4.5887)\tPrec@1 78.000 (79.818)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/261]\tTime 0.018 (0.046)\tLoss 5.0878 (4.6357)\tPrec@1 78.000 (79.857)\tPrec@5 97.000 (96.048)\n",
            "Test: [30/261]\tTime 0.033 (0.040)\tLoss 3.6429 (4.4119)\tPrec@1 83.000 (80.774)\tPrec@5 100.000 (96.548)\n",
            "Test: [40/261]\tTime 0.025 (0.036)\tLoss 3.6228 (4.3122)\tPrec@1 85.000 (81.317)\tPrec@5 95.000 (96.707)\n",
            "Test: [50/261]\tTime 0.032 (0.035)\tLoss 4.1111 (4.2534)\tPrec@1 80.000 (81.510)\tPrec@5 98.000 (96.745)\n",
            "Test: [60/261]\tTime 0.021 (0.034)\tLoss 3.6041 (4.2028)\tPrec@1 85.000 (81.852)\tPrec@5 96.000 (96.770)\n",
            "Test: [70/261]\tTime 0.053 (0.033)\tLoss 5.2949 (4.2235)\tPrec@1 78.000 (81.718)\tPrec@5 96.000 (96.746)\n",
            "Test: [80/261]\tTime 0.034 (0.032)\tLoss 3.6859 (4.2138)\tPrec@1 87.000 (81.840)\tPrec@5 97.000 (96.778)\n",
            "Test: [90/261]\tTime 0.024 (0.031)\tLoss 4.5757 (4.2741)\tPrec@1 82.000 (81.560)\tPrec@5 93.000 (96.626)\n",
            "Test: [100/261]\tTime 0.020 (0.030)\tLoss 4.4800 (4.2729)\tPrec@1 82.000 (81.554)\tPrec@5 95.000 (96.653)\n",
            "Test: [110/261]\tTime 0.018 (0.030)\tLoss 4.3651 (4.2670)\tPrec@1 81.000 (81.495)\tPrec@5 96.000 (96.712)\n",
            "Test: [120/261]\tTime 0.023 (0.030)\tLoss 2.7760 (4.2468)\tPrec@1 88.000 (81.636)\tPrec@5 98.000 (96.744)\n",
            "Test: [130/261]\tTime 0.027 (0.030)\tLoss 3.6993 (4.2403)\tPrec@1 84.000 (81.649)\tPrec@5 99.000 (96.763)\n",
            "Test: [140/261]\tTime 0.011 (0.029)\tLoss 5.9729 (4.2389)\tPrec@1 72.000 (81.638)\tPrec@5 94.000 (96.787)\n",
            "Test: [150/261]\tTime 0.032 (0.029)\tLoss 3.5759 (4.2272)\tPrec@1 83.000 (81.689)\tPrec@5 97.000 (96.735)\n",
            "Test: [160/261]\tTime 0.011 (0.029)\tLoss 2.8128 (4.2116)\tPrec@1 87.000 (81.745)\tPrec@5 99.000 (96.733)\n",
            "Test: [170/261]\tTime 0.027 (0.029)\tLoss 3.6984 (4.1922)\tPrec@1 86.000 (81.830)\tPrec@5 96.000 (96.754)\n",
            "Test: [180/261]\tTime 0.025 (0.029)\tLoss 3.8319 (4.1999)\tPrec@1 85.000 (81.840)\tPrec@5 95.000 (96.740)\n",
            "Test: [190/261]\tTime 0.022 (0.029)\tLoss 4.2600 (4.1878)\tPrec@1 83.000 (81.911)\tPrec@5 94.000 (96.743)\n",
            "Test: [200/261]\tTime 0.020 (0.029)\tLoss 4.2389 (4.1879)\tPrec@1 80.000 (81.896)\tPrec@5 98.000 (96.761)\n",
            "Test: [210/261]\tTime 0.020 (0.029)\tLoss 3.4446 (4.1801)\tPrec@1 82.000 (81.900)\tPrec@5 97.000 (96.777)\n",
            "Test: [220/261]\tTime 0.019 (0.029)\tLoss 4.7313 (4.1925)\tPrec@1 80.000 (81.837)\tPrec@5 98.000 (96.765)\n",
            "Test: [230/261]\tTime 0.032 (0.029)\tLoss 5.6257 (4.2089)\tPrec@1 75.000 (81.758)\tPrec@5 94.000 (96.753)\n",
            "Test: [240/261]\tTime 0.026 (0.029)\tLoss 3.8170 (4.2259)\tPrec@1 83.000 (81.664)\tPrec@5 96.000 (96.722)\n",
            "Test: [250/261]\tTime 0.024 (0.029)\tLoss 3.0290 (4.2025)\tPrec@1 86.000 (81.749)\tPrec@5 98.000 (96.733)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.4491 (4.2106)\tPrec@1 90.625 (81.730)\tPrec@5 100.000 (96.716)\n",
            "val Results: Prec@1 81.730 Prec@5 96.716 Loss 4.21065\n",
            "val Class Accuracy: [0.814,0.950,0.921,0.840,0.836,0.775,0.714,0.714,0.643,0.561]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [70][0/66], lr: 0.01000\tTime 0.666 (0.666)\tData 0.554 (0.554)\tLoss 0.2881 (0.2881)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [70][10/66], lr: 0.01000\tTime 0.094 (0.160)\tData 0.000 (0.057)\tLoss 0.3270 (0.4965)\tPrec@1 98.438 (97.692)\tPrec@5 99.609 (99.964)\n",
            "Epoch: [70][20/66], lr: 0.01000\tTime 0.093 (0.131)\tData 0.000 (0.033)\tLoss 0.5014 (0.4971)\tPrec@1 96.875 (97.452)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [70][30/66], lr: 0.01000\tTime 0.115 (0.122)\tData 0.008 (0.024)\tLoss 0.4639 (0.4841)\tPrec@1 97.266 (97.492)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [70][40/66], lr: 0.01000\tTime 0.081 (0.116)\tData 0.000 (0.020)\tLoss 0.5452 (0.4852)\tPrec@1 97.656 (97.542)\tPrec@5 99.609 (99.933)\n",
            "Epoch: [70][50/66], lr: 0.01000\tTime 0.130 (0.114)\tData 0.010 (0.018)\tLoss 0.2541 (0.4814)\tPrec@1 98.438 (97.549)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [70][60/66], lr: 0.01000\tTime 0.078 (0.110)\tData 0.000 (0.016)\tLoss 0.6715 (0.4878)\tPrec@1 96.094 (97.515)\tPrec@5 99.609 (99.930)\n",
            "Test: [0/261]\tTime 0.356 (0.356)\tLoss 3.4145 (3.4145)\tPrec@1 83.000 (83.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.029 (0.054)\tLoss 4.7103 (4.0312)\tPrec@1 80.000 (82.455)\tPrec@5 95.000 (95.636)\n",
            "Test: [20/261]\tTime 0.015 (0.044)\tLoss 4.6630 (4.0104)\tPrec@1 79.000 (82.429)\tPrec@5 96.000 (95.762)\n",
            "Test: [30/261]\tTime 0.047 (0.038)\tLoss 3.0980 (3.7660)\tPrec@1 85.000 (83.613)\tPrec@5 97.000 (96.290)\n",
            "Test: [40/261]\tTime 0.044 (0.036)\tLoss 3.7775 (3.7632)\tPrec@1 83.000 (83.732)\tPrec@5 95.000 (96.317)\n",
            "Test: [50/261]\tTime 0.015 (0.034)\tLoss 2.6535 (3.7140)\tPrec@1 89.000 (84.039)\tPrec@5 96.000 (96.333)\n",
            "Test: [60/261]\tTime 0.037 (0.033)\tLoss 3.2269 (3.6921)\tPrec@1 87.000 (84.197)\tPrec@5 98.000 (96.311)\n",
            "Test: [70/261]\tTime 0.025 (0.033)\tLoss 4.6204 (3.7068)\tPrec@1 81.000 (84.197)\tPrec@5 95.000 (96.366)\n",
            "Test: [80/261]\tTime 0.042 (0.032)\tLoss 3.6257 (3.7158)\tPrec@1 84.000 (84.148)\tPrec@5 96.000 (96.296)\n",
            "Test: [90/261]\tTime 0.027 (0.031)\tLoss 4.2146 (3.7757)\tPrec@1 83.000 (83.835)\tPrec@5 93.000 (96.231)\n",
            "Test: [100/261]\tTime 0.047 (0.031)\tLoss 4.8852 (3.7640)\tPrec@1 82.000 (83.921)\tPrec@5 96.000 (96.327)\n",
            "Test: [110/261]\tTime 0.031 (0.031)\tLoss 3.6102 (3.7494)\tPrec@1 84.000 (83.955)\tPrec@5 93.000 (96.315)\n",
            "Test: [120/261]\tTime 0.042 (0.031)\tLoss 3.1674 (3.7401)\tPrec@1 86.000 (83.975)\tPrec@5 96.000 (96.339)\n",
            "Test: [130/261]\tTime 0.022 (0.030)\tLoss 3.6101 (3.7221)\tPrec@1 83.000 (84.046)\tPrec@5 97.000 (96.359)\n",
            "Test: [140/261]\tTime 0.023 (0.030)\tLoss 4.5918 (3.7076)\tPrec@1 78.000 (84.050)\tPrec@5 96.000 (96.411)\n",
            "Test: [150/261]\tTime 0.014 (0.029)\tLoss 2.3108 (3.6994)\tPrec@1 90.000 (84.099)\tPrec@5 98.000 (96.430)\n",
            "Test: [160/261]\tTime 0.017 (0.029)\tLoss 2.7899 (3.6833)\tPrec@1 90.000 (84.168)\tPrec@5 97.000 (96.491)\n",
            "Test: [170/261]\tTime 0.037 (0.029)\tLoss 3.0814 (3.6561)\tPrec@1 86.000 (84.281)\tPrec@5 97.000 (96.538)\n",
            "Test: [180/261]\tTime 0.039 (0.029)\tLoss 3.8364 (3.6628)\tPrec@1 84.000 (84.249)\tPrec@5 94.000 (96.519)\n",
            "Test: [190/261]\tTime 0.025 (0.029)\tLoss 4.0455 (3.6653)\tPrec@1 81.000 (84.225)\tPrec@5 97.000 (96.550)\n",
            "Test: [200/261]\tTime 0.016 (0.029)\tLoss 3.8410 (3.6628)\tPrec@1 81.000 (84.184)\tPrec@5 96.000 (96.587)\n",
            "Test: [210/261]\tTime 0.025 (0.029)\tLoss 3.6838 (3.6590)\tPrec@1 84.000 (84.194)\tPrec@5 98.000 (96.555)\n",
            "Test: [220/261]\tTime 0.010 (0.028)\tLoss 4.1579 (3.6604)\tPrec@1 83.000 (84.186)\tPrec@5 97.000 (96.538)\n",
            "Test: [230/261]\tTime 0.019 (0.028)\tLoss 5.1888 (3.6708)\tPrec@1 77.000 (84.164)\tPrec@5 95.000 (96.519)\n",
            "Test: [240/261]\tTime 0.028 (0.028)\tLoss 3.4543 (3.6695)\tPrec@1 85.000 (84.178)\tPrec@5 97.000 (96.498)\n",
            "Test: [250/261]\tTime 0.037 (0.028)\tLoss 3.1202 (3.6451)\tPrec@1 85.000 (84.251)\tPrec@5 97.000 (96.546)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.8462 (3.6527)\tPrec@1 90.625 (84.219)\tPrec@5 100.000 (96.558)\n",
            "val Results: Prec@1 84.219 Prec@5 96.558 Loss 3.65265\n",
            "val Class Accuracy: [0.764,0.979,0.934,0.780,0.887,0.688,0.850,0.785,0.755,0.677]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [71][0/66], lr: 0.01000\tTime 0.643 (0.643)\tData 0.539 (0.539)\tLoss 0.3582 (0.3582)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [71][10/66], lr: 0.01000\tTime 0.091 (0.155)\tData 0.005 (0.055)\tLoss 0.4331 (0.4046)\tPrec@1 98.047 (97.834)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [71][20/66], lr: 0.01000\tTime 0.097 (0.130)\tData 0.002 (0.032)\tLoss 0.3825 (0.4254)\tPrec@1 98.047 (97.712)\tPrec@5 100.000 (99.888)\n",
            "Epoch: [71][30/66], lr: 0.01000\tTime 0.099 (0.121)\tData 0.004 (0.024)\tLoss 0.6472 (0.4510)\tPrec@1 96.875 (97.593)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [71][40/66], lr: 0.01000\tTime 0.101 (0.116)\tData 0.005 (0.019)\tLoss 0.2779 (0.4522)\tPrec@1 98.828 (97.590)\tPrec@5 100.000 (99.895)\n",
            "Epoch: [71][50/66], lr: 0.01000\tTime 0.101 (0.113)\tData 0.005 (0.017)\tLoss 0.6472 (0.4735)\tPrec@1 96.875 (97.511)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [71][60/66], lr: 0.01000\tTime 0.066 (0.110)\tData 0.000 (0.015)\tLoss 0.4333 (0.4794)\tPrec@1 98.047 (97.490)\tPrec@5 100.000 (99.904)\n",
            "Test: [0/261]\tTime 0.341 (0.341)\tLoss 4.9107 (4.9107)\tPrec@1 81.000 (81.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.033 (0.058)\tLoss 5.4347 (4.9463)\tPrec@1 79.000 (79.273)\tPrec@5 95.000 (95.182)\n",
            "Test: [20/261]\tTime 0.040 (0.040)\tLoss 4.8136 (4.8112)\tPrec@1 82.000 (80.238)\tPrec@5 95.000 (95.000)\n",
            "Test: [30/261]\tTime 0.018 (0.038)\tLoss 4.2425 (4.7336)\tPrec@1 80.000 (80.484)\tPrec@5 96.000 (95.161)\n",
            "Test: [40/261]\tTime 0.017 (0.034)\tLoss 3.4981 (4.5596)\tPrec@1 88.000 (81.512)\tPrec@5 96.000 (95.244)\n",
            "Test: [50/261]\tTime 0.033 (0.034)\tLoss 4.6390 (4.5098)\tPrec@1 81.000 (81.784)\tPrec@5 96.000 (95.216)\n",
            "Test: [60/261]\tTime 0.039 (0.032)\tLoss 5.6910 (4.4818)\tPrec@1 77.000 (81.951)\tPrec@5 96.000 (95.246)\n",
            "Test: [70/261]\tTime 0.038 (0.032)\tLoss 5.1687 (4.4952)\tPrec@1 81.000 (81.859)\tPrec@5 92.000 (95.239)\n",
            "Test: [80/261]\tTime 0.045 (0.031)\tLoss 5.0389 (4.5185)\tPrec@1 81.000 (81.704)\tPrec@5 92.000 (95.160)\n",
            "Test: [90/261]\tTime 0.034 (0.030)\tLoss 5.1080 (4.6046)\tPrec@1 81.000 (81.286)\tPrec@5 93.000 (95.066)\n",
            "Test: [100/261]\tTime 0.011 (0.030)\tLoss 4.5849 (4.6100)\tPrec@1 82.000 (81.267)\tPrec@5 97.000 (95.119)\n",
            "Test: [110/261]\tTime 0.054 (0.029)\tLoss 3.7574 (4.5794)\tPrec@1 85.000 (81.459)\tPrec@5 95.000 (95.117)\n",
            "Test: [120/261]\tTime 0.027 (0.029)\tLoss 3.3263 (4.5719)\tPrec@1 87.000 (81.438)\tPrec@5 98.000 (95.140)\n",
            "Test: [130/261]\tTime 0.057 (0.029)\tLoss 4.2975 (4.5488)\tPrec@1 82.000 (81.481)\tPrec@5 94.000 (95.183)\n",
            "Test: [140/261]\tTime 0.036 (0.029)\tLoss 5.3804 (4.5443)\tPrec@1 79.000 (81.454)\tPrec@5 93.000 (95.227)\n",
            "Test: [150/261]\tTime 0.031 (0.029)\tLoss 3.4255 (4.5421)\tPrec@1 86.000 (81.497)\tPrec@5 96.000 (95.285)\n",
            "Test: [160/261]\tTime 0.034 (0.029)\tLoss 3.1565 (4.5401)\tPrec@1 88.000 (81.422)\tPrec@5 98.000 (95.342)\n",
            "Test: [170/261]\tTime 0.036 (0.029)\tLoss 3.9266 (4.5251)\tPrec@1 84.000 (81.439)\tPrec@5 95.000 (95.386)\n",
            "Test: [180/261]\tTime 0.043 (0.029)\tLoss 4.2580 (4.5299)\tPrec@1 83.000 (81.403)\tPrec@5 95.000 (95.370)\n",
            "Test: [190/261]\tTime 0.034 (0.029)\tLoss 4.3688 (4.5279)\tPrec@1 82.000 (81.445)\tPrec@5 93.000 (95.408)\n",
            "Test: [200/261]\tTime 0.043 (0.029)\tLoss 4.0032 (4.5191)\tPrec@1 81.000 (81.458)\tPrec@5 96.000 (95.403)\n",
            "Test: [210/261]\tTime 0.044 (0.029)\tLoss 4.2951 (4.4995)\tPrec@1 83.000 (81.531)\tPrec@5 96.000 (95.427)\n",
            "Test: [220/261]\tTime 0.041 (0.030)\tLoss 5.5069 (4.4975)\tPrec@1 77.000 (81.507)\tPrec@5 95.000 (95.416)\n",
            "Test: [230/261]\tTime 0.039 (0.030)\tLoss 5.6497 (4.5034)\tPrec@1 75.000 (81.442)\tPrec@5 93.000 (95.394)\n",
            "Test: [240/261]\tTime 0.037 (0.031)\tLoss 4.3832 (4.5145)\tPrec@1 81.000 (81.349)\tPrec@5 95.000 (95.415)\n",
            "Test: [250/261]\tTime 0.050 (0.031)\tLoss 4.0639 (4.4895)\tPrec@1 81.000 (81.414)\tPrec@5 97.000 (95.486)\n",
            "Test: [260/261]\tTime 0.008 (0.031)\tLoss 4.1693 (4.5007)\tPrec@1 75.000 (81.365)\tPrec@5 96.875 (95.452)\n",
            "val Results: Prec@1 81.365 Prec@5 95.452 Loss 4.50067\n",
            "val Class Accuracy: [0.507,0.957,0.956,0.866,0.907,0.898,0.562,0.785,0.542,0.581]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [72][0/66], lr: 0.01000\tTime 1.041 (1.041)\tData 0.896 (0.896)\tLoss 0.2420 (0.2420)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [72][10/66], lr: 0.01000\tTime 0.110 (0.209)\tData 0.005 (0.097)\tLoss 0.3402 (0.5093)\tPrec@1 97.266 (97.408)\tPrec@5 99.609 (99.929)\n",
            "Epoch: [72][20/66], lr: 0.01000\tTime 0.098 (0.158)\tData 0.032 (0.057)\tLoss 1.0363 (0.5177)\tPrec@1 95.312 (97.321)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [72][30/66], lr: 0.01000\tTime 0.106 (0.142)\tData 0.005 (0.042)\tLoss 0.5576 (0.5612)\tPrec@1 97.266 (97.140)\tPrec@5 99.609 (99.912)\n",
            "Epoch: [72][40/66], lr: 0.01000\tTime 0.097 (0.132)\tData 0.005 (0.034)\tLoss 0.4525 (0.5499)\tPrec@1 98.047 (97.256)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [72][50/66], lr: 0.01000\tTime 0.085 (0.126)\tData 0.000 (0.028)\tLoss 0.6400 (0.5588)\tPrec@1 96.484 (97.250)\tPrec@5 99.609 (99.885)\n",
            "Epoch: [72][60/66], lr: 0.01000\tTime 0.066 (0.122)\tData 0.000 (0.024)\tLoss 0.3661 (0.5445)\tPrec@1 98.047 (97.330)\tPrec@5 100.000 (99.872)\n",
            "Test: [0/261]\tTime 0.274 (0.274)\tLoss 3.2791 (3.2791)\tPrec@1 84.000 (84.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.029 (0.061)\tLoss 4.4687 (3.7431)\tPrec@1 81.000 (83.182)\tPrec@5 98.000 (96.727)\n",
            "Test: [20/261]\tTime 0.024 (0.044)\tLoss 4.1089 (3.6354)\tPrec@1 82.000 (83.667)\tPrec@5 97.000 (97.000)\n",
            "Test: [30/261]\tTime 0.039 (0.039)\tLoss 2.4030 (3.4153)\tPrec@1 90.000 (85.097)\tPrec@5 97.000 (97.065)\n",
            "Test: [40/261]\tTime 0.011 (0.035)\tLoss 2.7816 (3.3856)\tPrec@1 91.000 (85.317)\tPrec@5 96.000 (97.171)\n",
            "Test: [50/261]\tTime 0.030 (0.032)\tLoss 3.4366 (3.3978)\tPrec@1 82.000 (85.294)\tPrec@5 98.000 (97.118)\n",
            "Test: [60/261]\tTime 0.010 (0.032)\tLoss 3.2215 (3.3444)\tPrec@1 88.000 (85.443)\tPrec@5 95.000 (97.033)\n",
            "Test: [70/261]\tTime 0.038 (0.032)\tLoss 3.9987 (3.3602)\tPrec@1 81.000 (85.451)\tPrec@5 99.000 (97.028)\n",
            "Test: [80/261]\tTime 0.030 (0.031)\tLoss 3.7081 (3.3533)\tPrec@1 84.000 (85.432)\tPrec@5 97.000 (96.988)\n",
            "Test: [90/261]\tTime 0.029 (0.030)\tLoss 3.6124 (3.4199)\tPrec@1 87.000 (85.132)\tPrec@5 96.000 (96.857)\n",
            "Test: [100/261]\tTime 0.047 (0.030)\tLoss 4.8743 (3.4340)\tPrec@1 78.000 (85.089)\tPrec@5 93.000 (96.891)\n",
            "Test: [110/261]\tTime 0.033 (0.030)\tLoss 3.3977 (3.3982)\tPrec@1 86.000 (85.225)\tPrec@5 95.000 (96.919)\n",
            "Test: [120/261]\tTime 0.011 (0.029)\tLoss 2.5273 (3.3865)\tPrec@1 90.000 (85.231)\tPrec@5 97.000 (96.868)\n",
            "Test: [130/261]\tTime 0.023 (0.029)\tLoss 3.5617 (3.4010)\tPrec@1 83.000 (85.183)\tPrec@5 96.000 (96.832)\n",
            "Test: [140/261]\tTime 0.044 (0.029)\tLoss 4.3694 (3.4012)\tPrec@1 81.000 (85.191)\tPrec@5 96.000 (96.858)\n",
            "Test: [150/261]\tTime 0.039 (0.029)\tLoss 2.9764 (3.4045)\tPrec@1 86.000 (85.192)\tPrec@5 98.000 (96.834)\n",
            "Test: [160/261]\tTime 0.012 (0.029)\tLoss 2.2406 (3.4048)\tPrec@1 92.000 (85.205)\tPrec@5 98.000 (96.826)\n",
            "Test: [170/261]\tTime 0.040 (0.029)\tLoss 2.8837 (3.3752)\tPrec@1 88.000 (85.368)\tPrec@5 94.000 (96.848)\n",
            "Test: [180/261]\tTime 0.019 (0.029)\tLoss 3.4878 (3.3956)\tPrec@1 85.000 (85.260)\tPrec@5 94.000 (96.840)\n",
            "Test: [190/261]\tTime 0.029 (0.029)\tLoss 3.3430 (3.4020)\tPrec@1 87.000 (85.241)\tPrec@5 98.000 (96.869)\n",
            "Test: [200/261]\tTime 0.035 (0.029)\tLoss 3.6704 (3.4053)\tPrec@1 83.000 (85.224)\tPrec@5 99.000 (96.876)\n",
            "Test: [210/261]\tTime 0.030 (0.029)\tLoss 2.7497 (3.3898)\tPrec@1 87.000 (85.303)\tPrec@5 100.000 (96.896)\n",
            "Test: [220/261]\tTime 0.050 (0.028)\tLoss 4.7447 (3.4026)\tPrec@1 80.000 (85.249)\tPrec@5 95.000 (96.873)\n",
            "Test: [230/261]\tTime 0.028 (0.028)\tLoss 3.9262 (3.4119)\tPrec@1 84.000 (85.190)\tPrec@5 94.000 (96.866)\n",
            "Test: [240/261]\tTime 0.024 (0.028)\tLoss 3.0638 (3.4254)\tPrec@1 87.000 (85.137)\tPrec@5 97.000 (96.826)\n",
            "Test: [250/261]\tTime 0.010 (0.028)\tLoss 3.2699 (3.4063)\tPrec@1 85.000 (85.199)\tPrec@5 97.000 (96.857)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.3558 (3.4172)\tPrec@1 90.625 (85.168)\tPrec@5 96.875 (96.823)\n",
            "val Results: Prec@1 85.168 Prec@5 96.823 Loss 3.41719\n",
            "val Class Accuracy: [0.815,0.945,0.872,0.850,0.889,0.880,0.774,0.798,0.843,0.616]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [73][0/66], lr: 0.01000\tTime 0.621 (0.621)\tData 0.551 (0.551)\tLoss 0.4543 (0.4543)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [73][10/66], lr: 0.01000\tTime 0.100 (0.153)\tData 0.000 (0.056)\tLoss 0.4050 (0.4458)\tPrec@1 97.266 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [73][20/66], lr: 0.01000\tTime 0.115 (0.125)\tData 0.005 (0.032)\tLoss 0.3409 (0.4784)\tPrec@1 98.047 (97.414)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [73][30/66], lr: 0.01000\tTime 0.109 (0.118)\tData 0.001 (0.025)\tLoss 0.5736 (0.4934)\tPrec@1 97.266 (97.467)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [73][40/66], lr: 0.01000\tTime 0.083 (0.113)\tData 0.005 (0.021)\tLoss 0.2602 (0.4836)\tPrec@1 98.828 (97.561)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [73][50/66], lr: 0.01000\tTime 0.103 (0.110)\tData 0.000 (0.018)\tLoss 0.4064 (0.4931)\tPrec@1 97.656 (97.480)\tPrec@5 100.000 (99.954)\n",
            "Epoch: [73][60/66], lr: 0.01000\tTime 0.055 (0.108)\tData 0.000 (0.017)\tLoss 0.5913 (0.4947)\tPrec@1 96.484 (97.426)\tPrec@5 100.000 (99.949)\n",
            "Test: [0/261]\tTime 0.278 (0.278)\tLoss 4.1743 (4.1743)\tPrec@1 84.000 (84.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.034 (0.060)\tLoss 5.1223 (4.5872)\tPrec@1 80.000 (80.091)\tPrec@5 96.000 (96.182)\n",
            "Test: [20/261]\tTime 0.010 (0.042)\tLoss 4.8106 (4.5065)\tPrec@1 80.000 (80.667)\tPrec@5 94.000 (96.476)\n",
            "Test: [30/261]\tTime 0.018 (0.037)\tLoss 4.0985 (4.2974)\tPrec@1 82.000 (81.581)\tPrec@5 95.000 (96.774)\n",
            "Test: [40/261]\tTime 0.024 (0.034)\tLoss 3.4239 (4.2507)\tPrec@1 86.000 (81.829)\tPrec@5 98.000 (96.951)\n",
            "Test: [50/261]\tTime 0.035 (0.032)\tLoss 3.3305 (4.1999)\tPrec@1 87.000 (82.020)\tPrec@5 97.000 (96.824)\n",
            "Test: [60/261]\tTime 0.024 (0.032)\tLoss 5.2701 (4.1770)\tPrec@1 79.000 (82.098)\tPrec@5 92.000 (96.689)\n",
            "Test: [70/261]\tTime 0.019 (0.030)\tLoss 4.3037 (4.1646)\tPrec@1 78.000 (82.141)\tPrec@5 95.000 (96.676)\n",
            "Test: [80/261]\tTime 0.028 (0.030)\tLoss 5.5332 (4.1913)\tPrec@1 74.000 (81.877)\tPrec@5 96.000 (96.691)\n",
            "Test: [90/261]\tTime 0.029 (0.029)\tLoss 4.5373 (4.2325)\tPrec@1 82.000 (81.725)\tPrec@5 95.000 (96.582)\n",
            "Test: [100/261]\tTime 0.025 (0.029)\tLoss 5.1541 (4.2136)\tPrec@1 76.000 (81.723)\tPrec@5 94.000 (96.594)\n",
            "Test: [110/261]\tTime 0.042 (0.029)\tLoss 5.1358 (4.2096)\tPrec@1 79.000 (81.829)\tPrec@5 94.000 (96.613)\n",
            "Test: [120/261]\tTime 0.042 (0.029)\tLoss 3.2231 (4.1854)\tPrec@1 86.000 (81.934)\tPrec@5 97.000 (96.612)\n",
            "Test: [130/261]\tTime 0.015 (0.029)\tLoss 4.0588 (4.1626)\tPrec@1 82.000 (81.992)\tPrec@5 94.000 (96.588)\n",
            "Test: [140/261]\tTime 0.030 (0.029)\tLoss 4.4142 (4.1317)\tPrec@1 81.000 (82.113)\tPrec@5 99.000 (96.645)\n",
            "Test: [150/261]\tTime 0.036 (0.028)\tLoss 3.6396 (4.1217)\tPrec@1 85.000 (82.146)\tPrec@5 96.000 (96.669)\n",
            "Test: [160/261]\tTime 0.027 (0.028)\tLoss 2.6015 (4.1082)\tPrec@1 87.000 (82.143)\tPrec@5 99.000 (96.739)\n",
            "Test: [170/261]\tTime 0.044 (0.029)\tLoss 3.9736 (4.0870)\tPrec@1 81.000 (82.234)\tPrec@5 99.000 (96.772)\n",
            "Test: [180/261]\tTime 0.044 (0.029)\tLoss 3.4603 (4.0851)\tPrec@1 87.000 (82.221)\tPrec@5 95.000 (96.757)\n",
            "Test: [190/261]\tTime 0.048 (0.029)\tLoss 2.9606 (4.0792)\tPrec@1 86.000 (82.209)\tPrec@5 98.000 (96.812)\n",
            "Test: [200/261]\tTime 0.051 (0.029)\tLoss 4.2896 (4.0921)\tPrec@1 80.000 (82.104)\tPrec@5 96.000 (96.776)\n",
            "Test: [210/261]\tTime 0.025 (0.029)\tLoss 3.1257 (4.0705)\tPrec@1 87.000 (82.237)\tPrec@5 99.000 (96.810)\n",
            "Test: [220/261]\tTime 0.039 (0.029)\tLoss 4.6616 (4.0708)\tPrec@1 76.000 (82.199)\tPrec@5 95.000 (96.805)\n",
            "Test: [230/261]\tTime 0.021 (0.029)\tLoss 4.5639 (4.0753)\tPrec@1 80.000 (82.186)\tPrec@5 95.000 (96.779)\n",
            "Test: [240/261]\tTime 0.021 (0.029)\tLoss 3.8669 (4.0794)\tPrec@1 83.000 (82.166)\tPrec@5 98.000 (96.776)\n",
            "Test: [250/261]\tTime 0.033 (0.029)\tLoss 2.9455 (4.0660)\tPrec@1 88.000 (82.227)\tPrec@5 97.000 (96.801)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 3.3237 (4.0699)\tPrec@1 87.500 (82.218)\tPrec@5 96.875 (96.785)\n",
            "val Results: Prec@1 82.218 Prec@5 96.785 Loss 4.06990\n",
            "val Class Accuracy: [0.736,0.914,0.909,0.851,0.936,0.660,0.790,0.602,0.813,0.735]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [74][0/66], lr: 0.01000\tTime 0.505 (0.505)\tData 0.390 (0.390)\tLoss 0.6791 (0.6791)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [74][10/66], lr: 0.01000\tTime 0.096 (0.152)\tData 0.005 (0.052)\tLoss 0.6233 (0.6192)\tPrec@1 97.266 (96.733)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [74][20/66], lr: 0.01000\tTime 0.099 (0.129)\tData 0.000 (0.030)\tLoss 0.4602 (0.5931)\tPrec@1 97.266 (96.912)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [74][30/66], lr: 0.01000\tTime 0.068 (0.118)\tData 0.005 (0.022)\tLoss 0.8520 (0.5852)\tPrec@1 94.531 (96.976)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [74][40/66], lr: 0.01000\tTime 0.104 (0.114)\tData 0.005 (0.019)\tLoss 0.3220 (0.5803)\tPrec@1 98.047 (97.008)\tPrec@5 100.000 (99.943)\n",
            "Epoch: [74][50/66], lr: 0.01000\tTime 0.097 (0.111)\tData 0.007 (0.017)\tLoss 0.5012 (0.5728)\tPrec@1 97.656 (97.082)\tPrec@5 100.000 (99.931)\n",
            "Epoch: [74][60/66], lr: 0.01000\tTime 0.094 (0.108)\tData 0.000 (0.014)\tLoss 0.4707 (0.5671)\tPrec@1 98.047 (97.125)\tPrec@5 100.000 (99.936)\n",
            "Test: [0/261]\tTime 0.340 (0.340)\tLoss 4.6483 (4.6483)\tPrec@1 82.000 (82.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.012 (0.055)\tLoss 5.3070 (4.3646)\tPrec@1 77.000 (81.636)\tPrec@5 95.000 (95.182)\n",
            "Test: [20/261]\tTime 0.031 (0.041)\tLoss 5.5059 (4.5198)\tPrec@1 76.000 (80.762)\tPrec@5 92.000 (95.286)\n",
            "Test: [30/261]\tTime 0.041 (0.038)\tLoss 4.2585 (4.2999)\tPrec@1 79.000 (81.613)\tPrec@5 96.000 (95.613)\n",
            "Test: [40/261]\tTime 0.024 (0.035)\tLoss 3.0998 (4.2024)\tPrec@1 89.000 (82.195)\tPrec@5 95.000 (95.927)\n",
            "Test: [50/261]\tTime 0.041 (0.033)\tLoss 4.2853 (4.1398)\tPrec@1 79.000 (82.373)\tPrec@5 97.000 (96.039)\n",
            "Test: [60/261]\tTime 0.025 (0.032)\tLoss 4.6967 (4.1512)\tPrec@1 80.000 (82.295)\tPrec@5 94.000 (95.918)\n",
            "Test: [70/261]\tTime 0.049 (0.032)\tLoss 5.6814 (4.1508)\tPrec@1 77.000 (82.324)\tPrec@5 92.000 (95.915)\n",
            "Test: [80/261]\tTime 0.017 (0.030)\tLoss 4.7465 (4.1873)\tPrec@1 78.000 (82.000)\tPrec@5 95.000 (95.951)\n",
            "Test: [90/261]\tTime 0.028 (0.030)\tLoss 4.8578 (4.2610)\tPrec@1 82.000 (81.791)\tPrec@5 94.000 (95.901)\n",
            "Test: [100/261]\tTime 0.016 (0.030)\tLoss 4.0425 (4.2533)\tPrec@1 83.000 (81.851)\tPrec@5 95.000 (96.030)\n",
            "Test: [110/261]\tTime 0.011 (0.030)\tLoss 3.8960 (4.2124)\tPrec@1 83.000 (81.964)\tPrec@5 96.000 (96.108)\n",
            "Test: [120/261]\tTime 0.028 (0.030)\tLoss 4.2060 (4.2196)\tPrec@1 83.000 (81.942)\tPrec@5 95.000 (96.058)\n",
            "Test: [130/261]\tTime 0.016 (0.030)\tLoss 4.2323 (4.2265)\tPrec@1 85.000 (81.878)\tPrec@5 94.000 (96.084)\n",
            "Test: [140/261]\tTime 0.026 (0.029)\tLoss 4.8542 (4.2201)\tPrec@1 79.000 (81.858)\tPrec@5 93.000 (96.099)\n",
            "Test: [150/261]\tTime 0.035 (0.029)\tLoss 3.4992 (4.2263)\tPrec@1 85.000 (81.887)\tPrec@5 97.000 (96.073)\n",
            "Test: [160/261]\tTime 0.033 (0.029)\tLoss 3.0363 (4.2144)\tPrec@1 86.000 (81.901)\tPrec@5 97.000 (96.118)\n",
            "Test: [170/261]\tTime 0.018 (0.029)\tLoss 4.2312 (4.2055)\tPrec@1 80.000 (81.936)\tPrec@5 96.000 (96.152)\n",
            "Test: [180/261]\tTime 0.028 (0.029)\tLoss 3.6371 (4.2025)\tPrec@1 86.000 (81.961)\tPrec@5 95.000 (96.155)\n",
            "Test: [190/261]\tTime 0.062 (0.029)\tLoss 4.0052 (4.1977)\tPrec@1 84.000 (81.963)\tPrec@5 94.000 (96.168)\n",
            "Test: [200/261]\tTime 0.030 (0.030)\tLoss 4.0629 (4.1920)\tPrec@1 82.000 (81.945)\tPrec@5 98.000 (96.194)\n",
            "Test: [210/261]\tTime 0.056 (0.030)\tLoss 3.2253 (4.1862)\tPrec@1 84.000 (81.943)\tPrec@5 98.000 (96.213)\n",
            "Test: [220/261]\tTime 0.058 (0.030)\tLoss 5.8992 (4.1938)\tPrec@1 76.000 (81.882)\tPrec@5 94.000 (96.231)\n",
            "Test: [230/261]\tTime 0.051 (0.031)\tLoss 5.1849 (4.2027)\tPrec@1 79.000 (81.818)\tPrec@5 94.000 (96.229)\n",
            "Test: [240/261]\tTime 0.018 (0.031)\tLoss 4.3004 (4.2197)\tPrec@1 81.000 (81.747)\tPrec@5 96.000 (96.191)\n",
            "Test: [250/261]\tTime 0.043 (0.032)\tLoss 3.6221 (4.1995)\tPrec@1 84.000 (81.813)\tPrec@5 96.000 (96.215)\n",
            "Test: [260/261]\tTime 0.007 (0.031)\tLoss 3.6779 (4.2034)\tPrec@1 84.375 (81.803)\tPrec@5 100.000 (96.212)\n",
            "val Results: Prec@1 81.803 Prec@5 96.212 Loss 4.20342\n",
            "val Class Accuracy: [0.759,0.986,0.921,0.874,0.741,0.826,0.660,0.616,0.703,0.656]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [75][0/66], lr: 0.01000\tTime 0.994 (0.994)\tData 0.849 (0.849)\tLoss 0.4924 (0.4924)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [75][10/66], lr: 0.01000\tTime 0.105 (0.189)\tData 0.000 (0.086)\tLoss 0.6119 (0.5463)\tPrec@1 96.484 (97.124)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [75][20/66], lr: 0.01000\tTime 0.094 (0.147)\tData 0.009 (0.054)\tLoss 0.4344 (0.5463)\tPrec@1 97.266 (97.154)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [75][30/66], lr: 0.01000\tTime 0.099 (0.131)\tData 0.001 (0.040)\tLoss 0.7428 (0.5396)\tPrec@1 96.875 (97.266)\tPrec@5 99.609 (99.924)\n",
            "Epoch: [75][40/66], lr: 0.01000\tTime 0.080 (0.124)\tData 0.010 (0.033)\tLoss 0.6085 (0.5685)\tPrec@1 96.484 (97.151)\tPrec@5 100.000 (99.914)\n",
            "Epoch: [75][50/66], lr: 0.01000\tTime 0.098 (0.118)\tData 0.008 (0.028)\tLoss 0.4746 (0.5491)\tPrec@1 97.266 (97.227)\tPrec@5 99.609 (99.908)\n",
            "Epoch: [75][60/66], lr: 0.01000\tTime 0.067 (0.114)\tData 0.000 (0.024)\tLoss 0.3904 (0.5541)\tPrec@1 97.656 (97.208)\tPrec@5 100.000 (99.910)\n",
            "Test: [0/261]\tTime 0.277 (0.277)\tLoss 5.9936 (5.9936)\tPrec@1 75.000 (75.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.021 (0.054)\tLoss 5.5782 (6.2027)\tPrec@1 78.000 (74.091)\tPrec@5 94.000 (91.727)\n",
            "Test: [20/261]\tTime 0.032 (0.044)\tLoss 6.3504 (6.1983)\tPrec@1 72.000 (74.048)\tPrec@5 94.000 (92.095)\n",
            "Test: [30/261]\tTime 0.041 (0.037)\tLoss 4.2383 (5.9910)\tPrec@1 82.000 (75.290)\tPrec@5 95.000 (92.258)\n",
            "Test: [40/261]\tTime 0.033 (0.035)\tLoss 4.7940 (5.8580)\tPrec@1 82.000 (75.927)\tPrec@5 94.000 (92.683)\n",
            "Test: [50/261]\tTime 0.015 (0.033)\tLoss 4.8952 (5.7592)\tPrec@1 83.000 (76.373)\tPrec@5 90.000 (92.725)\n",
            "Test: [60/261]\tTime 0.028 (0.032)\tLoss 8.2959 (5.7379)\tPrec@1 67.000 (76.393)\tPrec@5 87.000 (92.705)\n",
            "Test: [70/261]\tTime 0.020 (0.031)\tLoss 6.2073 (5.7231)\tPrec@1 73.000 (76.394)\tPrec@5 90.000 (92.704)\n",
            "Test: [80/261]\tTime 0.030 (0.031)\tLoss 5.1707 (5.7356)\tPrec@1 81.000 (76.420)\tPrec@5 92.000 (92.728)\n",
            "Test: [90/261]\tTime 0.017 (0.030)\tLoss 5.5184 (5.7786)\tPrec@1 78.000 (76.363)\tPrec@5 91.000 (92.626)\n",
            "Test: [100/261]\tTime 0.021 (0.030)\tLoss 7.1584 (5.7849)\tPrec@1 70.000 (76.257)\tPrec@5 91.000 (92.644)\n",
            "Test: [110/261]\tTime 0.018 (0.029)\tLoss 5.4373 (5.7781)\tPrec@1 78.000 (76.261)\tPrec@5 95.000 (92.658)\n",
            "Test: [120/261]\tTime 0.027 (0.029)\tLoss 4.1408 (5.7645)\tPrec@1 82.000 (76.314)\tPrec@5 96.000 (92.636)\n",
            "Test: [130/261]\tTime 0.018 (0.029)\tLoss 6.6188 (5.7465)\tPrec@1 71.000 (76.328)\tPrec@5 91.000 (92.710)\n",
            "Test: [140/261]\tTime 0.027 (0.028)\tLoss 7.6220 (5.7607)\tPrec@1 69.000 (76.319)\tPrec@5 91.000 (92.738)\n",
            "Test: [150/261]\tTime 0.036 (0.028)\tLoss 4.7281 (5.7560)\tPrec@1 83.000 (76.371)\tPrec@5 94.000 (92.755)\n",
            "Test: [160/261]\tTime 0.037 (0.028)\tLoss 5.0661 (5.7759)\tPrec@1 81.000 (76.280)\tPrec@5 92.000 (92.720)\n",
            "Test: [170/261]\tTime 0.032 (0.028)\tLoss 5.3522 (5.7435)\tPrec@1 75.000 (76.380)\tPrec@5 92.000 (92.743)\n",
            "Test: [180/261]\tTime 0.041 (0.028)\tLoss 4.9931 (5.7444)\tPrec@1 80.000 (76.370)\tPrec@5 93.000 (92.740)\n",
            "Test: [190/261]\tTime 0.019 (0.028)\tLoss 4.8722 (5.7282)\tPrec@1 79.000 (76.419)\tPrec@5 92.000 (92.764)\n",
            "Test: [200/261]\tTime 0.023 (0.028)\tLoss 6.0863 (5.7368)\tPrec@1 73.000 (76.368)\tPrec@5 93.000 (92.746)\n",
            "Test: [210/261]\tTime 0.019 (0.028)\tLoss 5.7353 (5.7172)\tPrec@1 76.000 (76.441)\tPrec@5 94.000 (92.787)\n",
            "Test: [220/261]\tTime 0.030 (0.028)\tLoss 6.3487 (5.7078)\tPrec@1 74.000 (76.439)\tPrec@5 93.000 (92.851)\n",
            "Test: [230/261]\tTime 0.010 (0.028)\tLoss 6.5874 (5.7150)\tPrec@1 73.000 (76.381)\tPrec@5 88.000 (92.844)\n",
            "Test: [240/261]\tTime 0.038 (0.028)\tLoss 6.0726 (5.7134)\tPrec@1 76.000 (76.361)\tPrec@5 90.000 (92.822)\n",
            "Test: [250/261]\tTime 0.034 (0.028)\tLoss 5.3043 (5.6814)\tPrec@1 81.000 (76.518)\tPrec@5 92.000 (92.873)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 4.0030 (5.6767)\tPrec@1 84.375 (76.525)\tPrec@5 93.750 (92.866)\n",
            "val Results: Prec@1 76.525 Prec@5 92.866 Loss 5.67672\n",
            "val Class Accuracy: [0.239,0.842,0.956,0.734,0.909,0.929,0.698,0.637,0.689,0.509]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [76][0/66], lr: 0.01000\tTime 0.638 (0.638)\tData 0.520 (0.520)\tLoss 0.8298 (0.8298)\tPrec@1 96.875 (96.875)\tPrec@5 98.828 (98.828)\n",
            "Epoch: [76][10/66], lr: 0.01000\tTime 0.131 (0.154)\tData 0.009 (0.052)\tLoss 0.1216 (0.5203)\tPrec@1 99.609 (97.479)\tPrec@5 100.000 (99.858)\n",
            "Epoch: [76][20/66], lr: 0.01000\tTime 0.108 (0.129)\tData 0.003 (0.029)\tLoss 0.5311 (0.5082)\tPrec@1 97.656 (97.489)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [76][30/66], lr: 0.01000\tTime 0.136 (0.122)\tData 0.000 (0.021)\tLoss 0.9991 (0.5467)\tPrec@1 95.312 (97.303)\tPrec@5 99.609 (99.924)\n",
            "Epoch: [76][40/66], lr: 0.01000\tTime 0.105 (0.117)\tData 0.000 (0.017)\tLoss 0.4307 (0.5106)\tPrec@1 98.047 (97.504)\tPrec@5 99.609 (99.914)\n",
            "Epoch: [76][50/66], lr: 0.01000\tTime 0.098 (0.113)\tData 0.000 (0.015)\tLoss 0.4932 (0.4985)\tPrec@1 97.656 (97.557)\tPrec@5 100.000 (99.916)\n",
            "Epoch: [76][60/66], lr: 0.01000\tTime 0.076 (0.110)\tData 0.000 (0.014)\tLoss 0.6086 (0.5097)\tPrec@1 97.266 (97.483)\tPrec@5 99.609 (99.917)\n",
            "Test: [0/261]\tTime 0.277 (0.277)\tLoss 3.7944 (3.7944)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.021 (0.058)\tLoss 3.9742 (3.9828)\tPrec@1 82.000 (82.545)\tPrec@5 97.000 (96.818)\n",
            "Test: [20/261]\tTime 0.030 (0.045)\tLoss 3.5293 (3.9873)\tPrec@1 85.000 (82.286)\tPrec@5 96.000 (96.095)\n",
            "Test: [30/261]\tTime 0.037 (0.039)\tLoss 3.6141 (3.8333)\tPrec@1 83.000 (83.065)\tPrec@5 96.000 (96.355)\n",
            "Test: [40/261]\tTime 0.019 (0.036)\tLoss 2.8564 (3.7487)\tPrec@1 90.000 (83.512)\tPrec@5 96.000 (96.561)\n",
            "Test: [50/261]\tTime 0.033 (0.034)\tLoss 2.3724 (3.7062)\tPrec@1 93.000 (83.627)\tPrec@5 97.000 (96.627)\n",
            "Test: [60/261]\tTime 0.012 (0.032)\tLoss 3.7064 (3.7004)\tPrec@1 85.000 (83.689)\tPrec@5 94.000 (96.574)\n",
            "Test: [70/261]\tTime 0.024 (0.032)\tLoss 3.7469 (3.6874)\tPrec@1 84.000 (83.845)\tPrec@5 96.000 (96.563)\n",
            "Test: [80/261]\tTime 0.011 (0.031)\tLoss 3.4884 (3.7012)\tPrec@1 86.000 (83.716)\tPrec@5 97.000 (96.593)\n",
            "Test: [90/261]\tTime 0.038 (0.031)\tLoss 3.7618 (3.7391)\tPrec@1 86.000 (83.538)\tPrec@5 96.000 (96.462)\n",
            "Test: [100/261]\tTime 0.022 (0.031)\tLoss 5.2250 (3.7282)\tPrec@1 76.000 (83.554)\tPrec@5 92.000 (96.455)\n",
            "Test: [110/261]\tTime 0.037 (0.030)\tLoss 4.7859 (3.7283)\tPrec@1 78.000 (83.514)\tPrec@5 95.000 (96.523)\n",
            "Test: [120/261]\tTime 0.033 (0.030)\tLoss 3.8009 (3.7157)\tPrec@1 83.000 (83.504)\tPrec@5 95.000 (96.512)\n",
            "Test: [130/261]\tTime 0.045 (0.030)\tLoss 3.8873 (3.7143)\tPrec@1 84.000 (83.496)\tPrec@5 94.000 (96.496)\n",
            "Test: [140/261]\tTime 0.036 (0.030)\tLoss 4.2784 (3.7024)\tPrec@1 81.000 (83.532)\tPrec@5 96.000 (96.511)\n",
            "Test: [150/261]\tTime 0.010 (0.029)\tLoss 3.7002 (3.7100)\tPrec@1 83.000 (83.556)\tPrec@5 97.000 (96.530)\n",
            "Test: [160/261]\tTime 0.014 (0.029)\tLoss 2.5610 (3.7091)\tPrec@1 88.000 (83.547)\tPrec@5 99.000 (96.565)\n",
            "Test: [170/261]\tTime 0.040 (0.029)\tLoss 2.7576 (3.6830)\tPrec@1 86.000 (83.661)\tPrec@5 95.000 (96.602)\n",
            "Test: [180/261]\tTime 0.023 (0.029)\tLoss 3.2015 (3.6785)\tPrec@1 88.000 (83.674)\tPrec@5 95.000 (96.586)\n",
            "Test: [190/261]\tTime 0.028 (0.029)\tLoss 3.4922 (3.6707)\tPrec@1 83.000 (83.712)\tPrec@5 98.000 (96.602)\n",
            "Test: [200/261]\tTime 0.017 (0.029)\tLoss 3.5201 (3.6662)\tPrec@1 83.000 (83.682)\tPrec@5 98.000 (96.622)\n",
            "Test: [210/261]\tTime 0.016 (0.029)\tLoss 3.3646 (3.6572)\tPrec@1 83.000 (83.735)\tPrec@5 98.000 (96.630)\n",
            "Test: [220/261]\tTime 0.017 (0.028)\tLoss 3.8058 (3.6577)\tPrec@1 84.000 (83.724)\tPrec@5 97.000 (96.611)\n",
            "Test: [230/261]\tTime 0.018 (0.028)\tLoss 4.9630 (3.6724)\tPrec@1 81.000 (83.662)\tPrec@5 94.000 (96.615)\n",
            "Test: [240/261]\tTime 0.044 (0.028)\tLoss 3.8683 (3.6844)\tPrec@1 82.000 (83.631)\tPrec@5 96.000 (96.581)\n",
            "Test: [250/261]\tTime 0.033 (0.028)\tLoss 3.3185 (3.6646)\tPrec@1 84.000 (83.689)\tPrec@5 96.000 (96.614)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.8787 (3.6771)\tPrec@1 84.375 (83.628)\tPrec@5 100.000 (96.600)\n",
            "val Results: Prec@1 83.628 Prec@5 96.600 Loss 3.67710\n",
            "val Class Accuracy: [0.852,0.939,0.908,0.888,0.806,0.742,0.826,0.760,0.745,0.603]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [77][0/66], lr: 0.01000\tTime 0.663 (0.663)\tData 0.577 (0.577)\tLoss 0.5400 (0.5400)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [77][10/66], lr: 0.01000\tTime 0.087 (0.155)\tData 0.006 (0.059)\tLoss 0.5504 (0.5116)\tPrec@1 97.266 (97.408)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [77][20/66], lr: 0.01000\tTime 0.083 (0.130)\tData 0.005 (0.034)\tLoss 0.4963 (0.5013)\tPrec@1 96.875 (97.396)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [77][30/66], lr: 0.01000\tTime 0.106 (0.120)\tData 0.000 (0.025)\tLoss 0.5018 (0.5064)\tPrec@1 97.266 (97.341)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [77][40/66], lr: 0.01000\tTime 0.081 (0.115)\tData 0.000 (0.020)\tLoss 0.5990 (0.5250)\tPrec@1 96.484 (97.304)\tPrec@5 99.609 (99.905)\n",
            "Epoch: [77][50/66], lr: 0.01000\tTime 0.106 (0.112)\tData 0.005 (0.018)\tLoss 0.6816 (0.5164)\tPrec@1 97.266 (97.365)\tPrec@5 99.219 (99.893)\n",
            "Epoch: [77][60/66], lr: 0.01000\tTime 0.068 (0.108)\tData 0.000 (0.016)\tLoss 0.3446 (0.5092)\tPrec@1 98.828 (97.413)\tPrec@5 100.000 (99.898)\n",
            "Test: [0/261]\tTime 0.266 (0.266)\tLoss 5.5239 (5.5239)\tPrec@1 77.000 (77.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.016 (0.059)\tLoss 5.1118 (4.8157)\tPrec@1 75.000 (78.455)\tPrec@5 96.000 (95.364)\n",
            "Test: [20/261]\tTime 0.038 (0.044)\tLoss 5.5905 (4.6809)\tPrec@1 74.000 (79.000)\tPrec@5 93.000 (95.333)\n",
            "Test: [30/261]\tTime 0.024 (0.038)\tLoss 4.0371 (4.4567)\tPrec@1 85.000 (80.000)\tPrec@5 96.000 (95.710)\n",
            "Test: [40/261]\tTime 0.037 (0.035)\tLoss 3.0899 (4.2509)\tPrec@1 87.000 (81.146)\tPrec@5 95.000 (95.976)\n",
            "Test: [50/261]\tTime 0.014 (0.034)\tLoss 4.3907 (4.2459)\tPrec@1 78.000 (81.255)\tPrec@5 97.000 (95.922)\n",
            "Test: [60/261]\tTime 0.035 (0.033)\tLoss 3.8037 (4.2058)\tPrec@1 82.000 (81.459)\tPrec@5 98.000 (95.918)\n",
            "Test: [70/261]\tTime 0.034 (0.032)\tLoss 4.9211 (4.2029)\tPrec@1 81.000 (81.507)\tPrec@5 93.000 (96.014)\n",
            "Test: [80/261]\tTime 0.029 (0.031)\tLoss 3.9225 (4.2568)\tPrec@1 83.000 (81.333)\tPrec@5 95.000 (95.951)\n",
            "Test: [90/261]\tTime 0.017 (0.030)\tLoss 3.9534 (4.2930)\tPrec@1 81.000 (81.187)\tPrec@5 94.000 (95.846)\n",
            "Test: [100/261]\tTime 0.024 (0.030)\tLoss 3.8752 (4.2692)\tPrec@1 84.000 (81.248)\tPrec@5 95.000 (95.891)\n",
            "Test: [110/261]\tTime 0.011 (0.030)\tLoss 4.5396 (4.2545)\tPrec@1 79.000 (81.243)\tPrec@5 93.000 (95.883)\n",
            "Test: [120/261]\tTime 0.021 (0.029)\tLoss 3.9099 (4.2397)\tPrec@1 82.000 (81.331)\tPrec@5 92.000 (95.785)\n",
            "Test: [130/261]\tTime 0.028 (0.029)\tLoss 3.6971 (4.2391)\tPrec@1 85.000 (81.313)\tPrec@5 94.000 (95.763)\n",
            "Test: [140/261]\tTime 0.013 (0.029)\tLoss 5.9142 (4.2677)\tPrec@1 70.000 (81.135)\tPrec@5 95.000 (95.823)\n",
            "Test: [150/261]\tTime 0.017 (0.029)\tLoss 3.2501 (4.2452)\tPrec@1 86.000 (81.265)\tPrec@5 98.000 (95.854)\n",
            "Test: [160/261]\tTime 0.017 (0.029)\tLoss 4.2650 (4.2395)\tPrec@1 80.000 (81.255)\tPrec@5 97.000 (95.870)\n",
            "Test: [170/261]\tTime 0.017 (0.029)\tLoss 4.0389 (4.2132)\tPrec@1 83.000 (81.351)\tPrec@5 96.000 (95.901)\n",
            "Test: [180/261]\tTime 0.029 (0.028)\tLoss 4.4184 (4.2111)\tPrec@1 81.000 (81.420)\tPrec@5 92.000 (95.890)\n",
            "Test: [190/261]\tTime 0.010 (0.028)\tLoss 4.8602 (4.2054)\tPrec@1 76.000 (81.414)\tPrec@5 95.000 (95.932)\n",
            "Test: [200/261]\tTime 0.036 (0.028)\tLoss 3.5364 (4.1946)\tPrec@1 82.000 (81.423)\tPrec@5 97.000 (95.915)\n",
            "Test: [210/261]\tTime 0.029 (0.029)\tLoss 4.3574 (4.1795)\tPrec@1 78.000 (81.507)\tPrec@5 98.000 (95.934)\n",
            "Test: [220/261]\tTime 0.017 (0.029)\tLoss 4.1854 (4.1870)\tPrec@1 81.000 (81.471)\tPrec@5 96.000 (95.923)\n",
            "Test: [230/261]\tTime 0.041 (0.030)\tLoss 4.3131 (4.1799)\tPrec@1 82.000 (81.493)\tPrec@5 94.000 (95.926)\n",
            "Test: [240/261]\tTime 0.047 (0.030)\tLoss 3.1367 (4.1921)\tPrec@1 85.000 (81.461)\tPrec@5 95.000 (95.892)\n",
            "Test: [250/261]\tTime 0.039 (0.031)\tLoss 3.0595 (4.1574)\tPrec@1 85.000 (81.570)\tPrec@5 98.000 (95.960)\n",
            "Test: [260/261]\tTime 0.008 (0.030)\tLoss 3.9397 (4.1646)\tPrec@1 84.375 (81.580)\tPrec@5 96.875 (95.940)\n",
            "val Results: Prec@1 81.580 Prec@5 95.940 Loss 4.16461\n",
            "val Class Accuracy: [0.763,0.973,0.750,0.896,0.795,0.860,0.564,0.911,0.689,0.687]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [78][0/66], lr: 0.01000\tTime 0.978 (0.978)\tData 0.844 (0.844)\tLoss 0.5466 (0.5466)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [78][10/66], lr: 0.01000\tTime 0.093 (0.202)\tData 0.005 (0.095)\tLoss 0.2428 (0.4852)\tPrec@1 99.219 (97.337)\tPrec@5 100.000 (99.893)\n",
            "Epoch: [78][20/66], lr: 0.01000\tTime 0.115 (0.156)\tData 0.016 (0.058)\tLoss 0.4948 (0.4791)\tPrec@1 97.656 (97.507)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [78][30/66], lr: 0.01000\tTime 0.088 (0.137)\tData 0.000 (0.040)\tLoss 0.6775 (0.4749)\tPrec@1 97.266 (97.631)\tPrec@5 99.609 (99.912)\n",
            "Epoch: [78][40/66], lr: 0.01000\tTime 0.111 (0.131)\tData 0.000 (0.034)\tLoss 0.3726 (0.4635)\tPrec@1 97.656 (97.685)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [78][50/66], lr: 0.01000\tTime 0.094 (0.124)\tData 0.000 (0.028)\tLoss 0.4786 (0.4699)\tPrec@1 98.047 (97.649)\tPrec@5 100.000 (99.931)\n",
            "Epoch: [78][60/66], lr: 0.01000\tTime 0.056 (0.120)\tData 0.000 (0.024)\tLoss 0.5547 (0.4879)\tPrec@1 97.266 (97.586)\tPrec@5 99.609 (99.930)\n",
            "Test: [0/261]\tTime 0.355 (0.355)\tLoss 3.2272 (3.2272)\tPrec@1 88.000 (88.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.021 (0.056)\tLoss 4.3615 (3.8102)\tPrec@1 82.000 (83.636)\tPrec@5 97.000 (96.364)\n",
            "Test: [20/261]\tTime 0.027 (0.042)\tLoss 4.8566 (3.7747)\tPrec@1 78.000 (83.571)\tPrec@5 95.000 (96.333)\n",
            "Test: [30/261]\tTime 0.041 (0.037)\tLoss 2.7462 (3.5285)\tPrec@1 89.000 (84.742)\tPrec@5 97.000 (96.581)\n",
            "Test: [40/261]\tTime 0.016 (0.034)\tLoss 2.4808 (3.4406)\tPrec@1 89.000 (85.098)\tPrec@5 95.000 (96.683)\n",
            "Test: [50/261]\tTime 0.042 (0.033)\tLoss 3.2001 (3.4017)\tPrec@1 87.000 (85.353)\tPrec@5 98.000 (96.706)\n",
            "Test: [60/261]\tTime 0.043 (0.032)\tLoss 4.1177 (3.4341)\tPrec@1 84.000 (85.344)\tPrec@5 95.000 (96.541)\n",
            "Test: [70/261]\tTime 0.052 (0.032)\tLoss 3.7768 (3.4147)\tPrec@1 86.000 (85.451)\tPrec@5 95.000 (96.592)\n",
            "Test: [80/261]\tTime 0.037 (0.031)\tLoss 3.5535 (3.4161)\tPrec@1 87.000 (85.481)\tPrec@5 95.000 (96.580)\n",
            "Test: [90/261]\tTime 0.011 (0.030)\tLoss 2.4529 (3.4689)\tPrec@1 92.000 (85.319)\tPrec@5 96.000 (96.418)\n",
            "Test: [100/261]\tTime 0.027 (0.030)\tLoss 5.2041 (3.4615)\tPrec@1 77.000 (85.317)\tPrec@5 94.000 (96.446)\n",
            "Test: [110/261]\tTime 0.038 (0.030)\tLoss 3.8940 (3.4379)\tPrec@1 83.000 (85.324)\tPrec@5 92.000 (96.495)\n",
            "Test: [120/261]\tTime 0.031 (0.030)\tLoss 2.7672 (3.4406)\tPrec@1 88.000 (85.273)\tPrec@5 96.000 (96.488)\n",
            "Test: [130/261]\tTime 0.038 (0.029)\tLoss 3.3921 (3.4408)\tPrec@1 87.000 (85.282)\tPrec@5 95.000 (96.519)\n",
            "Test: [140/261]\tTime 0.015 (0.029)\tLoss 4.0976 (3.4470)\tPrec@1 83.000 (85.234)\tPrec@5 96.000 (96.525)\n",
            "Test: [150/261]\tTime 0.038 (0.029)\tLoss 2.5304 (3.4330)\tPrec@1 90.000 (85.325)\tPrec@5 97.000 (96.536)\n",
            "Test: [160/261]\tTime 0.028 (0.029)\tLoss 2.5309 (3.4301)\tPrec@1 90.000 (85.273)\tPrec@5 99.000 (96.590)\n",
            "Test: [170/261]\tTime 0.025 (0.028)\tLoss 3.2200 (3.4050)\tPrec@1 85.000 (85.363)\tPrec@5 95.000 (96.643)\n",
            "Test: [180/261]\tTime 0.023 (0.028)\tLoss 3.4505 (3.3979)\tPrec@1 85.000 (85.387)\tPrec@5 96.000 (96.669)\n",
            "Test: [190/261]\tTime 0.012 (0.028)\tLoss 3.9256 (3.3990)\tPrec@1 84.000 (85.403)\tPrec@5 97.000 (96.686)\n",
            "Test: [200/261]\tTime 0.021 (0.028)\tLoss 1.9670 (3.3947)\tPrec@1 89.000 (85.383)\tPrec@5 99.000 (96.652)\n",
            "Test: [210/261]\tTime 0.043 (0.028)\tLoss 3.5718 (3.3947)\tPrec@1 83.000 (85.346)\tPrec@5 98.000 (96.678)\n",
            "Test: [220/261]\tTime 0.037 (0.028)\tLoss 3.5211 (3.3773)\tPrec@1 83.000 (85.407)\tPrec@5 97.000 (96.697)\n",
            "Test: [230/261]\tTime 0.024 (0.028)\tLoss 4.1817 (3.3884)\tPrec@1 83.000 (85.359)\tPrec@5 95.000 (96.701)\n",
            "Test: [240/261]\tTime 0.036 (0.028)\tLoss 2.8602 (3.3875)\tPrec@1 90.000 (85.357)\tPrec@5 99.000 (96.697)\n",
            "Test: [250/261]\tTime 0.041 (0.028)\tLoss 2.6318 (3.3616)\tPrec@1 88.000 (85.462)\tPrec@5 100.000 (96.741)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 2.4064 (3.3661)\tPrec@1 90.625 (85.460)\tPrec@5 96.875 (96.746)\n",
            "val Results: Prec@1 85.460 Prec@5 96.746 Loss 3.36607\n",
            "val Class Accuracy: [0.588,0.932,0.909,0.854,0.903,0.865,0.729,0.902,0.823,0.792]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [79][0/66], lr: 0.01000\tTime 0.518 (0.518)\tData 0.434 (0.434)\tLoss 0.5819 (0.5819)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [79][10/66], lr: 0.01000\tTime 0.102 (0.140)\tData 0.000 (0.051)\tLoss 0.6889 (0.5337)\tPrec@1 95.703 (97.159)\tPrec@5 99.609 (99.964)\n",
            "Epoch: [79][20/66], lr: 0.01000\tTime 0.106 (0.122)\tData 0.005 (0.030)\tLoss 0.5709 (0.5169)\tPrec@1 97.266 (97.414)\tPrec@5 100.000 (99.907)\n",
            "Epoch: [79][30/66], lr: 0.01000\tTime 0.099 (0.115)\tData 0.005 (0.025)\tLoss 0.6373 (0.4907)\tPrec@1 96.875 (97.568)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [79][40/66], lr: 0.01000\tTime 0.096 (0.112)\tData 0.005 (0.020)\tLoss 1.0009 (0.5063)\tPrec@1 95.703 (97.475)\tPrec@5 99.609 (99.886)\n",
            "Epoch: [79][50/66], lr: 0.01000\tTime 0.105 (0.109)\tData 0.005 (0.018)\tLoss 0.6264 (0.5098)\tPrec@1 97.266 (97.426)\tPrec@5 99.609 (99.893)\n",
            "Epoch: [79][60/66], lr: 0.01000\tTime 0.062 (0.107)\tData 0.000 (0.015)\tLoss 0.6935 (0.5250)\tPrec@1 95.703 (97.349)\tPrec@5 100.000 (99.878)\n",
            "Test: [0/261]\tTime 0.332 (0.332)\tLoss 4.5675 (4.5675)\tPrec@1 81.000 (81.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.041 (0.056)\tLoss 5.9342 (5.4110)\tPrec@1 76.000 (77.909)\tPrec@5 90.000 (93.182)\n",
            "Test: [20/261]\tTime 0.029 (0.042)\tLoss 5.6892 (5.1985)\tPrec@1 77.000 (79.000)\tPrec@5 95.000 (93.667)\n",
            "Test: [30/261]\tTime 0.013 (0.036)\tLoss 3.5625 (4.9975)\tPrec@1 85.000 (79.806)\tPrec@5 98.000 (94.129)\n",
            "Test: [40/261]\tTime 0.027 (0.033)\tLoss 3.7572 (4.9095)\tPrec@1 88.000 (80.244)\tPrec@5 94.000 (94.073)\n",
            "Test: [50/261]\tTime 0.032 (0.032)\tLoss 4.6386 (4.8095)\tPrec@1 85.000 (80.745)\tPrec@5 92.000 (94.196)\n",
            "Test: [60/261]\tTime 0.046 (0.031)\tLoss 5.6305 (4.7976)\tPrec@1 78.000 (80.852)\tPrec@5 92.000 (94.164)\n",
            "Test: [70/261]\tTime 0.027 (0.031)\tLoss 5.9863 (4.7735)\tPrec@1 75.000 (80.901)\tPrec@5 90.000 (94.141)\n",
            "Test: [80/261]\tTime 0.020 (0.030)\tLoss 5.1004 (4.7649)\tPrec@1 79.000 (80.914)\tPrec@5 93.000 (94.198)\n",
            "Test: [90/261]\tTime 0.023 (0.029)\tLoss 4.8991 (4.8286)\tPrec@1 84.000 (80.692)\tPrec@5 91.000 (94.143)\n",
            "Test: [100/261]\tTime 0.041 (0.029)\tLoss 5.3404 (4.7989)\tPrec@1 79.000 (80.743)\tPrec@5 94.000 (94.238)\n",
            "Test: [110/261]\tTime 0.041 (0.029)\tLoss 4.5333 (4.7737)\tPrec@1 83.000 (80.829)\tPrec@5 94.000 (94.315)\n",
            "Test: [120/261]\tTime 0.013 (0.029)\tLoss 4.3504 (4.7692)\tPrec@1 80.000 (80.818)\tPrec@5 96.000 (94.289)\n",
            "Test: [130/261]\tTime 0.029 (0.029)\tLoss 4.5875 (4.7476)\tPrec@1 83.000 (80.885)\tPrec@5 92.000 (94.336)\n",
            "Test: [140/261]\tTime 0.031 (0.029)\tLoss 5.4043 (4.7517)\tPrec@1 80.000 (80.844)\tPrec@5 95.000 (94.376)\n",
            "Test: [150/261]\tTime 0.026 (0.029)\tLoss 3.4417 (4.7558)\tPrec@1 84.000 (80.801)\tPrec@5 97.000 (94.404)\n",
            "Test: [160/261]\tTime 0.017 (0.028)\tLoss 3.7008 (4.7578)\tPrec@1 87.000 (80.752)\tPrec@5 97.000 (94.447)\n",
            "Test: [170/261]\tTime 0.035 (0.028)\tLoss 4.1814 (4.7379)\tPrec@1 81.000 (80.854)\tPrec@5 95.000 (94.485)\n",
            "Test: [180/261]\tTime 0.041 (0.028)\tLoss 4.2920 (4.7312)\tPrec@1 83.000 (80.901)\tPrec@5 94.000 (94.492)\n",
            "Test: [190/261]\tTime 0.029 (0.028)\tLoss 4.4049 (4.7247)\tPrec@1 82.000 (80.916)\tPrec@5 96.000 (94.529)\n",
            "Test: [200/261]\tTime 0.056 (0.028)\tLoss 4.2283 (4.7201)\tPrec@1 83.000 (80.915)\tPrec@5 98.000 (94.592)\n",
            "Test: [210/261]\tTime 0.025 (0.028)\tLoss 3.7904 (4.7108)\tPrec@1 83.000 (80.948)\tPrec@5 96.000 (94.592)\n",
            "Test: [220/261]\tTime 0.027 (0.028)\tLoss 5.3728 (4.7124)\tPrec@1 76.000 (80.910)\tPrec@5 96.000 (94.570)\n",
            "Test: [230/261]\tTime 0.034 (0.028)\tLoss 6.0365 (4.7263)\tPrec@1 77.000 (80.844)\tPrec@5 90.000 (94.532)\n",
            "Test: [240/261]\tTime 0.035 (0.028)\tLoss 5.4366 (4.7453)\tPrec@1 78.000 (80.747)\tPrec@5 94.000 (94.519)\n",
            "Test: [250/261]\tTime 0.023 (0.028)\tLoss 3.8079 (4.7185)\tPrec@1 86.000 (80.829)\tPrec@5 97.000 (94.562)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 1.7565 (4.7241)\tPrec@1 93.750 (80.812)\tPrec@5 96.875 (94.530)\n",
            "val Results: Prec@1 80.812 Prec@5 94.530 Loss 4.72412\n",
            "val Class Accuracy: [0.565,0.930,0.930,0.900,0.869,0.855,0.710,0.785,0.588,0.414]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [80][0/66], lr: 0.01000\tTime 0.634 (0.634)\tData 0.543 (0.543)\tLoss 0.5295 (0.5295)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [80][10/66], lr: 0.01000\tTime 0.093 (0.153)\tData 0.004 (0.055)\tLoss 0.5153 (0.4668)\tPrec@1 97.266 (97.585)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [80][20/66], lr: 0.01000\tTime 0.116 (0.129)\tData 0.005 (0.032)\tLoss 0.2265 (0.4966)\tPrec@1 98.828 (97.452)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [80][30/66], lr: 0.01000\tTime 0.104 (0.119)\tData 0.004 (0.023)\tLoss 0.4968 (0.4682)\tPrec@1 97.266 (97.618)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [80][40/66], lr: 0.01000\tTime 0.114 (0.114)\tData 0.000 (0.019)\tLoss 0.4005 (0.4819)\tPrec@1 98.438 (97.590)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [80][50/66], lr: 0.01000\tTime 0.088 (0.110)\tData 0.000 (0.017)\tLoss 0.3649 (0.4945)\tPrec@1 98.047 (97.518)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [80][60/66], lr: 0.01000\tTime 0.071 (0.108)\tData 0.000 (0.015)\tLoss 0.7365 (0.5155)\tPrec@1 95.703 (97.381)\tPrec@5 100.000 (99.936)\n",
            "Test: [0/261]\tTime 0.302 (0.302)\tLoss 2.9800 (2.9800)\tPrec@1 88.000 (88.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.042 (0.055)\tLoss 4.6611 (3.8633)\tPrec@1 79.000 (82.364)\tPrec@5 93.000 (96.000)\n",
            "Test: [20/261]\tTime 0.011 (0.038)\tLoss 4.4154 (3.8052)\tPrec@1 79.000 (83.476)\tPrec@5 96.000 (95.714)\n",
            "Test: [30/261]\tTime 0.025 (0.037)\tLoss 2.2894 (3.5819)\tPrec@1 89.000 (84.290)\tPrec@5 98.000 (96.000)\n",
            "Test: [40/261]\tTime 0.025 (0.035)\tLoss 2.8043 (3.5893)\tPrec@1 90.000 (84.463)\tPrec@5 96.000 (96.024)\n",
            "Test: [50/261]\tTime 0.011 (0.033)\tLoss 3.7678 (3.5927)\tPrec@1 85.000 (84.647)\tPrec@5 94.000 (95.784)\n",
            "Test: [60/261]\tTime 0.019 (0.031)\tLoss 3.6426 (3.5626)\tPrec@1 87.000 (84.836)\tPrec@5 95.000 (95.820)\n",
            "Test: [70/261]\tTime 0.033 (0.030)\tLoss 4.2247 (3.5428)\tPrec@1 85.000 (84.958)\tPrec@5 96.000 (95.901)\n",
            "Test: [80/261]\tTime 0.022 (0.030)\tLoss 4.1157 (3.5422)\tPrec@1 83.000 (84.975)\tPrec@5 98.000 (95.988)\n",
            "Test: [90/261]\tTime 0.029 (0.030)\tLoss 3.7808 (3.5938)\tPrec@1 85.000 (84.769)\tPrec@5 95.000 (95.868)\n",
            "Test: [100/261]\tTime 0.027 (0.029)\tLoss 3.6454 (3.5806)\tPrec@1 86.000 (84.782)\tPrec@5 94.000 (95.901)\n",
            "Test: [110/261]\tTime 0.043 (0.029)\tLoss 2.7556 (3.5442)\tPrec@1 88.000 (84.937)\tPrec@5 95.000 (95.955)\n",
            "Test: [120/261]\tTime 0.023 (0.029)\tLoss 2.4818 (3.5711)\tPrec@1 89.000 (84.810)\tPrec@5 98.000 (95.901)\n",
            "Test: [130/261]\tTime 0.023 (0.029)\tLoss 4.5321 (3.5747)\tPrec@1 82.000 (84.718)\tPrec@5 93.000 (95.931)\n",
            "Test: [140/261]\tTime 0.026 (0.029)\tLoss 4.5547 (3.5650)\tPrec@1 81.000 (84.695)\tPrec@5 95.000 (95.936)\n",
            "Test: [150/261]\tTime 0.012 (0.029)\tLoss 2.9784 (3.5629)\tPrec@1 87.000 (84.775)\tPrec@5 97.000 (95.907)\n",
            "Test: [160/261]\tTime 0.019 (0.029)\tLoss 2.7227 (3.5630)\tPrec@1 91.000 (84.770)\tPrec@5 97.000 (95.963)\n",
            "Test: [170/261]\tTime 0.010 (0.029)\tLoss 2.6767 (3.5395)\tPrec@1 88.000 (84.871)\tPrec@5 98.000 (96.023)\n",
            "Test: [180/261]\tTime 0.015 (0.028)\tLoss 2.9922 (3.5375)\tPrec@1 86.000 (84.884)\tPrec@5 96.000 (96.006)\n",
            "Test: [190/261]\tTime 0.040 (0.028)\tLoss 3.2290 (3.5419)\tPrec@1 86.000 (84.874)\tPrec@5 96.000 (96.010)\n",
            "Test: [200/261]\tTime 0.032 (0.028)\tLoss 3.8809 (3.5428)\tPrec@1 82.000 (84.841)\tPrec@5 97.000 (96.025)\n",
            "Test: [210/261]\tTime 0.030 (0.028)\tLoss 3.1327 (3.5338)\tPrec@1 85.000 (84.877)\tPrec@5 96.000 (96.038)\n",
            "Test: [220/261]\tTime 0.038 (0.028)\tLoss 3.0963 (3.5350)\tPrec@1 87.000 (84.882)\tPrec@5 96.000 (95.991)\n",
            "Test: [230/261]\tTime 0.031 (0.029)\tLoss 4.2184 (3.5429)\tPrec@1 80.000 (84.835)\tPrec@5 93.000 (96.000)\n",
            "Test: [240/261]\tTime 0.032 (0.029)\tLoss 3.8043 (3.5474)\tPrec@1 84.000 (84.801)\tPrec@5 96.000 (96.000)\n",
            "Test: [250/261]\tTime 0.055 (0.030)\tLoss 3.0834 (3.5261)\tPrec@1 88.000 (84.869)\tPrec@5 97.000 (96.052)\n",
            "Test: [260/261]\tTime 0.007 (0.030)\tLoss 1.7270 (3.5400)\tPrec@1 93.750 (84.830)\tPrec@5 96.875 (96.013)\n",
            "val Results: Prec@1 84.830 Prec@5 96.013 Loss 3.54003\n",
            "val Class Accuracy: [0.771,0.932,0.935,0.804,0.946,0.824,0.803,0.801,0.813,0.553]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [81][0/66], lr: 0.01000\tTime 0.993 (0.993)\tData 0.865 (0.865)\tLoss 0.5849 (0.5849)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [81][10/66], lr: 0.01000\tTime 0.085 (0.211)\tData 0.000 (0.104)\tLoss 0.2811 (0.4514)\tPrec@1 99.219 (97.656)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [81][20/66], lr: 0.01000\tTime 0.147 (0.161)\tData 0.070 (0.065)\tLoss 0.4327 (0.4650)\tPrec@1 98.047 (97.638)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [81][30/66], lr: 0.01000\tTime 0.100 (0.141)\tData 0.005 (0.047)\tLoss 0.2014 (0.4575)\tPrec@1 98.828 (97.732)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [81][40/66], lr: 0.01000\tTime 0.091 (0.131)\tData 0.004 (0.037)\tLoss 0.4826 (0.4619)\tPrec@1 97.656 (97.742)\tPrec@5 100.000 (99.924)\n",
            "Epoch: [81][50/66], lr: 0.01000\tTime 0.113 (0.125)\tData 0.008 (0.031)\tLoss 0.3669 (0.4868)\tPrec@1 98.047 (97.633)\tPrec@5 100.000 (99.900)\n",
            "Epoch: [81][60/66], lr: 0.01000\tTime 0.065 (0.120)\tData 0.000 (0.027)\tLoss 0.5725 (0.4999)\tPrec@1 96.484 (97.541)\tPrec@5 100.000 (99.904)\n",
            "Test: [0/261]\tTime 0.349 (0.349)\tLoss 3.9458 (3.9458)\tPrec@1 82.000 (82.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.032 (0.058)\tLoss 5.6170 (4.7955)\tPrec@1 75.000 (78.364)\tPrec@5 96.000 (95.636)\n",
            "Test: [20/261]\tTime 0.019 (0.042)\tLoss 5.6175 (4.6742)\tPrec@1 78.000 (79.762)\tPrec@5 96.000 (95.714)\n",
            "Test: [30/261]\tTime 0.026 (0.037)\tLoss 3.4816 (4.4870)\tPrec@1 84.000 (80.581)\tPrec@5 97.000 (95.839)\n",
            "Test: [40/261]\tTime 0.035 (0.034)\tLoss 3.8385 (4.5548)\tPrec@1 84.000 (80.366)\tPrec@5 96.000 (95.927)\n",
            "Test: [50/261]\tTime 0.032 (0.033)\tLoss 4.4526 (4.4895)\tPrec@1 83.000 (80.804)\tPrec@5 97.000 (95.961)\n",
            "Test: [60/261]\tTime 0.023 (0.032)\tLoss 4.6087 (4.4567)\tPrec@1 82.000 (80.967)\tPrec@5 95.000 (96.000)\n",
            "Test: [70/261]\tTime 0.012 (0.031)\tLoss 5.3277 (4.4449)\tPrec@1 75.000 (80.958)\tPrec@5 97.000 (96.000)\n",
            "Test: [80/261]\tTime 0.030 (0.030)\tLoss 4.2945 (4.4522)\tPrec@1 83.000 (80.951)\tPrec@5 97.000 (96.025)\n",
            "Test: [90/261]\tTime 0.037 (0.030)\tLoss 4.6917 (4.5006)\tPrec@1 81.000 (80.736)\tPrec@5 95.000 (95.967)\n",
            "Test: [100/261]\tTime 0.040 (0.030)\tLoss 4.8480 (4.4778)\tPrec@1 82.000 (80.842)\tPrec@5 94.000 (95.970)\n",
            "Test: [110/261]\tTime 0.039 (0.029)\tLoss 5.0860 (4.4372)\tPrec@1 78.000 (80.955)\tPrec@5 95.000 (96.036)\n",
            "Test: [120/261]\tTime 0.022 (0.029)\tLoss 3.2975 (4.4283)\tPrec@1 85.000 (81.033)\tPrec@5 96.000 (96.025)\n",
            "Test: [130/261]\tTime 0.034 (0.029)\tLoss 4.9687 (4.4286)\tPrec@1 79.000 (81.008)\tPrec@5 93.000 (96.015)\n",
            "Test: [140/261]\tTime 0.048 (0.029)\tLoss 5.6001 (4.4125)\tPrec@1 77.000 (81.043)\tPrec@5 93.000 (96.064)\n",
            "Test: [150/261]\tTime 0.026 (0.028)\tLoss 4.0698 (4.4076)\tPrec@1 81.000 (81.033)\tPrec@5 97.000 (96.053)\n",
            "Test: [160/261]\tTime 0.028 (0.029)\tLoss 3.2524 (4.4068)\tPrec@1 87.000 (81.056)\tPrec@5 99.000 (96.037)\n",
            "Test: [170/261]\tTime 0.041 (0.028)\tLoss 4.3942 (4.3815)\tPrec@1 82.000 (81.146)\tPrec@5 95.000 (96.047)\n",
            "Test: [180/261]\tTime 0.026 (0.028)\tLoss 3.0131 (4.3695)\tPrec@1 87.000 (81.193)\tPrec@5 96.000 (96.083)\n",
            "Test: [190/261]\tTime 0.024 (0.028)\tLoss 3.9413 (4.3641)\tPrec@1 82.000 (81.236)\tPrec@5 96.000 (96.120)\n",
            "Test: [200/261]\tTime 0.027 (0.028)\tLoss 3.7984 (4.3643)\tPrec@1 82.000 (81.204)\tPrec@5 97.000 (96.119)\n",
            "Test: [210/261]\tTime 0.035 (0.028)\tLoss 4.3923 (4.3641)\tPrec@1 82.000 (81.204)\tPrec@5 96.000 (96.095)\n",
            "Test: [220/261]\tTime 0.026 (0.028)\tLoss 4.5873 (4.3607)\tPrec@1 79.000 (81.172)\tPrec@5 96.000 (96.077)\n",
            "Test: [230/261]\tTime 0.023 (0.028)\tLoss 4.2977 (4.3644)\tPrec@1 85.000 (81.164)\tPrec@5 94.000 (96.078)\n",
            "Test: [240/261]\tTime 0.037 (0.028)\tLoss 4.1475 (4.3734)\tPrec@1 80.000 (81.154)\tPrec@5 98.000 (96.066)\n",
            "Test: [250/261]\tTime 0.034 (0.028)\tLoss 3.7043 (4.3523)\tPrec@1 83.000 (81.199)\tPrec@5 97.000 (96.112)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 2.8702 (4.3541)\tPrec@1 84.375 (81.238)\tPrec@5 96.875 (96.070)\n",
            "val Results: Prec@1 81.238 Prec@5 96.070 Loss 4.35412\n",
            "val Class Accuracy: [0.690,0.956,0.889,0.880,0.854,0.775,0.538,0.693,0.839,0.619]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [82][0/66], lr: 0.01000\tTime 0.663 (0.663)\tData 0.577 (0.577)\tLoss 0.5009 (0.5009)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [82][10/66], lr: 0.01000\tTime 0.085 (0.151)\tData 0.005 (0.058)\tLoss 0.3856 (0.4877)\tPrec@1 98.438 (97.727)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [82][20/66], lr: 0.01000\tTime 0.123 (0.128)\tData 0.043 (0.038)\tLoss 0.4773 (0.4806)\tPrec@1 96.875 (97.582)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [82][30/66], lr: 0.01000\tTime 0.109 (0.119)\tData 0.000 (0.028)\tLoss 0.4955 (0.4772)\tPrec@1 97.656 (97.568)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [82][40/66], lr: 0.01000\tTime 0.097 (0.114)\tData 0.004 (0.023)\tLoss 0.7883 (0.4861)\tPrec@1 95.703 (97.532)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [82][50/66], lr: 0.01000\tTime 0.061 (0.111)\tData 0.000 (0.019)\tLoss 0.6035 (0.4851)\tPrec@1 96.875 (97.511)\tPrec@5 100.000 (99.946)\n",
            "Epoch: [82][60/66], lr: 0.01000\tTime 0.141 (0.109)\tData 0.089 (0.020)\tLoss 0.3843 (0.4832)\tPrec@1 97.656 (97.541)\tPrec@5 99.609 (99.917)\n",
            "Test: [0/261]\tTime 0.302 (0.302)\tLoss 4.0253 (4.0253)\tPrec@1 81.000 (81.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.026 (0.060)\tLoss 4.9630 (4.2704)\tPrec@1 80.000 (81.091)\tPrec@5 94.000 (95.636)\n",
            "Test: [20/261]\tTime 0.015 (0.043)\tLoss 4.5761 (4.2170)\tPrec@1 80.000 (81.762)\tPrec@5 95.000 (95.476)\n",
            "Test: [30/261]\tTime 0.011 (0.037)\tLoss 2.8014 (3.9401)\tPrec@1 87.000 (82.968)\tPrec@5 96.000 (95.806)\n",
            "Test: [40/261]\tTime 0.037 (0.035)\tLoss 3.5419 (3.8836)\tPrec@1 85.000 (83.317)\tPrec@5 96.000 (96.073)\n",
            "Test: [50/261]\tTime 0.040 (0.033)\tLoss 3.8660 (3.8565)\tPrec@1 81.000 (83.490)\tPrec@5 97.000 (96.039)\n",
            "Test: [60/261]\tTime 0.024 (0.032)\tLoss 4.3170 (3.8689)\tPrec@1 85.000 (83.590)\tPrec@5 95.000 (96.000)\n",
            "Test: [70/261]\tTime 0.039 (0.032)\tLoss 4.3994 (3.8449)\tPrec@1 81.000 (83.732)\tPrec@5 95.000 (96.070)\n",
            "Test: [80/261]\tTime 0.039 (0.032)\tLoss 3.5895 (3.8130)\tPrec@1 85.000 (83.975)\tPrec@5 97.000 (96.099)\n",
            "Test: [90/261]\tTime 0.031 (0.031)\tLoss 4.2629 (3.8797)\tPrec@1 82.000 (83.626)\tPrec@5 96.000 (96.077)\n",
            "Test: [100/261]\tTime 0.018 (0.030)\tLoss 4.8243 (3.8752)\tPrec@1 81.000 (83.663)\tPrec@5 93.000 (96.059)\n",
            "Test: [110/261]\tTime 0.028 (0.030)\tLoss 4.7868 (3.8599)\tPrec@1 78.000 (83.676)\tPrec@5 91.000 (96.108)\n",
            "Test: [120/261]\tTime 0.041 (0.030)\tLoss 2.8371 (3.8536)\tPrec@1 87.000 (83.669)\tPrec@5 98.000 (96.157)\n",
            "Test: [130/261]\tTime 0.037 (0.030)\tLoss 4.6414 (3.8705)\tPrec@1 83.000 (83.603)\tPrec@5 93.000 (96.076)\n",
            "Test: [140/261]\tTime 0.022 (0.029)\tLoss 4.5612 (3.8624)\tPrec@1 82.000 (83.652)\tPrec@5 97.000 (96.135)\n",
            "Test: [150/261]\tTime 0.038 (0.030)\tLoss 3.0286 (3.8593)\tPrec@1 85.000 (83.728)\tPrec@5 97.000 (96.099)\n",
            "Test: [160/261]\tTime 0.021 (0.029)\tLoss 3.6604 (3.8607)\tPrec@1 84.000 (83.640)\tPrec@5 97.000 (96.075)\n",
            "Test: [170/261]\tTime 0.041 (0.029)\tLoss 3.2873 (3.8223)\tPrec@1 86.000 (83.830)\tPrec@5 97.000 (96.111)\n",
            "Test: [180/261]\tTime 0.022 (0.029)\tLoss 3.0042 (3.8005)\tPrec@1 87.000 (83.956)\tPrec@5 94.000 (96.105)\n",
            "Test: [190/261]\tTime 0.038 (0.029)\tLoss 3.8263 (3.8085)\tPrec@1 82.000 (83.874)\tPrec@5 96.000 (96.136)\n",
            "Test: [200/261]\tTime 0.033 (0.029)\tLoss 3.9612 (3.8135)\tPrec@1 82.000 (83.811)\tPrec@5 98.000 (96.134)\n",
            "Test: [210/261]\tTime 0.011 (0.029)\tLoss 2.7564 (3.7993)\tPrec@1 88.000 (83.877)\tPrec@5 99.000 (96.109)\n",
            "Test: [220/261]\tTime 0.029 (0.029)\tLoss 4.2226 (3.8052)\tPrec@1 83.000 (83.851)\tPrec@5 97.000 (96.122)\n",
            "Test: [230/261]\tTime 0.015 (0.029)\tLoss 4.6360 (3.8137)\tPrec@1 81.000 (83.818)\tPrec@5 94.000 (96.100)\n",
            "Test: [240/261]\tTime 0.012 (0.028)\tLoss 3.6011 (3.8217)\tPrec@1 86.000 (83.805)\tPrec@5 96.000 (96.046)\n",
            "Test: [250/261]\tTime 0.041 (0.028)\tLoss 3.7139 (3.7945)\tPrec@1 83.000 (83.884)\tPrec@5 98.000 (96.092)\n",
            "Test: [260/261]\tTime 0.009 (0.028)\tLoss 2.3996 (3.8004)\tPrec@1 90.625 (83.858)\tPrec@5 96.875 (96.082)\n",
            "val Results: Prec@1 83.858 Prec@5 96.082 Loss 3.80041\n",
            "val Class Accuracy: [0.744,0.966,0.881,0.847,0.909,0.791,0.676,0.769,0.869,0.625]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [83][0/66], lr: 0.01000\tTime 0.698 (0.698)\tData 0.602 (0.602)\tLoss 0.5820 (0.5820)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [83][10/66], lr: 0.01000\tTime 0.097 (0.160)\tData 0.003 (0.064)\tLoss 0.9759 (0.5746)\tPrec@1 94.141 (96.946)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [83][20/66], lr: 0.01000\tTime 0.063 (0.132)\tData 0.004 (0.037)\tLoss 0.9057 (0.5766)\tPrec@1 95.703 (97.042)\tPrec@5 99.609 (99.944)\n",
            "Epoch: [83][30/66], lr: 0.01000\tTime 0.087 (0.122)\tData 0.000 (0.028)\tLoss 0.3781 (0.5597)\tPrec@1 98.047 (97.203)\tPrec@5 100.000 (99.887)\n",
            "Epoch: [83][40/66], lr: 0.01000\tTime 0.115 (0.117)\tData 0.005 (0.023)\tLoss 0.5209 (0.5370)\tPrec@1 96.875 (97.294)\tPrec@5 100.000 (99.914)\n",
            "Epoch: [83][50/66], lr: 0.01000\tTime 0.081 (0.113)\tData 0.002 (0.019)\tLoss 0.4064 (0.5423)\tPrec@1 98.438 (97.250)\tPrec@5 100.000 (99.916)\n",
            "Epoch: [83][60/66], lr: 0.01000\tTime 0.075 (0.111)\tData 0.000 (0.017)\tLoss 0.4379 (0.5344)\tPrec@1 96.875 (97.259)\tPrec@5 100.000 (99.917)\n",
            "Test: [0/261]\tTime 0.271 (0.271)\tLoss 2.7795 (2.7795)\tPrec@1 90.000 (90.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.025 (0.060)\tLoss 4.4622 (3.9055)\tPrec@1 83.000 (84.000)\tPrec@5 96.000 (96.545)\n",
            "Test: [20/261]\tTime 0.022 (0.043)\tLoss 4.7583 (4.0701)\tPrec@1 82.000 (83.048)\tPrec@5 94.000 (96.190)\n",
            "Test: [30/261]\tTime 0.029 (0.039)\tLoss 2.7194 (3.8688)\tPrec@1 88.000 (84.065)\tPrec@5 96.000 (96.258)\n",
            "Test: [40/261]\tTime 0.018 (0.035)\tLoss 3.1348 (3.7649)\tPrec@1 89.000 (84.512)\tPrec@5 96.000 (96.488)\n",
            "Test: [50/261]\tTime 0.015 (0.034)\tLoss 2.1339 (3.6949)\tPrec@1 92.000 (84.902)\tPrec@5 98.000 (96.608)\n",
            "Test: [60/261]\tTime 0.035 (0.033)\tLoss 3.1018 (3.6871)\tPrec@1 88.000 (84.951)\tPrec@5 98.000 (96.492)\n",
            "Test: [70/261]\tTime 0.033 (0.032)\tLoss 4.0386 (3.6463)\tPrec@1 82.000 (85.056)\tPrec@5 95.000 (96.577)\n",
            "Test: [80/261]\tTime 0.029 (0.031)\tLoss 3.9599 (3.6310)\tPrec@1 83.000 (85.086)\tPrec@5 96.000 (96.605)\n",
            "Test: [90/261]\tTime 0.026 (0.031)\tLoss 3.8816 (3.6981)\tPrec@1 86.000 (84.824)\tPrec@5 96.000 (96.484)\n",
            "Test: [100/261]\tTime 0.014 (0.030)\tLoss 4.4172 (3.6907)\tPrec@1 82.000 (84.851)\tPrec@5 94.000 (96.485)\n",
            "Test: [110/261]\tTime 0.042 (0.030)\tLoss 3.4558 (3.6642)\tPrec@1 86.000 (84.946)\tPrec@5 95.000 (96.432)\n",
            "Test: [120/261]\tTime 0.022 (0.030)\tLoss 2.6523 (3.6429)\tPrec@1 89.000 (85.050)\tPrec@5 95.000 (96.331)\n",
            "Test: [130/261]\tTime 0.031 (0.029)\tLoss 3.9780 (3.6679)\tPrec@1 84.000 (84.962)\tPrec@5 94.000 (96.275)\n",
            "Test: [140/261]\tTime 0.033 (0.029)\tLoss 4.9953 (3.6697)\tPrec@1 79.000 (84.894)\tPrec@5 94.000 (96.298)\n",
            "Test: [150/261]\tTime 0.014 (0.029)\tLoss 2.4551 (3.6679)\tPrec@1 90.000 (84.894)\tPrec@5 96.000 (96.305)\n",
            "Test: [160/261]\tTime 0.012 (0.029)\tLoss 2.4157 (3.6593)\tPrec@1 91.000 (84.870)\tPrec@5 98.000 (96.373)\n",
            "Test: [170/261]\tTime 0.036 (0.029)\tLoss 2.6415 (3.6292)\tPrec@1 89.000 (84.982)\tPrec@5 96.000 (96.398)\n",
            "Test: [180/261]\tTime 0.013 (0.029)\tLoss 3.1010 (3.6250)\tPrec@1 88.000 (84.983)\tPrec@5 96.000 (96.398)\n",
            "Test: [190/261]\tTime 0.021 (0.029)\tLoss 4.0830 (3.6269)\tPrec@1 85.000 (84.963)\tPrec@5 96.000 (96.440)\n",
            "Test: [200/261]\tTime 0.047 (0.029)\tLoss 3.1993 (3.6220)\tPrec@1 84.000 (84.960)\tPrec@5 98.000 (96.468)\n",
            "Test: [210/261]\tTime 0.057 (0.030)\tLoss 3.5415 (3.6239)\tPrec@1 85.000 (84.938)\tPrec@5 97.000 (96.445)\n",
            "Test: [220/261]\tTime 0.025 (0.030)\tLoss 4.7475 (3.6251)\tPrec@1 79.000 (84.900)\tPrec@5 97.000 (96.448)\n",
            "Test: [230/261]\tTime 0.063 (0.030)\tLoss 5.2014 (3.6337)\tPrec@1 81.000 (84.861)\tPrec@5 91.000 (96.429)\n",
            "Test: [240/261]\tTime 0.027 (0.031)\tLoss 3.5265 (3.6386)\tPrec@1 86.000 (84.838)\tPrec@5 95.000 (96.402)\n",
            "Test: [250/261]\tTime 0.048 (0.031)\tLoss 2.6929 (3.6289)\tPrec@1 90.000 (84.845)\tPrec@5 100.000 (96.430)\n",
            "Test: [260/261]\tTime 0.007 (0.031)\tLoss 1.6747 (3.6219)\tPrec@1 90.625 (84.853)\tPrec@5 96.875 (96.435)\n",
            "val Results: Prec@1 84.853 Prec@5 96.435 Loss 3.62188\n",
            "val Class Accuracy: [0.602,0.942,0.930,0.864,0.891,0.891,0.775,0.790,0.708,0.760]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [84][0/66], lr: 0.01000\tTime 0.959 (0.959)\tData 0.855 (0.855)\tLoss 0.2585 (0.2585)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [84][10/66], lr: 0.01000\tTime 0.074 (0.184)\tData 0.000 (0.085)\tLoss 0.6666 (0.5133)\tPrec@1 96.875 (97.479)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [84][20/66], lr: 0.01000\tTime 0.071 (0.142)\tData 0.005 (0.047)\tLoss 0.2597 (0.4711)\tPrec@1 98.438 (97.619)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [84][30/66], lr: 0.01000\tTime 0.101 (0.126)\tData 0.005 (0.033)\tLoss 0.4213 (0.4748)\tPrec@1 98.047 (97.555)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [84][40/66], lr: 0.01000\tTime 0.109 (0.120)\tData 0.006 (0.027)\tLoss 0.4858 (0.4958)\tPrec@1 97.656 (97.428)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [84][50/66], lr: 0.01000\tTime 0.096 (0.117)\tData 0.000 (0.022)\tLoss 0.4650 (0.4929)\tPrec@1 97.266 (97.449)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [84][60/66], lr: 0.01000\tTime 0.092 (0.113)\tData 0.000 (0.019)\tLoss 0.7199 (0.5065)\tPrec@1 96.875 (97.336)\tPrec@5 99.609 (99.923)\n",
            "Test: [0/261]\tTime 0.298 (0.298)\tLoss 3.9889 (3.9889)\tPrec@1 86.000 (86.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.036 (0.058)\tLoss 4.5488 (4.1645)\tPrec@1 81.000 (82.000)\tPrec@5 93.000 (95.364)\n",
            "Test: [20/261]\tTime 0.020 (0.044)\tLoss 4.2849 (4.1083)\tPrec@1 81.000 (82.571)\tPrec@5 95.000 (95.048)\n",
            "Test: [30/261]\tTime 0.023 (0.038)\tLoss 2.6725 (3.8577)\tPrec@1 87.000 (83.710)\tPrec@5 97.000 (95.290)\n",
            "Test: [40/261]\tTime 0.042 (0.036)\tLoss 3.5889 (3.7709)\tPrec@1 87.000 (84.049)\tPrec@5 95.000 (95.585)\n",
            "Test: [50/261]\tTime 0.023 (0.035)\tLoss 3.3565 (3.7353)\tPrec@1 88.000 (84.314)\tPrec@5 96.000 (95.569)\n",
            "Test: [60/261]\tTime 0.024 (0.032)\tLoss 3.6903 (3.7392)\tPrec@1 85.000 (84.311)\tPrec@5 96.000 (95.492)\n",
            "Test: [70/261]\tTime 0.033 (0.032)\tLoss 3.8887 (3.7311)\tPrec@1 86.000 (84.394)\tPrec@5 96.000 (95.521)\n",
            "Test: [80/261]\tTime 0.025 (0.031)\tLoss 3.1004 (3.7367)\tPrec@1 88.000 (84.457)\tPrec@5 95.000 (95.432)\n",
            "Test: [90/261]\tTime 0.017 (0.031)\tLoss 4.0030 (3.8004)\tPrec@1 86.000 (84.297)\tPrec@5 95.000 (95.429)\n",
            "Test: [100/261]\tTime 0.042 (0.031)\tLoss 4.2802 (3.7833)\tPrec@1 83.000 (84.327)\tPrec@5 93.000 (95.475)\n",
            "Test: [110/261]\tTime 0.042 (0.030)\tLoss 3.8644 (3.7613)\tPrec@1 80.000 (84.378)\tPrec@5 96.000 (95.559)\n",
            "Test: [120/261]\tTime 0.023 (0.030)\tLoss 2.9321 (3.7487)\tPrec@1 87.000 (84.496)\tPrec@5 97.000 (95.595)\n",
            "Test: [130/261]\tTime 0.019 (0.029)\tLoss 3.9597 (3.7481)\tPrec@1 83.000 (84.473)\tPrec@5 93.000 (95.588)\n",
            "Test: [140/261]\tTime 0.037 (0.030)\tLoss 4.8839 (3.7382)\tPrec@1 80.000 (84.468)\tPrec@5 95.000 (95.603)\n",
            "Test: [150/261]\tTime 0.027 (0.030)\tLoss 3.1059 (3.7404)\tPrec@1 87.000 (84.497)\tPrec@5 97.000 (95.609)\n",
            "Test: [160/261]\tTime 0.036 (0.029)\tLoss 3.2036 (3.7293)\tPrec@1 87.000 (84.540)\tPrec@5 95.000 (95.621)\n",
            "Test: [170/261]\tTime 0.024 (0.029)\tLoss 3.0477 (3.7102)\tPrec@1 88.000 (84.643)\tPrec@5 95.000 (95.643)\n",
            "Test: [180/261]\tTime 0.030 (0.029)\tLoss 3.9607 (3.7047)\tPrec@1 84.000 (84.674)\tPrec@5 93.000 (95.602)\n",
            "Test: [190/261]\tTime 0.025 (0.029)\tLoss 3.9213 (3.6992)\tPrec@1 83.000 (84.712)\tPrec@5 93.000 (95.623)\n",
            "Test: [200/261]\tTime 0.043 (0.029)\tLoss 3.9519 (3.6880)\tPrec@1 81.000 (84.756)\tPrec@5 99.000 (95.672)\n",
            "Test: [210/261]\tTime 0.027 (0.029)\tLoss 3.1520 (3.6801)\tPrec@1 87.000 (84.806)\tPrec@5 97.000 (95.673)\n",
            "Test: [220/261]\tTime 0.024 (0.029)\tLoss 4.2413 (3.6891)\tPrec@1 83.000 (84.760)\tPrec@5 94.000 (95.647)\n",
            "Test: [230/261]\tTime 0.029 (0.029)\tLoss 5.1899 (3.7043)\tPrec@1 82.000 (84.723)\tPrec@5 92.000 (95.610)\n",
            "Test: [240/261]\tTime 0.026 (0.029)\tLoss 3.9205 (3.7195)\tPrec@1 84.000 (84.631)\tPrec@5 97.000 (95.573)\n",
            "Test: [250/261]\tTime 0.022 (0.029)\tLoss 3.2351 (3.6993)\tPrec@1 85.000 (84.689)\tPrec@5 97.000 (95.606)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.5989 (3.7017)\tPrec@1 96.875 (84.688)\tPrec@5 96.875 (95.609)\n",
            "val Results: Prec@1 84.688 Prec@5 95.609 Loss 3.70169\n",
            "val Class Accuracy: [0.749,0.951,0.936,0.891,0.938,0.833,0.700,0.819,0.686,0.574]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [85][0/66], lr: 0.01000\tTime 0.786 (0.786)\tData 0.711 (0.711)\tLoss 0.4598 (0.4598)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [85][10/66], lr: 0.01000\tTime 0.063 (0.155)\tData 0.000 (0.070)\tLoss 0.3750 (0.4295)\tPrec@1 97.656 (98.047)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [85][20/66], lr: 0.01000\tTime 0.108 (0.129)\tData 0.006 (0.043)\tLoss 0.5608 (0.4322)\tPrec@1 95.703 (97.749)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [85][30/66], lr: 0.01000\tTime 0.122 (0.119)\tData 0.005 (0.033)\tLoss 0.4106 (0.4437)\tPrec@1 98.047 (97.795)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [85][40/66], lr: 0.01000\tTime 0.106 (0.116)\tData 0.004 (0.028)\tLoss 0.2236 (0.4235)\tPrec@1 99.219 (97.923)\tPrec@5 100.000 (99.971)\n",
            "Epoch: [85][50/66], lr: 0.01000\tTime 0.096 (0.113)\tData 0.004 (0.024)\tLoss 0.3871 (0.4188)\tPrec@1 97.656 (97.932)\tPrec@5 100.000 (99.969)\n",
            "Epoch: [85][60/66], lr: 0.01000\tTime 0.090 (0.110)\tData 0.000 (0.021)\tLoss 0.4927 (0.4219)\tPrec@1 97.656 (97.887)\tPrec@5 100.000 (99.974)\n",
            "Test: [0/261]\tTime 0.322 (0.322)\tLoss 4.1347 (4.1347)\tPrec@1 82.000 (82.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.031 (0.060)\tLoss 5.1193 (4.0611)\tPrec@1 81.000 (82.727)\tPrec@5 94.000 (96.091)\n",
            "Test: [20/261]\tTime 0.015 (0.044)\tLoss 4.6684 (3.9785)\tPrec@1 78.000 (83.000)\tPrec@5 95.000 (95.810)\n",
            "Test: [30/261]\tTime 0.016 (0.036)\tLoss 2.6322 (3.6616)\tPrec@1 89.000 (84.323)\tPrec@5 97.000 (96.387)\n",
            "Test: [40/261]\tTime 0.034 (0.035)\tLoss 3.1783 (3.5090)\tPrec@1 87.000 (84.927)\tPrec@5 96.000 (96.610)\n",
            "Test: [50/261]\tTime 0.024 (0.033)\tLoss 3.6343 (3.5012)\tPrec@1 84.000 (85.020)\tPrec@5 96.000 (96.627)\n",
            "Test: [60/261]\tTime 0.051 (0.033)\tLoss 3.4638 (3.4961)\tPrec@1 87.000 (85.262)\tPrec@5 95.000 (96.443)\n",
            "Test: [70/261]\tTime 0.048 (0.032)\tLoss 3.7610 (3.4712)\tPrec@1 83.000 (85.380)\tPrec@5 98.000 (96.549)\n",
            "Test: [80/261]\tTime 0.030 (0.032)\tLoss 3.8873 (3.4640)\tPrec@1 83.000 (85.469)\tPrec@5 96.000 (96.494)\n",
            "Test: [90/261]\tTime 0.010 (0.031)\tLoss 2.1091 (3.5439)\tPrec@1 92.000 (85.121)\tPrec@5 96.000 (96.429)\n",
            "Test: [100/261]\tTime 0.028 (0.030)\tLoss 4.4731 (3.5405)\tPrec@1 79.000 (85.089)\tPrec@5 95.000 (96.485)\n",
            "Test: [110/261]\tTime 0.017 (0.030)\tLoss 3.9795 (3.5138)\tPrec@1 82.000 (85.252)\tPrec@5 96.000 (96.486)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 3.3427 (3.5036)\tPrec@1 86.000 (85.281)\tPrec@5 96.000 (96.463)\n",
            "Test: [130/261]\tTime 0.035 (0.030)\tLoss 3.8397 (3.4988)\tPrec@1 83.000 (85.305)\tPrec@5 96.000 (96.504)\n",
            "Test: [140/261]\tTime 0.026 (0.030)\tLoss 4.8876 (3.4971)\tPrec@1 81.000 (85.319)\tPrec@5 94.000 (96.546)\n",
            "Test: [150/261]\tTime 0.041 (0.030)\tLoss 3.1478 (3.4966)\tPrec@1 88.000 (85.351)\tPrec@5 97.000 (96.570)\n",
            "Test: [160/261]\tTime 0.029 (0.029)\tLoss 2.4981 (3.4868)\tPrec@1 90.000 (85.366)\tPrec@5 99.000 (96.634)\n",
            "Test: [170/261]\tTime 0.020 (0.029)\tLoss 2.3862 (3.4582)\tPrec@1 89.000 (85.456)\tPrec@5 99.000 (96.673)\n",
            "Test: [180/261]\tTime 0.031 (0.029)\tLoss 2.7256 (3.4561)\tPrec@1 88.000 (85.414)\tPrec@5 95.000 (96.680)\n",
            "Test: [190/261]\tTime 0.048 (0.029)\tLoss 4.3046 (3.4607)\tPrec@1 80.000 (85.377)\tPrec@5 92.000 (96.660)\n",
            "Test: [200/261]\tTime 0.022 (0.029)\tLoss 2.7203 (3.4565)\tPrec@1 87.000 (85.378)\tPrec@5 97.000 (96.662)\n",
            "Test: [210/261]\tTime 0.039 (0.029)\tLoss 3.3883 (3.4565)\tPrec@1 85.000 (85.374)\tPrec@5 98.000 (96.678)\n",
            "Test: [220/261]\tTime 0.029 (0.029)\tLoss 4.6062 (3.4484)\tPrec@1 81.000 (85.412)\tPrec@5 95.000 (96.665)\n",
            "Test: [230/261]\tTime 0.036 (0.028)\tLoss 4.5534 (3.4665)\tPrec@1 83.000 (85.333)\tPrec@5 94.000 (96.636)\n",
            "Test: [240/261]\tTime 0.022 (0.028)\tLoss 2.7544 (3.4695)\tPrec@1 86.000 (85.307)\tPrec@5 98.000 (96.598)\n",
            "Test: [250/261]\tTime 0.017 (0.028)\tLoss 3.0004 (3.4503)\tPrec@1 86.000 (85.343)\tPrec@5 96.000 (96.610)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.7298 (3.4503)\tPrec@1 87.500 (85.337)\tPrec@5 96.875 (96.581)\n",
            "val Results: Prec@1 85.337 Prec@5 96.581 Loss 3.45028\n",
            "val Class Accuracy: [0.719,0.957,0.894,0.838,0.877,0.894,0.769,0.894,0.707,0.697]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [86][0/66], lr: 0.01000\tTime 0.655 (0.655)\tData 0.547 (0.547)\tLoss 0.3760 (0.3760)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [86][10/66], lr: 0.01000\tTime 0.104 (0.150)\tData 0.000 (0.056)\tLoss 0.2342 (0.4635)\tPrec@1 98.828 (97.798)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [86][20/66], lr: 0.01000\tTime 0.092 (0.126)\tData 0.000 (0.034)\tLoss 0.7879 (0.4699)\tPrec@1 96.484 (97.768)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [86][30/66], lr: 0.01000\tTime 0.093 (0.116)\tData 0.000 (0.025)\tLoss 0.4483 (0.4647)\tPrec@1 96.875 (97.681)\tPrec@5 100.000 (99.899)\n",
            "Epoch: [86][40/66], lr: 0.01000\tTime 0.094 (0.114)\tData 0.000 (0.023)\tLoss 0.5819 (0.4872)\tPrec@1 96.875 (97.590)\tPrec@5 99.609 (99.905)\n",
            "Epoch: [86][50/66], lr: 0.01000\tTime 0.092 (0.109)\tData 0.004 (0.020)\tLoss 0.3715 (0.4810)\tPrec@1 98.047 (97.603)\tPrec@5 100.000 (99.900)\n",
            "Epoch: [86][60/66], lr: 0.01000\tTime 0.074 (0.109)\tData 0.011 (0.021)\tLoss 0.4657 (0.4866)\tPrec@1 97.656 (97.567)\tPrec@5 100.000 (99.904)\n",
            "Test: [0/261]\tTime 0.327 (0.327)\tLoss 3.9872 (3.9872)\tPrec@1 84.000 (84.000)\tPrec@5 99.000 (99.000)\n",
            "Test: [10/261]\tTime 0.024 (0.056)\tLoss 4.5883 (4.4140)\tPrec@1 81.000 (81.091)\tPrec@5 95.000 (96.455)\n",
            "Test: [20/261]\tTime 0.031 (0.042)\tLoss 5.1146 (4.5961)\tPrec@1 76.000 (80.000)\tPrec@5 96.000 (96.190)\n",
            "Test: [30/261]\tTime 0.017 (0.038)\tLoss 2.8351 (4.2709)\tPrec@1 89.000 (81.548)\tPrec@5 95.000 (96.290)\n",
            "Test: [40/261]\tTime 0.029 (0.035)\tLoss 4.0344 (4.2080)\tPrec@1 81.000 (81.732)\tPrec@5 96.000 (96.439)\n",
            "Test: [50/261]\tTime 0.023 (0.033)\tLoss 3.2001 (4.1781)\tPrec@1 88.000 (82.000)\tPrec@5 95.000 (96.529)\n",
            "Test: [60/261]\tTime 0.031 (0.032)\tLoss 4.9241 (4.1594)\tPrec@1 81.000 (82.164)\tPrec@5 94.000 (96.361)\n",
            "Test: [70/261]\tTime 0.042 (0.031)\tLoss 4.6049 (4.1605)\tPrec@1 82.000 (82.197)\tPrec@5 93.000 (96.394)\n",
            "Test: [80/261]\tTime 0.011 (0.031)\tLoss 4.3759 (4.1569)\tPrec@1 82.000 (82.185)\tPrec@5 94.000 (96.370)\n",
            "Test: [90/261]\tTime 0.047 (0.030)\tLoss 4.0213 (4.1847)\tPrec@1 84.000 (82.099)\tPrec@5 93.000 (96.297)\n",
            "Test: [100/261]\tTime 0.029 (0.030)\tLoss 5.0316 (4.1864)\tPrec@1 78.000 (82.020)\tPrec@5 93.000 (96.366)\n",
            "Test: [110/261]\tTime 0.026 (0.030)\tLoss 4.5066 (4.1601)\tPrec@1 81.000 (82.117)\tPrec@5 97.000 (96.486)\n",
            "Test: [120/261]\tTime 0.030 (0.030)\tLoss 2.9705 (4.1467)\tPrec@1 83.000 (82.190)\tPrec@5 96.000 (96.388)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 4.6310 (4.1287)\tPrec@1 78.000 (82.275)\tPrec@5 94.000 (96.366)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 4.9436 (4.1300)\tPrec@1 81.000 (82.220)\tPrec@5 95.000 (96.376)\n",
            "Test: [150/261]\tTime 0.022 (0.030)\tLoss 2.9850 (4.1180)\tPrec@1 87.000 (82.272)\tPrec@5 98.000 (96.391)\n",
            "Test: [160/261]\tTime 0.042 (0.030)\tLoss 2.2278 (4.1100)\tPrec@1 92.000 (82.236)\tPrec@5 99.000 (96.398)\n",
            "Test: [170/261]\tTime 0.023 (0.029)\tLoss 3.7124 (4.0899)\tPrec@1 82.000 (82.281)\tPrec@5 96.000 (96.404)\n",
            "Test: [180/261]\tTime 0.029 (0.029)\tLoss 4.1226 (4.0881)\tPrec@1 82.000 (82.243)\tPrec@5 97.000 (96.420)\n",
            "Test: [190/261]\tTime 0.034 (0.030)\tLoss 3.7828 (4.0756)\tPrec@1 82.000 (82.314)\tPrec@5 93.000 (96.419)\n",
            "Test: [200/261]\tTime 0.035 (0.030)\tLoss 3.7992 (4.0620)\tPrec@1 82.000 (82.328)\tPrec@5 96.000 (96.463)\n",
            "Test: [210/261]\tTime 0.039 (0.031)\tLoss 3.4869 (4.0505)\tPrec@1 83.000 (82.379)\tPrec@5 99.000 (96.460)\n",
            "Test: [220/261]\tTime 0.032 (0.032)\tLoss 4.3120 (4.0529)\tPrec@1 82.000 (82.394)\tPrec@5 96.000 (96.443)\n",
            "Test: [230/261]\tTime 0.034 (0.032)\tLoss 4.8497 (4.0572)\tPrec@1 80.000 (82.351)\tPrec@5 95.000 (96.420)\n",
            "Test: [240/261]\tTime 0.047 (0.032)\tLoss 4.3562 (4.0610)\tPrec@1 82.000 (82.361)\tPrec@5 98.000 (96.423)\n",
            "Test: [250/261]\tTime 0.037 (0.033)\tLoss 3.3686 (4.0388)\tPrec@1 83.000 (82.450)\tPrec@5 96.000 (96.454)\n",
            "Test: [260/261]\tTime 0.010 (0.032)\tLoss 2.5747 (4.0425)\tPrec@1 90.625 (82.460)\tPrec@5 96.875 (96.439)\n",
            "val Results: Prec@1 82.460 Prec@5 96.439 Loss 4.04247\n",
            "val Class Accuracy: [0.688,0.908,0.959,0.737,0.895,0.852,0.656,0.812,0.792,0.627]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [87][0/66], lr: 0.01000\tTime 0.686 (0.686)\tData 0.597 (0.597)\tLoss 0.7243 (0.7243)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][10/66], lr: 0.01000\tTime 0.100 (0.152)\tData 0.000 (0.060)\tLoss 0.5244 (0.5532)\tPrec@1 97.656 (97.017)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [87][20/66], lr: 0.01000\tTime 0.089 (0.125)\tData 0.016 (0.036)\tLoss 0.3782 (0.5659)\tPrec@1 98.438 (96.987)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [87][30/66], lr: 0.01000\tTime 0.125 (0.117)\tData 0.000 (0.028)\tLoss 0.6791 (0.5919)\tPrec@1 96.875 (96.988)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [87][40/66], lr: 0.01000\tTime 0.110 (0.114)\tData 0.039 (0.026)\tLoss 0.7055 (0.5795)\tPrec@1 96.875 (97.075)\tPrec@5 100.000 (99.905)\n",
            "Epoch: [87][50/66], lr: 0.01000\tTime 0.095 (0.112)\tData 0.016 (0.023)\tLoss 0.6919 (0.5470)\tPrec@1 95.703 (97.266)\tPrec@5 100.000 (99.916)\n",
            "Epoch: [87][60/66], lr: 0.01000\tTime 0.062 (0.109)\tData 0.000 (0.020)\tLoss 0.6405 (0.5435)\tPrec@1 96.484 (97.240)\tPrec@5 99.609 (99.917)\n",
            "Test: [0/261]\tTime 0.325 (0.325)\tLoss 4.5345 (4.5345)\tPrec@1 83.000 (83.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.016 (0.056)\tLoss 6.0539 (5.3894)\tPrec@1 78.000 (78.273)\tPrec@5 94.000 (93.818)\n",
            "Test: [20/261]\tTime 0.023 (0.042)\tLoss 5.5632 (5.3600)\tPrec@1 75.000 (78.190)\tPrec@5 94.000 (94.190)\n",
            "Test: [30/261]\tTime 0.022 (0.038)\tLoss 3.7473 (5.1734)\tPrec@1 82.000 (78.903)\tPrec@5 96.000 (94.581)\n",
            "Test: [40/261]\tTime 0.038 (0.034)\tLoss 4.3195 (5.1465)\tPrec@1 85.000 (79.024)\tPrec@5 95.000 (94.805)\n",
            "Test: [50/261]\tTime 0.041 (0.033)\tLoss 5.0069 (5.1318)\tPrec@1 80.000 (79.078)\tPrec@5 95.000 (94.667)\n",
            "Test: [60/261]\tTime 0.025 (0.032)\tLoss 5.9206 (5.1065)\tPrec@1 79.000 (79.311)\tPrec@5 90.000 (94.754)\n",
            "Test: [70/261]\tTime 0.026 (0.031)\tLoss 6.4818 (5.0937)\tPrec@1 75.000 (79.451)\tPrec@5 93.000 (94.718)\n",
            "Test: [80/261]\tTime 0.047 (0.031)\tLoss 5.6338 (5.1332)\tPrec@1 78.000 (79.198)\tPrec@5 94.000 (94.679)\n",
            "Test: [90/261]\tTime 0.033 (0.030)\tLoss 5.4927 (5.1707)\tPrec@1 78.000 (79.088)\tPrec@5 95.000 (94.549)\n",
            "Test: [100/261]\tTime 0.010 (0.030)\tLoss 5.8719 (5.1632)\tPrec@1 75.000 (79.069)\tPrec@5 94.000 (94.525)\n",
            "Test: [110/261]\tTime 0.032 (0.030)\tLoss 4.9236 (5.1246)\tPrec@1 81.000 (79.189)\tPrec@5 95.000 (94.577)\n",
            "Test: [120/261]\tTime 0.040 (0.030)\tLoss 4.2254 (5.1301)\tPrec@1 81.000 (79.174)\tPrec@5 94.000 (94.504)\n",
            "Test: [130/261]\tTime 0.022 (0.030)\tLoss 5.6353 (5.1208)\tPrec@1 75.000 (79.160)\tPrec@5 92.000 (94.443)\n",
            "Test: [140/261]\tTime 0.054 (0.030)\tLoss 5.2337 (5.1081)\tPrec@1 78.000 (79.177)\tPrec@5 91.000 (94.504)\n",
            "Test: [150/261]\tTime 0.022 (0.029)\tLoss 3.9048 (5.1103)\tPrec@1 84.000 (79.159)\tPrec@5 94.000 (94.470)\n",
            "Test: [160/261]\tTime 0.032 (0.029)\tLoss 3.0631 (5.0848)\tPrec@1 89.000 (79.242)\tPrec@5 98.000 (94.516)\n",
            "Test: [170/261]\tTime 0.020 (0.029)\tLoss 5.1694 (5.0754)\tPrec@1 78.000 (79.287)\tPrec@5 94.000 (94.538)\n",
            "Test: [180/261]\tTime 0.045 (0.029)\tLoss 4.0209 (5.0649)\tPrec@1 86.000 (79.354)\tPrec@5 95.000 (94.541)\n",
            "Test: [190/261]\tTime 0.013 (0.029)\tLoss 4.2740 (5.0452)\tPrec@1 83.000 (79.424)\tPrec@5 94.000 (94.623)\n",
            "Test: [200/261]\tTime 0.028 (0.029)\tLoss 6.2029 (5.0668)\tPrec@1 77.000 (79.294)\tPrec@5 92.000 (94.612)\n",
            "Test: [210/261]\tTime 0.029 (0.029)\tLoss 3.9086 (5.0562)\tPrec@1 84.000 (79.294)\tPrec@5 97.000 (94.649)\n",
            "Test: [220/261]\tTime 0.011 (0.028)\tLoss 5.5714 (5.0687)\tPrec@1 80.000 (79.244)\tPrec@5 93.000 (94.606)\n",
            "Test: [230/261]\tTime 0.048 (0.029)\tLoss 6.0559 (5.0782)\tPrec@1 77.000 (79.225)\tPrec@5 93.000 (94.602)\n",
            "Test: [240/261]\tTime 0.026 (0.028)\tLoss 4.2090 (5.0755)\tPrec@1 82.000 (79.178)\tPrec@5 98.000 (94.635)\n",
            "Test: [250/261]\tTime 0.032 (0.028)\tLoss 5.0369 (5.0602)\tPrec@1 79.000 (79.235)\tPrec@5 94.000 (94.669)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 5.1299 (5.0728)\tPrec@1 75.000 (79.233)\tPrec@5 96.875 (94.591)\n",
            "val Results: Prec@1 79.233 Prec@5 94.591 Loss 5.07284\n",
            "val Class Accuracy: [0.673,0.962,0.954,0.868,0.849,0.692,0.684,0.503,0.743,0.434]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [88][0/66], lr: 0.01000\tTime 0.663 (0.663)\tData 0.573 (0.573)\tLoss 0.5418 (0.5418)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [88][10/66], lr: 0.01000\tTime 0.118 (0.151)\tData 0.005 (0.058)\tLoss 0.4956 (0.5476)\tPrec@1 97.656 (97.372)\tPrec@5 99.609 (99.787)\n",
            "Epoch: [88][20/66], lr: 0.01000\tTime 0.095 (0.125)\tData 0.002 (0.032)\tLoss 0.4559 (0.5426)\tPrec@1 96.875 (97.266)\tPrec@5 99.609 (99.870)\n",
            "Epoch: [88][30/66], lr: 0.01000\tTime 0.112 (0.117)\tData 0.000 (0.024)\tLoss 0.6917 (0.5224)\tPrec@1 95.703 (97.291)\tPrec@5 100.000 (99.874)\n",
            "Epoch: [88][40/66], lr: 0.01000\tTime 0.093 (0.113)\tData 0.005 (0.019)\tLoss 0.1528 (0.5180)\tPrec@1 99.219 (97.304)\tPrec@5 100.000 (99.876)\n",
            "Epoch: [88][50/66], lr: 0.01000\tTime 0.103 (0.111)\tData 0.000 (0.017)\tLoss 0.3858 (0.5122)\tPrec@1 98.047 (97.327)\tPrec@5 100.000 (99.900)\n",
            "Epoch: [88][60/66], lr: 0.01000\tTime 0.069 (0.108)\tData 0.000 (0.015)\tLoss 0.2999 (0.4962)\tPrec@1 98.828 (97.407)\tPrec@5 100.000 (99.910)\n",
            "Test: [0/261]\tTime 0.354 (0.354)\tLoss 3.9324 (3.9324)\tPrec@1 83.000 (83.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.036 (0.058)\tLoss 4.7050 (4.0372)\tPrec@1 82.000 (83.273)\tPrec@5 96.000 (96.364)\n",
            "Test: [20/261]\tTime 0.031 (0.039)\tLoss 4.4524 (3.9091)\tPrec@1 81.000 (83.476)\tPrec@5 95.000 (96.619)\n",
            "Test: [30/261]\tTime 0.021 (0.035)\tLoss 2.9803 (3.6818)\tPrec@1 88.000 (84.419)\tPrec@5 98.000 (96.903)\n",
            "Test: [40/261]\tTime 0.030 (0.034)\tLoss 3.3591 (3.5677)\tPrec@1 85.000 (84.902)\tPrec@5 97.000 (97.098)\n",
            "Test: [50/261]\tTime 0.032 (0.033)\tLoss 3.3440 (3.6061)\tPrec@1 86.000 (84.843)\tPrec@5 99.000 (97.000)\n",
            "Test: [60/261]\tTime 0.033 (0.032)\tLoss 3.4663 (3.6291)\tPrec@1 82.000 (84.820)\tPrec@5 98.000 (96.852)\n",
            "Test: [70/261]\tTime 0.037 (0.031)\tLoss 4.0465 (3.6082)\tPrec@1 83.000 (84.958)\tPrec@5 97.000 (96.845)\n",
            "Test: [80/261]\tTime 0.019 (0.031)\tLoss 4.0942 (3.6249)\tPrec@1 82.000 (84.951)\tPrec@5 97.000 (96.926)\n",
            "Test: [90/261]\tTime 0.023 (0.030)\tLoss 4.4974 (3.7076)\tPrec@1 81.000 (84.582)\tPrec@5 94.000 (96.791)\n",
            "Test: [100/261]\tTime 0.019 (0.030)\tLoss 4.6371 (3.7168)\tPrec@1 81.000 (84.495)\tPrec@5 95.000 (96.782)\n",
            "Test: [110/261]\tTime 0.028 (0.029)\tLoss 3.7981 (3.6971)\tPrec@1 84.000 (84.495)\tPrec@5 96.000 (96.856)\n",
            "Test: [120/261]\tTime 0.025 (0.029)\tLoss 3.2176 (3.6951)\tPrec@1 87.000 (84.521)\tPrec@5 94.000 (96.777)\n",
            "Test: [130/261]\tTime 0.021 (0.029)\tLoss 4.2532 (3.7142)\tPrec@1 85.000 (84.420)\tPrec@5 94.000 (96.740)\n",
            "Test: [140/261]\tTime 0.027 (0.029)\tLoss 4.2832 (3.7086)\tPrec@1 83.000 (84.390)\tPrec@5 96.000 (96.816)\n",
            "Test: [150/261]\tTime 0.011 (0.029)\tLoss 3.1297 (3.7007)\tPrec@1 87.000 (84.477)\tPrec@5 97.000 (96.768)\n",
            "Test: [160/261]\tTime 0.013 (0.029)\tLoss 2.4740 (3.7034)\tPrec@1 91.000 (84.460)\tPrec@5 99.000 (96.826)\n",
            "Test: [170/261]\tTime 0.039 (0.028)\tLoss 2.5096 (3.6740)\tPrec@1 89.000 (84.591)\tPrec@5 100.000 (96.848)\n",
            "Test: [180/261]\tTime 0.014 (0.028)\tLoss 3.6107 (3.6903)\tPrec@1 84.000 (84.519)\tPrec@5 96.000 (96.829)\n",
            "Test: [190/261]\tTime 0.028 (0.028)\tLoss 4.5730 (3.6850)\tPrec@1 78.000 (84.534)\tPrec@5 98.000 (96.817)\n",
            "Test: [200/261]\tTime 0.028 (0.028)\tLoss 4.1110 (3.6985)\tPrec@1 82.000 (84.453)\tPrec@5 97.000 (96.831)\n",
            "Test: [210/261]\tTime 0.036 (0.028)\tLoss 3.5297 (3.6855)\tPrec@1 83.000 (84.498)\tPrec@5 99.000 (96.848)\n",
            "Test: [220/261]\tTime 0.026 (0.028)\tLoss 5.1361 (3.6971)\tPrec@1 79.000 (84.421)\tPrec@5 96.000 (96.837)\n",
            "Test: [230/261]\tTime 0.026 (0.028)\tLoss 5.0362 (3.7176)\tPrec@1 80.000 (84.299)\tPrec@5 94.000 (96.801)\n",
            "Test: [240/261]\tTime 0.015 (0.028)\tLoss 3.2518 (3.7229)\tPrec@1 85.000 (84.278)\tPrec@5 98.000 (96.801)\n",
            "Test: [250/261]\tTime 0.028 (0.028)\tLoss 3.6739 (3.7006)\tPrec@1 85.000 (84.359)\tPrec@5 98.000 (96.849)\n",
            "Test: [260/261]\tTime 0.005 (0.027)\tLoss 2.8707 (3.7010)\tPrec@1 87.500 (84.358)\tPrec@5 96.875 (96.839)\n",
            "val Results: Prec@1 84.358 Prec@5 96.839 Loss 3.70098\n",
            "val Class Accuracy: [0.726,0.983,0.905,0.819,0.840,0.854,0.857,0.689,0.719,0.710]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [89][0/66], lr: 0.01000\tTime 0.641 (0.641)\tData 0.541 (0.541)\tLoss 0.3954 (0.3954)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [89][10/66], lr: 0.01000\tTime 0.086 (0.156)\tData 0.005 (0.064)\tLoss 0.6197 (0.5059)\tPrec@1 96.875 (97.301)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [89][20/66], lr: 0.01000\tTime 0.108 (0.131)\tData 0.041 (0.040)\tLoss 0.3233 (0.4959)\tPrec@1 98.828 (97.377)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [89][30/66], lr: 0.01000\tTime 0.105 (0.122)\tData 0.005 (0.030)\tLoss 0.4518 (0.4987)\tPrec@1 97.266 (97.429)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [89][40/66], lr: 0.01000\tTime 0.113 (0.117)\tData 0.004 (0.024)\tLoss 0.7593 (0.5033)\tPrec@1 95.703 (97.370)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [89][50/66], lr: 0.01000\tTime 0.110 (0.114)\tData 0.000 (0.021)\tLoss 0.3705 (0.4970)\tPrec@1 97.656 (97.396)\tPrec@5 100.000 (99.946)\n",
            "Epoch: [89][60/66], lr: 0.01000\tTime 0.076 (0.110)\tData 0.000 (0.018)\tLoss 0.6332 (0.4954)\tPrec@1 96.875 (97.432)\tPrec@5 100.000 (99.955)\n",
            "Test: [0/261]\tTime 0.325 (0.325)\tLoss 4.9892 (4.9892)\tPrec@1 78.000 (78.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.041 (0.057)\tLoss 5.2834 (4.8698)\tPrec@1 79.000 (79.091)\tPrec@5 93.000 (94.909)\n",
            "Test: [20/261]\tTime 0.026 (0.043)\tLoss 4.7773 (4.6390)\tPrec@1 81.000 (79.810)\tPrec@5 96.000 (95.429)\n",
            "Test: [30/261]\tTime 0.022 (0.038)\tLoss 3.1399 (4.3435)\tPrec@1 87.000 (81.516)\tPrec@5 99.000 (95.742)\n",
            "Test: [40/261]\tTime 0.019 (0.036)\tLoss 4.8017 (4.3033)\tPrec@1 83.000 (81.805)\tPrec@5 94.000 (95.878)\n",
            "Test: [50/261]\tTime 0.029 (0.034)\tLoss 4.5954 (4.2811)\tPrec@1 82.000 (81.902)\tPrec@5 96.000 (95.902)\n",
            "Test: [60/261]\tTime 0.040 (0.033)\tLoss 4.4671 (4.2581)\tPrec@1 83.000 (81.984)\tPrec@5 96.000 (95.951)\n",
            "Test: [70/261]\tTime 0.026 (0.032)\tLoss 4.9144 (4.2217)\tPrec@1 81.000 (82.197)\tPrec@5 99.000 (96.085)\n",
            "Test: [80/261]\tTime 0.028 (0.031)\tLoss 4.3528 (4.1985)\tPrec@1 81.000 (82.235)\tPrec@5 94.000 (96.074)\n",
            "Test: [90/261]\tTime 0.065 (0.031)\tLoss 4.9384 (4.2398)\tPrec@1 80.000 (82.132)\tPrec@5 93.000 (95.956)\n",
            "Test: [100/261]\tTime 0.022 (0.031)\tLoss 4.5355 (4.2219)\tPrec@1 81.000 (82.188)\tPrec@5 93.000 (95.960)\n",
            "Test: [110/261]\tTime 0.042 (0.030)\tLoss 4.2443 (4.2043)\tPrec@1 85.000 (82.198)\tPrec@5 96.000 (96.063)\n",
            "Test: [120/261]\tTime 0.030 (0.030)\tLoss 2.8421 (4.2056)\tPrec@1 88.000 (82.240)\tPrec@5 97.000 (96.058)\n",
            "Test: [130/261]\tTime 0.046 (0.030)\tLoss 4.4229 (4.2255)\tPrec@1 83.000 (82.160)\tPrec@5 96.000 (96.023)\n",
            "Test: [140/261]\tTime 0.018 (0.030)\tLoss 4.7288 (4.2083)\tPrec@1 80.000 (82.199)\tPrec@5 95.000 (96.035)\n",
            "Test: [150/261]\tTime 0.014 (0.029)\tLoss 3.6084 (4.2226)\tPrec@1 84.000 (82.166)\tPrec@5 97.000 (96.007)\n",
            "Test: [160/261]\tTime 0.019 (0.029)\tLoss 2.9205 (4.2264)\tPrec@1 88.000 (82.099)\tPrec@5 99.000 (96.106)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 2.9704 (4.2138)\tPrec@1 86.000 (82.181)\tPrec@5 98.000 (96.082)\n",
            "Test: [180/261]\tTime 0.032 (0.029)\tLoss 3.9289 (4.2096)\tPrec@1 84.000 (82.199)\tPrec@5 97.000 (96.110)\n",
            "Test: [190/261]\tTime 0.024 (0.029)\tLoss 4.0493 (4.2065)\tPrec@1 82.000 (82.188)\tPrec@5 94.000 (96.136)\n",
            "Test: [200/261]\tTime 0.024 (0.029)\tLoss 4.1850 (4.2045)\tPrec@1 82.000 (82.169)\tPrec@5 95.000 (96.129)\n",
            "Test: [210/261]\tTime 0.050 (0.030)\tLoss 4.1068 (4.2053)\tPrec@1 85.000 (82.166)\tPrec@5 97.000 (96.118)\n",
            "Test: [220/261]\tTime 0.035 (0.030)\tLoss 4.6967 (4.2146)\tPrec@1 79.000 (82.104)\tPrec@5 98.000 (96.127)\n",
            "Test: [230/261]\tTime 0.032 (0.031)\tLoss 4.7013 (4.2289)\tPrec@1 83.000 (82.030)\tPrec@5 94.000 (96.126)\n",
            "Test: [240/261]\tTime 0.026 (0.031)\tLoss 4.3270 (4.2358)\tPrec@1 79.000 (82.012)\tPrec@5 96.000 (96.104)\n",
            "Test: [250/261]\tTime 0.046 (0.032)\tLoss 3.8125 (4.2163)\tPrec@1 86.000 (82.100)\tPrec@5 96.000 (96.147)\n",
            "Test: [260/261]\tTime 0.007 (0.031)\tLoss 2.1320 (4.2182)\tPrec@1 90.625 (82.110)\tPrec@5 96.875 (96.112)\n",
            "val Results: Prec@1 82.110 Prec@5 96.112 Loss 4.21824\n",
            "val Class Accuracy: [0.696,0.982,0.960,0.703,0.800,0.789,0.826,0.747,0.737,0.553]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [90][0/66], lr: 0.01000\tTime 0.798 (0.798)\tData 0.686 (0.686)\tLoss 0.4767 (0.4767)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][10/66], lr: 0.01000\tTime 0.118 (0.174)\tData 0.003 (0.070)\tLoss 0.3644 (0.4402)\tPrec@1 99.219 (97.763)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [90][20/66], lr: 0.01000\tTime 0.084 (0.142)\tData 0.000 (0.038)\tLoss 0.2410 (0.3949)\tPrec@1 99.219 (97.954)\tPrec@5 100.000 (99.981)\n",
            "Epoch: [90][30/66], lr: 0.01000\tTime 0.085 (0.127)\tData 0.001 (0.028)\tLoss 0.4728 (0.4405)\tPrec@1 98.047 (97.719)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [90][40/66], lr: 0.01000\tTime 0.093 (0.120)\tData 0.006 (0.023)\tLoss 0.4966 (0.4461)\tPrec@1 97.656 (97.752)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [90][50/66], lr: 0.01000\tTime 0.117 (0.118)\tData 0.000 (0.019)\tLoss 0.2129 (0.4536)\tPrec@1 98.438 (97.695)\tPrec@5 99.609 (99.946)\n",
            "Epoch: [90][60/66], lr: 0.01000\tTime 0.070 (0.114)\tData 0.000 (0.017)\tLoss 0.5337 (0.4497)\tPrec@1 97.266 (97.695)\tPrec@5 100.000 (99.936)\n",
            "Test: [0/261]\tTime 0.374 (0.374)\tLoss 4.8627 (4.8627)\tPrec@1 80.000 (80.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.018 (0.055)\tLoss 5.6458 (5.3508)\tPrec@1 79.000 (78.909)\tPrec@5 94.000 (93.455)\n",
            "Test: [20/261]\tTime 0.015 (0.041)\tLoss 5.6783 (5.2852)\tPrec@1 74.000 (79.095)\tPrec@5 93.000 (93.238)\n",
            "Test: [30/261]\tTime 0.018 (0.038)\tLoss 3.6615 (5.0645)\tPrec@1 85.000 (80.000)\tPrec@5 95.000 (93.645)\n",
            "Test: [40/261]\tTime 0.014 (0.035)\tLoss 3.4733 (4.9341)\tPrec@1 87.000 (80.439)\tPrec@5 96.000 (94.220)\n",
            "Test: [50/261]\tTime 0.046 (0.034)\tLoss 4.5325 (4.8959)\tPrec@1 82.000 (80.588)\tPrec@5 96.000 (94.294)\n",
            "Test: [60/261]\tTime 0.043 (0.033)\tLoss 5.2089 (4.8392)\tPrec@1 82.000 (80.803)\tPrec@5 93.000 (94.443)\n",
            "Test: [70/261]\tTime 0.030 (0.032)\tLoss 5.2663 (4.8263)\tPrec@1 80.000 (80.901)\tPrec@5 92.000 (94.493)\n",
            "Test: [80/261]\tTime 0.019 (0.032)\tLoss 5.5381 (4.8441)\tPrec@1 77.000 (80.864)\tPrec@5 96.000 (94.395)\n",
            "Test: [90/261]\tTime 0.012 (0.031)\tLoss 5.9304 (4.9157)\tPrec@1 78.000 (80.637)\tPrec@5 91.000 (94.286)\n",
            "Test: [100/261]\tTime 0.042 (0.031)\tLoss 5.5967 (4.9058)\tPrec@1 79.000 (80.703)\tPrec@5 91.000 (94.297)\n",
            "Test: [110/261]\tTime 0.019 (0.030)\tLoss 5.1879 (4.8669)\tPrec@1 83.000 (80.847)\tPrec@5 93.000 (94.342)\n",
            "Test: [120/261]\tTime 0.025 (0.030)\tLoss 4.4635 (4.8499)\tPrec@1 81.000 (80.926)\tPrec@5 93.000 (94.364)\n",
            "Test: [130/261]\tTime 0.032 (0.030)\tLoss 3.9595 (4.8509)\tPrec@1 85.000 (80.908)\tPrec@5 96.000 (94.359)\n",
            "Test: [140/261]\tTime 0.037 (0.030)\tLoss 5.8691 (4.8586)\tPrec@1 78.000 (80.879)\tPrec@5 94.000 (94.397)\n",
            "Test: [150/261]\tTime 0.027 (0.030)\tLoss 5.0152 (4.8868)\tPrec@1 81.000 (80.801)\tPrec@5 95.000 (94.358)\n",
            "Test: [160/261]\tTime 0.024 (0.030)\tLoss 3.4046 (4.8908)\tPrec@1 89.000 (80.758)\tPrec@5 98.000 (94.360)\n",
            "Test: [170/261]\tTime 0.023 (0.029)\tLoss 3.5929 (4.8643)\tPrec@1 85.000 (80.889)\tPrec@5 95.000 (94.404)\n",
            "Test: [180/261]\tTime 0.033 (0.029)\tLoss 4.1134 (4.8572)\tPrec@1 84.000 (80.917)\tPrec@5 95.000 (94.370)\n",
            "Test: [190/261]\tTime 0.059 (0.029)\tLoss 4.8790 (4.8611)\tPrec@1 81.000 (80.906)\tPrec@5 95.000 (94.351)\n",
            "Test: [200/261]\tTime 0.040 (0.029)\tLoss 5.2239 (4.8652)\tPrec@1 79.000 (80.836)\tPrec@5 93.000 (94.338)\n",
            "Test: [210/261]\tTime 0.014 (0.029)\tLoss 4.4468 (4.8508)\tPrec@1 82.000 (80.882)\tPrec@5 96.000 (94.341)\n",
            "Test: [220/261]\tTime 0.025 (0.029)\tLoss 4.7197 (4.8536)\tPrec@1 82.000 (80.869)\tPrec@5 95.000 (94.326)\n",
            "Test: [230/261]\tTime 0.046 (0.029)\tLoss 5.2965 (4.8585)\tPrec@1 79.000 (80.840)\tPrec@5 91.000 (94.329)\n",
            "Test: [240/261]\tTime 0.028 (0.029)\tLoss 4.6940 (4.8672)\tPrec@1 82.000 (80.809)\tPrec@5 93.000 (94.299)\n",
            "Test: [250/261]\tTime 0.029 (0.029)\tLoss 4.9088 (4.8432)\tPrec@1 81.000 (80.876)\tPrec@5 93.000 (94.363)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 1.9372 (4.8481)\tPrec@1 93.750 (80.885)\tPrec@5 96.875 (94.345)\n",
            "val Results: Prec@1 80.885 Prec@5 94.345 Loss 4.84806\n",
            "val Class Accuracy: [0.574,0.943,0.869,0.949,0.860,0.763,0.711,0.799,0.770,0.387]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [91][0/66], lr: 0.01000\tTime 0.589 (0.589)\tData 0.500 (0.500)\tLoss 0.6260 (0.6260)\tPrec@1 96.875 (96.875)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [91][10/66], lr: 0.01000\tTime 0.082 (0.145)\tData 0.005 (0.054)\tLoss 0.7193 (0.5195)\tPrec@1 96.484 (97.372)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [91][20/66], lr: 0.01000\tTime 0.097 (0.125)\tData 0.041 (0.037)\tLoss 0.6659 (0.5312)\tPrec@1 96.484 (97.414)\tPrec@5 99.609 (99.888)\n",
            "Epoch: [91][30/66], lr: 0.01000\tTime 0.089 (0.119)\tData 0.004 (0.032)\tLoss 0.2804 (0.5269)\tPrec@1 98.828 (97.366)\tPrec@5 100.000 (99.861)\n",
            "Epoch: [91][40/66], lr: 0.01000\tTime 0.099 (0.114)\tData 0.004 (0.026)\tLoss 0.3862 (0.5111)\tPrec@1 97.656 (97.447)\tPrec@5 100.000 (99.886)\n",
            "Epoch: [91][50/66], lr: 0.01000\tTime 0.114 (0.111)\tData 0.002 (0.022)\tLoss 0.7701 (0.5413)\tPrec@1 96.484 (97.289)\tPrec@5 100.000 (99.870)\n",
            "Epoch: [91][60/66], lr: 0.01000\tTime 0.078 (0.108)\tData 0.038 (0.021)\tLoss 0.3973 (0.5293)\tPrec@1 98.828 (97.342)\tPrec@5 100.000 (99.872)\n",
            "Test: [0/261]\tTime 0.282 (0.282)\tLoss 3.0277 (3.0277)\tPrec@1 86.000 (86.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.017 (0.055)\tLoss 4.7105 (3.7138)\tPrec@1 81.000 (84.000)\tPrec@5 97.000 (96.182)\n",
            "Test: [20/261]\tTime 0.028 (0.041)\tLoss 4.3467 (3.7209)\tPrec@1 81.000 (83.714)\tPrec@5 96.000 (96.143)\n",
            "Test: [30/261]\tTime 0.011 (0.037)\tLoss 3.9296 (3.5607)\tPrec@1 83.000 (84.548)\tPrec@5 95.000 (96.355)\n",
            "Test: [40/261]\tTime 0.012 (0.035)\tLoss 2.9227 (3.4470)\tPrec@1 90.000 (85.220)\tPrec@5 99.000 (96.634)\n",
            "Test: [50/261]\tTime 0.019 (0.034)\tLoss 3.3238 (3.4206)\tPrec@1 86.000 (85.490)\tPrec@5 97.000 (96.608)\n",
            "Test: [60/261]\tTime 0.018 (0.032)\tLoss 3.5306 (3.4180)\tPrec@1 85.000 (85.541)\tPrec@5 97.000 (96.607)\n",
            "Test: [70/261]\tTime 0.033 (0.031)\tLoss 4.2882 (3.4205)\tPrec@1 81.000 (85.507)\tPrec@5 96.000 (96.577)\n",
            "Test: [80/261]\tTime 0.049 (0.031)\tLoss 3.7827 (3.4535)\tPrec@1 83.000 (85.321)\tPrec@5 98.000 (96.543)\n",
            "Test: [90/261]\tTime 0.018 (0.030)\tLoss 5.1233 (3.5338)\tPrec@1 78.000 (84.978)\tPrec@5 94.000 (96.451)\n",
            "Test: [100/261]\tTime 0.017 (0.030)\tLoss 3.9323 (3.5177)\tPrec@1 82.000 (85.040)\tPrec@5 95.000 (96.485)\n",
            "Test: [110/261]\tTime 0.021 (0.030)\tLoss 3.7653 (3.5111)\tPrec@1 87.000 (85.072)\tPrec@5 98.000 (96.495)\n",
            "Test: [120/261]\tTime 0.031 (0.029)\tLoss 2.8355 (3.5092)\tPrec@1 87.000 (85.124)\tPrec@5 97.000 (96.471)\n",
            "Test: [130/261]\tTime 0.047 (0.029)\tLoss 3.3286 (3.5353)\tPrec@1 87.000 (85.023)\tPrec@5 95.000 (96.458)\n",
            "Test: [140/261]\tTime 0.032 (0.029)\tLoss 4.9823 (3.5391)\tPrec@1 79.000 (84.979)\tPrec@5 93.000 (96.433)\n",
            "Test: [150/261]\tTime 0.036 (0.029)\tLoss 3.5321 (3.5365)\tPrec@1 85.000 (84.974)\tPrec@5 98.000 (96.477)\n",
            "Test: [160/261]\tTime 0.030 (0.029)\tLoss 2.0149 (3.5195)\tPrec@1 92.000 (85.031)\tPrec@5 98.000 (96.503)\n",
            "Test: [170/261]\tTime 0.023 (0.029)\tLoss 2.4895 (3.5118)\tPrec@1 89.000 (85.023)\tPrec@5 97.000 (96.509)\n",
            "Test: [180/261]\tTime 0.038 (0.029)\tLoss 3.3781 (3.4983)\tPrec@1 84.000 (85.066)\tPrec@5 96.000 (96.508)\n",
            "Test: [190/261]\tTime 0.031 (0.029)\tLoss 3.1864 (3.4944)\tPrec@1 86.000 (85.099)\tPrec@5 95.000 (96.524)\n",
            "Test: [200/261]\tTime 0.026 (0.029)\tLoss 2.8520 (3.4944)\tPrec@1 86.000 (85.040)\tPrec@5 97.000 (96.547)\n",
            "Test: [210/261]\tTime 0.028 (0.029)\tLoss 2.8653 (3.4851)\tPrec@1 87.000 (85.062)\tPrec@5 98.000 (96.545)\n",
            "Test: [220/261]\tTime 0.021 (0.029)\tLoss 3.3373 (3.4905)\tPrec@1 86.000 (85.045)\tPrec@5 97.000 (96.543)\n",
            "Test: [230/261]\tTime 0.023 (0.028)\tLoss 3.7033 (3.4867)\tPrec@1 83.000 (85.078)\tPrec@5 95.000 (96.537)\n",
            "Test: [240/261]\tTime 0.041 (0.028)\tLoss 3.2953 (3.4945)\tPrec@1 85.000 (85.021)\tPrec@5 99.000 (96.531)\n",
            "Test: [250/261]\tTime 0.025 (0.028)\tLoss 2.3823 (3.4723)\tPrec@1 89.000 (85.092)\tPrec@5 98.000 (96.566)\n",
            "Test: [260/261]\tTime 0.005 (0.028)\tLoss 2.3071 (3.4702)\tPrec@1 87.500 (85.111)\tPrec@5 96.875 (96.539)\n",
            "val Results: Prec@1 85.111 Prec@5 96.539 Loss 3.47016\n",
            "val Class Accuracy: [0.778,0.973,0.909,0.873,0.857,0.759,0.800,0.793,0.706,0.768]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [92][0/66], lr: 0.01000\tTime 0.713 (0.713)\tData 0.616 (0.616)\tLoss 0.6260 (0.6260)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [92][10/66], lr: 0.01000\tTime 0.087 (0.158)\tData 0.005 (0.063)\tLoss 0.3907 (0.4888)\tPrec@1 98.828 (97.585)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [92][20/66], lr: 0.01000\tTime 0.075 (0.129)\tData 0.006 (0.035)\tLoss 0.6700 (0.4911)\tPrec@1 96.875 (97.452)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [92][30/66], lr: 0.01000\tTime 0.114 (0.118)\tData 0.000 (0.025)\tLoss 0.4956 (0.4729)\tPrec@1 97.266 (97.593)\tPrec@5 99.609 (99.950)\n",
            "Epoch: [92][40/66], lr: 0.01000\tTime 0.105 (0.114)\tData 0.005 (0.020)\tLoss 0.6433 (0.4675)\tPrec@1 96.875 (97.609)\tPrec@5 99.609 (99.933)\n",
            "Epoch: [92][50/66], lr: 0.01000\tTime 0.085 (0.109)\tData 0.000 (0.017)\tLoss 0.3963 (0.4811)\tPrec@1 98.438 (97.603)\tPrec@5 100.000 (99.923)\n",
            "Epoch: [92][60/66], lr: 0.01000\tTime 0.112 (0.108)\tData 0.000 (0.017)\tLoss 0.5225 (0.4870)\tPrec@1 96.484 (97.579)\tPrec@5 100.000 (99.923)\n",
            "Test: [0/261]\tTime 0.337 (0.337)\tLoss 4.1606 (4.1606)\tPrec@1 84.000 (84.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.044 (0.059)\tLoss 4.4753 (4.1758)\tPrec@1 82.000 (82.000)\tPrec@5 96.000 (96.182)\n",
            "Test: [20/261]\tTime 0.011 (0.044)\tLoss 3.9227 (4.1849)\tPrec@1 81.000 (81.905)\tPrec@5 97.000 (96.429)\n",
            "Test: [30/261]\tTime 0.028 (0.039)\tLoss 3.2569 (3.9439)\tPrec@1 86.000 (83.129)\tPrec@5 97.000 (96.710)\n",
            "Test: [40/261]\tTime 0.030 (0.035)\tLoss 3.4243 (3.7863)\tPrec@1 84.000 (83.805)\tPrec@5 96.000 (96.902)\n",
            "Test: [50/261]\tTime 0.041 (0.034)\tLoss 2.8597 (3.7269)\tPrec@1 88.000 (84.039)\tPrec@5 98.000 (96.902)\n",
            "Test: [60/261]\tTime 0.030 (0.033)\tLoss 3.2555 (3.6885)\tPrec@1 89.000 (84.279)\tPrec@5 96.000 (96.852)\n",
            "Test: [70/261]\tTime 0.053 (0.032)\tLoss 4.1694 (3.6772)\tPrec@1 82.000 (84.380)\tPrec@5 99.000 (96.901)\n",
            "Test: [80/261]\tTime 0.034 (0.032)\tLoss 4.0038 (3.6787)\tPrec@1 84.000 (84.420)\tPrec@5 97.000 (96.901)\n",
            "Test: [90/261]\tTime 0.028 (0.031)\tLoss 2.8968 (3.7149)\tPrec@1 90.000 (84.330)\tPrec@5 96.000 (96.901)\n",
            "Test: [100/261]\tTime 0.038 (0.031)\tLoss 4.6513 (3.7385)\tPrec@1 81.000 (84.218)\tPrec@5 92.000 (96.851)\n",
            "Test: [110/261]\tTime 0.050 (0.031)\tLoss 2.9184 (3.7073)\tPrec@1 85.000 (84.261)\tPrec@5 98.000 (96.919)\n",
            "Test: [120/261]\tTime 0.018 (0.030)\tLoss 2.6911 (3.7044)\tPrec@1 90.000 (84.298)\tPrec@5 95.000 (96.851)\n",
            "Test: [130/261]\tTime 0.013 (0.030)\tLoss 4.2370 (3.7206)\tPrec@1 83.000 (84.191)\tPrec@5 94.000 (96.855)\n",
            "Test: [140/261]\tTime 0.026 (0.030)\tLoss 5.2218 (3.7364)\tPrec@1 78.000 (84.106)\tPrec@5 94.000 (96.851)\n",
            "Test: [150/261]\tTime 0.030 (0.030)\tLoss 3.0544 (3.7233)\tPrec@1 87.000 (84.185)\tPrec@5 98.000 (96.854)\n",
            "Test: [160/261]\tTime 0.032 (0.029)\tLoss 2.3589 (3.7261)\tPrec@1 91.000 (84.149)\tPrec@5 99.000 (96.901)\n",
            "Test: [170/261]\tTime 0.039 (0.029)\tLoss 3.3120 (3.7150)\tPrec@1 83.000 (84.211)\tPrec@5 97.000 (96.854)\n",
            "Test: [180/261]\tTime 0.061 (0.029)\tLoss 3.1855 (3.7240)\tPrec@1 85.000 (84.149)\tPrec@5 93.000 (96.851)\n",
            "Test: [190/261]\tTime 0.037 (0.029)\tLoss 3.7419 (3.7144)\tPrec@1 84.000 (84.188)\tPrec@5 97.000 (96.885)\n",
            "Test: [200/261]\tTime 0.032 (0.029)\tLoss 3.0685 (3.7227)\tPrec@1 85.000 (84.144)\tPrec@5 99.000 (96.851)\n",
            "Test: [210/261]\tTime 0.030 (0.029)\tLoss 4.7979 (3.7213)\tPrec@1 78.000 (84.128)\tPrec@5 97.000 (96.839)\n",
            "Test: [220/261]\tTime 0.043 (0.029)\tLoss 4.4377 (3.7114)\tPrec@1 80.000 (84.163)\tPrec@5 97.000 (96.846)\n",
            "Test: [230/261]\tTime 0.021 (0.029)\tLoss 4.2382 (3.7183)\tPrec@1 80.000 (84.117)\tPrec@5 95.000 (96.835)\n",
            "Test: [240/261]\tTime 0.048 (0.029)\tLoss 2.7749 (3.7218)\tPrec@1 86.000 (84.071)\tPrec@5 97.000 (96.830)\n",
            "Test: [250/261]\tTime 0.045 (0.030)\tLoss 2.8980 (3.6952)\tPrec@1 87.000 (84.163)\tPrec@5 98.000 (96.853)\n",
            "Test: [260/261]\tTime 0.008 (0.029)\tLoss 2.6912 (3.6993)\tPrec@1 90.625 (84.162)\tPrec@5 93.750 (96.827)\n",
            "val Results: Prec@1 84.162 Prec@5 96.827 Loss 3.69929\n",
            "val Class Accuracy: [0.681,0.958,0.947,0.711,0.832,0.868,0.830,0.845,0.683,0.758]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [93][0/66], lr: 0.01000\tTime 0.978 (0.978)\tData 0.877 (0.877)\tLoss 0.5838 (0.5838)\tPrec@1 97.656 (97.656)\tPrec@5 99.609 (99.609)\n",
            "Epoch: [93][10/66], lr: 0.01000\tTime 0.098 (0.222)\tData 0.005 (0.099)\tLoss 0.3438 (0.4555)\tPrec@1 98.047 (97.692)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [93][20/66], lr: 0.01000\tTime 0.086 (0.168)\tData 0.022 (0.063)\tLoss 0.3344 (0.4937)\tPrec@1 98.828 (97.545)\tPrec@5 100.000 (99.944)\n",
            "Epoch: [93][30/66], lr: 0.01000\tTime 0.107 (0.147)\tData 0.003 (0.047)\tLoss 0.2283 (0.5073)\tPrec@1 98.438 (97.442)\tPrec@5 99.609 (99.937)\n",
            "Epoch: [93][40/66], lr: 0.01000\tTime 0.114 (0.136)\tData 0.033 (0.041)\tLoss 0.5316 (0.4665)\tPrec@1 97.266 (97.637)\tPrec@5 99.219 (99.933)\n",
            "Epoch: [93][50/66], lr: 0.01000\tTime 0.123 (0.130)\tData 0.003 (0.037)\tLoss 0.5957 (0.4603)\tPrec@1 95.703 (97.641)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [93][60/66], lr: 0.01000\tTime 0.061 (0.124)\tData 0.000 (0.031)\tLoss 0.4514 (0.4660)\tPrec@1 98.047 (97.599)\tPrec@5 100.000 (99.936)\n",
            "Test: [0/261]\tTime 0.337 (0.337)\tLoss 2.8127 (2.8127)\tPrec@1 89.000 (89.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.032 (0.057)\tLoss 4.4375 (4.3086)\tPrec@1 83.000 (81.727)\tPrec@5 97.000 (96.455)\n",
            "Test: [20/261]\tTime 0.032 (0.042)\tLoss 4.2467 (4.2679)\tPrec@1 80.000 (82.095)\tPrec@5 95.000 (96.143)\n",
            "Test: [30/261]\tTime 0.013 (0.038)\tLoss 3.3882 (4.0719)\tPrec@1 84.000 (82.871)\tPrec@5 96.000 (96.387)\n",
            "Test: [40/261]\tTime 0.036 (0.035)\tLoss 3.4895 (4.0016)\tPrec@1 88.000 (83.293)\tPrec@5 96.000 (96.537)\n",
            "Test: [50/261]\tTime 0.022 (0.033)\tLoss 3.4053 (4.0293)\tPrec@1 84.000 (83.176)\tPrec@5 97.000 (96.549)\n",
            "Test: [60/261]\tTime 0.013 (0.033)\tLoss 4.6320 (4.0053)\tPrec@1 83.000 (83.213)\tPrec@5 94.000 (96.410)\n",
            "Test: [70/261]\tTime 0.011 (0.031)\tLoss 4.6098 (3.9802)\tPrec@1 81.000 (83.310)\tPrec@5 97.000 (96.352)\n",
            "Test: [80/261]\tTime 0.035 (0.031)\tLoss 4.4119 (4.0177)\tPrec@1 80.000 (83.037)\tPrec@5 95.000 (96.321)\n",
            "Test: [90/261]\tTime 0.026 (0.031)\tLoss 4.4381 (4.0612)\tPrec@1 84.000 (82.934)\tPrec@5 94.000 (96.187)\n",
            "Test: [100/261]\tTime 0.018 (0.030)\tLoss 4.8575 (4.0652)\tPrec@1 79.000 (82.861)\tPrec@5 96.000 (96.218)\n",
            "Test: [110/261]\tTime 0.025 (0.030)\tLoss 4.1859 (4.0483)\tPrec@1 82.000 (82.838)\tPrec@5 96.000 (96.288)\n",
            "Test: [120/261]\tTime 0.027 (0.030)\tLoss 3.1003 (4.0461)\tPrec@1 85.000 (82.826)\tPrec@5 97.000 (96.314)\n",
            "Test: [130/261]\tTime 0.045 (0.030)\tLoss 4.6830 (4.0677)\tPrec@1 80.000 (82.702)\tPrec@5 93.000 (96.221)\n",
            "Test: [140/261]\tTime 0.025 (0.030)\tLoss 4.8960 (4.0501)\tPrec@1 78.000 (82.730)\tPrec@5 93.000 (96.241)\n",
            "Test: [150/261]\tTime 0.011 (0.029)\tLoss 3.5146 (4.0520)\tPrec@1 85.000 (82.722)\tPrec@5 98.000 (96.258)\n",
            "Test: [160/261]\tTime 0.039 (0.029)\tLoss 2.2563 (4.0413)\tPrec@1 90.000 (82.758)\tPrec@5 100.000 (96.342)\n",
            "Test: [170/261]\tTime 0.041 (0.029)\tLoss 2.7559 (4.0124)\tPrec@1 87.000 (82.883)\tPrec@5 96.000 (96.368)\n",
            "Test: [180/261]\tTime 0.024 (0.029)\tLoss 3.2835 (4.0262)\tPrec@1 85.000 (82.829)\tPrec@5 96.000 (96.326)\n",
            "Test: [190/261]\tTime 0.027 (0.029)\tLoss 4.7065 (4.0187)\tPrec@1 80.000 (82.874)\tPrec@5 95.000 (96.393)\n",
            "Test: [200/261]\tTime 0.025 (0.029)\tLoss 4.5052 (4.0346)\tPrec@1 80.000 (82.781)\tPrec@5 96.000 (96.398)\n",
            "Test: [210/261]\tTime 0.024 (0.029)\tLoss 3.7445 (4.0163)\tPrec@1 84.000 (82.858)\tPrec@5 97.000 (96.431)\n",
            "Test: [220/261]\tTime 0.015 (0.029)\tLoss 4.3199 (4.0176)\tPrec@1 84.000 (82.842)\tPrec@5 94.000 (96.425)\n",
            "Test: [230/261]\tTime 0.031 (0.029)\tLoss 4.9741 (4.0266)\tPrec@1 79.000 (82.784)\tPrec@5 95.000 (96.420)\n",
            "Test: [240/261]\tTime 0.022 (0.029)\tLoss 3.9692 (4.0231)\tPrec@1 80.000 (82.772)\tPrec@5 99.000 (96.415)\n",
            "Test: [250/261]\tTime 0.018 (0.028)\tLoss 3.3357 (3.9970)\tPrec@1 86.000 (82.896)\tPrec@5 99.000 (96.466)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.2681 (3.9964)\tPrec@1 87.500 (82.917)\tPrec@5 96.875 (96.439)\n",
            "val Results: Prec@1 82.917 Prec@5 96.439 Loss 3.99637\n",
            "val Class Accuracy: [0.798,0.952,0.924,0.750,0.880,0.806,0.898,0.595,0.758,0.607]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [94][0/66], lr: 0.01000\tTime 0.675 (0.675)\tData 0.537 (0.537)\tLoss 0.3359 (0.3359)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [94][10/66], lr: 0.01000\tTime 0.114 (0.154)\tData 0.000 (0.054)\tLoss 0.1920 (0.3640)\tPrec@1 98.828 (98.153)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [94][20/66], lr: 0.01000\tTime 0.102 (0.130)\tData 0.000 (0.030)\tLoss 0.5146 (0.3759)\tPrec@1 96.484 (98.010)\tPrec@5 99.609 (99.926)\n",
            "Epoch: [94][30/66], lr: 0.01000\tTime 0.077 (0.119)\tData 0.006 (0.022)\tLoss 0.5809 (0.4461)\tPrec@1 97.266 (97.681)\tPrec@5 99.609 (99.849)\n",
            "Epoch: [94][40/66], lr: 0.01000\tTime 0.083 (0.114)\tData 0.002 (0.018)\tLoss 0.6259 (0.4363)\tPrec@1 96.875 (97.761)\tPrec@5 99.609 (99.867)\n",
            "Epoch: [94][50/66], lr: 0.01000\tTime 0.097 (0.112)\tData 0.000 (0.016)\tLoss 0.4044 (0.4441)\tPrec@1 98.047 (97.725)\tPrec@5 100.000 (99.885)\n",
            "Epoch: [94][60/66], lr: 0.01000\tTime 0.097 (0.109)\tData 0.000 (0.014)\tLoss 0.7075 (0.4552)\tPrec@1 96.094 (97.656)\tPrec@5 100.000 (99.891)\n",
            "Test: [0/261]\tTime 0.279 (0.279)\tLoss 4.3205 (4.3205)\tPrec@1 81.000 (81.000)\tPrec@5 94.000 (94.000)\n",
            "Test: [10/261]\tTime 0.038 (0.061)\tLoss 4.5086 (4.6836)\tPrec@1 82.000 (80.364)\tPrec@5 96.000 (94.727)\n",
            "Test: [20/261]\tTime 0.040 (0.044)\tLoss 4.1974 (4.5455)\tPrec@1 82.000 (81.190)\tPrec@5 95.000 (95.095)\n",
            "Test: [30/261]\tTime 0.023 (0.038)\tLoss 3.4411 (4.3207)\tPrec@1 87.000 (82.355)\tPrec@5 96.000 (95.355)\n",
            "Test: [40/261]\tTime 0.025 (0.036)\tLoss 2.6895 (4.1278)\tPrec@1 90.000 (83.195)\tPrec@5 95.000 (95.561)\n",
            "Test: [50/261]\tTime 0.033 (0.034)\tLoss 3.6571 (4.1025)\tPrec@1 82.000 (83.235)\tPrec@5 96.000 (95.608)\n",
            "Test: [60/261]\tTime 0.012 (0.033)\tLoss 4.0660 (4.0688)\tPrec@1 83.000 (83.262)\tPrec@5 94.000 (95.639)\n",
            "Test: [70/261]\tTime 0.056 (0.033)\tLoss 4.5903 (4.0823)\tPrec@1 82.000 (83.113)\tPrec@5 93.000 (95.690)\n",
            "Test: [80/261]\tTime 0.025 (0.031)\tLoss 4.0611 (4.0698)\tPrec@1 83.000 (83.049)\tPrec@5 95.000 (95.728)\n",
            "Test: [90/261]\tTime 0.034 (0.032)\tLoss 4.5226 (4.1349)\tPrec@1 81.000 (82.769)\tPrec@5 96.000 (95.692)\n",
            "Test: [100/261]\tTime 0.024 (0.031)\tLoss 4.4680 (4.1227)\tPrec@1 81.000 (82.723)\tPrec@5 94.000 (95.772)\n",
            "Test: [110/261]\tTime 0.013 (0.031)\tLoss 4.0901 (4.0959)\tPrec@1 81.000 (82.784)\tPrec@5 94.000 (95.820)\n",
            "Test: [120/261]\tTime 0.042 (0.031)\tLoss 3.2846 (4.0790)\tPrec@1 87.000 (82.876)\tPrec@5 96.000 (95.777)\n",
            "Test: [130/261]\tTime 0.017 (0.030)\tLoss 4.7347 (4.0912)\tPrec@1 78.000 (82.824)\tPrec@5 94.000 (95.802)\n",
            "Test: [140/261]\tTime 0.018 (0.030)\tLoss 5.6696 (4.0946)\tPrec@1 75.000 (82.780)\tPrec@5 93.000 (95.837)\n",
            "Test: [150/261]\tTime 0.021 (0.030)\tLoss 2.9147 (4.0933)\tPrec@1 87.000 (82.841)\tPrec@5 97.000 (95.861)\n",
            "Test: [160/261]\tTime 0.020 (0.030)\tLoss 2.2752 (4.0963)\tPrec@1 90.000 (82.826)\tPrec@5 99.000 (95.925)\n",
            "Test: [170/261]\tTime 0.017 (0.030)\tLoss 3.1626 (4.0688)\tPrec@1 86.000 (82.930)\tPrec@5 97.000 (95.994)\n",
            "Test: [180/261]\tTime 0.028 (0.030)\tLoss 3.6331 (4.0664)\tPrec@1 84.000 (82.939)\tPrec@5 96.000 (96.000)\n",
            "Test: [190/261]\tTime 0.022 (0.030)\tLoss 4.0172 (4.0558)\tPrec@1 84.000 (82.948)\tPrec@5 97.000 (96.068)\n",
            "Test: [200/261]\tTime 0.046 (0.030)\tLoss 3.2840 (4.0453)\tPrec@1 84.000 (82.970)\tPrec@5 97.000 (96.085)\n",
            "Test: [210/261]\tTime 0.011 (0.029)\tLoss 3.5982 (4.0273)\tPrec@1 84.000 (83.047)\tPrec@5 98.000 (96.076)\n",
            "Test: [220/261]\tTime 0.017 (0.029)\tLoss 4.5586 (4.0290)\tPrec@1 82.000 (83.054)\tPrec@5 97.000 (96.072)\n",
            "Test: [230/261]\tTime 0.050 (0.029)\tLoss 5.3427 (4.0341)\tPrec@1 79.000 (83.052)\tPrec@5 92.000 (96.052)\n",
            "Test: [240/261]\tTime 0.037 (0.029)\tLoss 2.9544 (4.0301)\tPrec@1 88.000 (83.083)\tPrec@5 97.000 (96.050)\n",
            "Test: [250/261]\tTime 0.020 (0.029)\tLoss 3.3690 (4.0132)\tPrec@1 85.000 (83.120)\tPrec@5 97.000 (96.088)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 1.8146 (4.0149)\tPrec@1 93.750 (83.140)\tPrec@5 96.875 (96.089)\n",
            "val Results: Prec@1 83.140 Prec@5 96.089 Loss 4.01487\n",
            "val Class Accuracy: [0.624,0.914,0.892,0.927,0.908,0.845,0.828,0.804,0.625,0.573]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [95][0/66], lr: 0.01000\tTime 0.669 (0.669)\tData 0.583 (0.583)\tLoss 0.2713 (0.2713)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [95][10/66], lr: 0.01000\tTime 0.088 (0.155)\tData 0.005 (0.058)\tLoss 0.3773 (0.4318)\tPrec@1 98.438 (97.976)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [95][20/66], lr: 0.01000\tTime 0.082 (0.128)\tData 0.000 (0.033)\tLoss 0.2836 (0.3776)\tPrec@1 98.047 (98.196)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [95][30/66], lr: 0.01000\tTime 0.095 (0.118)\tData 0.004 (0.025)\tLoss 0.5604 (0.4191)\tPrec@1 97.656 (97.984)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [95][40/66], lr: 0.01000\tTime 0.094 (0.113)\tData 0.000 (0.021)\tLoss 0.2372 (0.4129)\tPrec@1 99.609 (98.028)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [95][50/66], lr: 0.01000\tTime 0.095 (0.111)\tData 0.000 (0.018)\tLoss 0.5612 (0.4320)\tPrec@1 96.875 (97.863)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [95][60/66], lr: 0.01000\tTime 0.089 (0.109)\tData 0.000 (0.016)\tLoss 0.3523 (0.4382)\tPrec@1 98.047 (97.772)\tPrec@5 100.000 (99.942)\n",
            "Test: [0/261]\tTime 0.306 (0.306)\tLoss 4.5811 (4.5811)\tPrec@1 80.000 (80.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.025 (0.059)\tLoss 4.4251 (4.7281)\tPrec@1 84.000 (80.091)\tPrec@5 96.000 (97.182)\n",
            "Test: [20/261]\tTime 0.010 (0.043)\tLoss 5.2695 (4.8143)\tPrec@1 74.000 (79.381)\tPrec@5 96.000 (96.238)\n",
            "Test: [30/261]\tTime 0.018 (0.037)\tLoss 3.6979 (4.5166)\tPrec@1 83.000 (80.871)\tPrec@5 98.000 (96.484)\n",
            "Test: [40/261]\tTime 0.017 (0.035)\tLoss 3.8991 (4.3499)\tPrec@1 85.000 (81.561)\tPrec@5 96.000 (96.610)\n",
            "Test: [50/261]\tTime 0.019 (0.034)\tLoss 4.0148 (4.3378)\tPrec@1 83.000 (81.686)\tPrec@5 97.000 (96.529)\n",
            "Test: [60/261]\tTime 0.019 (0.033)\tLoss 3.5777 (4.3096)\tPrec@1 88.000 (81.967)\tPrec@5 95.000 (96.311)\n",
            "Test: [70/261]\tTime 0.016 (0.032)\tLoss 3.9530 (4.2665)\tPrec@1 84.000 (82.000)\tPrec@5 97.000 (96.296)\n",
            "Test: [80/261]\tTime 0.024 (0.032)\tLoss 3.5098 (4.2662)\tPrec@1 85.000 (81.938)\tPrec@5 98.000 (96.222)\n",
            "Test: [90/261]\tTime 0.019 (0.031)\tLoss 4.7887 (4.3506)\tPrec@1 79.000 (81.637)\tPrec@5 92.000 (96.121)\n",
            "Test: [100/261]\tTime 0.050 (0.031)\tLoss 5.0406 (4.3379)\tPrec@1 78.000 (81.703)\tPrec@5 93.000 (96.089)\n",
            "Test: [110/261]\tTime 0.038 (0.030)\tLoss 4.1276 (4.3189)\tPrec@1 83.000 (81.775)\tPrec@5 96.000 (96.117)\n",
            "Test: [120/261]\tTime 0.026 (0.030)\tLoss 3.9652 (4.3071)\tPrec@1 82.000 (81.901)\tPrec@5 96.000 (96.107)\n",
            "Test: [130/261]\tTime 0.029 (0.030)\tLoss 4.5459 (4.3218)\tPrec@1 82.000 (81.916)\tPrec@5 95.000 (96.046)\n",
            "Test: [140/261]\tTime 0.023 (0.030)\tLoss 6.3308 (4.3305)\tPrec@1 74.000 (81.887)\tPrec@5 96.000 (96.064)\n",
            "Test: [150/261]\tTime 0.029 (0.030)\tLoss 3.2515 (4.3281)\tPrec@1 87.000 (81.901)\tPrec@5 98.000 (96.066)\n",
            "Test: [160/261]\tTime 0.019 (0.030)\tLoss 3.2746 (4.3220)\tPrec@1 88.000 (81.963)\tPrec@5 97.000 (96.106)\n",
            "Test: [170/261]\tTime 0.011 (0.029)\tLoss 3.3106 (4.2909)\tPrec@1 84.000 (82.070)\tPrec@5 96.000 (96.140)\n",
            "Test: [180/261]\tTime 0.049 (0.029)\tLoss 4.7274 (4.2891)\tPrec@1 83.000 (82.110)\tPrec@5 92.000 (96.138)\n",
            "Test: [190/261]\tTime 0.039 (0.029)\tLoss 4.2472 (4.2785)\tPrec@1 82.000 (82.162)\tPrec@5 95.000 (96.178)\n",
            "Test: [200/261]\tTime 0.033 (0.029)\tLoss 4.4584 (4.2875)\tPrec@1 81.000 (82.104)\tPrec@5 96.000 (96.204)\n",
            "Test: [210/261]\tTime 0.022 (0.029)\tLoss 3.9276 (4.2894)\tPrec@1 82.000 (82.095)\tPrec@5 96.000 (96.147)\n",
            "Test: [220/261]\tTime 0.022 (0.029)\tLoss 4.8291 (4.2934)\tPrec@1 82.000 (82.081)\tPrec@5 97.000 (96.186)\n",
            "Test: [230/261]\tTime 0.034 (0.029)\tLoss 5.4915 (4.2996)\tPrec@1 78.000 (82.056)\tPrec@5 94.000 (96.173)\n",
            "Test: [240/261]\tTime 0.046 (0.029)\tLoss 3.8307 (4.2918)\tPrec@1 83.000 (82.095)\tPrec@5 97.000 (96.178)\n",
            "Test: [250/261]\tTime 0.034 (0.030)\tLoss 3.0903 (4.2762)\tPrec@1 85.000 (82.124)\tPrec@5 99.000 (96.223)\n",
            "Test: [260/261]\tTime 0.009 (0.030)\tLoss 3.4462 (4.2849)\tPrec@1 87.500 (82.107)\tPrec@5 96.875 (96.201)\n",
            "val Results: Prec@1 82.107 Prec@5 96.201 Loss 4.28489\n",
            "val Class Accuracy: [0.788,0.938,0.901,0.908,0.849,0.833,0.781,0.775,0.369,0.632]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [96][0/66], lr: 0.01000\tTime 0.912 (0.912)\tData 0.817 (0.817)\tLoss 0.6351 (0.6351)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][10/66], lr: 0.01000\tTime 0.101 (0.205)\tData 0.005 (0.096)\tLoss 0.1277 (0.4407)\tPrec@1 99.609 (97.798)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [96][20/66], lr: 0.01000\tTime 0.125 (0.157)\tData 0.000 (0.053)\tLoss 0.8384 (0.4936)\tPrec@1 95.703 (97.545)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [96][30/66], lr: 0.01000\tTime 0.110 (0.140)\tData 0.000 (0.038)\tLoss 0.1895 (0.4825)\tPrec@1 98.828 (97.530)\tPrec@5 100.000 (99.975)\n",
            "Epoch: [96][40/66], lr: 0.01000\tTime 0.096 (0.130)\tData 0.000 (0.030)\tLoss 0.4190 (0.4925)\tPrec@1 97.266 (97.437)\tPrec@5 99.609 (99.962)\n",
            "Epoch: [96][50/66], lr: 0.01000\tTime 0.098 (0.123)\tData 0.005 (0.027)\tLoss 0.3021 (0.4846)\tPrec@1 98.828 (97.488)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [96][60/66], lr: 0.01000\tTime 0.097 (0.119)\tData 0.019 (0.024)\tLoss 0.5199 (0.4781)\tPrec@1 98.047 (97.547)\tPrec@5 100.000 (99.955)\n",
            "Test: [0/261]\tTime 0.321 (0.321)\tLoss 5.2993 (5.2993)\tPrec@1 78.000 (78.000)\tPrec@5 96.000 (96.000)\n",
            "Test: [10/261]\tTime 0.024 (0.057)\tLoss 5.4797 (4.7462)\tPrec@1 76.000 (79.364)\tPrec@5 95.000 (95.273)\n",
            "Test: [20/261]\tTime 0.030 (0.043)\tLoss 5.0519 (4.5329)\tPrec@1 77.000 (80.524)\tPrec@5 94.000 (95.476)\n",
            "Test: [30/261]\tTime 0.044 (0.038)\tLoss 3.0148 (4.2727)\tPrec@1 87.000 (81.613)\tPrec@5 99.000 (95.871)\n",
            "Test: [40/261]\tTime 0.011 (0.034)\tLoss 3.9471 (4.2194)\tPrec@1 84.000 (81.976)\tPrec@5 95.000 (96.073)\n",
            "Test: [50/261]\tTime 0.044 (0.033)\tLoss 4.5457 (4.1904)\tPrec@1 83.000 (82.235)\tPrec@5 94.000 (96.020)\n",
            "Test: [60/261]\tTime 0.017 (0.032)\tLoss 3.9864 (4.1580)\tPrec@1 84.000 (82.459)\tPrec@5 95.000 (95.918)\n",
            "Test: [70/261]\tTime 0.038 (0.031)\tLoss 4.9657 (4.1636)\tPrec@1 79.000 (82.437)\tPrec@5 96.000 (95.944)\n",
            "Test: [80/261]\tTime 0.018 (0.031)\tLoss 3.5030 (4.1146)\tPrec@1 87.000 (82.728)\tPrec@5 95.000 (96.000)\n",
            "Test: [90/261]\tTime 0.018 (0.030)\tLoss 4.3140 (4.1587)\tPrec@1 83.000 (82.582)\tPrec@5 95.000 (95.989)\n",
            "Test: [100/261]\tTime 0.028 (0.030)\tLoss 5.2956 (4.1525)\tPrec@1 76.000 (82.564)\tPrec@5 92.000 (95.891)\n",
            "Test: [110/261]\tTime 0.027 (0.030)\tLoss 4.0564 (4.1334)\tPrec@1 85.000 (82.631)\tPrec@5 94.000 (95.946)\n",
            "Test: [120/261]\tTime 0.017 (0.029)\tLoss 3.0585 (4.1387)\tPrec@1 87.000 (82.653)\tPrec@5 95.000 (95.959)\n",
            "Test: [130/261]\tTime 0.027 (0.029)\tLoss 4.6383 (4.1464)\tPrec@1 79.000 (82.611)\tPrec@5 95.000 (95.947)\n",
            "Test: [140/261]\tTime 0.037 (0.029)\tLoss 5.4808 (4.1566)\tPrec@1 76.000 (82.560)\tPrec@5 91.000 (95.894)\n",
            "Test: [150/261]\tTime 0.018 (0.029)\tLoss 4.0535 (4.1613)\tPrec@1 82.000 (82.543)\tPrec@5 97.000 (95.887)\n",
            "Test: [160/261]\tTime 0.044 (0.029)\tLoss 2.7215 (4.1560)\tPrec@1 90.000 (82.516)\tPrec@5 98.000 (95.925)\n",
            "Test: [170/261]\tTime 0.026 (0.029)\tLoss 3.5558 (4.1454)\tPrec@1 86.000 (82.585)\tPrec@5 97.000 (95.947)\n",
            "Test: [180/261]\tTime 0.040 (0.028)\tLoss 3.9693 (4.1510)\tPrec@1 85.000 (82.586)\tPrec@5 92.000 (95.939)\n",
            "Test: [190/261]\tTime 0.022 (0.028)\tLoss 3.7556 (4.1536)\tPrec@1 82.000 (82.539)\tPrec@5 95.000 (95.963)\n",
            "Test: [200/261]\tTime 0.046 (0.028)\tLoss 3.2045 (4.1425)\tPrec@1 86.000 (82.582)\tPrec@5 97.000 (95.975)\n",
            "Test: [210/261]\tTime 0.034 (0.028)\tLoss 4.2288 (4.1326)\tPrec@1 81.000 (82.621)\tPrec@5 99.000 (96.000)\n",
            "Test: [220/261]\tTime 0.033 (0.028)\tLoss 3.6603 (4.1363)\tPrec@1 85.000 (82.606)\tPrec@5 97.000 (96.005)\n",
            "Test: [230/261]\tTime 0.021 (0.028)\tLoss 4.6427 (4.1464)\tPrec@1 80.000 (82.558)\tPrec@5 94.000 (96.000)\n",
            "Test: [240/261]\tTime 0.018 (0.028)\tLoss 4.7939 (4.1582)\tPrec@1 79.000 (82.490)\tPrec@5 98.000 (95.996)\n",
            "Test: [250/261]\tTime 0.031 (0.028)\tLoss 3.8423 (4.1311)\tPrec@1 82.000 (82.586)\tPrec@5 96.000 (96.016)\n",
            "Test: [260/261]\tTime 0.006 (0.027)\tLoss 1.8615 (4.1387)\tPrec@1 93.750 (82.560)\tPrec@5 96.875 (95.997)\n",
            "val Results: Prec@1 82.560 Prec@5 95.997 Loss 4.13872\n",
            "val Class Accuracy: [0.745,0.952,0.956,0.747,0.857,0.752,0.738,0.874,0.781,0.465]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [97][0/66], lr: 0.01000\tTime 0.540 (0.540)\tData 0.473 (0.473)\tLoss 0.4050 (0.4050)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [97][10/66], lr: 0.01000\tTime 0.110 (0.154)\tData 0.005 (0.055)\tLoss 0.3537 (0.5396)\tPrec@1 98.047 (97.195)\tPrec@5 100.000 (99.929)\n",
            "Epoch: [97][20/66], lr: 0.01000\tTime 0.088 (0.129)\tData 0.005 (0.032)\tLoss 0.5254 (0.5012)\tPrec@1 97.656 (97.414)\tPrec@5 100.000 (99.963)\n",
            "Epoch: [97][30/66], lr: 0.01000\tTime 0.101 (0.118)\tData 0.005 (0.023)\tLoss 0.5406 (0.4814)\tPrec@1 97.656 (97.555)\tPrec@5 99.609 (99.950)\n",
            "Epoch: [97][40/66], lr: 0.01000\tTime 0.083 (0.112)\tData 0.000 (0.019)\tLoss 0.3836 (0.4694)\tPrec@1 98.047 (97.618)\tPrec@5 100.000 (99.933)\n",
            "Epoch: [97][50/66], lr: 0.01000\tTime 0.103 (0.110)\tData 0.002 (0.017)\tLoss 0.3780 (0.4793)\tPrec@1 97.656 (97.564)\tPrec@5 100.000 (99.939)\n",
            "Epoch: [97][60/66], lr: 0.01000\tTime 0.059 (0.109)\tData 0.000 (0.017)\tLoss 0.6297 (0.4767)\tPrec@1 96.484 (97.611)\tPrec@5 100.000 (99.942)\n",
            "Test: [0/261]\tTime 0.310 (0.310)\tLoss 4.0738 (4.0738)\tPrec@1 85.000 (85.000)\tPrec@5 97.000 (97.000)\n",
            "Test: [10/261]\tTime 0.030 (0.055)\tLoss 5.3011 (3.8462)\tPrec@1 80.000 (83.909)\tPrec@5 96.000 (96.909)\n",
            "Test: [20/261]\tTime 0.023 (0.041)\tLoss 5.4207 (3.9528)\tPrec@1 76.000 (83.190)\tPrec@5 96.000 (96.667)\n",
            "Test: [30/261]\tTime 0.015 (0.036)\tLoss 3.3074 (3.8179)\tPrec@1 83.000 (83.839)\tPrec@5 100.000 (96.903)\n",
            "Test: [40/261]\tTime 0.047 (0.035)\tLoss 3.1453 (3.7826)\tPrec@1 90.000 (83.976)\tPrec@5 97.000 (97.122)\n",
            "Test: [50/261]\tTime 0.026 (0.032)\tLoss 4.3353 (3.7705)\tPrec@1 78.000 (83.961)\tPrec@5 98.000 (97.137)\n",
            "Test: [60/261]\tTime 0.019 (0.031)\tLoss 3.6329 (3.7617)\tPrec@1 87.000 (84.033)\tPrec@5 95.000 (97.098)\n",
            "Test: [70/261]\tTime 0.027 (0.031)\tLoss 3.9635 (3.7652)\tPrec@1 82.000 (84.000)\tPrec@5 98.000 (97.155)\n",
            "Test: [80/261]\tTime 0.028 (0.031)\tLoss 3.5051 (3.7532)\tPrec@1 86.000 (84.099)\tPrec@5 98.000 (97.160)\n",
            "Test: [90/261]\tTime 0.011 (0.030)\tLoss 3.5771 (3.8004)\tPrec@1 87.000 (83.901)\tPrec@5 96.000 (97.044)\n",
            "Test: [100/261]\tTime 0.011 (0.030)\tLoss 4.4891 (3.7782)\tPrec@1 81.000 (84.000)\tPrec@5 95.000 (97.079)\n",
            "Test: [110/261]\tTime 0.035 (0.029)\tLoss 3.4437 (3.7235)\tPrec@1 85.000 (84.180)\tPrec@5 99.000 (97.180)\n",
            "Test: [120/261]\tTime 0.021 (0.029)\tLoss 3.1101 (3.7327)\tPrec@1 86.000 (84.116)\tPrec@5 96.000 (97.190)\n",
            "Test: [130/261]\tTime 0.026 (0.029)\tLoss 3.7520 (3.7337)\tPrec@1 83.000 (84.023)\tPrec@5 97.000 (97.168)\n",
            "Test: [140/261]\tTime 0.043 (0.029)\tLoss 4.8231 (3.7253)\tPrec@1 80.000 (84.021)\tPrec@5 94.000 (97.191)\n",
            "Test: [150/261]\tTime 0.027 (0.029)\tLoss 3.4240 (3.7188)\tPrec@1 85.000 (84.093)\tPrec@5 98.000 (97.199)\n",
            "Test: [160/261]\tTime 0.033 (0.029)\tLoss 2.8507 (3.7180)\tPrec@1 88.000 (84.056)\tPrec@5 99.000 (97.217)\n",
            "Test: [170/261]\tTime 0.033 (0.029)\tLoss 3.1212 (3.6910)\tPrec@1 85.000 (84.146)\tPrec@5 97.000 (97.222)\n",
            "Test: [180/261]\tTime 0.043 (0.029)\tLoss 3.1169 (3.6838)\tPrec@1 89.000 (84.177)\tPrec@5 96.000 (97.238)\n",
            "Test: [190/261]\tTime 0.027 (0.029)\tLoss 3.1791 (3.6786)\tPrec@1 87.000 (84.204)\tPrec@5 96.000 (97.241)\n",
            "Test: [200/261]\tTime 0.011 (0.028)\tLoss 2.9489 (3.6762)\tPrec@1 87.000 (84.199)\tPrec@5 96.000 (97.214)\n",
            "Test: [210/261]\tTime 0.040 (0.028)\tLoss 3.4954 (3.6844)\tPrec@1 84.000 (84.175)\tPrec@5 100.000 (97.227)\n",
            "Test: [220/261]\tTime 0.031 (0.028)\tLoss 3.6461 (3.6840)\tPrec@1 83.000 (84.163)\tPrec@5 98.000 (97.231)\n",
            "Test: [230/261]\tTime 0.029 (0.028)\tLoss 4.5750 (3.6939)\tPrec@1 81.000 (84.113)\tPrec@5 95.000 (97.225)\n",
            "Test: [240/261]\tTime 0.029 (0.028)\tLoss 3.5628 (3.6931)\tPrec@1 85.000 (84.116)\tPrec@5 97.000 (97.220)\n",
            "Test: [250/261]\tTime 0.042 (0.028)\tLoss 3.0095 (3.6720)\tPrec@1 85.000 (84.203)\tPrec@5 100.000 (97.247)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.5946 (3.6762)\tPrec@1 90.625 (84.204)\tPrec@5 96.875 (97.219)\n",
            "val Results: Prec@1 84.204 Prec@5 97.219 Loss 3.67625\n",
            "val Class Accuracy: [0.694,0.943,0.948,0.870,0.888,0.783,0.645,0.851,0.772,0.676]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [98][0/66], lr: 0.01000\tTime 0.552 (0.552)\tData 0.447 (0.447)\tLoss 0.3427 (0.3427)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [98][10/66], lr: 0.01000\tTime 0.107 (0.154)\tData 0.005 (0.050)\tLoss 0.1652 (0.4018)\tPrec@1 99.609 (98.153)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [98][20/66], lr: 0.01000\tTime 0.109 (0.128)\tData 0.005 (0.029)\tLoss 0.7573 (0.4775)\tPrec@1 96.094 (97.693)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [98][30/66], lr: 0.01000\tTime 0.088 (0.119)\tData 0.000 (0.021)\tLoss 0.3339 (0.4442)\tPrec@1 98.438 (97.883)\tPrec@5 100.000 (99.950)\n",
            "Epoch: [98][40/66], lr: 0.01000\tTime 0.113 (0.116)\tData 0.000 (0.017)\tLoss 0.4499 (0.4517)\tPrec@1 97.656 (97.790)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [98][50/66], lr: 0.01000\tTime 0.088 (0.114)\tData 0.005 (0.015)\tLoss 0.4147 (0.4708)\tPrec@1 97.656 (97.641)\tPrec@5 100.000 (99.946)\n",
            "Epoch: [98][60/66], lr: 0.01000\tTime 0.062 (0.110)\tData 0.000 (0.013)\tLoss 0.3310 (0.4693)\tPrec@1 98.438 (97.631)\tPrec@5 100.000 (99.949)\n",
            "Test: [0/261]\tTime 0.360 (0.360)\tLoss 3.8365 (3.8365)\tPrec@1 82.000 (82.000)\tPrec@5 95.000 (95.000)\n",
            "Test: [10/261]\tTime 0.027 (0.056)\tLoss 5.3138 (4.1304)\tPrec@1 80.000 (82.455)\tPrec@5 95.000 (96.455)\n",
            "Test: [20/261]\tTime 0.019 (0.044)\tLoss 4.6357 (4.1591)\tPrec@1 79.000 (82.714)\tPrec@5 96.000 (95.952)\n",
            "Test: [30/261]\tTime 0.030 (0.039)\tLoss 3.2978 (3.9849)\tPrec@1 85.000 (83.290)\tPrec@5 97.000 (96.194)\n",
            "Test: [40/261]\tTime 0.011 (0.036)\tLoss 2.7759 (3.8504)\tPrec@1 90.000 (83.878)\tPrec@5 97.000 (96.610)\n",
            "Test: [50/261]\tTime 0.027 (0.034)\tLoss 3.3252 (3.8131)\tPrec@1 85.000 (83.961)\tPrec@5 97.000 (96.529)\n",
            "Test: [60/261]\tTime 0.036 (0.033)\tLoss 3.9025 (3.8120)\tPrec@1 82.000 (83.967)\tPrec@5 96.000 (96.426)\n",
            "Test: [70/261]\tTime 0.040 (0.033)\tLoss 4.5625 (3.8002)\tPrec@1 80.000 (83.915)\tPrec@5 96.000 (96.408)\n",
            "Test: [80/261]\tTime 0.017 (0.032)\tLoss 3.5784 (3.7970)\tPrec@1 84.000 (83.926)\tPrec@5 95.000 (96.420)\n",
            "Test: [90/261]\tTime 0.037 (0.032)\tLoss 5.0333 (3.8433)\tPrec@1 80.000 (83.736)\tPrec@5 94.000 (96.308)\n",
            "Test: [100/261]\tTime 0.040 (0.031)\tLoss 4.2548 (3.8303)\tPrec@1 82.000 (83.683)\tPrec@5 95.000 (96.386)\n",
            "Test: [110/261]\tTime 0.025 (0.031)\tLoss 3.6192 (3.8006)\tPrec@1 85.000 (83.784)\tPrec@5 95.000 (96.441)\n",
            "Test: [120/261]\tTime 0.027 (0.031)\tLoss 2.9800 (3.7901)\tPrec@1 86.000 (83.818)\tPrec@5 96.000 (96.372)\n",
            "Test: [130/261]\tTime 0.026 (0.030)\tLoss 3.9330 (3.7900)\tPrec@1 84.000 (83.824)\tPrec@5 96.000 (96.359)\n",
            "Test: [140/261]\tTime 0.024 (0.030)\tLoss 5.1249 (3.7748)\tPrec@1 80.000 (83.915)\tPrec@5 93.000 (96.362)\n",
            "Test: [150/261]\tTime 0.036 (0.030)\tLoss 2.4717 (3.7822)\tPrec@1 88.000 (83.861)\tPrec@5 98.000 (96.391)\n",
            "Test: [160/261]\tTime 0.043 (0.030)\tLoss 2.5787 (3.7803)\tPrec@1 90.000 (83.832)\tPrec@5 97.000 (96.416)\n",
            "Test: [170/261]\tTime 0.030 (0.030)\tLoss 3.0211 (3.7670)\tPrec@1 87.000 (83.877)\tPrec@5 98.000 (96.468)\n",
            "Test: [180/261]\tTime 0.036 (0.030)\tLoss 3.0407 (3.7512)\tPrec@1 87.000 (83.972)\tPrec@5 95.000 (96.475)\n",
            "Test: [190/261]\tTime 0.020 (0.030)\tLoss 3.5416 (3.7469)\tPrec@1 84.000 (83.974)\tPrec@5 97.000 (96.497)\n",
            "Test: [200/261]\tTime 0.016 (0.030)\tLoss 3.5504 (3.7542)\tPrec@1 82.000 (83.905)\tPrec@5 96.000 (96.502)\n",
            "Test: [210/261]\tTime 0.020 (0.030)\tLoss 2.3677 (3.7410)\tPrec@1 87.000 (83.972)\tPrec@5 100.000 (96.521)\n",
            "Test: [220/261]\tTime 0.051 (0.030)\tLoss 3.9664 (3.7445)\tPrec@1 83.000 (83.914)\tPrec@5 97.000 (96.525)\n",
            "Test: [230/261]\tTime 0.030 (0.030)\tLoss 4.6595 (3.7542)\tPrec@1 80.000 (83.883)\tPrec@5 93.000 (96.493)\n",
            "Test: [240/261]\tTime 0.041 (0.031)\tLoss 3.2501 (3.7625)\tPrec@1 85.000 (83.855)\tPrec@5 96.000 (96.473)\n",
            "Test: [250/261]\tTime 0.034 (0.031)\tLoss 3.3228 (3.7399)\tPrec@1 85.000 (83.916)\tPrec@5 96.000 (96.502)\n",
            "Test: [260/261]\tTime 0.007 (0.031)\tLoss 2.2900 (3.7383)\tPrec@1 90.625 (83.920)\tPrec@5 96.875 (96.512)\n",
            "val Results: Prec@1 83.920 Prec@5 96.512 Loss 3.73832\n",
            "val Class Accuracy: [0.766,0.975,0.931,0.869,0.858,0.729,0.740,0.765,0.752,0.634]\n",
            "Best Prec@1: 85.583\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [99][0/66], lr: 0.01000\tTime 0.928 (0.928)\tData 0.769 (0.769)\tLoss 0.5091 (0.5091)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [99][10/66], lr: 0.01000\tTime 0.116 (0.192)\tData 0.001 (0.075)\tLoss 0.4538 (0.4376)\tPrec@1 97.266 (97.834)\tPrec@5 100.000 (99.964)\n",
            "Epoch: [99][20/66], lr: 0.01000\tTime 0.109 (0.152)\tData 0.005 (0.045)\tLoss 0.8044 (0.4722)\tPrec@1 95.703 (97.619)\tPrec@5 100.000 (99.926)\n",
            "Epoch: [99][30/66], lr: 0.01000\tTime 0.109 (0.136)\tData 0.003 (0.034)\tLoss 0.2252 (0.4757)\tPrec@1 98.438 (97.555)\tPrec@5 100.000 (99.937)\n",
            "Epoch: [99][40/66], lr: 0.01000\tTime 0.091 (0.128)\tData 0.004 (0.028)\tLoss 0.4042 (0.4594)\tPrec@1 98.047 (97.647)\tPrec@5 100.000 (99.952)\n",
            "Epoch: [99][50/66], lr: 0.01000\tTime 0.083 (0.124)\tData 0.000 (0.027)\tLoss 0.2767 (0.4482)\tPrec@1 98.828 (97.741)\tPrec@5 100.000 (99.962)\n",
            "Epoch: [99][60/66], lr: 0.01000\tTime 0.069 (0.119)\tData 0.000 (0.023)\tLoss 0.3640 (0.4536)\tPrec@1 98.047 (97.701)\tPrec@5 100.000 (99.962)\n",
            "Test: [0/261]\tTime 0.312 (0.312)\tLoss 5.8032 (5.8032)\tPrec@1 80.000 (80.000)\tPrec@5 92.000 (92.000)\n",
            "Test: [10/261]\tTime 0.032 (0.055)\tLoss 5.5075 (5.8589)\tPrec@1 79.000 (77.000)\tPrec@5 91.000 (93.545)\n",
            "Test: [20/261]\tTime 0.022 (0.042)\tLoss 5.0095 (5.6398)\tPrec@1 77.000 (77.762)\tPrec@5 95.000 (93.714)\n",
            "Test: [30/261]\tTime 0.035 (0.038)\tLoss 3.6326 (5.5055)\tPrec@1 85.000 (78.484)\tPrec@5 97.000 (94.129)\n",
            "Test: [40/261]\tTime 0.011 (0.035)\tLoss 5.1149 (5.3770)\tPrec@1 78.000 (78.951)\tPrec@5 95.000 (94.293)\n",
            "Test: [50/261]\tTime 0.047 (0.032)\tLoss 5.2423 (5.2672)\tPrec@1 82.000 (79.235)\tPrec@5 94.000 (94.392)\n",
            "Test: [60/261]\tTime 0.026 (0.032)\tLoss 5.6011 (5.2116)\tPrec@1 79.000 (79.393)\tPrec@5 94.000 (94.393)\n",
            "Test: [70/261]\tTime 0.029 (0.032)\tLoss 5.6223 (5.2198)\tPrec@1 79.000 (79.169)\tPrec@5 94.000 (94.563)\n",
            "Test: [80/261]\tTime 0.025 (0.031)\tLoss 5.9679 (5.2432)\tPrec@1 75.000 (79.012)\tPrec@5 94.000 (94.568)\n",
            "Test: [90/261]\tTime 0.025 (0.030)\tLoss 5.7627 (5.2902)\tPrec@1 78.000 (78.901)\tPrec@5 91.000 (94.396)\n",
            "Test: [100/261]\tTime 0.032 (0.030)\tLoss 6.0490 (5.2883)\tPrec@1 76.000 (78.822)\tPrec@5 92.000 (94.485)\n",
            "Test: [110/261]\tTime 0.011 (0.030)\tLoss 4.0174 (5.2477)\tPrec@1 84.000 (78.991)\tPrec@5 94.000 (94.432)\n",
            "Test: [120/261]\tTime 0.021 (0.030)\tLoss 4.2114 (5.2429)\tPrec@1 81.000 (79.025)\tPrec@5 94.000 (94.314)\n",
            "Test: [130/261]\tTime 0.039 (0.029)\tLoss 5.6308 (5.2403)\tPrec@1 74.000 (79.046)\tPrec@5 93.000 (94.328)\n",
            "Test: [140/261]\tTime 0.021 (0.029)\tLoss 6.0917 (5.2345)\tPrec@1 74.000 (79.078)\tPrec@5 93.000 (94.383)\n",
            "Test: [150/261]\tTime 0.049 (0.029)\tLoss 4.2869 (5.2247)\tPrec@1 82.000 (79.185)\tPrec@5 96.000 (94.437)\n",
            "Test: [160/261]\tTime 0.037 (0.029)\tLoss 3.6070 (5.2196)\tPrec@1 88.000 (79.149)\tPrec@5 95.000 (94.497)\n",
            "Test: [170/261]\tTime 0.025 (0.029)\tLoss 3.2954 (5.1917)\tPrec@1 85.000 (79.228)\tPrec@5 96.000 (94.544)\n",
            "Test: [180/261]\tTime 0.030 (0.029)\tLoss 5.1691 (5.1907)\tPrec@1 81.000 (79.227)\tPrec@5 93.000 (94.591)\n",
            "Test: [190/261]\tTime 0.025 (0.029)\tLoss 4.7305 (5.1921)\tPrec@1 80.000 (79.199)\tPrec@5 96.000 (94.613)\n",
            "Test: [200/261]\tTime 0.027 (0.029)\tLoss 4.3585 (5.1877)\tPrec@1 80.000 (79.209)\tPrec@5 99.000 (94.632)\n",
            "Test: [210/261]\tTime 0.035 (0.029)\tLoss 3.9531 (5.1739)\tPrec@1 80.000 (79.223)\tPrec@5 99.000 (94.659)\n",
            "Test: [220/261]\tTime 0.043 (0.029)\tLoss 5.6621 (5.1660)\tPrec@1 75.000 (79.231)\tPrec@5 94.000 (94.688)\n",
            "Test: [230/261]\tTime 0.017 (0.029)\tLoss 6.0847 (5.1761)\tPrec@1 77.000 (79.216)\tPrec@5 91.000 (94.675)\n",
            "Test: [240/261]\tTime 0.028 (0.029)\tLoss 5.4211 (5.1795)\tPrec@1 78.000 (79.178)\tPrec@5 94.000 (94.680)\n",
            "Test: [250/261]\tTime 0.019 (0.029)\tLoss 5.8596 (5.1599)\tPrec@1 77.000 (79.279)\tPrec@5 95.000 (94.713)\n",
            "Test: [260/261]\tTime 0.006 (0.028)\tLoss 2.0895 (5.1641)\tPrec@1 93.750 (79.283)\tPrec@5 96.875 (94.695)\n",
            "val Results: Prec@1 79.283 Prec@5 94.695 Loss 5.16412\n",
            "val Class Accuracy: [0.594,0.916,0.970,0.728,0.911,0.923,0.683,0.733,0.567,0.338]\n",
            "Best Prec@1: 85.583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_semi.py --dataset svhn --loss_type LDAM --imb_factor 0.02 --imb_factor_unlabel 0.02 --epochs=100 --resume '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/svhn_resnet32_LDAM_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' -e"
      ],
      "metadata": {
        "id": "q7HZAWzdgX5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382ac45e-2486-4ef3-e29a-0b10cc9fbe17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_semi.py:67: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
            "Use GPU: 0 for training\n",
            "===> Creating model 'resnet32'\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Unlabeled est total:\t13975\n",
            "After processing:\t13970,\t[4998, 3234, 2093, 1355, 876, 565, 364, 236, 153, 96]\n",
            "Labeled data extracted:\t2795\n",
            "20\n",
            "1000\n",
            "647\n",
            "419\n",
            "271\n",
            "175\n",
            "113\n",
            "73\n",
            "47\n",
            "30\n",
            "tcmalloc: large alloc 1631641600 bytes == 0x600ba000 @  0x7fe4cf5ae1e7 0x4b2590 0x5ad01c 0x7fe442fa38ba 0x7fe4431c19c6 0x7fe4431c1012 0x7fe4431cbc8d 0x7fe4431c9e84 0x7fe4431c0647 0x4d23e0 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x538786 0x5909f6 0x510d15 0x58fd37 0x50c4fc 0x58fd37 0x50c4fc\n",
            "Loading pseudo labels from ./data/pseudo_labeled_svhn.pickle\n",
            "Unlabeled data extracted:\t16765\n",
            "123\n",
            "6056\n",
            "3850\n",
            "2513\n",
            "1564\n",
            "1095\n",
            "637\n",
            "446\n",
            "303\n",
            "178\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Checkpoint '/content/drive/MyDrive/BDAProject/imbalanced-semi-self-master/checkpoint/svhn_resnet32_LDAM_None_exp_0.02_0.02_semi/ckpt.best.pth.tar' loaded, testing...\n",
            "Test: [0/261]\tTime 5.075 (5.075)\tLoss 1.8219 (1.8219)\tPrec@1 87.000 (87.000)\tPrec@5 98.000 (98.000)\n",
            "Test: [10/261]\tTime 0.019 (0.480)\tLoss 1.8302 (1.8367)\tPrec@1 84.000 (84.909)\tPrec@5 97.000 (98.000)\n",
            "Test: [20/261]\tTime 0.011 (0.264)\tLoss 1.8664 (1.8397)\tPrec@1 81.000 (84.190)\tPrec@5 97.000 (97.619)\n",
            "Test: [30/261]\tTime 0.045 (0.188)\tLoss 1.8364 (1.8343)\tPrec@1 85.000 (85.258)\tPrec@5 99.000 (97.774)\n",
            "Test: [40/261]\tTime 0.033 (0.148)\tLoss 1.8242 (1.8307)\tPrec@1 85.000 (85.610)\tPrec@5 97.000 (97.805)\n",
            "Test: [50/261]\tTime 0.045 (0.125)\tLoss 1.7979 (1.8287)\tPrec@1 92.000 (85.902)\tPrec@5 99.000 (97.882)\n",
            "Test: [60/261]\tTime 0.033 (0.111)\tLoss 1.8131 (1.8292)\tPrec@1 86.000 (85.623)\tPrec@5 98.000 (97.852)\n",
            "Test: [70/261]\tTime 0.047 (0.100)\tLoss 1.8331 (1.8294)\tPrec@1 86.000 (85.563)\tPrec@5 98.000 (97.775)\n",
            "Test: [80/261]\tTime 0.032 (0.093)\tLoss 1.8400 (1.8288)\tPrec@1 87.000 (85.704)\tPrec@5 97.000 (97.790)\n",
            "Test: [90/261]\tTime 0.034 (0.087)\tLoss 1.8624 (1.8300)\tPrec@1 79.000 (85.451)\tPrec@5 95.000 (97.692)\n",
            "Test: [100/261]\tTime 0.038 (0.082)\tLoss 1.8413 (1.8300)\tPrec@1 82.000 (85.495)\tPrec@5 96.000 (97.703)\n",
            "Test: [110/261]\tTime 0.028 (0.079)\tLoss 1.8336 (1.8300)\tPrec@1 85.000 (85.495)\tPrec@5 98.000 (97.667)\n",
            "Test: [120/261]\tTime 0.052 (0.075)\tLoss 1.8262 (1.8298)\tPrec@1 86.000 (85.529)\tPrec@5 98.000 (97.669)\n",
            "Test: [130/261]\tTime 0.032 (0.072)\tLoss 1.8511 (1.8300)\tPrec@1 83.000 (85.450)\tPrec@5 98.000 (97.695)\n",
            "Test: [140/261]\tTime 0.022 (0.069)\tLoss 1.8586 (1.8300)\tPrec@1 81.000 (85.404)\tPrec@5 97.000 (97.674)\n",
            "Test: [150/261]\tTime 0.030 (0.066)\tLoss 1.8198 (1.8296)\tPrec@1 88.000 (85.444)\tPrec@5 98.000 (97.669)\n",
            "Test: [160/261]\tTime 0.017 (0.064)\tLoss 1.7957 (1.8296)\tPrec@1 90.000 (85.366)\tPrec@5 100.000 (97.677)\n",
            "Test: [170/261]\tTime 0.025 (0.062)\tLoss 1.8403 (1.8291)\tPrec@1 87.000 (85.485)\tPrec@5 97.000 (97.725)\n",
            "Test: [180/261]\tTime 0.017 (0.059)\tLoss 1.8268 (1.8294)\tPrec@1 87.000 (85.486)\tPrec@5 96.000 (97.663)\n",
            "Test: [190/261]\tTime 0.014 (0.058)\tLoss 1.8254 (1.8291)\tPrec@1 85.000 (85.503)\tPrec@5 98.000 (97.712)\n",
            "Test: [200/261]\tTime 0.025 (0.056)\tLoss 1.8047 (1.8292)\tPrec@1 90.000 (85.493)\tPrec@5 97.000 (97.701)\n",
            "Test: [210/261]\tTime 0.035 (0.055)\tLoss 1.8398 (1.8293)\tPrec@1 86.000 (85.502)\tPrec@5 99.000 (97.701)\n",
            "Test: [220/261]\tTime 0.012 (0.053)\tLoss 1.8434 (1.8293)\tPrec@1 83.000 (85.493)\tPrec@5 99.000 (97.706)\n",
            "Test: [230/261]\tTime 0.030 (0.052)\tLoss 1.8605 (1.8295)\tPrec@1 79.000 (85.463)\tPrec@5 96.000 (97.710)\n",
            "Test: [240/261]\tTime 0.012 (0.051)\tLoss 1.8128 (1.8295)\tPrec@1 87.000 (85.485)\tPrec@5 97.000 (97.689)\n",
            "Test: [250/261]\tTime 0.021 (0.050)\tLoss 1.7890 (1.8290)\tPrec@1 90.000 (85.586)\tPrec@5 99.000 (97.697)\n",
            "Test: [260/261]\tTime 0.007 (0.049)\tLoss 1.8089 (1.8289)\tPrec@1 87.500 (85.583)\tPrec@5 100.000 (97.691)\n",
            "val Results: Prec@1 85.583 Prec@5 97.691 Loss 1.82890\n",
            "val Class Accuracy: [0.775,0.935,0.952,0.857,0.891,0.753,0.803,0.835,0.676,0.816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu9boGG7gfsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}